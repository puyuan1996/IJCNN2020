---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020739615
Z variance train             0.6925828
KL Divergence                0.14979754
KL Loss                      0.014979755
QF Loss                      170.93364
VF Loss                      28.43916
Policy Loss                  -5.2961206
Q Predictions Mean           0.00031675867
Q Predictions Std            0.001953969
Q Predictions Max            0.004820696
Q Predictions Min            -0.006647126
V Predictions Mean           0.0006681929
V Predictions Std            0.001489744
V Predictions Max            0.006949477
V Predictions Min            -0.0035818887
Log Pis Mean                 -5.3144464
Log Pis Std                  0.63060546
Log Pis Max                  -3.633874
Log Pis Min                  -7.648528
Policy mu Mean               0.00019556031
Policy mu Std                0.0018260028
Policy mu Max                0.005162905
Policy mu Min                -0.003271655
Policy log std Mean          0.000110227906
Policy log std Std           0.0018035872
Policy log std Max           0.0047096843
Policy log std Min           -0.0044151316
Z mean eval                  1.0544976
Z variance eval              0.0024129825
total_rewards                [ 13.13736166  -7.38926891  93.17613454 -20.71727439 165.7598549
  64.50569213  71.79475596  11.20247275  94.82248633   9.99270943]
total_rewards_mean           49.62849244052059
total_rewards_std            55.422712674363645
total_rewards_max            165.75985490347642
total_rewards_min            -20.717274385917413
Number of train steps total  4000
Number of env steps total    5816
Number of rollouts total     0
Train Time (s)               149.23043684707955
(Previous) Eval Time (s)     0
Sample Time (s)              21.58799327770248
Epoch Time (s)               170.81843012478203
Total Train Time (s)         200.9515971839428
Epoch                        0
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:59:13.283674 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #0 | Epoch Duration: 200.95620822906494
2020-01-12 01:59:13.284049 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0566139
Z variance train             0.002407066
KL Divergence                21.542606
KL Loss                      2.1542606
QF Loss                      181.38506
VF Loss                      31.826447
Policy Loss                  -89.68265
Q Predictions Mean           79.707436
Q Predictions Std            22.603193
Q Predictions Max            136.58455
Q Predictions Min            -20.208584
V Predictions Mean           89.10989
V Predictions Std            18.345472
V Predictions Max            138.96791
V Predictions Min            10.631987
Log Pis Mean                 -2.4285212
Log Pis Std                  1.8314219
Log Pis Max                  2.5941508
Log Pis Min                  -8.114782
Policy mu Mean               0.044504944
Policy mu Std                0.40066025
Policy mu Max                1.6059942
Policy mu Min                -1.1674106
Policy log std Mean          -0.81093395
Policy log std Std           0.11363833
Policy log std Max           -0.21670234
Policy log std Min           -1.150845
Z mean eval                  1.1397088
Z variance eval              0.005028114
total_rewards                [-175.58266771   35.645596    -46.37078067   10.06083892  -77.63924695
   31.37982564  -14.79590003  -53.50795412   10.32066599    6.17485603]
total_rewards_mean           -27.43147669183299
total_rewards_std            60.88160911848864
total_rewards_max            35.645596000592676
total_rewards_min            -175.58266770743697
Number of train steps total  8000
Number of env steps total    9872
Number of rollouts total     0
Train Time (s)               147.62579732807353
(Previous) Eval Time (s)     22.58427954511717
Sample Time (s)              13.87459096359089
Epoch Time (s)               184.0846678367816
Total Train Time (s)         385.12779380986467
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:02:17.460392 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #1 | Epoch Duration: 184.17612552642822
2020-01-12 02:02:17.460607 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1409552
Z variance train             0.00505676
KL Divergence                21.630806
KL Loss                      2.1630807
QF Loss                      377.52515
VF Loss                      60.044106
Policy Loss                  -169.96007
Q Predictions Mean           162.6568
Q Predictions Std            32.16505
Q Predictions Max            240.86234
Q Predictions Min            -60.781742
V Predictions Mean           173.03932
V Predictions Std            27.815828
V Predictions Max            246.92134
V Predictions Min            -26.464302
Log Pis Mean                 -1.2564224
Log Pis Std                  2.1493669
Log Pis Max                  5.755768
Log Pis Min                  -7.87923
Policy mu Mean               -0.011179952
Policy mu Std                0.5407934
Policy mu Max                1.6659592
Policy mu Min                -1.8308569
Policy log std Mean          -0.8368506
Policy log std Std           0.13767964
Policy log std Max           -0.26710713
Policy log std Min           -1.2649587
Z mean eval                  1.1919354
Z variance eval              0.008486282
total_rewards                [-42.91850687 -74.90735296  14.04386229   2.98243962 -70.38657656
   5.64582132  17.9697845    3.87189681  41.17354515 -32.1296302 ]
total_rewards_mean           -13.465471688001376
total_rewards_std            37.27957839181186
total_rewards_max            41.173545152492096
total_rewards_min            -74.90735295916778
Number of train steps total  12000
Number of env steps total    12769
Number of rollouts total     0
Train Time (s)               148.50378854526207
(Previous) Eval Time (s)     13.598402393981814
Sample Time (s)              13.458345065359026
Epoch Time (s)               175.5605360046029
Total Train Time (s)         560.7780516389757
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:05:13.112567 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #2 | Epoch Duration: 175.65174055099487
2020-01-12 02:05:13.112853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1879838
Z variance train             0.008594788
KL Divergence                22.08867
KL Loss                      2.208867
QF Loss                      215.13931
VF Loss                      72.14874
Policy Loss                  -218.62689
Q Predictions Mean           210.3663
Q Predictions Std            33.547077
Q Predictions Max            306.7834
Q Predictions Min            17.93596
V Predictions Mean           223.07822
V Predictions Std            28.865833
V Predictions Max            306.87415
V Predictions Min            85.75181
Log Pis Mean                 -1.7050557
Log Pis Std                  2.3909745
Log Pis Max                  7.495367
Log Pis Min                  -11.297843
Policy mu Mean               0.022688957
Policy mu Std                0.54718035
Policy mu Max                1.6941465
Policy mu Min                -1.6956433
Policy log std Mean          -0.78675675
Policy log std Std           0.132799
Policy log std Max           -0.1904356
Policy log std Min           -1.2419926
Z mean eval                  1.1943372
Z variance eval              0.005781381
total_rewards                [ 30.15888466 -22.44192132 -77.61071976  12.06497705  13.74167552
   4.14600521 -27.83406982  40.28186251  15.56433745  12.01679654]
total_rewards_mean           0.008782803868975541
total_rewards_std            32.51495620932859
total_rewards_max            40.2818625140113
total_rewards_min            -77.61071975920818
Number of train steps total  16000
Number of env steps total    16241
Number of rollouts total     0
Train Time (s)               147.22107549197972
(Previous) Eval Time (s)     23.85515489289537
Sample Time (s)              10.137045213021338
Epoch Time (s)               181.21327559789643
Total Train Time (s)         742.082006814424
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:08:14.417327 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #3 | Epoch Duration: 181.30430579185486
2020-01-12 02:08:14.417549 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1932265
Z variance train             0.0057705874
KL Divergence                22.737156
KL Loss                      2.2737157
QF Loss                      184.514
VF Loss                      38.644375
Policy Loss                  -237.90352
Q Predictions Mean           228.2254
Q Predictions Std            32.8014
Q Predictions Max            309.87054
Q Predictions Min            52.324368
V Predictions Mean           239.50693
V Predictions Std            25.89154
V Predictions Max            303.99063
V Predictions Min            154.73488
Log Pis Mean                 -2.2389333
Log Pis Std                  2.0019736
Log Pis Max                  4.044941
Log Pis Min                  -9.031786
Policy mu Mean               0.04706185
Policy mu Std                0.49314916
Policy mu Max                1.8001937
Policy mu Min                -1.7522733
Policy log std Mean          -0.7510754
Policy log std Std           0.13919504
Policy log std Max           -0.24323589
Policy log std Min           -1.3386207
Z mean eval                  1.1989933
Z variance eval              0.018279966
total_rewards                [   1.79700124  100.52926589   74.90109721   44.31445363  -13.45702129
    3.13507543   69.75661542   52.40010326   87.46440898 -183.61403938]
total_rewards_mean           23.7226960404253
total_rewards_std            78.24478208510145
total_rewards_max            100.52926589268236
total_rewards_min            -183.61403937607616
Number of train steps total  20000
Number of env steps total    19211
Number of rollouts total     0
Train Time (s)               139.12519570579752
(Previous) Eval Time (s)     24.04441267065704
Sample Time (s)              12.801806816831231
Epoch Time (s)               175.9714151932858
Total Train Time (s)         918.175864352379
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:11:10.512400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #4 | Epoch Duration: 176.0946545600891
2020-01-12 02:11:10.512656 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2023884
Z variance train             0.01827148
KL Divergence                20.219389
KL Loss                      2.021939
QF Loss                      149.64822
VF Loss                      40.489525
Policy Loss                  -253.6789
Q Predictions Mean           245.13567
Q Predictions Std            38.532124
Q Predictions Max            310.1511
Q Predictions Min            -1.4830879
V Predictions Mean           251.53381
V Predictions Std            27.833733
V Predictions Max            309.03003
V Predictions Min            91.52096
Log Pis Mean                 -2.294933
Log Pis Std                  2.140958
Log Pis Max                  5.796008
Log Pis Min                  -7.7982855
Policy mu Mean               0.07315215
Policy mu Std                0.47515523
Policy mu Max                1.8719985
Policy mu Min                -1.7857602
Policy log std Mean          -0.77948684
Policy log std Std           0.12778723
Policy log std Max           -0.23453316
Policy log std Min           -1.2556396
Z mean eval                  1.1930134
Z variance eval              0.023904419
total_rewards                [ 45.86202237  72.18432998  98.28852272  59.03729154  43.60269925
   0.50486024  76.54100898  30.42095658 109.95001052  32.26137118]
total_rewards_mean           56.86530733653363
total_rewards_std            31.525415303866687
total_rewards_max            109.95001051960334
total_rewards_min            0.5048602427953264
Number of train steps total  24000
Number of env steps total    21930
Number of rollouts total     0
Train Time (s)               139.7234011492692
(Previous) Eval Time (s)     18.080513229127973
Sample Time (s)              11.888500816654414
Epoch Time (s)               169.69241519505158
Total Train Time (s)         1087.9597620079294
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:14:00.298528 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #5 | Epoch Duration: 169.78568935394287
2020-01-12 02:14:00.298811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1967143
Z variance train             0.02406312
KL Divergence                20.824501
KL Loss                      2.0824502
QF Loss                      174.54517
VF Loss                      51.8351
Policy Loss                  -262.74182
Q Predictions Mean           254.66632
Q Predictions Std            36.797855
Q Predictions Max            337.63483
Q Predictions Min            6.0210023
V Predictions Mean           261.12518
V Predictions Std            29.941679
V Predictions Max            331.5363
V Predictions Min            156.21469
Log Pis Mean                 -2.385511
Log Pis Std                  2.034444
Log Pis Max                  4.1186814
Log Pis Min                  -7.879507
Policy mu Mean               0.040288623
Policy mu Std                0.4650556
Policy mu Max                1.6404253
Policy mu Min                -1.6847428
Policy log std Mean          -0.76992494
Policy log std Std           0.13140169
Policy log std Max           -0.3685484
Policy log std Min           -1.4375504
Z mean eval                  1.2106545
Z variance eval              0.033559225
total_rewards                [189.44157556 -13.04177735  65.48229684  99.8429142   43.07504756
 130.83152411  74.85454433 -12.09748668  22.13074185  68.01931214]
total_rewards_mean           66.85386925676625
total_rewards_std            59.54715346072747
total_rewards_max            189.44157556419432
total_rewards_min            -13.041777347867098
Number of train steps total  28000
Number of env steps total    24810
Number of rollouts total     0
Train Time (s)               143.47519650263712
(Previous) Eval Time (s)     20.624541501980275
Sample Time (s)              11.501424953807145
Epoch Time (s)               175.60116295842454
Total Train Time (s)         1263.7011395408772
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:16:56.040433 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #6 | Epoch Duration: 175.7414288520813
2020-01-12 02:16:56.040641 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2109798
Z variance train             0.033454277
KL Divergence                19.556278
KL Loss                      1.9556278
QF Loss                      339.74396
VF Loss                      42.103012
Policy Loss                  -266.46643
Q Predictions Mean           259.89056
Q Predictions Std            43.714977
Q Predictions Max            358.9482
Q Predictions Min            -35.12441
V Predictions Mean           265.07794
V Predictions Std            35.791107
V Predictions Max            360.5921
V Predictions Min            104.01368
Log Pis Mean                 -2.10249
Log Pis Std                  2.2231493
Log Pis Max                  9.603794
Log Pis Min                  -11.786749
Policy mu Mean               -0.045119744
Policy mu Std                0.4672354
Policy mu Max                1.8865727
Policy mu Min                -1.9127703
Policy log std Mean          -0.77882326
Policy log std Std           0.1370102
Policy log std Max           -0.38219434
Policy log std Min           -1.4392236
Z mean eval                  1.202303
Z variance eval              0.043017887
total_rewards                [ 12.53530024  83.81564848 102.0384848   94.44207371  83.53771296
  52.75458098  38.16175431  15.39794268 120.23954684 113.64425999]
total_rewards_mean           71.65673050030651
total_rewards_std            37.40863800840924
total_rewards_max            120.23954684477692
total_rewards_min            12.535300244037598
Number of train steps total  32000
Number of env steps total    27386
Number of rollouts total     0
Train Time (s)               148.08252565283328
(Previous) Eval Time (s)     22.578466564882547
Sample Time (s)              11.88409938942641
Epoch Time (s)               182.54509160714224
Total Train Time (s)         1446.3417553049512
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:19:58.682281 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #7 | Epoch Duration: 182.64148235321045
2020-01-12 02:19:58.682487 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #7 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1904852
Z variance train             0.043340877
KL Divergence                18.82072
KL Loss                      1.8820721
QF Loss                      185.9778
VF Loss                      83.38835
Policy Loss                  -268.1443
Q Predictions Mean           261.56787
Q Predictions Std            48.679165
Q Predictions Max            349.79916
Q Predictions Min            -47.374332
V Predictions Mean           273.82928
V Predictions Std            39.01479
V Predictions Max            358.99786
V Predictions Min            114.07263
Log Pis Mean                 -2.1378436
Log Pis Std                  2.3774507
Log Pis Max                  12.852284
Log Pis Min                  -8.142151
Policy mu Mean               0.010908625
Policy mu Std                0.45623094
Policy mu Max                1.5814681
Policy mu Min                -1.918077
Policy log std Mean          -0.788309
Policy log std Std           0.1301334
Policy log std Max           -0.34202665
Policy log std Min           -1.3360637
Z mean eval                  1.1826317
Z variance eval              0.032373484
total_rewards                [174.68346117  13.81022273  35.14565656 282.62152498 112.2579168
  22.74153156  84.89907807  65.76126897  33.34109932 129.10987527]
total_rewards_mean           95.43716354334795
total_rewards_std            79.47644900013061
total_rewards_max            282.62152498341214
total_rewards_min            13.810222731764307
Number of train steps total  36000
Number of env steps total    30489
Number of rollouts total     0
Train Time (s)               147.86339179286733
(Previous) Eval Time (s)     16.56301433267072
Sample Time (s)              13.406490257475525
Epoch Time (s)               177.83289638301358
Total Train Time (s)         1624.266385812778
Epoch                        8
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:22:56.608691 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #8 | Epoch Duration: 177.92603063583374
2020-01-12 02:22:56.608957 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1831156
Z variance train             0.032782827
KL Divergence                19.726295
KL Loss                      1.9726295
QF Loss                      170.5463
VF Loss                      50.460587
Policy Loss                  -279.77487
Q Predictions Mean           269.84418
Q Predictions Std            51.123604
Q Predictions Max            383.9404
Q Predictions Min            -49.57015
V Predictions Mean           275.6012
V Predictions Std            41.425274
V Predictions Max            359.97632
V Predictions Min            93.99472
Log Pis Mean                 -2.0414886
Log Pis Std                  2.1673114
Log Pis Max                  6.227373
Log Pis Min                  -9.221298
Policy mu Mean               0.023522282
Policy mu Std                0.47694138
Policy mu Max                2.3797014
Policy mu Min                -1.7713151
Policy log std Mean          -0.78533894
Policy log std Std           0.12057825
Policy log std Max           -0.3977667
Policy log std Min           -1.3716631
Z mean eval                  1.2297322
Z variance eval              0.03827124
total_rewards                [ 99.76966784 157.41863125 121.77692956  35.9408373   79.34231696
 170.70299875 193.40897804 -46.76904863  21.59205282 182.70847524]
total_rewards_mean           101.5891839119103
total_rewards_std            75.18646884477378
total_rewards_max            193.4089780364869
total_rewards_min            -46.76904863423529
Number of train steps total  40000
Number of env steps total    34452
Number of rollouts total     0
Train Time (s)               148.7874742182903
(Previous) Eval Time (s)     25.374113861005753
Sample Time (s)              13.398263896349818
Epoch Time (s)               187.55985197564587
Total Train Time (s)         1811.9278211891651
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:26:04.271139 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #9 | Epoch Duration: 187.6620135307312
2020-01-12 02:26:04.271400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2274735
Z variance train             0.038308285
KL Divergence                18.002083
KL Loss                      1.8002083
QF Loss                      126.11586
VF Loss                      28.29443
Policy Loss                  -288.66373
Q Predictions Mean           283.0558
Q Predictions Std            43.406525
Q Predictions Max            363.29944
Q Predictions Min            151.45932
V Predictions Mean           288.83984
V Predictions Std            40.980305
V Predictions Max            367.20013
V Predictions Min            185.00253
Log Pis Mean                 -2.2751222
Log Pis Std                  2.0265315
Log Pis Max                  9.057115
Log Pis Min                  -6.827588
Policy mu Mean               0.052466005
Policy mu Std                0.4324439
Policy mu Max                1.9591362
Policy mu Min                -1.8456533
Policy log std Mean          -0.7911769
Policy log std Std           0.121360414
Policy log std Max           -0.4418358
Policy log std Min           -1.4471177
Z mean eval                  1.2214562
Z variance eval              0.025867525
total_rewards                [348.81735834 203.01935006 140.81434318 113.55816152  95.60670708
 119.82186532  55.64308113  98.41051993  84.98843302 203.72783937]
total_rewards_mean           146.44076589523047
total_rewards_std            81.34637862318061
total_rewards_max            348.8173583372145
total_rewards_min            55.643081127025894
Number of train steps total  44000
Number of env steps total    37087
Number of rollouts total     0
Train Time (s)               148.9485857221298
(Previous) Eval Time (s)     29.100419081747532
Sample Time (s)              12.292741999961436
Epoch Time (s)               190.34174680383876
Total Train Time (s)         2002.3579883407801
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:29:14.702480 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #10 | Epoch Duration: 190.43092131614685
2020-01-12 02:29:14.702686 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #10 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2192675
Z variance train             0.025713857
KL Divergence                20.632374
KL Loss                      2.0632374
QF Loss                      149.43771
VF Loss                      55.76693
Policy Loss                  -288.57684
Q Predictions Mean           281.99014
Q Predictions Std            46.089664
Q Predictions Max            362.74335
Q Predictions Min            2.2964547
V Predictions Mean           291.4533
V Predictions Std            40.524372
V Predictions Max            370.45752
V Predictions Min            164.72441
Log Pis Mean                 -2.4438188
Log Pis Std                  2.099212
Log Pis Max                  6.022685
Log Pis Min                  -10.154972
Policy mu Mean               -0.016710188
Policy mu Std                0.44859642
Policy mu Max                1.4980482
Policy mu Min                -2.0078502
Policy log std Mean          -0.7745251
Policy log std Std           0.11876177
Policy log std Max           -0.27775234
Policy log std Min           -1.3061647
Z mean eval                  1.2236964
Z variance eval              0.058170937
total_rewards                [1.90974293e-01 7.18347402e+01 1.38768716e+02 9.96244795e+01
 1.91566389e+02 1.74852194e+02 4.47635446e+01 3.37166397e+01
 1.99138226e+02 3.01270009e+01]
total_rewards_mean           98.4582903582479
total_rewards_std            69.55353139334467
total_rewards_max            199.13822617738208
total_rewards_min            0.19097429275632694
Number of train steps total  48000
Number of env steps total    40838
Number of rollouts total     0
Train Time (s)               139.78361962363124
(Previous) Eval Time (s)     13.366811597719789
Sample Time (s)              12.692046544980258
Epoch Time (s)               165.84247776633129
Total Train Time (s)         2168.2869748091325
Epoch                        11
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:32:00.635577 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #11 | Epoch Duration: 165.93265867233276
2020-01-12 02:32:00.635909 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #11 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2240851
Z variance train             0.05720359
KL Divergence                18.3719
KL Loss                      1.83719
QF Loss                      195.5611
VF Loss                      46.754936
Policy Loss                  -307.42294
Q Predictions Mean           300.0487
Q Predictions Std            44.07146
Q Predictions Max            404.26382
Q Predictions Min            155.57442
V Predictions Mean           310.79285
V Predictions Std            39.51498
V Predictions Max            417.6064
V Predictions Min            199.60724
Log Pis Mean                 -2.2067251
Log Pis Std                  1.9792665
Log Pis Max                  10.257411
Log Pis Min                  -7.328621
Policy mu Mean               0.0103253005
Policy mu Std                0.4170177
Policy mu Max                1.6089126
Policy mu Min                -2.4236948
Policy log std Mean          -0.79141736
Policy log std Std           0.10235588
Policy log std Max           -0.47264588
Policy log std Min           -1.4746072
Z mean eval                  1.2620189
Z variance eval              0.047366537
total_rewards                [ -6.48397032 146.3312163  127.70477719  73.1033857  254.9754479
 282.83055629 255.69433913  18.48408757  11.28834583 347.96666723]
total_rewards_mean           151.1894852820649
total_rewards_std            121.02064479604506
total_rewards_max            347.9666672318244
total_rewards_min            -6.483970318780404
Number of train steps total  52000
Number of env steps total    44561
Number of rollouts total     0
Train Time (s)               140.26895567728207
(Previous) Eval Time (s)     17.30699310125783
Sample Time (s)              12.374353378079832
Epoch Time (s)               169.95030215661973
Total Train Time (s)         2338.3323191390373
Epoch                        12
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:34:50.679895 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #12 | Epoch Duration: 170.04374957084656
2020-01-12 02:34:50.680143 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2640232
Z variance train             0.04749287
KL Divergence                17.926754
KL Loss                      1.7926754
QF Loss                      142.35239
VF Loss                      54.431145
Policy Loss                  -311.0602
Q Predictions Mean           304.83682
Q Predictions Std            44.15947
Q Predictions Max            400.09412
Q Predictions Min            186.08719
V Predictions Mean           307.21906
V Predictions Std            42.836246
V Predictions Max            399.6843
V Predictions Min            188.79398
Log Pis Mean                 -2.4538088
Log Pis Std                  1.8693794
Log Pis Max                  3.6067736
Log Pis Min                  -8.396633
Policy mu Mean               0.031835176
Policy mu Std                0.4097006
Policy mu Max                1.4979184
Policy mu Min                -1.6177193
Policy log std Mean          -0.807139
Policy log std Std           0.10598414
Policy log std Max           -0.41943175
Policy log std Min           -1.3117325
Z mean eval                  1.2469945
Z variance eval              0.04247927
total_rewards                [ 84.11101734 191.28805254 153.49834452 226.74520973  95.85979475
 250.75919209 166.6386214  124.76757141 269.80564278 246.93944822]
total_rewards_mean           181.04128947797503
total_rewards_std            63.29317094075637
total_rewards_max            269.805642782332
total_rewards_min            84.11101733970159
Number of train steps total  56000
Number of env steps total    47137
Number of rollouts total     0
Train Time (s)               145.97927669575438
(Previous) Eval Time (s)     26.936512622982264
Sample Time (s)              11.46517939073965
Epoch Time (s)               184.3809687094763
Total Train Time (s)         2522.802729835268
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:37:55.151393 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #13 | Epoch Duration: 184.4710726737976
2020-01-12 02:37:55.151599 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2486366
Z variance train             0.04192553
KL Divergence                18.255875
KL Loss                      1.8255875
QF Loss                      155.13763
VF Loss                      73.169754
Policy Loss                  -305.47336
Q Predictions Mean           299.0765
Q Predictions Std            54.66857
Q Predictions Max            405.58984
Q Predictions Min            -60.620445
V Predictions Mean           309.98828
V Predictions Std            46.062653
V Predictions Max            413.61603
V Predictions Min            204.74008
Log Pis Mean                 -2.44344
Log Pis Std                  1.8572764
Log Pis Max                  4.751592
Log Pis Min                  -9.2038965
Policy mu Mean               0.021306409
Policy mu Std                0.42294756
Policy mu Max                1.9531257
Policy mu Min                -1.7261555
Policy log std Mean          -0.7945157
Policy log std Std           0.10424785
Policy log std Max           -0.34312725
Policy log std Min           -1.3588175
Z mean eval                  1.2704548
Z variance eval              0.036360122
total_rewards                [ 76.20858793 186.45120059  26.54064404  91.40161829 281.03484728
 262.75476956 158.8299596  111.13604239  55.36473865 402.3438192 ]
total_rewards_mean           165.20662275396893
total_rewards_std            112.8019557032434
total_rewards_max            402.3438192046944
total_rewards_min            26.54064404406762
Number of train steps total  60000
Number of env steps total    49664
Number of rollouts total     0
Train Time (s)               151.39915075525641
(Previous) Eval Time (s)     17.027381965890527
Sample Time (s)              10.141902423929423
Epoch Time (s)               178.56843514507636
Total Train Time (s)         2701.459562496282
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:40:53.809713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #14 | Epoch Duration: 178.65795135498047
2020-01-12 02:40:53.809920 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2757199
Z variance train             0.03641496
KL Divergence                18.764221
KL Loss                      1.8764222
QF Loss                      188.61285
VF Loss                      34.35664
Policy Loss                  -323.09882
Q Predictions Mean           315.23187
Q Predictions Std            54.34933
Q Predictions Max            414.38748
Q Predictions Min            -92.97176
V Predictions Mean           321.25763
V Predictions Std            46.173664
V Predictions Max            423.6205
V Predictions Min            86.017006
Log Pis Mean                 -2.2558029
Log Pis Std                  2.1778464
Log Pis Max                  13.8381195
Log Pis Min                  -8.532529
Policy mu Mean               0.009249026
Policy mu Std                0.43944675
Policy mu Max                2.2206273
Policy mu Min                -1.8399125
Policy log std Mean          -0.7981715
Policy log std Std           0.10566142
Policy log std Max           -0.47572726
Policy log std Min           -1.447911
Z mean eval                  1.303474
Z variance eval              0.034887612
total_rewards                [195.05687977 137.93887795 277.9471638  164.94660751 168.90507111
 295.76610441 254.32917343 466.8927822  592.13462483  91.34091444]
total_rewards_mean           264.5258199453228
total_rewards_std            148.13592476989174
total_rewards_max            592.1346248266684
total_rewards_min            91.34091444345785
Number of train steps total  64000
Number of env steps total    52700
Number of rollouts total     0
Train Time (s)               148.25464148120955
(Previous) Eval Time (s)     34.777983378153294
Sample Time (s)              13.211725275963545
Epoch Time (s)               196.24435013532639
Total Train Time (s)         2897.7883442379534
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:44:10.139365 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #15 | Epoch Duration: 196.32929754257202
2020-01-12 02:44:10.139552 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3063362
Z variance train             0.03484661
KL Divergence                19.208904
KL Loss                      1.9208905
QF Loss                      184.11522
VF Loss                      36.78253
Policy Loss                  -331.59973
Q Predictions Mean           322.12103
Q Predictions Std            51.049385
Q Predictions Max            426.9307
Q Predictions Min            58.86532
V Predictions Mean           330.80005
V Predictions Std            44.85094
V Predictions Max            439.66458
V Predictions Min            199.1062
Log Pis Mean                 -2.5377214
Log Pis Std                  1.9466329
Log Pis Max                  5.3180423
Log Pis Min                  -9.330341
Policy mu Mean               0.040640373
Policy mu Std                0.41549695
Policy mu Max                1.6091115
Policy mu Min                -2.0949423
Policy log std Mean          -0.7846751
Policy log std Std           0.10022927
Policy log std Max           -0.3209231
Policy log std Min           -1.3073584
Z mean eval                  1.3294942
Z variance eval              0.04074596
total_rewards                [184.64822765 265.35430516 181.25977289 145.97689856 320.75916349
 187.23252271   7.80901971 183.11779006 311.74237195  87.65409654]
total_rewards_mean           187.55541687134138
total_rewards_std            91.27102656453631
total_rewards_max            320.75916349164885
total_rewards_min            7.809019711971092
Number of train steps total  68000
Number of env steps total    56192
Number of rollouts total     0
Train Time (s)               151.30775674106553
(Previous) Eval Time (s)     28.45471150521189
Sample Time (s)              11.793275048956275
Epoch Time (s)               191.5557432952337
Total Train Time (s)         3089.4362739026546
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:47:21.788922 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #16 | Epoch Duration: 191.6492099761963
2020-01-12 02:47:21.789166 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #16 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3237432
Z variance train             0.040714182
KL Divergence                19.772324
KL Loss                      1.9772323
QF Loss                      158.1973
VF Loss                      41.14605
Policy Loss                  -328.8086
Q Predictions Mean           321.50266
Q Predictions Std            54.517982
Q Predictions Max            410.27863
Q Predictions Min            -18.132355
V Predictions Mean           330.66406
V Predictions Std            48.23886
V Predictions Max            413.96408
V Predictions Min            74.59718
Log Pis Mean                 -2.4556446
Log Pis Std                  2.5660677
Log Pis Max                  21.902065
Log Pis Min                  -8.379854
Policy mu Mean               0.03059306
Policy mu Std                0.42073667
Policy mu Max                3.0792487
Policy mu Min                -3.396662
Policy log std Mean          -0.80039823
Policy log std Std           0.102675095
Policy log std Max           -0.5026946
Policy log std Min           -1.266088
Z mean eval                  1.4828961
Z variance eval              0.3755185
total_rewards                [304.8658626  338.18743483 291.10481077   7.84608071 525.8450893
 487.40894002  20.09316662 210.51739328 312.16863542 282.40192813]
total_rewards_mean           278.04393416826736
total_rewards_std            159.69820310094735
total_rewards_max            525.8450893030268
total_rewards_min            7.8460807123094725
Number of train steps total  72000
Number of env steps total    59855
Number of rollouts total     0
Train Time (s)               148.4855574159883
(Previous) Eval Time (s)     27.416539925150573
Sample Time (s)              12.058784551918507
Epoch Time (s)               187.96088189305738
Total Train Time (s)         3277.482942267321
Epoch                        17
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:50:29.838692 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #17 | Epoch Duration: 188.04933834075928
2020-01-12 02:50:29.838973 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4858599
Z variance train             0.3751647
KL Divergence                16.323696
KL Loss                      1.6323696
QF Loss                      182.93225
VF Loss                      57.646034
Policy Loss                  -341.3095
Q Predictions Mean           331.05008
Q Predictions Std            66.03375
Q Predictions Max            448.1032
Q Predictions Min            -78.02628
V Predictions Mean           341.86923
V Predictions Std            52.389297
V Predictions Max            440.20917
V Predictions Min            167.1121
Log Pis Mean                 -2.5073783
Log Pis Std                  2.1113281
Log Pis Max                  9.134172
Log Pis Min                  -9.419468
Policy mu Mean               0.034670852
Policy mu Std                0.39561084
Policy mu Max                2.516118
Policy mu Min                -2.496137
Policy log std Mean          -0.798236
Policy log std Std           0.0920228
Policy log std Max           -0.45037144
Policy log std Min           -1.3393693
Z mean eval                  1.4210136
Z variance eval              0.057326168
total_rewards                [535.15331672 314.84739974 270.34055575 461.27773744 124.54470295
  64.90408064 138.01823042  68.14646406 497.10660008 302.83745984]
total_rewards_mean           277.7176547658345
total_rewards_std            168.03290187375546
total_rewards_max            535.153316722492
total_rewards_min            64.9040806403029
Number of train steps total  76000
Number of env steps total    63369
Number of rollouts total     0
Train Time (s)               136.91146493609995
(Previous) Eval Time (s)     22.498874149285257
Sample Time (s)              11.911144590936601
Epoch Time (s)               171.3214836763218
Total Train Time (s)         3448.8943955912255
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:53:21.252294 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #18 | Epoch Duration: 171.41300415992737
2020-01-12 02:53:21.252707 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4244914
Z variance train             0.057714313
KL Divergence                20.22934
KL Loss                      2.022934
QF Loss                      125.477615
VF Loss                      35.897766
Policy Loss                  -349.8206
Q Predictions Mean           339.9798
Q Predictions Std            56.913456
Q Predictions Max            472.38773
Q Predictions Min            216.2889
V Predictions Mean           347.63483
V Predictions Std            54.466732
V Predictions Max            472.4532
V Predictions Min            233.71465
Log Pis Mean                 -2.3473458
Log Pis Std                  1.8495461
Log Pis Max                  3.47024
Log Pis Min                  -9.865513
Policy mu Mean               0.006614738
Policy mu Std                0.38176084
Policy mu Max                1.5022734
Policy mu Min                -1.6681468
Policy log std Mean          -0.8112436
Policy log std Std           0.09603042
Policy log std Max           -0.5191695
Policy log std Min           -1.2920827
Z mean eval                  1.4022312
Z variance eval              0.0421261
total_rewards                [811.09796853 458.9515687  767.7370265  884.52342273  87.93569222
  92.34273914 294.04093172 332.27573331 406.66255356 368.65949918]
total_rewards_mean           450.4227135596132
total_rewards_std            269.4296631771421
total_rewards_max            884.5234227301944
total_rewards_min            87.93569222427982
Number of train steps total  80000
Number of env steps total    67114
Number of rollouts total     0
Train Time (s)               137.96470968518406
(Previous) Eval Time (s)     26.9362335591577
Sample Time (s)              12.359632932115346
Epoch Time (s)               177.2605761764571
Total Train Time (s)         3626.2477945126593
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:56:18.605507 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #19 | Epoch Duration: 177.35253596305847
2020-01-12 02:56:18.605711 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4003032
Z variance train             0.041811295
KL Divergence                21.030094
KL Loss                      2.1030095
QF Loss                      180.47649
VF Loss                      41.305855
Policy Loss                  -347.62097
Q Predictions Mean           337.4585
Q Predictions Std            68.267105
Q Predictions Max            482.63702
Q Predictions Min            -47.182274
V Predictions Mean           348.58292
V Predictions Std            55.599094
V Predictions Max            497.3725
V Predictions Min            59.703423
Log Pis Mean                 -2.37856
Log Pis Std                  2.3020163
Log Pis Max                  12.412126
Log Pis Min                  -9.090819
Policy mu Mean               0.019498628
Policy mu Std                0.4176955
Policy mu Max                2.1429677
Policy mu Min                -2.216785
Policy log std Mean          -0.8047863
Policy log std Std           0.09982979
Policy log std Max           -0.48774385
Policy log std Min           -1.5518197
Z mean eval                  1.3987427
Z variance eval              0.049248952
total_rewards                [ 11.06835484  94.0599027  155.37264937 323.89939119 239.82868274
  87.10290009 497.20806323 276.87390371 442.84356349 119.0453643 ]
total_rewards_mean           224.73027756652013
total_rewards_std            152.3962671670747
total_rewards_max            497.208063232042
total_rewards_min            11.068354843661416
Number of train steps total  84000
Number of env steps total    69621
Number of rollouts total     0
Train Time (s)               142.5562929310836
(Previous) Eval Time (s)     18.772278748918325
Sample Time (s)              10.502183090429753
Epoch Time (s)               171.83075477043167
Total Train Time (s)         3798.168584979605
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:59:10.528804 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #20 | Epoch Duration: 171.92283940315247
2020-01-12 02:59:10.529157 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3995701
Z variance train             0.048856314
KL Divergence                20.03452
KL Loss                      2.003452
QF Loss                      244.84671
VF Loss                      27.02066
Policy Loss                  -362.95642
Q Predictions Mean           353.2582
Q Predictions Std            75.41545
Q Predictions Max            491.32452
Q Predictions Min            -92.74903
V Predictions Mean           362.8625
V Predictions Std            59.268497
V Predictions Max            477.35696
V Predictions Min            68.13546
Log Pis Mean                 -2.321042
Log Pis Std                  2.3980908
Log Pis Max                  12.666454
Log Pis Min                  -8.6352005
Policy mu Mean               0.031222949
Policy mu Std                0.42650926
Policy mu Max                2.7344012
Policy mu Min                -2.5338068
Policy log std Mean          -0.8112147
Policy log std Std           0.10402053
Policy log std Max           -0.48549283
Policy log std Min           -1.5373068
Z mean eval                  1.3130854
Z variance eval              0.07937112
total_rewards                [171.20400881 154.53784001 351.8654592  362.16522525  86.41582651
 184.2886704  490.75217553 245.98119051 519.36662709 470.7795888 ]
total_rewards_mean           303.7356612106461
total_rewards_std            148.24363629547526
total_rewards_max            519.366627090738
total_rewards_min            86.41582650764498
Number of train steps total  88000
Number of env steps total    72257
Number of rollouts total     0
Train Time (s)               147.27454910008237
(Previous) Eval Time (s)     21.675254868343472
Sample Time (s)              12.135653132107109
Epoch Time (s)               181.08545710053295
Total Train Time (s)         3979.346457324922
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:02:11.707330 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #21 | Epoch Duration: 181.1779580116272
2020-01-12 03:02:11.707586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3182023
Z variance train             0.0792858
KL Divergence                16.366688
KL Loss                      1.6366688
QF Loss                      154.13914
VF Loss                      42.72235
Policy Loss                  -376.57123
Q Predictions Mean           366.88132
Q Predictions Std            60.175167
Q Predictions Max            494.76544
Q Predictions Min            210.85594
V Predictions Mean           376.66635
V Predictions Std            56.375095
V Predictions Max            494.16318
V Predictions Min            234.20027
Log Pis Mean                 -2.3602989
Log Pis Std                  1.9613153
Log Pis Max                  4.029257
Log Pis Min                  -9.674251
Policy mu Mean               0.030863091
Policy mu Std                0.39871535
Policy mu Max                1.6214503
Policy mu Min                -2.167438
Policy log std Mean          -0.8204947
Policy log std Std           0.093330525
Policy log std Max           -0.4475934
Policy log std Min           -1.2983797
Z mean eval                  1.3477523
Z variance eval              0.06495686
total_rewards                [333.5829457   -2.48063959 354.49329771  94.16219532 295.08248459
 485.45692756 461.04481152 208.96084629  64.27924902 168.29644263]
total_rewards_mean           246.28785607387
total_rewards_std            158.3234793326504
total_rewards_max            485.4569275601168
total_rewards_min            -2.480639588324076
Number of train steps total  92000
Number of env steps total    76083
Number of rollouts total     0
Train Time (s)               146.52307974081486
(Previous) Eval Time (s)     17.257477768231183
Sample Time (s)              12.267700236290693
Epoch Time (s)               176.04825774533674
Total Train Time (s)         4155.479520534165
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:05:07.841474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #22 | Epoch Duration: 176.13373017311096
2020-01-12 03:05:07.841649 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3438189
Z variance train             0.06467514
KL Divergence                19.075075
KL Loss                      1.9075075
QF Loss                      154.93454
VF Loss                      52.139046
Policy Loss                  -368.02237
Q Predictions Mean           361.42148
Q Predictions Std            59.569458
Q Predictions Max            481.8993
Q Predictions Min            203.5424
V Predictions Mean           370.26855
V Predictions Std            57.381023
V Predictions Max            496.56067
V Predictions Min            245.5625
Log Pis Mean                 -2.3555503
Log Pis Std                  2.018947
Log Pis Max                  5.7502327
Log Pis Min                  -9.9517565
Policy mu Mean               -0.005768822
Policy mu Std                0.40182257
Policy mu Max                1.7918863
Policy mu Min                -1.9746653
Policy log std Mean          -0.8226555
Policy log std Std           0.09060623
Policy log std Max           -0.49038047
Policy log std Min           -1.2909606
Z mean eval                  2.4416935
Z variance eval              0.15058038
total_rewards                [290.35770343 297.95989987  49.21040347 231.60117555 274.73895028
 294.47166665  57.45377998 461.87422465 287.21605981 963.43386158]
total_rewards_mean           320.8317725264958
total_rewards_std            242.7632310950705
total_rewards_max            963.4338615821122
total_rewards_min            49.21040346681495
Number of train steps total  96000
Number of env steps total    78912
Number of rollouts total     0
Train Time (s)               147.4154945272021
(Previous) Eval Time (s)     27.749587316066027
Sample Time (s)              12.348867329303175
Epoch Time (s)               187.5139491725713
Total Train Time (s)         4343.110650794581
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:08:15.474024 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #23 | Epoch Duration: 187.63221955299377
2020-01-12 03:08:15.474222 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4417686
Z variance train             0.15157226
KL Divergence                27.499987
KL Loss                      2.7499988
QF Loss                      227.53139
VF Loss                      50.570732
Policy Loss                  -365.34372
Q Predictions Mean           355.3521
Q Predictions Std            83.52966
Q Predictions Max            478.18652
Q Predictions Min            -29.2401
V Predictions Mean           365.7395
V Predictions Std            68.36756
V Predictions Max            485.02655
V Predictions Min            -22.208204
Log Pis Mean                 -2.2682145
Log Pis Std                  2.4198747
Log Pis Max                  13.000246
Log Pis Min                  -8.456212
Policy mu Mean               0.020821333
Policy mu Std                0.42755505
Policy mu Max                2.0605674
Policy mu Min                -2.543626
Policy log std Mean          -0.8214097
Policy log std Std           0.09645924
Policy log std Max           -0.40116188
Policy log std Min           -1.3974726
Z mean eval                  1.854546
Z variance eval              0.07860614
total_rewards                [815.24697519  79.97065291 309.55615363 141.57383328 654.49212313
  12.54923024 430.17649747  11.76948952 802.90156926 334.82241989]
total_rewards_mean           359.305894451262
total_rewards_std            294.3380005344088
total_rewards_max            815.2469751908708
total_rewards_min            11.769489518625662
Number of train steps total  100000
Number of env steps total    82460
Number of rollouts total     0
Train Time (s)               146.662843960803
(Previous) Eval Time (s)     23.13341499119997
Sample Time (s)              10.492659726180136
Epoch Time (s)               180.2889186781831
Total Train Time (s)         4523.491182946134
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:11:15.855803 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #24 | Epoch Duration: 180.38142657279968
2020-01-12 03:11:15.856006 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8627037
Z variance train             0.07746436
KL Divergence                25.92554
KL Loss                      2.592554
QF Loss                      221.19415
VF Loss                      41.43488
Policy Loss                  -368.38867
Q Predictions Mean           359.17923
Q Predictions Std            63.737587
Q Predictions Max            480.06235
Q Predictions Min            22.692797
V Predictions Mean           369.78192
V Predictions Std            58.696167
V Predictions Max            480.6085
V Predictions Min            147.9251
Log Pis Mean                 -2.1573215
Log Pis Std                  2.4183059
Log Pis Max                  15.322132
Log Pis Min                  -8.215649
Policy mu Mean               -0.022378454
Policy mu Std                0.42429537
Policy mu Max                2.2049677
Policy mu Min                -2.7483659
Policy log std Mean          -0.8401432
Policy log std Std           0.09414792
Policy log std Max           -0.53383636
Policy log std Min           -1.273047
Z mean eval                  1.631383
Z variance eval              0.111878
total_rewards                [486.81425075  17.89421816 401.53992424 295.74227505 278.88080094
 364.55104412 341.9814913  200.53985843 374.75955168 670.23918802]
total_rewards_mean           343.2942602687023
total_rewards_std            162.78865479370816
total_rewards_max            670.2391880178311
total_rewards_min            17.894218162010358
Number of train steps total  104000
Number of env steps total    86176
Number of rollouts total     0
Train Time (s)               137.4365718793124
(Previous) Eval Time (s)     27.168549482244998
Sample Time (s)              12.18144562235102
Epoch Time (s)               176.78656698390841
Total Train Time (s)         4700.36376320431
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:14:12.730294 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #25 | Epoch Duration: 176.87410736083984
2020-01-12 03:14:12.730571 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6347357
Z variance train             0.11245316
KL Divergence                23.996008
KL Loss                      2.3996007
QF Loss                      271.51102
VF Loss                      99.042114
Policy Loss                  -373.2381
Q Predictions Mean           364.20837
Q Predictions Std            83.50437
Q Predictions Max            494.3102
Q Predictions Min            -81.99213
V Predictions Mean           373.0412
V Predictions Std            68.51606
V Predictions Max            491.56018
V Predictions Min            1.5513592
Log Pis Mean                 -1.8529725
Log Pis Std                  2.8296227
Log Pis Max                  18.762947
Log Pis Min                  -6.9047403
Policy mu Mean               -0.025435336
Policy mu Std                0.46465966
Policy mu Max                2.6323216
Policy mu Min                -2.924293
Policy log std Mean          -0.82553506
Policy log std Std           0.107514046
Policy log std Max           -0.48349053
Policy log std Min           -1.4485087
Z mean eval                  1.4134004
Z variance eval              0.13116701
total_rewards                [1055.14520692  234.48677266   57.42980762  976.86709406  450.53464548
  329.08865297 1103.09022335  357.42399778  911.48347099  773.69487888]
total_rewards_mean           624.9244750718883
total_rewards_std            361.36181423798627
total_rewards_max            1103.0902233523398
total_rewards_min            57.42980762183191
Number of train steps total  108000
Number of env steps total    90906
Number of rollouts total     0
Train Time (s)               137.4804749172181
(Previous) Eval Time (s)     26.611884457990527
Sample Time (s)              12.899966748431325
Epoch Time (s)               176.99232612363994
Total Train Time (s)         4877.443429686595
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:17:09.811065 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #26 | Epoch Duration: 177.08031463623047
2020-01-12 03:17:09.811288 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #26 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4111258
Z variance train             0.13101816
KL Divergence                23.045288
KL Loss                      2.304529
QF Loss                      222.0751
VF Loss                      37.27869
Policy Loss                  -361.40402
Q Predictions Mean           351.7398
Q Predictions Std            76.761734
Q Predictions Max            489.82117
Q Predictions Min            13.6778755
V Predictions Mean           362.74197
V Predictions Std            66.16595
V Predictions Max            494.4371
V Predictions Min            213.09512
Log Pis Mean                 -2.158417
Log Pis Std                  2.187752
Log Pis Max                  7.5586033
Log Pis Min                  -8.207475
Policy mu Mean               -0.008376284
Policy mu Std                0.42011878
Policy mu Max                1.750129
Policy mu Min                -1.7666602
Policy log std Mean          -0.8281004
Policy log std Std           0.10285406
Policy log std Max           -0.48455453
Policy log std Min           -1.2793605
Z mean eval                  1.2446897
Z variance eval              0.843377
total_rewards                [260.51082116 948.64149902 158.89347471 710.08922118 769.7173429
 634.04669463 271.08089179 313.33148039 477.55338576 388.41555595]
total_rewards_mean           493.22803674828094
total_rewards_std            246.8981173241929
total_rewards_max            948.6414990244448
total_rewards_min            158.89347470943147
Number of train steps total  112000
Number of env steps total    93406
Number of rollouts total     0
Train Time (s)               142.4879337460734
(Previous) Eval Time (s)     25.278495298698545
Sample Time (s)              11.450237339828163
Epoch Time (s)               179.2166663846001
Total Train Time (s)         5056.745911771432
Epoch                        27
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:20:09.114655 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #27 | Epoch Duration: 179.3032157421112
2020-01-12 03:20:09.114841 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2416253
Z variance train             0.84292746
KL Divergence                18.197878
KL Loss                      1.8197879
QF Loss                      243.58125
VF Loss                      87.10949
Policy Loss                  -373.35828
Q Predictions Mean           366.0035
Q Predictions Std            74.79334
Q Predictions Max            517.86804
Q Predictions Min            -25.730188
V Predictions Mean           367.75125
V Predictions Std            66.94416
V Predictions Max            512.1696
V Predictions Min            211.16031
Log Pis Mean                 -2.597168
Log Pis Std                  1.9798702
Log Pis Max                  7.0057774
Log Pis Min                  -9.202297
Policy mu Mean               0.02604071
Policy mu Std                0.378956
Policy mu Max                1.8595932
Policy mu Min                -2.2845535
Policy log std Mean          -0.79413617
Policy log std Std           0.10050629
Policy log std Max           -0.43599516
Policy log std Min           -1.1500654
Z mean eval                  1.4356389
Z variance eval              0.07287562
total_rewards                [369.89490597 632.28718247 132.46653401 579.97710664 822.73918926
 413.05585358 837.27028043 469.51711728 125.59874485 794.06519386]
total_rewards_mean           517.6872108365417
total_rewards_std            250.1653455716603
total_rewards_max            837.2702804260814
total_rewards_min            125.5987448538993
Number of train steps total  116000
Number of env steps total    98686
Number of rollouts total     0
Train Time (s)               147.89368030428886
(Previous) Eval Time (s)     25.755507335998118
Sample Time (s)              11.059172335080802
Epoch Time (s)               184.70835997536778
Total Train Time (s)         5241.553789314348
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:23:13.924302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #28 | Epoch Duration: 184.8093032836914
2020-01-12 03:23:13.924541 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4319819
Z variance train             0.07385673
KL Divergence                23.7532
KL Loss                      2.3753202
QF Loss                      262.5862
VF Loss                      101.181145
Policy Loss                  -356.39288
Q Predictions Mean           344.1233
Q Predictions Std            82.16987
Q Predictions Max            489.15222
Q Predictions Min            -94.52217
V Predictions Mean           349.9946
V Predictions Std            72.18406
V Predictions Max            486.97125
V Predictions Min            46.012783
Log Pis Mean                 -2.011149
Log Pis Std                  2.874235
Log Pis Max                  25.531586
Log Pis Min                  -7.738886
Policy mu Mean               0.0017506649
Policy mu Std                0.4307712
Policy mu Max                3.9783254
Policy mu Min                -4.1726265
Policy log std Mean          -0.8331101
Policy log std Std           0.10811155
Policy log std Max           -0.37104166
Policy log std Min           -1.5073147
Z mean eval                  1.2933996
Z variance eval              0.08145963
total_rewards                [265.00636092 186.81269914 470.63668123  12.71739145 525.10890636
 144.47095413 864.8448121  136.00301165 405.08107948 300.45934276]
total_rewards_mean           331.1141239230446
total_rewards_std            234.06269010045636
total_rewards_max            864.8448121020633
total_rewards_min            12.717391454527954
Number of train steps total  120000
Number of env steps total    101647
Number of rollouts total     0
Train Time (s)               147.27348717628047
(Previous) Eval Time (s)     19.248615962918848
Sample Time (s)              12.308090801350772
Epoch Time (s)               178.8301939405501
Total Train Time (s)         5420.774091814645
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:26:13.145749 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #29 | Epoch Duration: 179.2210512161255
2020-01-12 03:26:13.145941 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2910507
Z variance train             0.081003785
KL Divergence                23.149887
KL Loss                      2.3149889
QF Loss                      180.01497
VF Loss                      55.51188
Policy Loss                  -377.4206
Q Predictions Mean           371.13132
Q Predictions Std            78.24858
Q Predictions Max            498.89792
Q Predictions Min            -37.35169
V Predictions Mean           378.22748
V Predictions Std            71.76893
V Predictions Max            512.6933
V Predictions Min            150.10062
Log Pis Mean                 -2.2848296
Log Pis Std                  2.1342714
Log Pis Max                  13.095684
Log Pis Min                  -9.858968
Policy mu Mean               -0.0022894219
Policy mu Std                0.41405228
Policy mu Max                2.482556
Policy mu Min                -2.425794
Policy log std Mean          -0.82575434
Policy log std Std           0.10072149
Policy log std Max           -0.39987442
Policy log std Min           -1.4960033
Z mean eval                  1.2519033
Z variance eval              0.08317338
total_rewards                [ 452.86353882  342.61711785 1088.40619335  389.80423212  698.14111444
  708.77957602  557.82831784   51.12180601  536.18790685  528.79014868]
total_rewards_mean           535.4539951978094
total_rewards_std            257.4119874203093
total_rewards_max            1088.406193345198
total_rewards_min            51.121806014710806
Number of train steps total  124000
Number of env steps total    105513
Number of rollouts total     0
Train Time (s)               147.96308364486322
(Previous) Eval Time (s)     30.807130305096507
Sample Time (s)              12.324702647514641
Epoch Time (s)               191.09491659747437
Total Train Time (s)         5611.955492649227
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:29:24.328515 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #30 | Epoch Duration: 191.1824288368225
2020-01-12 03:29:24.328698 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2545388
Z variance train             0.08338394
KL Divergence                22.710417
KL Loss                      2.2710416
QF Loss                      211.57205
VF Loss                      55.683693
Policy Loss                  -382.42926
Q Predictions Mean           373.2529
Q Predictions Std            84.78854
Q Predictions Max            569.25836
Q Predictions Min            211.3968
V Predictions Mean           382.77863
V Predictions Std            79.22591
V Predictions Max            539.30493
V Predictions Min            222.81812
Log Pis Mean                 -2.2149904
Log Pis Std                  2.4665349
Log Pis Max                  11.475931
Log Pis Min                  -10.5176525
Policy mu Mean               0.025362875
Policy mu Std                0.42864892
Policy mu Max                3.7684503
Policy mu Min                -2.3512673
Policy log std Mean          -0.83543
Policy log std Std           0.110755764
Policy log std Max           -0.4269026
Policy log std Min           -1.3611552
Z mean eval                  1.242022
Z variance eval              0.0828768
total_rewards                [ 708.3128325   487.54916521  533.95019586 1011.9766648   529.58503019
  266.79091234  304.97818739   65.13845575  833.60262766  158.48472433]
total_rewards_mean           490.0368796021095
total_rewards_std            285.68383962445614
total_rewards_max            1011.9766647982142
total_rewards_min            65.13845575255617
Number of train steps total  128000
Number of env steps total    109411
Number of rollouts total     0
Train Time (s)               145.8466008347459
(Previous) Eval Time (s)     27.222115635871887
Sample Time (s)              12.22536780172959
Epoch Time (s)               185.2940842723474
Total Train Time (s)         5797.336746307556
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:32:29.711394 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #31 | Epoch Duration: 185.3825500011444
2020-01-12 03:32:29.711617 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #31 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2341808
Z variance train             0.08410156
KL Divergence                22.97426
KL Loss                      2.297426
QF Loss                      275.87735
VF Loss                      116.41944
Policy Loss                  -396.74643
Q Predictions Mean           387.83228
Q Predictions Std            89.76276
Q Predictions Max            533.05585
Q Predictions Min            -86.537056
V Predictions Mean           404.61652
V Predictions Std            79.99831
V Predictions Max            532.46906
V Predictions Min            259.06445
Log Pis Mean                 -2.0763698
Log Pis Std                  1.9937294
Log Pis Max                  4.277859
Log Pis Min                  -7.441659
Policy mu Mean               0.0039936923
Policy mu Std                0.4235562
Policy mu Max                1.9051383
Policy mu Min                -2.2474594
Policy log std Mean          -0.83588076
Policy log std Std           0.10023836
Policy log std Max           -0.48033068
Policy log std Min           -1.3251216
Z mean eval                  1.2276967
Z variance eval              0.10615094
total_rewards                [ 508.70626681  364.99788192 1359.82036935  765.49659988  329.0419821
  201.56134202  350.24318011  583.04689665  270.03993602  362.20057422]
total_rewards_mean           509.5155029078467
total_rewards_std            323.5215474251397
total_rewards_max            1359.8203693469316
total_rewards_min            201.56134202330077
Number of train steps total  132000
Number of env steps total    112184
Number of rollouts total     0
Train Time (s)               136.79603163478896
(Previous) Eval Time (s)     23.420009560883045
Sample Time (s)              12.081146222073585
Epoch Time (s)               172.2971874177456
Total Train Time (s)         5969.943884020206
Epoch                        32
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:35:22.319872 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #32 | Epoch Duration: 172.6080904006958
2020-01-12 03:35:22.320073 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.230427
Z variance train             0.10612655
KL Divergence                23.337112
KL Loss                      2.3337114
QF Loss                      276.4198
VF Loss                      77.22198
Policy Loss                  -407.6648
Q Predictions Mean           397.43744
Q Predictions Std            97.11773
Q Predictions Max            574.55005
Q Predictions Min            -8.465256
V Predictions Mean           405.0525
V Predictions Std            86.8653
V Predictions Max            570.71936
V Predictions Min            102.65841
Log Pis Mean                 -1.9315767
Log Pis Std                  2.5245788
Log Pis Max                  18.22468
Log Pis Min                  -7.476952
Policy mu Mean               0.009225704
Policy mu Std                0.42453137
Policy mu Max                2.7991061
Policy mu Min                -2.468052
Policy log std Mean          -0.8478766
Policy log std Std           0.10882125
Policy log std Max           -0.5075305
Policy log std Min           -1.5888816
Z mean eval                  1.2441
Z variance eval              0.053728797
total_rewards                [ 624.17371937  172.5501404  1017.54075111  586.65185391  376.60128229
  621.58311431  262.80474418  547.6392329   125.08469621  719.96787651]
total_rewards_mean           505.459741117542
total_rewards_std            259.84409615563834
total_rewards_max            1017.5407511070458
total_rewards_min            125.08469620568872
Number of train steps total  136000
Number of env steps total    115856
Number of rollouts total     0
Train Time (s)               137.32994719827548
(Previous) Eval Time (s)     21.980516669806093
Sample Time (s)              11.942347057629377
Epoch Time (s)               171.25281092571095
Total Train Time (s)         6141.30370481126
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:38:13.681329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #33 | Epoch Duration: 171.36110758781433
2020-01-12 03:38:13.681531 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2449663
Z variance train             0.05329875
KL Divergence                24.208057
KL Loss                      2.4208057
QF Loss                      270.3619
VF Loss                      61.19486
Policy Loss                  -408.55664
Q Predictions Mean           401.28772
Q Predictions Std            89.90232
Q Predictions Max            565.9746
Q Predictions Min            -11.340281
V Predictions Mean           410.2051
V Predictions Std            85.799835
V Predictions Max            560.44763
V Predictions Min            176.60512
Log Pis Mean                 -2.047928
Log Pis Std                  2.3617904
Log Pis Max                  10.518747
Log Pis Min                  -10.681833
Policy mu Mean               0.0092147235
Policy mu Std                0.42541832
Policy mu Max                2.0804396
Policy mu Min                -2.9901614
Policy log std Mean          -0.8565544
Policy log std Std           0.107845984
Policy log std Max           -0.4942652
Policy log std Min           -1.3467865
Z mean eval                  1.1818198
Z variance eval              0.13552985
total_rewards                [  75.32466119 1223.47014053   42.08579436  317.95901744  294.18376781
  935.94318184  360.23096797  214.43817892  365.39202722  625.58738997]
total_rewards_mean           445.46151272390705
total_rewards_std            358.3597738021824
total_rewards_max            1223.470140525189
total_rewards_min            42.08579435840661
Number of train steps total  140000
Number of env steps total    119023
Number of rollouts total     0
Train Time (s)               143.03574838489294
(Previous) Eval Time (s)     22.836166366003454
Sample Time (s)              12.850327883381397
Epoch Time (s)               178.7222426342778
Total Train Time (s)         6320.114073945675
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:41:12.492901 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #34 | Epoch Duration: 178.8112096786499
2020-01-12 03:41:12.493091 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1842782
Z variance train             0.1343342
KL Divergence                20.330378
KL Loss                      2.033038
QF Loss                      420.12634
VF Loss                      61.288177
Policy Loss                  -409.45508
Q Predictions Mean           399.63257
Q Predictions Std            101.3196
Q Predictions Max            570.0996
Q Predictions Min            -46.845562
V Predictions Mean           413.01788
V Predictions Std            91.026695
V Predictions Max            569.32684
V Predictions Min            227.56801
Log Pis Mean                 -1.9538134
Log Pis Std                  2.4600708
Log Pis Max                  20.238546
Log Pis Min                  -7.2855425
Policy mu Mean               0.0368219
Policy mu Std                0.43413827
Policy mu Max                3.172846
Policy mu Min                -2.2948778
Policy log std Mean          -0.8508703
Policy log std Std           0.11160407
Policy log std Max           -0.40657908
Policy log std Min           -1.5404634
Z mean eval                  1.2123549
Z variance eval              0.061017044
total_rewards                [513.29199407 626.42256385 393.34009072 138.70316846 778.51507143
 390.43030643 178.39440944 396.98929192  85.41604877 214.25579386]
total_rewards_mean           371.5758738947628
total_rewards_std            212.20052907794866
total_rewards_max            778.5150714327397
total_rewards_min            85.4160487665855
Number of train steps total  144000
Number of env steps total    122938
Number of rollouts total     0
Train Time (s)               147.84591631684452
(Previous) Eval Time (s)     21.380710987839848
Sample Time (s)              14.05007255030796
Epoch Time (s)               183.27669985499233
Total Train Time (s)         6503.484969448298
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:44:15.865461 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #35 | Epoch Duration: 183.37221503257751
2020-01-12 03:44:15.865678 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2147377
Z variance train             0.06126503
KL Divergence                23.290117
KL Loss                      2.3290117
QF Loss                      521.4937
VF Loss                      83.57216
Policy Loss                  -421.04462
Q Predictions Mean           408.01224
Q Predictions Std            104.32154
Q Predictions Max            579.135
Q Predictions Min            -83.173836
V Predictions Mean           418.4619
V Predictions Std            89.25148
V Predictions Max            572.07623
V Predictions Min            214.61356
Log Pis Mean                 -1.7931573
Log Pis Std                  2.4557843
Log Pis Max                  15.08411
Log Pis Min                  -8.243905
Policy mu Mean               0.000494868
Policy mu Std                0.46321195
Policy mu Max                3.8279853
Policy mu Min                -2.6406288
Policy log std Mean          -0.85929155
Policy log std Std           0.117584504
Policy log std Max           -0.47884172
Policy log std Min           -1.3929155
Z mean eval                  1.228146
Z variance eval              0.04279983
total_rewards                [122.05634401 224.17780294 599.47982307 341.28747907 666.43497747
 918.18730457 342.92889139 228.65758316 429.14037735 312.3248004 ]
total_rewards_mean           418.4675383420322
total_rewards_std            229.92435677469857
total_rewards_max            918.1873045689211
total_rewards_min            122.05634400741054
Number of train steps total  148000
Number of env steps total    126435
Number of rollouts total     0
Train Time (s)               146.6581414011307
(Previous) Eval Time (s)     17.738923993892968
Sample Time (s)              12.259325466584414
Epoch Time (s)               176.6563908616081
Total Train Time (s)         6680.234447576106
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:47:12.616373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #36 | Epoch Duration: 176.75053787231445
2020-01-12 03:47:12.616569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2315543
Z variance train             0.0430632
KL Divergence                24.375122
KL Loss                      2.4375122
QF Loss                      321.71722
VF Loss                      68.45612
Policy Loss                  -430.15826
Q Predictions Mean           418.753
Q Predictions Std            105.57263
Q Predictions Max            593.2129
Q Predictions Min            -67.09137
V Predictions Mean           429.13324
V Predictions Std            93.57491
V Predictions Max            594.50726
V Predictions Min            186.58704
Log Pis Mean                 -2.0770297
Log Pis Std                  2.7015824
Log Pis Max                  22.269547
Log Pis Min                  -9.573923
Policy mu Mean               0.0055271806
Policy mu Std                0.4414161
Policy mu Max                2.6798885
Policy mu Min                -3.1223574
Policy log std Mean          -0.850611
Policy log std Std           0.11143233
Policy log std Max           -0.5009024
Policy log std Min           -1.403096
Z mean eval                  1.233886
Z variance eval              0.12835881
total_rewards                [ 360.7302594   250.34622301  285.05382499  165.718102    151.95427651
 1247.37262142  513.28232208 1093.50024116  373.80705301 1455.10855726]
total_rewards_mean           589.6873480833501
total_rewards_std            460.38122721096073
total_rewards_max            1455.1085572555774
total_rewards_min            151.95427650611234
Number of train steps total  152000
Number of env steps total    130173
Number of rollouts total     0
Train Time (s)               146.7173011326231
(Previous) Eval Time (s)     25.38676411798224
Sample Time (s)              11.638207549694926
Epoch Time (s)               183.74227280030027
Total Train Time (s)         6864.0651716827415
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:50:16.448595 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #37 | Epoch Duration: 183.831866979599
2020-01-12 03:50:16.448788 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #37 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2272556
Z variance train             0.12717529
KL Divergence                20.938173
KL Loss                      2.0938175
QF Loss                      244.22638
VF Loss                      48.026535
Policy Loss                  -431.74835
Q Predictions Mean           425.63828
Q Predictions Std            105.99351
Q Predictions Max            640.18835
Q Predictions Min            231.97914
V Predictions Mean           434.02728
V Predictions Std            101.63648
V Predictions Max            637.68646
V Predictions Min            246.29454
Log Pis Mean                 -1.9944232
Log Pis Std                  2.1890583
Log Pis Max                  12.57444
Log Pis Min                  -8.346413
Policy mu Mean               -0.012878883
Policy mu Std                0.42546162
Policy mu Max                2.3290744
Policy mu Min                -2.6749845
Policy log std Mean          -0.84352297
Policy log std Std           0.110565275
Policy log std Max           -0.52294827
Policy log std Min           -1.3537383
Z mean eval                  1.2508271
Z variance eval              0.09177275
total_rewards                [1145.18461743  539.62591339  736.25660764  975.66309308  665.2788844
  273.53915531 1140.18746248   14.46303549  296.35987728  797.59360272]
total_rewards_mean           658.4152249216535
total_rewards_std            360.994617449557
total_rewards_max            1145.1846174321302
total_rewards_min            14.463035491410558
Number of train steps total  156000
Number of env steps total    134268
Number of rollouts total     0
Train Time (s)               146.8674243800342
(Previous) Eval Time (s)     24.402628127951175
Sample Time (s)              10.397451331838965
Epoch Time (s)               181.66750383982435
Total Train Time (s)         7045.829056310467
Epoch                        38
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:53:18.214000 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #38 | Epoch Duration: 181.76507258415222
2020-01-12 03:53:18.214165 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2558541
Z variance train             0.091140315
KL Divergence                23.612827
KL Loss                      2.3612828
QF Loss                      306.87054
VF Loss                      54.175533
Policy Loss                  -444.54263
Q Predictions Mean           436.15686
Q Predictions Std            108.98154
Q Predictions Max            636.9404
Q Predictions Min            112.336754
V Predictions Mean           443.9854
V Predictions Std            103.48403
V Predictions Max            634.2162
V Predictions Min            138.12984
Log Pis Mean                 -1.9307938
Log Pis Std                  2.4214344
Log Pis Max                  18.13476
Log Pis Min                  -7.450885
Policy mu Mean               -0.0091282595
Policy mu Std                0.42433587
Policy mu Max                2.6531627
Policy mu Min                -2.3297603
Policy log std Mean          -0.87138903
Policy log std Std           0.1183744
Policy log std Max           -0.45914227
Policy log std Min           -1.5713661
Z mean eval                  1.2558223
Z variance eval              0.097483665
total_rewards                [ 234.94737431 1043.85540969  632.6431424   189.44936664  303.21336462
   68.19844464  357.90857225   38.50567933  822.39806689  497.46456449]
total_rewards_mean           418.8583985264336
total_rewards_std            312.4931026655759
total_rewards_max            1043.855409688479
total_rewards_min            38.505679329613876
Number of train steps total  160000
Number of env steps total    137563
Number of rollouts total     0
Train Time (s)               137.32688621385023
(Previous) Eval Time (s)     14.191549732815474
Sample Time (s)              12.147085970733315
Epoch Time (s)               163.66552191739902
Total Train Time (s)         7209.593499202281
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:56:01.980569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #39 | Epoch Duration: 163.76626467704773
2020-01-12 03:56:01.980763 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2552546
Z variance train             0.09884886
KL Divergence                22.844162
KL Loss                      2.2844162
QF Loss                      264.75113
VF Loss                      76.0322
Policy Loss                  -439.3036
Q Predictions Mean           428.557
Q Predictions Std            115.30579
Q Predictions Max            615.79926
Q Predictions Min            -4.692653
V Predictions Mean           438.7974
V Predictions Std            108.37769
V Predictions Max            614.27155
V Predictions Min            199.75798
Log Pis Mean                 -1.8335543
Log Pis Std                  1.9904225
Log Pis Max                  9.368203
Log Pis Min                  -7.9603934
Policy mu Mean               0.01008664
Policy mu Std                0.45058462
Policy mu Max                2.0818737
Policy mu Min                -2.9053943
Policy log std Mean          -0.86003494
Policy log std Std           0.118784055
Policy log std Max           -0.49968925
Policy log std Min           -1.4115033
Z mean eval                  1.2010624
Z variance eval              0.07718854
total_rewards                [409.46641573 216.70371505 148.09577627 536.98851863 694.88251751
 415.53137863 703.7409511  324.92655401 373.08934181 428.73494425]
total_rewards_mean           425.2160112978765
total_rewards_std            172.1021940836672
total_rewards_max            703.7409510986606
total_rewards_min            148.09577627108547
Number of train steps total  164000
Number of env steps total    141131
Number of rollouts total     0
Train Time (s)               137.83365571312606
(Previous) Eval Time (s)     23.188826739788055
Sample Time (s)              12.223345687612891
Epoch Time (s)               173.245828140527
Total Train Time (s)         7382.929752966389
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:58:55.318066 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #40 | Epoch Duration: 173.3371570110321
2020-01-12 03:58:55.318260 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2096307
Z variance train             0.07750615
KL Divergence                23.520124
KL Loss                      2.3520124
QF Loss                      231.21742
VF Loss                      64.72943
Policy Loss                  -438.77185
Q Predictions Mean           427.57285
Q Predictions Std            123.40449
Q Predictions Max            630.0761
Q Predictions Min            10.467874
V Predictions Mean           434.60733
V Predictions Std            116.39537
V Predictions Max            632.0898
V Predictions Min            191.78413
Log Pis Mean                 -1.7046142
Log Pis Std                  2.4891121
Log Pis Max                  14.351462
Log Pis Min                  -7.1538286
Policy mu Mean               0.025925085
Policy mu Std                0.46497294
Policy mu Max                2.251936
Policy mu Min                -2.7912295
Policy log std Mean          -0.8609885
Policy log std Std           0.11609984
Policy log std Max           -0.4487365
Policy log std Min           -1.4890814
Z mean eval                  1.3402524
Z variance eval              0.13702269
total_rewards                [ 729.6977294   299.34517064  591.29670498  285.5207319   414.48341919
   17.77115692  107.14508338   91.51844536 1049.13793347  397.98112102]
total_rewards_mean           398.3897496264375
total_rewards_std            302.8404947738087
total_rewards_max            1049.1379334705027
total_rewards_min            17.77115691514923
Number of train steps total  168000
Number of env steps total    144506
Number of rollouts total     0
Train Time (s)               142.89744039298967
(Previous) Eval Time (s)     22.419586569070816
Sample Time (s)              12.091365320142359
Epoch Time (s)               177.40839228220284
Total Train Time (s)         7560.4251651261
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:01:52.815619 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #41 | Epoch Duration: 177.4971899986267
2020-01-12 04:01:52.815882 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3382146
Z variance train             0.13661066
KL Divergence                20.855986
KL Loss                      2.0855987
QF Loss                      350.4218
VF Loss                      51.59214
Policy Loss                  -457.36383
Q Predictions Mean           452.08514
Q Predictions Std            117.22523
Q Predictions Max            647.61884
Q Predictions Min            219.98795
V Predictions Mean           457.81848
V Predictions Std            114.262276
V Predictions Max            657.44183
V Predictions Min            227.3154
Log Pis Mean                 -1.6583703
Log Pis Std                  2.43065
Log Pis Max                  14.569891
Log Pis Min                  -7.271239
Policy mu Mean               0.022845954
Policy mu Std                0.43481103
Policy mu Max                2.734498
Policy mu Min                -2.6899548
Policy log std Mean          -0.8855032
Policy log std Std           0.115013815
Policy log std Max           -0.48819238
Policy log std Min           -1.3204658
Z mean eval                  1.232033
Z variance eval              0.15184201
total_rewards                [1013.37030635  461.05282262  204.13401004  934.09791627  727.77414842
  289.07376288  222.30930187  165.9932526   188.69088481  268.3865404 ]
total_rewards_mean           447.48829462626253
total_rewards_std            308.0698911258676
total_rewards_max            1013.3703063540528
total_rewards_min            165.99325260376315
Number of train steps total  172000
Number of env steps total    147418
Number of rollouts total     0
Train Time (s)               148.31132341176271
(Previous) Eval Time (s)     20.015792863909155
Sample Time (s)              12.907880731392652
Epoch Time (s)               181.23499700706452
Total Train Time (s)         7741.745443343651
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:04:54.137162 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #42 | Epoch Duration: 181.32110118865967
2020-01-12 04:04:54.137401 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2311018
Z variance train             0.15120687
KL Divergence                22.23259
KL Loss                      2.223259
QF Loss                      283.9657
VF Loss                      159.62627
Policy Loss                  -434.2844
Q Predictions Mean           426.38837
Q Predictions Std            134.11417
Q Predictions Max            655.92163
Q Predictions Min            -32.493225
V Predictions Mean           431.7701
V Predictions Std            126.16781
V Predictions Max            669.30615
V Predictions Min            118.76023
Log Pis Mean                 -2.0866716
Log Pis Std                  2.3347404
Log Pis Max                  16.00346
Log Pis Min                  -8.267352
Policy mu Mean               0.018477885
Policy mu Std                0.43901306
Policy mu Max                3.0994518
Policy mu Min                -2.6796224
Policy log std Mean          -0.8506526
Policy log std Std           0.12245891
Policy log std Max           -0.28845316
Policy log std Min           -1.4456552
Z mean eval                  1.2475224
Z variance eval              0.29348296
total_rewards                [702.5872511   79.70175631  66.72054403 119.52362727 465.32699486
 281.37688994 230.21605923 250.37130448 356.87138251 154.69945147]
total_rewards_mean           270.73952612125714
total_rewards_std            186.65377791842988
total_rewards_max            702.5872510989228
total_rewards_min            66.72054402817619
Number of train steps total  176000
Number of env steps total    151276
Number of rollouts total     0
Train Time (s)               147.4065041579306
(Previous) Eval Time (s)     14.00532168103382
Sample Time (s)              13.190061547793448
Epoch Time (s)               174.60188738675788
Total Train Time (s)         7916.450868962333
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:07:48.843577 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #43 | Epoch Duration: 174.70599341392517
2020-01-12 04:07:48.843762 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2388017
Z variance train             0.29658067
KL Divergence                22.317724
KL Loss                      2.2317724
QF Loss                      264.9743
VF Loss                      71.62639
Policy Loss                  -459.5808
Q Predictions Mean           454.78677
Q Predictions Std            129.61928
Q Predictions Max            644.7849
Q Predictions Min            -6.782153
V Predictions Mean           461.75458
V Predictions Std            122.07543
V Predictions Max            647.9986
V Predictions Min            218.75317
Log Pis Mean                 -2.1155078
Log Pis Std                  2.1698341
Log Pis Max                  9.156916
Log Pis Min                  -8.786783
Policy mu Mean               0.016518723
Policy mu Std                0.4127955
Policy mu Max                2.0263462
Policy mu Min                -2.0197198
Policy log std Mean          -0.8532768
Policy log std Std           0.126691
Policy log std Max           -0.5237187
Policy log std Min           -1.5045621
Z mean eval                  1.2958134
Z variance eval              0.12128502
total_rewards                [ 401.00815477 1116.88046629  529.35176586 1142.94769475  176.40954848
  247.79343084  363.03418495  268.16104561   78.10293489  477.48648164]
total_rewards_mean           480.1175708088181
total_rewards_std            349.27967457523704
total_rewards_max            1142.947694754525
total_rewards_min            78.10293489173213
Number of train steps total  180000
Number of env steps total    154034
Number of rollouts total     0
Train Time (s)               147.3820583350025
(Previous) Eval Time (s)     17.44131771568209
Sample Time (s)              12.51278875861317
Epoch Time (s)               177.33616480929777
Total Train Time (s)         8093.876634099521
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:10:46.271908 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #44 | Epoch Duration: 177.42796802520752
2020-01-12 04:10:46.272250 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2971385
Z variance train             0.122125685
KL Divergence                23.63276
KL Loss                      2.363276
QF Loss                      305.13013
VF Loss                      54.03945
Policy Loss                  -462.37457
Q Predictions Mean           455.2082
Q Predictions Std            145.77364
Q Predictions Max            697.63007
Q Predictions Min            -46.186893
V Predictions Mean           458.68256
V Predictions Std            139.16866
V Predictions Max            674.5557
V Predictions Min            228.67285
Log Pis Mean                 -1.7141333
Log Pis Std                  2.4080477
Log Pis Max                  15.518396
Log Pis Min                  -7.7807193
Policy mu Mean               0.04056447
Policy mu Std                0.4304948
Policy mu Max                4.055021
Policy mu Min                -2.744232
Policy log std Mean          -0.84043694
Policy log std Std           0.122782715
Policy log std Max           -0.39485577
Policy log std Min           -1.3600953
Z mean eval                  1.2300246
Z variance eval              0.19252568
total_rewards                [1251.08293132  310.85224902  419.32240114 1797.1339858   397.11977824
  629.48338898 1260.54188476  113.87110197  804.02452561 1263.23669458]
total_rewards_mean           824.666894143221
total_rewards_std            516.2085730137626
total_rewards_max            1797.133985802424
total_rewards_min            113.87110197305242
Number of train steps total  184000
Number of env steps total    157561
Number of rollouts total     0
Train Time (s)               145.82688875636086
(Previous) Eval Time (s)     32.62500093784183
Sample Time (s)              11.750085738487542
Epoch Time (s)               190.20197543269023
Total Train Time (s)         8284.184513654094
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:13:56.581977 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #45 | Epoch Duration: 190.3095099925995
2020-01-12 04:13:56.582255 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.229794
Z variance train             0.19171211
KL Divergence                24.049564
KL Loss                      2.4049566
QF Loss                      278.84558
VF Loss                      58.430077
Policy Loss                  -481.22662
Q Predictions Mean           473.41287
Q Predictions Std            142.03723
Q Predictions Max            723.60016
Q Predictions Min            -38.4843
V Predictions Mean           478.20514
V Predictions Std            136.43758
V Predictions Max            708.5791
V Predictions Min            58.084415
Log Pis Mean                 -1.8423477
Log Pis Std                  2.4969366
Log Pis Max                  15.606122
Log Pis Min                  -7.3119707
Policy mu Mean               0.018475913
Policy mu Std                0.46185747
Policy mu Max                2.6057794
Policy mu Min                -2.4600103
Policy log std Mean          -0.8628892
Policy log std Std           0.12901554
Policy log std Max           -0.45499712
Policy log std Min           -1.6124119
Z mean eval                  1.2116776
Z variance eval              0.091130204
total_rewards                [ 310.93712274  575.5522962    53.43679434  606.03986828  909.47288213
 1067.8251348  1240.63543151   78.9473534   603.694917    305.53647191]
total_rewards_mean           575.2078272296767
total_rewards_std            382.1049851363626
total_rewards_max            1240.635431509341
total_rewards_min            53.43679433637311
Number of train steps total  188000
Number of env steps total    161294
Number of rollouts total     0
Train Time (s)               138.37399923009798
(Previous) Eval Time (s)     18.809058513026685
Sample Time (s)              11.674628556706011
Epoch Time (s)               168.85768629983068
Total Train Time (s)         8453.138722718693
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:16:45.536990 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #46 | Epoch Duration: 168.9545760154724
2020-01-12 04:16:45.537227 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2140434
Z variance train             0.091273874
KL Divergence                22.490002
KL Loss                      2.2490003
QF Loss                      340.58575
VF Loss                      48.247658
Policy Loss                  -474.67047
Q Predictions Mean           463.88223
Q Predictions Std            142.09018
Q Predictions Max            678.55676
Q Predictions Min            33.055126
V Predictions Mean           472.23456
V Predictions Std            134.61752
V Predictions Max            669.40784
V Predictions Min            237.51688
Log Pis Mean                 -1.818277
Log Pis Std                  2.543006
Log Pis Max                  10.459493
Log Pis Min                  -9.114943
Policy mu Mean               -0.001679632
Policy mu Std                0.45993006
Policy mu Max                2.0685272
Policy mu Min                -3.0337954
Policy log std Mean          -0.86504585
Policy log std Std           0.13255401
Policy log std Max           -0.55782294
Policy log std Min           -1.5190516
Z mean eval                  1.2742655
Z variance eval              0.20035645
total_rewards                [ 428.37574324 1441.78180792  232.46260572  430.06916383 1015.61771371
  646.15846661  675.47796482   56.96186656  733.14524181    7.68084737]
total_rewards_mean           566.7731421595519
total_rewards_std            416.53296887968975
total_rewards_max            1441.781807923952
total_rewards_min            7.680847373185587
Number of train steps total  192000
Number of env steps total    163989
Number of rollouts total     0
Train Time (s)               138.63976535294205
(Previous) Eval Time (s)     17.991697994992137
Sample Time (s)              11.227001695893705
Epoch Time (s)               167.8584650438279
Total Train Time (s)         8621.085541756358
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:19:33.485206 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #47 | Epoch Duration: 167.94779658317566
2020-01-12 04:19:33.485416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2743227
Z variance train             0.20154019
KL Divergence                22.014723
KL Loss                      2.2014723
QF Loss                      330.39032
VF Loss                      44.543934
Policy Loss                  -471.46167
Q Predictions Mean           462.47537
Q Predictions Std            142.96706
Q Predictions Max            692.60443
Q Predictions Min            90.69713
V Predictions Mean           472.12506
V Predictions Std            139.80084
V Predictions Max            689.95526
V Predictions Min            225.15964
Log Pis Mean                 -1.9231427
Log Pis Std                  2.2264323
Log Pis Max                  4.9446726
Log Pis Min                  -8.339248
Policy mu Mean               -0.015020458
Policy mu Std                0.44308874
Policy mu Max                2.286957
Policy mu Min                -2.2427294
Policy log std Mean          -0.8730795
Policy log std Std           0.13793842
Policy log std Max           -0.4350726
Policy log std Min           -1.4057231
Z mean eval                  1.2547609
Z variance eval              0.13760224
total_rewards                [ 528.0768843   154.58536503  446.25136308  501.58441465  311.08595021
 1554.15238235  486.5749311   947.5874942  1463.48803901  349.89738854]
total_rewards_mean           674.328421246267
total_rewards_std            460.1486259258905
total_rewards_max            1554.1523823460943
total_rewards_min            154.58536503248857
Number of train steps total  196000
Number of env steps total    168387
Number of rollouts total     0
Train Time (s)               141.6619714642875
(Previous) Eval Time (s)     27.804616685025394
Sample Time (s)              11.049760788679123
Epoch Time (s)               180.516348937992
Total Train Time (s)         8801.697772740386
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:22:34.098883 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #48 | Epoch Duration: 180.61331605911255
2020-01-12 04:22:34.099075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2545882
Z variance train             0.138432
KL Divergence                21.909979
KL Loss                      2.1909978
QF Loss                      309.99872
VF Loss                      128.57907
Policy Loss                  -463.52344
Q Predictions Mean           456.16623
Q Predictions Std            149.78801
Q Predictions Max            707.53436
Q Predictions Min            -0.8948022
V Predictions Mean           467.30746
V Predictions Std            146.20108
V Predictions Max            710.2632
V Predictions Min            16.060158
Log Pis Mean                 -1.3315375
Log Pis Std                  2.5228262
Log Pis Max                  9.728036
Log Pis Min                  -7.449027
Policy mu Mean               0.035897117
Policy mu Std                0.47714403
Policy mu Max                2.5802903
Policy mu Min                -3.5061255
Policy log std Mean          -0.8946482
Policy log std Std           0.13984227
Policy log std Max           -0.4850659
Policy log std Min           -1.497888
Z mean eval                  1.223211
Z variance eval              0.05669571
total_rewards                [480.91388808 243.39205785 445.86562301 945.86830794 349.26202708
 601.93809299 263.36979736 470.4459431  378.80863147 379.30922047]
total_rewards_mean           455.9173589361079
total_rewards_std            191.76611286617376
total_rewards_max            945.8683079381191
total_rewards_min            243.3920578455674
Number of train steps total  200000
Number of env steps total    170965
Number of rollouts total     0
Train Time (s)               148.5697961281985
(Previous) Eval Time (s)     21.649560380727053
Sample Time (s)              11.517228670418262
Epoch Time (s)               181.73658517934382
Total Train Time (s)         8983.845231623389
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:25:36.249267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #49 | Epoch Duration: 182.15002036094666
2020-01-12 04:25:36.249539 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2303915
Z variance train             0.056813687
KL Divergence                24.026123
KL Loss                      2.4026124
QF Loss                      328.20685
VF Loss                      67.48815
Policy Loss                  -488.6024
Q Predictions Mean           478.21863
Q Predictions Std            159.32626
Q Predictions Max            726.8261
Q Predictions Min            -52.15594
V Predictions Mean           485.82892
V Predictions Std            150.33162
V Predictions Max            718.3913
V Predictions Min            113.8488
Log Pis Mean                 -1.737493
Log Pis Std                  2.3090365
Log Pis Max                  9.796396
Log Pis Min                  -6.6498294
Policy mu Mean               -0.012972526
Policy mu Std                0.4743517
Policy mu Max                2.7988706
Policy mu Min                -3.371007
Policy log std Mean          -0.8691325
Policy log std Std           0.1306145
Policy log std Max           -0.3377648
Policy log std Min           -1.4609315
Z mean eval                  1.2432511
Z variance eval              0.15519641
total_rewards                [ 142.43047864  711.6291995   251.72931267  248.3225644   235.98544463
  475.39008835   86.23433856  563.06974739  531.81312807 1651.10237643]
total_rewards_mean           489.77066786368886
total_rewards_std            432.2168736937881
total_rewards_max            1651.1023764267738
total_rewards_min            86.23433856394767
Number of train steps total  204000
Number of env steps total    173636
Number of rollouts total     0
Train Time (s)               147.9484878797084
(Previous) Eval Time (s)     12.455973474308848
Sample Time (s)              13.488744386471808
Epoch Time (s)               173.89320574048907
Total Train Time (s)         9157.828106146306
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:28:30.234508 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #50 | Epoch Duration: 173.98477125167847
2020-01-12 04:28:30.234862 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2424184
Z variance train             0.15295917
KL Divergence                22.636452
KL Loss                      2.2636452
QF Loss                      387.3344
VF Loss                      77.49318
Policy Loss                  -493.03293
Q Predictions Mean           483.89673
Q Predictions Std            153.82729
Q Predictions Max            720.9813
Q Predictions Min            -20.320597
V Predictions Mean           489.57376
V Predictions Std            147.1962
V Predictions Max            718.98303
V Predictions Min            -3.0128677
Log Pis Mean                 -1.8890765
Log Pis Std                  2.2086964
Log Pis Max                  7.5068145
Log Pis Min                  -9.622714
Policy mu Mean               0.00011536735
Policy mu Std                0.41915384
Policy mu Max                2.1956403
Policy mu Min                -2.24649
Policy log std Mean          -0.873003
Policy log std Std           0.13717416
Policy log std Max           -0.5144026
Policy log std Min           -1.4836934
Z mean eval                  1.2714319
Z variance eval              0.24052458
total_rewards                [ 269.46465395 1091.85892173 1020.89837155  832.56749906  967.39036278
  555.25425539  867.22827745  826.9118526   755.25140904  365.79118545]
total_rewards_mean           755.2616788995331
total_rewards_std            260.80540170381687
total_rewards_max            1091.8589217267215
total_rewards_min            269.4646539546545
Number of train steps total  208000
Number of env steps total    177384
Number of rollouts total     0
Train Time (s)               146.90489235008135
(Previous) Eval Time (s)     23.491262735798955
Sample Time (s)              12.334968205075711
Epoch Time (s)               182.73112329095602
Total Train Time (s)         9340.77634849213
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:31:33.184211 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #51 | Epoch Duration: 182.94906163215637
2020-01-12 04:31:33.184511 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2699062
Z variance train             0.24111101
KL Divergence                19.474792
KL Loss                      1.9474792
QF Loss                      464.5599
VF Loss                      58.093437
Policy Loss                  -467.3666
Q Predictions Mean           457.12454
Q Predictions Std            153.06287
Q Predictions Max            692.3394
Q Predictions Min            105.2889
V Predictions Mean           466.6054
V Predictions Std            146.8479
V Predictions Max            685.6372
V Predictions Min            212.0709
Log Pis Mean                 -2.0165334
Log Pis Std                  2.4768364
Log Pis Max                  17.97253
Log Pis Min                  -7.1637335
Policy mu Mean               0.041555036
Policy mu Std                0.42129752
Policy mu Max                2.2686343
Policy mu Min                -2.7140503
Policy log std Mean          -0.86463296
Policy log std Std           0.13129269
Policy log std Max           -0.28924844
Policy log std Min           -1.447636
Z mean eval                  1.2640986
Z variance eval              0.12067584
total_rewards                [1114.82563092  248.72053293  403.13228621  618.21307387  118.72041749
  271.45717721  347.19246473  348.74512818 1571.00786746  784.52353714]
total_rewards_mean           582.6538116157077
total_rewards_std            432.2081330094472
total_rewards_max            1571.0078674640267
total_rewards_min            118.7204174929351
Number of train steps total  212000
Number of env steps total    179951
Number of rollouts total     0
Train Time (s)               145.89766291715205
(Previous) Eval Time (s)     21.606778481043875
Sample Time (s)              11.691472841892391
Epoch Time (s)               179.1959142400883
Total Train Time (s)         9520.069196533412
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:34:32.477550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #52 | Epoch Duration: 179.29282212257385
2020-01-12 04:34:32.477768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2659352
Z variance train             0.12111982
KL Divergence                22.91446
KL Loss                      2.291446
QF Loss                      170.42616
VF Loss                      62.998478
Policy Loss                  -483.6882
Q Predictions Mean           475.37354
Q Predictions Std            160.85565
Q Predictions Max            712.1578
Q Predictions Min            -32.730885
V Predictions Mean           483.9826
V Predictions Std            154.05106
V Predictions Max            718.11945
V Predictions Min            208.48433
Log Pis Mean                 -1.9247084
Log Pis Std                  2.6145701
Log Pis Max                  17.789053
Log Pis Min                  -9.971968
Policy mu Mean               -0.024191018
Policy mu Std                0.43838796
Policy mu Max                2.21016
Policy mu Min                -3.1018384
Policy log std Mean          -0.8655976
Policy log std Std           0.13400176
Policy log std Max           -0.4377275
Policy log std Min           -1.3965855
Z mean eval                  1.282463
Z variance eval              0.087110616
total_rewards                [ 335.1472156   300.22691973  464.21803523  324.71471868  168.55018862
  231.82934199  907.7783864   575.09470737  802.78157795 1099.30921401]
total_rewards_mean           520.9650305594106
total_rewards_std            299.8734404082666
total_rewards_max            1099.3092140059514
total_rewards_min            168.55018862443296
Number of train steps total  216000
Number of env steps total    183564
Number of rollouts total     0
Train Time (s)               140.25718973390758
(Previous) Eval Time (s)     21.005938163027167
Sample Time (s)              12.044518634211272
Epoch Time (s)               173.30764653114602
Total Train Time (s)         9693.46469461592
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:37:25.874718 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #53 | Epoch Duration: 173.39681029319763
2020-01-12 04:37:25.874935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2821558
Z variance train             0.08670609
KL Divergence                23.394505
KL Loss                      2.3394506
QF Loss                      269.5158
VF Loss                      105.38522
Policy Loss                  -506.779
Q Predictions Mean           500.5236
Q Predictions Std            167.60153
Q Predictions Max            753.50415
Q Predictions Min            183.3591
V Predictions Mean           511.82245
V Predictions Std            164.39003
V Predictions Max            758.8951
V Predictions Min            205.47139
Log Pis Mean                 -1.888561
Log Pis Std                  2.716828
Log Pis Max                  15.24073
Log Pis Min                  -8.205389
Policy mu Mean               0.059434555
Policy mu Std                0.4385613
Policy mu Max                2.7587218
Policy mu Min                -2.8717222
Policy log std Mean          -0.86171675
Policy log std Std           0.13930853
Policy log std Max           -0.43853444
Policy log std Min           -1.801749
Z mean eval                  1.2716575
Z variance eval              0.17023952
total_rewards                [ 552.44466918  602.6490666   560.8047685   249.5888453   601.16632022
  990.1621036   624.41675939  535.25688096 1203.12814368    5.47566056]
total_rewards_mean           592.5093217995543
total_rewards_std            316.2704685590072
total_rewards_max            1203.128143675559
total_rewards_min            5.475660560062215
Number of train steps total  220000
Number of env steps total    187087
Number of rollouts total     0
Train Time (s)               138.84996404964477
(Previous) Eval Time (s)     22.889463612809777
Sample Time (s)              11.669867840595543
Epoch Time (s)               173.4092955030501
Total Train Time (s)         9867.010012998711
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:40:19.422280 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #54 | Epoch Duration: 173.54713201522827
2020-01-12 04:40:19.422580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2689155
Z variance train             0.16870499
KL Divergence                22.900928
KL Loss                      2.290093
QF Loss                      323.76242
VF Loss                      58.08722
Policy Loss                  -491.9149
Q Predictions Mean           485.00275
Q Predictions Std            164.81328
Q Predictions Max            747.8525
Q Predictions Min            -31.624819
V Predictions Mean           491.5777
V Predictions Std            156.47876
V Predictions Max            728.00305
V Predictions Min            234.88298
Log Pis Mean                 -1.8299117
Log Pis Std                  2.4304302
Log Pis Max                  11.806103
Log Pis Min                  -8.36261
Policy mu Mean               -0.014025364
Policy mu Std                0.43215278
Policy mu Max                2.041173
Policy mu Min                -2.7315931
Policy log std Mean          -0.8818973
Policy log std Std           0.1355408
Policy log std Max           -0.48219448
Policy log std Min           -1.5494518
Z mean eval                  1.2762692
Z variance eval              0.15631437
total_rewards                [ 207.17891274  544.60288119  755.27974494  545.59743523  793.68367911
 1603.99473623  530.76788417  547.87893599  430.53966511  827.63167096]
total_rewards_mean           678.7155545666976
total_rewards_std            354.40778379345926
total_rewards_max            1603.9947362275539
total_rewards_min            207.17891274024976
Number of train steps total  224000
Number of env steps total    189819
Number of rollouts total     0
Train Time (s)               140.8692221599631
(Previous) Eval Time (s)     26.520766034256667
Sample Time (s)              12.300806649029255
Epoch Time (s)               179.69079484324902
Total Train Time (s)         10046.791865248233
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:43:19.205228 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #55 | Epoch Duration: 179.78246593475342
2020-01-12 04:43:19.205439 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2756559
Z variance train             0.15659295
KL Divergence                21.41196
KL Loss                      2.141196
QF Loss                      255.42058
VF Loss                      57.377033
Policy Loss                  -533.4002
Q Predictions Mean           524.5112
Q Predictions Std            168.82617
Q Predictions Max            784.0808
Q Predictions Min            -28.5265
V Predictions Mean           531.15063
V Predictions Std            162.10005
V Predictions Max            773.5649
V Predictions Min            239.22897
Log Pis Mean                 -1.6060188
Log Pis Std                  2.4962478
Log Pis Max                  15.984402
Log Pis Min                  -6.7277565
Policy mu Mean               0.03815617
Policy mu Std                0.45053917
Policy mu Max                3.052901
Policy mu Min                -3.3630054
Policy log std Mean          -0.8796371
Policy log std Std           0.12561382
Policy log std Max           -0.5535204
Policy log std Min           -1.4323574
Z mean eval                  1.2396321
Z variance eval              0.11045573
total_rewards                [ 505.11176533 1113.58973148  191.37678717 1391.71548133  696.98128661
 1111.44580082  677.14255269 1297.12317757  282.74179446  780.36329354]
total_rewards_mean           804.7591671005082
total_rewards_std            392.86116117558583
total_rewards_max            1391.7154813300895
total_rewards_min            191.37678716920993
Number of train steps total  228000
Number of env steps total    193274
Number of rollouts total     0
Train Time (s)               149.48991259234026
(Previous) Eval Time (s)     24.085978002287447
Sample Time (s)              11.410999331623316
Epoch Time (s)               184.98688992625102
Total Train Time (s)         10231.869508202188
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:46:24.290478 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #56 | Epoch Duration: 185.08486366271973
2020-01-12 04:46:24.290871 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2380142
Z variance train             0.1102291
KL Divergence                22.292664
KL Loss                      2.2292664
QF Loss                      472.2771
VF Loss                      94.98532
Policy Loss                  -497.45547
Q Predictions Mean           487.45966
Q Predictions Std            173.87129
Q Predictions Max            765.78394
Q Predictions Min            -89.286316
V Predictions Mean           494.28638
V Predictions Std            166.10526
V Predictions Max            774.5809
V Predictions Min            57.36389
Log Pis Mean                 -1.7080569
Log Pis Std                  2.7810786
Log Pis Max                  17.308243
Log Pis Min                  -8.06298
Policy mu Mean               0.03033424
Policy mu Std                0.4588198
Policy mu Max                2.533805
Policy mu Min                -3.2787352
Policy log std Mean          -0.8739206
Policy log std Std           0.14901048
Policy log std Max           -0.45544562
Policy log std Min           -1.6621246
Z mean eval                  1.2292262
Z variance eval              0.04099272
total_rewards                [1846.3653747   121.78449078  692.78707609  687.2557219   289.82082755
 1632.41789683  703.76209354  701.481916    502.08566959 1450.03260029]
total_rewards_mean           862.7793667273505
total_rewards_std            549.8286450271623
total_rewards_max            1846.3653747005021
total_rewards_min            121.78449077632598
Number of train steps total  232000
Number of env steps total    198830
Number of rollouts total     0
Train Time (s)               147.6378724416718
(Previous) Eval Time (s)     24.53674687212333
Sample Time (s)              13.005708694923669
Epoch Time (s)               185.1803280087188
Total Train Time (s)         10417.149703877512
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:49:29.566336 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #57 | Epoch Duration: 185.27513813972473
2020-01-12 04:49:29.566534 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2295605
Z variance train             0.04120399
KL Divergence                24.386703
KL Loss                      2.4386704
QF Loss                      303.4914
VF Loss                      125.93894
Policy Loss                  -525.3101
Q Predictions Mean           517.93677
Q Predictions Std            163.9726
Q Predictions Max            741.5029
Q Predictions Min            21.190485
V Predictions Mean           531.51227
V Predictions Std            159.18419
V Predictions Max            749.2716
V Predictions Min            232.09889
Log Pis Mean                 -1.5876341
Log Pis Std                  2.5672116
Log Pis Max                  10.492174
Log Pis Min                  -8.522718
Policy mu Mean               -0.03052894
Policy mu Std                0.4483542
Policy mu Max                2.47825
Policy mu Min                -2.7673573
Policy log std Mean          -0.8975401
Policy log std Std           0.15080483
Policy log std Max           -0.42852902
Policy log std Min           -1.5662587
Z mean eval                  1.1708483
Z variance eval              0.048855178
total_rewards                [ 330.87619338  153.31861505  387.72553926  403.79182401  693.75349824
  474.5030148  1020.43960867   74.60977147 1099.34389645  870.0956735 ]
total_rewards_mean           550.8457634825612
total_rewards_std            336.30167358306153
total_rewards_max            1099.3438964473473
total_rewards_min            74.60977146847435
Number of train steps total  236000
Number of env steps total    201269
Number of rollouts total     0
Train Time (s)               146.5572842741385
(Previous) Eval Time (s)     19.651416276115924
Sample Time (s)              12.416493157390505
Epoch Time (s)               178.62519370764494
Total Train Time (s)         10595.860166958999
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:52:28.278518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #58 | Epoch Duration: 178.71183466911316
2020-01-12 04:52:28.278724 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.16906
Z variance train             0.04905943
KL Divergence                22.78566
KL Loss                      2.2785661
QF Loss                      353.83813
VF Loss                      118.95221
Policy Loss                  -525.19446
Q Predictions Mean           517.3554
Q Predictions Std            176.32478
Q Predictions Max            761.4449
Q Predictions Min            -23.226524
V Predictions Mean           531.5229
V Predictions Std            172.96237
V Predictions Max            765.8841
V Predictions Min            20.343052
Log Pis Mean                 -1.6125641
Log Pis Std                  2.6723588
Log Pis Max                  11.743497
Log Pis Min                  -7.72048
Policy mu Mean               0.029699573
Policy mu Std                0.4594171
Policy mu Max                3.078553
Policy mu Min                -2.1955345
Policy log std Mean          -0.8874093
Policy log std Std           0.15311028
Policy log std Max           -0.49929544
Policy log std Min           -1.6173501
Z mean eval                  1.2004033
Z variance eval              0.026744362
total_rewards                [1313.7609408   565.30388327   73.62487841  652.11764265  201.62203299
  433.43481225  554.64299348  514.66574521 1780.7376016   409.25553204]
total_rewards_mean           649.9166062696402
total_rewards_std            489.0645906174561
total_rewards_max            1780.7376016002397
total_rewards_min            73.62487841179059
Number of train steps total  240000
Number of env steps total    204804
Number of rollouts total     0
Train Time (s)               147.51188009930775
(Previous) Eval Time (s)     19.500629162881523
Sample Time (s)              12.084445777814835
Epoch Time (s)               179.0969550400041
Total Train Time (s)         10775.043225100264
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:55:27.463004 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #59 | Epoch Duration: 179.18413376808167
2020-01-12 04:55:27.463203 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.199556
Z variance train             0.02679183
KL Divergence                25.262669
KL Loss                      2.5262668
QF Loss                      312.3936
VF Loss                      81.86003
Policy Loss                  -518.08044
Q Predictions Mean           511.8073
Q Predictions Std            177.65143
Q Predictions Max            761.6616
Q Predictions Min            70.66105
V Predictions Mean           513.86365
V Predictions Std            170.94153
V Predictions Max            753.8749
V Predictions Min            161.45432
Log Pis Mean                 -1.7976946
Log Pis Std                  2.5777617
Log Pis Max                  9.83292
Log Pis Min                  -8.924756
Policy mu Mean               0.0034425892
Policy mu Std                0.44759825
Policy mu Max                2.1745458
Policy mu Min                -3.8728619
Policy log std Mean          -0.86726904
Policy log std Std           0.13695711
Policy log std Max           -0.40784258
Policy log std Min           -1.6866719
Z mean eval                  1.2677829
Z variance eval              0.0495149
total_rewards                [ 460.90775781  538.22824574  602.8091478   411.50941715   85.26293941
   30.31214429  474.85640566 1180.17245382  131.52990159  151.34990411]
total_rewards_mean           406.69383173835257
total_rewards_std            323.6567436690532
total_rewards_max            1180.172453819287
total_rewards_min            30.31214429328052
Number of train steps total  244000
Number of env steps total    207460
Number of rollouts total     0
Train Time (s)               141.47448216425255
(Previous) Eval Time (s)     19.091336596757174
Sample Time (s)              12.49863045103848
Epoch Time (s)               173.0644492120482
Total Train Time (s)         10948.197300711647
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:58:20.618935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #60 | Epoch Duration: 173.15558004379272
2020-01-12 04:58:20.619121 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2679762
Z variance train             0.04945088
KL Divergence                23.863976
KL Loss                      2.3863976
QF Loss                      352.0481
VF Loss                      72.69202
Policy Loss                  -545.4673
Q Predictions Mean           536.8648
Q Predictions Std            180.27481
Q Predictions Max            766.48157
Q Predictions Min            24.755102
V Predictions Mean           544.1172
V Predictions Std            168.44223
V Predictions Max            761.44763
V Predictions Min            122.563934
Log Pis Mean                 -1.4886029
Log Pis Std                  3.2072008
Log Pis Max                  22.682034
Log Pis Min                  -10.6395035
Policy mu Mean               0.016420633
Policy mu Std                0.49776608
Policy mu Max                3.1569626
Policy mu Min                -3.2662563
Policy log std Mean          -0.8956853
Policy log std Std           0.14499189
Policy log std Max           -0.51544726
Policy log std Min           -1.6594629
Z mean eval                  1.2598982
Z variance eval              0.044816058
total_rewards                [1862.67402264  661.62755412  489.09211699  527.77991265   93.17727579
  888.40440006  464.9255334    89.26522838   94.97299857 2033.67593753]
total_rewards_mean           720.5594980117477
total_rewards_std            663.320018771521
total_rewards_max            2033.675937527155
total_rewards_min            89.26522838259515
Number of train steps total  248000
Number of env steps total    211065
Number of rollouts total     0
Train Time (s)               138.6859473171644
(Previous) Eval Time (s)     20.58487522089854
Sample Time (s)              11.695157585199922
Epoch Time (s)               170.96598012326285
Total Train Time (s)         11119.251452136785
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:01:11.674995 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #61 | Epoch Duration: 171.05569624900818
2020-01-12 05:01:11.675308 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2592368
Z variance train             0.04488253
KL Divergence                23.924288
KL Loss                      2.3924289
QF Loss                      367.42148
VF Loss                      104.08624
Policy Loss                  -529.90784
Q Predictions Mean           518.1002
Q Predictions Std            189.83017
Q Predictions Max            820.3933
Q Predictions Min            18.070126
V Predictions Mean           526.6172
V Predictions Std            179.25388
V Predictions Max            810.4969
V Predictions Min            157.5843
Log Pis Mean                 -1.5362548
Log Pis Std                  2.7658083
Log Pis Max                  14.687092
Log Pis Min                  -9.0883875
Policy mu Mean               -0.009033308
Policy mu Std                0.46030837
Policy mu Max                2.8313363
Policy mu Min                -2.6653666
Policy log std Mean          -0.8987133
Policy log std Std           0.16187952
Policy log std Max           -0.50071377
Policy log std Min           -1.8582991
Z mean eval                  1.2614192
Z variance eval              0.06974458
total_rewards                [1751.23309188  149.99570696  424.07666317  905.45032607  650.77672419
  685.1106415   467.56401893 1154.97285555  599.40694767  510.86748564]
total_rewards_mean           729.9454461556817
total_rewards_std            427.3796253093407
total_rewards_max            1751.2330918848795
total_rewards_min            149.9957069609966
Number of train steps total  252000
Number of env steps total    214466
Number of rollouts total     0
Train Time (s)               140.30033798282966
(Previous) Eval Time (s)     29.71482932008803
Sample Time (s)              11.096128396689892
Epoch Time (s)               181.11129569960758
Total Train Time (s)         11300.473074077629
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:04:12.898051 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #62 | Epoch Duration: 181.22255659103394
2020-01-12 05:04:12.898266 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.256694
Z variance train             0.069033876
KL Divergence                23.33343
KL Loss                      2.333343
QF Loss                      392.6551
VF Loss                      64.37436
Policy Loss                  -537.49286
Q Predictions Mean           524.58386
Q Predictions Std            183.05519
Q Predictions Max            797.2562
Q Predictions Min            7.67154
V Predictions Mean           540.1504
V Predictions Std            175.24887
V Predictions Max            798.17554
V Predictions Min            235.60239
Log Pis Mean                 -1.5041163
Log Pis Std                  2.7302704
Log Pis Max                  13.011522
Log Pis Min                  -8.525068
Policy mu Mean               0.03408063
Policy mu Std                0.48614448
Policy mu Max                2.36796
Policy mu Min                -2.386825
Policy log std Mean          -0.89823663
Policy log std Std           0.15228546
Policy log std Max           -0.12330127
Policy log std Min           -1.5200877
Z mean eval                  1.2698524
Z variance eval              0.11552031
total_rewards                [1456.15319606  425.9694332    94.48602971 1486.79254141 1267.60780423
  572.48443949 2106.43731241 1049.98293334  169.93617744  652.47711009]
total_rewards_mean           928.2326977378832
total_rewards_std            619.182309317349
total_rewards_max            2106.437312406498
total_rewards_min            94.48602971062016
Number of train steps total  256000
Number of env steps total    217355
Number of rollouts total     0
Train Time (s)               149.33218231564388
(Previous) Eval Time (s)     26.917298623360693
Sample Time (s)              13.333034125622362
Epoch Time (s)               189.58251506462693
Total Train Time (s)         11490.14495961275
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:07:22.571795 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #63 | Epoch Duration: 189.67337036132812
2020-01-12 05:07:22.571996 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2723532
Z variance train             0.11513184
KL Divergence                20.934092
KL Loss                      2.0934093
QF Loss                      499.9095
VF Loss                      110.3989
Policy Loss                  -543.85034
Q Predictions Mean           532.70984
Q Predictions Std            181.27232
Q Predictions Max            787.2185
Q Predictions Min            -61.298256
V Predictions Mean           546.66376
V Predictions Std            173.96062
V Predictions Max            791.7869
V Predictions Min            249.78912
Log Pis Mean                 -1.4274061
Log Pis Std                  2.4936354
Log Pis Max                  9.293995
Log Pis Min                  -7.383942
Policy mu Mean               0.038323656
Policy mu Std                0.46407136
Policy mu Max                2.1820707
Policy mu Min                -2.056312
Policy log std Mean          -0.90945613
Policy log std Std           0.1579208
Policy log std Max           -0.28307647
Policy log std Min           -1.719687
Z mean eval                  1.2290437
Z variance eval              0.045619734
total_rewards                [ 385.64883638  484.35566128  511.26568844  485.05155469  629.76727054
 1064.11212526  245.4272939   429.51886538  191.68684814 1497.12870669]
total_rewards_mean           592.3962850701583
total_rewards_std            377.15515580087265
total_rewards_max            1497.1287066897985
total_rewards_min            191.68684814218733
Number of train steps total  260000
Number of env steps total    221128
Number of rollouts total     0
Train Time (s)               147.77221189578995
(Previous) Eval Time (s)     25.1343494951725
Sample Time (s)              11.916188419796526
Epoch Time (s)               184.82274981075898
Total Train Time (s)         11675.055635738187
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:10:27.483938 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #64 | Epoch Duration: 184.91179609298706
2020-01-12 05:10:27.484129 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2277946
Z variance train             0.046155803
KL Divergence                23.96076
KL Loss                      2.396076
QF Loss                      445.59637
VF Loss                      154.1987
Policy Loss                  -547.6479
Q Predictions Mean           540.15356
Q Predictions Std            188.12155
Q Predictions Max            812.9769
Q Predictions Min            53.317554
V Predictions Mean           555.3153
V Predictions Std            187.23528
V Predictions Max            832.4102
V Predictions Min            145.8058
Log Pis Mean                 -1.5666208
Log Pis Std                  2.7834222
Log Pis Max                  14.808512
Log Pis Min                  -7.7653685
Policy mu Mean               -0.005925411
Policy mu Std                0.46323612
Policy mu Max                2.920718
Policy mu Min                -2.6937206
Policy log std Mean          -0.90222883
Policy log std Std           0.14726932
Policy log std Max           -0.541241
Policy log std Min           -1.5715383
Z mean eval                  1.2333007
Z variance eval              0.08634976
total_rewards                [1001.91737963  904.70469582   73.37759326  755.76271238 1983.82062612
 1145.65215115  682.45228078 1811.2739109   518.00256361 1053.68186436]
total_rewards_mean           993.0645777991351
total_rewards_std            539.4633968224124
total_rewards_max            1983.8206261150044
total_rewards_min            73.37759326155515
Number of train steps total  264000
Number of env steps total    224155
Number of rollouts total     0
Train Time (s)               146.93255919311196
(Previous) Eval Time (s)     22.25600208202377
Sample Time (s)              12.657073920127004
Epoch Time (s)               181.84563519526273
Total Train Time (s)         11856.990663953125
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:13:29.420577 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #65 | Epoch Duration: 181.93630456924438
2020-01-12 05:13:29.420767 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2270544
Z variance train             0.08564535
KL Divergence                22.216633
KL Loss                      2.2216632
QF Loss                      459.71716
VF Loss                      113.05988
Policy Loss                  -565.7088
Q Predictions Mean           555.2212
Q Predictions Std            182.79292
Q Predictions Max            820.4519
Q Predictions Min            -31.87717
V Predictions Mean           560.34766
V Predictions Std            174.53255
V Predictions Max            797.2983
V Predictions Min            45.42442
Log Pis Mean                 -1.6906457
Log Pis Std                  2.7290797
Log Pis Max                  12.084948
Log Pis Min                  -7.7650204
Policy mu Mean               0.030858524
Policy mu Std                0.48191705
Policy mu Max                3.3643124
Policy mu Min                -2.8375118
Policy log std Mean          -0.8868466
Policy log std Std           0.15210792
Policy log std Max           -0.49733293
Policy log std Min           -1.7164567
Z mean eval                  1.2324258
Z variance eval              0.059794534
total_rewards                [  86.91075743  612.66743507 1075.34705615  313.67651067  991.29951578
 1106.80758513  732.33337998 1360.44140426  470.51050432  690.65803397]
total_rewards_mean           744.0652182756479
total_rewards_std            373.4364776900268
total_rewards_max            1360.4414042576686
total_rewards_min            86.91075742866546
Number of train steps total  268000
Number of env steps total    227766
Number of rollouts total     0
Train Time (s)               147.23263476602733
(Previous) Eval Time (s)     17.506334602367133
Sample Time (s)              12.89196260459721
Epoch Time (s)               177.63093197299168
Total Train Time (s)         12034.718619927298
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:16:27.151490 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #66 | Epoch Duration: 177.73054552078247
2020-01-12 05:16:27.151868 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.224322
Z variance train             0.059877753
KL Divergence                23.735527
KL Loss                      2.3735528
QF Loss                      506.01544
VF Loss                      95.144394
Policy Loss                  -550.45355
Q Predictions Mean           540.3662
Q Predictions Std            188.13501
Q Predictions Max            813.85986
Q Predictions Min            18.178967
V Predictions Mean           553.883
V Predictions Std            181.09918
V Predictions Max            817.353
V Predictions Min            227.71126
Log Pis Mean                 -1.0864646
Log Pis Std                  3.2096853
Log Pis Max                  16.203264
Log Pis Min                  -7.5923367
Policy mu Mean               0.045391925
Policy mu Std                0.531334
Policy mu Max                3.1688056
Policy mu Min                -2.7491472
Policy log std Mean          -0.9090982
Policy log std Std           0.15542628
Policy log std Max           -0.3588159
Policy log std Min           -1.8577583
Z mean eval                  1.3041334
Z variance eval              0.11535152
total_rewards                [ 383.10087997 1139.46625201  493.35485986  413.31759605 1808.09010648
  818.78475645  370.31675173 1228.23164314  551.86079683  365.30258161]
total_rewards_mean           757.1826224118591
total_rewards_std            463.616968131429
total_rewards_max            1808.0901064769064
total_rewards_min            365.3025816085194
Number of train steps total  272000
Number of env steps total    230742
Number of rollouts total     0
Train Time (s)               140.3466214807704
(Previous) Eval Time (s)     27.05418691597879
Sample Time (s)              13.552830620668828
Epoch Time (s)               180.95363901741803
Total Train Time (s)         12215.910000167787
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:19:28.343384 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #67 | Epoch Duration: 181.1912498474121
2020-01-12 05:19:28.343580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3126023
Z variance train             0.11573736
KL Divergence                21.654814
KL Loss                      2.1654813
QF Loss                      620.46265
VF Loss                      112.14311
Policy Loss                  -558.1892
Q Predictions Mean           547.3266
Q Predictions Std            196.44633
Q Predictions Max            834.0842
Q Predictions Min            -43.235508
V Predictions Mean           558.96484
V Predictions Std            190.00046
V Predictions Max            829.9671
V Predictions Min            186.0825
Log Pis Mean                 -1.3861411
Log Pis Std                  3.2005534
Log Pis Max                  17.72455
Log Pis Min                  -6.798415
Policy mu Mean               0.009275682
Policy mu Std                0.49632585
Policy mu Max                3.4393208
Policy mu Min                -3.14548
Policy log std Mean          -0.90976524
Policy log std Std           0.16115554
Policy log std Max           -0.3704023
Policy log std Min           -1.6682754
Z mean eval                  1.2800118
Z variance eval              0.047176324
total_rewards                [ 409.55649818 1043.76323122  413.64969454  948.21752069  581.24733403
 1417.41956299  806.83892969 1595.63781652  556.41998967   67.10618744]
total_rewards_mean           783.9856764969339
total_rewards_std            451.5692151811207
total_rewards_max            1595.6378165237877
total_rewards_min            67.10618744086514
Number of train steps total  276000
Number of env steps total    233330
Number of rollouts total     0
Train Time (s)               138.98940745415166
(Previous) Eval Time (s)     24.403349785134196
Sample Time (s)              11.913210224360228
Epoch Time (s)               175.30596746364608
Total Train Time (s)         12391.304618903436
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:22:23.740181 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #68 | Epoch Duration: 175.39644026756287
2020-01-12 05:22:23.740451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2898102
Z variance train             0.04700438
KL Divergence                23.639414
KL Loss                      2.3639414
QF Loss                      331.24585
VF Loss                      97.25301
Policy Loss                  -584.55176
Q Predictions Mean           577.48083
Q Predictions Std            184.0657
Q Predictions Max            821.68866
Q Predictions Min            124.826836
V Predictions Mean           590.9036
V Predictions Std            181.83803
V Predictions Max            818.881
V Predictions Min            181.95459
Log Pis Mean                 -1.1187155
Log Pis Std                  2.7437541
Log Pis Max                  16.438416
Log Pis Min                  -6.8059006
Policy mu Mean               0.00943275
Policy mu Std                0.5022091
Policy mu Max                2.3888009
Policy mu Min                -3.7585168
Policy log std Mean          -0.904801
Policy log std Std           0.15769856
Policy log std Max           -0.44246355
Policy log std Min           -1.897852
Z mean eval                  1.25126
Z variance eval              0.07835587
total_rewards                [1820.41266403  661.06207377 1484.57060723 2302.10983223 1917.21654345
  904.28466494 2057.12371384 2142.12890064 1032.72318529  203.61723266]
total_rewards_mean           1452.524941807535
total_rewards_std            676.6224368230351
total_rewards_max            2302.1098322340363
total_rewards_min            203.61723265686174
Number of train steps total  280000
Number of env steps total    236065
Number of rollouts total     0
Train Time (s)               140.9226110642776
(Previous) Eval Time (s)     32.441000408958644
Sample Time (s)              11.530011938419193
Epoch Time (s)               184.89362341165543
Total Train Time (s)         12576.306069901213
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:25:28.743159 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #69 | Epoch Duration: 185.00251126289368
2020-01-12 05:25:28.743441 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2490485
Z variance train             0.07847874
KL Divergence                23.267143
KL Loss                      2.3267143
QF Loss                      488.5445
VF Loss                      113.658806
Policy Loss                  -556.4982
Q Predictions Mean           546.845
Q Predictions Std            180.49207
Q Predictions Max            810.236
Q Predictions Min            239.45627
V Predictions Mean           560.0356
V Predictions Std            175.02597
V Predictions Max            805.7862
V Predictions Min            262.977
Log Pis Mean                 -1.2476385
Log Pis Std                  2.4285367
Log Pis Max                  9.910967
Log Pis Min                  -6.2479258
Policy mu Mean               0.008172556
Policy mu Std                0.47143668
Policy mu Max                3.05046
Policy mu Min                -2.1914113
Policy log std Mean          -0.9156583
Policy log std Std           0.16095205
Policy log std Max           -0.2860858
Policy log std Min           -1.7074231
Z mean eval                  1.1742238
Z variance eval              0.026874816
total_rewards                [1723.61329471  752.09620828 2047.53175998 2145.85183618  166.35735328
 2116.36931153  133.13400276 2003.18881941 2039.96542637  280.00610483]
total_rewards_mean           1340.8114117319624
total_rewards_std            844.5621225850142
total_rewards_max            2145.8518361774127
total_rewards_min            133.1340027562243
Number of train steps total  284000
Number of env steps total    238564
Number of rollouts total     0
Train Time (s)               149.80336778610945
(Previous) Eval Time (s)     24.59285812312737
Sample Time (s)              10.048514929134399
Epoch Time (s)               184.44474083837122
Total Train Time (s)         12760.844211871736
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:28:33.283965 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #70 | Epoch Duration: 184.54035830497742
2020-01-12 05:28:33.284208 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #70 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1773279
Z variance train             0.026713774
KL Divergence                24.729404
KL Loss                      2.4729404
QF Loss                      1159.017
VF Loss                      119.386795
Policy Loss                  -588.1197
Q Predictions Mean           578.9889
Q Predictions Std            189.788
Q Predictions Max            830.4326
Q Predictions Min            116.56523
V Predictions Mean           583.72815
V Predictions Std            183.07687
V Predictions Max            820.4359
V Predictions Min            228.54002
Log Pis Mean                 -1.0223165
Log Pis Std                  2.7569609
Log Pis Max                  10.194109
Log Pis Min                  -8.611057
Policy mu Mean               0.0045745345
Policy mu Std                0.4897675
Policy mu Max                2.1243699
Policy mu Min                -2.5010548
Policy log std Mean          -0.9386706
Policy log std Std           0.17027824
Policy log std Max           -0.5382459
Policy log std Min           -1.8104124
Z mean eval                  1.248297
Z variance eval              0.09523897
total_rewards                [1943.25105629 1162.2021681   450.16791124  102.70692563  548.5101968
  855.60051806  409.31931847 2543.51976417 1547.21786663  187.98472567]
total_rewards_mean           975.0480451066453
total_rewards_std            770.2028088207153
total_rewards_max            2543.519764172765
total_rewards_min            102.70692562861936
Number of train steps total  288000
Number of env steps total    241318
Number of rollouts total     0
Train Time (s)               148.87825225992128
(Previous) Eval Time (s)     30.336005054879934
Sample Time (s)              13.01375881768763
Epoch Time (s)               192.22801613248885
Total Train Time (s)         12953.161749814637
Epoch                        71
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:31:45.602964 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #71 | Epoch Duration: 192.31857919692993
2020-01-12 05:31:45.603219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2506803
Z variance train             0.09505904
KL Divergence                21.683872
KL Loss                      2.1683872
QF Loss                      375.61908
VF Loss                      71.71071
Policy Loss                  -588.6643
Q Predictions Mean           577.5829
Q Predictions Std            201.08815
Q Predictions Max            850.9185
Q Predictions Min            -8.681563
V Predictions Mean           584.48083
V Predictions Std            192.106
V Predictions Max            845.33154
V Predictions Min            222.39658
Log Pis Mean                 -1.179746
Log Pis Std                  2.7192743
Log Pis Max                  12.832163
Log Pis Min                  -5.4797974
Policy mu Mean               0.013027266
Policy mu Std                0.47664195
Policy mu Max                2.3759735
Policy mu Min                -2.4894867
Policy log std Mean          -0.9251949
Policy log std Std           0.17509551
Policy log std Max           -0.48348895
Policy log std Min           -1.6529154
Z mean eval                  1.1960326
Z variance eval              0.039345313
total_rewards                [2288.62936059  878.86213584 2446.67001767 2061.02317314  465.27680466
  373.90896481 1885.8584448   405.35258682  937.05144485  597.84202329]
total_rewards_mean           1234.0474956484145
total_rewards_std            795.4901125678495
total_rewards_max            2446.6700176699833
total_rewards_min            373.9089648125763
Number of train steps total  292000
Number of env steps total    244160
Number of rollouts total     0
Train Time (s)               147.94762062001973
(Previous) Eval Time (s)     24.611397127155215
Sample Time (s)              12.02430998859927
Epoch Time (s)               184.58332773577422
Total Train Time (s)         13137.849230694119
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:34:50.292613 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #72 | Epoch Duration: 184.6890571117401
2020-01-12 05:34:50.292907 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1976717
Z variance train             0.039259452
KL Divergence                23.70444
KL Loss                      2.370444
QF Loss                      376.42426
VF Loss                      134.21564
Policy Loss                  -600.9004
Q Predictions Mean           589.8196
Q Predictions Std            200.27902
Q Predictions Max            869.2813
Q Predictions Min            -10.2653475
V Predictions Mean           600.2448
V Predictions Std            191.61494
V Predictions Max            865.10815
V Predictions Min            250.9682
Log Pis Mean                 -1.1039809
Log Pis Std                  2.9736223
Log Pis Max                  18.015945
Log Pis Min                  -9.343112
Policy mu Mean               0.009828339
Policy mu Std                0.5109297
Policy mu Max                4.6180167
Policy mu Min                -3.1798604
Policy log std Mean          -0.91250676
Policy log std Std           0.16670997
Policy log std Max           -0.31219453
Policy log std Min           -1.6152575
Z mean eval                  1.2035974
Z variance eval              0.043243572
total_rewards                [ 321.58674223  199.16263918  573.60787598  242.85634523  587.47495819
  697.62164203  911.43629488 1437.65934175  435.21219201  720.81409852]
total_rewards_mean           612.7432130007479
total_rewards_std            348.5559409652589
total_rewards_max            1437.6593417519396
total_rewards_min            199.16263918024805
Number of train steps total  296000
Number of env steps total    246912
Number of rollouts total     0
Train Time (s)               146.568622474093
(Previous) Eval Time (s)     20.765681040938944
Sample Time (s)              14.094809784553945
Epoch Time (s)               181.42911329958588
Total Train Time (s)         13319.372338231653
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:37:51.817329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #73 | Epoch Duration: 181.52423620224
2020-01-12 05:37:51.817533 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1988184
Z variance train             0.043480627
KL Divergence                23.809956
KL Loss                      2.3809955
QF Loss                      484.66998
VF Loss                      115.65809
Policy Loss                  -573.9017
Q Predictions Mean           563.9961
Q Predictions Std            203.6686
Q Predictions Max            845.3786
Q Predictions Min            -75.510635
V Predictions Mean           579.76013
V Predictions Std            196.7911
V Predictions Max            853.67957
V Predictions Min            226.1463
Log Pis Mean                 -1.4783676
Log Pis Std                  2.5819228
Log Pis Max                  8.992903
Log Pis Min                  -7.981624
Policy mu Mean               0.00092960475
Policy mu Std                0.47378373
Policy mu Max                1.8112519
Policy mu Min                -2.494443
Policy log std Mean          -0.8990526
Policy log std Std           0.16131058
Policy log std Max           -0.3478551
Policy log std Min           -1.5319942
Z mean eval                  1.2570488
Z variance eval              0.046418834
total_rewards                [ 464.50211207  641.8169995   333.26839833 2181.29906009  423.33291692
 2175.1662566   805.64179061   83.83917966 1339.47250189  910.57592281]
total_rewards_mean           935.8915138490742
total_rewards_std            701.9884066457968
total_rewards_max            2181.2990600854173
total_rewards_min            83.83917966360144
Number of train steps total  300000
Number of env steps total    249955
Number of rollouts total     0
Train Time (s)               140.6947680078447
(Previous) Eval Time (s)     30.07866667304188
Sample Time (s)              14.584345690906048
Epoch Time (s)               185.35778037179261
Total Train Time (s)         13504.816404552665
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:40:57.263283 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #74 | Epoch Duration: 185.44559907913208
2020-01-12 05:40:57.263481 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2538159
Z variance train             0.046216365
KL Divergence                22.88174
KL Loss                      2.2881742
QF Loss                      519.7311
VF Loss                      77.20994
Policy Loss                  -603.7061
Q Predictions Mean           594.0915
Q Predictions Std            210.60606
Q Predictions Max            898.6832
Q Predictions Min            18.018232
V Predictions Mean           603.8493
V Predictions Std            202.30731
V Predictions Max            892.91
V Predictions Min            219.1924
Log Pis Mean                 -1.1214149
Log Pis Std                  3.1372185
Log Pis Max                  13.439519
Log Pis Min                  -7.693735
Policy mu Mean               0.0042658956
Policy mu Std                0.5292446
Policy mu Max                2.6725824
Policy mu Min                -2.9909267
Policy log std Mean          -0.9250158
Policy log std Std           0.17024341
Policy log std Max           -0.3819771
Policy log std Min           -1.7618365
Z mean eval                  1.2687428
Z variance eval              0.03800621
total_rewards                [ 405.74306521  580.51283821  553.31960845  731.70994212 1761.23193983
 1067.95626563 1966.48375071 2198.69625777 2387.32325776 2270.35141398]
total_rewards_mean           1392.332833968735
total_rewards_std            758.6090824856149
total_rewards_max            2387.3232577649605
total_rewards_min            405.7430652100753
Number of train steps total  304000
Number of env steps total    252986
Number of rollouts total     0
Train Time (s)               139.17408319190145
(Previous) Eval Time (s)     27.82165684690699
Sample Time (s)              12.938561735674739
Epoch Time (s)               179.93430177448317
Total Train Time (s)         13684.841469957028
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:43:57.292272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #75 | Epoch Duration: 180.02860522270203
2020-01-12 05:43:57.292552 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.269149
Z variance train             0.037926055
KL Divergence                23.414541
KL Loss                      2.3414543
QF Loss                      456.57843
VF Loss                      117.195755
Policy Loss                  -600.51263
Q Predictions Mean           595.08167
Q Predictions Std            213.5937
Q Predictions Max            895.3767
Q Predictions Min            -18.922646
V Predictions Mean           599.8314
V Predictions Std            207.36089
V Predictions Max            894.48413
V Predictions Min            91.76229
Log Pis Mean                 -1.3309507
Log Pis Std                  2.627734
Log Pis Max                  11.056293
Log Pis Min                  -10.098885
Policy mu Mean               0.018922359
Policy mu Std                0.44282135
Policy mu Max                2.3944714
Policy mu Min                -3.0442927
Policy log std Mean          -0.9341626
Policy log std Std           0.17787856
Policy log std Max           -0.51558864
Policy log std Min           -1.9428282
Z mean eval                  1.1964266
Z variance eval              0.035620816
total_rewards                [2056.10757858  568.87963095 1093.80595705 1034.50947419  521.30508913
 2530.30009779  907.99196262 2373.72252263  458.49000685 2372.52758165]
total_rewards_mean           1391.7639901439825
total_rewards_std            801.251489981947
total_rewards_max            2530.3000977886986
total_rewards_min            458.49000685182114
Number of train steps total  308000
Number of env steps total    255368
Number of rollouts total     0
Train Time (s)               142.26606324594468
(Previous) Eval Time (s)     33.26637479988858
Sample Time (s)              11.523689358495176
Epoch Time (s)               187.05612740432844
Total Train Time (s)         13871.999023062177
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:47:04.451055 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #76 | Epoch Duration: 187.15827417373657
2020-01-12 05:47:04.451463 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1994783
Z variance train             0.035697028
KL Divergence                23.927505
KL Loss                      2.3927505
QF Loss                      615.14856
VF Loss                      104.2118
Policy Loss                  -607.6762
Q Predictions Mean           598.2045
Q Predictions Std            209.67445
Q Predictions Max            878.6144
Q Predictions Min            12.159829
V Predictions Mean           606.18274
V Predictions Std            202.56113
V Predictions Max            878.23004
V Predictions Min            131.49506
Log Pis Mean                 -0.9511509
Log Pis Std                  3.0248575
Log Pis Max                  16.710274
Log Pis Min                  -8.266005
Policy mu Mean               -0.013653804
Policy mu Std                0.5423959
Policy mu Max                3.205374
Policy mu Min                -3.751624
Policy log std Mean          -0.91887516
Policy log std Std           0.16848947
Policy log std Max           -0.27353007
Policy log std Min           -1.7209955
Z mean eval                  1.2096304
Z variance eval              0.04733301
total_rewards                [2250.46130483 1638.76348537 2284.65348626  145.9600619  2138.38642014
 2129.84226686  861.77408012 2213.73795795  628.70964958 1901.68309083]
total_rewards_mean           1619.3971803841619
total_rewards_std            743.6722890988275
total_rewards_max            2284.653486262042
total_rewards_min            145.96006189703863
Number of train steps total  312000
Number of env steps total    258799
Number of rollouts total     0
Train Time (s)               149.15541056217626
(Previous) Eval Time (s)     32.61582437576726
Sample Time (s)              11.376494188793004
Epoch Time (s)               193.14772912673652
Total Train Time (s)         14065.245722566731
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:50:17.699757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #77 | Epoch Duration: 193.24796795845032
2020-01-12 05:50:17.700075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2122569
Z variance train             0.04760154
KL Divergence                23.18921
KL Loss                      2.318921
QF Loss                      641.8063
VF Loss                      102.399956
Policy Loss                  -625.39465
Q Predictions Mean           616.4185
Q Predictions Std            212.90648
Q Predictions Max            886.4989
Q Predictions Min            37.691227
V Predictions Mean           623.7706
V Predictions Std            209.46413
V Predictions Max            877.5752
V Predictions Min            63.102013
Log Pis Mean                 -0.9977274
Log Pis Std                  3.7147386
Log Pis Max                  39.11149
Log Pis Min                  -8.719757
Policy mu Mean               0.029160157
Policy mu Std                0.5340366
Policy mu Max                6.0613594
Policy mu Min                -5.968633
Policy log std Mean          -0.93863213
Policy log std Std           0.18178345
Policy log std Max           -0.42766148
Policy log std Min           -2.3170896
Z mean eval                  1.2309209
Z variance eval              0.08058432
total_rewards                [1939.03909439 2148.10279654  931.61390403  528.15953595 1746.73745069
  108.78727548  633.41151969  719.696429   1022.66150243 1488.72705927]
total_rewards_mean           1126.6936567473253
total_rewards_std            638.0386771835869
total_rewards_max            2148.102796542768
total_rewards_min            108.7872754847943
Number of train steps total  316000
Number of env steps total    261327
Number of rollouts total     0
Train Time (s)               148.39885390596464
(Previous) Eval Time (s)     23.22514209104702
Sample Time (s)              10.798184433020651
Epoch Time (s)               182.4221804300323
Total Train Time (s)         14247.760292895604
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:53:20.214995 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #78 | Epoch Duration: 182.514732837677
2020-01-12 05:53:20.215200 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.234289
Z variance train             0.08020606
KL Divergence                21.855827
KL Loss                      2.1855829
QF Loss                      366.9513
VF Loss                      86.71423
Policy Loss                  -599.61224
Q Predictions Mean           595.0891
Q Predictions Std            201.45686
Q Predictions Max            870.7309
Q Predictions Min            -14.665744
V Predictions Mean           599.1012
V Predictions Std            200.21259
V Predictions Max            870.62213
V Predictions Min            -103.72915
Log Pis Mean                 -1.2000022
Log Pis Std                  2.9776459
Log Pis Max                  18.890558
Log Pis Min                  -7.9635406
Policy mu Mean               0.0060583376
Policy mu Std                0.5152874
Policy mu Max                2.7795622
Policy mu Min                -3.7493093
Policy log std Mean          -0.92652076
Policy log std Std           0.16817816
Policy log std Max           -0.36984533
Policy log std Min           -1.680601
Z mean eval                  1.218229
Z variance eval              0.031646237
total_rewards                [ 627.94837096 1363.14727142 2304.89924564  953.23752602  936.86771442
 1113.45319504 1263.60223374 1754.87611515 1625.28285283 2273.27909473]
total_rewards_mean           1421.6593619957991
total_rewards_std            535.3205253854505
total_rewards_max            2304.899245638278
total_rewards_min            627.9483709631922
Number of train steps total  320000
Number of env steps total    265926
Number of rollouts total     0
Train Time (s)               148.57618387509137
(Previous) Eval Time (s)     31.377890820149332
Sample Time (s)              12.39290611911565
Epoch Time (s)               192.34698081435636
Total Train Time (s)         14440.192522552796
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:56:32.649045 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #79 | Epoch Duration: 192.4336953163147
2020-01-12 05:56:32.649231 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2166336
Z variance train             0.03168813
KL Divergence                23.307735
KL Loss                      2.3307736
QF Loss                      701.36676
VF Loss                      109.07089
Policy Loss                  -636.338
Q Predictions Mean           622.9304
Q Predictions Std            219.0491
Q Predictions Max            904.8521
Q Predictions Min            -126.30424
V Predictions Mean           638.1478
V Predictions Std            208.59291
V Predictions Max            914.7554
V Predictions Min            242.39738
Log Pis Mean                 -1.1569616
Log Pis Std                  3.0296414
Log Pis Max                  15.789
Log Pis Min                  -7.499511
Policy mu Mean               -0.0077126594
Policy mu Std                0.52954036
Policy mu Max                3.18182
Policy mu Min                -2.6346743
Policy log std Mean          -0.9291992
Policy log std Std           0.18090689
Policy log std Max           -0.35659993
Policy log std Min           -1.6996753
Z mean eval                  1.2532191
Z variance eval              0.038257435
total_rewards                [1503.46042405   71.05925443 2478.8021578   540.40427509 1553.72482437
  573.86190092  616.71623578  208.73688418  450.94608956 1665.75971829]
total_rewards_mean           966.3471764472794
total_rewards_std            742.2308977908936
total_rewards_max            2478.8021577995937
total_rewards_min            71.05925442715834
Number of train steps total  324000
Number of env steps total    269297
Number of rollouts total     0
Train Time (s)               146.2137281219475
(Previous) Eval Time (s)     23.862419149838388
Sample Time (s)              11.435252607800066
Epoch Time (s)               181.51139987958595
Total Train Time (s)         14621.792243693955
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:59:34.251064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #80 | Epoch Duration: 181.60168170928955
2020-01-12 05:59:34.251295 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2554252
Z variance train             0.03878186
KL Divergence                24.013597
KL Loss                      2.4013598
QF Loss                      385.4354
VF Loss                      125.56702
Policy Loss                  -636.4267
Q Predictions Mean           626.76355
Q Predictions Std            215.7322
Q Predictions Max            902.4769
Q Predictions Min            -10.743888
V Predictions Mean           642.4813
V Predictions Std            206.25563
V Predictions Max            908.72864
V Predictions Min            262.51675
Log Pis Mean                 -0.8993196
Log Pis Std                  3.0615969
Log Pis Max                  16.220394
Log Pis Min                  -7.9268665
Policy mu Mean               -0.032624558
Policy mu Std                0.5163588
Policy mu Max                2.2806475
Policy mu Min                -2.9678645
Policy log std Mean          -0.9310522
Policy log std Std           0.17594805
Policy log std Max           -0.36906862
Policy log std Min           -1.6780524
Z mean eval                  1.2169945
Z variance eval              0.02723369
total_rewards                [1057.38642021  993.69045537 1376.36204571  224.33471121 2476.42672009
 1110.8487246  2364.01247942 2573.49850194 1094.74015807 1202.28986159]
total_rewards_mean           1447.359007821118
total_rewards_std            729.6427199186396
total_rewards_max            2573.4985019400183
total_rewards_min            224.33471120791455
Number of train steps total  328000
Number of env steps total    271562
Number of rollouts total     0
Train Time (s)               140.59267473500222
(Previous) Eval Time (s)     27.285299717914313
Sample Time (s)              11.468012926634401
Epoch Time (s)               179.34598737955093
Total Train Time (s)         14801.226131179836
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:02:33.686597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #81 | Epoch Duration: 179.43513894081116
2020-01-12 06:02:33.686807 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2188269
Z variance train             0.027119273
KL Divergence                24.794596
KL Loss                      2.4794595
QF Loss                      451.74496
VF Loss                      92.98673
Policy Loss                  -628.8228
Q Predictions Mean           619.3598
Q Predictions Std            239.56903
Q Predictions Max            930.79486
Q Predictions Min            -46.380783
V Predictions Mean           626.4489
V Predictions Std            226.48741
V Predictions Max            924.37823
V Predictions Min            94.36305
Log Pis Mean                 -0.7550207
Log Pis Std                  3.3424838
Log Pis Max                  18.066177
Log Pis Min                  -7.585187
Policy mu Mean               -0.0034181941
Policy mu Std                0.54315966
Policy mu Max                2.7756183
Policy mu Min                -2.819823
Policy log std Mean          -0.9509504
Policy log std Std           0.19480214
Policy log std Max           -0.4084561
Policy log std Min           -1.8873235
Z mean eval                  1.2250931
Z variance eval              0.03320954
total_rewards                [  53.92525545 1701.15068113 1091.71987066  910.55055461  695.41094236
  459.18922824  434.18448323  139.94235307 2073.931126    972.29928113]
total_rewards_mean           853.2303775876632
total_rewards_std            615.3749060881325
total_rewards_max            2073.9311259984925
total_rewards_min            53.925255445646314
Number of train steps total  332000
Number of env steps total    273995
Number of rollouts total     0
Train Time (s)               138.79913592431694
(Previous) Eval Time (s)     23.13055334193632
Sample Time (s)              11.011978768743575
Epoch Time (s)               172.94166803499684
Total Train Time (s)         14974.254534138832
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:05:26.716927 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #82 | Epoch Duration: 173.029967546463
2020-01-12 06:05:26.717132 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2156487
Z variance train             0.033338193
KL Divergence                23.169771
KL Loss                      2.3169773
QF Loss                      574.81226
VF Loss                      112.96126
Policy Loss                  -670.0603
Q Predictions Mean           662.7807
Q Predictions Std            209.5088
Q Predictions Max            911.3387
Q Predictions Min            6.1042128
V Predictions Mean           671.5763
V Predictions Std            203.89833
V Predictions Max            915.31525
V Predictions Min            173.15019
Log Pis Mean                 -0.9107009
Log Pis Std                  3.1097615
Log Pis Max                  20.76285
Log Pis Min                  -6.6926246
Policy mu Mean               0.037366748
Policy mu Std                0.5197586
Policy mu Max                3.1639407
Policy mu Min                -3.6582968
Policy log std Mean          -0.954213
Policy log std Std           0.18030907
Policy log std Max           -0.5279105
Policy log std Min           -2.1963046
Z mean eval                  1.16903
Z variance eval              0.020085972
total_rewards                [ 797.00231861 1274.34526559  733.90822458  402.69265205 1639.59661547
  646.5597314   835.33637092  661.42985137  137.37182644  411.44608568]
total_rewards_mean           753.9688942112768
total_rewards_std            412.91791197167663
total_rewards_max            1639.5966154724892
total_rewards_min            137.3718264354556
Number of train steps total  336000
Number of env steps total    276569
Number of rollouts total     0
Train Time (s)               143.35320040490478
(Previous) Eval Time (s)     25.013746864162385
Sample Time (s)              11.392708516214043
Epoch Time (s)               179.7596557852812
Total Train Time (s)         15154.10193358967
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:08:26.565858 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #83 | Epoch Duration: 179.84857773780823
2020-01-12 06:08:26.566044 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1706269
Z variance train             0.019950282
KL Divergence                25.161291
KL Loss                      2.5161293
QF Loss                      360.93634
VF Loss                      130.5082
Policy Loss                  -641.4356
Q Predictions Mean           632.7911
Q Predictions Std            222.41582
Q Predictions Max            915.39014
Q Predictions Min            38.607815
V Predictions Mean           636.084
V Predictions Std            216.10931
V Predictions Max            904.88885
V Predictions Min            153.29407
Log Pis Mean                 -1.1382004
Log Pis Std                  2.8720286
Log Pis Max                  13.098215
Log Pis Min                  -11.429075
Policy mu Mean               0.005325539
Policy mu Std                0.5041966
Policy mu Max                2.8853068
Policy mu Min                -2.6133313
Policy log std Mean          -0.9131365
Policy log std Std           0.1649485
Policy log std Max           -0.3491059
Policy log std Min           -1.7873266
Z mean eval                  1.1753063
Z variance eval              0.039203696
total_rewards                [ 822.56630103  797.585145    989.97097419 1931.66544644 1781.64335295
 2512.5271074   742.98686165 1051.28007435 1952.99835731 1242.21916769]
total_rewards_mean           1382.544278801633
total_rewards_std            584.0736511315941
total_rewards_max            2512.5271074029383
total_rewards_min            742.9868616453916
Number of train steps total  340000
Number of env steps total    279120
Number of rollouts total     0
Train Time (s)               149.71424422692508
(Previous) Eval Time (s)     25.464921046048403
Sample Time (s)              12.379470378160477
Epoch Time (s)               187.55863565113395
Total Train Time (s)         15341.750344645232
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:11:34.214700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #84 | Epoch Duration: 187.6485104560852
2020-01-12 06:11:34.214832 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1700993
Z variance train             0.03916826
KL Divergence                22.546705
KL Loss                      2.2546706
QF Loss                      498.1946
VF Loss                      83.75441
Policy Loss                  -651.63416
Q Predictions Mean           645.0315
Q Predictions Std            223.00726
Q Predictions Max            935.8363
Q Predictions Min            -18.80354
V Predictions Mean           653.68823
V Predictions Std            217.48587
V Predictions Max            927.05444
V Predictions Min            140.24844
Log Pis Mean                 -0.67722875
Log Pis Std                  2.7964444
Log Pis Max                  12.0827465
Log Pis Min                  -7.8666515
Policy mu Mean               -0.0032165307
Policy mu Std                0.51209456
Policy mu Max                2.6914966
Policy mu Min                -2.1244645
Policy log std Mean          -0.9575105
Policy log std Std           0.18893561
Policy log std Max           -0.5294476
Policy log std Min           -1.9296643
Z mean eval                  1.1979563
Z variance eval              0.028928483
total_rewards                [2608.14409732  569.02269043 2291.37509411 1693.50502666  304.51390583
   54.49391489 2254.82661103 1036.88874521 1182.41119729 1681.00673568]
total_rewards_mean           1367.6188018446528
total_rewards_std            837.8370477887995
total_rewards_max            2608.144097316611
total_rewards_min            54.49391489067982
Number of train steps total  344000
Number of env steps total    281533
Number of rollouts total     0
Train Time (s)               148.9949807948433
(Previous) Eval Time (s)     22.752141813281924
Sample Time (s)              11.50751081109047
Epoch Time (s)               183.25463341921568
Total Train Time (s)         15525.092606601771
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:14:37.564350 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #85 | Epoch Duration: 183.34941339492798
2020-01-12 06:14:37.564502 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2009137
Z variance train             0.02867887
KL Divergence                23.711088
KL Loss                      2.3711088
QF Loss                      391.70972
VF Loss                      107.778366
Policy Loss                  -659.16174
Q Predictions Mean           650.0903
Q Predictions Std            229.61896
Q Predictions Max            956.75586
Q Predictions Min            -40.493477
V Predictions Mean           659.9033
V Predictions Std            223.26768
V Predictions Max            954.89404
V Predictions Min            54.2499
Log Pis Mean                 -1.0327806
Log Pis Std                  3.3737257
Log Pis Max                  16.390398
Log Pis Min                  -8.509881
Policy mu Mean               -0.01790228
Policy mu Std                0.55465174
Policy mu Max                2.9992392
Policy mu Min                -4.752341
Policy log std Mean          -0.9175953
Policy log std Std           0.17162998
Policy log std Max           -0.3536448
Policy log std Min           -1.7263203
Z mean eval                  1.2555901
Z variance eval              0.02865633
total_rewards                [ 762.40194942  866.16482631 2157.37781393  911.7982612  1065.00649668
 2396.95769473 2562.25219887 2637.72158681  203.09799918  457.21037046]
total_rewards_mean           1401.9989197566513
total_rewards_std            883.9564626432452
total_rewards_max            2637.7215868064263
total_rewards_min            203.0979991765421
Number of train steps total  348000
Number of env steps total    285025
Number of rollouts total     0
Train Time (s)               149.27486234810203
(Previous) Eval Time (s)     27.787161422893405
Sample Time (s)              10.43576089385897
Epoch Time (s)               187.4977846648544
Total Train Time (s)         15712.838177558966
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:17:45.311387 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #86 | Epoch Duration: 187.74675726890564
2020-01-12 06:17:45.311587 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2574497
Z variance train             0.028501328
KL Divergence                23.150303
KL Loss                      2.3150303
QF Loss                      531.7721
VF Loss                      118.773544
Policy Loss                  -651.287
Q Predictions Mean           643.4686
Q Predictions Std            251.8469
Q Predictions Max            964.7
Q Predictions Min            49.426144
V Predictions Mean           650.2446
V Predictions Std            242.56291
V Predictions Max            961.04333
V Predictions Min            28.517784
Log Pis Mean                 -0.4707138
Log Pis Std                  3.232638
Log Pis Max                  12.647596
Log Pis Min                  -8.717959
Policy mu Mean               0.016787149
Policy mu Std                0.5487041
Policy mu Max                2.7912962
Policy mu Min                -3.216904
Policy log std Mean          -0.9452671
Policy log std Std           0.18905474
Policy log std Max           -0.31719232
Policy log std Min           -2.032273
Z mean eval                  1.1933038
Z variance eval              0.02534916
total_rewards                [2533.64892863 1857.28581938  324.27236694  810.90641237  173.43925535
 2417.66486724  366.33350087 1210.68725528 2341.71025077 1947.35446569]
total_rewards_mean           1398.330312251786
total_rewards_std            884.8320421145021
total_rewards_max            2533.648928632255
total_rewards_min            173.43925535267044
Number of train steps total  352000
Number of env steps total    287434
Number of rollouts total     0
Train Time (s)               147.71621628012508
(Previous) Eval Time (s)     25.765496281906962
Sample Time (s)              11.532107449602336
Epoch Time (s)               185.01382001163438
Total Train Time (s)         15897.942377127241
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:20:50.417223 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #87 | Epoch Duration: 185.1054916381836
2020-01-12 06:20:50.417408 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1919205
Z variance train             0.025367131
KL Divergence                22.595901
KL Loss                      2.2595901
QF Loss                      406.58426
VF Loss                      75.909904
Policy Loss                  -630.109
Q Predictions Mean           621.62146
Q Predictions Std            243.30646
Q Predictions Max            956.1316
Q Predictions Min            -6.3817058
V Predictions Mean           631.7838
V Predictions Std            236.87462
V Predictions Max            973.14886
V Predictions Min            52.52514
Log Pis Mean                 -0.89480096
Log Pis Std                  3.3483245
Log Pis Max                  17.37203
Log Pis Min                  -8.224986
Policy mu Mean               0.030512743
Policy mu Std                0.54902756
Policy mu Max                2.6526477
Policy mu Min                -3.9003603
Policy log std Mean          -0.9321716
Policy log std Std           0.17970532
Policy log std Max           -0.2656755
Policy log std Min           -1.9388661
Z mean eval                  1.1476127
Z variance eval              0.02292895
total_rewards                [2592.39690044  132.10529465 1014.41840954 1666.41464431 2476.53960781
  202.29085408   74.79105278  531.25747464  541.98715293 2556.1508476 ]
total_rewards_mean           1178.835223878978
total_rewards_std            996.8493656696365
total_rewards_max            2592.396900442329
total_rewards_min            74.79105278464723
Number of train steps total  356000
Number of env steps total    291953
Number of rollouts total     0
Train Time (s)               139.01898105069995
(Previous) Eval Time (s)     18.238343393895775
Sample Time (s)              10.12595839612186
Epoch Time (s)               167.38328284071758
Total Train Time (s)         16065.412812877446
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:23:37.890262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #88 | Epoch Duration: 167.4727041721344
2020-01-12 06:23:37.890492 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1448221
Z variance train             0.02283452
KL Divergence                23.356968
KL Loss                      2.335697
QF Loss                      488.17664
VF Loss                      230.66539
Policy Loss                  -684.84344
Q Predictions Mean           672.4157
Q Predictions Std            240.34409
Q Predictions Max            966.1811
Q Predictions Min            -48.577976
V Predictions Mean           689.605
V Predictions Std            232.08821
V Predictions Max            974.0711
V Predictions Min            -55.22654
Log Pis Mean                 -0.6276761
Log Pis Std                  3.213871
Log Pis Max                  24.37101
Log Pis Min                  -9.824659
Policy mu Mean               -0.02234854
Policy mu Std                0.5471166
Policy mu Max                3.2463582
Policy mu Min                -3.1276276
Policy log std Mean          -0.9673732
Policy log std Std           0.19086874
Policy log std Max           -0.465652
Policy log std Min           -1.79807
Z mean eval                  1.2047087
Z variance eval              0.047398448
total_rewards                [1428.5347378  2582.2768202   330.7520131  1825.85503151 1381.25274818
 2508.37941466  310.39136253  730.57519198  407.66310055 1258.78652452]
total_rewards_mean           1276.4466945016277
total_rewards_std            802.4642667198683
total_rewards_max            2582.2768202043253
total_rewards_min            310.39136252523383
Number of train steps total  360000
Number of env steps total    294381
Number of rollouts total     0
Train Time (s)               139.17070903722197
(Previous) Eval Time (s)     21.757069239392877
Sample Time (s)              11.1207689139992
Epoch Time (s)               172.04854719061404
Total Train Time (s)         16237.557006278541
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:26:30.036036 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #89 | Epoch Duration: 172.14535856246948
2020-01-12 06:26:30.036245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2003437
Z variance train             0.04718084
KL Divergence                22.581547
KL Loss                      2.2581546
QF Loss                      408.64053
VF Loss                      92.31023
Policy Loss                  -689.47424
Q Predictions Mean           680.8055
Q Predictions Std            241.5346
Q Predictions Max            994.63214
Q Predictions Min            -38.44844
V Predictions Mean           688.7739
V Predictions Std            234.55101
V Predictions Max            994.29016
V Predictions Min            263.95886
Log Pis Mean                 -1.1015483
Log Pis Std                  2.7718318
Log Pis Max                  17.022345
Log Pis Min                  -7.618719
Policy mu Mean               0.025560157
Policy mu Std                0.52272683
Policy mu Max                3.138613
Policy mu Min                -3.7139118
Policy log std Mean          -0.9508126
Policy log std Std           0.17795783
Policy log std Max           -0.44104177
Policy log std Min           -1.6695013
Z mean eval                  1.1874223
Z variance eval              0.084575854
total_rewards                [ 818.91255808 1115.09795493 1356.01906716  343.97288078 2433.22985542
  822.96698589  114.91359282  652.09009677 1381.6995485    66.34419007]
total_rewards_mean           910.5246730395374
total_rewards_std            673.0838349769548
total_rewards_max            2433.229855415489
total_rewards_min            66.34419006702781
Number of train steps total  364000
Number of env steps total    297197
Number of rollouts total     0
Train Time (s)               142.7363701891154
(Previous) Eval Time (s)     20.07053046580404
Sample Time (s)              10.698087928351015
Epoch Time (s)               173.50498858327046
Total Train Time (s)         16411.15207260009
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:29:23.633160 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #90 | Epoch Duration: 173.596755027771
2020-01-12 06:29:23.633409 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1880497
Z variance train             0.08332236
KL Divergence                21.393791
KL Loss                      2.1393793
QF Loss                      445.12112
VF Loss                      208.15698
Policy Loss                  -673.4366
Q Predictions Mean           662.9707
Q Predictions Std            242.30661
Q Predictions Max            952.4997
Q Predictions Min            32.836906
V Predictions Mean           673.56445
V Predictions Std            238.22221
V Predictions Max            967.87994
V Predictions Min            93.65132
Log Pis Mean                 -1.1098332
Log Pis Std                  2.874198
Log Pis Max                  12.677047
Log Pis Min                  -7.18493
Policy mu Mean               0.0039720484
Policy mu Std                0.50807697
Policy mu Max                2.8588095
Policy mu Min                -3.5936587
Policy log std Mean          -0.9247241
Policy log std Std           0.1725116
Policy log std Max           -0.33340183
Policy log std Min           -1.6797452
Z mean eval                  1.234973
Z variance eval              0.03050841
total_rewards                [ 362.49971123  871.78819516  709.89777007 1454.3502866   539.44111884
 1267.95609825 2266.82117524 1380.89531855  589.59053678  402.77791984]
total_rewards_mean           984.6018130553905
total_rewards_std            571.8399739517938
total_rewards_max            2266.821175243238
total_rewards_min            362.4997112300458
Number of train steps total  368000
Number of env steps total    300366
Number of rollouts total     0
Train Time (s)               149.74878827203065
(Previous) Eval Time (s)     25.48033235874027
Sample Time (s)              13.41522840410471
Epoch Time (s)               188.64434903487563
Total Train Time (s)         16599.889000396244
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:32:32.371596 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #91 | Epoch Duration: 188.73803901672363
2020-01-12 06:32:32.371799 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.235505
Z variance train             0.030487454
KL Divergence                24.99808
KL Loss                      2.499808
QF Loss                      751.15247
VF Loss                      133.05278
Policy Loss                  -706.05585
Q Predictions Mean           694.6696
Q Predictions Std            244.16373
Q Predictions Max            989.132
Q Predictions Min            -60.29544
V Predictions Mean           709.3718
V Predictions Std            230.15465
V Predictions Max            987.97565
V Predictions Min            54.654816
Log Pis Mean                 -1.0057867
Log Pis Std                  3.209762
Log Pis Max                  14.72183
Log Pis Min                  -6.928317
Policy mu Mean               0.03630165
Policy mu Std                0.5391352
Policy mu Max                3.7545874
Policy mu Min                -2.4181561
Policy log std Mean          -0.93333185
Policy log std Std           0.17860714
Policy log std Max           -0.3476653
Policy log std Min           -1.8470552
Z mean eval                  1.1962261
Z variance eval              0.06054887
total_rewards                [  82.26423032 1309.16388056  317.73582345  851.77105252   79.95898993
   54.53783655 1389.97053456  619.80516263  126.68389638  335.21863326]
total_rewards_mean           516.7110040165732
total_rewards_std            482.82600555471
total_rewards_max            1389.9705345620068
total_rewards_min            54.537836551410905
Number of train steps total  372000
Number of env steps total    302842
Number of rollouts total     0
Train Time (s)               148.81009068526328
(Previous) Eval Time (s)     11.083523836918175
Sample Time (s)              11.630320203490555
Epoch Time (s)               171.523934725672
Total Train Time (s)         16771.517793381587
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:35:24.002767 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #92 | Epoch Duration: 171.63082242012024
2020-01-12 06:35:24.002964 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1923995
Z variance train             0.061139643
KL Divergence                24.204062
KL Loss                      2.420406
QF Loss                      793.83716
VF Loss                      143.4344
Policy Loss                  -680.03235
Q Predictions Mean           670.54553
Q Predictions Std            254.89995
Q Predictions Max            1023.2843
Q Predictions Min            42.877514
V Predictions Mean           682.17596
V Predictions Std            243.05876
V Predictions Max            1018.6321
V Predictions Min            241.73999
Log Pis Mean                 -1.1684391
Log Pis Std                  3.073365
Log Pis Max                  15.493124
Log Pis Min                  -8.933916
Policy mu Mean               -0.0071155652
Policy mu Std                0.51564217
Policy mu Max                2.508322
Policy mu Min                -3.050954
Policy log std Mean          -0.92680794
Policy log std Std           0.18978256
Policy log std Max           -0.35319665
Policy log std Min           -1.978929
Z mean eval                  1.1856841
Z variance eval              0.66064906
total_rewards                [1305.40073055 1454.08526646 2569.01860624  207.30556809  462.71122242
 1583.21427801  580.10251423  832.15842825  296.61974191   72.36353761]
total_rewards_mean           936.2979893766117
total_rewards_std            744.1520968970583
total_rewards_max            2569.018606240665
total_rewards_min            72.36353760956361
Number of train steps total  376000
Number of env steps total    305346
Number of rollouts total     0
Train Time (s)               147.6685678982176
(Previous) Eval Time (s)     16.13161423522979
Sample Time (s)              10.760169543325901
Epoch Time (s)               174.56035167677328
Total Train Time (s)         16946.181398151442
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:38:18.668136 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #93 | Epoch Duration: 174.6650218963623
2020-01-12 06:38:18.668349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1699241
Z variance train             0.6536137
KL Divergence                20.405287
KL Loss                      2.0405288
QF Loss                      599.34326
VF Loss                      308.26935
Policy Loss                  -656.7255
Q Predictions Mean           652.09814
Q Predictions Std            255.32324
Q Predictions Max            989.92914
Q Predictions Min            64.57406
V Predictions Mean           658.47046
V Predictions Std            251.41638
V Predictions Max            987.9746
V Predictions Min            205.36296
Log Pis Mean                 -1.1932873
Log Pis Std                  2.9063413
Log Pis Max                  17.512894
Log Pis Min                  -8.273182
Policy mu Mean               0.034382455
Policy mu Std                0.5053118
Policy mu Max                3.9122071
Policy mu Min                -2.3325608
Policy log std Mean          -0.9514301
Policy log std Std           0.18332513
Policy log std Max           -0.2784801
Policy log std Min           -1.6057897
Z mean eval                  1.2639997
Z variance eval              0.015404969
total_rewards                [ 117.92201174  213.37886947 1281.94851929 2533.23189612 2590.39565797
  637.11346277  819.28874589 1305.0682978  2559.87984992  677.35906202]
total_rewards_mean           1273.5586372987761
total_rewards_std            916.6720595335402
total_rewards_max            2590.3956579671535
total_rewards_min            117.92201174418865
Number of train steps total  380000
Number of env steps total    308136
Number of rollouts total     0
Train Time (s)               147.5582202631049
(Previous) Eval Time (s)     24.68548820959404
Sample Time (s)              13.580032332800329
Epoch Time (s)               185.82374080549926
Total Train Time (s)         17132.095563327894
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:41:24.583962 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #94 | Epoch Duration: 185.91547060012817
2020-01-12 06:41:24.584143 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2667053
Z variance train             0.015330279
KL Divergence                25.928364
KL Loss                      2.5928364
QF Loss                      482.98724
VF Loss                      148.91621
Policy Loss                  -676.2685
Q Predictions Mean           669.2849
Q Predictions Std            255.9257
Q Predictions Max            1014.3653
Q Predictions Min            254.02249
V Predictions Mean           676.052
V Predictions Std            252.08888
V Predictions Max            1012.9043
V Predictions Min            233.3552
Log Pis Mean                 -1.2221296
Log Pis Std                  3.009971
Log Pis Max                  12.776218
Log Pis Min                  -9.707181
Policy mu Mean               -0.00927273
Policy mu Std                0.50666004
Policy mu Max                2.2866228
Policy mu Min                -2.6629224
Policy log std Mean          -0.9240497
Policy log std Std           0.18291092
Policy log std Max           -0.45637557
Policy log std Min           -1.6958327
Z mean eval                  1.2163854
Z variance eval              0.007557492
total_rewards                [1050.94330785  268.93927521 1563.87160619 1288.78499957 2042.08875265
  934.52627551 2638.86803586  143.02015271  476.54981432 2198.27699376]
total_rewards_mean           1260.586921364122
total_rewards_std            804.9685743938104
total_rewards_max            2638.86803586365
total_rewards_min            143.0201527135088
Number of train steps total  384000
Number of env steps total    311510
Number of rollouts total     0
Train Time (s)               141.61789701879025
(Previous) Eval Time (s)     21.93826209101826
Sample Time (s)              12.18146083317697
Epoch Time (s)               175.73761994298548
Total Train Time (s)         17307.92288214527
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:44:20.413704 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #95 | Epoch Duration: 175.82940196990967
2020-01-12 06:44:20.413947 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2197584
Z variance train             0.007523513
KL Divergence                26.727045
KL Loss                      2.6727045
QF Loss                      628.37933
VF Loss                      87.51657
Policy Loss                  -685.7674
Q Predictions Mean           676.74426
Q Predictions Std            252.86653
Q Predictions Max            1008.7613
Q Predictions Min            189.94412
V Predictions Mean           685.68677
V Predictions Std            247.12605
V Predictions Max            999.0443
V Predictions Min            282.09518
Log Pis Mean                 -1.0783896
Log Pis Std                  3.075821
Log Pis Max                  17.265766
Log Pis Min                  -9.898644
Policy mu Mean               0.003993692
Policy mu Std                0.5106444
Policy mu Max                3.1673808
Policy mu Min                -2.7711024
Policy log std Mean          -0.9252516
Policy log std Std           0.1791585
Policy log std Max           -0.43254465
Policy log std Min           -1.7615234
Z mean eval                  1.2026384
Z variance eval              0.02261879
total_rewards                [1305.55969977  986.18730301 1224.23241503 2191.05388767 1841.32470723
  832.05920341 1137.46163424 2476.69191388  831.18150632  218.465129  ]
total_rewards_mean           1304.4217399556164
total_rewards_std            648.8885593361658
total_rewards_max            2476.6919138755256
total_rewards_min            218.46512900141266
Number of train steps total  388000
Number of env steps total    314075
Number of rollouts total     0
Train Time (s)               140.31122437305748
(Previous) Eval Time (s)     24.55841604201123
Sample Time (s)              11.958357217721641
Epoch Time (s)               176.82799763279036
Total Train Time (s)         17484.840908899903
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:47:17.333324 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #96 | Epoch Duration: 176.9192087650299
2020-01-12 06:47:17.333578 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2015945
Z variance train             0.022426423
KL Divergence                23.823906
KL Loss                      2.3823907
QF Loss                      849.0974
VF Loss                      205.34795
Policy Loss                  -693.9183
Q Predictions Mean           682.7672
Q Predictions Std            259.47363
Q Predictions Max            1011.147
Q Predictions Min            -73.90362
V Predictions Mean           699.18945
V Predictions Std            246.30801
V Predictions Max            1011.4557
V Predictions Min            289.51468
Log Pis Mean                 -0.72654843
Log Pis Std                  3.6097398
Log Pis Max                  25.196428
Log Pis Min                  -7.1322474
Policy mu Mean               0.014805223
Policy mu Std                0.564737
Policy mu Max                4.1665077
Policy mu Min                -3.3849964
Policy log std Mean          -0.93727773
Policy log std Std           0.19471763
Policy log std Max           -0.34526062
Policy log std Min           -2.109959
Z mean eval                  1.1619077
Z variance eval              0.01427076
total_rewards                [1695.5513457   301.10650968 2673.46396385 1865.9269206  1964.61775986
 2772.84679337   17.34147245  310.98650661  351.77950332  152.9863408 ]
total_rewards_mean           1210.660711624517
total_rewards_std            1035.8681385038144
total_rewards_max            2772.846793374126
total_rewards_min            17.341472451308487
Number of train steps total  392000
Number of env steps total    316511
Number of rollouts total     0
Train Time (s)               142.17509068688378
(Previous) Eval Time (s)     20.892190949991345
Sample Time (s)              9.945095363538712
Epoch Time (s)               173.01237700041384
Total Train Time (s)         17657.96375869913
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:50:10.459404 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #97 | Epoch Duration: 173.12564325332642
2020-01-12 06:50:10.459665 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1656531
Z variance train             0.014277269
KL Divergence                25.955269
KL Loss                      2.595527
QF Loss                      694.4749
VF Loss                      135.01128
Policy Loss                  -683.8685
Q Predictions Mean           673.76
Q Predictions Std            261.34576
Q Predictions Max            1005.11066
Q Predictions Min            -58.52443
V Predictions Mean           682.062
V Predictions Std            254.21156
V Predictions Max            992.56683
V Predictions Min            83.3444
Log Pis Mean                 -0.898636
Log Pis Std                  2.9396951
Log Pis Max                  11.287434
Log Pis Min                  -9.723343
Policy mu Mean               -0.01987862
Policy mu Std                0.52384436
Policy mu Max                2.313381
Policy mu Min                -3.0903382
Policy log std Mean          -0.9422256
Policy log std Std           0.19293942
Policy log std Max           -0.3795081
Policy log std Min           -1.6927099
Z mean eval                  1.1643229
Z variance eval              0.013449127
total_rewards                [ 707.71298854  698.37630926 2648.2265651  1815.61393777 2292.12518808
  101.1887771  1041.50128668 1288.98289048 1669.90650436  430.40093164]
total_rewards_mean           1269.4035379008978
total_rewards_std            785.3918256561865
total_rewards_max            2648.2265651021594
total_rewards_min            101.18877709818337
Number of train steps total  396000
Number of env steps total    319086
Number of rollouts total     0
Train Time (s)               150.70688715716824
(Previous) Eval Time (s)     22.773365651722997
Sample Time (s)              12.588260620366782
Epoch Time (s)               186.06851342925802
Total Train Time (s)         17844.13222554326
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:53:16.629864 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #98 | Epoch Duration: 186.16997814178467
2020-01-12 06:53:16.630207 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1670195
Z variance train             0.013423249
KL Divergence                26.004799
KL Loss                      2.6004798
QF Loss                      450.21045
VF Loss                      165.82974
Policy Loss                  -709.1284
Q Predictions Mean           699.3596
Q Predictions Std            254.808
Q Predictions Max            1013.0004
Q Predictions Min            -73.04902
V Predictions Mean           711.374
V Predictions Std            245.94002
V Predictions Max            1003.19324
V Predictions Min            162.15494
Log Pis Mean                 -1.0176861
Log Pis Std                  3.0025523
Log Pis Max                  17.737122
Log Pis Min                  -8.505827
Policy mu Mean               -0.0030320135
Policy mu Std                0.53570646
Policy mu Max                3.180166
Policy mu Min                -3.0630846
Policy log std Mean          -0.94528776
Policy log std Std           0.18845743
Policy log std Max           -0.36966443
Policy log std Min           -1.7112688
Z mean eval                  1.4045141
Z variance eval              0.7563896
total_rewards                [2646.18319344  142.24564608  700.35381948 2522.07861034 1738.69496897
 1686.0092828  2609.94543116 2652.17711404 2360.08540198  411.92476798]
total_rewards_mean           1746.9698236266318
total_rewards_std            938.4077404558742
total_rewards_max            2652.1771140438013
total_rewards_min            142.2456460750306
Number of train steps total  400000
Number of env steps total    323170
Number of rollouts total     0
Train Time (s)               149.08501272182912
(Previous) Eval Time (s)     32.34722223691642
Sample Time (s)              13.263445565011352
Epoch Time (s)               194.6956805237569
Total Train Time (s)         18038.915907923132
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:56:31.415334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #99 | Epoch Duration: 194.78494143486023
2020-01-12 06:56:31.415521 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4059044
Z variance train             0.76517904
KL Divergence                22.504662
KL Loss                      2.250466
QF Loss                      849.4148
VF Loss                      270.9757
Policy Loss                  -630.32367
Q Predictions Mean           619.81604
Q Predictions Std            229.34232
Q Predictions Max            945.61224
Q Predictions Min            226.46065
V Predictions Mean           637.35425
V Predictions Std            227.43494
V Predictions Max            947.25476
V Predictions Min            243.71887
Log Pis Mean                 -0.8751
Log Pis Std                  3.2434585
Log Pis Max                  14.252442
Log Pis Min                  -8.381999
Policy mu Mean               0.026237804
Policy mu Std                0.5397209
Policy mu Max                3.7250288
Policy mu Min                -2.8840988
Policy log std Mean          -0.936098
Policy log std Std           0.19527143
Policy log std Max           -0.3714035
Policy log std Min           -1.824247
Z mean eval                  1.1881845
Z variance eval              0.026068568
total_rewards                [1739.18802385 1499.60852218 1538.61808211 1338.99531122 1406.79531699
  824.67391204 2521.11097736 1673.50479907 2117.99836945  163.19356973]
total_rewards_mean           1482.3686883993162
total_rewards_std            615.4684148401653
total_rewards_max            2521.110977363279
total_rewards_min            163.19356972896855
Number of train steps total  404000
Number of env steps total    325880
Number of rollouts total     0
Train Time (s)               149.10885492898524
(Previous) Eval Time (s)     31.579057666938752
Sample Time (s)              12.684067995287478
Epoch Time (s)               193.37198059121147
Total Train Time (s)         18232.381225489546
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:59:44.882721 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #100 | Epoch Duration: 193.46707105636597
2020-01-12 06:59:44.882915 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1856425
Z variance train             0.026010718
KL Divergence                23.534014
KL Loss                      2.3534014
QF Loss                      1212.2544
VF Loss                      160.64812
Policy Loss                  -697.7452
Q Predictions Mean           686.6853
Q Predictions Std            262.9664
Q Predictions Max            1027.658
Q Predictions Min            -12.898292
V Predictions Mean           703.06165
V Predictions Std            252.9054
V Predictions Max            1028.903
V Predictions Min            203.22842
Log Pis Mean                 -0.762094
Log Pis Std                  2.985682
Log Pis Max                  19.212181
Log Pis Min                  -6.462441
Policy mu Mean               -0.00056344504
Policy mu Std                0.53550655
Policy mu Max                2.629422
Policy mu Min                -3.173739
Policy log std Mean          -0.94255036
Policy log std Std           0.18340257
Policy log std Max           -0.42639345
Policy log std Min           -1.654099
Z mean eval                  1.1828663
Z variance eval              0.018161625
total_rewards                [ 179.74253211   75.55053992  742.17762579  396.37624377  937.09955318
  609.14761337 1001.94595705  636.2775699   491.3845811  2891.1363014 ]
total_rewards_mean           796.0838517604019
total_rewards_std            752.7649819520079
total_rewards_max            2891.1363014015033
total_rewards_min            75.55053992104845
Number of train steps total  408000
Number of env steps total    328573
Number of rollouts total     0
Train Time (s)               147.46990070398897
(Previous) Eval Time (s)     13.275358238257468
Sample Time (s)              12.115352084860206
Epoch Time (s)               172.86061102710664
Total Train Time (s)         18405.3396295188
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:02:37.843956 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #101 | Epoch Duration: 172.96087384223938
2020-01-12 07:02:37.844269 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.19462
Z variance train             0.017929439
KL Divergence                24.075367
KL Loss                      2.4075367
QF Loss                      404.22012
VF Loss                      122.19728
Policy Loss                  -716.20056
Q Predictions Mean           709.41846
Q Predictions Std            256.3584
Q Predictions Max            1025.7234
Q Predictions Min            -4.6772227
V Predictions Mean           713.36383
V Predictions Std            249.3921
V Predictions Max            999.1626
V Predictions Min            -20.465141
Log Pis Mean                 -0.94734436
Log Pis Std                  3.1572886
Log Pis Max                  18.045141
Log Pis Min                  -7.6790385
Policy mu Mean               0.00813631
Policy mu Std                0.5317549
Policy mu Max                3.5621057
Policy mu Min                -2.5343897
Policy log std Mean          -0.9434482
Policy log std Std           0.19731906
Policy log std Max           0.10577309
Policy log std Min           -1.8038874
Z mean eval                  1.2310461
Z variance eval              0.028850514
total_rewards                [ 866.08485432 1322.22265271  486.81168046  488.37276099 2636.51834946
  583.30263114  149.08703194 1870.39273733  148.82090766 1457.95519965]
total_rewards_mean           1000.9568805655703
total_rewards_std            769.0624451126928
total_rewards_max            2636.51834946131
total_rewards_min            148.82090766238616
Number of train steps total  412000
Number of env steps total    330969
Number of rollouts total     0
Train Time (s)               141.5538318771869
(Previous) Eval Time (s)     15.580198287963867
Sample Time (s)              11.846151850186288
Epoch Time (s)               168.98018201533705
Total Train Time (s)         18574.416989658028
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:05:26.923493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #102 | Epoch Duration: 169.07904624938965
2020-01-12 07:05:26.923756 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.23227
Z variance train             0.028811509
KL Divergence                23.010277
KL Loss                      2.3010278
QF Loss                      496.72375
VF Loss                      102.21991
Policy Loss                  -707.7411
Q Predictions Mean           697.45544
Q Predictions Std            269.3069
Q Predictions Max            1066.7131
Q Predictions Min            -22.761993
V Predictions Mean           704.23
V Predictions Std            263.23495
V Predictions Max            1046.2473
V Predictions Min            -10.073982
Log Pis Mean                 -0.7619128
Log Pis Std                  3.1796958
Log Pis Max                  16.480515
Log Pis Min                  -7.670928
Policy mu Mean               -0.01928762
Policy mu Std                0.5488704
Policy mu Max                3.0578592
Policy mu Min                -2.6635995
Policy log std Mean          -0.95350075
Policy log std Std           0.19010301
Policy log std Max           -0.18445164
Policy log std Min           -1.75857
Z mean eval                  1.1893642
Z variance eval              0.02558664
total_rewards                [ 699.96143016   44.00636564  772.7121605  1161.52560368 2397.23021424
  358.95975036   68.75547497  110.87883732 1021.48562547 2142.8997528 ]
total_rewards_mean           877.8415215154934
total_rewards_std            791.207272078459
total_rewards_max            2397.230214236981
total_rewards_min            44.00636564050856
Number of train steps total  416000
Number of env steps total    333724
Number of rollouts total     0
Train Time (s)               139.7117033773102
(Previous) Eval Time (s)     15.013571675401181
Sample Time (s)              11.393602922558784
Epoch Time (s)               166.11887797527015
Total Train Time (s)         18740.644320558757
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:08:13.152305 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #103 | Epoch Duration: 166.22837257385254
2020-01-12 07:08:13.152493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1844479
Z variance train             0.025486344
KL Divergence                23.21185
KL Loss                      2.3211849
QF Loss                      554.6378
VF Loss                      83.84252
Policy Loss                  -690.8
Q Predictions Mean           684.0313
Q Predictions Std            264.1507
Q Predictions Max            1027.625
Q Predictions Min            114.46675
V Predictions Mean           693.5632
V Predictions Std            258.5362
V Predictions Max            1030.8623
V Predictions Min            236.52548
Log Pis Mean                 -0.96016747
Log Pis Std                  2.908558
Log Pis Max                  16.182533
Log Pis Min                  -8.2673645
Policy mu Mean               0.019711828
Policy mu Std                0.50842047
Policy mu Max                2.3523364
Policy mu Min                -3.240733
Policy log std Mean          -0.93622696
Policy log std Std           0.18774635
Policy log std Max           -0.41915312
Policy log std Min           -1.7480972
Z mean eval                  1.18499
Z variance eval              0.083912276
total_rewards                [1620.34392375  913.25137752 1764.26746312 2768.93658335 1134.22614906
 1297.88192845 1210.14348907 1035.71241272 2742.29094692 1524.84560851]
total_rewards_mean           1601.1899882453488
total_rewards_std            628.8502126855664
total_rewards_max            2768.936583345872
total_rewards_min            913.2513775188597
Number of train steps total  420000
Number of env steps total    337492
Number of rollouts total     0
Train Time (s)               141.91873142682016
(Previous) Eval Time (s)     27.952119497116655
Sample Time (s)              11.67117317719385
Epoch Time (s)               181.54202410113066
Total Train Time (s)         18922.277907255106
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:11:14.788355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #104 | Epoch Duration: 181.63570189476013
2020-01-12 07:11:14.788598 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1780264
Z variance train             0.082795724
KL Divergence                21.746748
KL Loss                      2.1746747
QF Loss                      648.4034
VF Loss                      148.46786
Policy Loss                  -704.0943
Q Predictions Mean           696.82324
Q Predictions Std            252.92471
Q Predictions Max            1038.6277
Q Predictions Min            -21.728788
V Predictions Mean           703.7053
V Predictions Std            247.66217
V Predictions Max            1040.9454
V Predictions Min            97.25739
Log Pis Mean                 -0.81949806
Log Pis Std                  3.261674
Log Pis Max                  23.688099
Log Pis Min                  -9.882176
Policy mu Mean               0.015001046
Policy mu Std                0.51556414
Policy mu Max                5.049064
Policy mu Min                -3.5040257
Policy log std Mean          -0.9562771
Policy log std Std           0.1913668
Policy log std Max           -0.2645886
Policy log std Min           -2.0391693
Z mean eval                  1.1786091
Z variance eval              0.022414032
total_rewards                [1988.2803805   538.36707929  718.8180298  2816.95266399 1068.93982935
 2590.17466603 1307.9277752   394.64576308  967.54454623 1908.24756483]
total_rewards_mean           1429.9898298311496
total_rewards_std            808.821317776031
total_rewards_max            2816.952663993755
total_rewards_min            394.645763082915
Number of train steps total  424000
Number of env steps total    340066
Number of rollouts total     0
Train Time (s)               150.5902577857487
(Previous) Eval Time (s)     26.686062366236
Sample Time (s)              11.314607525244355
Epoch Time (s)               188.59092767722905
Total Train Time (s)         19110.95905977767
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:14:23.470962 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #105 | Epoch Duration: 188.68220710754395
2020-01-12 07:14:23.471150 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1784738
Z variance train             0.022320902
KL Divergence                23.409782
KL Loss                      2.3409784
QF Loss                      565.25757
VF Loss                      103.27989
Policy Loss                  -697.07935
Q Predictions Mean           682.8908
Q Predictions Std            271.25946
Q Predictions Max            1040.8523
Q Predictions Min            78.36752
V Predictions Mean           698.29974
V Predictions Std            260.05048
V Predictions Max            1033.4651
V Predictions Min            231.62895
Log Pis Mean                 -0.74852633
Log Pis Std                  3.022689
Log Pis Max                  11.06682
Log Pis Min                  -6.774143
Policy mu Mean               0.0034270268
Policy mu Std                0.51976687
Policy mu Max                2.9239204
Policy mu Min                -2.6387255
Policy log std Mean          -0.95389056
Policy log std Std           0.18480453
Policy log std Max           -0.45996222
Policy log std Min           -1.638652
Z mean eval                  1.2020425
Z variance eval              0.029679656
total_rewards                [1757.56040281 2783.85429889  215.87649426 1364.15548138 1664.51719555
  741.96340853 1411.71769521 1368.93896142 1707.08015757  497.98361834]
total_rewards_mean           1351.3647713965124
total_rewards_std            695.3198533660773
total_rewards_max            2783.8542988867607
total_rewards_min            215.8764942636296
Number of train steps total  428000
Number of env steps total    343301
Number of rollouts total     0
Train Time (s)               150.3141428050585
(Previous) Eval Time (s)     32.811168246902525
Sample Time (s)              13.647091919090599
Epoch Time (s)               196.77240297105163
Total Train Time (s)         19307.833082031924
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:17:40.347268 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #106 | Epoch Duration: 196.87591886520386
2020-01-12 07:17:40.347472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.199724
Z variance train             0.029697295
KL Divergence                21.876318
KL Loss                      2.1876318
QF Loss                      1238.4348
VF Loss                      173.95712
Policy Loss                  -721.0546
Q Predictions Mean           711.021
Q Predictions Std            266.23642
Q Predictions Max            1029.3474
Q Predictions Min            179.40784
V Predictions Mean           724.3807
V Predictions Std            259.8167
V Predictions Max            1036.0559
V Predictions Min            197.77713
Log Pis Mean                 -0.80532527
Log Pis Std                  2.812141
Log Pis Max                  12.935959
Log Pis Min                  -7.327595
Policy mu Mean               -0.008082256
Policy mu Std                0.50991833
Policy mu Max                2.2702177
Policy mu Min                -2.869358
Policy log std Mean          -0.9676838
Policy log std Std           0.20965084
Policy log std Max           -0.23798883
Policy log std Min           -1.957107
Z mean eval                  1.2084926
Z variance eval              0.025618225
total_rewards                [ 604.72479335 2058.26777815  418.76534205  700.83225247  604.29359482
  369.09026674  947.94129621 2728.93425982 2782.6969662   871.99971553]
total_rewards_mean           1208.7546265349836
total_rewards_std            894.9117435378826
total_rewards_max            2782.6969662022475
total_rewards_min            369.0902667408525
Number of train steps total  432000
Number of env steps total    345862
Number of rollouts total     0
Train Time (s)               148.13354269461706
(Previous) Eval Time (s)     31.29202124942094
Sample Time (s)              11.97624830249697
Epoch Time (s)               191.40181224653497
Total Train Time (s)         19499.333084776532
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:20:51.849270 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #107 | Epoch Duration: 191.50163388252258
2020-01-12 07:20:51.849504 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1997672
Z variance train             0.025811207
KL Divergence                22.271435
KL Loss                      2.2271435
QF Loss                      569.19543
VF Loss                      111.519325
Policy Loss                  -731.47705
Q Predictions Mean           727.2247
Q Predictions Std            264.1154
Q Predictions Max            1034.2383
Q Predictions Min            -55.06044
V Predictions Mean           736.81836
V Predictions Std            261.37872
V Predictions Max            1032.6869
V Predictions Min            -15.613311
Log Pis Mean                 -0.9156616
Log Pis Std                  2.7314281
Log Pis Max                  7.623104
Log Pis Min                  -8.147697
Policy mu Mean               -0.008053245
Policy mu Std                0.49055606
Policy mu Max                2.3917818
Policy mu Min                -1.8552834
Policy log std Mean          -0.96677274
Policy log std Std           0.19318603
Policy log std Max           -0.37119138
Policy log std Min           -1.7349277
Z mean eval                  1.1291425
Z variance eval              0.023874087
total_rewards                [ 431.37604721  746.23988679  315.90296976 2512.41642014  294.91640843
 1267.00836626 1528.12656387  346.1537417   435.06572812  441.98414168]
total_rewards_mean           831.9190273983606
total_rewards_std            690.3628612052871
total_rewards_max            2512.416420143054
total_rewards_min            294.9164084303184
Number of train steps total  436000
Number of env steps total    349701
Number of rollouts total     0
Train Time (s)               147.4319291007705
(Previous) Eval Time (s)     15.101437343750149
Sample Time (s)              13.926837523467839
Epoch Time (s)               176.4602039679885
Total Train Time (s)         19675.894028866664
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:23:48.414811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #108 | Epoch Duration: 176.56512117385864
2020-01-12 07:23:48.415119 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1241577
Z variance train             0.024169818
KL Divergence                23.132668
KL Loss                      2.3132668
QF Loss                      582.4058
VF Loss                      195.00264
Policy Loss                  -740.38464
Q Predictions Mean           725.5387
Q Predictions Std            268.5148
Q Predictions Max            1046.2181
Q Predictions Min            -113.166916
V Predictions Mean           733.79144
V Predictions Std            256.28745
V Predictions Max            1041.3759
V Predictions Min            -5.196641
Log Pis Mean                 -0.9112082
Log Pis Std                  3.1255755
Log Pis Max                  19.892836
Log Pis Min                  -9.354276
Policy mu Mean               0.0077122394
Policy mu Std                0.54291236
Policy mu Max                2.6458502
Policy mu Min                -3.0237277
Policy log std Mean          -0.9327481
Policy log std Std           0.18000269
Policy log std Max           -0.39342538
Policy log std Min           -1.7541506
Z mean eval                  1.2241414
Z variance eval              0.052397262
total_rewards                [ 814.82419841 1716.79264967 2443.61519419 2722.25373905 2889.05210913
  413.72768934  667.25414145  930.61013963 1018.2765354  1924.33729141]
total_rewards_mean           1554.0743687685808
total_rewards_std            860.8589781048922
total_rewards_max            2889.0521091344017
total_rewards_min            413.72768933798375
Number of train steps total  440000
Number of env steps total    352737
Number of rollouts total     0
Train Time (s)               140.17942601582035
(Previous) Eval Time (s)     30.96659741969779
Sample Time (s)              12.796581287868321
Epoch Time (s)               183.94260472338647
Total Train Time (s)         19859.923370459583
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:26:52.444625 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #109 | Epoch Duration: 184.02926182746887
2020-01-12 07:26:52.444808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2192131
Z variance train             0.051845025
KL Divergence                22.955036
KL Loss                      2.2955036
QF Loss                      528.5102
VF Loss                      127.622406
Policy Loss                  -739.5193
Q Predictions Mean           726.5459
Q Predictions Std            263.00082
Q Predictions Max            1021.0811
Q Predictions Min            63.73113
V Predictions Mean           735.48267
V Predictions Std            256.10358
V Predictions Max            1017.3048
V Predictions Min            87.656044
Log Pis Mean                 -0.5615777
Log Pis Std                  3.1787753
Log Pis Max                  18.178495
Log Pis Min                  -7.153151
Policy mu Mean               -0.028303921
Policy mu Std                0.54824406
Policy mu Max                2.9601283
Policy mu Min                -3.538616
Policy log std Mean          -0.988547
Policy log std Std           0.19629581
Policy log std Max           -0.51228535
Policy log std Min           -1.7078714
Z mean eval                  1.2440431
Z variance eval              0.045507304
total_rewards                [1659.07219587 2032.22854269  742.02070801  483.98322179 1810.62914891
  599.3035962   623.44857032 1222.15021258  806.16195165   75.0942532 ]
total_rewards_mean           1005.4092401211013
total_rewards_std            611.0849945855352
total_rewards_max            2032.2285426854235
total_rewards_min            75.09425320337905
Number of train steps total  444000
Number of env steps total    355581
Number of rollouts total     0
Train Time (s)               140.5376154370606
(Previous) Eval Time (s)     19.66283907974139
Sample Time (s)              12.424919695593417
Epoch Time (s)               172.6253742123954
Total Train Time (s)         20032.64284069417
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:29:45.166216 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #110 | Epoch Duration: 172.72127079963684
2020-01-12 07:29:45.166405 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2466434
Z variance train             0.045709614
KL Divergence                21.269304
KL Loss                      2.1269305
QF Loss                      401.81458
VF Loss                      110.24299
Policy Loss                  -747.3299
Q Predictions Mean           740.8229
Q Predictions Std            281.55185
Q Predictions Max            1112.6361
Q Predictions Min            -15.266952
V Predictions Mean           741.6024
V Predictions Std            275.73114
V Predictions Max            1098.8588
V Predictions Min            121.95724
Log Pis Mean                 -1.0608926
Log Pis Std                  2.741603
Log Pis Max                  9.648836
Log Pis Min                  -7.808818
Policy mu Mean               -0.013530593
Policy mu Std                0.49788705
Policy mu Max                2.572291
Policy mu Min                -3.4500067
Policy log std Mean          -0.94055367
Policy log std Std           0.17808428
Policy log std Max           -0.3917677
Policy log std Min           -2.1718655
Z mean eval                  1.1692455
Z variance eval              0.025938269
total_rewards                [ 641.09699224  338.79711868 1679.077023    926.3753358  1400.13077359
  112.44538511 1349.14142464 2948.14575942 2071.59581747 1134.2516779 ]
total_rewards_mean           1260.1057307844162
total_rewards_std            799.2113284663274
total_rewards_max            2948.1457594208987
total_rewards_min            112.44538510962633
Number of train steps total  448000
Number of env steps total    358130
Number of rollouts total     0
Train Time (s)               144.39525908092037
(Previous) Eval Time (s)     17.537349462974817
Sample Time (s)              12.113536758348346
Epoch Time (s)               174.04614530224353
Total Train Time (s)         20206.79023698205
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:32:39.315862 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #111 | Epoch Duration: 174.14930272102356
2020-01-12 07:32:39.316091 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1713603
Z variance train             0.026357811
KL Divergence                22.780106
KL Loss                      2.2780106
QF Loss                      674.5043
VF Loss                      177.05167
Policy Loss                  -738.8785
Q Predictions Mean           731.32385
Q Predictions Std            276.6838
Q Predictions Max            1083.653
Q Predictions Min            -23.981901
V Predictions Mean           738.595
V Predictions Std            269.33728
V Predictions Max            1083.604
V Predictions Min            -19.899296
Log Pis Mean                 -0.5094827
Log Pis Std                  3.6475441
Log Pis Max                  24.362461
Log Pis Min                  -7.780703
Policy mu Mean               -0.013209449
Policy mu Std                0.56307507
Policy mu Max                3.904347
Policy mu Min                -4.251239
Policy log std Mean          -0.9683077
Policy log std Std           0.20060329
Policy log std Max           -0.48378557
Policy log std Min           -2.0558243
Z mean eval                  1.2568767
Z variance eval              0.016016085
total_rewards                [1266.08942578 2650.61022634 2721.69243857 1003.08342342 2557.10958569
 2548.27562806 2579.51586597 2978.45007467 2675.75840588 2835.85057419]
total_rewards_mean           2381.643564857847
total_rewards_std            638.7142534796212
total_rewards_max            2978.4500746741733
total_rewards_min            1003.0834234170475
Number of train steps total  452000
Number of env steps total    360747
Number of rollouts total     0
Train Time (s)               150.8552286918275
(Previous) Eval Time (s)     33.77392952190712
Sample Time (s)              12.07982274191454
Epoch Time (s)               196.70898095564917
Total Train Time (s)         20403.597408267204
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:35:56.125780 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #112 | Epoch Duration: 196.80953741073608
2020-01-12 07:35:56.126003 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2609813
Z variance train             0.016032819
KL Divergence                23.336248
KL Loss                      2.3336248
QF Loss                      617.11035
VF Loss                      172.41931
Policy Loss                  -728.08344
Q Predictions Mean           721.6946
Q Predictions Std            291.4688
Q Predictions Max            1071.8235
Q Predictions Min            -9.420805
V Predictions Mean           725.3163
V Predictions Std            287.82007
V Predictions Max            1056.8982
V Predictions Min            -22.516733
Log Pis Mean                 -0.6551963
Log Pis Std                  3.7298946
Log Pis Max                  35.090363
Log Pis Min                  -7.094599
Policy mu Mean               -0.004371766
Policy mu Std                0.57500744
Policy mu Max                3.2538865
Policy mu Min                -3.6857424
Policy log std Mean          -0.93919975
Policy log std Std           0.1999095
Policy log std Max           -0.42103627
Policy log std Min           -1.7413638
Z mean eval                  1.1868583
Z variance eval              0.018665303
total_rewards                [ 841.83563121 1707.74573728 2686.1984459    52.61663347  432.68513385
 2757.5790415  2869.7420662  1448.16300349 1199.69763602 2646.38978557]
total_rewards_mean           1664.2653114502457
total_rewards_std            985.5166455487896
total_rewards_max            2869.742066198073
total_rewards_min            52.61663347437205
Number of train steps total  456000
Number of env steps total    363366
Number of rollouts total     0
Train Time (s)               149.59832997899503
(Previous) Eval Time (s)     22.316159031819552
Sample Time (s)              11.465562609490007
Epoch Time (s)               183.38005162030458
Total Train Time (s)         20587.0748666008
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:38:59.605036 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #113 | Epoch Duration: 183.47888255119324
2020-01-12 07:38:59.605234 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1869998
Z variance train             0.018682227
KL Divergence                22.537476
KL Loss                      2.2537477
QF Loss                      535.88684
VF Loss                      88.85633
Policy Loss                  -712.68256
Q Predictions Mean           707.191
Q Predictions Std            279.67505
Q Predictions Max            1061.3085
Q Predictions Min            3.0145183
V Predictions Mean           715.9048
V Predictions Std            275.30353
V Predictions Max            1063.4574
V Predictions Min            151.8456
Log Pis Mean                 -1.0065362
Log Pis Std                  2.7486317
Log Pis Max                  12.23478
Log Pis Min                  -8.1629505
Policy mu Mean               -0.004092385
Policy mu Std                0.50975114
Policy mu Max                3.441691
Policy mu Min                -3.70509
Policy log std Mean          -0.93502307
Policy log std Std           0.18522097
Policy log std Max           -0.15008134
Policy log std Min           -1.6152222
Z mean eval                  1.1983097
Z variance eval              0.01760152
total_rewards                [1070.03579321  956.1676483  1325.1268431   902.56143262 1744.26296185
  799.35891707 1335.09772057 1822.47055222  336.61283456 3011.21583242]
total_rewards_mean           1330.291053591733
total_rewards_std            699.9364523348146
total_rewards_max            3011.215832423239
total_rewards_min            336.61283456105014
Number of train steps total  460000
Number of env steps total    366670
Number of rollouts total     0
Train Time (s)               150.3957328191027
(Previous) Eval Time (s)     24.45816924981773
Sample Time (s)              11.531442787498236
Epoch Time (s)               186.38534485641867
Total Train Time (s)         20773.56439588964
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:42:06.097817 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #114 | Epoch Duration: 186.49240612983704
2020-01-12 07:42:06.098133 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1981562
Z variance train             0.017667264
KL Divergence                23.490536
KL Loss                      2.3490536
QF Loss                      653.845
VF Loss                      159.14651
Policy Loss                  -751.23615
Q Predictions Mean           743.2565
Q Predictions Std            284.1407
Q Predictions Max            1084.7335
Q Predictions Min            19.607851
V Predictions Mean           755.3655
V Predictions Std            273.8338
V Predictions Max            1086.0898
V Predictions Min            131.29306
Log Pis Mean                 -0.56989753
Log Pis Std                  3.6724217
Log Pis Max                  24.759424
Log Pis Min                  -7.742811
Policy mu Mean               -0.0131042
Policy mu Std                0.57632995
Policy mu Max                3.612392
Policy mu Min                -3.511208
Policy log std Mean          -0.9507531
Policy log std Std           0.20208374
Policy log std Max           -0.44472122
Policy log std Min           -1.9679241
Z mean eval                  1.1794614
Z variance eval              0.014909816
total_rewards                [2144.14234745 1399.98755936  362.44880516 1849.15226068  665.31435533
  102.96514499 2852.60688677 2845.75469754  808.70310001 1547.65933001]
total_rewards_mean           1457.873448729582
total_rewards_std            926.9452968857389
total_rewards_max            2852.606886771931
total_rewards_min            102.96514498619877
Number of train steps total  464000
Number of env steps total    369128
Number of rollouts total     0
Train Time (s)               148.93439111905172
(Previous) Eval Time (s)     26.91524377092719
Sample Time (s)              11.679001712240279
Epoch Time (s)               187.5286366022192
Total Train Time (s)         20961.193675473332
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:45:13.730727 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #115 | Epoch Duration: 187.63234901428223
2020-01-12 07:45:13.731309 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1794183
Z variance train             0.0147040505
KL Divergence                23.36792
KL Loss                      2.336792
QF Loss                      991.2019
VF Loss                      135.84424
Policy Loss                  -742.76636
Q Predictions Mean           742.61707
Q Predictions Std            281.03473
Q Predictions Max            1075.4535
Q Predictions Min            249.65416
V Predictions Mean           747.8445
V Predictions Std            279.8377
V Predictions Max            1073.7322
V Predictions Min            251.60597
Log Pis Mean                 -0.8049051
Log Pis Std                  2.7261596
Log Pis Max                  12.328889
Log Pis Min                  -6.4361506
Policy mu Mean               -0.02287642
Policy mu Std                0.50456494
Policy mu Max                2.341614
Policy mu Min                -2.334914
Policy log std Mean          -0.9631993
Policy log std Std           0.19460113
Policy log std Max           -0.5582044
Policy log std Min           -2.1786747
Z mean eval                  1.11424
Z variance eval              0.013523626
total_rewards                [ 299.55317632 1468.40450983 2816.89349309 1325.77768443 2882.56706212
  484.18178376 1510.40171038 2806.85255172 1905.18995851  212.12950832]
total_rewards_mean           1571.19514384775
total_rewards_std            981.3299484273974
total_rewards_max            2882.5670621150684
total_rewards_min            212.12950831618122
Number of train steps total  468000
Number of env steps total    372395
Number of rollouts total     0
Train Time (s)               140.42744745174423
(Previous) Eval Time (s)     22.113817093893886
Sample Time (s)              11.178434839472175
Epoch Time (s)               173.7196993851103
Total Train Time (s)         21135.004313215613
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:48:07.542584 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #116 | Epoch Duration: 173.81096386909485
2020-01-12 07:48:07.542921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1166724
Z variance train             0.01361047
KL Divergence                22.953213
KL Loss                      2.2953212
QF Loss                      825.42706
VF Loss                      213.89532
Policy Loss                  -774.0851
Q Predictions Mean           765.22876
Q Predictions Std            259.1822
Q Predictions Max            1077.4713
Q Predictions Min            6.683446
V Predictions Mean           769.1414
V Predictions Std            252.374
V Predictions Max            1077.9125
V Predictions Min            -19.144754
Log Pis Mean                 -0.38448292
Log Pis Std                  3.0846794
Log Pis Max                  20.605793
Log Pis Min                  -7.63621
Policy mu Mean               -0.029548422
Policy mu Std                0.5650733
Policy mu Max                4.098235
Policy mu Min                -3.1899736
Policy log std Mean          -0.9853367
Policy log std Std           0.20245197
Policy log std Max           0.23256779
Policy log std Min           -1.7879891
Z mean eval                  1.1204503
Z variance eval              0.012819904
total_rewards                [2744.51599694  822.98421779  312.80538656  657.55622102  528.86622948
 2639.90205041  641.7314385  1855.85675547  921.78573565 2844.26373106]
total_rewards_mean           1397.026776287327
total_rewards_std            962.6729097624138
total_rewards_max            2844.263731062358
total_rewards_min            312.8053865564277
Number of train steps total  472000
Number of env steps total    375983
Number of rollouts total     0
Train Time (s)               140.62084043910727
(Previous) Eval Time (s)     24.458904735744
Sample Time (s)              11.831009136978537
Epoch Time (s)               176.9107543118298
Total Train Time (s)         21312.018754696473
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:51:04.557061 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #117 | Epoch Duration: 177.01392483711243
2020-01-12 07:51:04.557189 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1231796
Z variance train             0.012811559
KL Divergence                23.355318
KL Loss                      2.335532
QF Loss                      571.0654
VF Loss                      166.9462
Policy Loss                  -723.30414
Q Predictions Mean           714.4071
Q Predictions Std            294.45886
Q Predictions Max            1111.9608
Q Predictions Min            -38.27729
V Predictions Mean           728.27966
V Predictions Std            285.6832
V Predictions Max            1111.2638
V Predictions Min            125.61362
Log Pis Mean                 -1.0217962
Log Pis Std                  2.9056268
Log Pis Max                  8.714205
Log Pis Min                  -9.921772
Policy mu Mean               -0.0123044485
Policy mu Std                0.5128706
Policy mu Max                2.6254694
Policy mu Min                -2.9351265
Policy log std Mean          -0.9487059
Policy log std Std           0.19589001
Policy log std Max           -0.36464268
Policy log std Min           -1.9640305
Z mean eval                  1.2063249
Z variance eval              0.012312335
total_rewards                [ 597.200229    284.34179841 3051.63437916 1534.94085842 2870.63281254
 2767.11982671 2856.07318006 2880.40125908 2620.21269796  903.89910746]
total_rewards_mean           2036.645614880099
total_rewards_std            1032.5046765331117
total_rewards_max            3051.634379155291
total_rewards_min            284.3417984103032
Number of train steps total  476000
Number of env steps total    378568
Number of rollouts total     0
Train Time (s)               144.46397626120597
(Previous) Eval Time (s)     25.0167925930582
Sample Time (s)              9.96308746933937
Epoch Time (s)               179.44385632360354
Total Train Time (s)         21491.545970292762
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:54:04.085352 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #118 | Epoch Duration: 179.528071641922
2020-01-12 07:54:04.085473 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2078397
Z variance train             0.012216947
KL Divergence                23.442036
KL Loss                      2.3442037
QF Loss                      419.6413
VF Loss                      171.22318
Policy Loss                  -760.79895
Q Predictions Mean           754.4415
Q Predictions Std            292.20218
Q Predictions Max            1098.5768
Q Predictions Min            -8.344828
V Predictions Mean           760.5404
V Predictions Std            284.42548
V Predictions Max            1103.4491
V Predictions Min            25.475971
Log Pis Mean                 -0.80802596
Log Pis Std                  2.9598312
Log Pis Max                  13.320987
Log Pis Min                  -8.464307
Policy mu Mean               -0.004784617
Policy mu Std                0.5331027
Policy mu Max                3.238746
Policy mu Min                -3.5093694
Policy log std Mean          -0.96271384
Policy log std Std           0.19890799
Policy log std Max           -0.35773683
Policy log std Min           -2.025497
Z mean eval                  1.186559
Z variance eval              0.014499009
total_rewards                [1884.79827721 3025.5498914  1341.85049542 1863.37825496 2855.55020434
  963.87968776 3018.91780633 1757.36479763 1696.95398281 1594.52082138]
total_rewards_mean           2000.2764219257756
total_rewards_std            683.7891903272961
total_rewards_max            3025.5498914005093
total_rewards_min            963.8796877625564
Number of train steps total  480000
Number of env steps total    380959
Number of rollouts total     0
Train Time (s)               150.5444938247092
(Previous) Eval Time (s)     32.262655295897275
Sample Time (s)              10.892680305521935
Epoch Time (s)               193.69982942612842
Total Train Time (s)         21685.34272231674
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:57:17.885541 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #119 | Epoch Duration: 193.79994010925293
2020-01-12 07:57:17.885808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1873422
Z variance train             0.014543986
KL Divergence                22.772318
KL Loss                      2.277232
QF Loss                      628.01465
VF Loss                      143.7021
Policy Loss                  -762.187
Q Predictions Mean           756.5292
Q Predictions Std            282.07733
Q Predictions Max            1107.477
Q Predictions Min            -9.158906
V Predictions Mean           763.202
V Predictions Std            280.625
V Predictions Max            1096.698
V Predictions Min            7.6715517
Log Pis Mean                 -0.8939019
Log Pis Std                  2.9178884
Log Pis Max                  14.5699215
Log Pis Min                  -9.082886
Policy mu Mean               0.0036713742
Policy mu Std                0.5227865
Policy mu Max                2.3347538
Policy mu Min                -2.693841
Policy log std Mean          -0.95980114
Policy log std Std           0.21033283
Policy log std Max           -0.4188942
Policy log std Min           -2.054077
Z mean eval                  1.1792688
Z variance eval              0.00892377
total_rewards                [1273.64681657 1662.67274602 2919.30751122 2702.23028437  740.09099433
  758.59192301  856.31863115 2870.43089451 3101.22019656  640.89887323]
total_rewards_mean           1752.5408870972715
total_rewards_std            980.8789780646864
total_rewards_max            3101.2201965578433
total_rewards_min            640.8988732343362
Number of train steps total  484000
Number of env steps total    384850
Number of rollouts total     0
Train Time (s)               149.49381318408996
(Previous) Eval Time (s)     37.47662839572877
Sample Time (s)              11.844850849360228
Epoch Time (s)               198.81529242917895
Total Train Time (s)         21884.248824388254
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:00:36.793758 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #120 | Epoch Duration: 198.9077503681183
2020-01-12 08:00:36.794026 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1720598
Z variance train             0.008936721
KL Divergence                23.829826
KL Loss                      2.3829827
QF Loss                      665.7984
VF Loss                      139.53708
Policy Loss                  -818.2946
Q Predictions Mean           813.22034
Q Predictions Std            245.28125
Q Predictions Max            1141.7891
Q Predictions Min            125.278275
V Predictions Mean           821.12366
V Predictions Std            239.31467
V Predictions Max            1113.6293
V Predictions Min            250.91399
Log Pis Mean                 -0.45409578
Log Pis Std                  3.0468414
Log Pis Max                  12.136347
Log Pis Min                  -8.285576
Policy mu Mean               -0.0006897814
Policy mu Std                0.5653476
Policy mu Max                2.4925296
Policy mu Min                -3.1051881
Policy log std Mean          -0.98610723
Policy log std Std           0.19695272
Policy log std Max           -0.36832
Policy log std Min           -1.867834
Z mean eval                  1.1612804
Z variance eval              0.011145163
total_rewards                [2848.80542056  559.52136509 2569.43138561  275.69636683  503.20770092
 3109.20541191 2850.59851905  799.44811053 1294.92939647 2950.80990593]
total_rewards_mean           1776.165358290053
total_rewards_std            1123.7720204346379
total_rewards_max            3109.2054119137274
total_rewards_min            275.6963668259198
Number of train steps total  488000
Number of env steps total    387524
Number of rollouts total     0
Train Time (s)               151.49058814765885
(Previous) Eval Time (s)     30.74880336318165
Sample Time (s)              11.672630154527724
Epoch Time (s)               193.91202166536823
Total Train Time (s)         22078.24624991184
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:03:50.793807 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #121 | Epoch Duration: 193.99960446357727
2020-01-12 08:03:50.794026 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1640316
Z variance train             0.011263423
KL Divergence                23.538973
KL Loss                      2.3538973
QF Loss                      432.3108
VF Loss                      141.15634
Policy Loss                  -792.0803
Q Predictions Mean           781.9409
Q Predictions Std            280.73608
Q Predictions Max            1128.5721
Q Predictions Min            1.2735441
V Predictions Mean           786.9536
V Predictions Std            273.18588
V Predictions Max            1126.1804
V Predictions Min            -16.273178
Log Pis Mean                 -0.8484798
Log Pis Std                  2.9197567
Log Pis Max                  10.543903
Log Pis Min                  -9.91643
Policy mu Mean               0.031716675
Policy mu Std                0.52878857
Policy mu Max                2.880226
Policy mu Min                -2.0272212
Policy log std Mean          -0.95742434
Policy log std Std           0.19732535
Policy log std Max           -0.4337026
Policy log std Min           -1.9285322
Z mean eval                  1.1712496
Z variance eval              0.019514972
total_rewards                [2815.87871906  599.66174057  549.7898018  1618.0215273  2840.56226182
 1948.77679548 1836.98016751  880.37461056 2936.66301354 2901.06088458]
total_rewards_mean           1892.7769522235496
total_rewards_std            918.6516318855655
total_rewards_max            2936.6630135431096
total_rewards_min            549.7898018045818
Number of train steps total  492000
Number of env steps total    391298
Number of rollouts total     0
Train Time (s)               149.36278107389808
(Previous) Eval Time (s)     27.227180724032223
Sample Time (s)              11.448110319208354
Epoch Time (s)               188.03807211713865
Total Train Time (s)         22266.456021012273
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:06:59.004785 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #122 | Epoch Duration: 188.21058893203735
2020-01-12 08:06:59.004979 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1700119
Z variance train             0.019505776
KL Divergence                20.987007
KL Loss                      2.0987008
QF Loss                      968.9841
VF Loss                      219.41904
Policy Loss                  -759.4806
Q Predictions Mean           751.5384
Q Predictions Std            277.07233
Q Predictions Max            1098.345
Q Predictions Min            183.26567
V Predictions Mean           761.6185
V Predictions Std            271.7443
V Predictions Max            1097.0347
V Predictions Min            99.46009
Log Pis Mean                 -0.34346023
Log Pis Std                  3.4711552
Log Pis Max                  14.29633
Log Pis Min                  -7.962785
Policy mu Mean               -0.0053412556
Policy mu Std                0.57549435
Policy mu Max                2.4225266
Policy mu Min                -2.6897168
Policy log std Mean          -0.9800773
Policy log std Std           0.2027248
Policy log std Max           -0.46812034
Policy log std Min           -2.154329
Z mean eval                  1.1503068
Z variance eval              0.027142882
total_rewards                [ 242.48284515 1796.97560431  222.3674866  2753.7469958  1007.34821304
 1921.83888223   98.39788849 2122.05186453  146.64257274 2289.2960562 ]
total_rewards_mean           1260.1148409107425
total_rewards_std            975.9598759532796
total_rewards_max            2753.7469958028037
total_rewards_min            98.39788849486104
Number of train steps total  496000
Number of env steps total    394160
Number of rollouts total     0
Train Time (s)               140.06021972186863
(Previous) Eval Time (s)     18.27461751597002
Sample Time (s)              10.926793847233057
Epoch Time (s)               169.2616310850717
Total Train Time (s)         22435.80960387923
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:09:48.360511 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #123 | Epoch Duration: 169.35539388656616
2020-01-12 08:09:48.360689 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1522881
Z variance train             0.027246708
KL Divergence                21.487074
KL Loss                      2.1487074
QF Loss                      447.71655
VF Loss                      100.50954
Policy Loss                  -779.3018
Q Predictions Mean           769.4165
Q Predictions Std            285.47388
Q Predictions Max            1135.9706
Q Predictions Min            -14.822797
V Predictions Mean           779.7927
V Predictions Std            275.00836
V Predictions Max            1118.1937
V Predictions Min            -9.149947
Log Pis Mean                 -0.48241773
Log Pis Std                  3.1608095
Log Pis Max                  12.839839
Log Pis Min                  -7.6355433
Policy mu Mean               -0.0026376713
Policy mu Std                0.5659814
Policy mu Max                3.4212976
Policy mu Min                -2.9489377
Policy log std Mean          -0.97365904
Policy log std Std           0.20164257
Policy log std Max           -0.35707092
Policy log std Min           -1.8823364
Z mean eval                  1.1195335
Z variance eval              0.0113448715
total_rewards                [ 687.30755923  886.75396767 2681.23379    2982.19112021  418.50871207
 3037.80270103 1803.04184621  206.41022801 2519.31350205 2888.87873336]
total_rewards_mean           1811.1442159836818
total_rewards_std            1092.1671032799388
total_rewards_max            3037.802701030734
total_rewards_min            206.41022800519056
Number of train steps total  500000
Number of env steps total    397525
Number of rollouts total     0
Train Time (s)               140.4370355317369
(Previous) Eval Time (s)     24.443831162992865
Sample Time (s)              10.934117577504367
Epoch Time (s)               175.81498427223414
Total Train Time (s)         22611.720773576293
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:12:44.274181 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #124 | Epoch Duration: 175.91334128379822
2020-01-12 08:12:44.274395 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1131226
Z variance train             0.011344416
KL Divergence                22.983644
KL Loss                      2.2983644
QF Loss                      517.72217
VF Loss                      94.585106
Policy Loss                  -824.15375
Q Predictions Mean           817.9223
Q Predictions Std            284.04062
Q Predictions Max            1129.8013
Q Predictions Min            11.685181
V Predictions Mean           823.61426
V Predictions Std            278.20428
V Predictions Max            1130.4525
V Predictions Min            44.825893
Log Pis Mean                 -0.6191057
Log Pis Std                  3.0068185
Log Pis Max                  11.802323
Log Pis Min                  -10.9113035
Policy mu Mean               -0.026299104
Policy mu Std                0.5736685
Policy mu Max                4.1981697
Policy mu Min                -3.1608222
Policy log std Mean          -0.9768865
Policy log std Std           0.19225241
Policy log std Max           0.03991449
Policy log std Min           -1.9523828
Z mean eval                  1.1332335
Z variance eval              0.0114903245
total_rewards                [2866.38872434 2076.10564251  600.25179769 2932.82721346 2964.70648693
  127.77576986  602.15197136  597.08637778 3031.57930638 3231.83089209]
total_rewards_mean           1903.070418240257
total_rewards_std            1201.312649598304
total_rewards_max            3231.8308920933173
total_rewards_min            127.77576986220973
Number of train steps total  504000
Number of env steps total    402469
Number of rollouts total     0
Train Time (s)               145.77745071286336
(Previous) Eval Time (s)     25.233150132000446
Sample Time (s)              10.577118886634707
Epoch Time (s)               181.5877197314985
Total Train Time (s)         22793.406179464422
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:15:45.962004 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #125 | Epoch Duration: 181.6874349117279
2020-01-12 08:15:45.962245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1381603
Z variance train             0.011506712
KL Divergence                22.646515
KL Loss                      2.2646515
QF Loss                      517.04175
VF Loss                      158.70564
Policy Loss                  -807.904
Q Predictions Mean           801.4813
Q Predictions Std            283.52686
Q Predictions Max            1117.013
Q Predictions Min            -3.1770456
V Predictions Mean           806.2134
V Predictions Std            282.26337
V Predictions Max            1123.7858
V Predictions Min            -9.081616
Log Pis Mean                 -0.5076507
Log Pis Std                  2.6960764
Log Pis Max                  12.347558
Log Pis Min                  -7.176537
Policy mu Mean               -0.008803956
Policy mu Std                0.5025406
Policy mu Max                3.135456
Policy mu Min                -1.7622532
Policy log std Mean          -0.9946493
Policy log std Std           0.2053684
Policy log std Max           -0.3482101
Policy log std Min           -2.1789553
Z mean eval                  1.159205
Z variance eval              0.015541822
total_rewards                [ 404.34719528 2889.91895311 1364.10431554 1592.22052662  289.74735559
  459.0474363  2416.40382942 2660.49754678 1165.56170723 2938.12447719]
total_rewards_mean           1617.9973343041727
total_rewards_std            996.7428725426875
total_rewards_max            2938.1244771870224
total_rewards_min            289.7473555869103
Number of train steps total  508000
Number of env steps total    406017
Number of rollouts total     0
Train Time (s)               150.7575328652747
(Previous) Eval Time (s)     24.812071609310806
Sample Time (s)              12.484296469017863
Epoch Time (s)               188.05390094360337
Total Train Time (s)         22981.731161049567
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:18:54.289752 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #126 | Epoch Duration: 188.32731342315674
2020-01-12 08:18:54.290072 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.157521
Z variance train             0.01541495
KL Divergence                22.250525
KL Loss                      2.2250526
QF Loss                      519.36975
VF Loss                      225.66037
Policy Loss                  -804.39655
Q Predictions Mean           795.5064
Q Predictions Std            293.3754
Q Predictions Max            1112.5254
Q Predictions Min            -21.443
V Predictions Mean           812.03296
V Predictions Std            284.8915
V Predictions Max            1121.769
V Predictions Min            71.39479
Log Pis Mean                 -0.41640753
Log Pis Std                  2.8125606
Log Pis Max                  11.773989
Log Pis Min                  -8.2122555
Policy mu Mean               -0.001779808
Policy mu Std                0.54893786
Policy mu Max                2.5483963
Policy mu Min                -2.8134825
Policy log std Mean          -0.9774939
Policy log std Std           0.19674905
Policy log std Max           -0.065297544
Policy log std Min           -1.9522874
Z mean eval                  1.2003047
Z variance eval              0.008175116
total_rewards                [2782.99088545  280.56243603 3019.52915092  823.8904327  2126.21439853
  761.50926467 1367.35599311  708.39384206 2595.22278145 1557.29984875]
total_rewards_mean           1602.2969033656682
total_rewards_std            926.2334480185307
total_rewards_max            3019.5291509162594
total_rewards_min            280.56243602894983
Number of train steps total  512000
Number of env steps total    409031
Number of rollouts total     0
Train Time (s)               150.9224638720043
(Previous) Eval Time (s)     28.286595177836716
Sample Time (s)              12.375379799399525
Epoch Time (s)               191.58443884924054
Total Train Time (s)         23173.446108032018
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:22:06.007456 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #127 | Epoch Duration: 191.71717238426208
2020-01-12 08:22:06.007743 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2071818
Z variance train             0.008193837
KL Divergence                23.403765
KL Loss                      2.3403766
QF Loss                      1014.6944
VF Loss                      241.38724
Policy Loss                  -795.46185
Q Predictions Mean           788.6599
Q Predictions Std            294.9337
Q Predictions Max            1118.5267
Q Predictions Min            226.59619
V Predictions Mean           795.2191
V Predictions Std            291.81125
V Predictions Max            1128.1348
V Predictions Min            220.07843
Log Pis Mean                 -0.66540635
Log Pis Std                  3.118186
Log Pis Max                  22.978985
Log Pis Min                  -7.357247
Policy mu Mean               0.008649841
Policy mu Std                0.52467585
Policy mu Max                2.9844315
Policy mu Min                -3.987068
Policy log std Mean          -0.98285544
Policy log std Std           0.20479491
Policy log std Max           -0.31672585
Policy log std Min           -1.8172469
Z mean eval                  1.1540805
Z variance eval              0.01608259
total_rewards                [2963.64730331 3067.73557776 3139.44269976  749.19181933  184.03364572
  979.38863266  584.07047912 2273.47144033  657.15926006 2276.5383842 ]
total_rewards_mean           1687.467924225553
total_rewards_std            1106.9544844637287
total_rewards_max            3139.4426997564933
total_rewards_min            184.03364571853382
Number of train steps total  516000
Number of env steps total    411827
Number of rollouts total     0
Train Time (s)               151.360485218931
(Previous) Eval Time (s)     32.1967323217541
Sample Time (s)              10.74459178885445
Epoch Time (s)               194.30180932953954
Total Train Time (s)         23367.851199313533
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:25:20.414615 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #128 | Epoch Duration: 194.40669679641724
2020-01-12 08:25:20.414828 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1472328
Z variance train             0.015836507
KL Divergence                22.127733
KL Loss                      2.2127733
QF Loss                      678.364
VF Loss                      104.59293
Policy Loss                  -797.8026
Q Predictions Mean           793.4234
Q Predictions Std            296.7691
Q Predictions Max            1122.8052
Q Predictions Min            232.74776
V Predictions Mean           798.16437
V Predictions Std            293.4541
V Predictions Max            1126.1248
V Predictions Min            243.68437
Log Pis Mean                 -0.90891546
Log Pis Std                  3.0042756
Log Pis Max                  17.701506
Log Pis Min                  -9.133039
Policy mu Mean               -0.027527591
Policy mu Std                0.5198928
Policy mu Max                4.2899094
Policy mu Min                -2.9806836
Policy log std Mean          -0.9608575
Policy log std Std           0.18993533
Policy log std Max           -0.53044295
Policy log std Min           -1.7634139
Z mean eval                  1.1798004
Z variance eval              0.016319988
total_rewards                [2676.62400972 2860.02458636 2998.95340306 2791.69266177 2801.52405873
 1041.25092786 1541.55029644 1214.69408264  799.72796158 2868.53799009]
total_rewards_mean           2159.457997826756
total_rewards_std            845.6602333195184
total_rewards_max            2998.953403063352
total_rewards_min            799.7279615802479
Number of train steps total  520000
Number of env steps total    415834
Number of rollouts total     0
Train Time (s)               149.40381304593757
(Previous) Eval Time (s)     31.463661228772253
Sample Time (s)              10.995336323510855
Epoch Time (s)               191.86281059822068
Total Train Time (s)         23559.890665100887
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:28:32.456410 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #129 | Epoch Duration: 192.04141283035278
2020-01-12 08:28:32.456615 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1754469
Z variance train             0.016221512
KL Divergence                22.205484
KL Loss                      2.2205484
QF Loss                      456.9549
VF Loss                      134.05334
Policy Loss                  -770.8285
Q Predictions Mean           761.25385
Q Predictions Std            304.68765
Q Predictions Max            1142.4808
Q Predictions Min            -36.300125
V Predictions Mean           771.4895
V Predictions Std            294.63956
V Predictions Max            1140.99
V Predictions Min            234.78499
Log Pis Mean                 -0.8208468
Log Pis Std                  3.041088
Log Pis Max                  13.763378
Log Pis Min                  -7.3649683
Policy mu Mean               0.02856187
Policy mu Std                0.5206006
Policy mu Max                2.748495
Policy mu Min                -2.5861168
Policy log std Mean          -0.95716804
Policy log std Std           0.19315475
Policy log std Max           -0.44630408
Policy log std Min           -1.9152651
Z mean eval                  1.136006
Z variance eval              0.012043485
total_rewards                [ 267.40395928 1201.44240862 2114.05231281 1502.28492807  612.81418917
 3241.29034142  643.07189173  989.28632167  133.63775352  373.96272389]
total_rewards_mean           1107.9246830190914
total_rewards_std            916.3795748874625
total_rewards_max            3241.2903414199727
total_rewards_min            133.6377535229826
Number of train steps total  524000
Number of env steps total    420826
Number of rollouts total     0
Train Time (s)               141.51108359592035
(Previous) Eval Time (s)     18.886877048760653
Sample Time (s)              12.118564091157168
Epoch Time (s)               172.51652473583817
Total Train Time (s)         23732.579690715764
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:31:25.149182 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #130 | Epoch Duration: 172.692316532135
2020-01-12 08:31:25.149562 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1379647
Z variance train             0.012055379
KL Divergence                22.613792
KL Loss                      2.2613792
QF Loss                      851.17725
VF Loss                      363.28326
Policy Loss                  -794.41907
Q Predictions Mean           789.1105
Q Predictions Std            308.08524
Q Predictions Max            1162.6123
Q Predictions Min            -13.662639
V Predictions Mean           790.53394
V Predictions Std            303.55252
V Predictions Max            1152.238
V Predictions Min            -47.07801
Log Pis Mean                 -0.76049125
Log Pis Std                  3.0405347
Log Pis Max                  13.789253
Log Pis Min                  -7.1293645
Policy mu Mean               -0.0060057053
Policy mu Std                0.5444901
Policy mu Max                2.349132
Policy mu Min                -3.6518223
Policy log std Mean          -0.9584182
Policy log std Std           0.20483094
Policy log std Max           -0.23491395
Policy log std Min           -2.0865912
Z mean eval                  1.1323943
Z variance eval              0.019206308
total_rewards                [ 229.51717127 2919.35078076 3075.94138907  771.11087604  669.14878294
 1996.2339589   460.14691487   63.47513136  486.12672784 1774.38751192]
total_rewards_mean           1244.5439244958366
total_rewards_std            1057.1501005570342
total_rewards_max            3075.9413890671444
total_rewards_min            63.4751313604094
Number of train steps total  528000
Number of env steps total    423886
Number of rollouts total     0
Train Time (s)               140.1161742308177
(Previous) Eval Time (s)     29.487742260098457
Sample Time (s)              11.654356906656176
Epoch Time (s)               181.25827339757234
Total Train Time (s)         23913.928373775445
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:34:26.500083 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #131 | Epoch Duration: 181.3502504825592
2020-01-12 08:34:26.500386 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1300871
Z variance train             0.019206729
KL Divergence                22.108631
KL Loss                      2.210863
QF Loss                      535.5329
VF Loss                      112.869675
Policy Loss                  -803.36975
Q Predictions Mean           799.56946
Q Predictions Std            307.43793
Q Predictions Max            1156.6437
Q Predictions Min            -1.7550247
V Predictions Mean           805.3238
V Predictions Std            301.77353
V Predictions Max            1166.4141
V Predictions Min            -6.589736
Log Pis Mean                 -0.7086941
Log Pis Std                  2.8517022
Log Pis Max                  10.343235
Log Pis Min                  -8.5767565
Policy mu Mean               0.020504959
Policy mu Std                0.5275519
Policy mu Max                3.1801872
Policy mu Min                -3.8326576
Policy log std Mean          -0.96520865
Policy log std Std           0.19248754
Policy log std Max           -0.4787029
Policy log std Min           -1.8162177
Z mean eval                  1.1689425
Z variance eval              0.021129062
total_rewards                [2894.9772858  3130.2953384  3030.4592362  2979.48614251 2792.14550738
 2949.56592849 2790.00591312  956.19004191 2963.59487235 2154.73745235]
total_rewards_mean           2664.1457718493957
total_rewards_std            623.231294000347
total_rewards_max            3130.2953383997483
total_rewards_min            956.1900419130156
Number of train steps total  532000
Number of env steps total    428248
Number of rollouts total     0
Train Time (s)               148.6310190721415
(Previous) Eval Time (s)     36.227011180948466
Sample Time (s)              13.03630743874237
Epoch Time (s)               197.89433769183233
Total Train Time (s)         24111.9241979355
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:37:44.498472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #132 | Epoch Duration: 197.9978802204132
2020-01-12 08:37:44.498858 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1494167
Z variance train             0.021687398
KL Divergence                21.735476
KL Loss                      2.1735475
QF Loss                      943.2372
VF Loss                      176.215
Policy Loss                  -808.3084
Q Predictions Mean           793.0406
Q Predictions Std            307.74588
Q Predictions Max            1163.3091
Q Predictions Min            -12.24826
V Predictions Mean           814.20764
V Predictions Std            297.2175
V Predictions Max            1165.7405
V Predictions Min            61.48768
Log Pis Mean                 -0.20525576
Log Pis Std                  3.50321
Log Pis Max                  13.883884
Log Pis Min                  -9.156412
Policy mu Mean               -0.020641908
Policy mu Std                0.5835216
Policy mu Max                2.7308922
Policy mu Min                -3.4414296
Policy log std Mean          -0.974729
Policy log std Std           0.20867214
Policy log std Max           -0.3793857
Policy log std Min           -2.2680635
Z mean eval                  1.1155064
Z variance eval              0.018303502
total_rewards                [1261.26922593 1871.28911543  819.16617011 1904.73437964 3031.43208137
  232.95770546  994.68399948  963.62120864 3196.55641531 2239.45900838]
total_rewards_mean           1651.516930973797
total_rewards_std            922.5751442353268
total_rewards_max            3196.5564153073174
total_rewards_min            232.95770545999258
Number of train steps total  536000
Number of env steps total    431265
Number of rollouts total     0
Train Time (s)               150.14553236868232
(Previous) Eval Time (s)     23.191895036958158
Sample Time (s)              12.115264009218663
Epoch Time (s)               185.45269141485915
Total Train Time (s)         24297.590394282248
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:40:50.166897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #133 | Epoch Duration: 185.6677360534668
2020-01-12 08:40:50.167110 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.108626
Z variance train             0.018262634
KL Divergence                21.999865
KL Loss                      2.1999865
QF Loss                      1575.0378
VF Loss                      110.11543
Policy Loss                  -827.99976
Q Predictions Mean           822.7911
Q Predictions Std            301.9371
Q Predictions Max            1155.6792
Q Predictions Min            240.95477
V Predictions Mean           828.3568
V Predictions Std            298.6718
V Predictions Max            1151.9249
V Predictions Min            246.10599
Log Pis Mean                 -0.49305204
Log Pis Std                  3.3328097
Log Pis Max                  18.880268
Log Pis Min                  -7.6880374
Policy mu Mean               -0.03845985
Policy mu Std                0.5532388
Policy mu Max                2.8150997
Policy mu Min                -2.7925537
Policy log std Mean          -0.98276937
Policy log std Std           0.21013929
Policy log std Max           -0.44818836
Policy log std Min           -1.8479745
Z mean eval                  1.1886739
Z variance eval              0.097212695
total_rewards                [3116.48420538 2432.78869507  897.326104   3132.91265559 3105.04015168
 3025.97090227 3177.11038797 1041.72274638 3018.91492219  803.0329621 ]
total_rewards_mean           2375.130373264411
total_rewards_std            978.4951594162503
total_rewards_max            3177.1103879679904
total_rewards_min            803.0329620976069
Number of train steps total  540000
Number of env steps total    435658
Number of rollouts total     0
Train Time (s)               149.26954628201202
(Previous) Eval Time (s)     29.434264719020575
Sample Time (s)              11.983525950461626
Epoch Time (s)               190.68733695149422
Total Train Time (s)         24488.36219384987
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:44:00.941609 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #134 | Epoch Duration: 190.77429699897766
2020-01-12 08:44:00.941837 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1897588
Z variance train             0.095842615
KL Divergence                20.080713
KL Loss                      2.0080714
QF Loss                      2442.5415
VF Loss                      342.55255
Policy Loss                  -935.6498
Q Predictions Mean           926.9678
Q Predictions Std            358.78455
Q Predictions Max            1335.7747
Q Predictions Min            -4.8801203
V Predictions Mean           942.56104
V Predictions Std            348.2708
V Predictions Max            1331.1667
V Predictions Min            287.00015
Log Pis Mean                 -0.68408316
Log Pis Std                  2.7511084
Log Pis Max                  10.878915
Log Pis Min                  -9.704649
Policy mu Mean               -0.007837145
Policy mu Std                0.51315355
Policy mu Max                1.814133
Policy mu Min                -3.1996303
Policy log std Mean          -0.97824836
Policy log std Std           0.1889748
Policy log std Max           -0.51741296
Policy log std Min           -1.816759
Z mean eval                  1.1106185
Z variance eval              0.01919492
total_rewards                [ 575.56852147  384.30652406 1437.4806241   743.80145243  773.98761717
 1160.3575503   864.94972857 1381.08469373  242.00908989 3117.75358951]
total_rewards_mean           1068.1299391241005
total_rewards_std            779.0713310674583
total_rewards_max            3117.753589511665
total_rewards_min            242.00908988647512
Number of train steps total  544000
Number of env steps total    439998
Number of rollouts total     0
Train Time (s)               150.92698129313067
(Previous) Eval Time (s)     24.47994481679052
Sample Time (s)              12.211497021373361
Epoch Time (s)               187.61842313129455
Total Train Time (s)         24676.090822271537
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:47:08.673253 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #135 | Epoch Duration: 187.73121762275696
2020-01-12 08:47:08.673565 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1140976
Z variance train             0.019193422
KL Divergence                21.07768
KL Loss                      2.107768
QF Loss                      1000.97705
VF Loss                      161.00502
Policy Loss                  -799.2025
Q Predictions Mean           794.2645
Q Predictions Std            315.5651
Q Predictions Max            1174.2944
Q Predictions Min            -57.059544
V Predictions Mean           801.38245
V Predictions Std            312.0046
V Predictions Max            1164.2726
V Predictions Min            -101.27235
Log Pis Mean                 -0.7511773
Log Pis Std                  3.0895846
Log Pis Max                  14.954445
Log Pis Min                  -7.9873424
Policy mu Mean               -0.004074069
Policy mu Std                0.5440567
Policy mu Max                2.4423409
Policy mu Min                -4.049431
Policy log std Mean          -0.94508266
Policy log std Std           0.19640276
Policy log std Max           -0.40690917
Policy log std Min           -1.8682249
Z mean eval                  1.1541405
Z variance eval              0.012345409
total_rewards                [1415.29035372 1686.6326817  3022.16161049 2532.40066571  531.72178719
  601.05456177  562.31143008 2410.71941784 1542.37032172 1619.73692744]
total_rewards_mean           1592.4399757658484
total_rewards_std            825.218188138079
total_rewards_max            3022.161610493456
total_rewards_min            531.721787185409
Number of train steps total  548000
Number of env steps total    444025
Number of rollouts total     0
Train Time (s)               146.79086795076728
(Previous) Eval Time (s)     31.96400768030435
Sample Time (s)              13.08893961366266
Epoch Time (s)               191.8438152447343
Total Train Time (s)         24868.02926694369
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:50:20.614890 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #136 | Epoch Duration: 191.94105768203735
2020-01-12 08:50:20.615216 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1535109
Z variance train             0.012364624
KL Divergence                22.500793
KL Loss                      2.2500794
QF Loss                      1076.5126
VF Loss                      151.47427
Policy Loss                  -785.4324
Q Predictions Mean           775.96906
Q Predictions Std            322.5999
Q Predictions Max            1163.4064
Q Predictions Min            16.888008
V Predictions Mean           793.2715
V Predictions Std            317.1318
V Predictions Max            1164.6562
V Predictions Min            -14.615841
Log Pis Mean                 -0.7960111
Log Pis Std                  2.9322267
Log Pis Max                  10.005274
Log Pis Min                  -9.841108
Policy mu Mean               -0.0035965024
Policy mu Std                0.5398001
Policy mu Max                2.115481
Policy mu Min                -2.791304
Policy log std Mean          -0.9587743
Policy log std Std           0.20354865
Policy log std Max           0.70075715
Policy log std Min           -1.8122736
Z mean eval                  1.0844262
Z variance eval              0.036952756
total_rewards                [2815.09637602 1156.53746894 1413.36811332 2317.86293066 1997.42538161
 1147.79726489 1763.082102    430.59860158  198.9273321  2597.14866943]
total_rewards_mean           1583.7844240562895
total_rewards_std            832.7356818747885
total_rewards_max            2815.0963760239933
total_rewards_min            198.92733210160128
Number of train steps total  552000
Number of env steps total    446593
Number of rollouts total     0
Train Time (s)               140.9595053838566
(Previous) Eval Time (s)     29.28898077318445
Sample Time (s)              11.082686421927065
Epoch Time (s)               181.3311725789681
Total Train Time (s)         25049.449545506854
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:53:22.036571 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #137 | Epoch Duration: 181.42116498947144
2020-01-12 08:53:22.036764 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0922556
Z variance train             0.03695803
KL Divergence                19.842129
KL Loss                      1.9842129
QF Loss                      696.9278
VF Loss                      210.30443
Policy Loss                  -840.2899
Q Predictions Mean           830.9193
Q Predictions Std            294.04462
Q Predictions Max            1206.5132
Q Predictions Min            103.00679
V Predictions Mean           834.0034
V Predictions Std            290.70108
V Predictions Max            1193.883
V Predictions Min            55.895287
Log Pis Mean                 -0.3754276
Log Pis Std                  3.232267
Log Pis Max                  17.934101
Log Pis Min                  -7.9585757
Policy mu Mean               0.007880107
Policy mu Std                0.5833146
Policy mu Max                3.1826737
Policy mu Min                -3.7880523
Policy log std Mean          -0.98396635
Policy log std Std           0.19558522
Policy log std Max           -0.42833212
Policy log std Min           -1.9586699
Z mean eval                  1.1238563
Z variance eval              0.02378468
total_rewards                [1374.39885684 1285.38887848  990.02529302 1519.80371331  323.49763175
  611.0973856  3101.62702626 3187.2650521   436.66106989  272.94732901]
total_rewards_mean           1310.2712236264938
total_rewards_std            1009.2103838634595
total_rewards_max            3187.2650521033142
total_rewards_min            272.947329012727
Number of train steps total  556000
Number of env steps total    449870
Number of rollouts total     0
Train Time (s)               141.83020592899993
(Previous) Eval Time (s)     18.92425133101642
Sample Time (s)              10.946388009004295
Epoch Time (s)               171.70084526902065
Total Train Time (s)         25221.23668784136
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:56:13.826358 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #138 | Epoch Duration: 171.78944039344788
2020-01-12 08:56:13.826578 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1282138
Z variance train             0.02370273
KL Divergence                20.563107
KL Loss                      2.0563107
QF Loss                      517.2103
VF Loss                      125.72542
Policy Loss                  -845.2224
Q Predictions Mean           840.3905
Q Predictions Std            305.18484
Q Predictions Max            1192.9292
Q Predictions Min            -17.053843
V Predictions Mean           842.9129
V Predictions Std            300.66666
V Predictions Max            1169.2592
V Predictions Min            -8.595264
Log Pis Mean                 -0.5517562
Log Pis Std                  3.3972385
Log Pis Max                  18.441818
Log Pis Min                  -10.686348
Policy mu Mean               -0.030317338
Policy mu Std                0.553773
Policy mu Max                3.4446082
Policy mu Min                -2.768784
Policy log std Mean          -0.9839664
Policy log std Std           0.20594423
Policy log std Max           -0.34775764
Policy log std Min           -1.9409759
Z mean eval                  1.1524079
Z variance eval              0.045854993
total_rewards                [ 778.53368185  477.11129034  541.93561293 1232.87720722  962.71514798
 1362.00092128 1751.39473208 2977.89833263 2971.77151366  193.90195029]
total_rewards_mean           1325.01403902549
total_rewards_std            931.5020722518215
total_rewards_max            2977.8983326276393
total_rewards_min            193.9019502901105
Number of train steps total  560000
Number of env steps total    452879
Number of rollouts total     0
Train Time (s)               150.84003834798932
(Previous) Eval Time (s)     25.417807477992028
Sample Time (s)              12.186558766290545
Epoch Time (s)               188.4444045922719
Total Train Time (s)         25409.76347162109
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:59:22.353629 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #139 | Epoch Duration: 188.5269079208374
2020-01-12 08:59:22.353764 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1550763
Z variance train             0.04655949
KL Divergence                21.461197
KL Loss                      2.1461198
QF Loss                      608.4531
VF Loss                      120.12602
Policy Loss                  -781.20386
Q Predictions Mean           775.94226
Q Predictions Std            327.74332
Q Predictions Max            1166.495
Q Predictions Min            158.71005
V Predictions Mean           775.4794
V Predictions Std            322.32355
V Predictions Max            1159.0048
V Predictions Min            214.12154
Log Pis Mean                 -0.8823159
Log Pis Std                  3.048787
Log Pis Max                  14.595524
Log Pis Min                  -8.362165
Policy mu Mean               0.015576084
Policy mu Std                0.53319234
Policy mu Max                2.6767778
Policy mu Min                -2.0897894
Policy log std Mean          -0.9489963
Policy log std Std           0.19242129
Policy log std Max           -0.3625077
Policy log std Min           -1.8766582
Z mean eval                  1.0636761
Z variance eval              0.012624422
total_rewards                [ 178.35606726 2932.87002978 1493.25079522 3083.58114198 2990.07039081
 2921.73979024 2986.73563328 2266.44952397 3106.35494603  481.10127928]
total_rewards_mean           2244.0509597856712
total_rewards_std            1069.0897070448186
total_rewards_max            3106.3549460314525
total_rewards_min            178.35606726488288
Number of train steps total  564000
Number of env steps total    459099
Number of rollouts total     0
Train Time (s)               149.128359306138
(Previous) Eval Time (s)     29.010198508854955
Sample Time (s)              10.703752880450338
Epoch Time (s)               188.8423106954433
Total Train Time (s)         25598.69653815264
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:02:31.290820 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #140 | Epoch Duration: 188.9368932247162
2020-01-12 09:02:31.291176 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0622013
Z variance train             0.012526113
KL Divergence                21.743702
KL Loss                      2.1743703
QF Loss                      599.6224
VF Loss                      159.46771
Policy Loss                  -790.957
Q Predictions Mean           784.2783
Q Predictions Std            316.4772
Q Predictions Max            1144.0304
Q Predictions Min            -40.3251
V Predictions Mean           785.66846
V Predictions Std            308.72134
V Predictions Max            1130.6831
V Predictions Min            -23.256811
Log Pis Mean                 -0.32815176
Log Pis Std                  3.784165
Log Pis Max                  36.50052
Log Pis Min                  -8.589142
Policy mu Mean               0.008051759
Policy mu Std                0.5957002
Policy mu Max                3.1587925
Policy mu Min                -4.625629
Policy log std Mean          -0.97829384
Policy log std Std           0.20250544
Policy log std Max           -0.416907
Policy log std Min           -1.7451425
Z mean eval                  1.1200234
Z variance eval              0.008886995
total_rewards                [1849.72206572 1102.12830814  772.67732977 2170.60336852 1957.12299851
 1448.63101285 2863.12161396 3055.51344331  734.49489609 2061.04528671]
total_rewards_mean           1801.5060323587136
total_rewards_std            757.6508673956938
total_rewards_max            3055.513443310487
total_rewards_min            734.4948960940977
Number of train steps total  568000
Number of env steps total    464943
Number of rollouts total     0
Train Time (s)               149.546079732012
(Previous) Eval Time (s)     33.29286831011996
Sample Time (s)              13.07467354182154
Epoch Time (s)               195.9136215839535
Total Train Time (s)         25794.71223042207
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:05:47.308115 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #141 | Epoch Duration: 196.01668000221252
2020-01-12 09:05:47.308359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1192671
Z variance train             0.008911034
KL Divergence                22.790346
KL Loss                      2.2790346
QF Loss                      795.0762
VF Loss                      140.40048
Policy Loss                  -778.5842
Q Predictions Mean           768.1957
Q Predictions Std            327.0422
Q Predictions Max            1136.674
Q Predictions Min            -24.124054
V Predictions Mean           780.3253
V Predictions Std            318.92923
V Predictions Max            1141.4285
V Predictions Min            226.91124
Log Pis Mean                 -0.41503498
Log Pis Std                  3.6763756
Log Pis Max                  19.35255
Log Pis Min                  -10.135122
Policy mu Mean               -0.0045266724
Policy mu Std                0.5799572
Policy mu Max                3.1038015
Policy mu Min                -2.9682744
Policy log std Mean          -0.9643199
Policy log std Std           0.21767938
Policy log std Max           -0.3884356
Policy log std Min           -2.3215952
Z mean eval                  1.0953192
Z variance eval              0.012029624
total_rewards                [3111.72536619 3056.64657639 3128.84542337 3174.36004517 2942.02530757
  243.68118867  406.62421243  600.06866729 2925.8334551  1622.92011611]
total_rewards_mean           2121.2730358271933
total_rewards_std            1197.0319836937733
total_rewards_max            3174.36004516672
total_rewards_min            243.68118867492024
Number of train steps total  572000
Number of env steps total    470785
Number of rollouts total     0
Train Time (s)               150.9877929938957
(Previous) Eval Time (s)     31.496887968387455
Sample Time (s)              12.86758984066546
Epoch Time (s)               195.35227080294862
Total Train Time (s)         25990.164374717977
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:09:02.767232 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #142 | Epoch Duration: 195.45869207382202
2020-01-12 09:09:02.767473 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0951575
Z variance train             0.011869522
KL Divergence                23.318142
KL Loss                      2.3318143
QF Loss                      521.7688
VF Loss                      226.32181
Policy Loss                  -808.47217
Q Predictions Mean           800.93384
Q Predictions Std            312.6693
Q Predictions Max            1160.1329
Q Predictions Min            -31.039968
V Predictions Mean           806.0513
V Predictions Std            307.3151
V Predictions Max            1142.5331
V Predictions Min            -40.688328
Log Pis Mean                 -0.2648408
Log Pis Std                  3.144712
Log Pis Max                  19.039444
Log Pis Min                  -8.851328
Policy mu Mean               -0.0065696244
Policy mu Std                0.57554585
Policy mu Max                3.342
Policy mu Min                -3.0199916
Policy log std Mean          -0.98377484
Policy log std Std           0.20248438
Policy log std Max           -0.2958001
Policy log std Min           -1.8969436
Z mean eval                  1.0975692
Z variance eval              0.04621325
total_rewards                [ 847.54842483 3012.44678417 2970.90171272 2824.78078903   33.05075378
 2338.34820472 2426.44289643 1126.35803119  259.50944083  629.73586703]
total_rewards_mean           1646.9122904734875
total_rewards_std            1120.928238669707
total_rewards_max            3012.446784171737
total_rewards_min            33.05075378391746
Number of train steps total  576000
Number of env steps total    474162
Number of rollouts total     0
Train Time (s)               144.49681778391823
(Previous) Eval Time (s)     22.679570795968175
Sample Time (s)              10.696582513861358
Epoch Time (s)               177.87297109374776
Total Train Time (s)         26168.126962595154
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:12:00.728430 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #143 | Epoch Duration: 177.9607858657837
2020-01-12 09:12:00.728619 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #143 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1022254
Z variance train             0.047211174
KL Divergence                20.886496
KL Loss                      2.0886495
QF Loss                      545.3043
VF Loss                      159.26193
Policy Loss                  -819.4302
Q Predictions Mean           810.9342
Q Predictions Std            337.5754
Q Predictions Max            1165.1019
Q Predictions Min            -53.239635
V Predictions Mean           817.7344
V Predictions Std            328.9631
V Predictions Max            1156.4667
V Predictions Min            2.4170187
Log Pis Mean                 -0.27392378
Log Pis Std                  4.0498514
Log Pis Max                  38.09146
Log Pis Min                  -9.298425
Policy mu Mean               -0.015500631
Policy mu Std                0.5732662
Policy mu Max                6.7049336
Policy mu Min                -3.844523
Policy log std Mean          -0.9904864
Policy log std Std           0.21290064
Policy log std Max           -0.41719025
Policy log std Min           -2.145568
Z mean eval                  1.0925434
Z variance eval              0.018344225
total_rewards                [2006.19552815 3055.47022544 3021.1040436  2280.7261043  1100.1404189
 1739.78611736 3014.62809421  822.62207514  244.7300828  2960.04983661]
total_rewards_mean           2024.545252650758
total_rewards_std            975.9768106609887
total_rewards_max            3055.4702254367835
total_rewards_min            244.73008280099657
Number of train steps total  580000
Number of env steps total    478508
Number of rollouts total     0
Train Time (s)               140.65358586609364
(Previous) Eval Time (s)     26.60274443682283
Sample Time (s)              11.896811519283801
Epoch Time (s)               179.15314182220027
Total Train Time (s)         26347.367379079573
Epoch                        144
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:14:59.970925 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #144 | Epoch Duration: 179.2421624660492
2020-01-12 09:14:59.971121 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0963638
Z variance train             0.018556338
KL Divergence                21.899473
KL Loss                      2.1899474
QF Loss                      571.41565
VF Loss                      113.78238
Policy Loss                  -834.2527
Q Predictions Mean           827.6948
Q Predictions Std            307.09415
Q Predictions Max            1151.8503
Q Predictions Min            24.878103
V Predictions Mean           831.72205
V Predictions Std            300.09402
V Predictions Max            1145.7494
V Predictions Min            143.73819
Log Pis Mean                 -0.47751743
Log Pis Std                  3.4755855
Log Pis Max                  25.271412
Log Pis Min                  -7.1980724
Policy mu Mean               -0.014938122
Policy mu Std                0.56951344
Policy mu Max                4.0106826
Policy mu Min                -3.1619558
Policy log std Mean          -0.9759395
Policy log std Std           0.21072702
Policy log std Max           -0.29176193
Policy log std Min           -2.5414245
Z mean eval                  1.12167
Z variance eval              0.01623021
total_rewards                [2326.48041329 2906.69558945   91.5914996  1491.41888872  518.96017609
 3069.29935769  676.16647092 1131.33777805  182.10947237  346.68309569]
total_rewards_mean           1274.074274186527
total_rewards_std            1069.6660511957216
total_rewards_max            3069.299357690136
total_rewards_min            91.59149960172596
Number of train steps total  584000
Number of env steps total    483914
Number of rollouts total     0
Train Time (s)               144.21510497899726
(Previous) Eval Time (s)     21.93153397878632
Sample Time (s)              11.159276112914085
Epoch Time (s)               177.30591507069767
Total Train Time (s)         26524.769065634813
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:17:57.375175 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #145 | Epoch Duration: 177.40383172035217
2020-01-12 09:17:57.375416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1127989
Z variance train             0.01634385
KL Divergence                20.709522
KL Loss                      2.0709522
QF Loss                      706.03674
VF Loss                      162.11699
Policy Loss                  -825.64667
Q Predictions Mean           816.5969
Q Predictions Std            306.78302
Q Predictions Max            1157.2412
Q Predictions Min            86.51262
V Predictions Mean           825.33264
V Predictions Std            298.86533
V Predictions Max            1165.2845
V Predictions Min            259.41776
Log Pis Mean                 -0.5396162
Log Pis Std                  3.388762
Log Pis Max                  17.173859
Log Pis Min                  -8.384055
Policy mu Mean               0.025708094
Policy mu Std                0.55873424
Policy mu Max                3.209954
Policy mu Min                -3.0231347
Policy log std Mean          -0.9773483
Policy log std Std           0.2057191
Policy log std Max           -0.45537803
Policy log std Min           -1.8037899
Z mean eval                  1.0850643
Z variance eval              0.02304301
total_rewards                [2624.99807152 2851.70992549 1367.96782248 3059.62928014  181.84223251
 3271.46638282  330.34606405  735.23837086  727.03504242 1314.75843163]
total_rewards_mean           1646.4991623930832
total_rewards_std            1130.8567245323875
total_rewards_max            3271.4663828232997
total_rewards_min            181.8422325095344
Number of train steps total  588000
Number of env steps total    489893
Number of rollouts total     0
Train Time (s)               151.8546595298685
(Previous) Eval Time (s)     23.960674681235105
Sample Time (s)              12.552792903967202
Epoch Time (s)               188.36812711507082
Total Train Time (s)         26713.23298370419
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:21:05.841332 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #146 | Epoch Duration: 188.46574568748474
2020-01-12 09:21:05.841520 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #146 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0906498
Z variance train             0.023238951
KL Divergence                20.77428
KL Loss                      2.077428
QF Loss                      467.3661
VF Loss                      102.85697
Policy Loss                  -812.9388
Q Predictions Mean           803.78735
Q Predictions Std            319.54645
Q Predictions Max            1226.1251
Q Predictions Min            -28.919592
V Predictions Mean           809.8135
V Predictions Std            315.52423
V Predictions Max            1223.5035
V Predictions Min            -8.809769
Log Pis Mean                 -0.53353083
Log Pis Std                  3.470574
Log Pis Max                  20.564262
Log Pis Min                  -9.026816
Policy mu Mean               0.0011343947
Policy mu Std                0.54602116
Policy mu Max                3.8181112
Policy mu Min                -2.8884487
Policy log std Mean          -0.97258
Policy log std Std           0.20316826
Policy log std Max           -0.41078335
Policy log std Min           -2.0143995
Z mean eval                  1.1387205
Z variance eval              0.015769357
total_rewards                [1649.85237063  353.80833154  354.22087972 1061.14381105 2882.8344013
  914.80896668 3000.29488713 3178.77974549 2088.76762419 2625.88451805]
total_rewards_mean           1811.0395535783089
total_rewards_std            1039.8215498040604
total_rewards_max            3178.7797454943143
total_rewards_min            353.80833154393997
Number of train steps total  592000
Number of env steps total    495178
Number of rollouts total     0
Train Time (s)               150.5665367678739
(Previous) Eval Time (s)     21.78669408010319
Sample Time (s)              14.30035947682336
Epoch Time (s)               186.65359032480046
Total Train Time (s)         26899.97435578378
Epoch                        147
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:24:12.585052 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #147 | Epoch Duration: 186.74339294433594
2020-01-12 09:24:12.585252 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1381313
Z variance train             0.015808243
KL Divergence                21.414383
KL Loss                      2.1414382
QF Loss                      686.729
VF Loss                      141.30167
Policy Loss                  -841.4122
Q Predictions Mean           836.8757
Q Predictions Std            323.2514
Q Predictions Max            1208.8185
Q Predictions Min            228.0478
V Predictions Mean           838.5365
V Predictions Std            318.40744
V Predictions Max            1199.5935
V Predictions Min            263.11188
Log Pis Mean                 -0.39401424
Log Pis Std                  3.0157645
Log Pis Max                  14.661232
Log Pis Min                  -12.127345
Policy mu Mean               -0.002836275
Policy mu Std                0.56745225
Policy mu Max                2.604429
Policy mu Min                -2.897207
Policy log std Mean          -0.97013116
Policy log std Std           0.20627686
Policy log std Max           -0.40462792
Policy log std Min           -2.1673255
Z mean eval                  1.0305564
Z variance eval              0.07379665
total_rewards                [2991.37353908 3228.95537256 1076.39417582 3128.19238989  798.08950757
  509.65773778 3193.51661668 1216.72000355 3092.24707364 1830.63691047]
total_rewards_mean           2106.5783327031586
total_rewards_std            1069.1508341786039
total_rewards_max            3228.955372556613
total_rewards_min            509.657737776531
Number of train steps total  596000
Number of env steps total    499815
Number of rollouts total     0
Train Time (s)               149.365127899684
(Previous) Eval Time (s)     34.81489566620439
Sample Time (s)              11.278405047953129
Epoch Time (s)               195.45842861384153
Total Train Time (s)         27095.533868120983
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:27:28.147785 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #148 | Epoch Duration: 195.56235527992249
2020-01-12 09:27:28.148088 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0372077
Z variance train             0.07714553
KL Divergence                20.58651
KL Loss                      2.058651
QF Loss                      636.4254
VF Loss                      211.19891
Policy Loss                  -813.3568
Q Predictions Mean           803.1444
Q Predictions Std            319.30087
Q Predictions Max            1179.372
Q Predictions Min            186.9203
V Predictions Mean           811.64966
V Predictions Std            313.71158
V Predictions Max            1184.2683
V Predictions Min            235.81537
Log Pis Mean                 -0.43368328
Log Pis Std                  3.3410707
Log Pis Max                  19.548256
Log Pis Min                  -7.0095196
Policy mu Mean               0.019383725
Policy mu Std                0.5568333
Policy mu Max                3.2911427
Policy mu Min                -2.9379609
Policy log std Mean          -1.0061707
Policy log std Std           0.21970008
Policy log std Max           -0.29548812
Policy log std Min           -2.1380074
Z mean eval                  1.0869353
Z variance eval              0.016234841
total_rewards                [2690.27818993 1424.22763339  391.08157948  491.84758775 3113.29204103
 3173.42566125 3248.79486379 3125.29160813 2706.2740878  3087.2304316 ]
total_rewards_mean           2345.174368415659
total_rewards_std            1077.1581313241816
total_rewards_max            3248.79486379487
total_rewards_min            391.0815794774846
Number of train steps total  600000
Number of env steps total    502709
Number of rollouts total     0
Train Time (s)               149.81933481059968
(Previous) Eval Time (s)     29.758851577993482
Sample Time (s)              12.803685913328081
Epoch Time (s)               192.38187230192125
Total Train Time (s)         27288.045374027453
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:30:40.661620 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #149 | Epoch Duration: 192.51331281661987
2020-01-12 09:30:40.661935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0885696
Z variance train             0.016141992
KL Divergence                21.4181
KL Loss                      2.1418102
QF Loss                      1178.1318
VF Loss                      115.565796
Policy Loss                  -809.6543
Q Predictions Mean           805.2071
Q Predictions Std            327.6558
Q Predictions Max            1194.7733
Q Predictions Min            -6.030516
V Predictions Mean           810.53485
V Predictions Std            324.77225
V Predictions Max            1198.1775
V Predictions Min            -6.1733084
Log Pis Mean                 -0.75367963
Log Pis Std                  2.7551835
Log Pis Max                  13.548402
Log Pis Min                  -8.895459
Policy mu Mean               0.034682058
Policy mu Std                0.5082423
Policy mu Max                3.154815
Policy mu Min                -3.278677
Policy log std Mean          -0.97758573
Policy log std Std           0.19526237
Policy log std Max           -0.36681336
Policy log std Min           -1.7468157
Z mean eval                  1.1076264
Z variance eval              0.031619765
total_rewards                [2995.79822737 3284.86394682 3063.92281823  546.89129477 3103.42957283
  348.60939275 3304.85454957 3192.01333406   98.0595012  2657.29055026]
total_rewards_mean           2259.573318787423
total_rewards_std            1277.8795145882802
total_rewards_max            3304.8545495733115
total_rewards_min            98.05950119835005
Number of train steps total  604000
Number of env steps total    508381
Number of rollouts total     0
Train Time (s)               142.56352926790714
(Previous) Eval Time (s)     28.393539142794907
Sample Time (s)              11.993733201175928
Epoch Time (s)               182.95080161187798
Total Train Time (s)         27471.08420283813
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:33:43.702654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #150 | Epoch Duration: 183.04054069519043
2020-01-12 09:33:43.702881 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1022667
Z variance train             0.031788938
KL Divergence                19.736862
KL Loss                      1.9736862
QF Loss                      585.7568
VF Loss                      66.534195
Policy Loss                  -867.5685
Q Predictions Mean           864.2206
Q Predictions Std            309.8301
Q Predictions Max            1234.2468
Q Predictions Min            244.58911
V Predictions Mean           867.8115
V Predictions Std            306.74496
V Predictions Max            1212.917
V Predictions Min            260.6172
Log Pis Mean                 -0.49894857
Log Pis Std                  2.7478886
Log Pis Max                  7.8421154
Log Pis Min                  -10.263928
Policy mu Mean               -0.021964245
Policy mu Std                0.5201063
Policy mu Max                2.1461864
Policy mu Min                -2.026312
Policy log std Mean          -0.9958545
Policy log std Std           0.19380216
Policy log std Max           -0.42153424
Policy log std Min           -1.6961617
Z mean eval                  1.1097174
Z variance eval              0.0151467
total_rewards                [3001.48262664  774.29738532  498.86358749 3071.28033299 2991.20968966
 3169.104381   2904.64466644 1748.89137829 3055.66963747 1692.42481446]
total_rewards_mean           2290.786849977138
total_rewards_std            974.709013191155
total_rewards_max            3169.1043810040137
total_rewards_min            498.863587487605
Number of train steps total  608000
Number of env steps total    512833
Number of rollouts total     0
Train Time (s)               140.52427451778203
(Previous) Eval Time (s)     31.803151628933847
Sample Time (s)              11.103977801278234
Epoch Time (s)               183.4314039479941
Total Train Time (s)         27654.600804613903
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:36:47.221961 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #151 | Epoch Duration: 183.51888728141785
2020-01-12 09:36:47.222277 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1103508
Z variance train             0.015191148
KL Divergence                21.493902
KL Loss                      2.1493902
QF Loss                      613.4691
VF Loss                      178.71297
Policy Loss                  -820.3936
Q Predictions Mean           813.1757
Q Predictions Std            326.22708
Q Predictions Max            1209.6261
Q Predictions Min            120.71027
V Predictions Mean           822.7885
V Predictions Std            322.35672
V Predictions Max            1209.039
V Predictions Min            244.49744
Log Pis Mean                 -0.3128577
Log Pis Std                  3.0670257
Log Pis Max                  16.47339
Log Pis Min                  -7.6424465
Policy mu Mean               -0.00867017
Policy mu Std                0.5643791
Policy mu Max                2.9207258
Policy mu Min                -2.7287498
Policy log std Mean          -0.9810543
Policy log std Std           0.20640981
Policy log std Max           -0.25562185
Policy log std Min           -1.9527323
Z mean eval                  1.0977685
Z variance eval              0.05536903
total_rewards                [2204.9237574   910.61640094 2988.27858541 3099.85527563 3084.15513843
 3236.7534772  3248.05422818  543.15367081 1993.88144122 1854.62747747]
total_rewards_mean           2316.429945267859
total_rewards_std            939.1490923855142
total_rewards_max            3248.0542281792937
total_rewards_min            543.1536708090445
Number of train steps total  612000
Number of env steps total    517969
Number of rollouts total     0
Train Time (s)               144.8578137550503
(Previous) Eval Time (s)     26.61128841387108
Sample Time (s)              10.985820278059691
Epoch Time (s)               182.45492244698107
Total Train Time (s)         27837.145044021774
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:39:49.768233 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #152 | Epoch Duration: 182.54572772979736
2020-01-12 09:39:49.768430 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #152 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0970407
Z variance train             0.056693204
KL Divergence                18.93815
KL Loss                      1.893815
QF Loss                      581.7053
VF Loss                      636.86237
Policy Loss                  -817.17975
Q Predictions Mean           807.93097
Q Predictions Std            314.27417
Q Predictions Max            1199.8816
Q Predictions Min            -25.621967
V Predictions Mean           819.676
V Predictions Std            303.4738
V Predictions Max            1205.9513
V Predictions Min            226.02487
Log Pis Mean                 -0.18407772
Log Pis Std                  3.3992486
Log Pis Max                  18.943733
Log Pis Min                  -7.5042224
Policy mu Mean               0.019488143
Policy mu Std                0.5961057
Policy mu Max                2.8734581
Policy mu Min                -4.890771
Policy log std Mean          -0.9785911
Policy log std Std           0.2186312
Policy log std Max           -0.2580222
Policy log std Min           -2.0128367
Z mean eval                  1.1437774
Z variance eval              0.039775647
total_rewards                [3232.3421667  3144.95061078 3105.67602716 3090.88602642  310.8092016
 3086.87441861  590.90501549 2893.40990172 3148.74714188 3084.26860625]
total_rewards_mean           2568.886911661656
total_rewards_std            1063.9293972633923
total_rewards_max            3232.342166704636
total_rewards_min            310.8092015972415
Number of train steps total  616000
Number of env steps total    524074
Number of rollouts total     0
Train Time (s)               151.76234086416662
(Previous) Eval Time (s)     30.977872570976615
Sample Time (s)              10.117179282940924
Epoch Time (s)               192.85739271808416
Total Train Time (s)         28030.090344609227
Epoch                        153
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:43:02.715672 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #153 | Epoch Duration: 192.94708371162415
2020-01-12 09:43:02.715860 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1546345
Z variance train             0.040162154
KL Divergence                20.541094
KL Loss                      2.0541093
QF Loss                      987.17126
VF Loss                      211.32243
Policy Loss                  -833.63
Q Predictions Mean           831.2672
Q Predictions Std            336.06186
Q Predictions Max            1233.8744
Q Predictions Min            -50.610424
V Predictions Mean           828.7732
V Predictions Std            327.96402
V Predictions Max            1191.8372
V Predictions Min            -15.396679
Log Pis Mean                 -0.43919307
Log Pis Std                  2.9702802
Log Pis Max                  15.264405
Log Pis Min                  -7.5339637
Policy mu Mean               -0.009713763
Policy mu Std                0.53702295
Policy mu Max                3.1014457
Policy mu Min                -2.6420813
Policy log std Mean          -0.9876889
Policy log std Std           0.21858376
Policy log std Max           -0.17114496
Policy log std Min           -2.039353
Z mean eval                  1.0731735
Z variance eval              0.020829577
total_rewards                [3138.56503155 3216.48676364 1919.9333794   504.8523145  1597.70680274
 3056.32033337 1750.29873848 2008.59534294 3149.63026049 3050.96769317]
total_rewards_mean           2339.33566602677
total_rewards_std            873.6601508069787
total_rewards_max            3216.4867636378603
total_rewards_min            504.8523145027101
Number of train steps total  620000
Number of env steps total    529680
Number of rollouts total     0
Train Time (s)               151.17848840728402
(Previous) Eval Time (s)     26.960822796914726
Sample Time (s)              10.7711676126346
Epoch Time (s)               188.91047881683335
Total Train Time (s)         28219.102668492123
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:46:11.730271 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #154 | Epoch Duration: 189.01426434516907
2020-01-12 09:46:11.730454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0771053
Z variance train             0.020958502
KL Divergence                21.704453
KL Loss                      2.1704452
QF Loss                      653.468
VF Loss                      66.957466
Policy Loss                  -829.731
Q Predictions Mean           821.1423
Q Predictions Std            323.15982
Q Predictions Max            1190.1776
Q Predictions Min            241.33383
V Predictions Mean           831.6151
V Predictions Std            319.06955
V Predictions Max            1188.1615
V Predictions Min            241.61499
Log Pis Mean                 -0.7592758
Log Pis Std                  3.1354187
Log Pis Max                  11.165052
Log Pis Min                  -8.552811
Policy mu Mean               0.002649175
Policy mu Std                0.5180781
Policy mu Max                2.3641517
Policy mu Min                -2.2986362
Policy log std Mean          -0.9877397
Policy log std Std           0.22280636
Policy log std Max           -0.39531916
Policy log std Min           -1.8685378
Z mean eval                  1.1358559
Z variance eval              0.01110859
total_rewards                [3227.16565778  168.55087702 2020.95731418 3165.26276184 3107.71659891
 3056.05151517  366.24423799 2957.56113914 2193.19024736 3071.26984107]
total_rewards_mean           2333.397019046
total_rewards_std            1105.4494953216795
total_rewards_max            3227.1656577794156
total_rewards_min            168.55087702289438
Number of train steps total  624000
Number of env steps total    535376
Number of rollouts total     0
Train Time (s)               151.40658697625622
(Previous) Eval Time (s)     31.562810211908072
Sample Time (s)              11.715915687382221
Epoch Time (s)               194.68531287554651
Total Train Time (s)         28413.875176389236
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:49:26.505545 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #155 | Epoch Duration: 194.77493906021118
2020-01-12 09:49:26.507357 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #155 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1375511
Z variance train             0.010989001
KL Divergence                23.025513
KL Loss                      2.3025513
QF Loss                      764.98474
VF Loss                      231.70508
Policy Loss                  -843.30115
Q Predictions Mean           835.7981
Q Predictions Std            321.90588
Q Predictions Max            1203.2814
Q Predictions Min            -4.111983
V Predictions Mean           843.30286
V Predictions Std            316.64273
V Predictions Max            1198.7347
V Predictions Min            188.61644
Log Pis Mean                 -0.39630762
Log Pis Std                  3.2343285
Log Pis Max                  24.54745
Log Pis Min                  -7.2498198
Policy mu Mean               0.011985674
Policy mu Std                0.5521013
Policy mu Max                3.5951304
Policy mu Min                -2.5365598
Policy log std Mean          -0.9848338
Policy log std Std           0.2123308
Policy log std Max           -0.39525908
Policy log std Min           -2.0655513
Z mean eval                  1.1113024
Z variance eval              0.0065387907
total_rewards                [ 816.64422497 3309.97173534 1637.28174465 2042.94515552 3069.0623166
 2523.68576032  170.27897041 3140.14850686 2372.28168612 1346.41056476]
total_rewards_mean           2042.87106655659
total_rewards_std            993.0819630431885
total_rewards_max            3309.9717353443534
total_rewards_min            170.27897041306682
Number of train steps total  628000
Number of env steps total    540474
Number of rollouts total     0
Train Time (s)               150.73696007905528
(Previous) Eval Time (s)     22.77338460739702
Sample Time (s)              12.326258129440248
Epoch Time (s)               185.83660281589255
Total Train Time (s)         28599.79977180669
Epoch                        156
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:52:32.433619 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #156 | Epoch Duration: 185.92591786384583
2020-01-12 09:52:32.433937 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1147865
Z variance train             0.0065463544
KL Divergence                23.567495
KL Loss                      2.3567495
QF Loss                      616.6174
VF Loss                      99.23217
Policy Loss                  -836.41986
Q Predictions Mean           833.69507
Q Predictions Std            320.06436
Q Predictions Max            1222.866
Q Predictions Min            23.422276
V Predictions Mean           837.4178
V Predictions Std            317.88312
V Predictions Max            1199.826
V Predictions Min            185.14784
Log Pis Mean                 -0.67057925
Log Pis Std                  3.30801
Log Pis Max                  11.971031
Log Pis Min                  -11.651594
Policy mu Mean               -0.0093498
Policy mu Std                0.53797156
Policy mu Max                2.372169
Policy mu Min                -2.710981
Policy log std Mean          -1.0108142
Policy log std Std           0.20907743
Policy log std Max           -0.51317626
Policy log std Min           -2.08232
Z mean eval                  1.0689704
Z variance eval              0.0426067
total_rewards                [ 773.37061072 2763.94700122  604.16810964 1941.07357964  690.08025606
 1362.88049438 1356.73879162  624.75440991 1502.74305065  536.08430657]
total_rewards_mean           1215.5840610411683
total_rewards_std            685.87025463609
total_rewards_max            2763.9470012169677
total_rewards_min            536.0843065727096
Number of train steps total  632000
Number of env steps total    546467
Number of rollouts total     0
Train Time (s)               141.81943471403793
(Previous) Eval Time (s)     23.12898707203567
Sample Time (s)              11.12319016829133
Epoch Time (s)               176.07161195436493
Total Train Time (s)         28775.961638795678
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:55:28.597047 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #157 | Epoch Duration: 176.16291785240173
2020-01-12 09:55:28.597252 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0677396
Z variance train             0.042750306
KL Divergence                19.427773
KL Loss                      1.9427773
QF Loss                      787.30743
VF Loss                      148.77092
Policy Loss                  -849.4911
Q Predictions Mean           846.63983
Q Predictions Std            306.0845
Q Predictions Max            1203.2124
Q Predictions Min            -35.75168
V Predictions Mean           850.6041
V Predictions Std            301.19662
V Predictions Max            1181.1699
V Predictions Min            -7.356078
Log Pis Mean                 -0.35442653
Log Pis Std                  3.0228202
Log Pis Max                  14.838769
Log Pis Min                  -7.209152
Policy mu Mean               -0.018383607
Policy mu Std                0.5570893
Policy mu Max                2.2742558
Policy mu Min                -2.552504
Policy log std Mean          -0.9888567
Policy log std Std           0.2050471
Policy log std Max           -0.28049082
Policy log std Min           -1.9649624
Z mean eval                  1.1298846
Z variance eval              0.009703668
total_rewards                [1678.06186861 1632.45279852  664.78972082  634.39192421  140.11802471
 1387.73400674 3113.89670831 1876.16874676 1132.05374024  764.71431924]
total_rewards_mean           1302.4381858162967
total_rewards_std            799.3668903239712
total_rewards_max            3113.896708306212
total_rewards_min            140.11802471181306
Number of train steps total  636000
Number of env steps total    549977
Number of rollouts total     0
Train Time (s)               141.57576686842367
(Previous) Eval Time (s)     24.972805961035192
Sample Time (s)              12.390757335815579
Epoch Time (s)               178.93933016527444
Total Train Time (s)         28954.98708834499
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:58:27.625403 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #158 | Epoch Duration: 179.02794194221497
2020-01-12 09:58:27.625658 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1336854
Z variance train             0.009700157
KL Divergence                22.026062
KL Loss                      2.2026062
QF Loss                      680.4155
VF Loss                      99.51518
Policy Loss                  -818.7432
Q Predictions Mean           809.08405
Q Predictions Std            338.02118
Q Predictions Max            1209.8364
Q Predictions Min            49.55529
V Predictions Mean           816.78973
V Predictions Std            330.74377
V Predictions Max            1196.7927
V Predictions Min            215.80502
Log Pis Mean                 -0.79783446
Log Pis Std                  3.1054242
Log Pis Max                  18.773335
Log Pis Min                  -9.231824
Policy mu Mean               -0.015057372
Policy mu Std                0.5350823
Policy mu Max                3.1919394
Policy mu Min                -3.1823347
Policy log std Mean          -0.9746157
Policy log std Std           0.20123754
Policy log std Max           -0.26804334
Policy log std Min           -1.8613657
Z mean eval                  1.0696326
Z variance eval              0.012413253
total_rewards                [3159.822988    471.91691571 1284.95835373 1844.27176242 3112.65508916
 3178.95348013 1868.73423697 1186.08177837 2590.61686819  147.64139701]
total_rewards_mean           1884.5652869687797
total_rewards_std            1056.8915882434032
total_rewards_max            3178.9534801303334
total_rewards_min            147.64139700932128
Number of train steps total  640000
Number of env steps total    554335
Number of rollouts total     0
Train Time (s)               146.7981078820303
(Previous) Eval Time (s)     31.605165938846767
Sample Time (s)              11.42635775078088
Epoch Time (s)               189.82963157165796
Total Train Time (s)         29144.92365772184
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:01:37.564840 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #159 | Epoch Duration: 189.93900656700134
2020-01-12 10:01:37.565063 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #159 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0681272
Z variance train             0.01253475
KL Divergence                21.331919
KL Loss                      2.1331918
QF Loss                      801.4905
VF Loss                      268.94708
Policy Loss                  -840.0173
Q Predictions Mean           833.5857
Q Predictions Std            327.33295
Q Predictions Max            1220.6106
Q Predictions Min            189.59453
V Predictions Mean           842.93555
V Predictions Std            320.6647
V Predictions Max            1223.5452
V Predictions Min            267.0891
Log Pis Mean                 -0.5285949
Log Pis Std                  3.0469427
Log Pis Max                  13.038717
Log Pis Min                  -7.9049234
Policy mu Mean               0.008187764
Policy mu Std                0.56042606
Policy mu Max                2.5043597
Policy mu Min                -3.0934799
Policy log std Mean          -0.9749569
Policy log std Std           0.21482675
Policy log std Max           -0.39687395
Policy log std Min           -1.9577093
Z mean eval                  1.1561692
Z variance eval              0.009112755
total_rewards                [3129.39004017  540.69297734 2769.12276882 2820.83489467  828.5183936
 3103.78588564  457.59631713 3009.4464275   514.02255569 3079.4949304 ]
total_rewards_mean           2025.2905190961276
total_rewards_std            1184.3210890469436
total_rewards_max            3129.3900401675414
total_rewards_min            457.59631713349063
Number of train steps total  644000
Number of env steps total    559096
Number of rollouts total     0
Train Time (s)               150.69106105994433
(Previous) Eval Time (s)     36.48718186188489
Sample Time (s)              11.72628459893167
Epoch Time (s)               198.9045275207609
Total Train Time (s)         29343.917699753307
Epoch                        160
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:04:56.561239 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #160 | Epoch Duration: 198.99601697921753
2020-01-12 10:04:56.561430 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1612742
Z variance train             0.009118113
KL Divergence                22.02735
KL Loss                      2.202735
QF Loss                      571.9667
VF Loss                      104.87035
Policy Loss                  -813.14844
Q Predictions Mean           807.39856
Q Predictions Std            336.37427
Q Predictions Max            1236.3289
Q Predictions Min            162.28706
V Predictions Mean           812.6382
V Predictions Std            332.38443
V Predictions Max            1239.298
V Predictions Min            221.4952
Log Pis Mean                 -0.4120309
Log Pis Std                  3.5740018
Log Pis Max                  18.473076
Log Pis Min                  -8.134787
Policy mu Mean               -0.0062699486
Policy mu Std                0.56536245
Policy mu Max                2.9038298
Policy mu Min                -3.1835182
Policy log std Mean          -0.97363925
Policy log std Std           0.22905514
Policy log std Max           -0.4125588
Policy log std Min           -2.1886764
Z mean eval                  1.1284025
Z variance eval              0.030519009
total_rewards                [1736.23478651   97.47613016 3199.71853291 3349.50974555 3146.13434871
 2190.73109804 2755.72885625 1024.32559766 3363.42136158 2498.21964816]
total_rewards_mean           2336.1500105523924
total_rewards_std            1039.2262288052286
total_rewards_max            3363.4213615776084
total_rewards_min            97.4761301622105
Number of train steps total  648000
Number of env steps total    564995
Number of rollouts total     0
Train Time (s)               150.49444757588208
(Previous) Eval Time (s)     25.869229645933956
Sample Time (s)              11.552600335329771
Epoch Time (s)               187.9162775571458
Total Train Time (s)         29531.922289494425
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:08:04.568282 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #161 | Epoch Duration: 188.00669193267822
2020-01-12 10:08:04.568539 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1313031
Z variance train             0.030616503
KL Divergence                19.51987
KL Loss                      1.9519871
QF Loss                      773.2929
VF Loss                      136.05164
Policy Loss                  -828.271
Q Predictions Mean           821.9607
Q Predictions Std            332.4065
Q Predictions Max            1215.1847
Q Predictions Min            253.87248
V Predictions Mean           828.5929
V Predictions Std            330.61075
V Predictions Max            1216.9783
V Predictions Min            262.918
Log Pis Mean                 -0.67424434
Log Pis Std                  3.0722635
Log Pis Max                  13.588464
Log Pis Min                  -6.344305
Policy mu Mean               0.012633206
Policy mu Std                0.53363794
Policy mu Max                2.8068247
Policy mu Min                -2.4380655
Policy log std Mean          -0.96530616
Policy log std Std           0.2130126
Policy log std Max           -0.27016854
Policy log std Min           -2.0244966
Z mean eval                  1.0868454
Z variance eval              0.018592287
total_rewards                [2915.55014846 1665.6457911   822.23493128 1077.76217669  317.04641308
 1385.3714524   493.77400218 3364.07386259 2419.40124735 1445.42639229]
total_rewards_mean           1590.6286417418519
total_rewards_std            966.1673488885951
total_rewards_max            3364.0738625912654
total_rewards_min            317.04641308118624
Number of train steps total  652000
Number of env steps total    571806
Number of rollouts total     0
Train Time (s)               151.40847667399794
(Previous) Eval Time (s)     26.21135544916615
Sample Time (s)              11.523203015327454
Epoch Time (s)               189.14303513849154
Total Train Time (s)         29721.150899169967
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:11:13.798896 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #162 | Epoch Duration: 189.23019886016846
2020-01-12 10:11:13.799087 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0807571
Z variance train             0.01844692
KL Divergence                20.270462
KL Loss                      2.0270462
QF Loss                      621.38184
VF Loss                      137.83551
Policy Loss                  -831.8614
Q Predictions Mean           825.7564
Q Predictions Std            342.1145
Q Predictions Max            1217.1437
Q Predictions Min            -5.5167108
V Predictions Mean           833.7927
V Predictions Std            338.0368
V Predictions Max            1221.866
V Predictions Min            69.24776
Log Pis Mean                 -0.6536863
Log Pis Std                  2.864786
Log Pis Max                  11.0231495
Log Pis Min                  -6.593418
Policy mu Mean               -0.023990812
Policy mu Std                0.53184134
Policy mu Max                2.7622066
Policy mu Min                -2.8790617
Policy log std Mean          -0.97100127
Policy log std Std           0.21205187
Policy log std Max           -0.4588325
Policy log std Min           -1.7637911
Z mean eval                  1.0450404
Z variance eval              0.023326958
total_rewards                [1799.36739192  433.58009778 1728.64459008 3183.34615865 3103.12048197
  988.49119485 3181.08314159 3088.39066483 1538.8763459  1562.35180515]
total_rewards_mean           2060.7251872738825
total_rewards_std            956.803982725173
total_rewards_max            3183.3461586506037
total_rewards_min            433.58009778056254
Number of train steps total  656000
Number of env steps total    578178
Number of rollouts total     0
Train Time (s)               149.46066272072494
(Previous) Eval Time (s)     27.889274589717388
Sample Time (s)              11.681494558695704
Epoch Time (s)               189.03143186913803
Total Train Time (s)         29910.298349244054
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:14:22.948935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #163 | Epoch Duration: 189.14970111846924
2020-01-12 10:14:22.949156 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0485306
Z variance train             0.023708984
KL Divergence                19.69799
KL Loss                      1.969799
QF Loss                      463.08713
VF Loss                      156.57904
Policy Loss                  -863.31537
Q Predictions Mean           854.0432
Q Predictions Std            336.85178
Q Predictions Max            1224.2333
Q Predictions Min            -30.150822
V Predictions Mean           854.62915
V Predictions Std            327.27603
V Predictions Max            1218.9775
V Predictions Min            193.74078
Log Pis Mean                 -0.524288
Log Pis Std                  2.6715991
Log Pis Max                  13.198981
Log Pis Min                  -8.48695
Policy mu Mean               -0.021293074
Policy mu Std                0.538356
Policy mu Max                2.261596
Policy mu Min                -3.4197412
Policy log std Mean          -0.97083485
Policy log std Std           0.19079849
Policy log std Max           -0.39685225
Policy log std Min           -2.0134563
Z mean eval                  1.1157272
Z variance eval              0.010067264
total_rewards                [3249.35927626 1094.83983999 1360.82258709 2160.58659068  449.52732896
 3221.45038762 3273.6583308   109.66847259 3315.23962399 1191.55325904]
total_rewards_mean           1942.6705697023767
total_rewards_std            1194.0096097016203
total_rewards_max            3315.2396239853333
total_rewards_min            109.66847259265812
Number of train steps total  660000
Number of env steps total    585071
Number of rollouts total     0
Train Time (s)               141.2832118878141
(Previous) Eval Time (s)     26.978307457175106
Sample Time (s)              10.966658955905586
Epoch Time (s)               179.2281783008948
Total Train Time (s)         30089.613556326833
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:17:22.269646 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #164 | Epoch Duration: 179.32030606269836
2020-01-12 10:17:22.270020 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1206919
Z variance train             0.009956064
KL Divergence                21.109818
KL Loss                      2.1109817
QF Loss                      639.657
VF Loss                      234.18825
Policy Loss                  -855.40076
Q Predictions Mean           847.501
Q Predictions Std            333.94
Q Predictions Max            1232.1722
Q Predictions Min            264.43637
V Predictions Mean           859.06946
V Predictions Std            329.56296
V Predictions Max            1232.5149
V Predictions Min            274.037
Log Pis Mean                 -0.17267887
Log Pis Std                  3.869449
Log Pis Max                  24.316465
Log Pis Min                  -7.549432
Policy mu Mean               -0.030397065
Policy mu Std                0.60399723
Policy mu Max                2.8839822
Policy mu Min                -3.3724422
Policy log std Mean          -0.9707145
Policy log std Std           0.22042817
Policy log std Max           -0.19677639
Policy log std Min           -2.235439
Z mean eval                  1.0039771
Z variance eval              0.011816181
total_rewards                [2190.95902125 3138.1538631  3080.55404569 1458.12264018 1481.89631655
 1056.63291211  646.31220079 3135.06143062 2100.57035285  527.91936495]
total_rewards_mean           1881.6182148083542
total_rewards_std            954.425953242522
total_rewards_max            3138.153863096385
total_rewards_min            527.9193649541207
Number of train steps total  664000
Number of env steps total    590878
Number of rollouts total     0
Train Time (s)               140.9251157050021
(Previous) Eval Time (s)     31.223386588972062
Sample Time (s)              11.42608178826049
Epoch Time (s)               183.57458408223465
Total Train Time (s)         30273.2904650867
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:20:25.949002 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #165 | Epoch Duration: 183.6787030696869
2020-01-12 10:20:25.949270 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0081378
Z variance train             0.011767386
KL Divergence                21.692959
KL Loss                      2.169296
QF Loss                      507.34888
VF Loss                      110.20311
Policy Loss                  -860.1677
Q Predictions Mean           855.51135
Q Predictions Std            346.71338
Q Predictions Max            1242.8986
Q Predictions Min            59.001896
V Predictions Mean           857.13586
V Predictions Std            342.54056
V Predictions Max            1240.4752
V Predictions Min            188.37236
Log Pis Mean                 -0.6857536
Log Pis Std                  2.718555
Log Pis Max                  13.267487
Log Pis Min                  -7.5137296
Policy mu Mean               -0.0214655
Policy mu Std                0.5157225
Policy mu Max                3.6262865
Policy mu Min                -2.5953057
Policy log std Mean          -0.9679173
Policy log std Std           0.20581281
Policy log std Max           -0.42590654
Policy log std Min           -2.2138648
Z mean eval                  1.1933308
Z variance eval              0.008205074
total_rewards                [3243.66079469 3241.26214484  729.09423356 1170.73229453  786.61194704
  710.5231778  2824.89394475 1831.97411698 1646.63872315 1064.78502582]
total_rewards_mean           1725.0176403152868
total_rewards_std            973.5189929842749
total_rewards_max            3243.6607946875406
total_rewards_min            710.5231778010634
Number of train steps total  668000
Number of env steps total    596238
Number of rollouts total     0
Train Time (s)               149.20020028809085
(Previous) Eval Time (s)     26.506604885682464
Sample Time (s)              12.406692368909717
Epoch Time (s)               188.11349754268304
Total Train Time (s)         30461.4974890789
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:23:34.159285 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #166 | Epoch Duration: 188.2097749710083
2020-01-12 10:23:34.159660 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1901915
Z variance train             0.008311338
KL Divergence                22.913174
KL Loss                      2.2913175
QF Loss                      693.63074
VF Loss                      438.60233
Policy Loss                  -864.2876
Q Predictions Mean           856.3766
Q Predictions Std            334.9778
Q Predictions Max            1218.6604
Q Predictions Min            0.35322618
V Predictions Mean           862.3068
V Predictions Std            324.22403
V Predictions Max            1213.1986
V Predictions Min            -3.9135752
Log Pis Mean                 -0.3091572
Log Pis Std                  3.8134375
Log Pis Max                  26.146805
Log Pis Min                  -8.316294
Policy mu Mean               0.033889808
Policy mu Std                0.58491987
Policy mu Max                4.03586
Policy mu Min                -3.8129888
Policy log std Mean          -0.9763348
Policy log std Std           0.21694656
Policy log std Max           -0.30653417
Policy log std Min           -2.2018147
Z mean eval                  1.0188122
Z variance eval              0.034967773
total_rewards                [2879.46001935 2539.42191508  524.86496593 1951.93538873 3117.55377267
 2001.25290771 1500.47520699 3110.49543849 2985.15500622 3120.79850187]
total_rewards_mean           2373.141312303499
total_rewards_std            825.1537992797864
total_rewards_max            3120.7985018732516
total_rewards_min            524.864965925244
Number of train steps total  672000
Number of env steps total    604517
Number of rollouts total     0
Train Time (s)               150.32516769925132
(Previous) Eval Time (s)     32.30423727212474
Sample Time (s)              12.64185668155551
Epoch Time (s)               195.27126165293157
Total Train Time (s)         30656.86080244137
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:26:49.522733 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #167 | Epoch Duration: 195.36287379264832
2020-01-12 10:26:49.522877 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0197318
Z variance train             0.035113804
KL Divergence                19.138233
KL Loss                      1.9138234
QF Loss                      544.46765
VF Loss                      96.4263
Policy Loss                  -793.7903
Q Predictions Mean           788.5166
Q Predictions Std            354.9894
Q Predictions Max            1228.1234
Q Predictions Min            5.814343
V Predictions Mean           790.83545
V Predictions Std            352.60754
V Predictions Max            1223.8717
V Predictions Min            215.32574
Log Pis Mean                 -0.9442637
Log Pis Std                  2.7870293
Log Pis Max                  9.510321
Log Pis Min                  -7.7970066
Policy mu Mean               -0.040286876
Policy mu Std                0.51842403
Policy mu Max                2.4060276
Policy mu Min                -2.1729894
Policy log std Mean          -0.9447422
Policy log std Std           0.20818081
Policy log std Max           -0.3807006
Policy log std Min           -1.8511456
Z mean eval                  1.0705808
Z variance eval              0.010738514
total_rewards                [1411.36044212 3149.45238403 1347.54454339 2980.487101    379.75413122
 3100.2362281  1173.30930195  468.19778312  449.27578894  998.99012634]
total_rewards_mean           1545.8607830221365
total_rewards_std            1061.3521765715336
total_rewards_max            3149.452384033857
total_rewards_min            379.75413121551196
Number of train steps total  676000
Number of env steps total    609451
Number of rollouts total     0
Train Time (s)               149.8417543657124
(Previous) Eval Time (s)     31.808534920215607
Sample Time (s)              12.655200301669538
Epoch Time (s)               194.30548958759755
Total Train Time (s)         30851.261859737337
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:30:03.928176 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #168 | Epoch Duration: 194.40512990951538
2020-01-12 10:30:03.928518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0739768
Z variance train             0.010734566
KL Divergence                21.40255
KL Loss                      2.140255
QF Loss                      2073.234
VF Loss                      234.93797
Policy Loss                  -876.58954
Q Predictions Mean           866.74475
Q Predictions Std            311.86658
Q Predictions Max            1227.6455
Q Predictions Min            208.17056
V Predictions Mean           878.9895
V Predictions Std            308.4489
V Predictions Max            1238.5486
V Predictions Min            204.71356
Log Pis Mean                 -0.21698211
Log Pis Std                  3.3724601
Log Pis Max                  20.276882
Log Pis Min                  -7.864152
Policy mu Mean               0.008769847
Policy mu Std                0.58496
Policy mu Max                3.1578186
Policy mu Min                -3.0131507
Policy log std Mean          -0.9840089
Policy log std Std           0.22057553
Policy log std Max           -0.2699737
Policy log std Min           -2.361929
Z mean eval                  1.0639586
Z variance eval              0.014552765
total_rewards                [1668.99533198 3147.84903968  594.9231167   940.88096143 1108.14244179
 3198.92047369 3112.76429109 3033.37276768  219.87624554 3142.48382197]
total_rewards_mean           2016.8208491557002
total_rewards_std            1163.3271250960022
total_rewards_max            3198.920473688152
total_rewards_min            219.87624554359604
Number of train steps total  680000
Number of env steps total    617320
Number of rollouts total     0
Train Time (s)               150.44002749305218
(Previous) Eval Time (s)     23.680578334257007
Sample Time (s)              12.131611990742385
Epoch Time (s)               186.25221781805158
Total Train Time (s)         31037.606232952792
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:33:10.274538 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #169 | Epoch Duration: 186.34583449363708
2020-01-12 10:33:10.274724 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0584087
Z variance train             0.014606744
KL Divergence                20.516466
KL Loss                      2.0516467
QF Loss                      635.1787
VF Loss                      126.94581
Policy Loss                  -867.17993
Q Predictions Mean           860.73834
Q Predictions Std            323.41986
Q Predictions Max            1246.0426
Q Predictions Min            38.1873
V Predictions Mean           864.70325
V Predictions Std            318.53885
V Predictions Max            1246.6377
V Predictions Min            -41.95686
Log Pis Mean                 -0.44382828
Log Pis Std                  3.196976
Log Pis Max                  18.316883
Log Pis Min                  -8.031166
Policy mu Mean               0.013124916
Policy mu Std                0.56310856
Policy mu Max                2.6844583
Policy mu Min                -4.0848455
Policy log std Mean          -0.9764823
Policy log std Std           0.21331821
Policy log std Max           -0.3849144
Policy log std Min           -2.1694584
Z mean eval                  1.1891725
Z variance eval              0.013773998
total_rewards                [2017.70727624 1203.08459371 2961.62560508 3186.04683284 1131.14763243
 3118.23805144 2981.3208353  3129.51556773 2845.36009954  716.4919643 ]
total_rewards_mean           2329.053845860713
total_rewards_std            921.4248544047623
total_rewards_max            3186.046832836536
total_rewards_min            716.4919643025471
Number of train steps total  684000
Number of env steps total    624091
Number of rollouts total     0
Train Time (s)               146.46746766380966
(Previous) Eval Time (s)     29.71187987923622
Sample Time (s)              11.639588795602322
Epoch Time (s)               187.8189363386482
Total Train Time (s)         31225.518743570894
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:36:18.189603 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #170 | Epoch Duration: 187.9147288799286
2020-01-12 10:36:18.189806 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.182092
Z variance train             0.013929208
KL Divergence                21.263794
KL Loss                      2.1263795
QF Loss                      1665.3105
VF Loss                      648.1735
Policy Loss                  -868.6311
Q Predictions Mean           859.13367
Q Predictions Std            332.1978
Q Predictions Max            1248.6201
Q Predictions Min            33.89097
V Predictions Mean           878.3622
V Predictions Std            323.67822
V Predictions Max            1251.154
V Predictions Min            56.52217
Log Pis Mean                 -0.14405403
Log Pis Std                  3.1862898
Log Pis Max                  14.54081
Log Pis Min                  -9.431418
Policy mu Mean               -0.029182516
Policy mu Std                0.57848054
Policy mu Max                3.6892412
Policy mu Min                -3.4689333
Policy log std Mean          -1.0077553
Policy log std Std           0.23528402
Policy log std Max           -0.35550314
Policy log std Min           -2.3649485
Z mean eval                  1.2306563
Z variance eval              0.017827822
total_rewards                [2798.40642434 1670.86706801  746.44640241 2298.79721153 3038.42177972
  434.74249842 3264.78877811 2622.77732507  365.13288791  206.94924235]
total_rewards_mean           1744.7329617860246
total_rewards_std            1147.1076529854956
total_rewards_max            3264.78877810766
total_rewards_min            206.94924235406714
Number of train steps total  688000
Number of env steps total    628620
Number of rollouts total     0
Train Time (s)               141.23819863284007
(Previous) Eval Time (s)     28.65375276422128
Sample Time (s)              10.651243435684592
Epoch Time (s)               180.54319483274594
Total Train Time (s)         31406.160399211105
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:39:18.833582 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #171 | Epoch Duration: 180.64361882209778
2020-01-12 10:39:18.833790 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2244904
Z variance train             0.018072924
KL Divergence                21.12846
KL Loss                      2.1128461
QF Loss                      1030.5815
VF Loss                      427.50967
Policy Loss                  -885.0974
Q Predictions Mean           876.839
Q Predictions Std            321.7414
Q Predictions Max            1279.3007
Q Predictions Min            -28.452911
V Predictions Mean           888.8749
V Predictions Std            320.72064
V Predictions Max            1293.0472
V Predictions Min            -28.368002
Log Pis Mean                 -0.2349211
Log Pis Std                  3.1134207
Log Pis Max                  21.549072
Log Pis Min                  -6.527759
Policy mu Mean               -0.0010456576
Policy mu Std                0.576468
Policy mu Max                3.78729
Policy mu Min                -2.637654
Policy log std Mean          -0.983235
Policy log std Std           0.22170618
Policy log std Max           -0.26431787
Policy log std Min           -1.9535471
Z mean eval                  1.1459744
Z variance eval              0.016265824
total_rewards                [3083.17125539 3122.90192628 3132.34727899   43.90282414 3028.04568696
 3167.71211401 3144.28522148  389.90056851 2014.62643971 3040.19529752]
total_rewards_mean           2416.7088613002315
total_rewards_std            1149.37770241744
total_rewards_max            3167.7121140127974
total_rewards_min            43.90282414055348
Number of train steps total  692000
Number of env steps total    633287
Number of rollouts total     0
Train Time (s)               142.11648711701855
(Previous) Eval Time (s)     27.585085663944483
Sample Time (s)              11.731971809174865
Epoch Time (s)               181.4335445901379
Total Train Time (s)         31587.68758200109
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:42:20.364026 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #172 | Epoch Duration: 181.53008151054382
2020-01-12 10:42:20.364272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.149934
Z variance train             0.016545707
KL Divergence                20.902311
KL Loss                      2.0902312
QF Loss                      1145.1045
VF Loss                      100.23943
Policy Loss                  -843.8185
Q Predictions Mean           838.76135
Q Predictions Std            357.46033
Q Predictions Max            1225.429
Q Predictions Min            -28.960846
V Predictions Mean           843.5614
V Predictions Std            353.5442
V Predictions Max            1222.6403
V Predictions Min            -15.726723
Log Pis Mean                 -0.6033193
Log Pis Std                  3.0557394
Log Pis Max                  17.295734
Log Pis Min                  -8.160171
Policy mu Mean               -0.040364895
Policy mu Std                0.5545871
Policy mu Max                5.65138
Policy mu Min                -2.385737
Policy log std Mean          -0.9781021
Policy log std Std           0.21094674
Policy log std Max           -0.24751073
Policy log std Min           -1.91827
Z mean eval                  1.1076978
Z variance eval              0.0132840155
total_rewards                [1980.76166206 1004.99427407  432.11809628 1238.98810786  436.36248465
 3131.73720973  859.69129582 1463.1670116  2319.29879555  632.6016119 ]
total_rewards_mean           1349.9720549533527
total_rewards_std            841.929393774178
total_rewards_max            3131.737209732679
total_rewards_min            432.1180962782002
Number of train steps total  696000
Number of env steps total    641849
Number of rollouts total     0
Train Time (s)               150.3959006536752
(Previous) Eval Time (s)     26.81308984803036
Sample Time (s)              11.289082132745534
Epoch Time (s)               188.4980726344511
Total Train Time (s)         31776.29148914758
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:45:28.971401 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #173 | Epoch Duration: 188.60692238807678
2020-01-12 10:45:28.971760 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1117532
Z variance train             0.013243651
KL Divergence                21.096811
KL Loss                      2.1096811
QF Loss                      492.19223
VF Loss                      93.83022
Policy Loss                  -906.7041
Q Predictions Mean           900.3528
Q Predictions Std            329.99606
Q Predictions Max            1260.568
Q Predictions Min            236.245
V Predictions Mean           905.5935
V Predictions Std            322.3853
V Predictions Max            1264.0614
V Predictions Min            208.34033
Log Pis Mean                 -0.34977055
Log Pis Std                  3.0637434
Log Pis Max                  13.565114
Log Pis Min                  -11.652405
Policy mu Mean               0.020874519
Policy mu Std                0.56581753
Policy mu Max                2.8193712
Policy mu Min                -2.5663452
Policy log std Mean          -0.9837785
Policy log std Std           0.20718509
Policy log std Max           -0.41577095
Policy log std Min           -2.2492626
Z mean eval                  1.0836707
Z variance eval              0.011168128
total_rewards                [ 894.55911137  631.23295834  704.83099572 2110.23307028 2714.34299221
  234.79193916  590.90487721  713.78518544 3235.29574405 1170.29498557]
total_rewards_mean           1300.0271859356785
total_rewards_std            967.7823338329156
total_rewards_max            3235.2957440493055
total_rewards_min            234.79193916118058
Number of train steps total  700000
Number of env steps total    646716
Number of rollouts total     0
Train Time (s)               150.01592706004158
(Previous) Eval Time (s)     20.92790629575029
Sample Time (s)              12.2879733950831
Epoch Time (s)               183.23180675087497
Total Train Time (s)         31959.611453760415
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:48:32.293525 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #174 | Epoch Duration: 183.3214979171753
2020-01-12 10:48:32.293715 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0810246
Z variance train             0.011113601
KL Divergence                21.830664
KL Loss                      2.1830664
QF Loss                      893.6666
VF Loss                      164.38077
Policy Loss                  -883.5959
Q Predictions Mean           873.44037
Q Predictions Std            330.17627
Q Predictions Max            1259.9131
Q Predictions Min            -9.974417
V Predictions Mean           884.0073
V Predictions Std            319.29114
V Predictions Max            1256.1935
V Predictions Min            64.04076
Log Pis Mean                 -0.28226164
Log Pis Std                  3.8377361
Log Pis Max                  21.023355
Log Pis Min                  -7.2332997
Policy mu Mean               0.010995356
Policy mu Std                0.60421884
Policy mu Max                3.020705
Policy mu Min                -4.4942036
Policy log std Mean          -0.9827899
Policy log std Std           0.24315377
Policy log std Max           -0.36881846
Policy log std Min           -2.6152782
Z mean eval                  1.0753219
Z variance eval              0.023360632
total_rewards                [3207.18777999 3203.42367602  903.8534446  3068.69322828 3196.41236971
  352.1721258  2547.44474639 3189.25967023 3346.06337933 2959.4650102 ]
total_rewards_mean           2597.39754305551
total_rewards_std            1013.5861297742745
total_rewards_max            3346.0633793314923
total_rewards_min            352.1721257997492
Number of train steps total  704000
Number of env steps total    652338
Number of rollouts total     0
Train Time (s)               148.82587977405638
(Previous) Eval Time (s)     33.66441651294008
Sample Time (s)              11.71252993028611
Epoch Time (s)               194.20282621728256
Total Train Time (s)         32153.898388961796
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:51:46.581532 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #175 | Epoch Duration: 194.28768396377563
2020-01-12 10:51:46.581681 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0740931
Z variance train             0.023331543
KL Divergence                20.0569
KL Loss                      2.00569
QF Loss                      569.8011
VF Loss                      272.8021
Policy Loss                  -887.366
Q Predictions Mean           884.14923
Q Predictions Std            348.87387
Q Predictions Max            1253.802
Q Predictions Min            -16.952015
V Predictions Mean           882.1757
V Predictions Std            343.8642
V Predictions Max            1240.0902
V Predictions Min            -24.656721
Log Pis Mean                 -0.15496877
Log Pis Std                  3.2914736
Log Pis Max                  15.970392
Log Pis Min                  -6.6665864
Policy mu Mean               0.0135281235
Policy mu Std                0.56659764
Policy mu Max                2.9621084
Policy mu Min                -3.3189213
Policy log std Mean          -0.98862636
Policy log std Std           0.23570055
Policy log std Max           -0.42615473
Policy log std Min           -2.176118
Z mean eval                  1.1557825
Z variance eval              0.006564413
total_rewards                [ 121.31326226 1046.04724578 1348.05188257  779.26486981  716.36885158
 2886.4740009  3263.53862212  321.54813399 3067.5572477   149.38975378]
total_rewards_mean           1369.9553870490781
total_rewards_std            1174.600806008545
total_rewards_max            3263.5386221230483
total_rewards_min            121.31326226278267
Number of train steps total  708000
Number of env steps total    656823
Number of rollouts total     0
Train Time (s)               150.2069992031902
(Previous) Eval Time (s)     20.464693679939955
Sample Time (s)              12.201441495679319
Epoch Time (s)               182.87313437880948
Total Train Time (s)         32337.022504931316
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:54:49.708767 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #176 | Epoch Duration: 183.12696933746338
2020-01-12 10:54:49.708975 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.156656
Z variance train             0.0065314085
KL Divergence                23.477964
KL Loss                      2.3477964
QF Loss                      855.6699
VF Loss                      164.22601
Policy Loss                  -876.25726
Q Predictions Mean           866.7373
Q Predictions Std            342.23322
Q Predictions Max            1259.6962
Q Predictions Min            -49.58784
V Predictions Mean           874.3875
V Predictions Std            333.03363
V Predictions Max            1255.2506
V Predictions Min            278.87656
Log Pis Mean                 -0.14931644
Log Pis Std                  3.4900851
Log Pis Max                  17.30114
Log Pis Min                  -7.949586
Policy mu Mean               0.04957475
Policy mu Std                0.60165256
Policy mu Max                2.4351466
Policy mu Min                -2.7527876
Policy log std Mean          -0.98010874
Policy log std Std           0.22884102
Policy log std Max           -0.40329295
Policy log std Min           -2.2606595
Z mean eval                  1.1003226
Z variance eval              0.020869222
total_rewards                [2156.06264235 1285.15312561  127.31137382  150.78902216 3124.90508547
 1801.83534618  733.99738136  671.85617278  754.87248311 3117.32339126]
total_rewards_mean           1392.4106024095408
total_rewards_std            1060.2084796977645
total_rewards_max            3124.9050854683046
total_rewards_min            127.31137382352146
Number of train steps total  712000
Number of env steps total    662693
Number of rollouts total     0
Train Time (s)               144.80082961916924
(Previous) Eval Time (s)     19.66176605504006
Sample Time (s)              12.70110370637849
Epoch Time (s)               177.1636993805878
Total Train Time (s)         32514.2725039972
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:57:46.961604 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #177 | Epoch Duration: 177.25248551368713
2020-01-12 10:57:46.961792 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1065614
Z variance train             0.020997778
KL Divergence                19.911562
KL Loss                      1.9911562
QF Loss                      881.5096
VF Loss                      183.66081
Policy Loss                  -848.88654
Q Predictions Mean           838.58685
Q Predictions Std            342.87485
Q Predictions Max            1224.2439
Q Predictions Min            -42.109108
V Predictions Mean           843.6168
V Predictions Std            334.88412
V Predictions Max            1222.0608
V Predictions Min            -13.633079
Log Pis Mean                 -0.32489938
Log Pis Std                  3.2811735
Log Pis Max                  15.5006485
Log Pis Min                  -8.33583
Policy mu Mean               -0.018590854
Policy mu Std                0.56258625
Policy mu Max                2.5505831
Policy mu Min                -3.1236577
Policy log std Mean          -0.9961879
Policy log std Std           0.23048896
Policy log std Max           -0.1256926
Policy log std Min           -2.0917156
Z mean eval                  1.1254618
Z variance eval              0.016560113
total_rewards                [3301.43719184 1679.20932595  786.36166472 3416.32519134 2130.63770258
 1574.05415758  784.79673704  541.59666857 1153.0673476  2222.68797307]
total_rewards_mean           1759.017396029568
total_rewards_std            962.4891943118282
total_rewards_max            3416.325191339355
total_rewards_min            541.5966685715193
Number of train steps total  716000
Number of env steps total    668574
Number of rollouts total     0
Train Time (s)               141.80258687818423
(Previous) Eval Time (s)     27.79942943993956
Sample Time (s)              11.277997652068734
Epoch Time (s)               180.88001397019252
Total Train Time (s)         32695.27693916997
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:00:47.968396 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #178 | Epoch Duration: 181.0064549446106
2020-01-12 11:00:47.968618 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1178993
Z variance train             0.016649133
KL Divergence                20.792507
KL Loss                      2.0792508
QF Loss                      1171.154
VF Loss                      295.891
Policy Loss                  -872.36237
Q Predictions Mean           866.6904
Q Predictions Std            348.10046
Q Predictions Max            1291.4938
Q Predictions Min            161.6137
V Predictions Mean           880.6813
V Predictions Std            343.85675
V Predictions Max            1283.8444
V Predictions Min            276.88525
Log Pis Mean                 -0.75903213
Log Pis Std                  2.717814
Log Pis Max                  8.173167
Log Pis Min                  -7.7576017
Policy mu Mean               -0.0054660887
Policy mu Std                0.54391545
Policy mu Max                3.182597
Policy mu Min                -2.3313153
Policy log std Mean          -0.9523893
Policy log std Std           0.20071618
Policy log std Max           -0.19304222
Policy log std Min           -1.948184
Z mean eval                  1.0352858
Z variance eval              0.009912437
total_rewards                [ 892.3586693   506.15708618 1692.0939083  2486.88192305  779.19411472
 1620.09350584  570.76858111 1549.34983105 1833.25747381 1693.74113761]
total_rewards_mean           1362.3896230975229
total_rewards_std            610.4840495683985
total_rewards_max            2486.8819230525282
total_rewards_min            506.15708618399646
Number of train steps total  720000
Number of env steps total    674832
Number of rollouts total     0
Train Time (s)               143.03084935201332
(Previous) Eval Time (s)     28.73566688876599
Sample Time (s)              11.205805457662791
Epoch Time (s)               182.9723216984421
Total Train Time (s)         32878.3373118774
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:03:51.030920 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #179 | Epoch Duration: 183.06215572357178
2020-01-12 11:03:51.031100 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.034478
Z variance train             0.009879303
KL Divergence                20.945217
KL Loss                      2.0945218
QF Loss                      818.0625
VF Loss                      182.74355
Policy Loss                  -844.0697
Q Predictions Mean           836.027
Q Predictions Std            356.75998
Q Predictions Max            1267.5111
Q Predictions Min            91.90061
V Predictions Mean           841.8938
V Predictions Std            350.98297
V Predictions Max            1265.697
V Predictions Min            226.95685
Log Pis Mean                 -0.5371656
Log Pis Std                  3.0662057
Log Pis Max                  16.331238
Log Pis Min                  -8.117907
Policy mu Mean               0.007646811
Policy mu Std                0.55553037
Policy mu Max                3.2038407
Policy mu Min                -3.0257623
Policy log std Mean          -0.9696951
Policy log std Std           0.21837033
Policy log std Max           -0.30620974
Policy log std Min           -2.092452
Z mean eval                  1.0871649
Z variance eval              0.013879505
total_rewards                [1347.61384849 1990.70362256  242.32256925 3468.25621811   27.63736483
 3314.947053   1016.97216708 2483.67908252 3521.31274835 3238.72677983]
total_rewards_mean           2065.217145402789
total_rewards_std            1276.5889483567316
total_rewards_max            3521.31274834766
total_rewards_min            27.637364833258665
Number of train steps total  724000
Number of env steps total    681938
Number of rollouts total     0
Train Time (s)               151.94988083234057
(Previous) Eval Time (s)     29.489654507953674
Sample Time (s)              11.865444473456591
Epoch Time (s)               193.30497981375083
Total Train Time (s)         33071.73290324723
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:07:04.429613 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #180 | Epoch Duration: 193.39829778671265
2020-01-12 11:07:04.429830 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0836985
Z variance train             0.014093539
KL Divergence                22.046886
KL Loss                      2.2046888
QF Loss                      982.2501
VF Loss                      130.938
Policy Loss                  -865.68994
Q Predictions Mean           861.32324
Q Predictions Std            345.0726
Q Predictions Max            1249.8287
Q Predictions Min            251.52708
V Predictions Mean           862.09753
V Predictions Std            346.84525
V Predictions Max            1252.4363
V Predictions Min            277.0223
Log Pis Mean                 -0.32145712
Log Pis Std                  3.0339923
Log Pis Max                  12.574976
Log Pis Min                  -8.007811
Policy mu Mean               -0.021391079
Policy mu Std                0.5727838
Policy mu Max                2.7581341
Policy mu Min                -2.0936387
Policy log std Mean          -0.9624467
Policy log std Std           0.22628358
Policy log std Max           -0.35511225
Policy log std Min           -2.0891702
Z mean eval                  1.3253672
Z variance eval              0.0104210535
total_rewards                [3285.05256091 1968.65381609 3145.2083661  2715.69702383 3167.44081254
 1302.7529279  1949.2474948   110.58852522 2973.68210675 1412.48070334]
total_rewards_mean           2203.080433747353
total_rewards_std            988.8583978820466
total_rewards_max            3285.0525609060655
total_rewards_min            110.58852522455169
Number of train steps total  728000
Number of env steps total    688361
Number of rollouts total     0
Train Time (s)               151.2604408399202
(Previous) Eval Time (s)     27.915462971199304
Sample Time (s)              11.794410509057343
Epoch Time (s)               190.97031432017684
Total Train Time (s)         33262.79363320256
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:10:15.492992 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #181 | Epoch Duration: 191.0630009174347
2020-01-12 11:10:15.493228 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3224427
Z variance train             0.010610446
KL Divergence                22.736523
KL Loss                      2.2736523
QF Loss                      1079.3087
VF Loss                      307.86444
Policy Loss                  -879.8668
Q Predictions Mean           870.2113
Q Predictions Std            342.76984
Q Predictions Max            1245.8895
Q Predictions Min            8.323293
V Predictions Mean           867.79724
V Predictions Std            334.85327
V Predictions Max            1222.3765
V Predictions Min            11.660019
Log Pis Mean                 -0.16006762
Log Pis Std                  3.4814856
Log Pis Max                  11.617233
Log Pis Min                  -7.2958117
Policy mu Mean               0.007647534
Policy mu Std                0.5820906
Policy mu Max                3.3278947
Policy mu Min                -3.4301963
Policy log std Mean          -1.0088269
Policy log std Std           0.24917522
Policy log std Max           -0.39717197
Policy log std Min           -2.2015643
Z mean eval                  1.1505777
Z variance eval              0.008253239
total_rewards                [3279.86875396 3258.03529568 3495.12926853 3218.2319563   590.14631142
 2637.8249801  3279.34175393  340.66574672 3310.38887522 3421.31139225]
total_rewards_mean           2683.094433409927
total_rewards_std            1131.189467148677
total_rewards_max            3495.1292685275525
total_rewards_min            340.66574672108334
Number of train steps total  732000
Number of env steps total    694012
Number of rollouts total     0
Train Time (s)               151.11385653121397
(Previous) Eval Time (s)     33.879407851956785
Sample Time (s)              11.789575174450874
Epoch Time (s)               196.78283955762163
Total Train Time (s)         33459.67566028237
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:13:32.378116 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #182 | Epoch Duration: 196.8847143650055
2020-01-12 11:13:32.378392 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1537083
Z variance train             0.008273237
KL Divergence                24.142979
KL Loss                      2.4142978
QF Loss                      553.08655
VF Loss                      234.19829
Policy Loss                  -824.1093
Q Predictions Mean           817.5619
Q Predictions Std            370.22562
Q Predictions Max            1292.1243
Q Predictions Min            -36.03129
V Predictions Mean           822.1719
V Predictions Std            364.45776
V Predictions Max            1271.1406
V Predictions Min            23.762627
Log Pis Mean                 -0.45834276
Log Pis Std                  3.1615162
Log Pis Max                  20.182983
Log Pis Min                  -7.3472238
Policy mu Mean               -0.0043458785
Policy mu Std                0.5632023
Policy mu Max                3.39564
Policy mu Min                -4.164534
Policy log std Mean          -0.9592327
Policy log std Std           0.21141334
Policy log std Max           -0.30507302
Policy log std Min           -1.9460762
Z mean eval                  1.0860054
Z variance eval              0.011330461
total_rewards                [1672.34593923  530.62922926  810.37859927  856.38256675 2017.89564645
 1213.37314876 1637.66235183 3289.25086395   58.02825247  549.86686495]
total_rewards_mean           1263.5813462916517
total_rewards_std            886.1739116651893
total_rewards_max            3289.250863950011
total_rewards_min            58.02825247477902
Number of train steps total  736000
Number of env steps total    700084
Number of rollouts total     0
Train Time (s)               150.383162365295
(Previous) Eval Time (s)     24.537167890928686
Sample Time (s)              10.842543374281377
Epoch Time (s)               185.76287363050506
Total Train Time (s)         33645.526710845996
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:16:38.231854 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #183 | Epoch Duration: 185.853280544281
2020-01-12 11:16:38.232123 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0813439
Z variance train             0.011395188
KL Divergence                22.868717
KL Loss                      2.2868717
QF Loss                      700.7653
VF Loss                      187.0997
Policy Loss                  -864.7077
Q Predictions Mean           861.2545
Q Predictions Std            349.08725
Q Predictions Max            1243.6376
Q Predictions Min            -15.606261
V Predictions Mean           868.36597
V Predictions Std            347.2581
V Predictions Max            1247.679
V Predictions Min            96.63404
Log Pis Mean                 -0.596467
Log Pis Std                  2.9987178
Log Pis Max                  14.67665
Log Pis Min                  -9.391786
Policy mu Mean               -0.018923134
Policy mu Std                0.5538228
Policy mu Max                2.8235724
Policy mu Min                -2.8393872
Policy log std Mean          -0.9548174
Policy log std Std           0.19518784
Policy log std Max           -0.3429153
Policy log std Min           -1.978448
Z mean eval                  1.1912628
Z variance eval              0.0065843402
total_rewards                [2070.68034425 3287.51848766 1694.63454668 3095.66686523 3395.33533718
 3076.05206995 3233.35471905 3293.791093    724.35482278 3383.20914639]
total_rewards_mean           2725.459743216598
total_rewards_std            867.9839453040104
total_rewards_max            3395.3353371804324
total_rewards_min            724.3548227835726
Number of train steps total  740000
Number of env steps total    707433
Number of rollouts total     0
Train Time (s)               142.1887872312218
(Previous) Eval Time (s)     36.45491302991286
Sample Time (s)              10.846237654797733
Epoch Time (s)               189.4899379159324
Total Train Time (s)         33835.10795861343
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:19:47.813496 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #184 | Epoch Duration: 189.58122396469116
2020-01-12 11:19:47.813637 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #184 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1953757
Z variance train             0.006587325
KL Divergence                22.122295
KL Loss                      2.2122295
QF Loss                      1002.3098
VF Loss                      152.9399
Policy Loss                  -863.4439
Q Predictions Mean           854.24243
Q Predictions Std            356.51263
Q Predictions Max            1275.157
Q Predictions Min            93.897385
V Predictions Mean           861.4787
V Predictions Std            354.19107
V Predictions Max            1274.1069
V Predictions Min            -10.714715
Log Pis Mean                 -0.5280184
Log Pis Std                  3.354779
Log Pis Max                  22.00865
Log Pis Min                  -6.311781
Policy mu Mean               0.004649676
Policy mu Std                0.56711406
Policy mu Max                3.9008589
Policy mu Min                -3.3396122
Policy log std Mean          -0.97442085
Policy log std Std           0.22838862
Policy log std Max           -0.30230802
Policy log std Min           -2.199801
Z mean eval                  1.2222726
Z variance eval              0.008128271
total_rewards                [3391.69996661 3174.40131077 1565.40350651 3114.96556276 3333.0673902
 1989.87547282 1130.14993271 1979.703284    401.38678056 3273.88313092]
total_rewards_mean           2335.453633785405
total_rewards_std            1016.6288838906833
total_rewards_max            3391.6999666120896
total_rewards_min            401.38678055651104
Number of train steps total  744000
Number of env steps total    713314
Number of rollouts total     0
Train Time (s)               141.80431928113103
(Previous) Eval Time (s)     28.156042288057506
Sample Time (s)              10.355266250204295
Epoch Time (s)               180.31562781939283
Total Train Time (s)         34015.53370776726
Epoch                        185
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:22:48.242610 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #185 | Epoch Duration: 180.4288456439972
2020-01-12 11:22:48.242815 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #185 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.210881
Z variance train             0.008141441
KL Divergence                21.7928
KL Loss                      2.17928
QF Loss                      782.07544
VF Loss                      141.19745
Policy Loss                  -903.7664
Q Predictions Mean           897.43677
Q Predictions Std            335.0181
Q Predictions Max            1273.9972
Q Predictions Min            -17.802744
V Predictions Mean           910.5481
V Predictions Std            327.46002
V Predictions Max            1271.1616
V Predictions Min            231.68024
Log Pis Mean                 -0.29027262
Log Pis Std                  3.0955245
Log Pis Max                  13.899207
Log Pis Min                  -8.516551
Policy mu Mean               -0.00827725
Policy mu Std                0.5791747
Policy mu Max                3.7431672
Policy mu Min                -2.7881355
Policy log std Mean          -1.0007974
Policy log std Std           0.20997995
Policy log std Max           -0.49853554
Policy log std Min           -2.0417829
Z mean eval                  1.0977356
Z variance eval              0.009962166
total_rewards                [1277.93429251  528.98990169  124.60188424 1885.90345657  277.4188844
 2381.03367094  343.57711756 1994.94255475   26.62362259 1483.28192777]
total_rewards_mean           1032.4307312994777
total_rewards_std            828.9106952108929
total_rewards_max            2381.0336709438684
total_rewards_min            26.623622585875115
Number of train steps total  748000
Number of env steps total    717533
Number of rollouts total     0
Train Time (s)               146.52207550173625
(Previous) Eval Time (s)     13.590126519091427
Sample Time (s)              11.865294713992625
Epoch Time (s)               171.9774967348203
Total Train Time (s)         34187.60594679415
Epoch                        186
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:25:40.319466 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #186 | Epoch Duration: 172.07645535469055
2020-01-12 11:25:40.319877 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1082534
Z variance train             0.009927759
KL Divergence                21.069847
KL Loss                      2.1069849
QF Loss                      620.1838
VF Loss                      251.35977
Policy Loss                  -821.5682
Q Predictions Mean           815.4731
Q Predictions Std            365.7501
Q Predictions Max            1254.4595
Q Predictions Min            -101.83784
V Predictions Mean           814.66455
V Predictions Std            359.85593
V Predictions Max            1243.1754
V Predictions Min            34.19482
Log Pis Mean                 -0.63691044
Log Pis Std                  3.7087424
Log Pis Max                  22.765776
Log Pis Min                  -8.051193
Policy mu Mean               0.019326877
Policy mu Std                0.57727104
Policy mu Max                3.2130613
Policy mu Min                -3.2229977
Policy log std Mean          -0.9621674
Policy log std Std           0.21590094
Policy log std Max           -0.27918947
Policy log std Min           -1.9934186
Z mean eval                  1.1174257
Z variance eval              0.0060321353
total_rewards                [ 602.22334642  991.4059209   805.67258381  179.3279537  3384.07988143
 3150.88358632 3437.47610721  866.62151355 3375.49618445  832.13737443]
total_rewards_mean           1762.532445221005
total_rewards_std            1303.6635009311578
total_rewards_max            3437.4761072073466
total_rewards_min            179.32795369640743
Number of train steps total  752000
Number of env steps total    722990
Number of rollouts total     0
Train Time (s)               152.444268676918
(Previous) Eval Time (s)     22.134009561035782
Sample Time (s)              13.087863401975483
Epoch Time (s)               187.66614163992926
Total Train Time (s)         34375.36611807998
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:28:48.081059 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #187 | Epoch Duration: 187.76091599464417
2020-01-12 11:28:48.081276 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1173315
Z variance train             0.0060534
KL Divergence                23.090916
KL Loss                      2.3090916
QF Loss                      888.3511
VF Loss                      165.58163
Policy Loss                  -900.0864
Q Predictions Mean           890.05255
Q Predictions Std            347.95776
Q Predictions Max            1297.3551
Q Predictions Min            104.8108
V Predictions Mean           901.8938
V Predictions Std            341.25668
V Predictions Max            1305.0558
V Predictions Min            199.401
Log Pis Mean                 -0.20650855
Log Pis Std                  3.3483748
Log Pis Max                  17.82299
Log Pis Min                  -9.369988
Policy mu Mean               -8.358387e-06
Policy mu Std                0.57404107
Policy mu Max                2.8937395
Policy mu Min                -2.6505308
Policy log std Mean          -0.9892845
Policy log std Std           0.2059049
Policy log std Max           -0.3175751
Policy log std Min           -2.1993656
Z mean eval                  1.0892996
Z variance eval              0.009873608
total_rewards                [2293.94672318 2344.78535286  629.16040487 1227.79627763 2109.71295489
  928.78590254 3329.12961946 1410.28716111 1962.46411813 2334.83581616]
total_rewards_mean           1857.0904330852804
total_rewards_std            765.7647991280945
total_rewards_max            3329.1296194643346
total_rewards_min            629.1604048720054
Number of train steps total  756000
Number of env steps total    730762
Number of rollouts total     0
Train Time (s)               151.69031224306673
(Previous) Eval Time (s)     21.00969175901264
Sample Time (s)              12.208362989127636
Epoch Time (s)               184.908366991207
Total Train Time (s)         34560.362699450925
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:31:53.080136 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #188 | Epoch Duration: 184.99871373176575
2020-01-12 11:31:53.080325 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #188 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0917172
Z variance train             0.009865301
KL Divergence                21.652168
KL Loss                      2.165217
QF Loss                      1216.6204
VF Loss                      256.97882
Policy Loss                  -869.3175
Q Predictions Mean           860.7187
Q Predictions Std            359.3523
Q Predictions Max            1269.3019
Q Predictions Min            226.31567
V Predictions Mean           863.88074
V Predictions Std            353.8787
V Predictions Max            1265.6836
V Predictions Min            256.42026
Log Pis Mean                 -0.6285397
Log Pis Std                  2.8926878
Log Pis Max                  13.369419
Log Pis Min                  -10.036106
Policy mu Mean               -0.009293106
Policy mu Std                0.5528805
Policy mu Max                2.3120935
Policy mu Min                -2.5954053
Policy log std Mean          -0.9614657
Policy log std Std           0.20918329
Policy log std Max           -0.35383224
Policy log std Min           -1.8955541
Z mean eval                  1.0797776
Z variance eval              0.008015996
total_rewards                [1414.52277852 1174.98083546 3170.3769988  3283.42018954 3232.5143603
 1025.20031436 3011.94860404 3410.94376736 1151.2257599  3183.93590632]
total_rewards_mean           2405.9069514594717
total_rewards_std            999.951782677132
total_rewards_max            3410.9437673578905
total_rewards_min            1025.200314363733
Number of train steps total  760000
Number of env steps total    736102
Number of rollouts total     0
Train Time (s)               151.81704868981615
(Previous) Eval Time (s)     36.118081491906196
Sample Time (s)              10.742676356807351
Epoch Time (s)               198.6778065385297
Total Train Time (s)         34759.14346957719
Epoch                        189
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:35:11.863610 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #189 | Epoch Duration: 198.78314018249512
2020-01-12 11:35:11.863829 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.081322
Z variance train             0.007987061
KL Divergence                23.15178
KL Loss                      2.315178
QF Loss                      653.3334
VF Loss                      187.20297
Policy Loss                  -878.22144
Q Predictions Mean           871.9376
Q Predictions Std            348.60803
Q Predictions Max            1282.0393
Q Predictions Min            -76.47644
V Predictions Mean           878.5508
V Predictions Std            341.5162
V Predictions Max            1290.7362
V Predictions Min            278.13306
Log Pis Mean                 -0.46141905
Log Pis Std                  3.0266776
Log Pis Max                  15.13836
Log Pis Min                  -7.2218637
Policy mu Mean               0.015194897
Policy mu Std                0.56505406
Policy mu Max                3.5807328
Policy mu Min                -3.2369406
Policy log std Mean          -0.9602599
Policy log std Std           0.20684017
Policy log std Max           -0.18894118
Policy log std Min           -1.9522371
Z mean eval                  1.0117203
Z variance eval              0.0094366735
total_rewards                [3129.68740753 3500.67130502 1387.6205897  1524.97517513 2752.72140327
 1463.04418372 3174.81686801 1207.85956662 3248.36476947 2476.05053417]
total_rewards_mean           2386.581180265167
total_rewards_std            853.3490463682897
total_rewards_max            3500.671305019934
total_rewards_min            1207.8595666217732
Number of train steps total  764000
Number of env steps total    745768
Number of rollouts total     0
Train Time (s)               151.44936726195738
(Previous) Eval Time (s)     26.325090452097356
Sample Time (s)              12.059164772275835
Epoch Time (s)               189.83362248633057
Total Train Time (s)         34949.082793288864
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:38:21.806038 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #190 | Epoch Duration: 189.94204688072205
2020-01-12 11:38:21.806270 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0165513
Z variance train             0.009364283
KL Divergence                20.967575
KL Loss                      2.0967577
QF Loss                      560.148
VF Loss                      137.87675
Policy Loss                  -879.5269
Q Predictions Mean           874.59625
Q Predictions Std            342.21307
Q Predictions Max            1282.2913
Q Predictions Min            241.55396
V Predictions Mean           877.34204
V Predictions Std            342.15292
V Predictions Max            1274.1001
V Predictions Min            230.95335
Log Pis Mean                 -0.42421332
Log Pis Std                  2.971557
Log Pis Max                  9.43477
Log Pis Min                  -10.85659
Policy mu Mean               0.011120932
Policy mu Std                0.5483615
Policy mu Max                2.1822715
Policy mu Min                -2.4337752
Policy log std Mean          -0.96969616
Policy log std Std           0.22439261
Policy log std Max           -0.30574167
Policy log std Min           -2.183377
Z mean eval                  1.0902178
Z variance eval              0.017609742
total_rewards                [1467.69848285 1128.07818852 3375.80649726 3491.69282225 3434.40447694
   85.27755221  871.77918388  141.26077895 1942.54734474 2124.02389341]
total_rewards_mean           1806.256922100584
total_rewards_std            1235.1669698105704
total_rewards_max            3491.6928222522697
total_rewards_min            85.27755220686764
Number of train steps total  768000
Number of env steps total    750861
Number of rollouts total     0
Train Time (s)               142.16148529900238
(Previous) Eval Time (s)     21.66134360106662
Sample Time (s)              11.123320020269603
Epoch Time (s)               174.9461489203386
Total Train Time (s)         35124.115473868325
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:41:16.841001 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #191 | Epoch Duration: 175.03457736968994
2020-01-12 11:41:16.841188 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0906979
Z variance train             0.017649977
KL Divergence                20.330982
KL Loss                      2.0330982
QF Loss                      820.7438
VF Loss                      119.05687
Policy Loss                  -863.59863
Q Predictions Mean           858.579
Q Predictions Std            354.9025
Q Predictions Max            1271.3539
Q Predictions Min            -54.924347
V Predictions Mean           866.3235
V Predictions Std            351.8614
V Predictions Max            1283.8258
V Predictions Min            -37.21148
Log Pis Mean                 -0.7751923
Log Pis Std                  3.0990183
Log Pis Max                  12.334565
Log Pis Min                  -7.502907
Policy mu Mean               0.02569215
Policy mu Std                0.5615399
Policy mu Max                3.9957707
Policy mu Min                -2.411466
Policy log std Mean          -0.9629464
Policy log std Std           0.20725784
Policy log std Max           -0.45665407
Policy log std Min           -1.9891393
Z mean eval                  1.0508301
Z variance eval              0.012199258
total_rewards                [3321.31990775 1029.8289473  3252.44598632 2021.16312739  432.50955866
 1803.17927962  548.78838091  607.74380129 1565.14435577 1837.98580919]
total_rewards_mean           1642.0109154204165
total_rewards_std            986.4142306949441
total_rewards_max            3321.319907753666
total_rewards_min            432.50955865873755
Number of train steps total  772000
Number of env steps total    757439
Number of rollouts total     0
Train Time (s)               142.12829228676856
(Previous) Eval Time (s)     24.345157032832503
Sample Time (s)              11.247187841683626
Epoch Time (s)               177.72063716128469
Total Train Time (s)         35301.92524700146
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:44:14.653637 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #192 | Epoch Duration: 177.81230878829956
2020-01-12 11:44:14.653836 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0579592
Z variance train             0.012261875
KL Divergence                21.39128
KL Loss                      2.139128
QF Loss                      562.3188
VF Loss                      179.72395
Policy Loss                  -896.3641
Q Predictions Mean           893.2206
Q Predictions Std            342.79294
Q Predictions Max            1285.1656
Q Predictions Min            246.00255
V Predictions Mean           891.7421
V Predictions Std            338.763
V Predictions Max            1264.7985
V Predictions Min            245.06694
Log Pis Mean                 -0.73245317
Log Pis Std                  3.138662
Log Pis Max                  12.613906
Log Pis Min                  -8.362744
Policy mu Mean               -0.014810802
Policy mu Std                0.5444565
Policy mu Max                2.6515257
Policy mu Min                -3.5879807
Policy log std Mean          -0.9623882
Policy log std Std           0.23227896
Policy log std Max           -0.20547777
Policy log std Min           -2.272778
Z mean eval                  1.0919312
Z variance eval              0.012527826
total_rewards                [3383.35787612 3434.16048039  628.57585242 1188.52539261 1310.62549265
 1590.5125126   547.45456767 3502.70448852  314.00429763 3316.31396175]
total_rewards_mean           1921.6234922351027
total_rewards_std            1266.2761128230788
total_rewards_max            3502.7044885210466
total_rewards_min            314.00429763012573
Number of train steps total  776000
Number of env steps total    762203
Number of rollouts total     0
Train Time (s)               147.14015239709988
(Previous) Eval Time (s)     21.222222382202744
Sample Time (s)              11.087307342793792
Epoch Time (s)               179.44968212209642
Total Train Time (s)         35481.462309216615
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:47:14.193189 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #193 | Epoch Duration: 179.5391981601715
2020-01-12 11:47:14.193383 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #193 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0987284
Z variance train             0.0126182465
KL Divergence                21.63637
KL Loss                      2.163637
QF Loss                      746.4238
VF Loss                      299.53973
Policy Loss                  -853.0224
Q Predictions Mean           846.1881
Q Predictions Std            350.03262
Q Predictions Max            1304.6503
Q Predictions Min            27.55241
V Predictions Mean           853.9894
V Predictions Std            344.84744
V Predictions Max            1283.4441
V Predictions Min            153.5735
Log Pis Mean                 -0.8226207
Log Pis Std                  3.2016342
Log Pis Max                  18.168783
Log Pis Min                  -11.703276
Policy mu Mean               -0.0004957542
Policy mu Std                0.569558
Policy mu Max                3.503994
Policy mu Min                -3.0104682
Policy log std Mean          -0.9561528
Policy log std Std           0.20502853
Policy log std Max           -0.06804299
Policy log std Min           -1.9230014
Z mean eval                  1.1016161
Z variance eval              0.016095882
total_rewards                [3283.56990947 3537.24024762 1533.27056484 1568.19084133  353.0371697
 3213.58109735 3340.25350637 3303.70538275 3371.54215147 3333.46444181]
total_rewards_mean           2683.7855312715883
total_rewards_std            1052.6051681529777
total_rewards_max            3537.240247622984
total_rewards_min            353.03716969620507
Number of train steps total  780000
Number of env steps total    767973
Number of rollouts total     0
Train Time (s)               153.11191471712664
(Previous) Eval Time (s)     30.108005065005273
Sample Time (s)              12.66098963888362
Epoch Time (s)               195.88090942101553
Total Train Time (s)         35677.437690145336
Epoch                        194
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:50:30.171160 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #194 | Epoch Duration: 195.97763109207153
2020-01-12 11:50:30.171443 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1182112
Z variance train             0.016587103
KL Divergence                20.76865
KL Loss                      2.076865
QF Loss                      834.1061
VF Loss                      429.61072
Policy Loss                  -831.7376
Q Predictions Mean           816.7574
Q Predictions Std            366.0534
Q Predictions Max            1275.8545
Q Predictions Min            37.73117
V Predictions Mean           819.1117
V Predictions Std            356.88693
V Predictions Max            1266.4104
V Predictions Min            148.58719
Log Pis Mean                 -0.7678799
Log Pis Std                  3.0116336
Log Pis Max                  12.436422
Log Pis Min                  -8.484849
Policy mu Mean               -0.0014596921
Policy mu Std                0.540866
Policy mu Max                1.8818138
Policy mu Min                -2.411131
Policy log std Mean          -0.95996684
Policy log std Std           0.21053459
Policy log std Max           -0.45389986
Policy log std Min           -1.8571434
Z mean eval                  1.0244181
Z variance eval              0.0074942955
total_rewards                [2315.54407708  303.02383516 3236.2150154    46.57576132 2076.73746424
 3136.40587958  586.38427277  489.0827515   265.21469017  275.92122512]
total_rewards_mean           1273.1104972340413
total_rewards_std            1208.3096253738242
total_rewards_max            3236.2150154014917
total_rewards_min            46.575761320237746
Number of train steps total  784000
Number of env steps total    772827
Number of rollouts total     0
Train Time (s)               151.59753649914637
(Previous) Eval Time (s)     15.701583862304688
Sample Time (s)              11.797971048392355
Epoch Time (s)               179.09709140984342
Total Train Time (s)         35856.62126999209
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:53:29.357701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #195 | Epoch Duration: 179.1861035823822
2020-01-12 11:53:29.357911 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0232586
Z variance train             0.007403561
KL Divergence                22.495552
KL Loss                      2.2495553
QF Loss                      417.94598
VF Loss                      119.93836
Policy Loss                  -871.9908
Q Predictions Mean           864.2619
Q Predictions Std            360.58447
Q Predictions Max            1304.4948
Q Predictions Min            -54.829826
V Predictions Mean           867.9458
V Predictions Std            356.0455
V Predictions Max            1309.6888
V Predictions Min            -29.524794
Log Pis Mean                 -0.58836555
Log Pis Std                  2.8478997
Log Pis Max                  13.896923
Log Pis Min                  -6.27643
Policy mu Mean               0.014466416
Policy mu Std                0.55503
Policy mu Max                2.6165402
Policy mu Min                -2.4882588
Policy log std Mean          -0.95707965
Policy log std Std           0.2097776
Policy log std Max           -0.36707532
Policy log std Min           -2.1053765
Z mean eval                  1.1493685
Z variance eval              0.013833824
total_rewards                [ 957.39274558  116.67582392 1822.46014161 3339.23451552 1253.00876536
 2411.73174398  551.32894926 1944.95497166 1608.97783204 3365.27082153]
total_rewards_mean           1737.1036310453521
total_rewards_std            1030.23899042486
total_rewards_max            3365.2708215277216
total_rewards_min            116.67582392455535
Number of train steps total  788000
Number of env steps total    779681
Number of rollouts total     0
Train Time (s)               152.62843635072932
(Previous) Eval Time (s)     24.506486226804554
Sample Time (s)              11.742517571896315
Epoch Time (s)               188.87744014943019
Total Train Time (s)         36045.59151741117
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:56:38.331640 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #196 | Epoch Duration: 188.973530292511
2020-01-12 11:56:38.332012 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.148143
Z variance train             0.013758679
KL Divergence                22.580612
KL Loss                      2.2580612
QF Loss                      812.7106
VF Loss                      184.19008
Policy Loss                  -865.91125
Q Predictions Mean           860.71326
Q Predictions Std            356.61115
Q Predictions Max            1297.5474
Q Predictions Min            260.23972
V Predictions Mean           865.13727
V Predictions Std            354.80762
V Predictions Max            1281.5426
V Predictions Min            278.29407
Log Pis Mean                 -0.7082487
Log Pis Std                  2.8033116
Log Pis Max                  15.440068
Log Pis Min                  -7.349331
Policy mu Mean               0.007386043
Policy mu Std                0.54057086
Policy mu Max                2.431421
Policy mu Min                -2.1386628
Policy log std Mean          -0.96045864
Policy log std Std           0.2117728
Policy log std Max           -0.4592605
Policy log std Min           -2.3008451
Z mean eval                  1.2567686
Z variance eval              0.007923073
total_rewards                [3288.80867693  476.38452867 2437.84451299 3210.52772775 3503.33696008
 3406.05444734 3175.67075349 3300.45015938 3547.46291172 3161.88952674]
total_rewards_mean           2950.8430205091363
total_rewards_std            874.843117848453
total_rewards_max            3547.4629117243567
total_rewards_min            476.3845286713917
Number of train steps total  792000
Number of env steps total    788449
Number of rollouts total     0
Train Time (s)               151.06196016306058
(Previous) Eval Time (s)     34.56239088391885
Sample Time (s)              11.549260355066508
Epoch Time (s)               197.17361140204594
Total Train Time (s)         36242.8767894716
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:59:55.618524 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #197 | Epoch Duration: 197.28625774383545
2020-01-12 11:59:55.618712 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2542745
Z variance train             0.007963385
KL Divergence                22.392204
KL Loss                      2.2392204
QF Loss                      576.18274
VF Loss                      179.18413
Policy Loss                  -882.4584
Q Predictions Mean           875.38525
Q Predictions Std            352.17206
Q Predictions Max            1303.0988
Q Predictions Min            14.211243
V Predictions Mean           882.4614
V Predictions Std            343.7221
V Predictions Max            1290.8188
V Predictions Min            205.22868
Log Pis Mean                 -0.22196388
Log Pis Std                  3.093995
Log Pis Max                  16.848587
Log Pis Min                  -9.115799
Policy mu Mean               -0.05773955
Policy mu Std                0.5421369
Policy mu Max                2.7846658
Policy mu Min                -2.7338974
Policy log std Mean          -0.99785614
Policy log std Std           0.24291357
Policy log std Max           -0.34722036
Policy log std Min           -2.2054782
Z mean eval                  1.200367
Z variance eval              0.016596556
total_rewards                [2608.45226384 1116.46255198 3342.73636116 3335.53811488 2321.73288308
 3226.31847006 2995.46981399 3158.27310235 3233.91059384 3355.59538463]
total_rewards_mean           2869.4489539811852
total_rewards_std            669.1891140912591
total_rewards_max            3355.5953846324705
total_rewards_min            1116.462551984296
Number of train steps total  796000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               142.3258315557614
(Previous) Eval Time (s)     30.698361871298403
Sample Time (s)              11.821899946779013
Epoch Time (s)               184.8460933738388
Total Train Time (s)         36427.81354079023
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:03:00.558152 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #198 | Epoch Duration: 184.93930196762085
2020-01-12 12:03:00.558344 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1963637
Z variance train             0.016607122
KL Divergence                20.28001
KL Loss                      2.028001
QF Loss                      641.2472
VF Loss                      120.30177
Policy Loss                  -882.3903
Q Predictions Mean           877.95874
Q Predictions Std            361.84183
Q Predictions Max            1317.094
Q Predictions Min            243.97021
V Predictions Mean           886.4883
V Predictions Std            360.9491
V Predictions Max            1310.0684
V Predictions Min            262.76062
Log Pis Mean                 -0.6599668
Log Pis Std                  2.9354875
Log Pis Max                  14.563263
Log Pis Min                  -7.694032
Policy mu Mean               -0.021984955
Policy mu Std                0.5401513
Policy mu Max                2.6687424
Policy mu Min                -2.6542988
Policy log std Mean          -0.9737183
Policy log std Std           0.21428397
Policy log std Max           -0.39807087
Policy log std Min           -2.2078142
Z mean eval                  1.2475947
Z variance eval              0.022600394
total_rewards                [2770.16944396 3190.43719936 3191.71507903 3381.5759862  3260.25291264
 3159.1111713  3176.90353962 3275.70921027 3211.23213655 3298.1792742 ]
total_rewards_mean           3191.5285953134926
total_rewards_std            154.43430879734072
total_rewards_max            3381.575986204682
total_rewards_min            2770.1694439644034
Number of train steps total  800000
Number of env steps total    799478
Number of rollouts total     0
Train Time (s)               142.5965895028785
(Previous) Eval Time (s)     35.949669987894595
Sample Time (s)              11.377347184345126
Epoch Time (s)               189.9236066751182
Total Train Time (s)         36617.837709525134
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:06:10.585015 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #199 | Epoch Duration: 190.02652645111084
2020-01-12 12:06:10.585211 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2545973
Z variance train             0.022545576
KL Divergence                20.185287
KL Loss                      2.0185287
QF Loss                      871.3984
VF Loss                      243.84908
Policy Loss                  -849.9526
Q Predictions Mean           845.05334
Q Predictions Std            358.4217
Q Predictions Max            1297.8197
Q Predictions Min            -31.499073
V Predictions Mean           851.0877
V Predictions Std            354.3711
V Predictions Max            1296.058
V Predictions Min            -24.704525
Log Pis Mean                 -0.5777588
Log Pis Std                  3.1342556
Log Pis Max                  18.217255
Log Pis Min                  -7.2817965
Policy mu Mean               -0.008006973
Policy mu Std                0.5567779
Policy mu Max                2.7435336
Policy mu Min                -3.9871874
Policy log std Mean          -0.94849265
Policy log std Std           0.21593605
Policy log std Max           -0.41542184
Policy log std Min           -2.085845
Z mean eval                  1.2574105
Z variance eval              0.024075495
total_rewards                [1114.87852994 2365.36980401 3289.79903713 3089.20634971 3365.93880734
 3301.31556128 3338.64246274 1533.75633304 2662.79207082 3179.64416855]
total_rewards_mean           2724.1343124564237
total_rewards_std            769.583889065185
total_rewards_max            3365.9388073394994
total_rewards_min            1114.878529942811
Number of train steps total  804000
Number of env steps total    809391
Number of rollouts total     0
Train Time (s)               150.56739003770053
(Previous) Eval Time (s)     33.451935733202845
Sample Time (s)              11.348698354326189
Epoch Time (s)               195.36802412522957
Total Train Time (s)         36813.30844069831
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:09:26.060403 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #200 | Epoch Duration: 195.47501468658447
2020-01-12 12:09:26.060751 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2627361
Z variance train             0.023587767
KL Divergence                20.23888
KL Loss                      2.023888
QF Loss                      1266.5969
VF Loss                      121.859726
Policy Loss                  -847.975
Q Predictions Mean           840.5812
Q Predictions Std            395.72446
Q Predictions Max            1329.1072
Q Predictions Min            -30.674116
V Predictions Mean           843.2561
V Predictions Std            387.68823
V Predictions Max            1338.9683
V Predictions Min            23.293861
Log Pis Mean                 -0.5689157
Log Pis Std                  3.3144042
Log Pis Max                  17.153522
Log Pis Min                  -10.133438
Policy mu Mean               0.010243613
Policy mu Std                0.5428011
Policy mu Max                2.4832819
Policy mu Min                -3.1335018
Policy log std Mean          -0.9751673
Policy log std Std           0.23501168
Policy log std Max           -0.45370358
Policy log std Min           -2.5029607
Z mean eval                  1.0603654
Z variance eval              0.008870824
total_rewards                [1461.66865465 2571.48333137 3385.08463238 3301.8875033   632.56889888
 1012.94365215  420.82585761  306.13732121 2788.33563938 3307.26492223]
total_rewards_mean           1918.8200413147338
total_rewards_std            1212.4927604964375
total_rewards_max            3385.0846323779633
total_rewards_min            306.1373212062983
Number of train steps total  808000
Number of env steps total    818126
Number of rollouts total     0
Train Time (s)               149.9772669430822
(Previous) Eval Time (s)     25.417903451249003
Sample Time (s)              11.648883884772658
Epoch Time (s)               187.04405427910388
Total Train Time (s)         37000.449054921046
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:12:33.202463 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #201 | Epoch Duration: 187.14145469665527
2020-01-12 12:12:33.202675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0605063
Z variance train             0.008876034
KL Divergence                21.38842
KL Loss                      2.138842
QF Loss                      662.41235
VF Loss                      243.79448
Policy Loss                  -876.69836
Q Predictions Mean           874.12
Q Predictions Std            345.50726
Q Predictions Max            1323.0575
Q Predictions Min            227.8527
V Predictions Mean           877.7764
V Predictions Std            345.9959
V Predictions Max            1302.5193
V Predictions Min            209.96288
Log Pis Mean                 -0.89899707
Log Pis Std                  3.22205
Log Pis Max                  24.600307
Log Pis Min                  -8.682854
Policy mu Mean               -0.00622373
Policy mu Std                0.5605573
Policy mu Max                4.912643
Policy mu Min                -2.94623
Policy log std Mean          -0.9600072
Policy log std Std           0.20981881
Policy log std Max           -0.35419947
Policy log std Min           -2.1808937
Z mean eval                  1.066681
Z variance eval              0.011017968
total_rewards                [1839.62655481 3476.71625534  515.72663379 1404.14632503 3319.16860098
 3319.80869093  514.09905797 3324.66406393 3355.59065063 3128.75526657]
total_rewards_mean           2419.8302099982734
total_rewards_std            1164.4053095975353
total_rewards_max            3476.7162553419707
total_rewards_min            514.0990579717364
Number of train steps total  812000
Number of env steps total    825954
Number of rollouts total     0
Train Time (s)               151.00324597023427
(Previous) Eval Time (s)     32.64906819490716
Sample Time (s)              11.962139033712447
Epoch Time (s)               195.61445319885388
Total Train Time (s)         37196.16502945591
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:15:48.922966 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #202 | Epoch Duration: 195.72006726264954
2020-01-12 12:15:48.923419 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0637052
Z variance train             0.01095601
KL Divergence                20.975256
KL Loss                      2.0975256
QF Loss                      6805.5684
VF Loss                      190.0015
Policy Loss                  -887.79114
Q Predictions Mean           880.43054
Q Predictions Std            355.18985
Q Predictions Max            1309.5122
Q Predictions Min            99.262276
V Predictions Mean           894.29
V Predictions Std            348.97476
V Predictions Max            1300.1418
V Predictions Min            288.83734
Log Pis Mean                 -0.16789806
Log Pis Std                  3.5507445
Log Pis Max                  27.672321
Log Pis Min                  -7.6659513
Policy mu Mean               -0.022146117
Policy mu Std                0.5982073
Policy mu Max                3.4185236
Policy mu Min                -4.135024
Policy log std Mean          -0.97037315
Policy log std Std           0.22013868
Policy log std Max           -0.46438986
Policy log std Min           -2.0989158
Z mean eval                  1.1108055
Z variance eval              0.013374518
total_rewards                [3125.37771002 3532.71352893 3307.11413811 3318.07229792 3223.54462302
 1940.4024925  1455.4857968  3276.93121646 3346.60251947 3173.82184603]
total_rewards_mean           2970.006616924939
total_rewards_std            653.55013303416
total_rewards_max            3532.7135289256094
total_rewards_min            1455.4857968044598
Number of train steps total  816000
Number of env steps total    833878
Number of rollouts total     0
Train Time (s)               151.91537989722565
(Previous) Eval Time (s)     32.72178626572713
Sample Time (s)              11.546876915730536
Epoch Time (s)               196.18404307868332
Total Train Time (s)         37392.44392884942
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:19:05.203359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #203 | Epoch Duration: 196.27965116500854
2020-01-12 12:19:05.203550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.10977
Z variance train             0.013448593
KL Divergence                22.376991
KL Loss                      2.2376993
QF Loss                      757.66254
VF Loss                      588.847
Policy Loss                  -894.19556
Q Predictions Mean           889.1191
Q Predictions Std            341.78217
Q Predictions Max            1322.821
Q Predictions Min            113.4357
V Predictions Mean           902.1692
V Predictions Std            337.76132
V Predictions Max            1329.2255
V Predictions Min            187.30447
Log Pis Mean                 -0.18188776
Log Pis Std                  3.25812
Log Pis Max                  23.747822
Log Pis Min                  -6.5075555
Policy mu Mean               -0.0070919213
Policy mu Std                0.58408874
Policy mu Max                3.134442
Policy mu Min                -3.3070347
Policy log std Mean          -0.9889552
Policy log std Std           0.23282146
Policy log std Max           -0.43677968
Policy log std Min           -2.145699
Z mean eval                  1.1859083
Z variance eval              0.018923039
total_rewards                [3553.28145657 3214.9654348  2944.22803488 3294.93456199 1044.34028072
 3409.15635625 1668.58347387 3391.11664464  987.53430664 3087.59703582]
total_rewards_mean           2659.573758618014
total_rewards_std            962.2304621533839
total_rewards_max            3553.281456572768
total_rewards_min            987.5343066408183
Number of train steps total  820000
Number of env steps total    840051
Number of rollouts total     0
Train Time (s)               146.61147156590596
(Previous) Eval Time (s)     31.67374645266682
Sample Time (s)              11.47987951990217
Epoch Time (s)               189.76509753847495
Total Train Time (s)         37582.295146625955
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:22:15.057835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #204 | Epoch Duration: 189.8541305065155
2020-01-12 12:22:15.058084 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1833379
Z variance train             0.018992659
KL Divergence                22.066113
KL Loss                      2.2066114
QF Loss                      1375.7201
VF Loss                      222.08755
Policy Loss                  -911.455
Q Predictions Mean           901.4801
Q Predictions Std            351.1591
Q Predictions Max            1341.2383
Q Predictions Min            -65.001015
V Predictions Mean           910.55505
V Predictions Std            339.3427
V Predictions Max            1361.4645
V Predictions Min            222.62628
Log Pis Mean                 -0.20364884
Log Pis Std                  3.0889568
Log Pis Max                  20.331776
Log Pis Min                  -7.299629
Policy mu Mean               0.0026609027
Policy mu Std                0.5922112
Policy mu Max                3.659874
Policy mu Min                -3.349841
Policy log std Mean          -0.9877089
Policy log std Std           0.2336042
Policy log std Max           -0.053274155
Policy log std Min           -2.2828875
Z mean eval                  1.068969
Z variance eval              0.0071388804
total_rewards                [3270.49566321 2495.12792964  425.56227729  258.70276025 3403.55022865
 3250.33775165 3017.08743282 1776.54820155 3313.72638703 1197.81908578]
total_rewards_mean           2240.895771786943
total_rewards_std            1173.7563596005862
total_rewards_max            3403.550228648973
total_rewards_min            258.7027602519612
Number of train steps total  824000
Number of env steps total    848281
Number of rollouts total     0
Train Time (s)               142.6253861989826
(Previous) Eval Time (s)     26.770942497998476
Sample Time (s)              10.38052123459056
Epoch Time (s)               179.77684993157163
Total Train Time (s)         37762.165458441246
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:25:14.931686 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #205 | Epoch Duration: 179.8734269142151
2020-01-12 12:25:14.931930 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0687308
Z variance train             0.007132406
KL Divergence                21.618635
KL Loss                      2.1618636
QF Loss                      629.1248
VF Loss                      261.28796
Policy Loss                  -854.9578
Q Predictions Mean           849.5249
Q Predictions Std            378.6171
Q Predictions Max            1294.8754
Q Predictions Min            34.014515
V Predictions Mean           855.94916
V Predictions Std            373.12766
V Predictions Max            1288.3679
V Predictions Min            -9.82722
Log Pis Mean                 -0.3105123
Log Pis Std                  3.2654073
Log Pis Max                  15.366173
Log Pis Min                  -8.014648
Policy mu Mean               0.025269771
Policy mu Std                0.5825386
Policy mu Max                3.1006653
Policy mu Min                -3.6586893
Policy log std Mean          -0.9569912
Policy log std Std           0.21735857
Policy log std Max           -0.3152458
Policy log std Min           -2.0950284
Z mean eval                  1.0667249
Z variance eval              0.01787998
total_rewards                [3380.32793708 1070.99383984  717.01099908 3350.38518968 3279.06084148
 3585.44493666   94.88370741   84.36924885 1364.72281109 3438.85354315]
total_rewards_mean           2036.6053054315119
total_rewards_std            1419.4075272616935
total_rewards_max            3585.4449366633576
total_rewards_min            84.36924884988935
Number of train steps total  828000
Number of env steps total    857807
Number of rollouts total     0
Train Time (s)               143.87253092508763
(Previous) Eval Time (s)     27.450084377080202
Sample Time (s)              12.168814918026328
Epoch Time (s)               183.49143022019416
Total Train Time (s)         37945.75102526136
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:28:18.518999 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #206 | Epoch Duration: 183.58691000938416
2020-01-12 12:28:18.519226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0619661
Z variance train             0.017869314
KL Divergence                20.42047
KL Loss                      2.042047
QF Loss                      472.88086
VF Loss                      261.00616
Policy Loss                  -860.54736
Q Predictions Mean           857.87976
Q Predictions Std            381.37155
Q Predictions Max            1345.7504
Q Predictions Min            -18.271948
V Predictions Mean           859.22577
V Predictions Std            377.92084
V Predictions Max            1323.0541
V Predictions Min            129.94371
Log Pis Mean                 -0.9195683
Log Pis Std                  3.219554
Log Pis Max                  18.269924
Log Pis Min                  -8.783073
Policy mu Mean               -0.007246768
Policy mu Std                0.5570064
Policy mu Max                3.1908834
Policy mu Min                -4.029795
Policy log std Mean          -0.9183283
Policy log std Std           0.20117374
Policy log std Max           -0.29239458
Policy log std Min           -2.1531372
Z mean eval                  1.1149743
Z variance eval              0.010899885
total_rewards                [1294.6743693  1964.3303668  3180.27661954 3324.26800508 2152.10477305
 3094.95311128 3460.69122542 3126.2238016  2681.54930033  434.88252987]
total_rewards_mean           2471.395410226173
total_rewards_std            946.6529521119878
total_rewards_max            3460.6912254152257
total_rewards_min            434.8825298671023
Number of train steps total  832000
Number of env steps total    866301
Number of rollouts total     0
Train Time (s)               151.917247178033
(Previous) Eval Time (s)     33.71495279390365
Sample Time (s)              11.696172663010657
Epoch Time (s)               197.3283726349473
Total Train Time (s)         38143.22156784404
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:31:35.993474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #207 | Epoch Duration: 197.47408413887024
2020-01-12 12:31:35.993721 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1199119
Z variance train             0.011174075
KL Divergence                21.474941
KL Loss                      2.147494
QF Loss                      599.4226
VF Loss                      357.92847
Policy Loss                  -907.2473
Q Predictions Mean           901.85376
Q Predictions Std            352.6629
Q Predictions Max            1338.0205
Q Predictions Min            -35.425278
V Predictions Mean           910.8409
V Predictions Std            342.5877
V Predictions Max            1330.8531
V Predictions Min            253.82028
Log Pis Mean                 -0.5777549
Log Pis Std                  2.9898372
Log Pis Max                  11.150745
Log Pis Min                  -10.577001
Policy mu Mean               -0.0025753865
Policy mu Std                0.57333165
Policy mu Max                2.7184968
Policy mu Min                -2.6841094
Policy log std Mean          -0.958821
Policy log std Std           0.2096689
Policy log std Max           -0.36742496
Policy log std Min           -2.051177
Z mean eval                  1.0619074
Z variance eval              0.032780886
total_rewards                [3462.83467646 2476.12201784  747.99098111 1679.18013936  491.29044408
 2341.311669   3486.70117689 2015.02489942   34.08741816  148.20918923]
total_rewards_mean           1688.2752611562205
total_rewards_std            1223.2110246208645
total_rewards_max            3486.7011768853527
total_rewards_min            34.087418164184164
Number of train steps total  836000
Number of env steps total    875197
Number of rollouts total     0
Train Time (s)               151.37322304071859
(Previous) Eval Time (s)     18.042531209997833
Sample Time (s)              11.643390640616417
Epoch Time (s)               181.05914489133283
Total Train Time (s)         38324.37198525481
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:34:37.145852 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #208 | Epoch Duration: 181.151957988739
2020-01-12 12:34:37.146048 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0611192
Z variance train             0.03285894
KL Divergence                19.278133
KL Loss                      1.9278134
QF Loss                      774.84033
VF Loss                      165.82819
Policy Loss                  -886.8715
Q Predictions Mean           878.4562
Q Predictions Std            384.2045
Q Predictions Max            1331.2441
Q Predictions Min            28.892866
V Predictions Mean           885.14087
V Predictions Std            377.00403
V Predictions Max            1331.78
V Predictions Min            0.86734366
Log Pis Mean                 -0.4339121
Log Pis Std                  3.1985106
Log Pis Max                  15.544581
Log Pis Min                  -8.7196455
Policy mu Mean               0.013305761
Policy mu Std                0.56495744
Policy mu Max                3.2395246
Policy mu Min                -3.479515
Policy log std Mean          -0.9644822
Policy log std Std           0.23097254
Policy log std Max           -0.31948453
Policy log std Min           -2.005786
Z mean eval                  1.1167257
Z variance eval              0.013757654
total_rewards                [3352.51473919   94.76526946  445.50426047 1378.92768203 1129.03198287
 3387.56871406 1139.46003865 2345.57136698 3377.17887001 1046.73893802]
total_rewards_mean           1769.7261861739848
total_rewards_std            1186.606596279883
total_rewards_max            3387.5687140584423
total_rewards_min            94.76526946065285
Number of train steps total  840000
Number of env steps total    883992
Number of rollouts total     0
Train Time (s)               150.73425698187202
(Previous) Eval Time (s)     23.122218403033912
Sample Time (s)              11.293435307219625
Epoch Time (s)               185.14991069212556
Total Train Time (s)         38509.62368882308
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:37:42.401160 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #209 | Epoch Duration: 185.25492572784424
2020-01-12 12:37:42.401637 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1120417
Z variance train             0.01388031
KL Divergence                19.908928
KL Loss                      1.9908928
QF Loss                      476.93475
VF Loss                      243.05788
Policy Loss                  -922.7266
Q Predictions Mean           917.0113
Q Predictions Std            358.56473
Q Predictions Max            1347.4514
Q Predictions Min            -14.690786
V Predictions Mean           927.3876
V Predictions Std            354.6424
V Predictions Max            1352.9048
V Predictions Min            155.44275
Log Pis Mean                 -0.48037446
Log Pis Std                  3.090248
Log Pis Max                  20.294544
Log Pis Min                  -6.875155
Policy mu Mean               0.049124792
Policy mu Std                0.5746789
Policy mu Max                2.4257526
Policy mu Min                -3.3667808
Policy log std Mean          -0.9643295
Policy log std Std           0.22626796
Policy log std Max           -0.40594703
Policy log std Min           -2.0735512
Z mean eval                  1.1327933
Z variance eval              0.016408091
total_rewards                [2449.73159198 3294.95329821 3388.4508766  2779.77111811 3310.80283082
 3220.05665081 2858.54869525 3221.93961795  823.21191077 3624.79377545]
total_rewards_mean           2897.226036595946
total_rewards_std            763.3233508478942
total_rewards_max            3624.7937754527643
total_rewards_min            823.2119107717043
Number of train steps total  844000
Number of env steps total    890127
Number of rollouts total     0
Train Time (s)               151.70643581310287
(Previous) Eval Time (s)     32.835095453076065
Sample Time (s)              12.858797084074467
Epoch Time (s)               197.4003283502534
Total Train Time (s)         38707.11775763286
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:40:59.897469 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #210 | Epoch Duration: 197.49558973312378
2020-01-12 12:40:59.897673 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1405798
Z variance train             0.016769554
KL Divergence                21.989029
KL Loss                      2.1989028
QF Loss                      565.5111
VF Loss                      86.851295
Policy Loss                  -894.0703
Q Predictions Mean           886.6139
Q Predictions Std            354.8102
Q Predictions Max            1309.7827
Q Predictions Min            242.2655
V Predictions Mean           895.38306
V Predictions Std            356.57303
V Predictions Max            1305.3508
V Predictions Min            261.0526
Log Pis Mean                 -0.5402913
Log Pis Std                  3.0038252
Log Pis Max                  15.107037
Log Pis Min                  -7.800265
Policy mu Mean               -0.008738605
Policy mu Std                0.5286982
Policy mu Max                2.867859
Policy mu Min                -3.275409
Policy log std Mean          -0.9927452
Policy log std Std           0.22589527
Policy log std Max           -0.42724496
Policy log std Min           -2.052899
Z mean eval                  1.0697862
Z variance eval              0.0047577834
total_rewards                [3388.01586568 3255.00151056 3288.0531259  3117.82608401 1457.81283371
 3197.44089664 3411.9047441  3390.28277313 3335.85462472 1159.14618242]
total_rewards_mean           2900.1338640873696
total_rewards_std            803.3404416679173
total_rewards_max            3411.9047440960603
total_rewards_min            1159.1461824184203
Number of train steps total  848000
Number of env steps total    896233
Number of rollouts total     0
Train Time (s)               145.17228948278353
(Previous) Eval Time (s)     34.035147415008396
Sample Time (s)              12.803192927967757
Epoch Time (s)               192.01062982575968
Total Train Time (s)         38899.215457088314
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:44:11.998170 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #211 | Epoch Duration: 192.10033798217773
2020-01-12 12:44:11.998390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0707283
Z variance train             0.004853587
KL Divergence                25.223244
KL Loss                      2.5223243
QF Loss                      1176.434
VF Loss                      411.5146
Policy Loss                  -889.6698
Q Predictions Mean           883.4794
Q Predictions Std            375.35626
Q Predictions Max            1361.1201
Q Predictions Min            11.507847
V Predictions Mean           886.25836
V Predictions Std            370.6699
V Predictions Max            1363.3984
V Predictions Min            -7.9093084
Log Pis Mean                 -0.8040234
Log Pis Std                  3.7875042
Log Pis Max                  26.298052
Log Pis Min                  -10.346233
Policy mu Mean               0.005764407
Policy mu Std                0.56335205
Policy mu Max                3.643193
Policy mu Min                -4.667454
Policy log std Mean          -0.9755217
Policy log std Std           0.24567197
Policy log std Max           -0.4532655
Policy log std Min           -2.4016943
Z mean eval                  1.1123946
Z variance eval              0.0050544837
total_rewards                [3465.64690758 1194.3064028  3331.81659141 3376.14522668 1759.05685342
 2980.06862841 1503.53589815 3305.34784836 1247.96944201 2918.55668663]
total_rewards_mean           2508.245048544829
total_rewards_std            908.8420064713266
total_rewards_max            3465.6469075767527
total_rewards_min            1194.306402802315
Number of train steps total  852000
Number of env steps total    904604
Number of rollouts total     0
Train Time (s)               142.7812729589641
(Previous) Eval Time (s)     26.93916559126228
Sample Time (s)              11.24278125911951
Epoch Time (s)               180.9632198093459
Total Train Time (s)         39080.27097678976
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:47:13.056882 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #212 | Epoch Duration: 181.0583200454712
2020-01-12 12:47:13.057132 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1066127
Z variance train             0.005027391
KL Divergence                24.868397
KL Loss                      2.4868398
QF Loss                      627.7401
VF Loss                      206.05414
Policy Loss                  -886.86725
Q Predictions Mean           880.5602
Q Predictions Std            363.3885
Q Predictions Max            1329.2773
Q Predictions Min            -37.425735
V Predictions Mean           894.6438
V Predictions Std            359.35077
V Predictions Max            1341.0597
V Predictions Min            176.48204
Log Pis Mean                 -0.44011107
Log Pis Std                  3.1148913
Log Pis Max                  20.0303
Log Pis Min                  -6.8997455
Policy mu Mean               0.002269877
Policy mu Std                0.55888474
Policy mu Max                2.8680174
Policy mu Min                -2.8583732
Policy log std Mean          -0.9598422
Policy log std Std           0.21555121
Policy log std Max           -0.30210406
Policy log std Min           -2.0066714
Z mean eval                  1.0585306
Z variance eval              0.013631429
total_rewards                [2226.25186205 2937.44993383 3005.00233369 3509.93290938 3342.47154715
 1854.2507408  3546.27834002 1339.14511805 1459.08581475 3408.287634  ]
total_rewards_mean           2662.8156233716954
total_rewards_std            821.8104803652772
total_rewards_max            3546.2783400156723
total_rewards_min            1339.1451180506963
Number of train steps total  856000
Number of env steps total    911509
Number of rollouts total     0
Train Time (s)               146.24448462296277
(Previous) Eval Time (s)     31.513316587079316
Sample Time (s)              11.03538103075698
Epoch Time (s)               188.79318224079907
Total Train Time (s)         39269.1556261424
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:50:21.945686 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #213 | Epoch Duration: 188.88838911056519
2020-01-12 12:50:21.945874 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #213 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0595896
Z variance train             0.013660179
KL Divergence                20.71642
KL Loss                      2.071642
QF Loss                      804.08356
VF Loss                      124.49773
Policy Loss                  -908.02563
Q Predictions Mean           897.4498
Q Predictions Std            363.4985
Q Predictions Max            1342.7671
Q Predictions Min            -41.577415
V Predictions Mean           904.8799
V Predictions Std            355.04303
V Predictions Max            1344.9437
V Predictions Min            287.4726
Log Pis Mean                 -0.30273664
Log Pis Std                  3.1405184
Log Pis Max                  14.213736
Log Pis Min                  -8.934364
Policy mu Mean               0.01795525
Policy mu Std                0.6023179
Policy mu Max                2.4688587
Policy mu Min                -2.7591007
Policy log std Mean          -0.9664091
Policy log std Std           0.23228358
Policy log std Max           -0.37376523
Policy log std Min           -1.9977748
Z mean eval                  1.0533936
Z variance eval              0.009705989
total_rewards                [3446.72979267 3482.13674101 3510.98666667  808.58296215 3505.1409649
 1471.58569289 3420.91961499  474.78613911 3246.19461033 3228.61261181]
total_rewards_mean           2659.5675796532405
total_rewards_std            1165.9531976139242
total_rewards_max            3510.986666669063
total_rewards_min            474.78613911404375
Number of train steps total  860000
Number of env steps total    919509
Number of rollouts total     0
Train Time (s)               153.17816523695365
(Previous) Eval Time (s)     31.648490220773965
Sample Time (s)              11.152932598721236
Epoch Time (s)               195.97958805644885
Total Train Time (s)         39465.230606240686
Epoch                        214
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:53:38.024626 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #214 | Epoch Duration: 196.07856464385986
2020-01-12 12:53:38.024983 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0520691
Z variance train             0.00970504
KL Divergence                20.88248
KL Loss                      2.088248
QF Loss                      940.49524
VF Loss                      513.9438
Policy Loss                  -887.16876
Q Predictions Mean           884.6302
Q Predictions Std            383.9508
Q Predictions Max            1344.9052
Q Predictions Min            -39.068974
V Predictions Mean           883.8685
V Predictions Std            378.3601
V Predictions Max            1348.8994
V Predictions Min            -15.54138
Log Pis Mean                 -0.6711627
Log Pis Std                  2.9683008
Log Pis Max                  16.142033
Log Pis Min                  -7.433329
Policy mu Mean               0.008360857
Policy mu Std                0.54641414
Policy mu Max                3.0662796
Policy mu Min                -1.8935554
Policy log std Mean          -0.9530932
Policy log std Std           0.21716149
Policy log std Max           -0.36470175
Policy log std Min           -2.2556303
Z mean eval                  1.2571627
Z variance eval              0.01858793
total_rewards                [ 359.98269294 3405.01078687  304.90227167 2163.20773547 1884.40015289
 3074.87473821 1231.20674678 2162.88892796 1270.10342193 3320.83987142]
total_rewards_mean           1917.741734613613
total_rewards_std            1075.160583685056
total_rewards_max            3405.0107868702444
total_rewards_min            304.90227166853725
Number of train steps total  864000
Number of env steps total    925553
Number of rollouts total     0
Train Time (s)               152.23874430498108
(Previous) Eval Time (s)     22.813901566900313
Sample Time (s)              11.83336024126038
Epoch Time (s)               186.88600611314178
Total Train Time (s)         39652.21526749665
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:56:45.012431 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #215 | Epoch Duration: 186.9872009754181
2020-01-12 12:56:45.012680 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2618476
Z variance train             0.018630624
KL Divergence                19.896626
KL Loss                      1.9896625
QF Loss                      749.7224
VF Loss                      86.79006
Policy Loss                  -901.6723
Q Predictions Mean           895.9202
Q Predictions Std            352.869
Q Predictions Max            1388.7954
Q Predictions Min            267.6648
V Predictions Mean           903.7409
V Predictions Std            353.92535
V Predictions Max            1378.905
V Predictions Min            269.33224
Log Pis Mean                 -0.6754687
Log Pis Std                  3.0850675
Log Pis Max                  15.0997925
Log Pis Min                  -7.5623055
Policy mu Mean               0.021798844
Policy mu Std                0.5660567
Policy mu Max                4.2474527
Policy mu Min                -3.115043
Policy log std Mean          -0.9410199
Policy log std Std           0.2163366
Policy log std Max           -0.2251668
Policy log std Min           -2.2043052
Z mean eval                  1.0339466
Z variance eval              0.010987368
total_rewards                [3501.98225652 1502.46116777  695.070499   2267.94492589  954.01673448
  256.48177253  276.45380352 2033.20746376 2643.91785838  514.51843259]
total_rewards_mean           1464.6054914453002
total_rewards_std            1055.395423536985
total_rewards_max            3501.9822565211207
total_rewards_min            256.48177253438143
Number of train steps total  868000
Number of env steps total    932996
Number of rollouts total     0
Train Time (s)               152.8662296710536
(Previous) Eval Time (s)     21.443103343248367
Sample Time (s)              11.691148414742202
Epoch Time (s)               186.00048142904416
Total Train Time (s)         39838.3052353668
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:59:51.105427 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #216 | Epoch Duration: 186.0925636291504
2020-01-12 12:59:51.105731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0369211
Z variance train             0.010922072
KL Divergence                21.144821
KL Loss                      2.1144822
QF Loss                      710.2988
VF Loss                      502.7683
Policy Loss                  -895.2052
Q Predictions Mean           888.1302
Q Predictions Std            373.80707
Q Predictions Max            1340.2723
Q Predictions Min            -30.564705
V Predictions Mean           887.57153
V Predictions Std            368.0322
V Predictions Max            1319.7715
V Predictions Min            -27.739586
Log Pis Mean                 -0.3748311
Log Pis Std                  3.9057455
Log Pis Max                  29.79597
Log Pis Min                  -9.912023
Policy mu Mean               -0.014532551
Policy mu Std                0.5855598
Policy mu Max                3.3737993
Policy mu Min                -4.544677
Policy log std Mean          -0.96728265
Policy log std Std           0.24341579
Policy log std Max           -0.35854262
Policy log std Min           -2.5176845
Z mean eval                  1.0862513
Z variance eval              0.006170531
total_rewards                [ 900.7220203  3451.77448926 1007.02251907 3393.84325873 2763.42090114
 3500.14773945 3430.61580828 1623.8895088  3639.60450833 3621.96830988]
total_rewards_mean           2733.300906325104
total_rewards_std            1058.6794560518754
total_rewards_max            3639.6045083340687
total_rewards_min            900.7220203018705
Number of train steps total  872000
Number of env steps total    941451
Number of rollouts total     0
Train Time (s)               152.22731381375343
(Previous) Eval Time (s)     30.741844782605767
Sample Time (s)              12.26102087739855
Epoch Time (s)               195.23017947375774
Total Train Time (s)         40033.62483820552
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:03:06.427897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #217 | Epoch Duration: 195.32198023796082
2020-01-12 13:03:06.428125 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0905297
Z variance train             0.006161225
KL Divergence                23.302212
KL Loss                      2.3302212
QF Loss                      694.7346
VF Loss                      205.04457
Policy Loss                  -901.0982
Q Predictions Mean           892.8197
Q Predictions Std            363.27267
Q Predictions Max            1360.2156
Q Predictions Min            -78.37477
V Predictions Mean           901.9614
V Predictions Std            359.4029
V Predictions Max            1361.6077
V Predictions Min            234.05603
Log Pis Mean                 -0.41285503
Log Pis Std                  2.9915266
Log Pis Max                  14.429856
Log Pis Min                  -9.4182205
Policy mu Mean               0.044989284
Policy mu Std                0.531157
Policy mu Max                2.526271
Policy mu Min                -2.1523848
Policy log std Mean          -0.9812096
Policy log std Std           0.2348779
Policy log std Max           -0.23174232
Policy log std Min           -2.3065958
Z mean eval                  1.1456001
Z variance eval              0.0064252107
total_rewards                [ 630.90459809 2111.83589336 3394.43055002  751.32032516 3614.63839419
 3427.75605282 3489.49178472 2091.20938345 3508.46979746 3472.24318014]
total_rewards_mean           2649.229995941335
total_rewards_std            1117.6314969395023
total_rewards_max            3614.6383941861313
total_rewards_min            630.9045980873758
Number of train steps total  876000
Number of env steps total    947617
Number of rollouts total     0
Train Time (s)               142.75870225206017
(Previous) Eval Time (s)     31.047897251322865
Sample Time (s)              10.918971291277558
Epoch Time (s)               184.7255707946606
Total Train Time (s)         40218.436047584284
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:06:11.241139 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #218 | Epoch Duration: 184.81287097930908
2020-01-12 13:06:11.241314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1425617
Z variance train             0.0064301416
KL Divergence                23.5196
KL Loss                      2.35196
QF Loss                      534.1946
VF Loss                      97.61308
Policy Loss                  -891.7483
Q Predictions Mean           888.23
Q Predictions Std            358.47522
Q Predictions Max            1305.0496
Q Predictions Min            238.71294
V Predictions Mean           895.1884
V Predictions Std            356.1423
V Predictions Max            1299.7476
V Predictions Min            238.13322
Log Pis Mean                 -0.49401292
Log Pis Std                  3.2896905
Log Pis Max                  17.218636
Log Pis Min                  -9.881902
Policy mu Mean               0.009349431
Policy mu Std                0.5852878
Policy mu Max                2.8721154
Policy mu Min                -5.2544494
Policy log std Mean          -0.9609106
Policy log std Std           0.1967777
Policy log std Max           -0.2738843
Policy log std Min           -2.0012667
Z mean eval                  1.1117778
Z variance eval              0.020970404
total_rewards                [1506.90626109  627.28750767   79.57604274 2156.47968481  723.33298251
  144.76667086 3482.62412055  424.46818728 3608.86925043 1848.01509081]
total_rewards_mean           1460.2325798762072
total_rewards_std            1236.5399404574102
total_rewards_max            3608.869250429254
total_rewards_min            79.5760427441585
Number of train steps total  880000
Number of env steps total    954162
Number of rollouts total     0
Train Time (s)               142.85363600729033
(Previous) Eval Time (s)     19.713828315027058
Sample Time (s)              11.227911747992039
Epoch Time (s)               173.79537607030943
Total Train Time (s)         40392.31700220611
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:09:05.125040 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #219 | Epoch Duration: 173.8835883140564
2020-01-12 13:09:05.125217 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1087917
Z variance train             0.020998131
KL Divergence                19.050858
KL Loss                      1.9050858
QF Loss                      712.7364
VF Loss                      142.02356
Policy Loss                  -945.1904
Q Predictions Mean           938.33264
Q Predictions Std            349.01086
Q Predictions Max            1346.8586
Q Predictions Min            -73.603516
V Predictions Mean           944.7093
V Predictions Std            347.19742
V Predictions Max            1343.8185
V Predictions Min            1.2079456
Log Pis Mean                 -0.19685076
Log Pis Std                  2.9039598
Log Pis Max                  13.953887
Log Pis Min                  -7.5140276
Policy mu Mean               0.028094571
Policy mu Std                0.5529997
Policy mu Max                4.029097
Policy mu Min                -2.9685848
Policy log std Mean          -0.9894315
Policy log std Std           0.21609317
Policy log std Max           -0.3944052
Policy log std Min           -2.132679
Z mean eval                  1.1108825
Z variance eval              0.009215349
total_rewards                [3358.16453333 3336.56120004 3463.2242379  1244.37703864  939.28629956
 2058.86413991 3382.64330128 3366.29259271 3621.7170833  2631.97751598]
total_rewards_mean           2740.3107942658858
total_rewards_std            938.0189559825859
total_rewards_max            3621.7170833041764
total_rewards_min            939.286299555184
Number of train steps total  884000
Number of env steps total    963151
Number of rollouts total     0
Train Time (s)               149.528456246946
(Previous) Eval Time (s)     32.1980996709317
Sample Time (s)              11.342490293551236
Epoch Time (s)               193.06904621142894
Total Train Time (s)         40585.511425500736
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:12:18.322605 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #220 | Epoch Duration: 193.19724106788635
2020-01-12 13:12:18.322822 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1014066
Z variance train             0.009251902
KL Divergence                21.704035
KL Loss                      2.1704035
QF Loss                      867.5927
VF Loss                      128.97476
Policy Loss                  -876.47986
Q Predictions Mean           872.13086
Q Predictions Std            384.49704
Q Predictions Max            1349.5562
Q Predictions Min            266.944
V Predictions Mean           878.8003
V Predictions Std            380.783
V Predictions Max            1346.7499
V Predictions Min            263.08133
Log Pis Mean                 -0.6353954
Log Pis Std                  2.8627539
Log Pis Max                  7.8040743
Log Pis Min                  -8.558731
Policy mu Mean               0.020720461
Policy mu Std                0.5339548
Policy mu Max                2.5840986
Policy mu Min                -2.3793557
Policy log std Mean          -0.95409346
Policy log std Std           0.20982286
Policy log std Max           -0.41899276
Policy log std Min           -1.7982469
Z mean eval                  1.0894177
Z variance eval              0.0106304865
total_rewards                [3367.97975829 3042.08414844 1708.23324165 3377.61010812  131.69527761
  391.07619302 1819.10541145 3125.69440151  674.59743275  801.44388858]
total_rewards_mean           1843.9519861416215
total_rewards_std            1235.6809225725356
total_rewards_max            3377.6101081164416
total_rewards_min            131.69527761280477
Number of train steps total  888000
Number of env steps total    971544
Number of rollouts total     0
Train Time (s)               153.0391508191824
(Previous) Eval Time (s)     22.767821945250034
Sample Time (s)              12.89212818769738
Epoch Time (s)               188.6991009521298
Total Train Time (s)         40774.30350813642
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:15:27.117675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #221 | Epoch Duration: 188.7946903705597
2020-01-12 13:15:27.117886 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0861099
Z variance train             0.01054958
KL Divergence                20.39949
KL Loss                      2.0399492
QF Loss                      1549.8374
VF Loss                      210.58345
Policy Loss                  -903.3842
Q Predictions Mean           896.3767
Q Predictions Std            361.78116
Q Predictions Max            1320.1488
Q Predictions Min            140.17133
V Predictions Mean           904.57886
V Predictions Std            356.41507
V Predictions Max            1326.6567
V Predictions Min            143.51457
Log Pis Mean                 -0.6266073
Log Pis Std                  2.9338453
Log Pis Max                  13.356194
Log Pis Min                  -7.658085
Policy mu Mean               0.002356824
Policy mu Std                0.5616844
Policy mu Max                3.9638104
Policy mu Min                -2.633087
Policy log std Mean          -0.9486705
Policy log std Std           0.21807466
Policy log std Max           -0.40341777
Policy log std Min           -1.920791
Z mean eval                  1.1334115
Z variance eval              0.00906706
total_rewards                [3449.12629845  276.02830821 2794.87495478 3108.34782455  884.95319823
 3243.84073468 3561.61923235 2998.66886676 3231.12472677 2363.82467654]
total_rewards_mean           2591.240882132609
total_rewards_std            1063.5388320890693
total_rewards_max            3561.619232348402
total_rewards_min            276.02830821104925
Number of train steps total  892000
Number of env steps total    981247
Number of rollouts total     0
Train Time (s)               151.51406367728487
(Previous) Eval Time (s)     29.330424583051354
Sample Time (s)              12.133256665430963
Epoch Time (s)               192.97774492576718
Total Train Time (s)         40967.37685357593
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:18:40.193808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #222 | Epoch Duration: 193.07577228546143
2020-01-12 13:18:40.194011 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1348085
Z variance train             0.009117676
KL Divergence                22.131548
KL Loss                      2.2131548
QF Loss                      771.0454
VF Loss                      164.19342
Policy Loss                  -933.3517
Q Predictions Mean           929.4752
Q Predictions Std            367.3683
Q Predictions Max            1350.232
Q Predictions Min            -43.39413
V Predictions Mean           937.42413
V Predictions Std            365.52475
V Predictions Max            1360.964
V Predictions Min            10.8334875
Log Pis Mean                 -0.39348286
Log Pis Std                  3.5574522
Log Pis Max                  23.345644
Log Pis Min                  -7.8422613
Policy mu Mean               0.029243862
Policy mu Std                0.60211134
Policy mu Max                3.1952276
Policy mu Min                -4.801361
Policy log std Mean          -0.97254777
Policy log std Std           0.22915174
Policy log std Max           -0.30097246
Policy log std Min           -2.3281367
Z mean eval                  1.1273339
Z variance eval              0.008206891
total_rewards                [1159.3657228  3054.86553368 1423.0244002  3050.3839375  3023.99852132
 1151.63202315 2946.87759522 1518.72182013 2638.0905912  3202.86140007]
total_rewards_mean           2316.982154526934
total_rewards_std            836.7424867379684
total_rewards_max            3202.861400073753
total_rewards_min            1151.6320231472678
Number of train steps total  896000
Number of env steps total    991341
Number of rollouts total     0
Train Time (s)               153.3740158630535
(Previous) Eval Time (s)     31.85820882022381
Sample Time (s)              13.493303225375712
Epoch Time (s)               198.72552790865302
Total Train Time (s)         41166.219809986185
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:21:59.042404 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #223 | Epoch Duration: 198.8482151031494
2020-01-12 13:21:59.042699 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1293156
Z variance train             0.0082023395
KL Divergence                22.015776
KL Loss                      2.2015777
QF Loss                      786.6825
VF Loss                      141.12097
Policy Loss                  -905.252
Q Predictions Mean           896.77783
Q Predictions Std            365.6717
Q Predictions Max            1341.0485
Q Predictions Min            229.19896
V Predictions Mean           901.59143
V Predictions Std            362.03226
V Predictions Max            1361.193
V Predictions Min            234.01492
Log Pis Mean                 -0.31257653
Log Pis Std                  3.4618628
Log Pis Max                  17.841286
Log Pis Min                  -10.996071
Policy mu Mean               0.027841572
Policy mu Std                0.5800564
Policy mu Max                2.4154863
Policy mu Min                -2.9792593
Policy log std Mean          -0.9792067
Policy log std Std           0.23558569
Policy log std Max           -0.393196
Policy log std Min           -2.1647792
Z mean eval                  1.0839096
Z variance eval              0.008636532
total_rewards                [ 416.71694138 3368.59052759 3479.63575492 3108.17144975 3307.98952922
 3089.30553203 3282.21144638 3173.27345958  286.56798108 3346.05081284]
total_rewards_mean           2685.851343476461
total_rewards_std            1172.9890272609257
total_rewards_max            3479.635754920965
total_rewards_min            286.56798108035457
Number of train steps total  900000
Number of env steps total    1001342
Number of rollouts total     0
Train Time (s)               150.47462534811348
(Previous) Eval Time (s)     28.747707074973732
Sample Time (s)              12.061193058732897
Epoch Time (s)               191.2835254818201
Total Train Time (s)         41357.600110953674
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:25:10.424541 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #224 | Epoch Duration: 191.38165378570557
2020-01-12 13:25:10.424750 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #224 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0889461
Z variance train             0.008616801
KL Divergence                20.687473
KL Loss                      2.0687473
QF Loss                      688.0986
VF Loss                      171.6298
Policy Loss                  -919.3247
Q Predictions Mean           913.50977
Q Predictions Std            356.75903
Q Predictions Max            1316.9731
Q Predictions Min            258.7308
V Predictions Mean           925.6764
V Predictions Std            354.8003
V Predictions Max            1321.6447
V Predictions Min            281.79953
Log Pis Mean                 -0.13802496
Log Pis Std                  3.0298092
Log Pis Max                  19.350962
Log Pis Min                  -8.112691
Policy mu Mean               0.035153627
Policy mu Std                0.5812242
Policy mu Max                2.3597114
Policy mu Min                -2.1063461
Policy log std Mean          -0.9735175
Policy log std Std           0.21946363
Policy log std Max           -0.4751015
Policy log std Min           -2.013599
Z mean eval                  0.9798425
Z variance eval              0.011370969
total_rewards                [3361.02511447 3380.13424609 3346.2095713  3112.89807161 2859.2411793
 3356.01484682 1667.30699777 1752.31465424 3339.9526948  1238.9536347 ]
total_rewards_mean           2741.405101111394
total_rewards_std            802.1805354939836
total_rewards_max            3380.1342460877277
total_rewards_min            1238.953634699528
Number of train steps total  904000
Number of env steps total    1010307
Number of rollouts total     0
Train Time (s)               142.39840598218143
(Previous) Eval Time (s)     29.50606978079304
Sample Time (s)              11.350968895945698
Epoch Time (s)               183.25544465892017
Total Train Time (s)         41540.94145125337
Epoch                        225
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:28:13.768638 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #225 | Epoch Duration: 183.34372639656067
2020-01-12 13:28:13.768845 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9822014
Z variance train             0.011426857
KL Divergence                20.632097
KL Loss                      2.0632098
QF Loss                      404.17603
VF Loss                      116.90861
Policy Loss                  -881.8271
Q Predictions Mean           875.98816
Q Predictions Std            367.80133
Q Predictions Max            1339.8917
Q Predictions Min            253.44058
V Predictions Mean           885.13684
V Predictions Std            364.47095
V Predictions Max            1332.358
V Predictions Min            255.34418
Log Pis Mean                 -0.79298985
Log Pis Std                  2.8765407
Log Pis Max                  10.524383
Log Pis Min                  -13.116009
Policy mu Mean               0.024093118
Policy mu Std                0.5266647
Policy mu Max                1.9104835
Policy mu Min                -2.0595422
Policy log std Mean          -0.9637495
Policy log std Std           0.21775016
Policy log std Max           -0.39382035
Policy log std Min           -2.0161989
Z mean eval                  1.0029427
Z variance eval              0.008404545
total_rewards                [3137.48323026 3211.44157989 3522.81278292 3469.19161473 3345.98493848
  465.56663109 3400.7860716   250.66701624 1371.27151996 3425.09119443]
total_rewards_mean           2560.0296579594647
total_rewards_std            1253.6874624088398
total_rewards_max            3522.8127829179857
total_rewards_min            250.6670162403882
Number of train steps total  908000
Number of env steps total    1020239
Number of rollouts total     0
Train Time (s)               142.841070080176
(Previous) Eval Time (s)     27.386314434930682
Sample Time (s)              11.034292434342206
Epoch Time (s)               181.26167694944888
Total Train Time (s)         41722.295519151725
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:31:15.125701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #226 | Epoch Duration: 181.3567008972168
2020-01-12 13:31:15.125913 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0021131
Z variance train             0.008411325
KL Divergence                20.792067
KL Loss                      2.0792067
QF Loss                      587.3385
VF Loss                      204.66016
Policy Loss                  -919.7437
Q Predictions Mean           912.93695
Q Predictions Std            362.8558
Q Predictions Max            1354.6044
Q Predictions Min            -9.553106
V Predictions Mean           919.8507
V Predictions Std            354.83148
V Predictions Max            1350.613
V Predictions Min            106.0408
Log Pis Mean                 -0.20002341
Log Pis Std                  3.796005
Log Pis Max                  25.389488
Log Pis Min                  -8.072117
Policy mu Mean               0.02522787
Policy mu Std                0.63477343
Policy mu Max                4.459966
Policy mu Min                -4.6702604
Policy log std Mean          -0.9590362
Policy log std Std           0.23329076
Policy log std Max           0.1305685
Policy log std Min           -2.5214872
Z mean eval                  1.0436821
Z variance eval              0.011383456
total_rewards                [3186.48062    1490.21820685 3274.34947225 1874.47575254 2505.25617008
  425.06078474 2211.205476   1110.21486003 3370.29392068  329.69633281]
total_rewards_mean           1977.7251595981684
total_rewards_std            1074.3387461383172
total_rewards_max            3370.2939206822757
total_rewards_min            329.6963328076648
Number of train steps total  912000
Number of env steps total    1030018
Number of rollouts total     0
Train Time (s)               152.3609280041419
(Previous) Eval Time (s)     29.2587446346879
Sample Time (s)              11.45753941917792
Epoch Time (s)               193.07721205800772
Total Train Time (s)         41915.458814802114
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:34:28.292013 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #227 | Epoch Duration: 193.16595005989075
2020-01-12 13:34:28.292201 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #227 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0432187
Z variance train             0.011330978
KL Divergence                20.999586
KL Loss                      2.0999587
QF Loss                      1446.1147
VF Loss                      158.80916
Policy Loss                  -892.5854
Q Predictions Mean           884.0792
Q Predictions Std            383.27017
Q Predictions Max            1341.6573
Q Predictions Min            46.42083
V Predictions Mean           896.36475
V Predictions Std            378.905
V Predictions Max            1335.3392
V Predictions Min            78.34902
Log Pis Mean                 -0.46192825
Log Pis Std                  3.1882281
Log Pis Max                  16.9756
Log Pis Min                  -7.9009323
Policy mu Mean               0.04845103
Policy mu Std                0.5812822
Policy mu Max                2.5234375
Policy mu Min                -3.412922
Policy log std Mean          -0.9514599
Policy log std Std           0.21682806
Policy log std Max           -0.45971876
Policy log std Min           -2.082944
Z mean eval                  1.1623867
Z variance eval              0.008388213
total_rewards                [ 552.65987941 3398.27166176 3412.44884385 2003.2067246  3362.2777772
 1177.73686127 3381.82074455  490.53265126 3308.57078429 1484.64980824]
total_rewards_mean           2257.217573643192
total_rewards_std            1186.6402680925423
total_rewards_max            3412.4488438452827
total_rewards_min            490.53265125779035
Number of train steps total  916000
Number of env steps total    1036995
Number of rollouts total     0
Train Time (s)               151.94644141197205
(Previous) Eval Time (s)     27.851295885629952
Sample Time (s)              11.969364290125668
Epoch Time (s)               191.76710158772767
Total Train Time (s)         42107.321071711835
Epoch                        228
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:37:40.157363 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #228 | Epoch Duration: 191.86501026153564
2020-01-12 13:37:40.157569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.152477
Z variance train             0.008380844
KL Divergence                21.740688
KL Loss                      2.174069
QF Loss                      602.27246
VF Loss                      230.59587
Policy Loss                  -930.5867
Q Predictions Mean           925.7979
Q Predictions Std            370.06793
Q Predictions Max            1378.8336
Q Predictions Min            -2.3324075
V Predictions Mean           927.9612
V Predictions Std            364.3485
V Predictions Max            1364.7401
V Predictions Min            171.46774
Log Pis Mean                 -0.61790675
Log Pis Std                  2.7266095
Log Pis Max                  10.983053
Log Pis Min                  -9.456513
Policy mu Mean               0.003665031
Policy mu Std                0.5393888
Policy mu Max                2.74459
Policy mu Min                -2.36298
Policy log std Mean          -0.95089304
Policy log std Std           0.21177667
Policy log std Max           -0.36441702
Policy log std Min           -2.3102617
Z mean eval                  1.055562
Z variance eval              0.048506822
total_rewards                [ 405.3348635  2603.19716672 1976.98159463  437.85532191  640.46660573
   72.21252218 3035.30855173   11.98832453  238.28162706 1337.83404117]
total_rewards_mean           1075.9460619164931
total_rewards_std            1045.932023048141
total_rewards_max            3035.3085517347527
total_rewards_min            11.98832453425825
Number of train steps total  920000
Number of env steps total    1048046
Number of rollouts total     0
Train Time (s)               151.39502540510148
(Previous) Eval Time (s)     12.694666124880314
Sample Time (s)              11.739715456031263
Epoch Time (s)               175.82940698601305
Total Train Time (s)         42283.239797668066
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:40:36.083245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #229 | Epoch Duration: 175.9254972934723
2020-01-12 13:40:36.083502 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0581326
Z variance train             0.04878763
KL Divergence                19.701496
KL Loss                      1.9701496
QF Loss                      922.94104
VF Loss                      136.47707
Policy Loss                  -954.48505
Q Predictions Mean           946.93475
Q Predictions Std            341.9736
Q Predictions Max            1377.8597
Q Predictions Min            138.54591
V Predictions Mean           954.8389
V Predictions Std            336.63916
V Predictions Max            1379.5991
V Predictions Min            248.00287
Log Pis Mean                 -0.2550932
Log Pis Std                  3.4233375
Log Pis Max                  25.383125
Log Pis Min                  -7.27303
Policy mu Mean               0.03917828
Policy mu Std                0.5996841
Policy mu Max                3.0748322
Policy mu Min                -3.9349911
Policy log std Mean          -0.9702296
Policy log std Std           0.21184908
Policy log std Max           -0.38020062
Policy log std Min           -1.9162459
Z mean eval                  1.159076
Z variance eval              0.033362452
total_rewards                [1945.40980548 3184.61534187 2988.485479   1546.07305462  880.75004512
 1702.63792492 1103.09121287 2679.43573073 3481.0385839   552.4359755 ]
total_rewards_mean           2006.3973154003954
total_rewards_std            973.9187541511008
total_rewards_max            3481.0385839012724
total_rewards_min            552.4359754953351
Number of train steps total  924000
Number of env steps total    1055181
Number of rollouts total     0
Train Time (s)               152.90710812201723
(Previous) Eval Time (s)     24.183250745758414
Sample Time (s)              11.475939242634922
Epoch Time (s)               188.56629811041057
Total Train Time (s)         42471.90110553941
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:43:44.747860 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #230 | Epoch Duration: 188.66416144371033
2020-01-12 13:43:44.748086 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.154204
Z variance train             0.033008832
KL Divergence                19.877327
KL Loss                      1.9877328
QF Loss                      478.17407
VF Loss                      216.14874
Policy Loss                  -930.15607
Q Predictions Mean           921.6034
Q Predictions Std            376.23508
Q Predictions Max            1355.416
Q Predictions Min            -21.463543
V Predictions Mean           928.0955
V Predictions Std            364.98196
V Predictions Max            1350.2684
V Predictions Min            0.29812956
Log Pis Mean                 -0.31408072
Log Pis Std                  3.290569
Log Pis Max                  19.555176
Log Pis Min                  -8.203912
Policy mu Mean               0.03353916
Policy mu Std                0.5865805
Policy mu Max                4.35701
Policy mu Min                -3.7668362
Policy log std Mean          -0.97675854
Policy log std Std           0.22663137
Policy log std Max           -0.054548264
Policy log std Min           -2.1482813
Z mean eval                  1.2365501
Z variance eval              0.04482454
total_rewards                [2456.5429326  3547.1496093  1751.75395694  682.34137036 1105.77181872
 1321.68972009  303.68860736 3202.24985889 1326.02415285  845.28002578]
total_rewards_mean           1654.2492052887815
total_rewards_std            1028.3367739236792
total_rewards_max            3547.1496093002643
total_rewards_min            303.6886073602167
Number of train steps total  928000
Number of env steps total    1065072
Number of rollouts total     0
Train Time (s)               148.98108132788911
(Previous) Eval Time (s)     25.17146109882742
Sample Time (s)              11.872250916901976
Epoch Time (s)               186.0247933436185
Total Train Time (s)         42658.019441580866
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:46:50.869066 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #231 | Epoch Duration: 186.1208052635193
2020-01-12 13:46:50.869289 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2430469
Z variance train             0.04488218
KL Divergence                19.52415
KL Loss                      1.9524151
QF Loss                      1581.2502
VF Loss                      240.68105
Policy Loss                  -911.23975
Q Predictions Mean           905.24805
Q Predictions Std            368.15463
Q Predictions Max            1342.8097
Q Predictions Min            49.39763
V Predictions Mean           911.22595
V Predictions Std            368.61264
V Predictions Max            1338.8676
V Predictions Min            31.931149
Log Pis Mean                 -0.27782792
Log Pis Std                  2.8552756
Log Pis Max                  16.824053
Log Pis Min                  -7.2803864
Policy mu Mean               0.026317045
Policy mu Std                0.55757153
Policy mu Max                2.8298187
Policy mu Min                -2.950369
Policy log std Mean          -0.95057154
Policy log std Std           0.21504804
Policy log std Max           -0.47138405
Policy log std Min           -2.1825151
Z mean eval                  1.0923171
Z variance eval              0.02225418
total_rewards                [3458.43705114 3388.23318387  806.62027355 3432.80928397 1007.8170545
   30.46855685 3533.782279    999.47158011 3674.92762671  401.03415205]
total_rewards_mean           2073.360104177331
total_rewards_std            1451.0896323360203
total_rewards_max            3674.9276267118403
total_rewards_min            30.468556854224122
Number of train steps total  932000
Number of env steps total    1073410
Number of rollouts total     0
Train Time (s)               142.72506200475618
(Previous) Eval Time (s)     21.765310898888856
Sample Time (s)              8.690001456998289
Epoch Time (s)               173.18037436064333
Total Train Time (s)         42831.550703004
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:49:44.403108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #232 | Epoch Duration: 173.5336730480194
2020-01-12 13:49:44.403312 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0926995
Z variance train             0.022811044
KL Divergence                21.544535
KL Loss                      2.1544535
QF Loss                      1264.7405
VF Loss                      104.81219
Policy Loss                  -913.714
Q Predictions Mean           910.43854
Q Predictions Std            385.95258
Q Predictions Max            1392.1045
Q Predictions Min            49.649525
V Predictions Mean           918.7176
V Predictions Std            380.88754
V Predictions Max            1382.3185
V Predictions Min            285.77725
Log Pis Mean                 -0.5357073
Log Pis Std                  3.0260916
Log Pis Max                  11.865629
Log Pis Min                  -7.203336
Policy mu Mean               -0.030382391
Policy mu Std                0.55613065
Policy mu Max                2.0001624
Policy mu Min                -2.6705072
Policy log std Mean          -0.96633923
Policy log std Std           0.23321998
Policy log std Max           -0.18254793
Policy log std Min           -2.0862262
Z mean eval                  1.0420574
Z variance eval              0.0293452
total_rewards                [3721.60286308 3423.12588313 3504.81379757 3643.84351325 1321.31560125
 3466.39302257 3400.90130627 3457.49199421 3579.76108976  592.94906874]
total_rewards_mean           3011.2198139847033
total_rewards_std            1044.193490384928
total_rewards_max            3721.602863077159
total_rewards_min            592.9490687432183
Number of train steps total  936000
Number of env steps total    1082231
Number of rollouts total     0
Train Time (s)               143.93105149595067
(Previous) Eval Time (s)     31.770420981105417
Sample Time (s)              11.44264671439305
Epoch Time (s)               187.14411919144914
Total Train Time (s)         43018.79010802088
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:52:51.645355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #233 | Epoch Duration: 187.24189400672913
2020-01-12 13:52:51.645582 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0415903
Z variance train             0.030642167
KL Divergence                20.002022
KL Loss                      2.0002022
QF Loss                      936.56824
VF Loss                      403.7328
Policy Loss                  -874.0947
Q Predictions Mean           871.1139
Q Predictions Std            358.20483
Q Predictions Max            1282.432
Q Predictions Min            18.68047
V Predictions Mean           868.03314
V Predictions Std            359.96436
V Predictions Max            1284.3285
V Predictions Min            -20.19348
Log Pis Mean                 -0.58608884
Log Pis Std                  2.91507
Log Pis Max                  11.354082
Log Pis Min                  -7.343309
Policy mu Mean               -0.0070300205
Policy mu Std                0.5461407
Policy mu Max                2.0300229
Policy mu Min                -3.675143
Policy log std Mean          -0.9639807
Policy log std Std           0.23092197
Policy log std Max           -0.36541128
Policy log std Min           -2.1076198
Z mean eval                  1.1240591
Z variance eval              0.05254973
total_rewards                [2022.06481066   15.09976082  541.18043446 3019.16088886 3473.63641003
 3298.90555519 1843.12351911  468.00698149 3462.3998618   224.72394579]
total_rewards_mean           1836.8302168211326
total_rewards_std            1355.0463700492946
total_rewards_max            3473.6364100304145
total_rewards_min            15.099760824940084
Number of train steps total  940000
Number of env steps total    1092553
Number of rollouts total     0
Train Time (s)               153.32133066980168
(Previous) Eval Time (s)     23.070256853010505
Sample Time (s)              10.424064503517002
Epoch Time (s)               186.8156520263292
Total Train Time (s)         43205.69263430871
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:55:58.552064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #234 | Epoch Duration: 186.90627455711365
2020-01-12 13:55:58.552509 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1224697
Z variance train             0.05474638
KL Divergence                17.184523
KL Loss                      1.7184523
QF Loss                      2051.2568
VF Loss                      607.27783
Policy Loss                  -959.38544
Q Predictions Mean           952.2831
Q Predictions Std            367.0647
Q Predictions Max            1369.4739
Q Predictions Min            4.8446045
V Predictions Mean           957.938
V Predictions Std            363.31696
V Predictions Max            1353.9651
V Predictions Min            61.65128
Log Pis Mean                 -0.44457513
Log Pis Std                  3.4860406
Log Pis Max                  19.51731
Log Pis Min                  -6.6931963
Policy mu Mean               0.03936018
Policy mu Std                0.61035347
Policy mu Max                5.5363812
Policy mu Min                -2.704654
Policy log std Mean          -0.93639266
Policy log std Std           0.22684969
Policy log std Max           -0.3332585
Policy log std Min           -2.3969905
Z mean eval                  1.1349107
Z variance eval              0.020363268
total_rewards                [2457.34221128 1532.13173199 2956.4618496  3337.3681571  3190.38401007
 3407.87458612 3454.61131043 2790.83821497 1849.31163861 2078.18110955]
total_rewards_mean           2705.450481971604
total_rewards_std            657.5785126640658
total_rewards_max            3454.611310425644
total_rewards_min            1532.1317319917503
Number of train steps total  944000
Number of env steps total    1100788
Number of rollouts total     0
Train Time (s)               151.72795113222674
(Previous) Eval Time (s)     32.01938941795379
Sample Time (s)              13.10589276952669
Epoch Time (s)               196.85323331970721
Total Train Time (s)         43402.635143416
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:59:15.496825 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #235 | Epoch Duration: 196.94403338432312
2020-01-12 13:59:15.497016 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1355871
Z variance train             0.020280955
KL Divergence                19.198975
KL Loss                      1.9198974
QF Loss                      728.157
VF Loss                      106.12516
Policy Loss                  -935.0047
Q Predictions Mean           927.65125
Q Predictions Std            347.15445
Q Predictions Max            1320.6426
Q Predictions Min            -53.561653
V Predictions Mean           936.2538
V Predictions Std            338.72818
V Predictions Max            1323.9185
V Predictions Min            267.8594
Log Pis Mean                 -0.6497662
Log Pis Std                  3.2435586
Log Pis Max                  21.421875
Log Pis Min                  -10.047176
Policy mu Mean               0.021627808
Policy mu Std                0.5582959
Policy mu Max                3.2569945
Policy mu Min                -3.8628843
Policy log std Mean          -0.9665386
Policy log std Std           0.22460397
Policy log std Max           -0.3865549
Policy log std Min           -2.0917306
Z mean eval                  1.0284746
Z variance eval              0.012884798
total_rewards                [1220.7168114  2577.88307071  313.86981874 3349.57539416 3646.40977673
 2574.79451298  733.14697029  480.91345815 3391.51072238 3171.78032349]
total_rewards_mean           2146.0600859027395
total_rewards_std            1251.2094149162083
total_rewards_max            3646.4097767309204
total_rewards_min            313.86981874435304
Number of train steps total  948000
Number of env steps total    1108027
Number of rollouts total     0
Train Time (s)               152.13047480909154
(Previous) Eval Time (s)     26.19838339043781
Sample Time (s)              11.827008934225887
Epoch Time (s)               190.15586713375524
Total Train Time (s)         43592.88321714243
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:02:25.753167 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #236 | Epoch Duration: 190.25596261024475
2020-01-12 14:02:25.753495 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0323293
Z variance train             0.012827684
KL Divergence                20.427492
KL Loss                      2.0427492
QF Loss                      1231.4478
VF Loss                      237.85504
Policy Loss                  -963.49884
Q Predictions Mean           961.1222
Q Predictions Std            346.80524
Q Predictions Max            1377.6156
Q Predictions Min            -32.38489
V Predictions Mean           966.54346
V Predictions Std            346.40314
V Predictions Max            1372.6925
V Predictions Min            -26.935558
Log Pis Mean                 -0.27036715
Log Pis Std                  3.339405
Log Pis Max                  25.264408
Log Pis Min                  -6.271396
Policy mu Mean               -0.004623328
Policy mu Std                0.5898372
Policy mu Max                4.239464
Policy mu Min                -4.6021867
Policy log std Mean          -0.95923907
Policy log std Std           0.21080579
Policy log std Max           0.26792336
Policy log std Min           -2.5879254
Z mean eval                  1.1418412
Z variance eval              0.007841455
total_rewards                [2504.1045265   650.47586504 3238.65792562  939.40260986  558.83217179
  825.86295956  326.76832695 1088.43572717 2173.79778879 3530.4821734 ]
total_rewards_mean           1583.6820074679351
total_rewards_std            1116.2467399532466
total_rewards_max            3530.482173399275
total_rewards_min            326.76832695151705
Number of train steps total  952000
Number of env steps total    1115632
Number of rollouts total     0
Train Time (s)               152.23667739797384
(Previous) Eval Time (s)     23.86213499866426
Sample Time (s)              12.204515722114593
Epoch Time (s)               188.3033281187527
Total Train Time (s)         43781.28326462954
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:05:34.153648 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #237 | Epoch Duration: 188.3999330997467
2020-01-12 14:05:34.153991 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1389719
Z variance train             0.007860223
KL Divergence                22.78633
KL Loss                      2.2786329
QF Loss                      643.96985
VF Loss                      265.23596
Policy Loss                  -943.8849
Q Predictions Mean           941.03296
Q Predictions Std            355.41406
Q Predictions Max            1377.0594
Q Predictions Min            29.833637
V Predictions Mean           942.92554
V Predictions Std            357.54416
V Predictions Max            1363.1077
V Predictions Min            -11.231587
Log Pis Mean                 -0.47781518
Log Pis Std                  3.269095
Log Pis Max                  14.74946
Log Pis Min                  -9.020661
Policy mu Mean               0.05057237
Policy mu Std                0.57571805
Policy mu Max                3.2190335
Policy mu Min                -2.385942
Policy log std Mean          -0.9823581
Policy log std Std           0.23013704
Policy log std Max           -0.3508188
Policy log std Min           -2.6553397
Z mean eval                  1.0112462
Z variance eval              0.017583352
total_rewards                [3500.3485688  3334.95689623 3373.46480607 3275.86526607 3280.77644412
 3558.01745802 3471.78398805 3469.18548996 3468.9117071  3215.25843694]
total_rewards_mean           3394.8569061377375
total_rewards_std            108.6973274403017
total_rewards_max            3558.0174580248977
total_rewards_min            3215.258436935823
Number of train steps total  956000
Number of env steps total    1122946
Number of rollouts total     0
Train Time (s)               146.03535106312484
(Previous) Eval Time (s)     36.39892614912242
Sample Time (s)              11.635161973070353
Epoch Time (s)               194.0694391853176
Total Train Time (s)         43975.43907234259
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:08:48.312467 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #238 | Epoch Duration: 194.158296585083
2020-01-12 14:08:48.312666 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0183742
Z variance train             0.01750674
KL Divergence                18.418667
KL Loss                      1.8418667
QF Loss                      921.9597
VF Loss                      240.72984
Policy Loss                  -957.0018
Q Predictions Mean           951.98267
Q Predictions Std            341.25452
Q Predictions Max            1383.4286
Q Predictions Min            278.18088
V Predictions Mean           950.4068
V Predictions Std            337.6648
V Predictions Max            1341.5471
V Predictions Min            270.72498
Log Pis Mean                 0.053841017
Log Pis Std                  3.095274
Log Pis Max                  10.163962
Log Pis Min                  -10.137326
Policy mu Mean               0.030767372
Policy mu Std                0.60512507
Policy mu Max                2.3146112
Policy mu Min                -2.1811714
Policy log std Mean          -0.999194
Policy log std Std           0.24138096
Policy log std Max           -0.45769626
Policy log std Min           -2.2467048
Z mean eval                  1.0909203
Z variance eval              0.004908925
total_rewards                [3471.20376504 3468.5435007   394.77321274 3424.61673574  302.94017446
 3343.97091543 2577.72803001   56.64233447 3574.13823601 2440.53915138]
total_rewards_mean           2305.5096055983986
total_rewards_std            1395.0860087706867
total_rewards_max            3574.1382360106477
total_rewards_min            56.64233446922654
Number of train steps total  960000
Number of env steps total    1133814
Number of rollouts total     0
Train Time (s)               143.27745526097715
(Previous) Eval Time (s)     28.178314078133553
Sample Time (s)              11.105176826938987
Epoch Time (s)               182.5609461660497
Total Train Time (s)         44158.08968552807
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:11:50.965865 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #239 | Epoch Duration: 182.6530385017395
2020-01-12 14:11:50.966060 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0966747
Z variance train             0.0049033603
KL Divergence                22.139328
KL Loss                      2.2139328
QF Loss                      732.6404
VF Loss                      214.33682
Policy Loss                  -936.79724
Q Predictions Mean           928.71497
Q Predictions Std            351.72958
Q Predictions Max            1371.805
Q Predictions Min            268.12387
V Predictions Mean           934.66486
V Predictions Std            347.0353
V Predictions Max            1380.125
V Predictions Min            278.68857
Log Pis Mean                 -0.32038838
Log Pis Std                  3.2584763
Log Pis Max                  15.685337
Log Pis Min                  -7.2559924
Policy mu Mean               0.041270945
Policy mu Std                0.5808669
Policy mu Max                2.8650699
Policy mu Min                -3.4927053
Policy log std Mean          -0.9754087
Policy log std Std           0.23892702
Policy log std Max           -0.35654336
Policy log std Min           -2.4043834
Z mean eval                  1.0910223
Z variance eval              0.010666641
total_rewards                [1732.53932841 3338.90017691 3431.36954518 3509.7657659  3546.75046671
 3615.43562521  949.72546892 1064.40789246 3381.60237436 3435.14435893]
total_rewards_mean           2800.564100298482
total_rewards_std            1035.9688436477195
total_rewards_max            3615.4356252119974
total_rewards_min            949.7254689154508
Number of train steps total  964000
Number of env steps total    1143617
Number of rollouts total     0
Train Time (s)               147.0860477676615
(Previous) Eval Time (s)     30.143505103420466
Sample Time (s)              11.946330766193569
Epoch Time (s)               189.17588363727555
Total Train Time (s)         44347.35312539479
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:15:00.232465 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #240 | Epoch Duration: 189.26625967025757
2020-01-12 14:15:00.232667 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0799986
Z variance train             0.010603447
KL Divergence                20.637787
KL Loss                      2.0637786
QF Loss                      852.12714
VF Loss                      190.85847
Policy Loss                  -976.7627
Q Predictions Mean           971.22015
Q Predictions Std            342.80377
Q Predictions Max            1352.8551
Q Predictions Min            274.21228
V Predictions Mean           985.56555
V Predictions Std            342.68274
V Predictions Max            1366.8505
V Predictions Min            285.61185
Log Pis Mean                 -0.4818326
Log Pis Std                  2.8365195
Log Pis Max                  13.784443
Log Pis Min                  -7.6231966
Policy mu Mean               -0.01716477
Policy mu Std                0.55577344
Policy mu Max                2.4261878
Policy mu Min                -2.5970654
Policy log std Mean          -0.99491477
Policy log std Std           0.21731931
Policy log std Max           -0.4398899
Policy log std Min           -2.2077103
Z mean eval                  1.1033597
Z variance eval              0.014336077
total_rewards                [3107.22353037  511.99038493  946.71557282  636.00507315 1626.08179832
 3534.02706292 1058.40232366 1220.79164305 2712.04037333 1352.90784114]
total_rewards_mean           1670.6185603701244
total_rewards_std            1011.8122816160117
total_rewards_max            3534.027062922103
total_rewards_min            511.99038492898757
Number of train steps total  968000
Number of env steps total    1153481
Number of rollouts total     0
Train Time (s)               153.99764177994803
(Previous) Eval Time (s)     24.42372405389324
Sample Time (s)              10.584663328249007
Epoch Time (s)               189.00602916209027
Total Train Time (s)         44536.590056455694
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:18:09.472470 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #241 | Epoch Duration: 189.2396411895752
2020-01-12 14:18:09.472664 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0980827
Z variance train             0.014359942
KL Divergence                21.053238
KL Loss                      2.1053238
QF Loss                      753.55444
VF Loss                      167.55893
Policy Loss                  -928.3153
Q Predictions Mean           924.03394
Q Predictions Std            375.6601
Q Predictions Max            1358.7634
Q Predictions Min            20.751486
V Predictions Mean           929.1072
V Predictions Std            375.06955
V Predictions Max            1363.6344
V Predictions Min            14.454056
Log Pis Mean                 -0.537146
Log Pis Std                  3.392461
Log Pis Max                  24.289402
Log Pis Min                  -7.463187
Policy mu Mean               -0.012463575
Policy mu Std                0.5591422
Policy mu Max                3.5481687
Policy mu Min                -3.2725172
Policy log std Mean          -0.9475882
Policy log std Std           0.23941275
Policy log std Max           -0.0077391863
Policy log std Min           -2.1998038
Z mean eval                  0.98866737
Z variance eval              0.009433041
total_rewards                [3170.71792639 3456.15305715 3215.64873086 3223.25920004 3265.64487758
 3176.34617181 3381.10340057 3281.21477379 3214.29563687 3134.17454195]
total_rewards_mean           3251.855831700673
total_rewards_std            94.42871372314657
total_rewards_max            3456.1530571529975
total_rewards_min            3134.174541954344
Number of train steps total  972000
Number of env steps total    1163124
Number of rollouts total     0
Train Time (s)               152.87371760513633
(Previous) Eval Time (s)     35.98774336185306
Sample Time (s)              12.036249792668968
Epoch Time (s)               200.89771075965837
Total Train Time (s)         44737.57543276902
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:21:30.461050 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #242 | Epoch Duration: 200.98823714256287
2020-01-12 14:21:30.461245 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98645717
Z variance train             0.009483966
KL Divergence                21.980423
KL Loss                      2.1980424
QF Loss                      567.77625
VF Loss                      118.92252
Policy Loss                  -972.92834
Q Predictions Mean           969.00055
Q Predictions Std            359.17203
Q Predictions Max            1406.8164
Q Predictions Min            16.012321
V Predictions Mean           969.7638
V Predictions Std            359.1605
V Predictions Max            1399.5865
V Predictions Min            -68.30901
Log Pis Mean                 -0.48280013
Log Pis Std                  3.043638
Log Pis Max                  17.808495
Log Pis Min                  -6.0620804
Policy mu Mean               -0.021263644
Policy mu Std                0.5686338
Policy mu Max                3.3553221
Policy mu Min                -3.0019555
Policy log std Mean          -0.98453414
Policy log std Std           0.23721573
Policy log std Max           -0.3808025
Policy log std Min           -2.3144999
Z mean eval                  1.0811441
Z variance eval              0.033635385
total_rewards                [2132.76234447   26.57860261 1792.90858694 1514.72602846 1304.35883387
 1308.79325182 3378.18379802  502.75399887   88.99774363 2285.60229669]
total_rewards_mean           1433.566548536448
total_rewards_std            990.8705691838314
total_rewards_max            3378.1837980204755
total_rewards_min            26.578602613023083
Number of train steps total  976000
Number of env steps total    1171525
Number of rollouts total     0
Train Time (s)               154.46223454689607
(Previous) Eval Time (s)     18.79815675225109
Sample Time (s)              11.535108881536871
Epoch Time (s)               184.79550018068403
Total Train Time (s)         44922.47752701817
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:24:35.366964 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #243 | Epoch Duration: 184.90556383132935
2020-01-12 14:24:35.367212 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0653392
Z variance train             0.033519845
KL Divergence                19.955135
KL Loss                      1.9955136
QF Loss                      513.64795
VF Loss                      83.74453
Policy Loss                  -1051.2931
Q Predictions Mean           1047.776
Q Predictions Std            363.12875
Q Predictions Max            1435.36
Q Predictions Min            1.2844015
V Predictions Mean           1049.4932
V Predictions Std            361.80133
V Predictions Max            1432.7745
V Predictions Min            52.389896
Log Pis Mean                 -0.39650434
Log Pis Std                  2.4733012
Log Pis Max                  9.411968
Log Pis Min                  -7.313451
Policy mu Mean               0.016515322
Policy mu Std                0.5831845
Policy mu Max                3.5771825
Policy mu Min                -2.491882
Policy log std Mean          -0.9537176
Policy log std Std           0.21007775
Policy log std Max           -0.19586301
Policy log std Min           -1.8442247
Z mean eval                  1.0450838
Z variance eval              0.009899815
total_rewards                [3419.19260935 2768.306713   3302.83524683 1462.27394941 3444.90236114
 3522.41473289 3575.50812026 3554.90988063 3728.77342919 3277.92624594]
total_rewards_mean           3205.704328864479
total_rewards_std            630.9449780060189
total_rewards_max            3728.7734291863176
total_rewards_min            1462.2739494081052
Number of train steps total  980000
Number of env steps total    1180962
Number of rollouts total     0
Train Time (s)               152.26411103317514
(Previous) Eval Time (s)     33.75765220541507
Sample Time (s)              13.300572354346514
Epoch Time (s)               199.32233559293672
Total Train Time (s)         45121.88888255786
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:27:54.781802 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #244 | Epoch Duration: 199.41443133354187
2020-01-12 14:27:54.782008 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0401889
Z variance train             0.009877134
KL Divergence                20.938587
KL Loss                      2.0938587
QF Loss                      1537.2041
VF Loss                      138.0235
Policy Loss                  -976.0951
Q Predictions Mean           973.41833
Q Predictions Std            339.61536
Q Predictions Max            1360.6051
Q Predictions Min            173.7182
V Predictions Mean           977.49963
V Predictions Std            338.72177
V Predictions Max            1372.9089
V Predictions Min            257.79504
Log Pis Mean                 -0.8458695
Log Pis Std                  2.8435938
Log Pis Max                  13.244349
Log Pis Min                  -8.465018
Policy mu Mean               0.032301657
Policy mu Std                0.5577022
Policy mu Max                2.3438642
Policy mu Min                -2.7425728
Policy log std Mean          -0.934566
Policy log std Std           0.2400015
Policy log std Max           -0.26262355
Policy log std Min           -2.0416784
Z mean eval                  0.9928296
Z variance eval              0.013220479
total_rewards                [1182.98183648 3567.51059194 3307.12308029 3508.32213992  508.45347975
  393.71385466 2655.85407411 3600.36598882 1864.35897998  834.90336655]
total_rewards_mean           2142.3587392499016
total_rewards_std            1267.97417847736
total_rewards_max            3600.3659888169423
total_rewards_min            393.71385466028266
Number of train steps total  984000
Number of env steps total    1190960
Number of rollouts total     0
Train Time (s)               143.41525864508003
(Previous) Eval Time (s)     20.247795462142676
Sample Time (s)              10.456232178490609
Epoch Time (s)               174.11928628571332
Total Train Time (s)         45296.10381228058
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:30:48.999628 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #245 | Epoch Duration: 174.2174665927887
2020-01-12 14:30:48.999838 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99204075
Z variance train             0.0132360635
KL Divergence                21.348145
KL Loss                      2.1348145
QF Loss                      635.919
VF Loss                      71.78102
Policy Loss                  -951.60583
Q Predictions Mean           947.61707
Q Predictions Std            348.84268
Q Predictions Max            1363.8163
Q Predictions Min            106.42636
V Predictions Mean           951.3652
V Predictions Std            349.34988
V Predictions Max            1367.6273
V Predictions Min            119.01993
Log Pis Mean                 -0.59652025
Log Pis Std                  2.9696908
Log Pis Max                  15.434259
Log Pis Min                  -7.2448053
Policy mu Mean               0.013049705
Policy mu Std                0.5385621
Policy mu Max                2.307432
Policy mu Min                -2.3393593
Policy log std Mean          -0.94727325
Policy log std Std           0.24370693
Policy log std Max           -0.39109713
Policy log std Min           -2.1670346
Z mean eval                  1.0493863
Z variance eval              0.030276168
total_rewards                [1385.76740783 1188.13976632  716.21235349  174.02255203 3667.04339537
 2252.43963252 2694.32720661  146.21769604 1033.62759277  960.61885502]
total_rewards_mean           1421.8416457992612
total_rewards_std            1070.1205351377553
total_rewards_max            3667.043395366002
total_rewards_min            146.21769603978507
Number of train steps total  988000
Number of env steps total    1201733
Number of rollouts total     0
Train Time (s)               143.6013448331505
(Previous) Eval Time (s)     14.153801708016545
Sample Time (s)              11.785528672393411
Epoch Time (s)               169.54067521356046
Total Train Time (s)         45465.73286121292
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:33:38.631314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #246 | Epoch Duration: 169.63133144378662
2020-01-12 14:33:38.631491 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0476573
Z variance train             0.03013878
KL Divergence                19.396948
KL Loss                      1.9396948
QF Loss                      631.98035
VF Loss                      375.16525
Policy Loss                  -964.10767
Q Predictions Mean           959.2672
Q Predictions Std            371.37192
Q Predictions Max            1410.7396
Q Predictions Min            216.16676
V Predictions Mean           956.59015
V Predictions Std            367.2883
V Predictions Max            1386.1093
V Predictions Min            288.39395
Log Pis Mean                 -0.36819762
Log Pis Std                  3.397614
Log Pis Max                  22.99379
Log Pis Min                  -8.414314
Policy mu Mean               -0.00698448
Policy mu Std                0.572363
Policy mu Max                2.3152518
Policy mu Min                -3.744757
Policy log std Mean          -0.95708394
Policy log std Std           0.27393937
Policy log std Max           -0.25835758
Policy log std Min           -2.8646374
Z mean eval                  1.1999711
Z variance eval              0.010388443
total_rewards                [3478.30792888  383.88783771  249.83496729 1594.75519045 1190.07197547
 2435.77866019 2155.10463979 1425.31843425 3425.81289456 3644.17883822]
total_rewards_mean           1998.30513668114
total_rewards_std            1181.56482618227
total_rewards_max            3644.178838221572
total_rewards_min            249.83496729216262
Number of train steps total  992000
Number of env steps total    1212127
Number of rollouts total     0
Train Time (s)               149.5087153748609
(Previous) Eval Time (s)     26.193310072645545
Sample Time (s)              11.965480098966509
Epoch Time (s)               187.66750554647297
Total Train Time (s)         45653.487407962326
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:36:46.388936 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #247 | Epoch Duration: 187.75731229782104
2020-01-12 14:36:46.389118 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #247 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1924822
Z variance train             0.010403683
KL Divergence                20.620205
KL Loss                      2.0620205
QF Loss                      1687.1753
VF Loss                      254.4296
Policy Loss                  -952.37225
Q Predictions Mean           948.5033
Q Predictions Std            358.00717
Q Predictions Max            1415.0232
Q Predictions Min            292.5406
V Predictions Mean           958.8263
V Predictions Std            358.61667
V Predictions Max            1410.0385
V Predictions Min            300.84692
Log Pis Mean                 -0.33353665
Log Pis Std                  3.0198476
Log Pis Max                  14.63559
Log Pis Min                  -7.149976
Policy mu Mean               -0.014790118
Policy mu Std                0.58367
Policy mu Max                2.9644904
Policy mu Min                -2.8869889
Policy log std Mean          -0.9519507
Policy log std Std           0.24231909
Policy log std Max           -0.38706988
Policy log std Min           -2.340812
Z mean eval                  1.1014087
Z variance eval              0.0105519835
total_rewards                [  55.36041361 3491.65657734  969.01934493  423.28416875  156.5227717
 3186.00715797  886.40626451  961.27496089  202.59288572  502.48918615]
total_rewards_mean           1083.461373157301
total_rewards_std            1172.708778899034
total_rewards_max            3491.6565773434177
total_rewards_min            55.360413610355685
Number of train steps total  996000
Number of env steps total    1221812
Number of rollouts total     0
Train Time (s)               152.88073267322034
(Previous) Eval Time (s)     18.757918587885797
Sample Time (s)              11.802446173969656
Epoch Time (s)               183.4410974350758
Total Train Time (s)         45837.01827404322
Epoch                        248
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:39:49.923346 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #248 | Epoch Duration: 183.53408455848694
2020-01-12 14:39:49.923545 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1056677
Z variance train             0.010566036
KL Divergence                20.625336
KL Loss                      2.0625336
QF Loss                      993.2765
VF Loss                      204.20071
Policy Loss                  -959.9129
Q Predictions Mean           957.0936
Q Predictions Std            381.47678
Q Predictions Max            1420.5369
Q Predictions Min            -14.477545
V Predictions Mean           958.8235
V Predictions Std            382.3129
V Predictions Max            1409.5966
V Predictions Min            72.5171
Log Pis Mean                 -0.40822062
Log Pis Std                  3.3793035
Log Pis Max                  11.410946
Log Pis Min                  -8.0171585
Policy mu Mean               0.037674524
Policy mu Std                0.5834073
Policy mu Max                2.839424
Policy mu Min                -2.27975
Policy log std Mean          -0.9687236
Policy log std Std           0.26899117
Policy log std Max           -0.4104563
Policy log std Min           -2.2199283
Z mean eval                  1.2100631
Z variance eval              0.00858981
total_rewards                [2231.79867767 2272.49288716 1083.73669227 2424.76444654  142.59591494
 3167.74608748  352.24081121 2259.95766155 3195.47564461 3400.32575773]
total_rewards_mean           2053.1134581162923
total_rewards_std            1100.2762982548054
total_rewards_max            3400.3257577327363
total_rewards_min            142.5959149373052
Number of train steps total  1000000
Number of env steps total    1231651
Number of rollouts total     0
Train Time (s)               152.63570267381147
(Previous) Eval Time (s)     24.0417970251292
Sample Time (s)              11.266486328560859
Epoch Time (s)               187.94398602750152
Total Train Time (s)         46025.05111516267
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:42:57.957466 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #249 | Epoch Duration: 188.03379321098328
2020-01-12 14:42:57.957593 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1984608
Z variance train             0.008560783
KL Divergence                21.211685
KL Loss                      2.1211686
QF Loss                      593.839
VF Loss                      90.664566
Policy Loss                  -1018.7179
Q Predictions Mean           1016.2212
Q Predictions Std            353.7492
Q Predictions Max            1407.8921
Q Predictions Min            309.58005
V Predictions Mean           1019.218
V Predictions Std            350.40475
V Predictions Max            1395.9998
V Predictions Min            318.00784
Log Pis Mean                 0.008065678
Log Pis Std                  2.8651118
Log Pis Max                  12.613289
Log Pis Min                  -7.3812838
Policy mu Mean               0.030368902
Policy mu Std                0.5846158
Policy mu Max                2.3367429
Policy mu Min                -2.2249138
Policy log std Mean          -0.9708394
Policy log std Std           0.25496534
Policy log std Max           -0.36129087
Policy log std Min           -2.0490386
Z mean eval                  1.1075809
Z variance eval              0.011417593
total_rewards                [3288.15848999 3369.69979018 1071.00160125 3457.76259929 1375.91334841
  493.29628389 3362.25442234 3328.13111421 1984.05235781 3504.69614405]
total_rewards_mean           2523.4966151421595
total_rewards_std            1110.2579424825005
total_rewards_max            3504.696144053269
total_rewards_min            493.2962838882322
Number of train steps total  1004000
Number of env steps total    1241094
Number of rollouts total     0
Train Time (s)               154.2679670653306
(Previous) Eval Time (s)     25.47615888994187
Sample Time (s)              10.556021339260042
Epoch Time (s)               190.3001472945325
Total Train Time (s)         46215.5332111991
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:46:08.443407 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #250 | Epoch Duration: 190.48569869995117
2020-01-12 14:46:08.443625 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1055027
Z variance train             0.011385612
KL Divergence                21.631798
KL Loss                      2.1631799
QF Loss                      480.3116
VF Loss                      109.57513
Policy Loss                  -945.3663
Q Predictions Mean           943.9733
Q Predictions Std            378.85126
Q Predictions Max            1411.773
Q Predictions Min            -0.7067529
V Predictions Mean           951.1282
V Predictions Std            377.79077
V Predictions Max            1407.6472
V Predictions Min            37.402473
Log Pis Mean                 -0.7488664
Log Pis Std                  3.118898
Log Pis Max                  16.606075
Log Pis Min                  -8.238204
Policy mu Mean               0.017628198
Policy mu Std                0.5572905
Policy mu Max                2.724751
Policy mu Min                -2.3857179
Policy log std Mean          -0.91561925
Policy log std Std           0.23365502
Policy log std Max           -0.34865427
Policy log std Min           -2.0935931
Z mean eval                  1.0435594
Z variance eval              0.007429057
total_rewards                [1814.87868234 3419.93229888  116.44435881 2901.39960505 3384.93596234
 1269.57933305  628.42990022  424.67659944 2925.26104361  737.8406231 ]
total_rewards_mean           1762.3378406850447
total_rewards_std            1229.2075632050999
total_rewards_max            3419.932298883111
total_rewards_min            116.44435880804025
Number of train steps total  1008000
Number of env steps total    1250001
Number of rollouts total     0
Train Time (s)               152.72866003774107
(Previous) Eval Time (s)     21.199861652217805
Sample Time (s)              11.976923607289791
Epoch Time (s)               185.90544529724866
Total Train Time (s)         46401.52538098395
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:49:14.443679 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #251 | Epoch Duration: 185.99987745285034
2020-01-12 14:49:14.443891 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0491229
Z variance train             0.007526861
KL Divergence                22.035412
KL Loss                      2.2035413
QF Loss                      565.5577
VF Loss                      148.39537
Policy Loss                  -983.7127
Q Predictions Mean           978.8701
Q Predictions Std            374.0981
Q Predictions Max            1392.366
Q Predictions Min            5.418974
V Predictions Mean           981.71063
V Predictions Std            368.10556
V Predictions Max            1380.773
V Predictions Min            69.15481
Log Pis Mean                 -0.6079149
Log Pis Std                  3.049263
Log Pis Max                  14.095161
Log Pis Min                  -8.636501
Policy mu Mean               -0.017280154
Policy mu Std                0.5739599
Policy mu Max                3.4158287
Policy mu Min                -3.4777076
Policy log std Mean          -0.9395584
Policy log std Std           0.24021424
Policy log std Max           -0.0006175041
Policy log std Min           -2.2173352
Z mean eval                  1.1636106
Z variance eval              0.003882389
total_rewards                [2373.19429688 2656.00586622 1385.59068588  863.73634503  134.58035296
 1939.61765672 2826.35671796  912.01952068   66.29978097  494.99640942]
total_rewards_mean           1365.2397632715627
total_rewards_std            977.9182878793899
total_rewards_max            2826.356717964889
total_rewards_min            66.29978097073281
Number of train steps total  1012000
Number of env steps total    1259929
Number of rollouts total     0
Train Time (s)               143.0417911047116
(Previous) Eval Time (s)     20.170757967978716
Sample Time (s)              12.022869301959872
Epoch Time (s)               175.23541837465018
Total Train Time (s)         46576.85743171722
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:52:09.776731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #252 | Epoch Duration: 175.33265566825867
2020-01-12 14:52:09.777010 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1654608
Z variance train             0.0038822498
KL Divergence                25.159367
KL Loss                      2.5159366
QF Loss                      410.2617
VF Loss                      208.13739
Policy Loss                  -979.9922
Q Predictions Mean           975.78674
Q Predictions Std            367.34067
Q Predictions Max            1417.3673
Q Predictions Min            -45.672382
V Predictions Mean           979.3299
V Predictions Std            364.18692
V Predictions Max            1409.3473
V Predictions Min            -20.092735
Log Pis Mean                 -0.8124721
Log Pis Std                  3.272414
Log Pis Max                  17.989975
Log Pis Min                  -8.4723835
Policy mu Mean               -0.027522746
Policy mu Std                0.56693614
Policy mu Max                2.4721007
Policy mu Min                -3.2181013
Policy log std Mean          -0.9000351
Policy log std Std           0.24824318
Policy log std Max           -0.08922279
Policy log std Min           -2.4492865
Z mean eval                  1.0517375
Z variance eval              0.015819862
total_rewards                [ 564.84213612 3272.47265678 3235.69152842 1947.78514751 1927.36021837
 1984.03279578  411.71272337 3296.321922   1950.82146708  648.77307103]
total_rewards_mean           1923.9813666461264
total_rewards_std            1057.7148767177296
total_rewards_max            3296.3219219961857
total_rewards_min            411.71272336936556
Number of train steps total  1016000
Number of env steps total    1267646
Number of rollouts total     0
Train Time (s)               142.6859728381969
(Previous) Eval Time (s)     24.6161771658808
Sample Time (s)              13.357610593549907
Epoch Time (s)               180.6597605976276
Total Train Time (s)         46757.60775711201
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:55:10.529941 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #253 | Epoch Duration: 180.75275421142578
2020-01-12 14:55:10.530143 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0523497
Z variance train             0.015893197
KL Divergence                22.447565
KL Loss                      2.2447565
QF Loss                      893.3608
VF Loss                      1239.1978
Policy Loss                  -1008.06165
Q Predictions Mean           1001.4392
Q Predictions Std            362.61572
Q Predictions Max            1412.9923
Q Predictions Min            49.547913
V Predictions Mean           1004.9823
V Predictions Std            357.33167
V Predictions Max            1403.588
V Predictions Min            177.569
Log Pis Mean                 -0.479546
Log Pis Std                  3.2632315
Log Pis Max                  17.839947
Log Pis Min                  -8.836822
Policy mu Mean               -0.038474612
Policy mu Std                0.5682539
Policy mu Max                3.2566044
Policy mu Min                -2.6505573
Policy log std Mean          -0.95296
Policy log std Std           0.24994639
Policy log std Max           -0.33909988
Policy log std Min           -2.5998957
Z mean eval                  1.0259831
Z variance eval              0.026686918
total_rewards                [1432.20819817 2057.97266756 2215.23932589 1652.43133586 3476.57873121
 3088.81893302 3572.41507014  197.75056986 3642.1183738  1434.38763456]
total_rewards_mean           2276.992084008544
total_rewards_std            1087.589437203967
total_rewards_max            3642.1183738011673
total_rewards_min            197.75056986425975
Number of train steps total  1020000
Number of env steps total    1277184
Number of rollouts total     0
Train Time (s)               151.53827206417918
(Previous) Eval Time (s)     27.693305043969303
Sample Time (s)              11.660873922985047
Epoch Time (s)               190.89245103113353
Total Train Time (s)         46948.60149055673
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:58:21.528222 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #254 | Epoch Duration: 190.99787044525146
2020-01-12 14:58:21.528622 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0255909
Z variance train             0.02672771
KL Divergence                18.5566
KL Loss                      1.8556601
QF Loss                      756.9948
VF Loss                      195.53532
Policy Loss                  -916.61395
Q Predictions Mean           909.6544
Q Predictions Std            384.34238
Q Predictions Max            1417.4673
Q Predictions Min            1.620048
V Predictions Mean           917.58264
V Predictions Std            377.0772
V Predictions Max            1405.133
V Predictions Min            315.67276
Log Pis Mean                 -0.44316232
Log Pis Std                  3.2927654
Log Pis Max                  13.916138
Log Pis Min                  -7.0535946
Policy mu Mean               -8.041016e-05
Policy mu Std                0.551775
Policy mu Max                2.3631678
Policy mu Min                -2.4540646
Policy log std Mean          -0.96528494
Policy log std Std           0.2682999
Policy log std Max           -0.305107
Policy log std Min           -2.5519032
Z mean eval                  1.274718
Z variance eval              0.012733149
total_rewards                [3113.24031798 1069.07353904 2414.26303954 3417.29143691  547.75798969
 3349.36546448 3430.21079084 3595.08576548 3506.54867808 3334.39431782]
total_rewards_mean           2777.723133986129
total_rewards_std            1039.5968866140554
total_rewards_max            3595.0857654824354
total_rewards_min            547.7579896852192
Number of train steps total  1024000
Number of env steps total    1284445
Number of rollouts total     0
Train Time (s)               152.18933157622814
(Previous) Eval Time (s)     30.770339787006378
Sample Time (s)              11.854491868522018
Epoch Time (s)               194.81416323175654
Total Train Time (s)         47143.50488226209
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:01:36.433760 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #255 | Epoch Duration: 194.90491437911987
2020-01-12 15:01:36.433952 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2774454
Z variance train             0.01277489
KL Divergence                20.316624
KL Loss                      2.0316625
QF Loss                      573.6678
VF Loss                      184.62036
Policy Loss                  -971.59314
Q Predictions Mean           969.73047
Q Predictions Std            374.389
Q Predictions Max            1414.2522
Q Predictions Min            323.78937
V Predictions Mean           976.4613
V Predictions Std            373.6716
V Predictions Max            1418.4696
V Predictions Min            330.46918
Log Pis Mean                 -0.78798974
Log Pis Std                  2.8559916
Log Pis Max                  7.5994015
Log Pis Min                  -7.6247625
Policy mu Mean               -0.02329218
Policy mu Std                0.5525654
Policy mu Max                2.1965036
Policy mu Min                -2.348581
Policy log std Mean          -0.91479677
Policy log std Std           0.23907724
Policy log std Max           -0.3046133
Policy log std Min           -1.9751239
Z mean eval                  1.1212847
Z variance eval              0.011008394
total_rewards                [3562.91859768  929.08500122 3477.16960721   99.6735101  1413.94426389
 2115.61082536 3579.66726113  857.23527075 3430.57566767 3478.05306449]
total_rewards_mean           2294.3933069485615
total_rewards_std            1300.209397597265
total_rewards_max            3579.6672611320864
total_rewards_min            99.67351009585302
Number of train steps total  1028000
Number of env steps total    1295403
Number of rollouts total     0
Train Time (s)               152.12493413081393
(Previous) Eval Time (s)     24.551784995943308
Sample Time (s)              13.138557231519371
Epoch Time (s)               189.8152763582766
Total Train Time (s)         47333.40723469015
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:04:46.339107 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #256 | Epoch Duration: 189.90501070022583
2020-01-12 15:04:46.339302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1272681
Z variance train             0.011048524
KL Divergence                20.444128
KL Loss                      2.0444129
QF Loss                      541.8827
VF Loss                      123.74128
Policy Loss                  -987.3609
Q Predictions Mean           983.2703
Q Predictions Std            372.46317
Q Predictions Max            1403.0764
Q Predictions Min            144.64854
V Predictions Mean           987.96826
V Predictions Std            371.61325
V Predictions Max            1407.2927
V Predictions Min            232.94688
Log Pis Mean                 -0.5437762
Log Pis Std                  2.8179288
Log Pis Max                  7.3534164
Log Pis Min                  -7.252457
Policy mu Mean               -0.00019567413
Policy mu Std                0.56547546
Policy mu Max                2.716228
Policy mu Min                -2.4111092
Policy log std Mean          -0.93705624
Policy log std Std           0.24887986
Policy log std Max           -0.3459618
Policy log std Min           -1.9588614
Z mean eval                  1.0589422
Z variance eval              0.021850096
total_rewards                [3429.25440714 3655.16665806 3599.25646138 2380.80486575 2291.67064108
 3696.7751051  3450.13529132 1703.36144767 2602.94689318 3453.00077216]
total_rewards_mean           3026.237254283458
total_rewards_std            676.9866981277162
total_rewards_max            3696.775105100231
total_rewards_min            1703.3614476738887
Number of train steps total  1032000
Number of env steps total    1304951
Number of rollouts total     0
Train Time (s)               153.44380103098229
(Previous) Eval Time (s)     33.5588319003582
Sample Time (s)              11.921953046694398
Epoch Time (s)               198.92458597803488
Total Train Time (s)         47532.42615406355
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:08:05.361929 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #257 | Epoch Duration: 199.0224597454071
2020-01-12 15:08:05.362250 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0435671
Z variance train             0.020754801
KL Divergence                20.183407
KL Loss                      2.0183408
QF Loss                      1320.0553
VF Loss                      1235.6359
Policy Loss                  -1016.94116
Q Predictions Mean           1006.16077
Q Predictions Std            355.56155
Q Predictions Max            1422.167
Q Predictions Min            -41.57386
V Predictions Mean           1007.6627
V Predictions Std            343.0182
V Predictions Max            1416.6117
V Predictions Min            332.48282
Log Pis Mean                 -0.46682066
Log Pis Std                  3.5455532
Log Pis Max                  24.586994
Log Pis Min                  -7.3202095
Policy mu Mean               0.033003762
Policy mu Std                0.61051565
Policy mu Max                3.6202292
Policy mu Min                -4.223944
Policy log std Mean          -0.9553637
Policy log std Std           0.25414628
Policy log std Max           -0.3733502
Policy log std Min           -2.100921
Z mean eval                  1.1210932
Z variance eval              0.038558997
total_rewards                [ 495.68136678  534.58402711  331.26454929 3339.10226857 1510.79386285
 1811.72330897  163.55852995 1543.07214602 3282.75417974  760.45729549]
total_rewards_mean           1377.2991534772175
total_rewards_std            1102.212478018769
total_rewards_max            3339.102268572518
total_rewards_min            163.55852994556608
Number of train steps total  1036000
Number of env steps total    1313673
Number of rollouts total     0
Train Time (s)               147.63197336997837
(Previous) Eval Time (s)     19.24743855698034
Sample Time (s)              12.437786253169179
Epoch Time (s)               179.3171981801279
Total Train Time (s)         47711.83348304825
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:11:04.772432 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #258 | Epoch Duration: 179.40999555587769
2020-01-12 15:11:04.772626 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0905963
Z variance train             0.038269572
KL Divergence                17.931997
KL Loss                      1.7931998
QF Loss                      621.9378
VF Loss                      199.03836
Policy Loss                  -938.82214
Q Predictions Mean           931.7727
Q Predictions Std            379.37598
Q Predictions Max            1415.4243
Q Predictions Min            -84.789734
V Predictions Mean           941.1276
V Predictions Std            374.85052
V Predictions Max            1424.9164
V Predictions Min            186.54895
Log Pis Mean                 -0.6790633
Log Pis Std                  3.379529
Log Pis Max                  27.47678
Log Pis Min                  -9.399417
Policy mu Mean               0.029090106
Policy mu Std                0.6136143
Policy mu Max                5.1959405
Policy mu Min                -3.294137
Policy log std Mean          -0.8763515
Policy log std Std           0.2547637
Policy log std Max           -0.34198737
Policy log std Min           -2.765026
Z mean eval                  1.2664692
Z variance eval              0.013508886
total_rewards                [3598.67475043 3225.9793275   718.34393476 1698.82043827 1410.68020338
  507.46004456 1915.17840363 1652.5499886  1704.75236138 1931.59684625]
total_rewards_mean           1836.4036298751319
total_rewards_std            912.0986601436192
total_rewards_max            3598.6747504297978
total_rewards_min            507.46004455775
Number of train steps total  1040000
Number of env steps total    1324209
Number of rollouts total     0
Train Time (s)               143.430351795163
(Previous) Eval Time (s)     21.150936515070498
Sample Time (s)              11.353653507307172
Epoch Time (s)               175.93494181754068
Total Train Time (s)         47887.855085296556
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:14:00.797181 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #259 | Epoch Duration: 176.024409532547
2020-01-12 15:14:00.797373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2613623
Z variance train             0.013535192
KL Divergence                20.522697
KL Loss                      2.0522697
QF Loss                      615.7903
VF Loss                      136.63644
Policy Loss                  -1001.4429
Q Predictions Mean           998.54034
Q Predictions Std            353.59866
Q Predictions Max            1427.2428
Q Predictions Min            318.8953
V Predictions Mean           1004.79346
V Predictions Std            352.83472
V Predictions Max            1423.1476
V Predictions Min            331.3041
Log Pis Mean                 -0.22748621
Log Pis Std                  3.0226257
Log Pis Max                  9.73216
Log Pis Min                  -7.7073936
Policy mu Mean               -0.0033296647
Policy mu Std                0.6027421
Policy mu Max                2.5928192
Policy mu Min                -2.6040585
Policy log std Mean          -0.9360545
Policy log std Std           0.2541074
Policy log std Max           -0.2592193
Policy log std Min           -2.4294486
Z mean eval                  1.0549811
Z variance eval              0.11780335
total_rewards                [3469.14518384   74.78701992 1188.72264816 1979.85099038 2500.47004904
 1477.76318868 3459.27108609 3418.76510278  346.35307842 3504.83294142]
total_rewards_mean           2141.996128873838
total_rewards_std            1264.3741102761348
total_rewards_max            3504.8329414188565
total_rewards_min            74.78701992285053
Number of train steps total  1044000
Number of env steps total    1333206
Number of rollouts total     0
Train Time (s)               144.74825614597648
(Previous) Eval Time (s)     26.001518482342362
Sample Time (s)              11.771907612681389
Epoch Time (s)               182.52168224100024
Total Train Time (s)         48070.466037801
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:17:03.411088 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #260 | Epoch Duration: 182.6135721206665
2020-01-12 15:17:03.411704 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0560777
Z variance train             0.11874094
KL Divergence                18.409588
KL Loss                      1.8409588
QF Loss                      1039.7206
VF Loss                      212.41577
Policy Loss                  -929.5557
Q Predictions Mean           923.68744
Q Predictions Std            349.49496
Q Predictions Max            1345.974
Q Predictions Min            189.8198
V Predictions Mean           936.06134
V Predictions Std            348.94388
V Predictions Max            1342.7975
V Predictions Min            253.86061
Log Pis Mean                 -0.29409876
Log Pis Std                  3.6095948
Log Pis Max                  32.956535
Log Pis Min                  -7.8345647
Policy mu Mean               0.00038064318
Policy mu Std                0.6196219
Policy mu Max                4.299395
Policy mu Min                -6.455852
Policy log std Mean          -0.9538676
Policy log std Std           0.25336772
Policy log std Max           -0.35124266
Policy log std Min           -2.8354535
Z mean eval                  1.0225323
Z variance eval              0.037147522
total_rewards                [ 171.37618013 3520.5624896  2648.23398116 3422.74678431   54.60270254
 2441.79466041 1988.17142889 1834.02333741 3647.70597258 1059.44551062]
total_rewards_mean           2078.8663047646774
total_rewards_std            1250.8081859262002
total_rewards_max            3647.705972583606
total_rewards_min            54.60270254476933
Number of train steps total  1048000
Number of env steps total    1340610
Number of rollouts total     0
Train Time (s)               152.46801265422255
(Previous) Eval Time (s)     22.764653909020126
Sample Time (s)              11.44701334927231
Epoch Time (s)               186.67967991251498
Total Train Time (s)         48257.24638244836
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:20:10.196785 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #261 | Epoch Duration: 186.78488206863403
2020-01-12 15:20:10.197251 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0316833
Z variance train             0.037136726
KL Divergence                18.438156
KL Loss                      1.8438157
QF Loss                      1141.5146
VF Loss                      199.9754
Policy Loss                  -992.31055
Q Predictions Mean           985.3959
Q Predictions Std            375.75623
Q Predictions Max            1453.5891
Q Predictions Min            -37.490158
V Predictions Mean           986.3127
V Predictions Std            371.5458
V Predictions Max            1450.8624
V Predictions Min            36.02092
Log Pis Mean                 -0.61317563
Log Pis Std                  3.0485637
Log Pis Max                  13.089296
Log Pis Min                  -8.160755
Policy mu Mean               0.01798214
Policy mu Std                0.5758018
Policy mu Max                2.308783
Policy mu Min                -2.6106453
Policy log std Mean          -0.90633225
Policy log std Std           0.2651006
Policy log std Max           -0.281098
Policy log std Min           -2.3992486
Z mean eval                  1.1354636
Z variance eval              0.023675965
total_rewards                [3244.35487321 3345.42389209 3272.93651507 3238.30831568 3504.44995526
 2170.35790754 2928.61039729  118.50228411 3342.32638837 1203.97518538]
total_rewards_mean           2636.9245713990836
total_rewards_std            1076.37671413084
total_rewards_max            3504.449955259057
total_rewards_min            118.50228411216881
Number of train steps total  1052000
Number of env steps total    1347942
Number of rollouts total     0
Train Time (s)               151.92054936196655
(Previous) Eval Time (s)     35.73298595612869
Sample Time (s)              12.411701274104416
Epoch Time (s)               200.06523659219965
Total Train Time (s)         48457.425890097395
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:23:30.382559 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #262 | Epoch Duration: 200.1850664615631
2020-01-12 15:23:30.382821 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1361452
Z variance train             0.023560304
KL Divergence                19.714855
KL Loss                      1.9714855
QF Loss                      3238.4143
VF Loss                      138.30275
Policy Loss                  -975.81433
Q Predictions Mean           974.54004
Q Predictions Std            381.30865
Q Predictions Max            1452.6578
Q Predictions Min            329.3814
V Predictions Mean           973.73413
V Predictions Std            380.7512
V Predictions Max            1434.5621
V Predictions Min            317.9382
Log Pis Mean                 -0.89055085
Log Pis Std                  3.2120075
Log Pis Max                  11.8768635
Log Pis Min                  -9.398873
Policy mu Mean               0.015277432
Policy mu Std                0.58074063
Policy mu Max                2.047421
Policy mu Min                -2.5667214
Policy log std Mean          -0.893818
Policy log std Std           0.25531358
Policy log std Max           -0.28073376
Policy log std Min           -2.2421355
Z mean eval                  1.0972182
Z variance eval              0.014262527
total_rewards                [ 979.115486   3223.25764467 1821.34945706 3369.57201617 2106.02559214
  512.56377674 2092.67245316 2313.65405326 2288.05034423 2434.52144554]
total_rewards_mean           2114.0782268967696
total_rewards_std            831.7767995212739
total_rewards_max            3369.572016167972
total_rewards_min            512.5637767438276
Number of train steps total  1056000
Number of env steps total    1356313
Number of rollouts total     0
Train Time (s)               151.93757773004472
(Previous) Eval Time (s)     28.074006178881973
Sample Time (s)              10.286138582509011
Epoch Time (s)               190.2977224914357
Total Train Time (s)         48647.824837191496
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:26:40.781872 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #263 | Epoch Duration: 190.39887762069702
2020-01-12 15:26:40.782124 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0999556
Z variance train             0.014169132
KL Divergence                20.682068
KL Loss                      2.0682068
QF Loss                      523.5771
VF Loss                      78.43045
Policy Loss                  -986.4939
Q Predictions Mean           983.3728
Q Predictions Std            370.12772
Q Predictions Max            1420.0349
Q Predictions Min            287.97797
V Predictions Mean           990.56384
V Predictions Std            368.74033
V Predictions Max            1427.9993
V Predictions Min            281.29465
Log Pis Mean                 -0.72921705
Log Pis Std                  3.0800698
Log Pis Max                  12.125067
Log Pis Min                  -10.687713
Policy mu Mean               0.015749604
Policy mu Std                0.5868583
Policy mu Max                2.1278217
Policy mu Min                -2.5575778
Policy log std Mean          -0.89006424
Policy log std Std           0.2432506
Policy log std Max           -0.33787638
Policy log std Min           -1.8645499
Z mean eval                  1.1416595
Z variance eval              0.022087526
total_rewards                [ 919.14376042  624.46601592 2402.80287361  194.34497797 3534.95939607
 3525.05775449  616.79595563 1405.50517107 3535.84378606  919.54544568]
total_rewards_mean           1767.8465136917844
total_rewards_std            1281.3590037431584
total_rewards_max            3535.8437860556087
total_rewards_min            194.34497796567646
Number of train steps total  1060000
Number of env steps total    1366504
Number of rollouts total     0
Train Time (s)               153.39152397867292
(Previous) Eval Time (s)     24.8113626036793
Sample Time (s)              12.688567526172847
Epoch Time (s)               190.89145410852507
Total Train Time (s)         48838.80490246415
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:29:51.764657 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #264 | Epoch Duration: 190.98236632347107
2020-01-12 15:29:51.764845 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1335298
Z variance train             0.022308841
KL Divergence                21.523901
KL Loss                      2.1523902
QF Loss                      370.7269
VF Loss                      65.06588
Policy Loss                  -993.30084
Q Predictions Mean           991.822
Q Predictions Std            366.39505
Q Predictions Max            1440.607
Q Predictions Min            345.36154
V Predictions Mean           992.252
V Predictions Std            368.80347
V Predictions Max            1435.0673
V Predictions Min            345.11163
Log Pis Mean                 -0.9914065
Log Pis Std                  2.8477373
Log Pis Max                  8.232889
Log Pis Min                  -7.758939
Policy mu Mean               0.04133202
Policy mu Std                0.5473544
Policy mu Max                2.1836338
Policy mu Min                -2.2798214
Policy log std Mean          -0.8924537
Policy log std Std           0.24454509
Policy log std Max           0.16402662
Policy log std Min           -1.7937739
Z mean eval                  1.1308056
Z variance eval              0.022817496
total_rewards                [1457.32012249 3166.54630993 2353.1507163  1995.66496262  459.83474579
 1366.43817728 1014.08227226 3380.3440942  2604.80816611  178.20790946]
total_rewards_mean           1797.6397476430025
total_rewards_std            1034.706806926955
total_rewards_max            3380.344094196843
total_rewards_min            178.207909455884
Number of train steps total  1064000
Number of env steps total    1375426
Number of rollouts total     0
Train Time (s)               145.77149751828983
(Previous) Eval Time (s)     23.57444160571322
Sample Time (s)              12.678952483460307
Epoch Time (s)               182.02489160746336
Total Train Time (s)         49021.039857409894
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:32:54.002667 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #265 | Epoch Duration: 182.23768281936646
2020-01-12 15:32:54.002858 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1377815
Z variance train             0.022776976
KL Divergence                21.667103
KL Loss                      2.1667104
QF Loss                      12557.431
VF Loss                      219.4167
Policy Loss                  -1006.7237
Q Predictions Mean           1001.9133
Q Predictions Std            363.23593
Q Predictions Max            1427.9884
Q Predictions Min            253.71204
V Predictions Mean           1012.2774
V Predictions Std            356.53198
V Predictions Max            1431.6316
V Predictions Min            368.56363
Log Pis Mean                 -0.44907576
Log Pis Std                  3.2300537
Log Pis Max                  12.986841
Log Pis Min                  -11.288146
Policy mu Mean               0.017719176
Policy mu Std                0.58848625
Policy mu Max                2.790548
Policy mu Min                -2.2843485
Policy log std Mean          -0.91601914
Policy log std Std           0.26517665
Policy log std Max           -0.28222948
Policy log std Min           -2.63241
Z mean eval                  1.0194849
Z variance eval              0.03126047
total_rewards                [1033.52235826 3271.17808458 1910.07215124 3370.24222222  397.06169452
 1455.64495548 3089.20535254 2595.9586241  1185.14796792  672.38988631]
total_rewards_mean           1898.042329717145
total_rewards_std            1056.6679189983136
total_rewards_max            3370.242222217246
total_rewards_min            397.061694519091
Number of train steps total  1068000
Number of env steps total    1384324
Number of rollouts total     0
Train Time (s)               143.55532472673804
(Previous) Eval Time (s)     21.077080257236958
Sample Time (s)              12.927234946750104
Epoch Time (s)               177.5596399307251
Total Train Time (s)         49198.69020131091
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:35:51.656222 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #266 | Epoch Duration: 177.65322017669678
2020-01-12 15:35:51.656412 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #266 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0163825
Z variance train             0.030850684
KL Divergence                20.442493
KL Loss                      2.0442493
QF Loss                      901.7895
VF Loss                      244.62096
Policy Loss                  -993.62524
Q Predictions Mean           988.5857
Q Predictions Std            363.25845
Q Predictions Max            1434.2628
Q Predictions Min            294.40674
V Predictions Mean           994.45703
V Predictions Std            361.20065
V Predictions Max            1422.8003
V Predictions Min            358.27863
Log Pis Mean                 -0.72715056
Log Pis Std                  3.2219625
Log Pis Max                  8.74021
Log Pis Min                  -8.447862
Policy mu Mean               0.06508049
Policy mu Std                0.5897381
Policy mu Max                2.3987312
Policy mu Min                -2.294916
Policy log std Mean          -0.8961773
Policy log std Std           0.26712632
Policy log std Max           -0.33148998
Policy log std Min           -2.592592
Z mean eval                  1.1637948
Z variance eval              0.018457
total_rewards                [3386.13761296   13.72043123  389.00405463 1366.88844871 2378.5505562
   11.55901809  747.92655112 1670.28933788 3591.240153   3473.91119475]
total_rewards_mean           1702.9227358555868
total_rewards_std            1358.6142833725999
total_rewards_max            3591.2401530008556
total_rewards_min            11.559018085822826
Number of train steps total  1072000
Number of env steps total    1393076
Number of rollouts total     0
Train Time (s)               146.57793792989105
(Previous) Eval Time (s)     19.048806559760123
Sample Time (s)              11.677638425957412
Epoch Time (s)               177.30438291560858
Total Train Time (s)         49376.081369020976
Epoch                        267
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:38:49.050615 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #267 | Epoch Duration: 177.39405798912048
2020-01-12 15:38:49.050824 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1649635
Z variance train             0.018551117
KL Divergence                20.00369
KL Loss                      2.000369
QF Loss                      756.6199
VF Loss                      96.85214
Policy Loss                  -1047.8695
Q Predictions Mean           1041.5367
Q Predictions Std            357.2957
Q Predictions Max            1474.6753
Q Predictions Min            -86.29408
V Predictions Mean           1047.105
V Predictions Std            356.15622
V Predictions Max            1468.1676
V Predictions Min            39.009438
Log Pis Mean                 -0.32243687
Log Pis Std                  3.0119433
Log Pis Max                  8.331614
Log Pis Min                  -6.8299932
Policy mu Mean               0.022541888
Policy mu Std                0.61069655
Policy mu Max                2.5230992
Policy mu Min                -2.205474
Policy log std Mean          -0.9269272
Policy log std Std           0.26774442
Policy log std Max           -0.33930606
Policy log std Min           -2.50036
Z mean eval                  1.0066602
Z variance eval              0.013446513
total_rewards                [ 107.89161605 3568.14351598 2069.15240397 1228.4607857  2907.33001172
  292.46904362 3566.0053997  3489.13791508  161.7994286  1833.21051211]
total_rewards_mean           1922.360063252312
total_rewards_std            1356.2646450045875
total_rewards_max            3568.143515983891
total_rewards_min            107.89161605461902
Number of train steps total  1076000
Number of env steps total    1402675
Number of rollouts total     0
Train Time (s)               154.88831547275186
(Previous) Eval Time (s)     21.945882617030293
Sample Time (s)              10.855587437748909
Epoch Time (s)               187.68978552753106
Total Train Time (s)         49563.861293849535
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:41:56.833878 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #268 | Epoch Duration: 187.78289127349854
2020-01-12 15:41:56.834130 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0069826
Z variance train             0.013402452
KL Divergence                19.211487
KL Loss                      1.9211487
QF Loss                      500.6092
VF Loss                      89.11803
Policy Loss                  -1017.56366
Q Predictions Mean           1011.291
Q Predictions Std            336.4235
Q Predictions Max            1432.5707
Q Predictions Min            356.43652
V Predictions Mean           1013.5882
V Predictions Std            336.7273
V Predictions Max            1424.8013
V Predictions Min            359.35983
Log Pis Mean                 -0.62911654
Log Pis Std                  2.9200666
Log Pis Max                  8.035797
Log Pis Min                  -9.927098
Policy mu Mean               0.022358268
Policy mu Std                0.5889767
Policy mu Max                2.245686
Policy mu Min                -2.4700048
Policy log std Mean          -0.91111237
Policy log std Std           0.25503054
Policy log std Max           -0.35904038
Policy log std Min           -2.0659647
Z mean eval                  1.1463884
Z variance eval              0.031827677
total_rewards                [2175.33974491 1539.6741152    14.930569   3656.01288976 3567.26565262
  446.61085812 2156.57848727 3485.05027971 1725.35856287 3578.97940441]
total_rewards_mean           2234.580056386572
total_rewards_std            1266.6127956581588
total_rewards_max            3656.0128897564764
total_rewards_min            14.930569001970886
Number of train steps total  1080000
Number of env steps total    1411954
Number of rollouts total     0
Train Time (s)               153.62083309190348
(Previous) Eval Time (s)     25.55139531614259
Sample Time (s)              11.29211312578991
Epoch Time (s)               190.46434153383598
Total Train Time (s)         49754.41102151759
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:45:07.390660 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #269 | Epoch Duration: 190.55634236335754
2020-01-12 15:45:07.390970 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1468484
Z variance train             0.031781018
KL Divergence                18.86513
KL Loss                      1.886513
QF Loss                      1080.7856
VF Loss                      68.67398
Policy Loss                  -1041.2329
Q Predictions Mean           1036.4141
Q Predictions Std            331.0933
Q Predictions Max            1445.2977
Q Predictions Min            330.76468
V Predictions Mean           1042.9723
V Predictions Std            332.07892
V Predictions Max            1450.071
V Predictions Min            343.56332
Log Pis Mean                 -0.42749777
Log Pis Std                  2.7483768
Log Pis Max                  6.7944307
Log Pis Min                  -8.381867
Policy mu Mean               0.03583514
Policy mu Std                0.61694324
Policy mu Max                2.388544
Policy mu Min                -2.3280234
Policy log std Mean          -0.90123206
Policy log std Std           0.22689275
Policy log std Max           -0.38737386
Policy log std Min           -1.7968022
Z mean eval                  1.0116796
Z variance eval              0.01639537
total_rewards                [3373.99882023 2718.56816132 3617.64262555  340.8468533    86.43715692
 1391.27959583  741.01805453 1084.13311362 3564.25255013 3065.06443843]
total_rewards_mean           1998.3241369843902
total_rewards_std            1334.5823683669805
total_rewards_max            3617.642625547367
total_rewards_min            86.43715691705862
Number of train steps total  1084000
Number of env steps total    1421575
Number of rollouts total     0
Train Time (s)               153.04009199002758
(Previous) Eval Time (s)     30.46591162867844
Sample Time (s)              11.022070804145187
Epoch Time (s)               194.5280744228512
Total Train Time (s)         49949.04425954679
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:48:22.027923 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #270 | Epoch Duration: 194.6366732120514
2020-01-12 15:48:22.028306 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0106255
Z variance train             0.016435318
KL Divergence                19.236303
KL Loss                      1.9236304
QF Loss                      554.47156
VF Loss                      115.98984
Policy Loss                  -999.5424
Q Predictions Mean           992.352
Q Predictions Std            368.33365
Q Predictions Max            1442.7705
Q Predictions Min            -23.93295
V Predictions Mean           998.9064
V Predictions Std            365.73337
V Predictions Max            1451.8612
V Predictions Min            252.18881
Log Pis Mean                 -0.6810354
Log Pis Std                  3.1170948
Log Pis Max                  16.632206
Log Pis Min                  -7.335866
Policy mu Mean               0.014954584
Policy mu Std                0.57053536
Policy mu Max                2.7540689
Policy mu Min                -2.3076189
Policy log std Mean          -0.93110275
Policy log std Std           0.26235253
Policy log std Max           -0.3357892
Policy log std Min           -2.6308932
Z mean eval                  1.0584238
Z variance eval              0.018426357
total_rewards                [ 491.71914267 2686.64644094 1943.95180386  770.57236358  325.51923424
 1381.24353325 2282.27237193 3350.62152129  182.07151317 3107.1489999 ]
total_rewards_mean           1652.1766924841309
total_rewards_std            1125.7203088421961
total_rewards_max            3350.621521288651
total_rewards_min            182.0715131689734
Number of train steps total  1088000
Number of env steps total    1432345
Number of rollouts total     0
Train Time (s)               152.19010671880096
(Previous) Eval Time (s)     18.97770568029955
Sample Time (s)              12.749894842971116
Epoch Time (s)               183.91770724207163
Total Train Time (s)         50133.05811947398
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:51:26.045924 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #271 | Epoch Duration: 184.01731038093567
2020-01-12 15:51:26.046213 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0613832
Z variance train             0.018338231
KL Divergence                19.360796
KL Loss                      1.9360796
QF Loss                      1425.6415
VF Loss                      450.1999
Policy Loss                  -1027.0671
Q Predictions Mean           1027.575
Q Predictions Std            356.3596
Q Predictions Max            1472.1235
Q Predictions Min            337.57852
V Predictions Mean           1043.0447
V Predictions Std            356.56058
V Predictions Max            1453.2087
V Predictions Min            365.3715
Log Pis Mean                 -0.64267415
Log Pis Std                  2.9275532
Log Pis Max                  7.637039
Log Pis Min                  -7.435134
Policy mu Mean               0.020044506
Policy mu Std                0.5791636
Policy mu Max                2.5417614
Policy mu Min                -2.5904818
Policy log std Mean          -0.92403746
Policy log std Std           0.25057784
Policy log std Max           -0.3931957
Policy log std Min           -2.2441761
Z mean eval                  1.0451531
Z variance eval              0.013060264
total_rewards                [ 333.69070278  984.61243286 2810.50703501  367.46794972 2519.71561417
 1212.75112263 3429.75160938  806.02098666 2130.73873157 2576.43211577]
total_rewards_mean           1717.1688300551075
total_rewards_std            1050.6547335328444
total_rewards_max            3429.7516093767917
total_rewards_min            333.6907027752551
Number of train steps total  1092000
Number of env steps total    1443509
Number of rollouts total     0
Train Time (s)               145.33939300104976
(Previous) Eval Time (s)     20.111035676207393
Sample Time (s)              12.603166684973985
Epoch Time (s)               178.05359536223114
Total Train Time (s)         50311.202059911564
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:54:24.192453 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #272 | Epoch Duration: 178.14606475830078
2020-01-12 15:54:24.192651 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0446103
Z variance train             0.013087863
KL Divergence                19.859169
KL Loss                      1.985917
QF Loss                      1118.6611
VF Loss                      108.19149
Policy Loss                  -992.4165
Q Predictions Mean           990.8495
Q Predictions Std            354.44843
Q Predictions Max            1446.0804
Q Predictions Min            360.80542
V Predictions Mean           995.314
V Predictions Std            356.18457
V Predictions Max            1447.9287
V Predictions Min            342.79153
Log Pis Mean                 -0.883621
Log Pis Std                  3.0618706
Log Pis Max                  14.566004
Log Pis Min                  -8.672869
Policy mu Mean               0.021366064
Policy mu Std                0.5755198
Policy mu Max                2.3721232
Policy mu Min                -2.905166
Policy log std Mean          -0.8918346
Policy log std Std           0.25246397
Policy log std Max           -0.1990344
Policy log std Min           -2.4314697
Z mean eval                  1.1077497
Z variance eval              0.012880882
total_rewards                [3332.46857936 2074.55684956 3186.60844436  932.88322839 1266.16910016
  219.90125407 2277.4692607  3240.17999747 3118.60030233 2293.25160029]
total_rewards_mean           2194.2088616689366
total_rewards_std            1030.058071799473
total_rewards_max            3332.468579364706
total_rewards_min            219.90125407070124
Number of train steps total  1096000
Number of env steps total    1453486
Number of rollouts total     0
Train Time (s)               144.59314617794007
(Previous) Eval Time (s)     29.797801771201193
Sample Time (s)              11.201032461132854
Epoch Time (s)               185.59198041027412
Total Train Time (s)         50496.89021658525
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:57:29.888701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #273 | Epoch Duration: 185.69587445259094
2020-01-12 15:57:29.888915 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1011894
Z variance train             0.0128349485
KL Divergence                19.978088
KL Loss                      1.9978088
QF Loss                      3568.3667
VF Loss                      121.94455
Policy Loss                  -984.2663
Q Predictions Mean           979.51794
Q Predictions Std            363.9148
Q Predictions Max            1443.4413
Q Predictions Min            355.02866
V Predictions Mean           980.95276
V Predictions Std            361.8517
V Predictions Max            1433.8013
V Predictions Min            361.9398
Log Pis Mean                 -0.8025934
Log Pis Std                  3.0005026
Log Pis Max                  11.636439
Log Pis Min                  -7.2640824
Policy mu Mean               0.029594235
Policy mu Std                0.56471676
Policy mu Max                2.5918162
Policy mu Min                -2.2975569
Policy log std Mean          -0.8942994
Policy log std Std           0.26445568
Policy log std Max           -0.26671487
Policy log std Min           -2.4781923
Z mean eval                  1.0012791
Z variance eval              0.0147269815
total_rewards                [2171.95163063  401.48688496   78.12936912  782.75061645  667.05037588
 1637.81185644 1548.51294152 1358.21675646  738.80141723 1305.70822655]
total_rewards_mean           1069.042007525021
total_rewards_std            607.4200085257569
total_rewards_max            2171.951630631829
total_rewards_min            78.12936912141123
Number of train steps total  1100000
Number of env steps total    1461969
Number of rollouts total     0
Train Time (s)               147.8650624230504
(Previous) Eval Time (s)     13.655104632955045
Sample Time (s)              11.018544679041952
Epoch Time (s)               172.5387117350474
Total Train Time (s)         50669.5238888422
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:00:22.525773 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #274 | Epoch Duration: 172.6367084980011
2020-01-12 16:00:22.525977 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #274 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9985962
Z variance train             0.014759843
KL Divergence                19.940203
KL Loss                      1.9940203
QF Loss                      565.3544
VF Loss                      233.31732
Policy Loss                  -1025.2605
Q Predictions Mean           1022.16113
Q Predictions Std            351.10333
Q Predictions Max            1451.6609
Q Predictions Min            371.36996
V Predictions Mean           1026.9471
V Predictions Std            350.01245
V Predictions Max            1457.3298
V Predictions Min            367.55353
Log Pis Mean                 -0.6703682
Log Pis Std                  3.0690045
Log Pis Max                  17.938854
Log Pis Min                  -8.203094
Policy mu Mean               0.027387131
Policy mu Std                0.57180315
Policy mu Max                3.2506423
Policy mu Min                -2.4061816
Policy log std Mean          -0.92464316
Policy log std Std           0.24761903
Policy log std Max           -0.33642995
Policy log std Min           -2.367736
Z mean eval                  1.1514769
Z variance eval              0.014691274
total_rewards                [1.09035163e+03 3.55216282e+03 3.14107509e+03 1.59534197e+03
 1.67718736e+03 3.22449561e+03 5.75544280e+02 2.06789675e+00
 1.26159945e+03 7.34407648e+02]
total_rewards_mean           1685.423374041648
total_rewards_std            1161.2169977182575
total_rewards_max            3552.162815021042
total_rewards_min            2.0678967545106484
Number of train steps total  1104000
Number of env steps total    1469715
Number of rollouts total     0
Train Time (s)               154.68322593998164
(Previous) Eval Time (s)     19.04784030513838
Sample Time (s)              12.033588559366763
Epoch Time (s)               185.76465480448678
Total Train Time (s)         50855.39024710888
Epoch                        275
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:03:28.395770 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #275 | Epoch Duration: 185.86961770057678
2020-01-12 16:03:28.396081 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #275 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1555916
Z variance train             0.014775207
KL Divergence                20.716417
KL Loss                      2.0716417
QF Loss                      757.6687
VF Loss                      50.920593
Policy Loss                  -1025.7573
Q Predictions Mean           1017.894
Q Predictions Std            362.7739
Q Predictions Max            1488.1825
Q Predictions Min            313.85568
V Predictions Mean           1023.0807
V Predictions Std            360.50537
V Predictions Max            1482.0504
V Predictions Min            316.6996
Log Pis Mean                 -0.67212033
Log Pis Std                  2.6641357
Log Pis Max                  8.078575
Log Pis Min                  -7.1982327
Policy mu Mean               0.029060323
Policy mu Std                0.6016163
Policy mu Max                1.97909
Policy mu Min                -2.3581736
Policy log std Mean          -0.8688997
Policy log std Std           0.23152047
Policy log std Max           -0.26790178
Policy log std Min           -1.7254356
Z mean eval                  1.2063159
Z variance eval              0.039177634
total_rewards                [3195.31331631  242.20341441 1332.47796345 1059.56527625 1167.7081765
 2251.85211129 3374.51660475 3358.66423978 3282.72632805  471.35096118]
total_rewards_mean           1973.6378391953112
total_rewards_std            1196.4628936710908
total_rewards_max            3374.516604748384
total_rewards_min            242.20341440772873
Number of train steps total  1108000
Number of env steps total    1477833
Number of rollouts total     0
Train Time (s)               153.2827833951451
(Previous) Eval Time (s)     22.08194280602038
Sample Time (s)              11.229811494704336
Epoch Time (s)               186.5945376958698
Total Train Time (s)         51042.078839947004
Epoch                        276
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:06:35.087049 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #276 | Epoch Duration: 186.69074988365173
2020-01-12 16:06:35.087254 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.208052
Z variance train             0.03886432
KL Divergence                19.340527
KL Loss                      1.9340527
QF Loss                      2748.0845
VF Loss                      769.9839
Policy Loss                  -1040.7316
Q Predictions Mean           1038.2495
Q Predictions Std            349.35928
Q Predictions Max            1469.1929
Q Predictions Min            359.3812
V Predictions Mean           1040.9646
V Predictions Std            349.9657
V Predictions Max            1462.4777
V Predictions Min            360.9885
Log Pis Mean                 -0.6326813
Log Pis Std                  3.0608258
Log Pis Max                  10.620162
Log Pis Min                  -7.670501
Policy mu Mean               0.025964197
Policy mu Std                0.60229474
Policy mu Max                2.6913142
Policy mu Min                -2.2682934
Policy log std Mean          -0.9016442
Policy log std Std           0.25680152
Policy log std Max           -0.18376493
Policy log std Min           -2.5469842
Z mean eval                  1.0517671
Z variance eval              0.029080445
total_rewards                [ 321.08130384  805.34380836 3032.41369986 3245.03103037 3515.46715957
  533.0759834  3451.45287504 3297.36904887 3368.64871894 2540.50751855]
total_rewards_mean           2411.0391146790835
total_rewards_std            1248.0447329305418
total_rewards_max            3515.4671595721534
total_rewards_min            321.08130383726876
Number of train steps total  1112000
Number of env steps total    1488458
Number of rollouts total     0
Train Time (s)               153.28785199578851
(Previous) Eval Time (s)     27.542608429212123
Sample Time (s)              12.249857081100345
Epoch Time (s)               193.08031750610098
Total Train Time (s)         51235.24409264419
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:09:48.256878 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #277 | Epoch Duration: 193.1694371700287
2020-01-12 16:09:48.257295 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0575631
Z variance train             0.028758978
KL Divergence                19.051758
KL Loss                      1.9051758
QF Loss                      510.39368
VF Loss                      155.51042
Policy Loss                  -1001.6245
Q Predictions Mean           995.66943
Q Predictions Std            350.21997
Q Predictions Max            1409.758
Q Predictions Min            353.4728
V Predictions Mean           999.03357
V Predictions Std            350.98474
V Predictions Max            1411.7765
V Predictions Min            345.4565
Log Pis Mean                 -0.7898246
Log Pis Std                  3.0491688
Log Pis Max                  9.779414
Log Pis Min                  -7.481603
Policy mu Mean               0.054716397
Policy mu Std                0.5899908
Policy mu Max                2.1289804
Policy mu Min                -2.5642893
Policy log std Mean          -0.8947085
Policy log std Std           0.262842
Policy log std Max           -0.23249584
Policy log std Min           -1.8802836
Z mean eval                  1.0482135
Z variance eval              0.053685825
total_rewards                [2955.47651685  668.53338682  346.42819407 3426.43774235 3472.41777841
 2278.39041248 3249.85939333  580.03244295 2313.56211009 3514.353156  ]
total_rewards_mean           2280.549113336391
total_rewards_std            1219.968991268566
total_rewards_max            3514.353155998281
total_rewards_min            346.42819407371206
Number of train steps total  1116000
Number of env steps total    1496842
Number of rollouts total     0
Train Time (s)               152.92794058285654
(Previous) Eval Time (s)     26.11409752489999
Sample Time (s)              12.46279912116006
Epoch Time (s)               191.50483722891659
Total Train Time (s)         51426.873007722665
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:12:59.889469 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #278 | Epoch Duration: 191.63187551498413
2020-01-12 16:12:59.889882 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0487688
Z variance train             0.053791177
KL Divergence                17.450893
KL Loss                      1.7450894
QF Loss                      1111.6638
VF Loss                      465.78568
Policy Loss                  -1011.0688
Q Predictions Mean           1004.51685
Q Predictions Std            342.04507
Q Predictions Max            1451.8584
Q Predictions Min            339.25372
V Predictions Mean           1014.4019
V Predictions Std            344.7716
V Predictions Max            1461.839
V Predictions Min            335.40094
Log Pis Mean                 -0.605629
Log Pis Std                  3.2276154
Log Pis Max                  21.448341
Log Pis Min                  -6.990406
Policy mu Mean               -3.5681296e-06
Policy mu Std                0.59473604
Policy mu Max                3.0003648
Policy mu Min                -2.882147
Policy log std Mean          -0.90931445
Policy log std Std           0.27602145
Policy log std Max           -0.21044338
Policy log std Min           -2.4675593
Z mean eval                  1.2472485
Z variance eval              0.00706964
total_rewards                [1295.83890493 1363.28503634 1708.10254014  463.02053945  903.64609935
  110.02434047 2795.4652856  1516.05364893 2258.49218322  981.04635468]
total_rewards_mean           1339.4974933115636
total_rewards_std            757.1114098377783
total_rewards_max            2795.465285604568
total_rewards_min            110.02434047490736
Number of train steps total  1120000
Number of env steps total    1506323
Number of rollouts total     0
Train Time (s)               143.51549919741228
(Previous) Eval Time (s)     16.8821171480231
Sample Time (s)              11.232196114957333
Epoch Time (s)               171.6298124603927
Total Train Time (s)         51598.59536730265
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:15:51.613907 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #279 | Epoch Duration: 171.723778963089
2020-01-12 16:15:51.614102 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2392948
Z variance train             0.0070998883
KL Divergence                22.466324
KL Loss                      2.2466323
QF Loss                      641.96765
VF Loss                      430.49475
Policy Loss                  -1008.8087
Q Predictions Mean           1002.7646
Q Predictions Std            366.6497
Q Predictions Max            1477.5088
Q Predictions Min            41.950924
V Predictions Mean           1003.77045
V Predictions Std            362.3287
V Predictions Max            1458.4777
V Predictions Min            353.73526
Log Pis Mean                 -0.43618506
Log Pis Std                  3.306006
Log Pis Max                  17.143986
Log Pis Min                  -8.8417015
Policy mu Mean               0.03143868
Policy mu Std                0.6012944
Policy mu Max                2.4234798
Policy mu Min                -2.2687194
Policy log std Mean          -0.92151177
Policy log std Std           0.2818043
Policy log std Max           -0.25353968
Policy log std Min           -2.2860434
Z mean eval                  1.1968086
Z variance eval              0.015570328
total_rewards                [ 199.35450151 1866.02665186 1228.79407416  276.77323539  516.95919218
  383.90261797 3329.45638925 1949.40052074  564.36788603 1249.43340273]
total_rewards_mean           1156.4468471823425
total_rewards_std            944.1561355500937
total_rewards_max            3329.456389252898
total_rewards_min            199.35450150667694
Number of train steps total  1124000
Number of env steps total    1514412
Number of rollouts total     0
Train Time (s)               144.62338744290173
(Previous) Eval Time (s)     12.123481415212154
Sample Time (s)              11.853202279657125
Epoch Time (s)               168.600071137771
Total Train Time (s)         51767.2831341452
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:18:40.304698 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #280 | Epoch Duration: 168.6904537677765
2020-01-12 16:18:40.304876 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1956165
Z variance train             0.015589306
KL Divergence                19.799295
KL Loss                      1.9799296
QF Loss                      5006.507
VF Loss                      168.27454
Policy Loss                  -986.3475
Q Predictions Mean           978.62573
Q Predictions Std            354.90616
Q Predictions Max            1438.9269
Q Predictions Min            193.06357
V Predictions Mean           985.60046
V Predictions Std            354.9512
V Predictions Max            1436.9937
V Predictions Min            306.51703
Log Pis Mean                 -0.2366607
Log Pis Std                  3.4028141
Log Pis Max                  17.091291
Log Pis Min                  -7.9312572
Policy mu Mean               0.07071763
Policy mu Std                0.6249454
Policy mu Max                3.1323385
Policy mu Min                -3.1314564
Policy log std Mean          -0.9154391
Policy log std Std           0.26244587
Policy log std Max           0.077907324
Policy log std Min           -2.065556
Z mean eval                  0.9863914
Z variance eval              0.013257007
total_rewards                [2725.49963604 2193.34802544 1029.36829474  949.10087733 3390.10436463
 2178.10133129 3506.28380706 3398.21154912   75.61814397 1186.62476995]
total_rewards_mean           2063.2260799562714
total_rewards_std            1145.5607424851323
total_rewards_max            3506.2838070554812
total_rewards_min            75.61814396509644
Number of train steps total  1128000
Number of env steps total    1521637
Number of rollouts total     0
Train Time (s)               148.5237696361728
(Previous) Eval Time (s)     23.788712741341442
Sample Time (s)              11.04682796029374
Epoch Time (s)               183.35931033780798
Total Train Time (s)         51950.72860483406
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:21:43.753548 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #281 | Epoch Duration: 183.44853687286377
2020-01-12 16:21:43.753726 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #281 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9878584
Z variance train             0.013132067
KL Divergence                19.411938
KL Loss                      1.9411938
QF Loss                      478.8957
VF Loss                      110.63722
Policy Loss                  -1035.0181
Q Predictions Mean           1029.6276
Q Predictions Std            339.33942
Q Predictions Max            1442.8107
Q Predictions Min            328.31912
V Predictions Mean           1032.6434
V Predictions Std            337.51758
V Predictions Max            1441.6259
V Predictions Min            361.53912
Log Pis Mean                 -0.37798327
Log Pis Std                  3.2662327
Log Pis Max                  17.938522
Log Pis Min                  -7.892683
Policy mu Mean               0.04984292
Policy mu Std                0.6021003
Policy mu Max                2.468258
Policy mu Min                -2.3542068
Policy log std Mean          -0.91779155
Policy log std Std           0.258242
Policy log std Max           -0.21156979
Policy log std Min           -2.3138256
Z mean eval                  1.0703534
Z variance eval              0.019349694
total_rewards                [3300.44178295 3531.21520722 1481.75223855 3348.28145004 2236.8023972
 2507.75614396 1054.20706417 3345.22024048 3374.04105834 1089.4594877 ]
total_rewards_mean           2526.9177070618425
total_rewards_std            952.9373566374587
total_rewards_max            3531.2152072227673
total_rewards_min            1054.207064171934
Number of train steps total  1132000
Number of env steps total    1532894
Number of rollouts total     0
Train Time (s)               154.512791542802
(Previous) Eval Time (s)     27.477044499013573
Sample Time (s)              11.760528015438467
Epoch Time (s)               193.75036405725405
Total Train Time (s)         52144.56450788025
Epoch                        282
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:24:57.592665 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #282 | Epoch Duration: 193.8387966156006
2020-01-12 16:24:57.592864 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0682323
Z variance train             0.019391362
KL Divergence                19.793037
KL Loss                      1.9793037
QF Loss                      385.57397
VF Loss                      51.433994
Policy Loss                  -1014.99725
Q Predictions Mean           1007.78674
Q Predictions Std            367.50595
Q Predictions Max            1560.2037
Q Predictions Min            6.7146635
V Predictions Mean           1015.6374
V Predictions Std            364.3914
V Predictions Max            1561.0659
V Predictions Min            380.00232
Log Pis Mean                 -0.69887555
Log Pis Std                  3.0080857
Log Pis Max                  9.731867
Log Pis Min                  -7.0573387
Policy mu Mean               3.196078e-05
Policy mu Std                0.5956769
Policy mu Max                2.1830103
Policy mu Min                -2.404478
Policy log std Mean          -0.86769617
Policy log std Std           0.25445563
Policy log std Max           -0.24699235
Policy log std Min           -2.220717
Z mean eval                  1.2414083
Z variance eval              0.015505212
total_rewards                [ 127.82002115 1638.42991963 2587.29070107  249.80917309  519.83735202
  751.25205857 3490.30073212 2345.08703081    6.14991287  506.20856331]
total_rewards_mean           1222.2185464642903
total_rewards_std            1152.892642127832
total_rewards_max            3490.300732122636
total_rewards_min            6.149912870755275
Number of train steps total  1136000
Number of env steps total    1542282
Number of rollouts total     0
Train Time (s)               153.7837832630612
(Previous) Eval Time (s)     13.300561941228807
Sample Time (s)              12.41809633281082
Epoch Time (s)               179.50244153710082
Total Train Time (s)         52324.16250946466
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:27:57.194204 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #283 | Epoch Duration: 179.60119771957397
2020-01-12 16:27:57.194400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.242583
Z variance train             0.01553455
KL Divergence                20.121439
KL Loss                      2.0121439
QF Loss                      339.7262
VF Loss                      80.2236
Policy Loss                  -1033.6168
Q Predictions Mean           1028.1588
Q Predictions Std            342.11
Q Predictions Max            1464.25
Q Predictions Min            356.98523
V Predictions Mean           1032.7527
V Predictions Std            342.30447
V Predictions Max            1463.8743
V Predictions Min            357.44595
Log Pis Mean                 -0.34726864
Log Pis Std                  3.1845765
Log Pis Max                  8.661622
Log Pis Min                  -9.10254
Policy mu Mean               -0.0053372774
Policy mu Std                0.629223
Policy mu Max                2.7451267
Policy mu Min                -2.2983725
Policy log std Mean          -0.89693594
Policy log std Std           0.2571477
Policy log std Max           -0.29638863
Policy log std Min           -2.0482998
Z mean eval                  1.2017756
Z variance eval              0.01014478
total_rewards                [ 305.07576428 3401.65775991  183.88656639  527.85205179 2503.29445221
  757.44023403  294.5124719   777.06645752  803.35832506 3498.22766288]
total_rewards_mean           1305.2371745964294
total_rewards_std            1239.1165422904087
total_rewards_max            3498.227662877134
total_rewards_min            183.88656638715685
Number of train steps total  1140000
Number of env steps total    1552426
Number of rollouts total     0
Train Time (s)               154.733177495189
(Previous) Eval Time (s)     17.549797659739852
Sample Time (s)              11.579345420468599
Epoch Time (s)               183.86232057539746
Total Train Time (s)         52508.11480732169
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:31:01.149693 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #284 | Epoch Duration: 183.95515275001526
2020-01-12 16:31:01.149880 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2141057
Z variance train             0.010089986
KL Divergence                20.541245
KL Loss                      2.0541246
QF Loss                      543.9736
VF Loss                      81.20375
Policy Loss                  -1008.5488
Q Predictions Mean           1002.13525
Q Predictions Std            364.7858
Q Predictions Max            1457.1427
Q Predictions Min            378.63214
V Predictions Mean           1005.03326
V Predictions Std            364.65338
V Predictions Max            1458.5845
V Predictions Min            372.5642
Log Pis Mean                 -1.0846913
Log Pis Std                  2.909019
Log Pis Max                  8.283813
Log Pis Min                  -9.418367
Policy mu Mean               -0.021987181
Policy mu Std                0.5422641
Policy mu Max                2.9168391
Policy mu Min                -2.3948922
Policy log std Mean          -0.87848586
Policy log std Std           0.23856765
Policy log std Max           -0.2698179
Policy log std Min           -1.7879313
Z mean eval                  0.9879514
Z variance eval              0.011634862
total_rewards                [3420.88886343 3431.94154415 1642.57953704 3285.28142601 2153.75316432
 1667.76347853 1701.81341769 2460.69457429 1145.73558927 3516.54706427]
total_rewards_mean           2442.6998659001742
total_rewards_std            857.5608619071417
total_rewards_max            3516.5470642681703
total_rewards_min            1145.735589270728
Number of train steps total  1144000
Number of env steps total    1563279
Number of rollouts total     0
Train Time (s)               153.13309106836095
(Previous) Eval Time (s)     30.192771608941257
Sample Time (s)              11.358320924453437
Epoch Time (s)               194.68418360175565
Total Train Time (s)         52702.88553857058
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:34:15.923422 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #285 | Epoch Duration: 194.77340412139893
2020-01-12 16:34:15.923610 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9879626
Z variance train             0.011679786
KL Divergence                20.411978
KL Loss                      2.0411978
QF Loss                      402.15405
VF Loss                      155.79514
Policy Loss                  -1065.1167
Q Predictions Mean           1059.22
Q Predictions Std            339.25388
Q Predictions Max            1480.245
Q Predictions Min            344.62408
V Predictions Mean           1064.6002
V Predictions Std            338.54514
V Predictions Max            1481.3494
V Predictions Min            375.05133
Log Pis Mean                 -0.71690315
Log Pis Std                  2.777496
Log Pis Max                  7.871819
Log Pis Min                  -8.132344
Policy mu Mean               -0.010959061
Policy mu Std                0.5792774
Policy mu Max                1.9764206
Policy mu Min                -2.584974
Policy log std Mean          -0.9087044
Policy log std Std           0.25102392
Policy log std Max           -0.26975197
Policy log std Min           -1.7751138
Z mean eval                  1.0913305
Z variance eval              0.008685613
total_rewards                [1768.13576733 3419.01627595 2388.83758195 3491.69911034   79.37794608
  585.31125297 1284.22560537  422.83250955  444.97593335  395.10243611]
total_rewards_mean           1427.9514418996107
total_rewards_std            1218.813079469434
total_rewards_max            3491.6991103416403
total_rewards_min            79.37794608337502
Number of train steps total  1148000
Number of env steps total    1573565
Number of rollouts total     0
Train Time (s)               144.11210432834923
(Previous) Eval Time (s)     17.95622381195426
Sample Time (s)              10.301475157029927
Epoch Time (s)               172.36980329733342
Total Train Time (s)         52875.46540881181
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:37:08.506830 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #286 | Epoch Duration: 172.58307647705078
2020-01-12 16:37:08.507030 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0909789
Z variance train             0.008695437
KL Divergence                20.532303
KL Loss                      2.0532303
QF Loss                      688.98364
VF Loss                      73.21281
Policy Loss                  -1068.6786
Q Predictions Mean           1064.7456
Q Predictions Std            346.0473
Q Predictions Max            1482.5245
Q Predictions Min            382.3567
V Predictions Mean           1070.2297
V Predictions Std            345.2509
V Predictions Max            1480.0763
V Predictions Min            382.37668
Log Pis Mean                 -0.8374493
Log Pis Std                  2.8663342
Log Pis Max                  8.106817
Log Pis Min                  -9.594872
Policy mu Mean               -0.015760427
Policy mu Std                0.58657503
Policy mu Max                2.0682364
Policy mu Min                -2.3600428
Policy log std Mean          -0.8937369
Policy log std Std           0.2496182
Policy log std Max           -0.27548337
Policy log std Min           -1.8034575
Z mean eval                  1.181637
Z variance eval              0.3218279
total_rewards                [1539.83473694  212.1117229  1375.93426131 3653.3070091  1700.97333317
 3296.45382623  612.58861298 3646.35978327 3318.71469033 3740.41622737]
total_rewards_mean           2309.6694203602697
total_rewards_std            1294.059682433887
total_rewards_max            3740.4162273668244
total_rewards_min            212.11172290273802
Number of train steps total  1152000
Number of env steps total    1582056
Number of rollouts total     0
Train Time (s)               144.16482623200864
(Previous) Eval Time (s)     28.381731364876032
Sample Time (s)              12.135706119704992
Epoch Time (s)               184.68226371658966
Total Train Time (s)         53060.238546963315
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:40:13.283320 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #287 | Epoch Duration: 184.7761414051056
2020-01-12 16:40:13.283514 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1861635
Z variance train             0.32170746
KL Divergence                21.014713
KL Loss                      2.1014714
QF Loss                      1026.3827
VF Loss                      172.61841
Policy Loss                  -1076.068
Q Predictions Mean           1071.4299
Q Predictions Std            341.64392
Q Predictions Max            1513.8934
Q Predictions Min            70.13629
V Predictions Mean           1073.0968
V Predictions Std            336.71503
V Predictions Max            1517.0886
V Predictions Min            354.8726
Log Pis Mean                 -0.34192234
Log Pis Std                  3.3254557
Log Pis Max                  24.407225
Log Pis Min                  -8.098004
Policy mu Mean               -0.012810836
Policy mu Std                0.61307985
Policy mu Max                3.6342633
Policy mu Min                -3.0375118
Policy log std Mean          -0.9302951
Policy log std Std           0.27317122
Policy log std Max           -0.31200075
Policy log std Min           -2.4629571
Z mean eval                  1.0246129
Z variance eval              0.012939328
total_rewards                [1546.27827891 3506.80929604  464.90636033 3519.93178482 1257.73829791
  416.52596805 3490.16641229 3401.4542421   633.85504176 2362.15961425]
total_rewards_mean           2059.9825296451254
total_rewards_std            1278.5768547733583
total_rewards_max            3519.931784823278
total_rewards_min            416.5259680476851
Number of train steps total  1156000
Number of env steps total    1593313
Number of rollouts total     0
Train Time (s)               150.93568548373878
(Previous) Eval Time (s)     30.245241893921047
Sample Time (s)              11.233423022553325
Epoch Time (s)               192.41435040021315
Total Train Time (s)         53252.769883545116
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:43:25.818316 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #288 | Epoch Duration: 192.53464603424072
2020-01-12 16:43:25.818536 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0248567
Z variance train             0.012925136
KL Divergence                21.35316
KL Loss                      2.1353161
QF Loss                      449.05255
VF Loss                      124.34816
Policy Loss                  -1068.3933
Q Predictions Mean           1062.9099
Q Predictions Std            341.24524
Q Predictions Max            1482.3209
Q Predictions Min            3.1141634
V Predictions Mean           1069.719
V Predictions Std            336.5742
V Predictions Max            1474.8696
V Predictions Min            314.41382
Log Pis Mean                 -0.23002928
Log Pis Std                  3.5332415
Log Pis Max                  21.952246
Log Pis Min                  -7.4838343
Policy mu Mean               0.037101123
Policy mu Std                0.61559594
Policy mu Max                3.3839989
Policy mu Min                -2.4768515
Policy log std Mean          -0.9221495
Policy log std Std           0.2720184
Policy log std Max           -0.30176425
Policy log std Min           -2.0420065
Z mean eval                  1.0557001
Z variance eval              0.036796957
total_rewards                [1155.73083869  384.12116107 2641.01112135   92.42251707  400.26711143
  638.97458541  821.82579304  192.93952275 3554.19329701  549.92478051]
total_rewards_mean           1043.1410728328442
total_rewards_std            1086.3307210924102
total_rewards_max            3554.1932970100447
total_rewards_min            92.42251707136074
Number of train steps total  1160000
Number of env steps total    1602736
Number of rollouts total     0
Train Time (s)               153.63832810288295
(Previous) Eval Time (s)     12.353299980051816
Sample Time (s)              10.812232812400907
Epoch Time (s)               176.80386089533567
Total Train Time (s)         53429.66149332002
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:46:22.713207 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #289 | Epoch Duration: 176.89451575279236
2020-01-12 16:46:22.713429 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0595629
Z variance train             0.036503293
KL Divergence                17.716282
KL Loss                      1.7716283
QF Loss                      10574.465
VF Loss                      94.81291
Policy Loss                  -1048.7567
Q Predictions Mean           1049.204
Q Predictions Std            354.61038
Q Predictions Max            1493.164
Q Predictions Min            389.8669
V Predictions Mean           1054.6858
V Predictions Std            355.8015
V Predictions Max            1509.1356
V Predictions Min            394.27737
Log Pis Mean                 -0.804615
Log Pis Std                  2.8388414
Log Pis Max                  12.847662
Log Pis Min                  -7.7065554
Policy mu Mean               0.02597788
Policy mu Std                0.5817005
Policy mu Max                2.4925823
Policy mu Min                -2.4998207
Policy log std Mean          -0.8851532
Policy log std Std           0.2537233
Policy log std Max           -0.26401687
Policy log std Min           -2.028601
Z mean eval                  1.0293825
Z variance eval              0.023744116
total_rewards                [ 290.14160801 3415.61610463 1508.70474806 3352.95178105 3282.17816162
 2098.21999554 3383.11070673 3344.39542804 3495.90120926  176.4723648 ]
total_rewards_mean           2434.769210774058
total_rewards_std            1266.7354625285705
total_rewards_max            3495.9012092605794
total_rewards_min            176.4723648007816
Number of train steps total  1164000
Number of env steps total    1612472
Number of rollouts total     0
Train Time (s)               153.06344231031835
(Previous) Eval Time (s)     27.611191108822823
Sample Time (s)              11.791093500796705
Epoch Time (s)               192.46572691993788
Total Train Time (s)         53622.23486772273
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:49:35.290192 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #290 | Epoch Duration: 192.57660150527954
2020-01-12 16:49:35.290402 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0314993
Z variance train             0.023863068
KL Divergence                20.372028
KL Loss                      2.0372028
QF Loss                      391.42108
VF Loss                      73.63926
Policy Loss                  -1044.7633
Q Predictions Mean           1037.7148
Q Predictions Std            349.4199
Q Predictions Max            1468.0498
Q Predictions Min            374.58426
V Predictions Mean           1045.9528
V Predictions Std            348.09985
V Predictions Max            1471.6553
V Predictions Min            385.49548
Log Pis Mean                 -0.65122837
Log Pis Std                  2.8846357
Log Pis Max                  9.429583
Log Pis Min                  -8.320538
Policy mu Mean               -0.0027913535
Policy mu Std                0.58322465
Policy mu Max                2.5578847
Policy mu Min                -2.2595134
Policy log std Mean          -0.9049972
Policy log std Std           0.2528664
Policy log std Max           -0.28798717
Policy log std Min           -1.9909258
Z mean eval                  1.0026635
Z variance eval              0.010373758
total_rewards                [ 772.40686341 2070.94024002  684.93545934 3111.0637833  1950.81806315
  497.92925802 2820.46202914 1312.65128212  349.21046051 1679.90937828]
total_rewards_mean           1525.0326817294358
total_rewards_std            919.3335116769467
total_rewards_max            3111.0637833035034
total_rewards_min            349.21046051163114
Number of train steps total  1168000
Number of env steps total    1622045
Number of rollouts total     0
Train Time (s)               154.80846773600206
(Previous) Eval Time (s)     22.25150630204007
Sample Time (s)              11.458436476998031
Epoch Time (s)               188.51841051504016
Total Train Time (s)         53810.90585615346
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:52:43.964654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #291 | Epoch Duration: 188.67409229278564
2020-01-12 16:52:43.964902 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0046104
Z variance train             0.010344591
KL Divergence                20.620161
KL Loss                      2.0620162
QF Loss                      1006.4354
VF Loss                      338.75427
Policy Loss                  -954.11804
Q Predictions Mean           947.0766
Q Predictions Std            331.1191
Q Predictions Max            1414.6014
Q Predictions Min            373.55347
V Predictions Mean           954.6444
V Predictions Std            329.26425
V Predictions Max            1419.4595
V Predictions Min            369.1601
Log Pis Mean                 -0.85198635
Log Pis Std                  3.2952905
Log Pis Max                  9.892502
Log Pis Min                  -10.140732
Policy mu Mean               -0.010250335
Policy mu Std                0.5969641
Policy mu Max                2.7133107
Policy mu Min                -2.2912414
Policy log std Mean          -0.8830773
Policy log std Std           0.2556104
Policy log std Max           -0.3277998
Policy log std Min           -2.2201865
Z mean eval                  1.0618814
Z variance eval              0.041118372
total_rewards                [1227.8239269    91.10040399  500.68035272 1519.19020968  834.27628723
 3403.12162106  677.22711654 2321.35324635 1402.97447809 3517.1333302 ]
total_rewards_mean           1549.4880972768071
total_rewards_std            1119.30658683487
total_rewards_max            3517.133330203623
total_rewards_min            91.10040399003351
Number of train steps total  1172000
Number of env steps total    1631880
Number of rollouts total     0
Train Time (s)               152.96908886777237
(Previous) Eval Time (s)     24.33213480282575
Sample Time (s)              12.09094048384577
Epoch Time (s)               189.3921641544439
Total Train Time (s)         54000.390143861994
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:55:53.451977 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #292 | Epoch Duration: 189.48691725730896
2020-01-12 16:55:53.452193 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0633341
Z variance train             0.041653555
KL Divergence                17.466846
KL Loss                      1.7466847
QF Loss                      615.0245
VF Loss                      329.53223
Policy Loss                  -1046.6299
Q Predictions Mean           1041.1931
Q Predictions Std            349.98685
Q Predictions Max            1554.2771
Q Predictions Min            89.78325
V Predictions Mean           1048.1926
V Predictions Std            344.9469
V Predictions Max            1545.1697
V Predictions Min            359.9436
Log Pis Mean                 -0.65288675
Log Pis Std                  3.1861422
Log Pis Max                  18.361137
Log Pis Min                  -9.78856
Policy mu Mean               0.0026511166
Policy mu Std                0.5976162
Policy mu Max                2.0948358
Policy mu Min                -2.5354407
Policy log std Mean          -0.8832685
Policy log std Std           0.27751282
Policy log std Max           -0.17788899
Policy log std Min           -2.8833773
Z mean eval                  1.1691682
Z variance eval              0.051209737
total_rewards                [3491.32915915  401.63240804 3665.84811267  338.40699154  542.30527115
 2231.9872263  2747.00575023  174.1626828  1175.64026578 2513.57485628]
total_rewards_mean           1728.189272393522
total_rewards_std            1288.0097733953992
total_rewards_max            3665.8481126698366
total_rewards_min            174.16268280037798
Number of train steps total  1176000
Number of env steps total    1641326
Number of rollouts total     0
Train Time (s)               144.50332704000175
(Previous) Eval Time (s)     19.811038156971335
Sample Time (s)              11.855773708317429
Epoch Time (s)               176.17013890529051
Total Train Time (s)         54176.64931959892
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:58:49.714931 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #293 | Epoch Duration: 176.2625651359558
2020-01-12 16:58:49.715165 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1699942
Z variance train             0.05160203
KL Divergence                19.229168
KL Loss                      1.9229168
QF Loss                      447.56357
VF Loss                      75.80665
Policy Loss                  -1068.1494
Q Predictions Mean           1061.1978
Q Predictions Std            348.619
Q Predictions Max            1489.3704
Q Predictions Min            129.51727
V Predictions Mean           1068.2781
V Predictions Std            345.7005
V Predictions Max            1480.3536
V Predictions Min            378.03564
Log Pis Mean                 -0.72859395
Log Pis Std                  3.21014
Log Pis Max                  15.623208
Log Pis Min                  -9.045637
Policy mu Mean               0.021926854
Policy mu Std                0.6136352
Policy mu Max                2.4157846
Policy mu Min                -3.0844562
Policy log std Mean          -0.8943398
Policy log std Std           0.2802802
Policy log std Max           -0.2766577
Policy log std Min           -2.6844263
Z mean eval                  1.0966202
Z variance eval              0.027036825
total_rewards                [ 489.58589978 3406.7972025   881.62283572 1235.91740063 3386.79287964
 1654.52091635  122.95009682 1170.9659825   255.78926905 3350.35177413]
total_rewards_mean           1595.5294257123285
total_rewards_std            1248.1161558936299
total_rewards_max            3406.797202497431
total_rewards_min            122.95009681893146
Number of train steps total  1180000
Number of env steps total    1651943
Number of rollouts total     0
Train Time (s)               144.17557275202125
(Previous) Eval Time (s)     19.68120743520558
Sample Time (s)              11.514757025055587
Epoch Time (s)               175.37153721228242
Total Train Time (s)         54352.11081402097
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:01:45.179729 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #294 | Epoch Duration: 175.46436309814453
2020-01-12 17:01:45.179943 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0926416
Z variance train             0.027273908
KL Divergence                20.11799
KL Loss                      2.011799
QF Loss                      376.77625
VF Loss                      66.4114
Policy Loss                  -1078.5547
Q Predictions Mean           1076.3024
Q Predictions Std            337.5795
Q Predictions Max            1505.9741
Q Predictions Min            34.670414
V Predictions Mean           1080.9977
V Predictions Std            337.4357
V Predictions Max            1491.4294
V Predictions Min            37.96412
Log Pis Mean                 -0.52279234
Log Pis Std                  3.0418587
Log Pis Max                  8.87076
Log Pis Min                  -10.655525
Policy mu Mean               0.022177741
Policy mu Std                0.6006573
Policy mu Max                2.1539285
Policy mu Min                -2.6057353
Policy log std Mean          -0.90165234
Policy log std Std           0.27409416
Policy log std Max           -0.16706568
Policy log std Min           -2.2939086
Z mean eval                  1.1682255
Z variance eval              0.0146229835
total_rewards                [ 106.68451094  744.45434521 1035.22200532   61.90249386  155.54081357
  336.62099971 2680.28269493  450.68062602  880.57328318 1189.64775284]
total_rewards_mean           764.160952559794
total_rewards_std            742.7581597197122
total_rewards_max            2680.2826949319133
total_rewards_min            61.902493864991115
Number of train steps total  1184000
Number of env steps total    1661439
Number of rollouts total     0
Train Time (s)               151.28618284408003
(Previous) Eval Time (s)     8.903277185745537
Sample Time (s)              11.130401749163866
Epoch Time (s)               171.31986177898943
Total Train Time (s)         54523.51929890644
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:04:36.591649 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #295 | Epoch Duration: 171.4115617275238
2020-01-12 17:04:36.591827 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1695929
Z variance train             0.014637646
KL Divergence                20.324018
KL Loss                      2.0324018
QF Loss                      2370.0435
VF Loss                      212.07445
Policy Loss                  -1057.1487
Q Predictions Mean           1053.9575
Q Predictions Std            336.3078
Q Predictions Max            1497.7827
Q Predictions Min            403.59973
V Predictions Mean           1055.1558
V Predictions Std            338.78714
V Predictions Max            1499.4619
V Predictions Min            393.9311
Log Pis Mean                 -0.4185224
Log Pis Std                  3.1140118
Log Pis Max                  21.321033
Log Pis Min                  -7.5611467
Policy mu Mean               -0.036485218
Policy mu Std                0.63496524
Policy mu Max                3.3329587
Policy mu Min                -2.7524161
Policy log std Mean          -0.8765216
Policy log std Std           0.25977257
Policy log std Max           -0.15107423
Policy log std Min           -2.503191
Z mean eval                  1.1046752
Z variance eval              0.01647028
total_rewards                [1594.45618256  607.56337809  831.32919209 3592.22928051  404.18057098
 1185.73143481  622.60179099 3034.66629802  878.72988445  841.17820591]
total_rewards_mean           1359.2666218427235
total_rewards_std            1033.2708356104822
total_rewards_max            3592.2292805122906
total_rewards_min            404.180570983669
Number of train steps total  1188000
Number of env steps total    1670207
Number of rollouts total     0
Train Time (s)               153.82984286593273
(Previous) Eval Time (s)     28.69526020111516
Sample Time (s)              12.707954261917621
Epoch Time (s)               195.23305732896551
Total Train Time (s)         54718.84822419565
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:07:51.922676 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #296 | Epoch Duration: 195.33072018623352
2020-01-12 17:07:51.922808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1017822
Z variance train             0.016430166
KL Divergence                19.080925
KL Loss                      1.9080925
QF Loss                      595.9436
VF Loss                      57.744106
Policy Loss                  -1081.6818
Q Predictions Mean           1078.1792
Q Predictions Std            335.1066
Q Predictions Max            1486.143
Q Predictions Min            384.6722
V Predictions Mean           1082.2362
V Predictions Std            335.43954
V Predictions Max            1504.0482
V Predictions Min            396.929
Log Pis Mean                 -0.27736104
Log Pis Std                  2.867723
Log Pis Max                  10.119513
Log Pis Min                  -9.089668
Policy mu Mean               -0.012792399
Policy mu Std                0.5707401
Policy mu Max                2.3368495
Policy mu Min                -2.340695
Policy log std Mean          -0.9607924
Policy log std Std           0.2730246
Policy log std Max           -0.21887296
Policy log std Min           -1.9435698
Z mean eval                  1.0403416
Z variance eval              0.049894836
total_rewards                [2659.00586189  881.05497202  780.5225405  3652.31211173 3485.89731856
 1545.8787099   209.398798   3016.62170475  567.40109926 2043.68353058]
total_rewards_mean           1884.1776647185773
total_rewards_std            1203.2280066881417
total_rewards_max            3652.3121117259834
total_rewards_min            209.39879800410438
Number of train steps total  1192000
Number of env steps total    1679823
Number of rollouts total     0
Train Time (s)               152.8678523749113
(Previous) Eval Time (s)     23.789393851999193
Sample Time (s)              11.581156335771084
Epoch Time (s)               188.23840256268159
Total Train Time (s)         54907.17616556026
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:11:00.254731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #297 | Epoch Duration: 188.33180952072144
2020-01-12 17:11:00.254951 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0423306
Z variance train             0.049928304
KL Divergence                16.974731
KL Loss                      1.6974732
QF Loss                      11798.695
VF Loss                      84.93175
Policy Loss                  -1090.1987
Q Predictions Mean           1085.9705
Q Predictions Std            323.2767
Q Predictions Max            1479.0166
Q Predictions Min            400.34143
V Predictions Mean           1092.9032
V Predictions Std            324.84918
V Predictions Max            1471.7606
V Predictions Min            399.55127
Log Pis Mean                 -0.2709642
Log Pis Std                  2.814211
Log Pis Max                  9.3467045
Log Pis Min                  -6.476461
Policy mu Mean               0.018835044
Policy mu Std                0.6332092
Policy mu Max                2.2361274
Policy mu Min                -2.3570302
Policy log std Mean          -0.89924586
Policy log std Std           0.25099546
Policy log std Max           -0.30957693
Policy log std Min           -1.9575188
Z mean eval                  1.3945816
Z variance eval              0.006581488
total_rewards                [ 321.48771536 2814.68130805 1618.67585542  314.46388622 2795.8292234
  522.28285865 2181.45148401  518.52198958 1107.44875791 1563.56365636]
total_rewards_mean           1375.8406734947048
total_rewards_std            927.5569421719537
total_rewards_max            2814.6813080478487
total_rewards_min            314.46388622174914
Number of train steps total  1196000
Number of env steps total    1688436
Number of rollouts total     0
Train Time (s)               154.34343484602869
(Previous) Eval Time (s)     20.34293374978006
Sample Time (s)              13.427225401159376
Epoch Time (s)               188.11359399696812
Total Train Time (s)         55095.38050434319
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:14:08.467665 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #298 | Epoch Duration: 188.21256041526794
2020-01-12 17:14:08.468001 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4166317
Z variance train             0.0064804256
KL Divergence                22.55276
KL Loss                      2.255276
QF Loss                      578.3037
VF Loss                      190.74927
Policy Loss                  -1044.6675
Q Predictions Mean           1037.6843
Q Predictions Std            355.9526
Q Predictions Max            1478.2498
Q Predictions Min            392.60568
V Predictions Mean           1038.9418
V Predictions Std            356.42444
V Predictions Max            1466.0225
V Predictions Min            375.89194
Log Pis Mean                 -0.6734221
Log Pis Std                  3.0729666
Log Pis Max                  12.448935
Log Pis Min                  -5.9172983
Policy mu Mean               -0.018403463
Policy mu Std                0.5943779
Policy mu Max                2.3786101
Policy mu Min                -2.297082
Policy log std Mean          -0.92008215
Policy log std Std           0.27428156
Policy log std Max           -0.32480025
Policy log std Min           -2.433599
Z mean eval                  0.97662246
Z variance eval              0.01927759
total_rewards                [1184.22225765 3363.78033068  737.49774158 3571.33427784  804.28679551
 3446.31244295  104.59780784 1530.39419919 1322.44214518 2745.00640771]
total_rewards_mean           1880.9874406121903
total_rewards_std            1216.3676093170263
total_rewards_max            3571.334277835905
total_rewards_min            104.5978078367983
Number of train steps total  1200000
Number of env steps total    1698554
Number of rollouts total     0
Train Time (s)               152.60856210021302
(Previous) Eval Time (s)     21.219944483134896
Sample Time (s)              12.357201931998134
Epoch Time (s)               186.18570851534605
Total Train Time (s)         55281.66493512364
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:17:14.750054 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #299 | Epoch Duration: 186.28177189826965
2020-01-12 17:17:14.750259 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98503125
Z variance train             0.018925285
KL Divergence                17.604794
KL Loss                      1.7604793
QF Loss                      718.01855
VF Loss                      118.09555
Policy Loss                  -1033.8243
Q Predictions Mean           1028.8411
Q Predictions Std            348.84125
Q Predictions Max            1525.5889
Q Predictions Min            393.75388
V Predictions Mean           1033.0374
V Predictions Std            351.1013
V Predictions Max            1530.5725
V Predictions Min            397.51718
Log Pis Mean                 -0.6036198
Log Pis Std                  3.1921906
Log Pis Max                  12.547067
Log Pis Min                  -7.250758
Policy mu Mean               -0.04075501
Policy mu Std                0.5895654
Policy mu Max                2.2577574
Policy mu Min                -2.174966
Policy log std Mean          -0.8791478
Policy log std Std           0.2643929
Policy log std Max           -0.007813215
Policy log std Min           -2.0076349
Z mean eval                  1.1969192
Z variance eval              0.044678263
total_rewards                [ 943.97342777 1272.94281573  287.96147476   74.59981379  603.6582036
  577.96254646  129.75040029 1458.7488283  1198.29138292  385.78773645]
total_rewards_mean           693.3676630067037
total_rewards_std            471.2038502495122
total_rewards_max            1458.7488283045616
total_rewards_min            74.599813787189
Number of train steps total  1204000
Number of env steps total    1709470
Number of rollouts total     0
Train Time (s)               144.1198589792475
(Previous) Eval Time (s)     13.149532365147024
Sample Time (s)              11.858327321708202
Epoch Time (s)               169.12771866610274
Total Train Time (s)         55450.89432366658
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:20:03.983897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #300 | Epoch Duration: 169.2334749698639
2020-01-12 17:20:03.984185 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1977028
Z variance train             0.044915795
KL Divergence                17.087763
KL Loss                      1.7087764
QF Loss                      655.69214
VF Loss                      114.118515
Policy Loss                  -1102.6023
Q Predictions Mean           1093.7157
Q Predictions Std            315.19128
Q Predictions Max            1452.892
Q Predictions Min            393.01566
V Predictions Mean           1100.226
V Predictions Std            313.24753
V Predictions Max            1462.3243
V Predictions Min            397.4785
Log Pis Mean                 -0.38117623
Log Pis Std                  3.088946
Log Pis Max                  13.076898
Log Pis Min                  -10.088754
Policy mu Mean               -0.014054565
Policy mu Std                0.6282985
Policy mu Max                3.1713686
Policy mu Min                -2.7568777
Policy log std Mean          -0.91500235
Policy log std Std           0.24762431
Policy log std Max           -0.21138853
Policy log std Min           -2.612358
Z mean eval                  1.1143624
Z variance eval              0.02114938
total_rewards                [ 672.39411666 2935.25616344 3323.20888267 1349.47504176 3210.85214863
 1454.27856845 1582.11264909 2123.11586257  887.36877713   96.06318881]
total_rewards_mean           1763.4125399206373
total_rewards_std            1052.0577673304647
total_rewards_max            3323.208882672493
total_rewards_min            96.06318881347366
Number of train steps total  1208000
Number of env steps total    1718451
Number of rollouts total     0
Train Time (s)               145.16558888182044
(Previous) Eval Time (s)     23.857500575948507
Sample Time (s)              11.71942164329812
Epoch Time (s)               180.74251110106707
Total Train Time (s)         55631.71986250719
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:23:04.818173 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #301 | Epoch Duration: 180.83381009101868
2020-01-12 17:23:04.818391 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1099138
Z variance train             0.02114449
KL Divergence                18.385025
KL Loss                      1.8385025
QF Loss                      381.61475
VF Loss                      300.54388
Policy Loss                  -1091.2771
Q Predictions Mean           1086.554
Q Predictions Std            341.6021
Q Predictions Max            1483.4038
Q Predictions Min            -14.8081875
V Predictions Mean           1095.7412
V Predictions Std            336.2176
V Predictions Max            1488.0717
V Predictions Min            349.8533
Log Pis Mean                 -0.55441743
Log Pis Std                  2.9366035
Log Pis Max                  19.792652
Log Pis Min                  -8.474423
Policy mu Mean               -0.064113736
Policy mu Std                0.5983052
Policy mu Max                2.3942983
Policy mu Min                -2.67786
Policy log std Mean          -0.8990448
Policy log std Std           0.2585118
Policy log std Max           -0.14686203
Policy log std Min           -2.0026226
Z mean eval                  1.1849782
Z variance eval              0.029065032
total_rewards                [ 767.19117119 1271.76140631 3295.60405846 2414.08821638 3620.14102197
 3516.83437481  172.34714082 3550.83753025 3269.97180149 3268.84405861]
total_rewards_mean           2514.7620780295792
total_rewards_std            1230.6200513333204
total_rewards_max            3620.1410219748195
total_rewards_min            172.34714081862484
Number of train steps total  1212000
Number of env steps total    1728360
Number of rollouts total     0
Train Time (s)               153.37039896287024
(Previous) Eval Time (s)     31.982023219112307
Sample Time (s)              12.56262410711497
Epoch Time (s)               197.91504628909752
Total Train Time (s)         55829.727905492764
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:26:22.829656 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #302 | Epoch Duration: 198.01109886169434
2020-01-12 17:26:22.829879 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1884445
Z variance train             0.029338092
KL Divergence                18.793388
KL Loss                      1.8793389
QF Loss                      378.31458
VF Loss                      64.88612
Policy Loss                  -1087.0264
Q Predictions Mean           1083.7902
Q Predictions Std            326.22522
Q Predictions Max            1476.0929
Q Predictions Min            395.83896
V Predictions Mean           1087.0457
V Predictions Std            324.70023
V Predictions Max            1462.0237
V Predictions Min            395.02887
Log Pis Mean                 -0.4262805
Log Pis Std                  3.0854714
Log Pis Max                  17.875435
Log Pis Min                  -7.7156386
Policy mu Mean               -0.013199026
Policy mu Std                0.6018571
Policy mu Max                2.0283625
Policy mu Min                -2.9905777
Policy log std Mean          -0.93223375
Policy log std Std           0.26309302
Policy log std Max           -0.3626752
Policy log std Min           -2.232664
Z mean eval                  1.0155152
Z variance eval              0.007911214
total_rewards                [3623.01429609 3490.0661742  2646.76808569 1806.26900239 2835.0519258
    9.21973799 2106.28190877 3370.92901649 3502.46071716 3347.75455543]
total_rewards_mean           2673.7815420009247
total_rewards_std            1067.5012005885255
total_rewards_max            3623.014296094216
total_rewards_min            9.219737987522794
Number of train steps total  1216000
Number of env steps total    1738467
Number of rollouts total     0
Train Time (s)               153.31702026585117
(Previous) Eval Time (s)     32.29711522581056
Sample Time (s)              12.773288094438612
Epoch Time (s)               198.38742358610034
Total Train Time (s)         56028.20416114433
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:29:41.308752 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #303 | Epoch Duration: 198.47873163223267
2020-01-12 17:29:41.308911 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0240989
Z variance train             0.007978454
KL Divergence                21.476753
KL Loss                      2.1476753
QF Loss                      349.24164
VF Loss                      87.083664
Policy Loss                  -1101.3129
Q Predictions Mean           1095.6958
Q Predictions Std            311.64697
Q Predictions Max            1507.2936
Q Predictions Min            406.18582
V Predictions Mean           1101.4716
V Predictions Std            310.72168
V Predictions Max            1504.746
V Predictions Min            409.83185
Log Pis Mean                 -0.4574495
Log Pis Std                  3.0437536
Log Pis Max                  9.1446085
Log Pis Min                  -10.875417
Policy mu Mean               0.01293197
Policy mu Std                0.6209324
Policy mu Max                1.9316833
Policy mu Min                -2.5768929
Policy log std Mean          -0.92456627
Policy log std Std           0.2719474
Policy log std Max           -0.28442836
Policy log std Min           -2.1672716
Z mean eval                  1.1400734
Z variance eval              0.037026547
total_rewards                [1079.4399436  3557.76817551 2648.2877563  3744.45660715  383.83089464
  672.19433628  729.98786322 3504.89751075 1961.40038006 1064.54345385]
total_rewards_mean           1934.6806921354696
total_rewards_std            1257.9387480725068
total_rewards_max            3744.456607154003
total_rewards_min            383.8308946401812
Number of train steps total  1220000
Number of env steps total    1748019
Number of rollouts total     0
Train Time (s)               152.73106244625524
(Previous) Eval Time (s)     24.0870358729735
Sample Time (s)              11.260218621697277
Epoch Time (s)               188.07831694092602
Total Train Time (s)         56216.41641390929
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:32:49.526451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #304 | Epoch Duration: 188.2173764705658
2020-01-12 17:32:49.526780 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.139281
Z variance train             0.036733624
KL Divergence                18.614704
KL Loss                      1.8614705
QF Loss                      349.52234
VF Loss                      69.18687
Policy Loss                  -1096.2015
Q Predictions Mean           1091.4724
Q Predictions Std            321.00986
Q Predictions Max            1488.9269
Q Predictions Min            404.92648
V Predictions Mean           1096.7485
V Predictions Std            323.19147
V Predictions Max            1493.5922
V Predictions Min            405.63275
Log Pis Mean                 -0.4948453
Log Pis Std                  2.7807922
Log Pis Max                  10.773922
Log Pis Min                  -9.867314
Policy mu Mean               -0.04771593
Policy mu Std                0.605634
Policy mu Max                2.4590378
Policy mu Min                -2.829356
Policy log std Mean          -0.9077426
Policy log std Std           0.25689065
Policy log std Max           -0.2829489
Policy log std Min           -2.2756724
Z mean eval                  1.0170169
Z variance eval              0.010651868
total_rewards                [3488.30984835 3580.57858748 2348.91588589 3554.20822495 1201.85716086
  334.17624852 3514.39158714 3633.62050093 3674.93739364 3539.86248875]
total_rewards_mean           2887.0857926501917
total_rewards_std            1137.1929775720682
total_rewards_max            3674.9373936379043
total_rewards_min            334.17624851569906
Number of train steps total  1224000
Number of env steps total    1756994
Number of rollouts total     0
Train Time (s)               154.64021803392097
(Previous) Eval Time (s)     31.64884701371193
Sample Time (s)              11.944088126067072
Epoch Time (s)               198.23315317369998
Total Train Time (s)         56414.73590965755
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:36:07.848902 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #305 | Epoch Duration: 198.32194256782532
2020-01-12 17:36:07.849080 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0131667
Z variance train             0.010652669
KL Divergence                20.230167
KL Loss                      2.0230167
QF Loss                      746.2006
VF Loss                      209.18437
Policy Loss                  -1074.7401
Q Predictions Mean           1070.2015
Q Predictions Std            332.0848
Q Predictions Max            1498.0511
Q Predictions Min            403.2053
V Predictions Mean           1073.1417
V Predictions Std            332.81253
V Predictions Max            1491.636
V Predictions Min            401.59402
Log Pis Mean                 -0.63004047
Log Pis Std                  3.0878203
Log Pis Max                  14.448248
Log Pis Min                  -7.850202
Policy mu Mean               -0.03426415
Policy mu Std                0.6022895
Policy mu Max                2.1290298
Policy mu Min                -2.5377173
Policy log std Mean          -0.9022031
Policy log std Std           0.2563329
Policy log std Max           -0.32052624
Policy log std Min           -2.6339293
Z mean eval                  1.0085267
Z variance eval              0.019832145
total_rewards                [ 239.75488248 3456.86260582 1231.38480251 1857.15718987 2352.73197951
 3408.89987302  892.55814159  932.93240145  345.32281439 3498.03086769]
total_rewards_mean           1821.5635558319784
total_rewards_std            1223.5285763097108
total_rewards_max            3498.0308676858776
total_rewards_min            239.75488247959922
Number of train steps total  1228000
Number of env steps total    1765669
Number of rollouts total     0
Train Time (s)               149.0089652086608
(Previous) Eval Time (s)     18.324732682667673
Sample Time (s)              11.81807386642322
Epoch Time (s)               179.1517717577517
Total Train Time (s)         56593.9805145571
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:39:07.099838 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #306 | Epoch Duration: 179.25061011314392
2020-01-12 17:39:07.100142 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.013365
Z variance train             0.019810159
KL Divergence                17.948143
KL Loss                      1.7948143
QF Loss                      399.31137
VF Loss                      80.732994
Policy Loss                  -1093.9719
Q Predictions Mean           1091.6819
Q Predictions Std            337.0518
Q Predictions Max            1508.7472
Q Predictions Min            390.9883
V Predictions Mean           1098.427
V Predictions Std            336.24683
V Predictions Max            1511.8834
V Predictions Min            401.8192
Log Pis Mean                 -0.721107
Log Pis Std                  2.640774
Log Pis Max                  6.37869
Log Pis Min                  -6.9864545
Policy mu Mean               -0.017549574
Policy mu Std                0.60453516
Policy mu Max                2.0413406
Policy mu Min                -1.9468813
Policy log std Mean          -0.9031836
Policy log std Std           0.25471163
Policy log std Max           -0.30752313
Policy log std Min           -2.0388029
Z mean eval                  1.1239855
Z variance eval              0.009929461
total_rewards                [1093.15038022 3499.29594018  843.03073848  561.65105106 3552.2039709
 1600.01795028 3716.51322845  234.34863079 2682.60317607 3614.20940925]
total_rewards_mean           2139.702447567529
total_rewards_std            1341.1713806569398
total_rewards_max            3716.513228449434
total_rewards_min            234.348630787216
Number of train steps total  1232000
Number of env steps total    1776111
Number of rollouts total     0
Train Time (s)               145.01619992870837
(Previous) Eval Time (s)     24.031977529171854
Sample Time (s)              10.968691044021398
Epoch Time (s)               180.01686850190163
Total Train Time (s)         56774.09704514686
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:42:07.219034 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #307 | Epoch Duration: 180.11865043640137
2020-01-12 17:42:07.219254 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.120343
Z variance train             0.009929095
KL Divergence                21.306145
KL Loss                      2.1306145
QF Loss                      332.6753
VF Loss                      118.31647
Policy Loss                  -1093.1803
Q Predictions Mean           1090.238
Q Predictions Std            318.23627
Q Predictions Max            1495.1564
Q Predictions Min            412.09412
V Predictions Mean           1090.4575
V Predictions Std            319.16083
V Predictions Max            1488.6163
V Predictions Min            406.84094
Log Pis Mean                 -0.21869549
Log Pis Std                  2.866117
Log Pis Max                  8.074708
Log Pis Min                  -8.5074215
Policy mu Mean               -0.030357884
Policy mu Std                0.6097702
Policy mu Max                2.2016654
Policy mu Min                -2.4318588
Policy log std Mean          -0.92180693
Policy log std Std           0.25596514
Policy log std Max           -0.31665736
Policy log std Min           -2.0760775
Z mean eval                  1.0860965
Z variance eval              0.017373335
total_rewards                [2729.40536146 3140.31389576 1525.62603777   92.14713209  818.98730668
 1736.11776887  293.82899835 3612.66635254  609.50603563 3721.74311212]
total_rewards_mean           1828.0342001261172
total_rewards_std            1314.3655768015376
total_rewards_max            3721.7431121158875
total_rewards_min            92.14713208686041
Number of train steps total  1236000
Number of env steps total    1787291
Number of rollouts total     0
Train Time (s)               145.34709922224283
(Previous) Eval Time (s)     26.09877637634054
Sample Time (s)              12.910936851520091
Epoch Time (s)               184.35681245010346
Total Train Time (s)         56958.545717725065
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:45:11.671332 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #308 | Epoch Duration: 184.45191359519958
2020-01-12 17:45:11.671543 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0856351
Z variance train             0.017347246
KL Divergence                19.236238
KL Loss                      1.9236239
QF Loss                      357.14874
VF Loss                      152.36145
Policy Loss                  -1100.9392
Q Predictions Mean           1095.0664
Q Predictions Std            317.91513
Q Predictions Max            1529.9171
Q Predictions Min            378.57397
V Predictions Mean           1091.5017
V Predictions Std            313.96207
V Predictions Max            1514.9858
V Predictions Min            384.4007
Log Pis Mean                 -0.77805275
Log Pis Std                  2.8897414
Log Pis Max                  7.3464813
Log Pis Min                  -9.673117
Policy mu Mean               0.034082532
Policy mu Std                0.56199366
Policy mu Max                1.9658573
Policy mu Min                -1.9451765
Policy log std Mean          -0.9258771
Policy log std Std           0.2494011
Policy log std Max           -0.15649736
Policy log std Min           -2.2275486
Z mean eval                  1.0174234
Z variance eval              0.011602218
total_rewards                [2267.84842478 3214.06501377 2719.82299466 1274.30981327 3438.72033542
 3208.03901439 3702.49063784  756.04700031 1929.73307928 2689.27450325]
total_rewards_mean           2520.0350816985747
total_rewards_std            913.3076068515268
total_rewards_max            3702.490637843087
total_rewards_min            756.0470003054406
Number of train steps total  1240000
Number of env steps total    1797831
Number of rollouts total     0
Train Time (s)               154.2282172231935
(Previous) Eval Time (s)     27.26229175599292
Sample Time (s)              13.472044501453638
Epoch Time (s)               194.96255348064005
Total Train Time (s)         57153.60024027387
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:48:26.729344 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #309 | Epoch Duration: 195.0576512813568
2020-01-12 17:48:26.729545 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0168309
Z variance train             0.011551726
KL Divergence                20.435991
KL Loss                      2.0435991
QF Loss                      743.1166
VF Loss                      73.75372
Policy Loss                  -1068.3688
Q Predictions Mean           1061.8027
Q Predictions Std            325.96698
Q Predictions Max            1488.7632
Q Predictions Min            373.23065
V Predictions Mean           1065.2673
V Predictions Std            323.80423
V Predictions Max            1476.5863
V Predictions Min            375.78104
Log Pis Mean                 -0.47608122
Log Pis Std                  3.058899
Log Pis Max                  11.2284355
Log Pis Min                  -8.203607
Policy mu Mean               -0.03145121
Policy mu Std                0.6215261
Policy mu Max                2.3925853
Policy mu Min                -2.4431765
Policy log std Mean          -0.8891562
Policy log std Std           0.2419667
Policy log std Max           -0.28020018
Policy log std Min           -1.846365
Z mean eval                  1.1718043
Z variance eval              0.012968105
total_rewards                [ 363.64927166  959.30688647  511.71919299 1267.33658332  437.02868488
  223.96711274  115.17630412 1194.66009358 1578.48638686  154.8965533 ]
total_rewards_mean           680.6227069898424
total_rewards_std            498.526050003542
total_rewards_max            1578.486386858422
total_rewards_min            115.1763041165348
Number of train steps total  1244000
Number of env steps total    1808286
Number of rollouts total     0
Train Time (s)               152.86632027989253
(Previous) Eval Time (s)     11.056981260888278
Sample Time (s)              12.458147414959967
Epoch Time (s)               176.38144895574078
Total Train Time (s)         57330.06637514802
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:51:23.199365 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #310 | Epoch Duration: 176.46964597702026
2020-01-12 17:51:23.199661 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1671231
Z variance train             0.013002326
KL Divergence                21.42205
KL Loss                      2.142205
QF Loss                      1366.0969
VF Loss                      143.2039
Policy Loss                  -1124.8375
Q Predictions Mean           1117.865
Q Predictions Std            315.65906
Q Predictions Max            1524.8063
Q Predictions Min            397.5328
V Predictions Mean           1119.146
V Predictions Std            312.69974
V Predictions Max            1516.9022
V Predictions Min            394.44467
Log Pis Mean                 -0.095822684
Log Pis Std                  3.3110766
Log Pis Max                  12.686159
Log Pis Min                  -14.011497
Policy mu Mean               0.065186955
Policy mu Std                0.6793136
Policy mu Max                2.61588
Policy mu Min                -2.5087016
Policy log std Mean          -0.8850558
Policy log std Std           0.25095794
Policy log std Max           -0.28796625
Policy log std Min           -2.1604955
Z mean eval                  1.2355243
Z variance eval              0.02533868
total_rewards                [2024.51008499  277.80076382 3573.28231285 1366.83374137 3474.73490036
 3301.94658578 1337.73912468 2171.71902199  999.85848269 2065.98868648]
total_rewards_mean           2059.441370501639
total_rewards_std            1055.9345303843243
total_rewards_max            3573.282312853773
total_rewards_min            277.80076381689855
Number of train steps total  1248000
Number of env steps total    1819457
Number of rollouts total     0
Train Time (s)               151.91181061277166
(Previous) Eval Time (s)     24.562867044005543
Sample Time (s)              11.483444275800139
Epoch Time (s)               187.95812193257734
Total Train Time (s)         57518.11171577778
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:54:31.248203 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #311 | Epoch Duration: 188.04837012290955
2020-01-12 17:54:31.248400 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #311 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2296112
Z variance train             0.025841366
KL Divergence                19.34752
KL Loss                      1.9347521
QF Loss                      5252.927
VF Loss                      653.3864
Policy Loss                  -1125.5457
Q Predictions Mean           1124.3168
Q Predictions Std            304.76755
Q Predictions Max            1512.2878
Q Predictions Min            87.29684
V Predictions Mean           1128.3906
V Predictions Std            303.0672
V Predictions Max            1514.0358
V Predictions Min            316.31784
Log Pis Mean                 0.13702588
Log Pis Std                  3.4772449
Log Pis Max                  33.44645
Log Pis Min                  -6.706066
Policy mu Mean               -0.030554958
Policy mu Std                0.66345376
Policy mu Max                2.7614722
Policy mu Min                -5.9480414
Policy log std Mean          -0.9214442
Policy log std Std           0.23696384
Policy log std Max           1.6833304
Policy log std Min           -1.8438486
Z mean eval                  1.155549
Z variance eval              0.009762785
total_rewards                [3169.54740878  100.96485021 1621.01208486 3606.55895511   64.429332
  270.52328561 2584.70170658 1343.81861152 3247.31566444  257.44183204]
total_rewards_mean           1626.6313731142068
total_rewards_std            1356.726825649295
total_rewards_max            3606.5589551068297
total_rewards_min            64.42933200409021
Number of train steps total  1252000
Number of env steps total    1829011
Number of rollouts total     0
Train Time (s)               153.904285187833
(Previous) Eval Time (s)     28.151181939058006
Sample Time (s)              12.559824377298355
Epoch Time (s)               194.61529150418937
Total Train Time (s)         57712.833088691346
Epoch                        312
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:57:45.971290 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #312 | Epoch Duration: 194.72275710105896
2020-01-12 17:57:45.971434 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #312 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1566719
Z variance train             0.009712921
KL Divergence                22.284863
KL Loss                      2.2284863
QF Loss                      608.03784
VF Loss                      121.983505
Policy Loss                  -1130.0696
Q Predictions Mean           1123.3293
Q Predictions Std            315.28732
Q Predictions Max            1534.5872
Q Predictions Min            389.33768
V Predictions Mean           1135.6929
V Predictions Std            308.98584
V Predictions Max            1525.743
V Predictions Min            473.35684
Log Pis Mean                 0.22386706
Log Pis Std                  3.2932293
Log Pis Max                  17.901255
Log Pis Min                  -6.59988
Policy mu Mean               -0.004207664
Policy mu Std                0.71649295
Policy mu Max                2.6226892
Policy mu Min                -2.9821775
Policy log std Mean          -0.9041678
Policy log std Std           0.25157475
Policy log std Max           -0.14194584
Policy log std Min           -2.04576
Z mean eval                  1.4709315
Z variance eval              0.011056872
total_rewards                [ -975.51149951   849.02462614  -878.92621785  1053.25367795
 -1103.34625582 -1205.77212022  -266.02012677  -790.23311258
 -1196.91823153  -578.03387475]
total_rewards_mean           -509.24831349288615
total_rewards_std            780.6543741999791
total_rewards_max            1053.2536779528232
total_rewards_min            -1205.772120215317
Number of train steps total  1256000
Number of env steps total    1838019
Number of rollouts total     0
Train Time (s)               147.19839857891202
(Previous) Eval Time (s)     33.88832867704332
Sample Time (s)              12.552435484714806
Epoch Time (s)               193.63916274067014
Total Train Time (s)         57906.56466300413
Epoch                        313
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:00:59.707238 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #313 | Epoch Duration: 193.73565363883972
2020-01-12 18:00:59.707450 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4458406
Z variance train             0.011026426
KL Divergence                26.23642
KL Loss                      2.623642
QF Loss                      1035.7025
VF Loss                      389.00003
Policy Loss                  -1329.8358
Q Predictions Mean           1316.7852
Q Predictions Std            251.08601
Q Predictions Max            2069.5364
Q Predictions Min            636.4136
V Predictions Mean           1337.731
V Predictions Std            251.20847
V Predictions Max            2113.5273
V Predictions Min            654.54877
Log Pis Mean                 1.9780924
Log Pis Std                  4.0562086
Log Pis Max                  13.801552
Log Pis Min                  -6.0523195
Policy mu Mean               0.033522703
Policy mu Std                0.9088365
Policy mu Max                3.2848618
Policy mu Min                -3.3263562
Policy log std Mean          -0.9149214
Policy log std Std           0.2568676
Policy log std Max           -0.058027506
Policy log std Min           -1.8781936
Z mean eval                  1.4111719
Z variance eval              0.0019201599
total_rewards                [-356.63972978 -977.23237367 -785.80790831 -796.22365748 -977.11541825
  150.15403139 -373.5548448  -342.81999691 -229.03478948 -885.65407947]
total_rewards_mean           -557.3928766751696
total_rewards_std            360.27526006833904
total_rewards_max            150.1540313940214
total_rewards_min            -977.232373672735
Number of train steps total  1260000
Number of env steps total    1847177
Number of rollouts total     0
Train Time (s)               143.68227604869753
(Previous) Eval Time (s)     33.86959840031341
Sample Time (s)              11.382225766777992
Epoch Time (s)               188.93410021578893
Total Train Time (s)         58095.58645602828
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:04:08.732676 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #314 | Epoch Duration: 189.02506613731384
2020-01-12 18:04:08.732897 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4184649
Z variance train             0.0018792946
KL Divergence                34.332134
KL Loss                      3.4332135
QF Loss                      1280.7993
VF Loss                      448.75916
Policy Loss                  -1569.1508
Q Predictions Mean           1548.9596
Q Predictions Std            290.27975
Q Predictions Max            2344.0054
Q Predictions Min            -65.24384
V Predictions Mean           1571.9651
V Predictions Std            284.92017
V Predictions Max            2438.4226
V Predictions Min            752.3802
Log Pis Mean                 2.646749
Log Pis Std                  4.2662325
Log Pis Max                  16.22276
Log Pis Min                  -6.792287
Policy mu Mean               0.16861936
Policy mu Std                0.96585655
Policy mu Max                2.8324294
Policy mu Min                -2.8461766
Policy log std Mean          -0.9201001
Policy log std Std           0.27577734
Policy log std Max           0.04555279
Policy log std Min           -2.2732873
Z mean eval                  1.4429919
Z variance eval              0.039977632
total_rewards                [-725.52646819 -752.35051571 -848.63082574 -720.79455543 -702.04422483
 -606.95252017 -779.6901808  -766.39442316 -769.28769975 -833.50541049]
total_rewards_mean           -750.5176824274807
total_rewards_std            65.14644062268621
total_rewards_max            -606.952520173006
total_rewards_min            -848.630825739513
Number of train steps total  1264000
Number of env steps total    1858435
Number of rollouts total     0
Train Time (s)               148.51147568505257
(Previous) Eval Time (s)     37.350319895893335
Sample Time (s)              11.133202984463423
Epoch Time (s)               196.99499856540933
Total Train Time (s)         58292.67321140366
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:07:25.822593 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #315 | Epoch Duration: 197.089537858963
2020-01-12 18:07:25.822784 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4450203
Z variance train             0.03967111
KL Divergence                32.243183
KL Loss                      3.2243183
QF Loss                      4305.5293
VF Loss                      411.82068
Policy Loss                  -1656.2714
Q Predictions Mean           1638.0592
Q Predictions Std            307.02948
Q Predictions Max            2722.139
Q Predictions Min            540.0096
V Predictions Mean           1660.0065
V Predictions Std            308.5592
V Predictions Max            2782.8389
V Predictions Min            604.6637
Log Pis Mean                 2.2938242
Log Pis Std                  4.007882
Log Pis Max                  18.491617
Log Pis Min                  -11.8235
Policy mu Mean               0.18787071
Policy mu Std                0.934286
Policy mu Max                4.5075264
Policy mu Min                -2.6148229
Policy log std Mean          -0.9289403
Policy log std Std           0.25029305
Policy log std Max           -0.22366846
Policy log std Min           -2.7448664
Z mean eval                  1.4779624
Z variance eval              0.06930202
total_rewards                [-1245.02876269 -1312.3454143  -1075.21291839 -1131.00225419
 -1345.38136998 -1309.723159   -1225.60841701 -1274.04792515
 -1280.89492713 -1093.57067741]
total_rewards_mean           -1229.281582526377
total_rewards_std            91.42891557719898
total_rewards_max            -1075.2129183948632
total_rewards_min            -1345.3813699826078
Number of train steps total  1268000
Number of env steps total    1868848
Number of rollouts total     0
Train Time (s)               154.58948649279773
(Previous) Eval Time (s)     37.71306660491973
Sample Time (s)              12.118201351258904
Epoch Time (s)               204.42075444897637
Total Train Time (s)         58497.18560497789
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:10:50.336796 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #316 | Epoch Duration: 204.5138864517212
2020-01-12 18:10:50.336921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #316 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4801724
Z variance train             0.06869622
KL Divergence                32.909702
KL Loss                      3.2909703
QF Loss                      1606.8629
VF Loss                      353.04645
Policy Loss                  -1900.4507
Q Predictions Mean           1874.023
Q Predictions Std            499.24075
Q Predictions Max            3622.0989
Q Predictions Min            1439.1503
V Predictions Mean           1901.197
V Predictions Std            523.31647
V Predictions Max            3772.6343
V Predictions Min            1461.222
Log Pis Mean                 3.7097383
Log Pis Std                  4.308485
Log Pis Max                  18.964706
Log Pis Min                  -6.705779
Policy mu Mean               -0.055219077
Policy mu Std                1.1209675
Policy mu Max                3.198918
Policy mu Min                -3.1061995
Policy log std Mean          -0.9023528
Policy log std Std           0.25475162
Policy log std Max           -0.08522189
Policy log std Min           -2.1275897
Z mean eval                  1.3931012
Z variance eval              0.004489407
total_rewards                [ -719.12768993 -1081.85729373  -992.02498209 -1018.3435289
 -1742.45956722  -879.9355635  -1036.70492552 -1076.58988965
 -1070.42569441 -1051.26273608]
total_rewards_mean           -1066.8731871025482
total_rewards_std            249.34560607631875
total_rewards_max            -719.1276899292783
total_rewards_min            -1742.4595672174112
Number of train steps total  1272000
Number of env steps total    1878691
Number of rollouts total     0
Train Time (s)               154.2077472708188
(Previous) Eval Time (s)     34.855496814940125
Sample Time (s)              12.037464685738087
Epoch Time (s)               201.100708771497
Total Train Time (s)         58698.39980738005
Epoch                        317
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:14:11.556368 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #317 | Epoch Duration: 201.21932172775269
2020-01-12 18:14:11.556609 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #317 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4008201
Z variance train             0.004498971
KL Divergence                36.478893
KL Loss                      3.6478894
QF Loss                      5940.845
VF Loss                      1648.4819
Policy Loss                  -2101.3706
Q Predictions Mean           2050.568
Q Predictions Std            578.34375
Q Predictions Max            5341.4243
Q Predictions Min            1467.2473
V Predictions Mean           2071.901
V Predictions Std            594.12537
V Predictions Max            5419.5723
V Predictions Min            1638.8203
Log Pis Mean                 6.8672037
Log Pis Std                  4.9904594
Log Pis Max                  35.442966
Log Pis Min                  -4.01447
Policy mu Mean               -0.24616438
Policy mu Std                1.3932669
Policy mu Max                4.3703985
Policy mu Min                -3.9607115
Policy log std Mean          -0.85318005
Policy log std Std           0.2958892
Policy log std Max           0.00050103664
Policy log std Min           -2.6135745
Z mean eval                  1.7240446
Z variance eval              0.92411727
total_rewards                [   -9.72734321 -1579.13812267    -6.3400673   -686.1713692
   -24.08552826  -724.99548764 -1350.51036538   -18.95041645
   -10.53139543  -610.15265012]
total_rewards_mean           -502.0602745660769
total_rewards_std            562.7460426214794
total_rewards_max            -6.340067299402408
total_rewards_min            -1579.1381226686558
Number of train steps total  1276000
Number of env steps total    1888632
Number of rollouts total     0
Train Time (s)               155.86250674631447
(Previous) Eval Time (s)     19.6783701707609
Sample Time (s)              12.039343386888504
Epoch Time (s)               187.58022030396387
Total Train Time (s)         58886.25867235288
Epoch                        318
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:17:19.418059 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #318 | Epoch Duration: 187.86126565933228
2020-01-12 18:17:19.418265 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7244368
Z variance train             0.92715895
KL Divergence                34.19626
KL Loss                      3.419626
QF Loss                      11286.811
VF Loss                      2973.0786
Policy Loss                  -2516.6523
Q Predictions Mean           2468.9072
Q Predictions Std            911.10236
Q Predictions Max            5517.823
Q Predictions Min            1466.092
V Predictions Mean           2490.8013
V Predictions Std            939.0236
V Predictions Max            5675.052
V Predictions Min            1061.0239
Log Pis Mean                 6.951073
Log Pis Std                  4.5721993
Log Pis Max                  18.797764
Log Pis Min                  -3.6772804
Policy mu Mean               0.047948632
Policy mu Std                1.3351609
Policy mu Max                4.0273614
Policy mu Min                -3.6500764
Policy log std Mean          -0.98576915
Policy log std Std           0.34061486
Policy log std Max           0.143103
Policy log std Min           -2.3622596
Z mean eval                  1.7661139
Z variance eval              0.01290791
total_rewards                [ -559.52499634 -1257.28019839    10.23531116  -548.93897002
 -1431.03986413  -378.89486835  -160.04480499  -483.68208366
 -1123.25359376  -437.41774596]
total_rewards_mean           -636.9841814436901
total_rewards_std            451.8632570965373
total_rewards_max            10.235311164872579
total_rewards_min            -1431.039864134808
Number of train steps total  1280000
Number of env steps total    1899693
Number of rollouts total     0
Train Time (s)               153.48924480192363
(Previous) Eval Time (s)     33.8296360289678
Sample Time (s)              11.583649832755327
Epoch Time (s)               198.90253066364676
Total Train Time (s)         59085.249533290975
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:20:38.412725 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #319 | Epoch Duration: 198.99432802200317
2020-01-12 18:20:38.412850 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #319 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7588854
Z variance train             0.0128829
KL Divergence                37.828167
KL Loss                      3.7828166
QF Loss                      10072.697
VF Loss                      1915.7358
Policy Loss                  -3171.1692
Q Predictions Mean           3139.445
Q Predictions Std            815.3507
Q Predictions Max            6141.162
Q Predictions Min            1776.8739
V Predictions Mean           3153.4941
V Predictions Std            817.8694
V Predictions Max            6136.8594
V Predictions Min            1625.7472
Log Pis Mean                 6.4965563
Log Pis Std                  3.6633596
Log Pis Max                  17.316998
Log Pis Min                  -5.78523
Policy mu Mean               0.14961559
Policy mu Std                1.2507815
Policy mu Max                3.4473913
Policy mu Min                -3.564956
Policy log std Mean          -1.0451543
Policy log std Std           0.3370662
Policy log std Max           -0.071371794
Policy log std Min           -2.470273
Z mean eval                  1.6535925
Z variance eval              0.019697959
total_rewards                [-1.06456678e+02 -1.70673153e+02  4.60616217e+01 -2.56798671e+02
 -9.39090918e+00 -1.40836869e+03 -1.35948638e+03  2.14164723e+01
 -8.70515533e+01 -1.26867516e+00]
total_rewards_mean           -333.2016609689879
total_rewards_std            532.7408483614877
total_rewards_max            46.06162167347942
total_rewards_min            -1408.3686869701212
Number of train steps total  1284000
Number of env steps total    1910099
Number of rollouts total     0
Train Time (s)               144.41916404338554
(Previous) Eval Time (s)     33.877994813025
Sample Time (s)              11.208727843128145
Epoch Time (s)               189.50588669953868
Total Train Time (s)         59274.85030045826
Epoch                        320
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:23:48.017286 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #320 | Epoch Duration: 189.6043312549591
2020-01-12 18:23:48.017466 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #320 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6511018
Z variance train             0.019803515
KL Divergence                40.80596
KL Loss                      4.0805964
QF Loss                      7322.426
VF Loss                      1003.06165
Policy Loss                  -3507.8354
Q Predictions Mean           3465.6704
Q Predictions Std            667.368
Q Predictions Max            5616.64
Q Predictions Min            2180.242
V Predictions Mean           3489.5645
V Predictions Std            663.901
V Predictions Max            5573.1284
V Predictions Min            2259.681
Log Pis Mean                 6.4421415
Log Pis Std                  3.9911811
Log Pis Max                  25.906345
Log Pis Min                  -3.9553595
Policy mu Mean               0.17354132
Policy mu Std                1.2373941
Policy mu Max                3.8686955
Policy mu Min                -3.6464767
Policy log std Mean          -1.0657573
Policy log std Std           0.35646933
Policy log std Max           0.14646077
Policy log std Min           -2.2123723
Z mean eval                  1.6701326
Z variance eval              0.13528252
total_rewards                [-7.08085209e-03 -5.09132362e+02  2.66045318e+01 -7.70833958e+02
 -5.51724100e+02  3.16015916e+00 -1.04498127e+02 -9.68866909e+01
 -4.15098137e+02 -3.75355358e+02]
total_rewards_mean           -279.3771121728407
total_rewards_std            266.74094394364016
total_rewards_max            26.604531768000587
total_rewards_min            -770.8339581705745
Number of train steps total  1288000
Number of env steps total    1919876
Number of rollouts total     0
Train Time (s)               144.9526311941445
(Previous) Eval Time (s)     27.33575610537082
Sample Time (s)              11.123611492104828
Epoch Time (s)               183.41199879162014
Total Train Time (s)         59458.35025365651
Epoch                        321
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:26:51.520994 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #321 | Epoch Duration: 183.50337481498718
2020-01-12 18:26:51.521183 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6710926
Z variance train             0.135169
KL Divergence                36.250965
KL Loss                      3.6250966
QF Loss                      5941.991
VF Loss                      1136.5273
Policy Loss                  -3473.806
Q Predictions Mean           3441.315
Q Predictions Std            558.4651
Q Predictions Max            4893.691
Q Predictions Min            805.09357
V Predictions Mean           3474.3015
V Predictions Std            525.75275
V Predictions Max            4896.7617
V Predictions Min            2550.8486
Log Pis Mean                 5.337529
Log Pis Std                  3.7245114
Log Pis Max                  32.75962
Log Pis Min                  -2.9680097
Policy mu Mean               0.23491043
Policy mu Std                1.1109779
Policy mu Max                5.909814
Policy mu Min                -3.6515546
Policy log std Mean          -1.0920823
Policy log std Std           0.32045048
Policy log std Max           0.32393062
Policy log std Min           -2.2643847
Z mean eval                  1.9148245
Z variance eval              0.090813905
total_rewards                [ -931.04906135    -4.24920872    -3.42591471   117.62022084
  -349.55739429  -121.81224634  -829.08928734    -6.62207325
 -1213.67751259   117.28663658]
total_rewards_mean           -322.45758411679776
total_rewards_std            463.9136214091902
total_rewards_max            117.62022084387206
total_rewards_min            -1213.6775125886836
Number of train steps total  1292000
Number of env steps total    1930375
Number of rollouts total     0
Train Time (s)               153.630740580149
(Previous) Eval Time (s)     26.80248801317066
Sample Time (s)              11.89106961619109
Epoch Time (s)               192.32429820951074
Total Train Time (s)         59650.76055729389
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:30:03.934451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #322 | Epoch Duration: 192.41311883926392
2020-01-12 18:30:03.934670 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9240595
Z variance train             0.090616375
KL Divergence                36.148575
KL Loss                      3.6148574
QF Loss                      57669.71
VF Loss                      738.6092
Policy Loss                  -3269.5093
Q Predictions Mean           3243.9922
Q Predictions Std            375.80023
Q Predictions Max            4845.3223
Q Predictions Min            2564.9138
V Predictions Mean           3270.3967
V Predictions Std            387.21765
V Predictions Max            4939.578
V Predictions Min            2607.8328
Log Pis Mean                 4.809881
Log Pis Std                  3.8736994
Log Pis Max                  22.991913
Log Pis Min                  -4.1885753
Policy mu Mean               0.1734287
Policy mu Std                1.101365
Policy mu Max                3.232794
Policy mu Min                -3.5201201
Policy log std Mean          -1.0549815
Policy log std Std           0.30525875
Policy log std Max           0.16277397
Policy log std Min           -2.0569062
Z mean eval                  1.731941
Z variance eval              1.575454
total_rewards                [   -7.4977506  -1196.89044057  -859.18475701  -820.91022837
  -829.06008232  -869.99547322  -854.77517121  -855.74462041
  -880.38655668  -855.44759162]
total_rewards_mean           -802.9892671997242
total_rewards_std            284.74912180803756
total_rewards_max            -7.497750595845712
total_rewards_min            -1196.890440566067
Number of train steps total  1296000
Number of env steps total    1942029
Number of rollouts total     0
Train Time (s)               153.59153491444886
(Previous) Eval Time (s)     33.623831258155406
Sample Time (s)              10.6905010570772
Epoch Time (s)               197.90586722968146
Total Train Time (s)         59848.7539765113
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:33:21.931650 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #323 | Epoch Duration: 197.99682545661926
2020-01-12 18:33:21.931842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7337658
Z variance train             1.5780925
KL Divergence                33.807476
KL Loss                      3.3807476
QF Loss                      4768.3564
VF Loss                      1163.3759
Policy Loss                  -3390.4004
Q Predictions Mean           3348.71
Q Predictions Std            341.5412
Q Predictions Max            4854.7583
Q Predictions Min            2578.8147
V Predictions Mean           3379.5786
V Predictions Std            350.4373
V Predictions Max            4915.099
V Predictions Min            2599.2317
Log Pis Mean                 6.6745996
Log Pis Std                  3.9751377
Log Pis Max                  27.252956
Log Pis Min                  -7.087332
Policy mu Mean               0.078560114
Policy mu Std                1.3401877
Policy mu Max                4.2013016
Policy mu Min                -3.375782
Policy log std Mean          -0.9803177
Policy log std Std           0.32880253
Policy log std Max           0.0053520203
Policy log std Min           -2.269502
Z mean eval                  1.9961879
Z variance eval              0.7066411
total_rewards                [-1241.09919455  -692.71829624  -902.2606745   -938.38699987
  -972.90528651 -1037.79467686 -1270.39589227 -1209.82168709
 -1064.18134846  -759.61182861]
total_rewards_mean           -1008.9175884950971
total_rewards_std            186.094634320913
total_rewards_max            -692.7182962427102
total_rewards_min            -1270.3958922738932
Number of train steps total  1300000
Number of env steps total    1952580
Number of rollouts total     0
Train Time (s)               152.57076527597383
(Previous) Eval Time (s)     39.66360830422491
Sample Time (s)              10.546502003911883
Epoch Time (s)               202.78087558411062
Total Train Time (s)         60051.63529673079
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:36:44.818064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #324 | Epoch Duration: 202.88606190681458
2020-01-12 18:36:44.818324 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #324 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9906414
Z variance train             0.7068297
KL Divergence                31.08393
KL Loss                      3.108393
QF Loss                      50882.504
VF Loss                      721.191
Policy Loss                  -2857.0386
Q Predictions Mean           2842.7568
Q Predictions Std            359.28122
Q Predictions Max            4312.521
Q Predictions Min            2032.2297
V Predictions Mean           2856.4067
V Predictions Std            363.90518
V Predictions Max            4348.1396
V Predictions Min            2079.1746
Log Pis Mean                 2.8936
Log Pis Std                  3.39598
Log Pis Max                  18.676414
Log Pis Min                  -5.005078
Policy mu Mean               0.100892484
Policy mu Std                0.8980893
Policy mu Max                3.0002034
Policy mu Min                -2.672014
Policy log std Mean          -1.0852115
Policy log std Std           0.26254845
Policy log std Max           -0.18164837
Policy log std Min           -2.1359422
Z mean eval                  1.4874717
Z variance eval              0.040515713
total_rewards                [   96.751902    -570.20731316    77.37586224 -1125.49364771
    59.5779912      8.95121919   325.06996863  -204.6854327
 -1270.54727907   198.94588247]
total_rewards_mean           -240.42608469110755
total_rewards_std            532.3757496670526
total_rewards_max            325.06996862938
total_rewards_min            -1270.5472790650037
Number of train steps total  1304000
Number of env steps total    1964635
Number of rollouts total     0
Train Time (s)               154.99739852780476
(Previous) Eval Time (s)     22.198996601160616
Sample Time (s)              12.54458750039339
Epoch Time (s)               189.74098262935877
Total Train Time (s)         60241.46346932044
Epoch                        325
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:39:54.648660 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #325 | Epoch Duration: 189.83017539978027
2020-01-12 18:39:54.648816 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4820178
Z variance train             0.04016469
KL Divergence                29.06754
KL Loss                      2.906754
QF Loss                      1749.1487
VF Loss                      332.24902
Policy Loss                  -2859.9321
Q Predictions Mean           2849.0957
Q Predictions Std            392.99948
Q Predictions Max            4098.1694
Q Predictions Min            2040.8386
V Predictions Mean           2857.622
V Predictions Std            394.09653
V Predictions Max            4134.913
V Predictions Min            2067.5325
Log Pis Mean                 2.2174015
Log Pis Std                  3.1443548
Log Pis Max                  13.821455
Log Pis Min                  -6.1987643
Policy mu Mean               0.12280393
Policy mu Std                0.8780367
Policy mu Max                2.933448
Policy mu Min                -2.6509573
Policy log std Mean          -0.9993282
Policy log std Std           0.2944557
Policy log std Max           -0.22024655
Policy log std Min           -2.2891808
Z mean eval                  1.5341567
Z variance eval              0.037801128
total_rewards                [-290.41439204 -322.06082605  313.02810475   68.10541512 -301.28956793
 -490.00349297 -350.59135073 -242.80863378  302.87098568 -194.54715247]
total_rewards_mean           -150.77109104203012
total_rewards_std            265.6497696187147
total_rewards_max            313.02810475088177
total_rewards_min            -490.0034929733567
Number of train steps total  1308000
Number of env steps total    1976410
Number of rollouts total     0
Train Time (s)               149.07535095419735
(Previous) Eval Time (s)     32.52825285680592
Sample Time (s)              11.59793690033257
Epoch Time (s)               193.20154071133584
Total Train Time (s)         60434.7989484882
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:43:07.987738 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #326 | Epoch Duration: 193.3387942314148
2020-01-12 18:43:07.987925 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5381489
Z variance train             0.03784546
KL Divergence                29.157715
KL Loss                      2.9157715
QF Loss                      68637.61
VF Loss                      742.2949
Policy Loss                  -2272.35
Q Predictions Mean           2263.8755
Q Predictions Std            314.29175
Q Predictions Max            3254.5127
Q Predictions Min            63.944054
V Predictions Mean           2281.0857
V Predictions Std            313.3693
V Predictions Max            3273.0146
V Predictions Min            66.57733
Log Pis Mean                 2.0920029
Log Pis Std                  3.4857376
Log Pis Max                  24.129684
Log Pis Min                  -6.348624
Policy mu Mean               0.01754966
Policy mu Std                0.8340175
Policy mu Max                3.0751288
Policy mu Min                -3.257087
Policy log std Mean          -1.0353347
Policy log std Std           0.27414805
Policy log std Max           -0.29341853
Policy log std Min           -2.6648147
Z mean eval                  1.3897512
Z variance eval              0.10093031
total_rewards                [ 422.6138678   127.0931969   943.21802276   24.26777621 -163.54458485
  220.77992433   15.32116923 -299.78024423  113.59673191  107.90868571]
total_rewards_mean           151.14745457728324
total_rewards_std            323.5260169375456
total_rewards_max            943.2180227585708
total_rewards_min            -299.78024422780254
Number of train steps total  1312000
Number of env steps total    1984161
Number of rollouts total     0
Train Time (s)               144.23100022692233
(Previous) Eval Time (s)     16.98962543392554
Sample Time (s)              11.882729331962764
Epoch Time (s)               173.10335499281064
Total Train Time (s)         60607.997451334726
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:46:01.189713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #327 | Epoch Duration: 173.20164608955383
2020-01-12 18:46:01.189891 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3861634
Z variance train             0.10072454
KL Divergence                24.059666
KL Loss                      2.4059665
QF Loss                      2815.9836
VF Loss                      266.267
Policy Loss                  -2189.4749
Q Predictions Mean           2180.5278
Q Predictions Std            257.49765
Q Predictions Max            2957.9536
Q Predictions Min            810.3203
V Predictions Mean           2183.5537
V Predictions Std            247.02258
V Predictions Max            2957.4568
V Predictions Min            1440.3163
Log Pis Mean                 1.1753213
Log Pis Std                  2.8427353
Log Pis Max                  11.171413
Log Pis Min                  -8.007212
Policy mu Mean               0.053433333
Policy mu Std                0.74832195
Policy mu Max                2.6079326
Policy mu Min                -2.5627494
Policy log std Mean          -1.0320431
Policy log std Std           0.24041659
Policy log std Max           -0.36364168
Policy log std Min           -2.2867215
Z mean eval                  1.4148248
Z variance eval              0.036942173
total_rewards                [-304.37302985  139.70750809  169.31792004  151.33817797  176.36449398
  -49.63136549  -46.99007918  511.66595097  122.89951758 -106.2199199 ]
total_rewards_mean           76.4079174209567
total_rewards_std            207.19942464395524
total_rewards_max            511.6659509652572
total_rewards_min            -304.3730298514408
Number of train steps total  1316000
Number of env steps total    1995900
Number of rollouts total     0
Train Time (s)               146.92609975626692
(Previous) Eval Time (s)     26.65702383313328
Sample Time (s)              12.139623035211116
Epoch Time (s)               185.72274662461132
Total Train Time (s)         60793.809568865225
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:49:07.006074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #328 | Epoch Duration: 185.81601905822754
2020-01-12 18:49:07.006366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4120858
Z variance train             0.037304107
KL Divergence                24.933762
KL Loss                      2.4933763
QF Loss                      983.51794
VF Loss                      305.97345
Policy Loss                  -1911.882
Q Predictions Mean           1908.3533
Q Predictions Std            249.5635
Q Predictions Max            2505.4062
Q Predictions Min            103.66696
V Predictions Mean           1912.7163
V Predictions Std            245.88753
V Predictions Max            2524.4353
V Predictions Min            203.24167
Log Pis Mean                 0.60984313
Log Pis Std                  2.898901
Log Pis Max                  22.04485
Log Pis Min                  -6.6028023
Policy mu Mean               -0.018440975
Policy mu Std                0.76904535
Policy mu Max                10.9977255
Policy mu Min                -5.532728
Policy log std Mean          -0.97369814
Policy log std Std           0.24113135
Policy log std Max           2.0
Policy log std Min           -1.9452858
Z mean eval                  1.1792623
Z variance eval              0.030163089
total_rewards                [ 192.28819981 1634.18752367  -39.93917416 -161.72883824 1297.1986607
  668.9933573   392.73777929 1532.51324919  715.56554866  482.66820075]
total_rewards_mean           671.4484506973314
total_rewards_std            600.4151643428085
total_rewards_max            1634.1875236741896
total_rewards_min            -161.7288382376796
Number of train steps total  1320000
Number of env steps total    2008030
Number of rollouts total     0
Train Time (s)               156.19717214489356
(Previous) Eval Time (s)     28.433223966974765
Sample Time (s)              12.380513921380043
Epoch Time (s)               197.01091003324836
Total Train Time (s)         60990.911891299766
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:52:24.111798 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #329 | Epoch Duration: 197.1052589416504
2020-01-12 18:52:24.111990 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1882333
Z variance train             0.030447554
KL Divergence                22.707825
KL Loss                      2.2707825
QF Loss                      1998.3512
VF Loss                      693.2447
Policy Loss                  -1698.403
Q Predictions Mean           1697.0154
Q Predictions Std            187.61089
Q Predictions Max            2043.447
Q Predictions Min            896.3644
V Predictions Mean           1709.0812
V Predictions Std            183.58757
V Predictions Max            2049.1772
V Predictions Min            789.2833
Log Pis Mean                 0.26998472
Log Pis Std                  2.399108
Log Pis Max                  11.138495
Log Pis Min                  -7.7739873
Policy mu Mean               0.08093317
Policy mu Std                0.6305301
Policy mu Max                2.2179275
Policy mu Min                -2.2854867
Policy log std Mean          -1.0063239
Policy log std Std           0.20537253
Policy log std Max           -0.37355608
Policy log std Min           -2.0717974
Z mean eval                  1.1296539
Z variance eval              0.02860567
total_rewards                [2412.30420717  297.8839778  1737.72008138 1786.78503492   95.78722951
 2606.43469431 1505.50788542 1282.6177979  2464.80318403  248.36869643]
total_rewards_mean           1443.821278885957
total_rewards_std            901.4044932056643
total_rewards_max            2606.434694310523
total_rewards_min            95.7872295050162
Number of train steps total  1324000
Number of env steps total    2018962
Number of rollouts total     0
Train Time (s)               155.0573328831233
(Previous) Eval Time (s)     33.30829914705828
Sample Time (s)              13.374270870815963
Epoch Time (s)               201.73990290099755
Total Train Time (s)         61192.74025470996
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:55:45.950021 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #330 | Epoch Duration: 201.83786416053772
2020-01-12 18:55:45.950430 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1209881
Z variance train             0.028220687
KL Divergence                20.931686
KL Loss                      2.0931687
QF Loss                      1079.1083
VF Loss                      269.85928
Policy Loss                  -1568.8525
Q Predictions Mean           1568.0266
Q Predictions Std            212.87796
Q Predictions Max            1884.4386
Q Predictions Min            -60.200455
V Predictions Mean           1576.0508
V Predictions Std            206.4254
V Predictions Max            1878.3431
V Predictions Min            65.499245
Log Pis Mean                 0.069856524
Log Pis Std                  2.5617542
Log Pis Max                  16.703163
Log Pis Min                  -9.268141
Policy mu Mean               0.0024718153
Policy mu Std                0.61726516
Policy mu Max                2.6555247
Policy mu Min                -2.335024
Policy log std Mean          -0.998894
Policy log std Std           0.21974169
Policy log std Max           -0.38377655
Policy log std Min           -2.7996225
Z mean eval                  1.2716177
Z variance eval              0.054341156
total_rewards                [2652.6064687   847.75211063 1334.26840256  839.29720044 1108.25584463
  797.82487217 1433.12437086 1416.92890027 2922.95578427  629.96275186]
total_rewards_mean           1398.297670638784
total_rewards_std            745.2613650638881
total_rewards_max            2922.9557842691684
total_rewards_min            629.9627518613786
Number of train steps total  1328000
Number of env steps total    2027328
Number of rollouts total     0
Train Time (s)               154.75381695711985
(Previous) Eval Time (s)     26.21646440308541
Sample Time (s)              12.039162663277239
Epoch Time (s)               193.0094440234825
Total Train Time (s)         61385.84941241145
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:58:59.057128 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #331 | Epoch Duration: 193.10636854171753
2020-01-12 18:58:59.057312 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2711265
Z variance train             0.054646276
KL Divergence                19.58432
KL Loss                      1.9584321
QF Loss                      6250.953
VF Loss                      128.13939
Policy Loss                  -1451.4568
Q Predictions Mean           1447.4781
Q Predictions Std            185.2005
Q Predictions Max            1780.4437
Q Predictions Min            856.14154
V Predictions Mean           1457.7471
V Predictions Std            183.00127
V Predictions Max            1796.5104
V Predictions Min            875.30786
Log Pis Mean                 0.38884762
Log Pis Std                  2.4796627
Log Pis Max                  9.392909
Log Pis Min                  -7.18613
Policy mu Mean               -0.02549319
Policy mu Std                0.6732537
Policy mu Max                2.1811533
Policy mu Min                -2.3807764
Policy log std Mean          -0.96283185
Policy log std Std           0.19836488
Policy log std Max           -0.40259707
Policy log std Min           -1.9557233
Z mean eval                  1.225997
Z variance eval              0.13595384
total_rewards                [2227.83268376 1368.22114539 2403.35059221  321.59521961 1111.95158122
 2880.0714423  1849.80509015 2797.07217073 2895.02435949  112.48714458]
total_rewards_mean           1796.741142943408
total_rewards_std            979.9212523311987
total_rewards_max            2895.024359491789
total_rewards_min            112.48714457795106
Number of train steps total  1332000
Number of env steps total    2038733
Number of rollouts total     0
Train Time (s)               155.066851596348
(Previous) Eval Time (s)     31.15353419072926
Sample Time (s)              10.679881270043552
Epoch Time (s)               196.9002670571208
Total Train Time (s)         61582.83724723151
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:02:16.047710 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #332 | Epoch Duration: 196.9902582168579
2020-01-12 19:02:16.047903 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2222011
Z variance train             0.13538532
KL Divergence                17.596815
KL Loss                      1.7596816
QF Loss                      1319.2026
VF Loss                      468.63354
Policy Loss                  -1384.6808
Q Predictions Mean           1380.5286
Q Predictions Std            220.56181
Q Predictions Max            1715.1744
Q Predictions Min            787.7792
V Predictions Mean           1392.7994
V Predictions Std            221.67244
V Predictions Max            1721.154
V Predictions Min            793.5081
Log Pis Mean                 0.027879488
Log Pis Std                  2.3039644
Log Pis Max                  8.146363
Log Pis Min                  -7.106935
Policy mu Mean               -0.004601561
Policy mu Std                0.6209308
Policy mu Max                1.822417
Policy mu Min                -2.4003184
Policy log std Mean          -0.9576603
Policy log std Std           0.1911495
Policy log std Max           -0.39268404
Policy log std Min           -1.6699022
Z mean eval                  1.122215
Z variance eval              0.054073226
total_rewards                [ 231.66663036 1656.65551257  534.3932257   604.16997188  707.44152385
  115.93984049 1926.85458603  113.59648805 1088.01212868  941.90302741]
total_rewards_mean           792.0632935028614
total_rewards_std            590.3957824782149
total_rewards_max            1926.8545860297272
total_rewards_min            113.59648805325517
Number of train steps total  1336000
Number of env steps total    2048806
Number of rollouts total     0
Train Time (s)               145.97132091689855
(Previous) Eval Time (s)     24.19625486107543
Sample Time (s)              11.970035036094487
Epoch Time (s)               182.13761081406847
Total Train Time (s)         61765.091523405164
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:05:18.306630 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #333 | Epoch Duration: 182.25855827331543
2020-01-12 19:05:18.306999 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1266239
Z variance train             0.05395568
KL Divergence                18.714352
KL Loss                      1.8714352
QF Loss                      436.3711
VF Loss                      857.649
Policy Loss                  -1245.6755
Q Predictions Mean           1240.7107
Q Predictions Std            264.63013
Q Predictions Max            1646.4956
Q Predictions Min            202.23006
V Predictions Mean           1239.7795
V Predictions Std            264.83047
V Predictions Max            1625.2767
V Predictions Min            -135.63536
Log Pis Mean                 0.050369665
Log Pis Std                  2.4514816
Log Pis Max                  12.599258
Log Pis Min                  -6.450273
Policy mu Mean               -0.0045799743
Policy mu Std                0.6350779
Policy mu Max                1.998552
Policy mu Min                -2.6111622
Policy log std Mean          -0.967299
Policy log std Std           0.2071231
Policy log std Max           -0.045988083
Policy log std Min           -2.5288997
Z mean eval                  1.2182274
Z variance eval              0.4833538
total_rewards                [ 521.3869255   942.0497634   405.94165335  249.84919855 1767.57392259
  428.87420681 1334.15860786 2552.89657081 1397.22610714 2898.73452221]
total_rewards_mean           1249.8691478228232
total_rewards_std            878.9311598751195
total_rewards_max            2898.734522214219
total_rewards_min            249.8491985528303
Number of train steps total  1340000
Number of env steps total    2059355
Number of rollouts total     0
Train Time (s)               145.22537313122302
(Previous) Eval Time (s)     24.142613308038563
Sample Time (s)              11.895266279112548
Epoch Time (s)               181.26325271837413
Total Train Time (s)         61946.4416283248
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:08:19.662215 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #334 | Epoch Duration: 181.35486388206482
2020-01-12 19:08:19.662471 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2132056
Z variance train             0.4785861
KL Divergence                17.293802
KL Loss                      1.7293802
QF Loss                      16086.309
VF Loss                      361.67514
Policy Loss                  -1239.5847
Q Predictions Mean           1234.5553
Q Predictions Std            257.34372
Q Predictions Max            1591.1553
Q Predictions Min            618.2622
V Predictions Mean           1248.0522
V Predictions Std            256.40027
V Predictions Max            1601.4644
V Predictions Min            618.9964
Log Pis Mean                 -0.19984698
Log Pis Std                  2.6543438
Log Pis Max                  8.918297
Log Pis Min                  -6.6948814
Policy mu Mean               -0.051542178
Policy mu Std                0.64265984
Policy mu Max                2.3935263
Policy mu Min                -2.2477968
Policy log std Mean          -0.90229535
Policy log std Std           0.21004356
Policy log std Max           -0.32194078
Policy log std Min           -1.8129966
Z mean eval                  1.0373015
Z variance eval              0.11092244
total_rewards                [1698.5609815  3101.63778464  991.61688333 2313.83394208  516.5839375
  597.49344237 3136.32931816 3014.85137752  674.45352524 1265.8661971 ]
total_rewards_mean           1731.122738942328
total_rewards_std            1023.7964212791643
total_rewards_max            3136.329318155126
total_rewards_min            516.5839374991255
Number of train steps total  1344000
Number of env steps total    2071059
Number of rollouts total     0
Train Time (s)               151.29030657093972
(Previous) Eval Time (s)     24.688588007818907
Sample Time (s)              11.7950129234232
Epoch Time (s)               187.77390750218183
Total Train Time (s)         62134.305890669115
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:11:27.528730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #335 | Epoch Duration: 187.86607336997986
2020-01-12 19:11:27.528939 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0282261
Z variance train             0.110424854
KL Divergence                17.030376
KL Loss                      1.7030376
QF Loss                      3944.1467
VF Loss                      89.80071
Policy Loss                  -1101.9886
Q Predictions Mean           1097.7133
Q Predictions Std            280.26633
Q Predictions Max            1517.1571
Q Predictions Min            502.30862
V Predictions Mean           1100.669
V Predictions Std            275.74057
V Predictions Max            1494.468
V Predictions Min            522.0986
Log Pis Mean                 -0.2558037
Log Pis Std                  2.8706396
Log Pis Max                  20.512321
Log Pis Min                  -7.6930103
Policy mu Mean               0.069409415
Policy mu Std                0.6312177
Policy mu Max                3.7111504
Policy mu Min                -2.23212
Policy log std Mean          -0.9124168
Policy log std Std           0.21034484
Policy log std Max           -0.21589142
Policy log std Min           -2.472507
Z mean eval                  1.1660681
Z variance eval              0.06213841
total_rewards                [ 154.597428   3044.97048213 2918.26061882 1158.28673655  233.43416727
 2167.28129885 1282.01579191 2982.20296109 2998.61789716 1045.43832599]
total_rewards_mean           1798.5105707767682
total_rewards_std            1103.6559876376612
total_rewards_max            3044.970482127466
total_rewards_min            154.59742800324867
Number of train steps total  1348000
Number of env steps total    2082279
Number of rollouts total     0
Train Time (s)               154.60706338193268
(Previous) Eval Time (s)     21.56496499525383
Sample Time (s)              11.267354012001306
Epoch Time (s)               187.4393823891878
Total Train Time (s)         62321.83821318485
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:14:35.065202 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #336 | Epoch Duration: 187.5360996723175
2020-01-12 19:14:35.065463 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1699047
Z variance train             0.061753374
KL Divergence                17.772278
KL Loss                      1.7772278
QF Loss                      12851.748
VF Loss                      144.03743
Policy Loss                  -1110.0568
Q Predictions Mean           1105.4592
Q Predictions Std            297.9744
Q Predictions Max            1473.1638
Q Predictions Min            -184.75723
V Predictions Mean           1115.8232
V Predictions Std            295.06674
V Predictions Max            1492.7703
V Predictions Min            -71.32197
Log Pis Mean                 -0.19598372
Log Pis Std                  3.377337
Log Pis Max                  28.507927
Log Pis Min                  -8.836941
Policy mu Mean               0.039776467
Policy mu Std                0.63223505
Policy mu Max                5.006557
Policy mu Min                -3.3857782
Policy log std Mean          -0.9470116
Policy log std Std           0.21841228
Policy log std Max           -0.21620429
Policy log std Min           -2.720397
Z mean eval                  1.139856
Z variance eval              0.044395156
total_rewards                [3097.27571311 1226.37364716  305.51298403 1725.94084104 1385.24804724
  449.46441633 1382.53094966  389.42393875 1023.84966637 1025.77456881]
total_rewards_mean           1201.13947724964
total_rewards_std            776.2997840833646
total_rewards_max            3097.2757131107296
total_rewards_min            305.5129840284609
Number of train steps total  1352000
Number of env steps total    2093325
Number of rollouts total     0
Train Time (s)               154.9100159071386
(Previous) Eval Time (s)     24.57879181811586
Sample Time (s)              12.740956163965166
Epoch Time (s)               192.2297638892196
Total Train Time (s)         62514.17183020385
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:17:47.402349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #337 | Epoch Duration: 192.33670687675476
2020-01-12 19:17:47.402589 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1343832
Z variance train             0.04434942
KL Divergence                16.778976
KL Loss                      1.6778977
QF Loss                      319.38544
VF Loss                      72.81346
Policy Loss                  -1112.0128
Q Predictions Mean           1107.9233
Q Predictions Std            266.4179
Q Predictions Max            1454.5264
Q Predictions Min            446.04382
V Predictions Mean           1109.9854
V Predictions Std            265.97534
V Predictions Max            1457.4357
V Predictions Min            445.1164
Log Pis Mean                 -0.40705138
Log Pis Std                  2.6655285
Log Pis Max                  7.1741705
Log Pis Min                  -8.124761
Policy mu Mean               0.0403626
Policy mu Std                0.6169504
Policy mu Max                2.5988495
Policy mu Min                -2.6155198
Policy log std Mean          -0.91689795
Policy log std Std           0.20499563
Policy log std Max           -0.36865425
Policy log std Min           -1.8467398
Z mean eval                  0.9920209
Z variance eval              0.13386653
total_rewards                [  51.39180669 2419.74222933 2680.11156761 2810.5384031   682.35767015
 2671.34761749  993.22453521 1939.89027478  654.19422231 2948.13175327]
total_rewards_mean           1785.0930079944083
total_rewards_std            1026.8971460958307
total_rewards_max            2948.1317532688627
total_rewards_min            51.39180668541072
Number of train steps total  1356000
Number of env steps total    2103742
Number of rollouts total     0
Train Time (s)               155.78221913799644
(Previous) Eval Time (s)     29.052906896919012
Sample Time (s)              12.41004431527108
Epoch Time (s)               197.24517035018653
Total Train Time (s)         62711.50931305159
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:21:04.743979 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #338 | Epoch Duration: 197.34123468399048
2020-01-12 19:21:04.744191 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9925116
Z variance train             0.13529266
KL Divergence                15.681095
KL Loss                      1.5681095
QF Loss                      8530.499
VF Loss                      104.23615
Policy Loss                  -1099.1437
Q Predictions Mean           1096.4644
Q Predictions Std            276.7569
Q Predictions Max            1438.0244
Q Predictions Min            432.40234
V Predictions Mean           1103.5688
V Predictions Std            280.3825
V Predictions Max            1439.8186
V Predictions Min            427.17596
Log Pis Mean                 0.03849694
Log Pis Std                  2.5673273
Log Pis Max                  8.610442
Log Pis Min                  -8.030345
Policy mu Mean               -0.017109588
Policy mu Std                0.62357557
Policy mu Max                2.846597
Policy mu Min                -2.170761
Policy log std Mean          -0.914984
Policy log std Std           0.21050534
Policy log std Max           -0.3047757
Policy log std Min           -2.034986
Z mean eval                  1.1469705
Z variance eval              0.051059045
total_rewards                [1540.82353804 2309.07407257 2733.82224301 3241.99345776 3207.81832257
 3186.67889659 3028.45175165  769.11955241 1291.37890906 1201.65707081]
total_rewards_mean           2251.0817814475818
total_rewards_std            913.0333453960558
total_rewards_max            3241.9934577611107
total_rewards_min            769.1195524117365
Number of train steps total  1360000
Number of env steps total    2114154
Number of rollouts total     0
Train Time (s)               153.35119965299964
(Previous) Eval Time (s)     26.073352369945496
Sample Time (s)              11.445613254792988
Epoch Time (s)               190.87016527773812
Total Train Time (s)         62902.46955805784
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:24:15.707548 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #339 | Epoch Duration: 190.96321177482605
2020-01-12 19:24:15.707747 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1482829
Z variance train             0.050870627
KL Divergence                19.223183
KL Loss                      1.9223183
QF Loss                      13225.365
VF Loss                      228.16371
Policy Loss                  -1101.216
Q Predictions Mean           1096.4645
Q Predictions Std            303.29315
Q Predictions Max            1497.4371
Q Predictions Min            432.8503
V Predictions Mean           1109.9342
V Predictions Std            304.43478
V Predictions Max            1506.8422
V Predictions Min            446.7641
Log Pis Mean                 -0.3418768
Log Pis Std                  2.8692107
Log Pis Max                  11.382925
Log Pis Min                  -8.821535
Policy mu Mean               0.02057055
Policy mu Std                0.64782786
Policy mu Max                2.4433658
Policy mu Min                -2.3976746
Policy log std Mean          -0.90599597
Policy log std Std           0.21916315
Policy log std Max           -0.3080731
Policy log std Min           -2.0374234
Z mean eval                  1.2461016
Z variance eval              0.22764933
total_rewards                [1011.20688531  100.22469272  212.87046564  125.52514402 3057.17105292
 1153.13056071 1183.69785125 2669.0575301  2869.16325666 1876.61213326]
total_rewards_mean           1425.8659572595438
total_rewards_std            1082.4741105962537
total_rewards_max            3057.171052921316
total_rewards_min            100.2246927193884
Number of train steps total  1364000
Number of env steps total    2124941
Number of rollouts total     0
Train Time (s)               145.84985592216253
(Previous) Eval Time (s)     18.655385673977435
Sample Time (s)              11.349499142263085
Epoch Time (s)               175.85474073840305
Total Train Time (s)         63078.41504433099
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:27:11.656931 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #340 | Epoch Duration: 175.94904112815857
2020-01-12 19:27:11.657114 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2681984
Z variance train             0.2275984
KL Divergence                17.046652
KL Loss                      1.7046652
QF Loss                      609.4907
VF Loss                      120.8654
Policy Loss                  -1066.6234
Q Predictions Mean           1060.0364
Q Predictions Std            285.78714
Q Predictions Max            1483.1571
Q Predictions Min            111.31125
V Predictions Mean           1062.5203
V Predictions Std            291.96503
V Predictions Max            1469.0358
V Predictions Min            -96.32096
Log Pis Mean                 -0.16265552
Log Pis Std                  3.4430184
Log Pis Max                  32.29221
Log Pis Min                  -8.27111
Policy mu Mean               -0.026790533
Policy mu Std                0.64170647
Policy mu Max                4.5704536
Policy mu Min                -3.911483
Policy log std Mean          -0.92994475
Policy log std Std           0.26056218
Policy log std Max           2.0
Policy log std Min           -1.774481
Z mean eval                  1.2904537
Z variance eval              0.1199619
total_rewards                [ 703.93723138  137.120356   3131.94814559  900.53932328 1491.78689886
  264.18220653 3000.11048274  806.19021117  819.64647878 1489.42006533]
total_rewards_mean           1274.488139966378
total_rewards_std            986.2666031225582
total_rewards_max            3131.948145592197
total_rewards_min            137.12035599662056
Number of train steps total  1368000
Number of env steps total    2135025
Number of rollouts total     0
Train Time (s)               144.74875654978678
(Previous) Eval Time (s)     21.179621427785605
Sample Time (s)              11.723892621695995
Epoch Time (s)               177.65227059926838
Total Train Time (s)         63256.15787223913
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:30:09.403464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #341 | Epoch Duration: 177.74620723724365
2020-01-12 19:30:09.403655 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2909353
Z variance train             0.12169148
KL Divergence                15.325059
KL Loss                      1.5325059
QF Loss                      942.27045
VF Loss                      126.46101
Policy Loss                  -1005.6851
Q Predictions Mean           1002.3135
Q Predictions Std            305.52335
Q Predictions Max            1395.3738
Q Predictions Min            398.20047
V Predictions Mean           1007.1031
V Predictions Std            307.44513
V Predictions Max            1400.7382
V Predictions Min            390.6891
Log Pis Mean                 -0.4596801
Log Pis Std                  3.0640535
Log Pis Max                  12.87546
Log Pis Min                  -10.30134
Policy mu Mean               0.058880538
Policy mu Std                0.6289819
Policy mu Max                4.000637
Policy mu Min                -2.3632843
Policy log std Mean          -0.9268764
Policy log std Std           0.23223044
Policy log std Max           -0.30863547
Policy log std Min           -2.1773648
Z mean eval                  1.2435051
Z variance eval              0.07521473
total_rewards                [3015.21431193  387.96232653  357.2755676   242.11798179 2985.09583456
  282.30849295 1457.50699075 2815.45047301 1265.54168254  385.93787994]
total_rewards_mean           1319.4411541597617
total_rewards_std            1131.8646777436168
total_rewards_max            3015.2143119274583
total_rewards_min            242.11798178621686
Number of train steps total  1372000
Number of env steps total    2147005
Number of rollouts total     0
Train Time (s)               152.35868421429768
(Previous) Eval Time (s)     25.24386825505644
Sample Time (s)              12.913728238549083
Epoch Time (s)               190.5162807079032
Total Train Time (s)         63447.023114404175
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:33:20.272633 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #342 | Epoch Duration: 190.8688235282898
2020-01-12 19:33:20.272852 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2473419
Z variance train             0.07566033
KL Divergence                16.69371
KL Loss                      1.669371
QF Loss                      335.8734
VF Loss                      68.784935
Policy Loss                  -1076.6656
Q Predictions Mean           1072.9319
Q Predictions Std            308.28342
Q Predictions Max            1442.088
Q Predictions Min            125.79235
V Predictions Mean           1079.4075
V Predictions Std            308.41483
V Predictions Max            1455.9578
V Predictions Min            156.28886
Log Pis Mean                 -0.39354196
Log Pis Std                  2.8684282
Log Pis Max                  12.449972
Log Pis Min                  -10.051002
Policy mu Mean               -0.008521595
Policy mu Std                0.6172612
Policy mu Max                1.8200343
Policy mu Min                -2.1227012
Policy log std Mean          -0.9100368
Policy log std Std           0.21436077
Policy log std Max           -0.35923934
Policy log std Min           -2.5537858
Z mean eval                  1.182569
Z variance eval              0.05160706
total_rewards                [ 481.40383523 2922.620206   2831.83290595  464.70497855 1407.64175177
 2348.43502192 2499.61690022 1354.67927543   77.77710074  893.9335621 ]
total_rewards_mean           1528.2645537901901
total_rewards_std            1001.886760726556
total_rewards_max            2922.62020599811
total_rewards_min            77.77710073717334
Number of train steps total  1376000
Number of env steps total    2157487
Number of rollouts total     0
Train Time (s)               154.25871644215658
(Previous) Eval Time (s)     24.491683477070183
Sample Time (s)              12.218645930755883
Epoch Time (s)               190.96904584998265
Total Train Time (s)         63638.093734912574
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:36:31.347109 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #343 | Epoch Duration: 191.07407879829407
2020-01-12 19:36:31.347544 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1841538
Z variance train             0.05188351
KL Divergence                16.259045
KL Loss                      1.6259044
QF Loss                      1104.0046
VF Loss                      170.03502
Policy Loss                  -1091.3611
Q Predictions Mean           1085.0952
Q Predictions Std            283.1911
Q Predictions Max            1418.3953
Q Predictions Min            117.33065
V Predictions Mean           1087.4294
V Predictions Std            285.0522
V Predictions Max            1425.635
V Predictions Min            89.22546
Log Pis Mean                 -0.19634886
Log Pis Std                  3.3994706
Log Pis Max                  27.405865
Log Pis Min                  -7.0177827
Policy mu Mean               0.06572862
Policy mu Std                0.6394694
Policy mu Max                4.3931108
Policy mu Min                -2.6787052
Policy log std Mean          -0.91854525
Policy log std Std           0.24917386
Policy log std Max           0.39660704
Policy log std Min           -3.0009933
Z mean eval                  1.0974886
Z variance eval              0.048067518
total_rewards                [ 530.85306701 3357.21117071   36.51434103  166.55177331 1390.48985333
  350.13455247  639.14513199 1214.14548089 2366.71364477  617.012173  ]
total_rewards_mean           1066.8771188508672
total_rewards_std            1005.9933513716918
total_rewards_max            3357.2111707104773
total_rewards_min            36.514341030615135
Number of train steps total  1380000
Number of env steps total    2168287
Number of rollouts total     0
Train Time (s)               152.62860260810703
(Previous) Eval Time (s)     18.681319469120353
Sample Time (s)              12.349929504096508
Epoch Time (s)               183.6598515813239
Total Train Time (s)         63821.85457096947
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:39:35.112779 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #344 | Epoch Duration: 183.7649405002594
2020-01-12 19:39:35.113183 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0984263
Z variance train             0.047793675
KL Divergence                16.236044
KL Loss                      1.6236044
QF Loss                      495.79083
VF Loss                      74.70315
Policy Loss                  -1003.62213
Q Predictions Mean           999.8921
Q Predictions Std            301.41708
Q Predictions Max            1383.6238
Q Predictions Min            350.35852
V Predictions Mean           1005.04584
V Predictions Std            304.28998
V Predictions Max            1380.1755
V Predictions Min            344.07874
Log Pis Mean                 -0.42858186
Log Pis Std                  3.0368857
Log Pis Max                  18.78659
Log Pis Min                  -8.867646
Policy mu Mean               0.021726806
Policy mu Std                0.61276054
Policy mu Max                2.289562
Policy mu Min                -2.5354233
Policy log std Mean          -0.8997172
Policy log std Std           0.24496332
Policy log std Max           -0.28635585
Policy log std Min           -2.3465915
Z mean eval                  1.2803259
Z variance eval              0.018151429
total_rewards                [3052.73696872 3202.85255466 2068.89493753 3257.46569424 2711.69920186
  448.94532849 3141.96827566 3070.12051893  665.03921822 3022.81577188]
total_rewards_mean           2464.25384702126
total_rewards_std            1008.7401915827733
total_rewards_max            3257.4656942415036
total_rewards_min            448.94532849119446
Number of train steps total  1384000
Number of env steps total    2180462
Number of rollouts total     0
Train Time (s)               154.74058041907847
(Previous) Eval Time (s)     33.35705667408183
Sample Time (s)              12.024157613981515
Epoch Time (s)               200.12179470714182
Total Train Time (s)         64022.19639710989
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:42:55.458381 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #345 | Epoch Duration: 200.34494972229004
2020-01-12 19:42:55.458576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2810564
Z variance train             0.018195843
KL Divergence                17.447914
KL Loss                      1.7447914
QF Loss                      473.5284
VF Loss                      173.54733
Policy Loss                  -993.8183
Q Predictions Mean           989.5029
Q Predictions Std            301.6005
Q Predictions Max            1415.8003
Q Predictions Min            347.8409
V Predictions Mean           991.06537
V Predictions Std            299.31583
V Predictions Max            1389.9796
V Predictions Min            350.58502
Log Pis Mean                 -0.32980794
Log Pis Std                  2.7410936
Log Pis Max                  11.191424
Log Pis Min                  -6.920253
Policy mu Mean               -0.005897247
Policy mu Std                0.5842161
Policy mu Max                1.9319435
Policy mu Min                -2.5790782
Policy log std Mean          -0.942902
Policy log std Std           0.23691435
Policy log std Max           -0.30774063
Policy log std Min           -2.0053463
Z mean eval                  0.9614577
Z variance eval              0.11247082
total_rewards                [1178.28240812 1199.33610196  592.05509536 1531.81087532 3135.85613192
 1042.68536716 1263.51414802 3066.86733648 1123.3625566   207.24092935]
total_rewards_mean           1434.1010950285206
total_rewards_std            904.7150246337394
total_rewards_max            3135.856131915258
total_rewards_min            207.24092934734574
Number of train steps total  1388000
Number of env steps total    2190220
Number of rollouts total     0
Train Time (s)               150.17297364771366
(Previous) Eval Time (s)     19.678888389840722
Sample Time (s)              13.230647271033376
Epoch Time (s)               183.08250930858776
Total Train Time (s)         64205.379546939395
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:45:58.645150 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #346 | Epoch Duration: 183.18642473220825
2020-01-12 19:45:58.645363 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9629774
Z variance train             0.11042769
KL Divergence                16.247688
KL Loss                      1.6247689
QF Loss                      284.38034
VF Loss                      86.346825
Policy Loss                  -994.1537
Q Predictions Mean           989.77045
Q Predictions Std            306.99533
Q Predictions Max            1420.2627
Q Predictions Min            357.07422
V Predictions Mean           994.3401
V Predictions Std            309.8405
V Predictions Max            1402.8768
V Predictions Min            358.11548
Log Pis Mean                 -0.5468159
Log Pis Std                  2.9142544
Log Pis Max                  9.403638
Log Pis Min                  -9.4002
Policy mu Mean               -0.0003791079
Policy mu Std                0.6025455
Policy mu Max                2.8227155
Policy mu Min                -2.4429483
Policy log std Mean          -0.90842664
Policy log std Std           0.24319583
Policy log std Max           -0.2634915
Policy log std Min           -1.7564073
Z mean eval                  1.0917609
Z variance eval              0.076958224
total_rewards                [1275.52362084  948.34270639  237.62995414 1368.95362976 1929.04818874
  638.24594161 3301.87868651  746.34699133 1812.69394649 3140.94770214]
total_rewards_mean           1539.9611367954658
total_rewards_std            973.7272052694055
total_rewards_max            3301.8786865101097
total_rewards_min            237.6299541367234
Number of train steps total  1392000
Number of env steps total    2202336
Number of rollouts total     0
Train Time (s)               145.2760340468958
(Previous) Eval Time (s)     21.525639054365456
Sample Time (s)              11.038048027548939
Epoch Time (s)               177.8397211288102
Total Train Time (s)         64383.31633551838
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:48:56.586254 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #347 | Epoch Duration: 177.94073152542114
2020-01-12 19:48:56.586475 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0952985
Z variance train             0.078128755
KL Divergence                15.483388
KL Loss                      1.5483388
QF Loss                      349.57758
VF Loss                      89.21744
Policy Loss                  -1034.7076
Q Predictions Mean           1030.979
Q Predictions Std            301.94547
Q Predictions Max            1422.6189
Q Predictions Min            32.359303
V Predictions Mean           1033.5432
V Predictions Std            301.48093
V Predictions Max            1420.6041
V Predictions Min            32.923058
Log Pis Mean                 -0.35101166
Log Pis Std                  3.3310406
Log Pis Max                  25.842587
Log Pis Min                  -7.889675
Policy mu Mean               -0.0177194
Policy mu Std                0.62918055
Policy mu Max                5.6422563
Policy mu Min                -4.0816607
Policy log std Mean          -0.91000485
Policy log std Std           0.24365975
Policy log std Max           0.46032798
Policy log std Min           -2.2133894
Z mean eval                  1.0855954
Z variance eval              0.016899142
total_rewards                [1632.27411448  984.72714379 2565.2805585   940.0478812   829.21938529
 3305.70324358 3285.76230424  510.72133299  873.68343444  135.32808664]
total_rewards_mean           1506.2747485131736
total_rewards_std            1089.206586157265
total_rewards_max            3305.703243575743
total_rewards_min            135.32808663747085
Number of train steps total  1396000
Number of env steps total    2214524
Number of rollouts total     0
Train Time (s)               145.38460571598262
(Previous) Eval Time (s)     20.24320965912193
Sample Time (s)              12.161287159193307
Epoch Time (s)               177.78910253429785
Total Train Time (s)         64561.21632063016
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:51:54.490076 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #348 | Epoch Duration: 177.90343475341797
2020-01-12 19:51:54.490267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084738
Z variance train             0.016902268
KL Divergence                19.380936
KL Loss                      1.9380935
QF Loss                      456.81436
VF Loss                      47.740036
Policy Loss                  -1029.0703
Q Predictions Mean           1022.96814
Q Predictions Std            291.77557
Q Predictions Max            1412.7333
Q Predictions Min            342.65622
V Predictions Mean           1029.3115
V Predictions Std            293.1402
V Predictions Max            1407.517
V Predictions Min            337.0841
Log Pis Mean                 -0.38926563
Log Pis Std                  2.743925
Log Pis Max                  9.644721
Log Pis Min                  -6.7434444
Policy mu Mean               -0.017951475
Policy mu Std                0.60211515
Policy mu Max                2.2102237
Policy mu Min                -2.3830972
Policy log std Mean          -0.9127596
Policy log std Std           0.2264982
Policy log std Max           -0.28976333
Policy log std Min           -2.5512614
Z mean eval                  1.1763881
Z variance eval              0.09161936
total_rewards                [1264.2062266  3319.35494348 1066.9070861  1512.06242443 3189.72454117
 3372.28229094 1364.78905297 3103.10069055  157.70076249 2752.84309795]
total_rewards_mean           2110.2971116691283
total_rewards_std            1102.2226336057654
total_rewards_max            3372.282290941268
total_rewards_min            157.70076249111864
Number of train steps total  1400000
Number of env steps total    2226348
Number of rollouts total     0
Train Time (s)               154.08954999269918
(Previous) Eval Time (s)     32.755193187855184
Sample Time (s)              12.816460023168474
Epoch Time (s)               199.66120320372283
Total Train Time (s)         64760.96933440771
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:55:14.245629 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #349 | Epoch Duration: 199.75523495674133
2020-01-12 19:55:14.245757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1758776
Z variance train             0.09109914
KL Divergence                17.443558
KL Loss                      1.7443558
QF Loss                      985.4492
VF Loss                      471.70477
Policy Loss                  -1028.5352
Q Predictions Mean           1020.46515
Q Predictions Std            300.6303
Q Predictions Max            1398.1622
Q Predictions Min            13.746922
V Predictions Mean           1029.0696
V Predictions Std            295.49164
V Predictions Max            1382.2285
V Predictions Min            319.99692
Log Pis Mean                 -0.47933155
Log Pis Std                  2.9329607
Log Pis Max                  14.770815
Log Pis Min                  -10.590024
Policy mu Mean               0.014742364
Policy mu Std                0.6067743
Policy mu Max                2.870311
Policy mu Min                -3.8372474
Policy log std Mean          -0.90983266
Policy log std Std           0.2415599
Policy log std Max           -0.27709746
Policy log std Min           -2.0348654
Z mean eval                  1.0709194
Z variance eval              0.07584307
total_rewards                [1644.32888191 3276.97794271 3319.26313927  784.09253818 3149.69754886
 3155.06318815 3260.12409332 2002.53401731 1083.76329013 1142.04603571]
total_rewards_mean           2281.7890675555777
total_rewards_std            1000.0739621878738
total_rewards_max            3319.2631392686594
total_rewards_min            784.0925381823445
Number of train steps total  1404000
Number of env steps total    2235260
Number of rollouts total     0
Train Time (s)               153.73117669299245
(Previous) Eval Time (s)     33.825766512192786
Sample Time (s)              11.479712960775942
Epoch Time (s)               199.03665616596118
Total Train Time (s)         64960.104930278845
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:58:33.386071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #350 | Epoch Duration: 199.14019966125488
2020-01-12 19:58:33.386284 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0712731
Z variance train             0.07563148
KL Divergence                15.976104
KL Loss                      1.5976104
QF Loss                      899.2602
VF Loss                      102.55065
Policy Loss                  -1014.90015
Q Predictions Mean           1010.7063
Q Predictions Std            306.30518
Q Predictions Max            1408.5906
Q Predictions Min            327.65485
V Predictions Mean           1009.5465
V Predictions Std            307.1518
V Predictions Max            1393.7152
V Predictions Min            319.74026
Log Pis Mean                 -0.53363776
Log Pis Std                  2.6377501
Log Pis Max                  7.729777
Log Pis Min                  -9.694672
Policy mu Mean               0.025116205
Policy mu Std                0.600956
Policy mu Max                2.0335746
Policy mu Min                -2.1344097
Policy log std Mean          -0.8974859
Policy log std Std           0.22400358
Policy log std Max           -0.3506531
Policy log std Min           -2.0339777
Z mean eval                  1.0361954
Z variance eval              0.15775865
total_rewards                [1963.22690202 3139.1989416  2942.70216911 2492.58209162 3282.6246846
 2962.37651083  427.82540132 3154.24687729 3325.61163028  720.45202218]
total_rewards_mean           2441.084723085275
total_rewards_std            1012.654745262471
total_rewards_max            3325.6116302842556
total_rewards_min            427.8254013209564
Number of train steps total  1408000
Number of env steps total    2245227
Number of rollouts total     0
Train Time (s)               153.60434939758852
(Previous) Eval Time (s)     37.87001624703407
Sample Time (s)              11.679640252143145
Epoch Time (s)               203.15400589676574
Total Train Time (s)         65163.371794687584
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:01:56.658115 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #351 | Epoch Duration: 203.27164888381958
2020-01-12 20:01:56.658447 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0355089
Z variance train             0.1586582
KL Divergence                14.060594
KL Loss                      1.4060594
QF Loss                      1456.864
VF Loss                      85.81682
Policy Loss                  -1042.8867
Q Predictions Mean           1037.0806
Q Predictions Std            273.82587
Q Predictions Max            1414.2031
Q Predictions Min            332.52167
V Predictions Mean           1040.6604
V Predictions Std            274.18234
V Predictions Max            1397.7959
V Predictions Min            329.9715
Log Pis Mean                 -0.10865853
Log Pis Std                  2.9574733
Log Pis Max                  16.545254
Log Pis Min                  -7.2794404
Policy mu Mean               0.032665677
Policy mu Std                0.6252188
Policy mu Max                3.362601
Policy mu Min                -2.7011561
Policy log std Mean          -0.9459413
Policy log std Std           0.2322852
Policy log std Max           -0.31926644
Policy log std Min           -2.0926197
Z mean eval                  1.0993131
Z variance eval              0.045321066
total_rewards                [3050.80680473 1057.83861811 3325.40502211 2948.13380932 3355.59612074
 3340.78682345 3184.52114946 1099.98881719 2988.31451881  113.74993722]
total_rewards_mean           2446.514162112757
total_rewards_std            1141.7940161138476
total_rewards_max            3355.5961207356077
total_rewards_min            113.74993722381367
Number of train steps total  1412000
Number of env steps total    2256899
Number of rollouts total     0
Train Time (s)               153.47885007597506
(Previous) Eval Time (s)     28.65166571130976
Sample Time (s)              11.551151175517589
Epoch Time (s)               193.6816669628024
Total Train Time (s)         65357.14741420839
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:05:10.439940 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #352 | Epoch Duration: 193.78125619888306
2020-01-12 20:05:10.440291 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.101082
Z variance train             0.04573582
KL Divergence                18.337667
KL Loss                      1.8337668
QF Loss                      352.86954
VF Loss                      91.38078
Policy Loss                  -1060.6835
Q Predictions Mean           1055.7908
Q Predictions Std            303.4276
Q Predictions Max            1417.2762
Q Predictions Min            313.27075
V Predictions Mean           1056.945
V Predictions Std            302.69113
V Predictions Max            1413.0676
V Predictions Min            325.18594
Log Pis Mean                 -0.05240669
Log Pis Std                  2.7738209
Log Pis Max                  9.393957
Log Pis Min                  -7.9944873
Policy mu Mean               0.01668171
Policy mu Std                0.60667247
Policy mu Max                1.8820826
Policy mu Min                -2.1462715
Policy log std Mean          -0.947067
Policy log std Std           0.2352083
Policy log std Max           -0.33417183
Policy log std Min           -1.880583
Z mean eval                  1.0499687
Z variance eval              0.029456442
total_rewards                [ 418.6063488    66.4851779  3301.71672911 1185.79043802 3280.53517093
 3350.78768182 1677.05830203  158.51082781  503.19191159 2220.0869285 ]
total_rewards_mean           1616.2769516506028
total_rewards_std            1279.5663104811265
total_rewards_max            3350.7876818192485
total_rewards_min            66.48517789672225
Number of train steps total  1416000
Number of env steps total    2268154
Number of rollouts total     0
Train Time (s)               146.35124565195292
(Previous) Eval Time (s)     29.848437692970037
Sample Time (s)              13.115340325515717
Epoch Time (s)               189.31502367043868
Total Train Time (s)         65546.55140787037
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:08:19.846711 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #353 | Epoch Duration: 189.40620112419128
2020-01-12 20:08:19.846919 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0438089
Z variance train             0.029485738
KL Divergence                17.376032
KL Loss                      1.7376032
QF Loss                      435.51428
VF Loss                      44.112827
Policy Loss                  -1050.8031
Q Predictions Mean           1046.3125
Q Predictions Std            290.39966
Q Predictions Max            1390.6467
Q Predictions Min            324.2672
V Predictions Mean           1053.3325
V Predictions Std            291.0563
V Predictions Max            1375.3698
V Predictions Min            334.39868
Log Pis Mean                 -0.4104619
Log Pis Std                  2.6911914
Log Pis Max                  8.830757
Log Pis Min                  -8.354654
Policy mu Mean               0.022216685
Policy mu Std                0.59019405
Policy mu Max                2.4454825
Policy mu Min                -2.2531316
Policy log std Mean          -0.938203
Policy log std Std           0.22923344
Policy log std Max           -0.24612051
Policy log std Min           -1.7598096
Z mean eval                  1.157496
Z variance eval              0.046232186
total_rewards                [3308.8926552   232.21682056  941.426682    394.12875574  384.19257632
 3326.31701555 3192.14683936  899.3036128  2684.75331871 1602.51185717]
total_rewards_mean           1696.589013340378
total_rewards_std            1234.7735022069264
total_rewards_max            3326.31701554576
total_rewards_min            232.21682056475981
Number of train steps total  1420000
Number of env steps total    2279041
Number of rollouts total     0
Train Time (s)               145.17302241595462
(Previous) Eval Time (s)     21.630457068793476
Sample Time (s)              11.511615421622992
Epoch Time (s)               178.3150949063711
Total Train Time (s)         65724.95260160649
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:11:18.259065 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #354 | Epoch Duration: 178.4119644165039
2020-01-12 20:11:18.259551 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1571944
Z variance train             0.046351165
KL Divergence                17.706833
KL Loss                      1.7706833
QF Loss                      241.16965
VF Loss                      98.05525
Policy Loss                  -1072.1731
Q Predictions Mean           1068.6067
Q Predictions Std            280.0009
Q Predictions Max            1403.0085
Q Predictions Min            330.90005
V Predictions Mean           1076.8237
V Predictions Std            280.48166
V Predictions Max            1423.4392
V Predictions Min            330.8858
Log Pis Mean                 -0.50397384
Log Pis Std                  2.4970455
Log Pis Max                  11.031864
Log Pis Min                  -6.515819
Policy mu Mean               0.062710114
Policy mu Std                0.57573366
Policy mu Max                2.7229345
Policy mu Min                -2.0287335
Policy log std Mean          -0.93789244
Policy log std Std           0.23421432
Policy log std Max           -0.25823098
Policy log std Min           -2.2747386
Z mean eval                  1.0576669
Z variance eval              0.046049222
total_rewards                [ 656.46841317  228.19339147 2609.37862271 3169.81755812  535.47949785
 2303.7006628   657.35045188   76.74998858 2406.33475776   85.98533827]
total_rewards_mean           1272.945868261154
total_rewards_std            1138.653897070583
total_rewards_max            3169.817558122019
total_rewards_min            76.74998858487876
Number of train steps total  1424000
Number of env steps total    2289256
Number of rollouts total     0
Train Time (s)               149.58068259386346
(Previous) Eval Time (s)     19.415047908201814
Sample Time (s)              10.267850821372122
Epoch Time (s)               179.2635813234374
Total Train Time (s)         65904.31124379346
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:14:17.614355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #355 | Epoch Duration: 179.3544056415558
2020-01-12 20:14:17.614601 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0571059
Z variance train             0.045933675
KL Divergence                17.31347
KL Loss                      1.7313471
QF Loss                      11732.465
VF Loss                      65.45181
Policy Loss                  -1000.12634
Q Predictions Mean           995.68835
Q Predictions Std            314.32007
Q Predictions Max            1431.874
Q Predictions Min            295.68207
V Predictions Mean           1001.02576
V Predictions Std            311.0235
V Predictions Max            1422.2272
V Predictions Min            322.67365
Log Pis Mean                 -0.48202324
Log Pis Std                  2.697547
Log Pis Max                  11.939366
Log Pis Min                  -6.454962
Policy mu Mean               0.012985727
Policy mu Std                0.5975619
Policy mu Max                2.9119627
Policy mu Min                -2.1816566
Policy log std Mean          -0.8945868
Policy log std Std           0.23583485
Policy log std Max           -0.30471712
Policy log std Min           -2.03328
Z mean eval                  1.0606873
Z variance eval              0.059031866
total_rewards                [  80.04838297  303.26132271 3002.13823106 2119.32790008  438.85366062
 2023.37655796 3254.9911004  3347.11282718 3040.58041315  743.40835357]
total_rewards_mean           1835.309874970096
total_rewards_std            1257.0480623111769
total_rewards_max            3347.1128271826583
total_rewards_min            80.04838297325858
Number of train steps total  1428000
Number of env steps total    2299647
Number of rollouts total     0
Train Time (s)               156.34567295014858
(Previous) Eval Time (s)     24.41188055742532
Sample Time (s)              11.504998039919883
Epoch Time (s)               192.26255154749379
Total Train Time (s)         66096.66621657228
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:17:29.979262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #356 | Epoch Duration: 192.36444568634033
2020-01-12 20:17:29.979672 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #356 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0633239
Z variance train             0.05787327
KL Divergence                15.184028
KL Loss                      1.5184028
QF Loss                      342.26984
VF Loss                      589.16614
Policy Loss                  -1011.12964
Q Predictions Mean           1005.5973
Q Predictions Std            312.8895
Q Predictions Max            1389.5295
Q Predictions Min            48.37918
V Predictions Mean           1009.23505
V Predictions Std            312.70425
V Predictions Max            1383.0497
V Predictions Min            315.69388
Log Pis Mean                 -0.59622675
Log Pis Std                  2.5424192
Log Pis Max                  9.92817
Log Pis Min                  -6.4731894
Policy mu Mean               0.033670828
Policy mu Std                0.6173479
Policy mu Max                2.646952
Policy mu Min                -2.5266564
Policy log std Mean          -0.88759893
Policy log std Std           0.22645675
Policy log std Max           -0.3059684
Policy log std Min           -2.4815345
Z mean eval                  1.0217448
Z variance eval              0.097186185
total_rewards                [1.36170243e+00 3.45864121e+03 3.22994689e+03 5.41987588e+02
 1.13467556e+03 2.76967217e+03 5.64521316e+02 1.12168827e+02
 1.45740717e+03 3.92592306e+02]
total_rewards_mean           1366.29747411392
total_rewards_std            1248.5521046285671
total_rewards_max            3458.641211390782
total_rewards_min            1.361702431042903
Number of train steps total  1432000
Number of env steps total    2308255
Number of rollouts total     0
Train Time (s)               154.88049503182992
(Previous) Eval Time (s)     17.188914836850017
Sample Time (s)              13.173360304441303
Epoch Time (s)               185.24277017312124
Total Train Time (s)         66282.0133956573
Epoch                        357
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:20:35.324731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #357 | Epoch Duration: 185.3447449207306
2020-01-12 20:20:35.324930 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0144508
Z variance train             0.09472039
KL Divergence                14.854185
KL Loss                      1.4854186
QF Loss                      475.496
VF Loss                      204.3403
Policy Loss                  -1035.8223
Q Predictions Mean           1032.9573
Q Predictions Std            259.4449
Q Predictions Max            1393.1697
Q Predictions Min            -17.584362
V Predictions Mean           1035.8723
V Predictions Std            257.8683
V Predictions Max            1389.1919
V Predictions Min            31.609268
Log Pis Mean                 -0.22861154
Log Pis Std                  2.6030788
Log Pis Max                  8.191493
Log Pis Min                  -7.9484606
Policy mu Mean               0.014690239
Policy mu Std                0.61000335
Policy mu Max                2.0544205
Policy mu Min                -2.5454783
Policy log std Mean          -0.9648065
Policy log std Std           0.24351247
Policy log std Max           -0.4196269
Policy log std Min           -2.4200344
Z mean eval                  1.2042153
Z variance eval              0.049000204
total_rewards                [ 969.66222243  161.54497266 3520.4745356  1955.65684265 2815.72781293
  441.08867936 3572.82668966 1547.66097314  519.9232861  1407.50462949]
total_rewards_mean           1691.2070644020328
total_rewards_std            1188.1700125047214
total_rewards_max            3572.826689659154
total_rewards_min            161.54497265902097
Number of train steps total  1436000
Number of env steps total    2319500
Number of rollouts total     0
Train Time (s)               155.42966494895518
(Previous) Eval Time (s)     23.863879788201302
Sample Time (s)              12.413471192587167
Epoch Time (s)               191.70701592974365
Total Train Time (s)         66473.81699536834
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:23:47.131879 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #358 | Epoch Duration: 191.8067910671234
2020-01-12 20:23:47.132075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2079194
Z variance train             0.047820795
KL Divergence                18.632877
KL Loss                      1.8632878
QF Loss                      735.35846
VF Loss                      103.053024
Policy Loss                  -1055.0037
Q Predictions Mean           1046.1038
Q Predictions Std            269.04706
Q Predictions Max            1355.8623
Q Predictions Min            19.208729
V Predictions Mean           1053.5016
V Predictions Std            263.58994
V Predictions Max            1366.2017
V Predictions Min            231.05046
Log Pis Mean                 -0.42239153
Log Pis Std                  2.881264
Log Pis Max                  12.266588
Log Pis Min                  -7.5448055
Policy mu Mean               -0.022872385
Policy mu Std                0.6100786
Policy mu Max                2.5033731
Policy mu Min                -2.7031322
Policy log std Mean          -0.97242117
Policy log std Std           0.23557901
Policy log std Max           -0.13299698
Policy log std Min           -1.9648559
Z mean eval                  1.0582718
Z variance eval              0.06587453
total_rewards                [3426.968673   1848.63711143 2374.14294768 2014.50831608 3290.24650581
 3200.86177436 3338.24283383 1277.54371119 3070.14780115 1330.25244603]
total_rewards_mean           2517.1552120555834
total_rewards_std            808.5956184332674
total_rewards_max            3426.9686729963546
total_rewards_min            1277.5437111857589
Number of train steps total  1440000
Number of env steps total    2330082
Number of rollouts total     0
Train Time (s)               153.58251582505181
(Previous) Eval Time (s)     29.65009194985032
Sample Time (s)              12.535317606758326
Epoch Time (s)               195.76792538166046
Total Train Time (s)         66669.67903835559
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:27:02.999243 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #359 | Epoch Duration: 195.86697816848755
2020-01-12 20:27:02.999549 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0615808
Z variance train             0.06419109
KL Divergence                17.239233
KL Loss                      1.7239233
QF Loss                      346.08524
VF Loss                      98.73128
Policy Loss                  -1073.7697
Q Predictions Mean           1068.8848
Q Predictions Std            286.44995
Q Predictions Max            1391.7527
Q Predictions Min            309.71494
V Predictions Mean           1071.0413
V Predictions Std            283.89825
V Predictions Max            1391.8184
V Predictions Min            330.1097
Log Pis Mean                 -0.33025783
Log Pis Std                  2.7879066
Log Pis Max                  12.652011
Log Pis Min                  -7.308745
Policy mu Mean               0.09746951
Policy mu Std                0.56302017
Policy mu Max                2.68267
Policy mu Min                -2.2240784
Policy log std Mean          -0.9519789
Policy log std Std           0.24170803
Policy log std Max           -0.28308308
Policy log std Min           -2.4054446
Z mean eval                  1.0666244
Z variance eval              0.025343072
total_rewards                [ 112.09262537  112.54239322  291.23617705  447.28960845 3193.12960408
 1475.22289334  658.5719486  3339.61672525 2648.60690807 3275.72974075]
total_rewards_mean           1555.40386241652
total_rewards_std            1334.9885888574813
total_rewards_max            3339.6167252523064
total_rewards_min            112.09262536511864
Number of train steps total  1444000
Number of env steps total    2340117
Number of rollouts total     0
Train Time (s)               145.43063986394554
(Previous) Eval Time (s)     24.917540574911982
Sample Time (s)              11.500901526305825
Epoch Time (s)               181.84908196516335
Total Train Time (s)         66851.62198818475
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:30:04.945834 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #360 | Epoch Duration: 181.94608306884766
2020-01-12 20:30:04.946043 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0695193
Z variance train             0.025366306
KL Divergence                19.107609
KL Loss                      1.9107609
QF Loss                      311.40442
VF Loss                      123.55563
Policy Loss                  -1038.5826
Q Predictions Mean           1033.8264
Q Predictions Std            300.05353
Q Predictions Max            1373.3385
Q Predictions Min            332.5037
V Predictions Mean           1037.395
V Predictions Std            299.11276
V Predictions Max            1365.5734
V Predictions Min            330.0475
Log Pis Mean                 -0.15025742
Log Pis Std                  3.0102754
Log Pis Max                  15.302868
Log Pis Min                  -7.302169
Policy mu Mean               0.022055201
Policy mu Std                0.5882564
Policy mu Max                3.4799101
Policy mu Min                -2.1960943
Policy log std Mean          -0.9431008
Policy log std Std           0.26522818
Policy log std Max           -0.10391021
Policy log std Min           -2.3029234
Z mean eval                  1.0709336
Z variance eval              0.023698095
total_rewards                [ 245.73747768  133.66200545  414.67038249  366.32569255 2159.32540005
  259.73896527  341.00867194  316.24865355 3546.74141946  386.09746455]
total_rewards_mean           816.9556132981068
total_rewards_std            1067.0112616568704
total_rewards_max            3546.741419464747
total_rewards_min            133.66200544857864
Number of train steps total  1448000
Number of env steps total    2350007
Number of rollouts total     0
Train Time (s)               144.7054669102654
(Previous) Eval Time (s)     18.615443627815694
Sample Time (s)              11.273317295126617
Epoch Time (s)               174.5942278332077
Total Train Time (s)         67026.56213308731
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:32:59.890178 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #361 | Epoch Duration: 174.94398641586304
2020-01-12 20:32:59.890377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0702112
Z variance train             0.023779135
KL Divergence                17.477615
KL Loss                      1.7477616
QF Loss                      246.12006
VF Loss                      72.372795
Policy Loss                  -1103.3092
Q Predictions Mean           1100.4485
Q Predictions Std            278.53156
Q Predictions Max            1417.9324
Q Predictions Min            320.20752
V Predictions Mean           1102.8945
V Predictions Std            277.103
V Predictions Max            1420.1539
V Predictions Min            322.95648
Log Pis Mean                 -0.40532282
Log Pis Std                  2.612609
Log Pis Max                  8.898451
Log Pis Min                  -11.165732
Policy mu Mean               -0.001887109
Policy mu Std                0.6084495
Policy mu Max                2.370725
Policy mu Min                -2.5927713
Policy log std Mean          -0.9435464
Policy log std Std           0.2223325
Policy log std Max           -0.26473993
Policy log std Min           -2.32888
Z mean eval                  1.078936
Z variance eval              0.09622575
total_rewards                [3344.01114574 1004.61917688 1831.82947164  978.19820988 1821.11946086
 3416.03280073 1675.29917426 2894.09123013  919.91781369 1241.316015  ]
total_rewards_mean           1912.6434498799827
total_rewards_std            920.7254374492402
total_rewards_max            3416.032800731266
total_rewards_min            919.9178136886565
Number of train steps total  1452000
Number of env steps total    2359116
Number of rollouts total     0
Train Time (s)               151.10973591031507
(Previous) Eval Time (s)     32.22817890532315
Sample Time (s)              11.349347701761872
Epoch Time (s)               194.6872625174001
Total Train Time (s)         67221.34712000843
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:36:14.679475 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #362 | Epoch Duration: 194.78894567489624
2020-01-12 20:36:14.679689 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0846837
Z variance train             0.09641611
KL Divergence                14.296548
KL Loss                      1.4296548
QF Loss                      404.41055
VF Loss                      168.30109
Policy Loss                  -1062.4438
Q Predictions Mean           1055.9056
Q Predictions Std            330.577
Q Predictions Max            1428.6451
Q Predictions Min            260.3527
V Predictions Mean           1059.4286
V Predictions Std            331.09607
V Predictions Max            1439.7661
V Predictions Min            219.09085
Log Pis Mean                 -0.58437145
Log Pis Std                  2.7850502
Log Pis Max                  8.356637
Log Pis Min                  -8.408097
Policy mu Mean               0.009269192
Policy mu Std                0.58677334
Policy mu Max                2.1987407
Policy mu Min                -2.2897112
Policy log std Mean          -0.92224085
Policy log std Std           0.22255209
Policy log std Max           -0.37174487
Policy log std Min           -1.9962893
Z mean eval                  1.0889356
Z variance eval              0.01200044
total_rewards                [2792.31732467 1767.95467236  512.53437519  876.61295728 2399.99111658
 3176.89343363  758.40662301  977.67820283 2415.4133921   483.97094953]
total_rewards_mean           1616.177304717989
total_rewards_std            963.6205156630107
total_rewards_max            3176.8934336252423
total_rewards_min            483.97094953241054
Number of train steps total  1456000
Number of env steps total    2368391
Number of rollouts total     0
Train Time (s)               155.2725290870294
(Previous) Eval Time (s)     19.178215401712805
Sample Time (s)              13.479633943643421
Epoch Time (s)               187.93037843238562
Total Train Time (s)         67409.37296712864
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:39:22.709798 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #363 | Epoch Duration: 188.0299482345581
2020-01-12 20:39:22.710034 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.086252
Z variance train             0.012047365
KL Divergence                20.295341
KL Loss                      2.029534
QF Loss                      317.6663
VF Loss                      198.42386
Policy Loss                  -1049.1694
Q Predictions Mean           1044.993
Q Predictions Std            304.2641
Q Predictions Max            1412.1993
Q Predictions Min            286.4904
V Predictions Mean           1051.1921
V Predictions Std            307.4681
V Predictions Max            1433.4064
V Predictions Min            308.85553
Log Pis Mean                 -0.17903261
Log Pis Std                  2.8363168
Log Pis Max                  9.260995
Log Pis Min                  -7.280485
Policy mu Mean               0.029456113
Policy mu Std                0.60848117
Policy mu Max                2.2413917
Policy mu Min                -2.4389975
Policy log std Mean          -0.94850934
Policy log std Std           0.24098217
Policy log std Max           -0.09711802
Policy log std Min           -2.0185313
Z mean eval                  1.1252847
Z variance eval              0.04688065
total_rewards                [3268.40323486  503.11086495 3517.66093533 3533.06232534 3216.99816603
  855.21763749  141.27623276 3302.64045074 3393.23925572 3317.03139184]
total_rewards_mean           2504.8640495061877
total_rewards_std            1325.6412132715259
total_rewards_max            3533.06232533929
total_rewards_min            141.27623275762096
Number of train steps total  1460000
Number of env steps total    2379231
Number of rollouts total     0
Train Time (s)               153.6303052417934
(Previous) Eval Time (s)     29.79254601476714
Sample Time (s)              13.025388181209564
Epoch Time (s)               196.4482394377701
Total Train Time (s)         67605.90842458745
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:42:39.248731 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #364 | Epoch Duration: 196.53854656219482
2020-01-12 20:42:39.248922 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1260276
Z variance train             0.046744645
KL Divergence                16.214905
KL Loss                      1.6214905
QF Loss                      10707.1875
VF Loss                      129.14497
Policy Loss                  -1056.864
Q Predictions Mean           1052.5225
Q Predictions Std            295.63083
Q Predictions Max            1424.2579
Q Predictions Min            -44.508083
V Predictions Mean           1055.3799
V Predictions Std            294.12384
V Predictions Max            1415.2417
V Predictions Min            6.667878
Log Pis Mean                 -0.34254384
Log Pis Std                  2.6011457
Log Pis Max                  12.271285
Log Pis Min                  -7.406988
Policy mu Mean               0.013249055
Policy mu Std                0.5772961
Policy mu Max                2.2191825
Policy mu Min                -2.4051452
Policy log std Mean          -0.9680312
Policy log std Std           0.23118934
Policy log std Max           -0.20244253
Policy log std Min           -2.0426772
Z mean eval                  1.216258
Z variance eval              0.008883098
total_rewards                [1528.73063963  218.840984   3234.98388834 2186.82703707 3495.39231473
 1815.84576939  169.77367311 1159.34642602  562.85652108 1852.65206457]
total_rewards_mean           1622.5249317931516
total_rewards_std            1092.8617530667607
total_rewards_max            3495.3923147300093
total_rewards_min            169.77367310847404
Number of train steps total  1464000
Number of env steps total    2389984
Number of rollouts total     0
Train Time (s)               155.40376405837014
(Previous) Eval Time (s)     19.19995762826875
Sample Time (s)              11.499421161133796
Epoch Time (s)               186.1031428477727
Total Train Time (s)         67792.10999729345
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:45:45.455485 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #365 | Epoch Duration: 186.20639514923096
2020-01-12 20:45:45.455788 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.215242
Z variance train             0.008869898
KL Divergence                19.444979
KL Loss                      1.944498
QF Loss                      431.01025
VF Loss                      178.60797
Policy Loss                  -1076.1721
Q Predictions Mean           1072.5513
Q Predictions Std            284.88318
Q Predictions Max            1431.6729
Q Predictions Min            320.97763
V Predictions Mean           1086.5927
V Predictions Std            284.4308
V Predictions Max            1433.1866
V Predictions Min            331.5056
Log Pis Mean                 -0.18312716
Log Pis Std                  2.7864797
Log Pis Max                  9.758419
Log Pis Min                  -7.009043
Policy mu Mean               0.044579577
Policy mu Std                0.59825397
Policy mu Max                1.8836306
Policy mu Min                -2.4167674
Policy log std Mean          -0.9605945
Policy log std Std           0.22387245
Policy log std Max           -0.40304124
Policy log std Min           -1.9535542
Z mean eval                  1.0335815
Z variance eval              0.041554116
total_rewards                [ 785.86407833  567.48853383 3221.22583858 2993.22870616  139.64849513
 3593.48122413  826.26471856 1435.65226311  927.12433204  635.72807531]
total_rewards_mean           1512.5706265169933
total_rewards_std            1197.3625225029186
total_rewards_max            3593.4812241261607
total_rewards_min            139.64849513247285
Number of train steps total  1468000
Number of env steps total    2399931
Number of rollouts total     0
Train Time (s)               152.5060122050345
(Previous) Eval Time (s)     18.04951490694657
Sample Time (s)              11.972153502050787
Epoch Time (s)               182.52768061403185
Total Train Time (s)         67974.72643436026
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:48:48.075493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #366 | Epoch Duration: 182.61952710151672
2020-01-12 20:48:48.075693 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0323234
Z variance train             0.04353111
KL Divergence                16.6077
KL Loss                      1.66077
QF Loss                      455.62674
VF Loss                      91.93873
Policy Loss                  -1061.7267
Q Predictions Mean           1056.6893
Q Predictions Std            295.21484
Q Predictions Max            1439.8215
Q Predictions Min            -26.146187
V Predictions Mean           1060.9414
V Predictions Std            290.90338
V Predictions Max            1439.4503
V Predictions Min            92.00031
Log Pis Mean                 -0.014263719
Log Pis Std                  2.96922
Log Pis Max                  20.95632
Log Pis Min                  -7.8966584
Policy mu Mean               -0.037482455
Policy mu Std                0.6163016
Policy mu Max                2.7445478
Policy mu Min                -2.8961017
Policy log std Mean          -0.96342087
Policy log std Std           0.25548574
Policy log std Max           -0.17348158
Policy log std Min           -2.8067813
Z mean eval                  0.9325348
Z variance eval              0.052246798
total_rewards                [ 410.03256233 1299.72627272 2208.84733189  116.96855257 1526.1279458
 2442.14580606 1031.76392549 2107.20473229 3301.4776712  2571.87563503]
total_rewards_mean           1701.6170435389613
total_rewards_std            954.3263570533054
total_rewards_max            3301.477671197525
total_rewards_min            116.96855257457725
Number of train steps total  1472000
Number of env steps total    2408965
Number of rollouts total     0
Train Time (s)               144.88928426988423
(Previous) Eval Time (s)     21.328761484008282
Sample Time (s)              13.067757778335363
Epoch Time (s)               179.28580353222787
Total Train Time (s)         68154.09912722139
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:51:47.452267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #367 | Epoch Duration: 179.37642550468445
2020-01-12 20:51:47.452506 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94031125
Z variance train             0.052098304
KL Divergence                16.178268
KL Loss                      1.6178268
QF Loss                      1185.4725
VF Loss                      78.31975
Policy Loss                  -1067.5912
Q Predictions Mean           1061.9543
Q Predictions Std            314.17358
Q Predictions Max            1440.6615
Q Predictions Min            232.62985
V Predictions Mean           1067.9243
V Predictions Std            314.07693
V Predictions Max            1450.6819
V Predictions Min            312.22366
Log Pis Mean                 -0.3490817
Log Pis Std                  2.770562
Log Pis Max                  8.651562
Log Pis Min                  -6.8380384
Policy mu Mean               0.008284202
Policy mu Std                0.5876867
Policy mu Max                2.2850802
Policy mu Min                -3.0795293
Policy log std Mean          -0.9507227
Policy log std Std           0.23636705
Policy log std Max           -0.3235522
Policy log std Min           -2.1059113
Z mean eval                  1.0127599
Z variance eval              0.021298736
total_rewards                [1730.82325822  469.95888686  361.44507587  631.67460707  356.14179905
  141.06623937 1040.79901404 1065.03879594  959.02648041  942.17386309]
total_rewards_mean           769.8148019915809
total_rewards_std            446.3012248236655
total_rewards_max            1730.8232582205237
total_rewards_min            141.0662393691383
Number of train steps total  1476000
Number of env steps total    2420965
Number of rollouts total     0
Train Time (s)               145.9239089912735
(Previous) Eval Time (s)     8.393153077922761
Sample Time (s)              10.917748831678182
Epoch Time (s)               165.23481090087444
Total Train Time (s)         68319.42352980562
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:54:32.780287 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #368 | Epoch Duration: 165.32763671875
2020-01-12 20:54:32.780472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0114841
Z variance train             0.021356981
KL Divergence                17.623222
KL Loss                      1.7623223
QF Loss                      1249.7455
VF Loss                      80.2191
Policy Loss                  -1019.41266
Q Predictions Mean           1012.27264
Q Predictions Std            324.86786
Q Predictions Max            1406.7593
Q Predictions Min            314.57712
V Predictions Mean           1018.5963
V Predictions Std            324.26093
V Predictions Max            1396.5123
V Predictions Min            312.85318
Log Pis Mean                 -0.7026214
Log Pis Std                  2.8760955
Log Pis Max                  13.538151
Log Pis Min                  -6.945898
Policy mu Mean               0.014390072
Policy mu Std                0.58104897
Policy mu Max                2.9272997
Policy mu Min                -2.3232138
Policy log std Mean          -0.9239389
Policy log std Std           0.24930981
Policy log std Max           -0.25041378
Policy log std Min           -2.006406
Z mean eval                  1.1760724
Z variance eval              0.055644434
total_rewards                [ 709.79468876  279.52259289 1899.56350471  307.06371778 2101.24449847
  213.28856564 1208.44425461 2905.58820307 1787.27212204  967.89364927]
total_rewards_mean           1237.967579724744
total_rewards_std            863.3420099979353
total_rewards_max            2905.5882030685652
total_rewards_min            213.28856564154515
Number of train steps total  1480000
Number of env steps total    2432872
Number of rollouts total     0
Train Time (s)               153.97015423700213
(Previous) Eval Time (s)     15.592668309807777
Sample Time (s)              12.012938977219164
Epoch Time (s)               181.57576152402908
Total Train Time (s)         68501.09329182142
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:57:34.452854 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #369 | Epoch Duration: 181.67223572731018
2020-01-12 20:57:34.453056 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1741259
Z variance train             0.05645076
KL Divergence                16.167316
KL Loss                      1.6167316
QF Loss                      1080.9419
VF Loss                      72.72158
Policy Loss                  -985.2387
Q Predictions Mean           979.64624
Q Predictions Std            307.89667
Q Predictions Max            1323.198
Q Predictions Min            268.68643
V Predictions Mean           984.3386
V Predictions Std            306.43863
V Predictions Max            1317.7504
V Predictions Min            289.204
Log Pis Mean                 -0.2514834
Log Pis Std                  2.972864
Log Pis Max                  10.766664
Log Pis Min                  -7.7925053
Policy mu Mean               0.0067767594
Policy mu Std                0.6105659
Policy mu Max                2.0373285
Policy mu Min                -2.766641
Policy log std Mean          -0.9182256
Policy log std Std           0.25766677
Policy log std Max           -0.22970808
Policy log std Min           -2.4401143
Z mean eval                  1.1683524
Z variance eval              0.048632655
total_rewards                [1397.99740386  933.93568087 3410.26438045  149.01877475 1858.79576904
 3405.85540113 1398.58372199  485.82759658  288.31736942  104.39540797]
total_rewards_mean           1343.2991506075527
total_rewards_std            1173.6813523659346
total_rewards_max            3410.264380448276
total_rewards_min            104.39540797419542
Number of train steps total  1484000
Number of env steps total    2444184
Number of rollouts total     0
Train Time (s)               155.07484502438456
(Previous) Eval Time (s)     16.24991381773725
Sample Time (s)              13.165771923493594
Epoch Time (s)               184.4905307656154
Total Train Time (s)         68685.67039423576
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:00:39.036740 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #370 | Epoch Duration: 184.58351230621338
2020-01-12 21:00:39.037015 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1608074
Z variance train             0.048558533
KL Divergence                16.436768
KL Loss                      1.6436768
QF Loss                      327.82208
VF Loss                      63.462006
Policy Loss                  -1052.0377
Q Predictions Mean           1044.0862
Q Predictions Std            305.85355
Q Predictions Max            1383.7948
Q Predictions Min            -2.311279
V Predictions Mean           1049.9397
V Predictions Std            298.84708
V Predictions Max            1376.9695
V Predictions Min            285.96652
Log Pis Mean                 -0.19375494
Log Pis Std                  2.6971085
Log Pis Max                  10.806915
Log Pis Min                  -5.989669
Policy mu Mean               0.0061415955
Policy mu Std                0.6105855
Policy mu Max                2.2833648
Policy mu Min                -2.5933518
Policy log std Mean          -0.94645655
Policy log std Std           0.24535586
Policy log std Max           -0.24960268
Policy log std Min           -2.071781
Z mean eval                  0.9330282
Z variance eval              0.023826001
total_rewards                [ 218.7701708   418.19868307   77.79316029  461.43351796  575.66218244
 2034.22942296 1559.63216688  823.48906636 1948.48398102 3159.05311407]
total_rewards_mean           1127.6745465844635
total_rewards_std            952.968719161931
total_rewards_max            3159.053114070735
total_rewards_min            77.79316028664803
Number of train steps total  1488000
Number of env steps total    2456099
Number of rollouts total     0
Train Time (s)               153.6992734260857
(Previous) Eval Time (s)     20.179374222178012
Sample Time (s)              12.835717947687954
Epoch Time (s)               186.71436559595168
Total Train Time (s)         68872.47717687255
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:03:45.847379 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #371 | Epoch Duration: 186.81018805503845
2020-01-12 21:03:45.847584 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93265486
Z variance train             0.023841321
KL Divergence                16.78074
KL Loss                      1.6780741
QF Loss                      1504.2258
VF Loss                      285.7618
Policy Loss                  -1032.1719
Q Predictions Mean           1026.3835
Q Predictions Std            303.8583
Q Predictions Max            1437.1991
Q Predictions Min            310.45703
V Predictions Mean           1030.1282
V Predictions Std            302.1932
V Predictions Max            1425.7748
V Predictions Min            308.3984
Log Pis Mean                 -0.15395032
Log Pis Std                  3.1491466
Log Pis Max                  22.483292
Log Pis Min                  -8.732092
Policy mu Mean               -0.014229126
Policy mu Std                0.63566864
Policy mu Max                4.55394
Policy mu Min                -2.648468
Policy log std Mean          -0.96051586
Policy log std Std           0.2454275
Policy log std Max           -0.017548323
Policy log std Min           -2.255004
Z mean eval                  0.9700743
Z variance eval              0.084943786
total_rewards                [ 622.59928002  124.74292702  525.44728639 1880.0855034   356.6977658
  407.7886551  3136.61581746  785.86411427 1568.26781498  103.7018473 ]
total_rewards_mean           951.1811011751921
total_rewards_std            915.7639558492695
total_rewards_max            3136.615817463938
total_rewards_min            103.70184730478913
Number of train steps total  1492000
Number of env steps total    2465804
Number of rollouts total     0
Train Time (s)               155.86303772823885
(Previous) Eval Time (s)     15.195344486739486
Sample Time (s)              13.258479215204716
Epoch Time (s)               184.31686143018305
Total Train Time (s)         69056.88708968088
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:06:50.262327 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #372 | Epoch Duration: 184.41457724571228
2020-01-12 21:06:50.262580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96811104
Z variance train             0.083903834
KL Divergence                14.363126
KL Loss                      1.4363126
QF Loss                      774.5725
VF Loss                      180.49718
Policy Loss                  -1032.8114
Q Predictions Mean           1027.8801
Q Predictions Std            295.92307
Q Predictions Max            1395.6221
Q Predictions Min            301.76822
V Predictions Mean           1031.8348
V Predictions Std            298.21964
V Predictions Max            1386.9578
V Predictions Min            301.82358
Log Pis Mean                 -0.050640106
Log Pis Std                  2.981002
Log Pis Max                  14.893117
Log Pis Min                  -8.11429
Policy mu Mean               0.0012219318
Policy mu Std                0.62205416
Policy mu Max                2.1510384
Policy mu Min                -2.5042555
Policy log std Mean          -0.94940186
Policy log std Std           0.2715416
Policy log std Max           -0.34202588
Policy log std Min           -2.8776307
Z mean eval                  0.9471485
Z variance eval              0.0548221
total_rewards                [1277.81305908 3819.87975241  738.83346087  601.45968206 3415.06232155
  426.58011088 3031.30505039 2772.10964909 3471.53572583  696.85343956]
total_rewards_mean           2025.1432251713493
total_rewards_std            1318.144674245603
total_rewards_max            3819.879752410062
total_rewards_min            426.5801108798653
Number of train steps total  1496000
Number of env steps total    2474964
Number of rollouts total     0
Train Time (s)               153.64394230488688
(Previous) Eval Time (s)     23.20480819698423
Sample Time (s)              12.133730148430914
Epoch Time (s)               188.98248065030202
Total Train Time (s)         69245.95609867852
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:09:59.335796 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #373 | Epoch Duration: 189.07303094863892
2020-01-12 21:09:59.336017 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94739044
Z variance train             0.05471257
KL Divergence                15.759472
KL Loss                      1.5759472
QF Loss                      303.67645
VF Loss                      66.45312
Policy Loss                  -1060.8226
Q Predictions Mean           1055.2356
Q Predictions Std            273.21365
Q Predictions Max            1412.1158
Q Predictions Min            310.28363
V Predictions Mean           1061.791
V Predictions Std            272.01108
V Predictions Max            1403.7358
V Predictions Min            297.67108
Log Pis Mean                 -0.31309518
Log Pis Std                  2.8903146
Log Pis Max                  10.710152
Log Pis Min                  -10.27043
Policy mu Mean               -0.007784988
Policy mu Std                0.6189663
Policy mu Max                2.9672666
Policy mu Min                -2.630437
Policy log std Mean          -0.9441849
Policy log std Std           0.22825977
Policy log std Max           -0.27132636
Policy log std Min           -1.918678
Z mean eval                  0.9507812
Z variance eval              0.04392739
total_rewards                [2409.4694742  2287.02246138 3297.12664799  665.44845895 1201.02109937
  268.19682659  691.39104567 2171.01192516  152.77283226 1836.25930733]
total_rewards_mean           1497.9720078901566
total_rewards_std            1000.5779661936087
total_rewards_max            3297.1266479902833
total_rewards_min            152.77283225835197
Number of train steps total  1500000
Number of env steps total    2484838
Number of rollouts total     0
Train Time (s)               145.69913306599483
(Previous) Eval Time (s)     21.412858366966248
Sample Time (s)              11.56056691519916
Epoch Time (s)               178.67255834816024
Total Train Time (s)         69424.72222126974
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:12:58.106487 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #374 | Epoch Duration: 178.77029585838318
2020-01-12 21:12:58.106754 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95647687
Z variance train             0.04397904
KL Divergence                17.600866
KL Loss                      1.7600867
QF Loss                      348.4789
VF Loss                      101.37673
Policy Loss                  -1064.6984
Q Predictions Mean           1060.0703
Q Predictions Std            308.153
Q Predictions Max            1404.6221
Q Predictions Min            328.1983
V Predictions Mean           1059.4451
V Predictions Std            306.70084
V Predictions Max            1409.3064
V Predictions Min            328.73914
Log Pis Mean                 -0.51594734
Log Pis Std                  2.6693847
Log Pis Max                  7.153879
Log Pis Min                  -7.0077305
Policy mu Mean               -0.008378159
Policy mu Std                0.61005807
Policy mu Max                2.3905673
Policy mu Min                -2.191318
Policy log std Mean          -0.9365799
Policy log std Std           0.2354747
Policy log std Max           -0.3400604
Policy log std Min           -2.0519996
Z mean eval                  0.95018417
Z variance eval              0.056026768
total_rewards                [ 494.11613923 1929.70837732  813.06533349  441.03419674  939.11717936
 1814.6465707  2991.06591854  713.66617828   74.91829581 3481.73272939]
total_rewards_mean           1369.3070918861617
total_rewards_std            1087.7612792810733
total_rewards_max            3481.7327293907756
total_rewards_min            74.91829580695749
Number of train steps total  1504000
Number of env steps total    2495139
Number of rollouts total     0
Train Time (s)               145.5478665935807
(Previous) Eval Time (s)     18.5865174732171
Sample Time (s)              11.421552136540413
Epoch Time (s)               175.5559362033382
Total Train Time (s)         69600.37816705229
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:15:53.766433 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #375 | Epoch Duration: 175.65949845314026
2020-01-12 21:15:53.766644 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9484021
Z variance train             0.055975348
KL Divergence                16.017515
KL Loss                      1.6017516
QF Loss                      636.8272
VF Loss                      223.92484
Policy Loss                  -1065.5212
Q Predictions Mean           1061.5823
Q Predictions Std            290.02493
Q Predictions Max            1367.0577
Q Predictions Min            312.00974
V Predictions Mean           1061.4868
V Predictions Std            290.70218
V Predictions Max            1360.3359
V Predictions Min            309.55206
Log Pis Mean                 7.998198e-05
Log Pis Std                  2.9718027
Log Pis Max                  15.353889
Log Pis Min                  -7.2887826
Policy mu Mean               0.019834753
Policy mu Std                0.60911554
Policy mu Max                4.1106358
Policy mu Min                -3.4723132
Policy log std Mean          -0.98926014
Policy log std Std           0.25415784
Policy log std Max           0.3095553
Policy log std Min           -2.3625188
Z mean eval                  1.1213753
Z variance eval              0.048737127
total_rewards                [ 345.32157998  297.59878562  222.49042928  703.20079791 1185.17707619
 1067.67280476  443.40508651  670.89718847  912.50642462  852.55607473]
total_rewards_mean           670.0826248073167
total_rewards_std            318.1978955215101
total_rewards_max            1185.1770761921905
total_rewards_min            222.49042928117967
Number of train steps total  1508000
Number of env steps total    2507187
Number of rollouts total     0
Train Time (s)               153.4645899985917
(Previous) Eval Time (s)     21.000448820646852
Sample Time (s)              12.418742658104748
Epoch Time (s)               186.8837814773433
Total Train Time (s)         69787.36809752509
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:19:00.760853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #376 | Epoch Duration: 186.99405360221863
2020-01-12 21:19:00.761043 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1194389
Z variance train             0.049401734
KL Divergence                15.450618
KL Loss                      1.5450618
QF Loss                      240.70921
VF Loss                      137.68823
Policy Loss                  -1093.7925
Q Predictions Mean           1090.0264
Q Predictions Std            268.24115
Q Predictions Max            1453.8655
Q Predictions Min            332.4756
V Predictions Mean           1083.808
V Predictions Std            267.80298
V Predictions Max            1444.7429
V Predictions Min            327.4713
Log Pis Mean                 -0.22131003
Log Pis Std                  2.6507084
Log Pis Max                  6.482535
Log Pis Min                  -8.842302
Policy mu Mean               0.007808819
Policy mu Std                0.6113541
Policy mu Max                2.192614
Policy mu Min                -2.3462
Policy log std Mean          -0.9441366
Policy log std Std           0.2322028
Policy log std Max           -0.29371744
Policy log std Min           -1.9249139
Z mean eval                  0.95062315
Z variance eval              0.04075665
total_rewards                [3519.45836766  230.50316124 2284.50195262 3484.39277363 2876.13517882
 1144.24397045 3051.86425878 3617.74662672 1107.62853566 3472.26822825]
total_rewards_mean           2478.8743053826993
total_rewards_std            1166.978338464717
total_rewards_max            3617.746626716839
total_rewards_min            230.5031612401891
Number of train steps total  1512000
Number of env steps total    2518563
Number of rollouts total     0
Train Time (s)               154.76652874285355
(Previous) Eval Time (s)     29.99797925585881
Sample Time (s)              13.456157040782273
Epoch Time (s)               198.22066503949463
Total Train Time (s)         69985.68442832213
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:22:19.081032 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #377 | Epoch Duration: 198.31983041763306
2020-01-12 21:22:19.081284 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9464984
Z variance train             0.04056589
KL Divergence                17.086092
KL Loss                      1.7086092
QF Loss                      336.02786
VF Loss                      134.732
Policy Loss                  -1077.8605
Q Predictions Mean           1076.2483
Q Predictions Std            279.36246
Q Predictions Max            1437.524
Q Predictions Min            320.8434
V Predictions Mean           1085.1807
V Predictions Std            281.65677
V Predictions Max            1438.2335
V Predictions Min            316.57068
Log Pis Mean                 -0.07051574
Log Pis Std                  2.8289647
Log Pis Max                  9.231604
Log Pis Min                  -10.696342
Policy mu Mean               0.06354697
Policy mu Std                0.6017623
Policy mu Max                2.7312193
Policy mu Min                -2.3305612
Policy log std Mean          -0.97559494
Policy log std Std           0.23627652
Policy log std Max           -0.26861846
Policy log std Min           -2.1602669
Z mean eval                  0.9384363
Z variance eval              0.09175863
total_rewards                [3410.83800813 1922.03079501  414.35220104 2636.62481962 3489.77748142
  274.06124352 3430.32124613 3536.90894099  602.16207246 3449.01306405]
total_rewards_mean           2316.608987236924
total_rewards_std            1325.6507799630253
total_rewards_max            3536.9089409879657
total_rewards_min            274.061243520917
Number of train steps total  1516000
Number of env steps total    2528341
Number of rollouts total     0
Train Time (s)               153.664029289037
(Previous) Eval Time (s)     31.07997904997319
Sample Time (s)              12.275550544261932
Epoch Time (s)               197.0195588832721
Total Train Time (s)         70182.8076756713
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:25:36.207808 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #378 | Epoch Duration: 197.126371383667
2020-01-12 21:25:36.207992 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9348062
Z variance train             0.0905749
KL Divergence                13.595192
KL Loss                      1.3595192
QF Loss                      363.99252
VF Loss                      117.424805
Policy Loss                  -1032.9656
Q Predictions Mean           1030.015
Q Predictions Std            269.84143
Q Predictions Max            1354.6608
Q Predictions Min            305.4496
V Predictions Mean           1038.2949
V Predictions Std            270.451
V Predictions Max            1352.8448
V Predictions Min            308.4432
Log Pis Mean                 -0.334475
Log Pis Std                  2.878681
Log Pis Max                  8.502519
Log Pis Min                  -8.695658
Policy mu Mean               0.008351475
Policy mu Std                0.5803731
Policy mu Max                2.3012896
Policy mu Min                -2.2230675
Policy log std Mean          -0.98070085
Policy log std Std           0.2523945
Policy log std Max           -0.23221767
Policy log std Min           -2.1914825
Z mean eval                  0.94683456
Z variance eval              0.04389222
total_rewards                [3015.64239317  428.16756387 3187.91381651 2587.58526536 3440.77514473
  137.32631933 3380.71210622  509.71280516  978.72581893  717.60494281]
total_rewards_mean           1838.4166176092046
total_rewards_std            1317.4876318310119
total_rewards_max            3440.7751447299415
total_rewards_min            137.3263193272711
Number of train steps total  1520000
Number of env steps total    2538412
Number of rollouts total     0
Train Time (s)               155.09218467399478
(Previous) Eval Time (s)     30.47878108220175
Sample Time (s)              12.005612096283585
Epoch Time (s)               197.5765778524801
Total Train Time (s)         70380.47229151847
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:28:53.876493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #379 | Epoch Duration: 197.66835522651672
2020-01-12 21:28:53.876685 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9494502
Z variance train             0.04390042
KL Divergence                16.468565
KL Loss                      1.6468565
QF Loss                      10903.416
VF Loss                      73.642746
Policy Loss                  -1078.7725
Q Predictions Mean           1074.9341
Q Predictions Std            258.75998
Q Predictions Max            1392.3695
Q Predictions Min            294.4932
V Predictions Mean           1083.1208
V Predictions Std            259.56537
V Predictions Max            1390.0961
V Predictions Min            298.03778
Log Pis Mean                 0.38172063
Log Pis Std                  2.8039656
Log Pis Max                  8.144419
Log Pis Min                  -7.966834
Policy mu Mean               0.020821659
Policy mu Std                0.62261593
Policy mu Max                2.332299
Policy mu Min                -2.4692943
Policy log std Mean          -0.99868006
Policy log std Std           0.2482875
Policy log std Max           -0.30638546
Policy log std Min           -1.9955726
Z mean eval                  1.0127732
Z variance eval              0.04478748
total_rewards                [1293.17044399 2967.87135299  338.2473998  3477.70510334 2677.70055553
  258.23908978  387.46594328  293.23898099 3318.12309455 3511.66810817]
total_rewards_mean           1852.3430072414922
total_rewards_std            1385.3623537497058
total_rewards_max            3511.6681081662286
total_rewards_min            258.239089775779
Number of train steps total  1524000
Number of env steps total    2550797
Number of rollouts total     0
Train Time (s)               149.6100397100672
(Previous) Eval Time (s)     25.75650705071166
Sample Time (s)              12.360302917193621
Epoch Time (s)               187.7268496779725
Total Train Time (s)         70568.30178474961
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:32:01.710113 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #380 | Epoch Duration: 187.83328533172607
2020-01-12 21:32:01.710301 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0115587
Z variance train             0.044943117
KL Divergence                16.227459
KL Loss                      1.6227459
QF Loss                      307.6502
VF Loss                      68.85536
Policy Loss                  -1075.0024
Q Predictions Mean           1071.3899
Q Predictions Std            266.0381
Q Predictions Max            1400.7461
Q Predictions Min            295.52954
V Predictions Mean           1071.555
V Predictions Std            265.19656
V Predictions Max            1389.5228
V Predictions Min            294.79382
Log Pis Mean                 -0.048489608
Log Pis Std                  2.5503263
Log Pis Max                  11.275879
Log Pis Min                  -9.43288
Policy mu Mean               0.04164931
Policy mu Std                0.6105208
Policy mu Max                2.134098
Policy mu Min                -2.626412
Policy log std Mean          -0.9776497
Policy log std Std           0.246051
Policy log std Max           -0.061522484
Policy log std Min           -2.8678
Z mean eval                  1.0040883
Z variance eval              0.084718235
total_rewards                [3531.98824583  307.66620589 1045.45251843 3178.48172313 3316.90341025
 3436.4799732  2309.15509617 3540.45882311 3434.03779641 1678.58675189]
total_rewards_mean           2577.9210544303733
total_rewards_std            1122.3682422864392
total_rewards_max            3540.458823114176
total_rewards_min            307.6662058924695
Number of train steps total  1528000
Number of env steps total    2561696
Number of rollouts total     0
Train Time (s)               145.49047930911183
(Previous) Eval Time (s)     32.56511037796736
Sample Time (s)              11.906323487404734
Epoch Time (s)               189.96191317448393
Total Train Time (s)         70758.34918140015
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:35:11.761252 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #381 | Epoch Duration: 190.0508098602295
2020-01-12 21:35:11.761425 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0026639
Z variance train             0.085011736
KL Divergence                13.923891
KL Loss                      1.3923892
QF Loss                      11046.393
VF Loss                      108.688484
Policy Loss                  -1027.1636
Q Predictions Mean           1022.7872
Q Predictions Std            283.5083
Q Predictions Max            1379.1495
Q Predictions Min            255.84511
V Predictions Mean           1025.0459
V Predictions Std            282.71768
V Predictions Max            1366.2308
V Predictions Min            265.03802
Log Pis Mean                 -0.046880953
Log Pis Std                  2.89634
Log Pis Max                  10.290144
Log Pis Min                  -9.071616
Policy mu Mean               0.017744279
Policy mu Std                0.634927
Policy mu Max                2.2217948
Policy mu Min                -2.6365323
Policy log std Mean          -0.9493176
Policy log std Std           0.27350807
Policy log std Max           -0.2981882
Policy log std Min           -2.3280897
Z mean eval                  1.0947492
Z variance eval              0.088697046
total_rewards                [1413.45942348 2512.98746545  836.65766671  253.36984518 2330.3163245
  801.7405817   556.94524377 1715.62700282 1642.27300215 2998.62362599]
total_rewards_mean           1506.2000181751678
total_rewards_std            860.5992876730999
total_rewards_max            2998.623625993801
total_rewards_min            253.3698451782325
Number of train steps total  1532000
Number of env steps total    2572962
Number of rollouts total     0
Train Time (s)               147.7262653959915
(Previous) Eval Time (s)     14.96643230970949
Sample Time (s)              11.268855911679566
Epoch Time (s)               173.96155361738056
Total Train Time (s)         70932.39762628404
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:38:05.813805 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #382 | Epoch Duration: 174.05223989486694
2020-01-12 21:38:05.813998 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.094232
Z variance train             0.08838563
KL Divergence                13.880537
KL Loss                      1.3880538
QF Loss                      202.76773
VF Loss                      82.119385
Policy Loss                  -1078.8085
Q Predictions Mean           1074.0476
Q Predictions Std            303.89886
Q Predictions Max            1437.4216
Q Predictions Min            331.79434
V Predictions Mean           1074.8308
V Predictions Std            303.18295
V Predictions Max            1421.7465
V Predictions Min            329.4874
Log Pis Mean                 -0.3835813
Log Pis Std                  2.6614313
Log Pis Max                  9.316481
Log Pis Min                  -9.047032
Policy mu Mean               0.04679899
Policy mu Std                0.5977651
Policy mu Max                2.5318267
Policy mu Min                -2.376063
Policy log std Mean          -0.95995414
Policy log std Std           0.24800688
Policy log std Max           -0.2705589
Policy log std Min           -2.2650208
Z mean eval                  0.8673301
Z variance eval              0.06747334
total_rewards                [  98.48511082 2599.29527562  774.5360192   247.73817847  481.78498868
 3442.48640526  335.84215254 3686.62127855  862.03180042 3505.17956161]
total_rewards_mean           1603.400077117437
total_rewards_std            1432.9890382225922
total_rewards_max            3686.6212785464713
total_rewards_min            98.4851108245234
Number of train steps total  1536000
Number of env steps total    2585279
Number of rollouts total     0
Train Time (s)               156.134403409902
(Previous) Eval Time (s)     20.915027615614235
Sample Time (s)              13.121235236525536
Epoch Time (s)               190.17066626204178
Total Train Time (s)         71122.65954413079
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:41:16.080341 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #383 | Epoch Duration: 190.26619744300842
2020-01-12 21:41:16.080548 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86231244
Z variance train             0.067455515
KL Divergence                14.602121
KL Loss                      1.4602121
QF Loss                      688.98126
VF Loss                      56.078896
Policy Loss                  -1042.5061
Q Predictions Mean           1038.1163
Q Predictions Std            308.5093
Q Predictions Max            1374.7267
Q Predictions Min            297.863
V Predictions Mean           1046.6221
V Predictions Std            308.58606
V Predictions Max            1383.0839
V Predictions Min            309.62625
Log Pis Mean                 0.0878693
Log Pis Std                  2.7190268
Log Pis Max                  8.986563
Log Pis Min                  -7.194241
Policy mu Mean               -0.023574648
Policy mu Std                0.60029036
Policy mu Max                2.7330534
Policy mu Min                -2.5218306
Policy log std Mean          -0.9898497
Policy log std Std           0.2560784
Policy log std Max           0.024115562
Policy log std Min           -2.0992622
Z mean eval                  1.0667573
Z variance eval              0.10559527
total_rewards                [3391.81135284 2520.72294822   77.44112712 3047.41101329 3526.47102066
 1899.18735234 2533.93527386  830.96607802 3655.26148403 2922.98015669]
total_rewards_mean           2440.618780706604
total_rewards_std            1124.4523861173916
total_rewards_max            3655.2614840306605
total_rewards_min            77.44112711872812
Number of train steps total  1540000
Number of env steps total    2593950
Number of rollouts total     0
Train Time (s)               154.79055056720972
(Previous) Eval Time (s)     26.38985814899206
Sample Time (s)              11.707676435355097
Epoch Time (s)               192.88808515155688
Total Train Time (s)         71315.63422232587
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:44:29.059089 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #384 | Epoch Duration: 192.97837829589844
2020-01-12 21:44:29.059308 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.068831
Z variance train             0.10546295
KL Divergence                14.390091
KL Loss                      1.4390091
QF Loss                      265.33423
VF Loss                      43.685337
Policy Loss                  -1073.3846
Q Predictions Mean           1068.476
Q Predictions Std            323.61972
Q Predictions Max            1404.3966
Q Predictions Min            291.27933
V Predictions Mean           1073.1682
V Predictions Std            324.04636
V Predictions Max            1403.5862
V Predictions Min            296.75946
Log Pis Mean                 -0.17565994
Log Pis Std                  2.8380246
Log Pis Max                  9.057539
Log Pis Min                  -9.103194
Policy mu Mean               0.04241079
Policy mu Std                0.607554
Policy mu Max                2.6057718
Policy mu Min                -2.0795403
Policy log std Mean          -0.9440836
Policy log std Std           0.25166297
Policy log std Max           -0.16230154
Policy log std Min           -2.157264
Z mean eval                  1.0363102
Z variance eval              0.038205523
total_rewards                [2598.21884445 3573.8439237  3486.74272328  529.02733966 3256.92945599
 3344.24588125  211.78091571 3182.43013767 3262.58254864 3440.81283371]
total_rewards_mean           2688.661460405088
total_rewards_std            1188.245024758396
total_rewards_max            3573.8439237014704
total_rewards_min            211.78091570934595
Number of train steps total  1544000
Number of env steps total    2605651
Number of rollouts total     0
Train Time (s)               154.44127891398966
(Previous) Eval Time (s)     31.73978559114039
Sample Time (s)              12.032003683038056
Epoch Time (s)               198.2130681881681
Total Train Time (s)         71513.95021588076
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:47:47.380428 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #385 | Epoch Duration: 198.32093286514282
2020-01-12 21:47:47.380755 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0377364
Z variance train             0.038382933
KL Divergence                14.948042
KL Loss                      1.4948043
QF Loss                      1659.733
VF Loss                      121.887955
Policy Loss                  -1089.6555
Q Predictions Mean           1077.991
Q Predictions Std            293.68207
Q Predictions Max            1408.7474
Q Predictions Min            313.96594
V Predictions Mean           1087.6754
V Predictions Std            291.84875
V Predictions Max            1413.7622
V Predictions Min            318.05798
Log Pis Mean                 -0.019680485
Log Pis Std                  2.9078722
Log Pis Max                  12.349348
Log Pis Min                  -7.988263
Policy mu Mean               0.03710407
Policy mu Std                0.6030006
Policy mu Max                2.6151843
Policy mu Min                -2.8691728
Policy log std Mean          -0.998302
Policy log std Std           0.27025554
Policy log std Max           0.08184683
Policy log std Min           -2.342986
Z mean eval                  1.054601
Z variance eval              0.21956126
total_rewards                [ 680.24273591 3542.33156677  351.17082154 1054.61211923 1229.91338722
 1619.13053344 2975.52540731 2171.28548575 3451.10610489 2660.27393132]
total_rewards_mean           1973.559209337175
total_rewards_std            1094.8381031193253
total_rewards_max            3542.33156676895
total_rewards_min            351.17082153889015
Number of train steps total  1548000
Number of env steps total    2614117
Number of rollouts total     0
Train Time (s)               154.7117391419597
(Previous) Eval Time (s)     25.849643101915717
Sample Time (s)              11.882146610412747
Epoch Time (s)               192.44352885428816
Total Train Time (s)         71706.48838193994
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:50:59.921957 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #386 | Epoch Duration: 192.5410122871399
2020-01-12 21:50:59.922151 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0462637
Z variance train             0.21812816
KL Divergence                13.852175
KL Loss                      1.3852175
QF Loss                      477.498
VF Loss                      149.3677
Policy Loss                  -1095.8524
Q Predictions Mean           1091.9454
Q Predictions Std            316.56696
Q Predictions Max            1452.4272
Q Predictions Min            59.645996
V Predictions Mean           1104.4214
V Predictions Std            315.28625
V Predictions Max            1461.116
V Predictions Min            163.6636
Log Pis Mean                 -0.0016805679
Log Pis Std                  2.9695857
Log Pis Max                  12.7171135
Log Pis Min                  -7.6750607
Policy mu Mean               0.01008612
Policy mu Std                0.61256623
Policy mu Max                2.1948066
Policy mu Min                -2.6555882
Policy log std Mean          -0.96435547
Policy log std Std           0.259173
Policy log std Max           -0.25505644
Policy log std Min           -2.4944952
Z mean eval                  1.0484304
Z variance eval              0.112924054
total_rewards                [3417.4132207  3416.37328009 1649.89703891 1003.01227369 3196.50592185
 2562.51393254  768.07079082 1043.50276994 3406.75551236 2568.28861674]
total_rewards_mean           2303.2333357646667
total_rewards_std            1034.152960335491
total_rewards_max            3417.413220703977
total_rewards_min            768.0707908179522
Number of train steps total  1552000
Number of env steps total    2623874
Number of rollouts total     0
Train Time (s)               146.01159071270376
(Previous) Eval Time (s)     26.262571034021676
Sample Time (s)              12.065216567832977
Epoch Time (s)               184.33937831455842
Total Train Time (s)         71890.91335507901
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:54:04.351022 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #387 | Epoch Duration: 184.42872714996338
2020-01-12 21:54:04.351304 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0520842
Z variance train             0.11379059
KL Divergence                14.930826
KL Loss                      1.4930826
QF Loss                      472.83044
VF Loss                      61.12039
Policy Loss                  -1072.5126
Q Predictions Mean           1061.6766
Q Predictions Std            303.39175
Q Predictions Max            1416.878
Q Predictions Min            129.09901
V Predictions Mean           1068.3052
V Predictions Std            296.75888
V Predictions Max            1405.1157
V Predictions Min            291.73804
Log Pis Mean                 -0.18607356
Log Pis Std                  2.5865886
Log Pis Max                  13.434467
Log Pis Min                  -15.71018
Policy mu Mean               -0.05461374
Policy mu Std                0.5842001
Policy mu Max                1.7289423
Policy mu Min                -2.3992789
Policy log std Mean          -1.0038946
Policy log std Std           0.2331552
Policy log std Max           -0.25400072
Policy log std Min           -1.9472339
Z mean eval                  1.1103017
Z variance eval              0.26694486
total_rewards                [1014.09000741 1064.18939949 1784.54854082  711.99074022  760.27038424
  155.99658469 3479.02516754 1081.79420859 3220.85931499 1387.46068054]
total_rewards_mean           1466.0225028519276
total_rewards_std            1026.4221756074726
total_rewards_max            3479.025167536563
total_rewards_min            155.9965846860636
Number of train steps total  1556000
Number of env steps total    2634530
Number of rollouts total     0
Train Time (s)               145.8236125339754
(Previous) Eval Time (s)     25.500765919219702
Sample Time (s)              11.40069478424266
Epoch Time (s)               182.72507323743775
Total Train Time (s)         72073.7343285745
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:57:07.176237 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #388 | Epoch Duration: 182.824782371521
2020-01-12 21:57:07.176437 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1093776
Z variance train             0.2656078
KL Divergence                12.204699
KL Loss                      1.2204698
QF Loss                      11317.386
VF Loss                      124.636
Policy Loss                  -1125.7202
Q Predictions Mean           1125.6407
Q Predictions Std            264.14536
Q Predictions Max            1415.716
Q Predictions Min            313.16977
V Predictions Mean           1134.2319
V Predictions Std            263.4285
V Predictions Max            1412.4635
V Predictions Min            324.50266
Log Pis Mean                 0.2075511
Log Pis Std                  2.509832
Log Pis Max                  7.9481173
Log Pis Min                  -6.166641
Policy mu Mean               0.041136526
Policy mu Std                0.56995106
Policy mu Max                2.2121959
Policy mu Min                -2.256117
Policy log std Mean          -1.0314014
Policy log std Std           0.25018317
Policy log std Max           -0.3255247
Policy log std Min           -2.3127432
Z mean eval                  0.9643281
Z variance eval              0.2071501
total_rewards                [ 373.09628072 3367.29848694 1112.44095194 2639.01975841  429.21850533
 2764.20953364 1816.17258621  843.01172529 3295.58419147  847.54678547]
total_rewards_mean           1748.7598805416958
total_rewards_std            1118.5563961386838
total_rewards_max            3367.2984869351794
total_rewards_min            373.0962807186114
Number of train steps total  1560000
Number of env steps total    2646554
Number of rollouts total     0
Train Time (s)               149.45867306180298
(Previous) Eval Time (s)     24.958006928674877
Sample Time (s)              10.942022535018623
Epoch Time (s)               185.35870252549648
Total Train Time (s)         72259.18271555379
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:00:12.629067 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #389 | Epoch Duration: 185.45245337486267
2020-01-12 22:00:12.629329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9567526
Z variance train             0.20687363
KL Divergence                12.039477
KL Loss                      1.2039478
QF Loss                      384.10486
VF Loss                      80.07754
Policy Loss                  -1108.0795
Q Predictions Mean           1105.3242
Q Predictions Std            298.45734
Q Predictions Max            1402.0581
Q Predictions Min            305.69992
V Predictions Mean           1111.3242
V Predictions Std            299.445
V Predictions Max            1425.3389
V Predictions Min            306.06436
Log Pis Mean                 -0.074096836
Log Pis Std                  2.720121
Log Pis Max                  8.86976
Log Pis Min                  -5.8807592
Policy mu Mean               0.06290649
Policy mu Std                0.59161085
Policy mu Max                2.208991
Policy mu Min                -2.1427653
Policy log std Mean          -0.98500586
Policy log std Std           0.23662573
Policy log std Max           -0.37874472
Policy log std Min           -2.1249752
Z mean eval                  0.95785856
Z variance eval              0.13302514
total_rewards                [ 994.84986434 2903.15622059 2416.2797107   617.40633698  171.11467383
 1187.24518762   69.21285876 2142.79375524 3503.01012132 1044.58414614]
total_rewards_mean           1504.965287551137
total_rewards_std            1112.9177042601204
total_rewards_max            3503.010121322429
total_rewards_min            69.21285875571989
Number of train steps total  1564000
Number of env steps total    2658872
Number of rollouts total     0
Train Time (s)               156.12944735214114
(Previous) Eval Time (s)     22.681738913059235
Sample Time (s)              13.12441854737699
Epoch Time (s)               191.93560481257737
Total Train Time (s)         72451.28673355421
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:03:24.737261 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #390 | Epoch Duration: 192.10775470733643
2020-01-12 22:03:24.737472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.958844
Z variance train             0.13344467
KL Divergence                12.329926
KL Loss                      1.2329925
QF Loss                      227.668
VF Loss                      74.703255
Policy Loss                  -1129.8635
Q Predictions Mean           1126.9164
Q Predictions Std            276.33188
Q Predictions Max            1446.8608
Q Predictions Min            311.76297
V Predictions Mean           1134.9788
V Predictions Std            276.1833
V Predictions Max            1434.6199
V Predictions Min            306.6311
Log Pis Mean                 -0.098319
Log Pis Std                  2.6812296
Log Pis Max                  11.153324
Log Pis Min                  -9.190401
Policy mu Mean               0.0054364246
Policy mu Std                0.5986366
Policy mu Max                4.255139
Policy mu Min                -3.5053048
Policy log std Mean          -1.0011163
Policy log std Std           0.24291685
Policy log std Max           0.09686923
Policy log std Min           -1.9001956
Z mean eval                  1.0453423
Z variance eval              0.15738524
total_rewards                [ 432.57944213  472.26740157  348.28923561 1312.70933506  397.03842711
  137.86320378  706.54856215 1731.80853882  197.80341889 3593.57645722]
total_rewards_mean           933.0484022342318
total_rewards_std            1008.8020054013211
total_rewards_max            3593.5764572222224
total_rewards_min            137.8632037827014
Number of train steps total  1568000
Number of env steps total    2671176
Number of rollouts total     0
Train Time (s)               155.78484528977424
(Previous) Eval Time (s)     24.311104509979486
Sample Time (s)              12.92441733321175
Epoch Time (s)               193.02036713296548
Total Train Time (s)         72644.40258734301
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:06:37.858041 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #391 | Epoch Duration: 193.12035536766052
2020-01-12 22:06:37.858262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0239619
Z variance train             0.15847251
KL Divergence                13.435606
KL Loss                      1.3435606
QF Loss                      256.78738
VF Loss                      123.46474
Policy Loss                  -1105.1031
Q Predictions Mean           1103.9446
Q Predictions Std            303.37433
Q Predictions Max            1440.0385
Q Predictions Min            285.6211
V Predictions Mean           1112.4442
V Predictions Std            303.24112
V Predictions Max            1440.2401
V Predictions Min            294.1601
Log Pis Mean                 -0.49355757
Log Pis Std                  2.478193
Log Pis Max                  8.281638
Log Pis Min                  -8.1094
Policy mu Mean               -0.03373088
Policy mu Std                0.5794331
Policy mu Max                2.442672
Policy mu Min                -2.2863758
Policy log std Mean          -0.9617673
Policy log std Std           0.23980027
Policy log std Max           -0.13486993
Policy log std Min           -2.1060429
Z mean eval                  0.9521452
Z variance eval              0.10282578
total_rewards                [1534.3535898   278.13831207 2805.95195751 2227.05751264 1761.87230697
 2822.09641411 1409.55218839 3493.00996077  100.23043381 1234.93263808]
total_rewards_mean           1766.71953141295
total_rewards_std            1041.3096225286422
total_rewards_max            3493.0099607728407
total_rewards_min            100.2304338096734
Number of train steps total  1572000
Number of env steps total    2681811
Number of rollouts total     0
Train Time (s)               156.74619844695553
(Previous) Eval Time (s)     24.653452578932047
Sample Time (s)              11.99969933880493
Epoch Time (s)               193.3993503646925
Total Train Time (s)         72837.90029299678
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:09:51.358825 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #392 | Epoch Duration: 193.5004003047943
2020-01-12 22:09:51.359009 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9525935
Z variance train             0.103005745
KL Divergence                13.567782
KL Loss                      1.3567783
QF Loss                      376.4111
VF Loss                      114.30189
Policy Loss                  -1130.6517
Q Predictions Mean           1126.7245
Q Predictions Std            274.65125
Q Predictions Max            1476.496
Q Predictions Min            309.74945
V Predictions Mean           1129.907
V Predictions Std            274.07315
V Predictions Max            1475.9872
V Predictions Min            283.95917
Log Pis Mean                 0.2629492
Log Pis Std                  2.7157676
Log Pis Max                  10.348233
Log Pis Min                  -8.146161
Policy mu Mean               -0.028529638
Policy mu Std                0.62170225
Policy mu Max                3.1670358
Policy mu Min                -2.4552035
Policy log std Mean          -1.00539
Policy log std Std           0.26014414
Policy log std Max           -0.23385572
Policy log std Min           -2.2913938
Z mean eval                  0.9995866
Z variance eval              0.11737859
total_rewards                [3405.64954888 1136.59713593  957.87947855  713.20721467  789.27623444
 3337.66446051 3411.58321105 1290.72447934 1642.08660745 1219.8033584 ]
total_rewards_mean           1790.4471729217537
total_rewards_std            1072.9253519093766
total_rewards_max            3411.583211052744
total_rewards_min            713.207214666183
Number of train steps total  1576000
Number of env steps total    2691751
Number of rollouts total     0
Train Time (s)               154.38129679812118
(Previous) Eval Time (s)     23.42266326583922
Sample Time (s)              11.50625104829669
Epoch Time (s)               189.3102111122571
Total Train Time (s)         73027.330825001
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:13:00.793427 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #393 | Epoch Duration: 189.4342794418335
2020-01-12 22:13:00.793623 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0013926
Z variance train             0.11747122
KL Divergence                12.164698
KL Loss                      1.2164698
QF Loss                      2419.7212
VF Loss                      230.40244
Policy Loss                  -1128.0969
Q Predictions Mean           1126.2427
Q Predictions Std            316.83688
Q Predictions Max            1454.2495
Q Predictions Min            311.48422
V Predictions Mean           1121.7781
V Predictions Std            317.27988
V Predictions Max            1431.5637
V Predictions Min            298.3078
Log Pis Mean                 0.12423838
Log Pis Std                  2.6120548
Log Pis Max                  8.331729
Log Pis Min                  -10.788939
Policy mu Mean               -0.031281903
Policy mu Std                0.62435484
Policy mu Max                2.2769
Policy mu Min                -2.564732
Policy log std Mean          -0.9512539
Policy log std Std           0.24282604
Policy log std Max           -0.28177303
Policy log std Min           -1.9473125
Z mean eval                  0.9815825
Z variance eval              0.29334897
total_rewards                [ 592.4161225  1614.15114584   94.71607821   73.3650331  1216.72893269
 1613.78106423 3149.73208539 3127.63246368 1403.40301863 1908.12842587]
total_rewards_mean           1479.4054370135705
total_rewards_std            1023.8407911152451
total_rewards_max            3149.7320853855863
total_rewards_min            73.3650331011439
Number of train steps total  1580000
Number of env steps total    2704090
Number of rollouts total     0
Train Time (s)               145.90101838996634
(Previous) Eval Time (s)     17.42058579204604
Sample Time (s)              11.979575397446752
Epoch Time (s)               175.30117957945913
Total Train Time (s)         73202.7194502647
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:15:56.186382 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #394 | Epoch Duration: 175.39261078834534
2020-01-12 22:15:56.186571 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98423547
Z variance train             0.2929257
KL Divergence                13.635141
KL Loss                      1.3635142
QF Loss                      335.2789
VF Loss                      51.22711
Policy Loss                  -1150.1884
Q Predictions Mean           1145.4474
Q Predictions Std            254.4523
Q Predictions Max            1441.8744
Q Predictions Min            266.97113
V Predictions Mean           1151.3438
V Predictions Std            252.17883
V Predictions Max            1428.7607
V Predictions Min            284.88022
Log Pis Mean                 0.38336536
Log Pis Std                  2.6494877
Log Pis Max                  8.068035
Log Pis Min                  -9.381189
Policy mu Mean               0.005520586
Policy mu Std                0.6269619
Policy mu Max                2.1144702
Policy mu Min                -2.2159104
Policy log std Mean          -0.9956181
Policy log std Std           0.25308737
Policy log std Max           -0.29685158
Policy log std Min           -2.1913204
Z mean eval                  1.035505
Z variance eval              0.1825893
total_rewards                [3358.77500733 3680.58578692 2972.03439654  430.60120084 2253.42343967
 1666.25428212 3531.17792563 3505.66908831 3494.3768086  3517.51914224]
total_rewards_mean           2841.041707820318
total_rewards_std            1016.2761093443559
total_rewards_max            3680.585786921383
total_rewards_min            430.60120083815957
Number of train steps total  1584000
Number of env steps total    2714434
Number of rollouts total     0
Train Time (s)               145.8197345728986
(Previous) Eval Time (s)     32.47811661986634
Sample Time (s)              11.209201131016016
Epoch Time (s)               189.50705232378095
Total Train Time (s)         73392.3156955503
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:19:05.787067 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #395 | Epoch Duration: 189.60033535957336
2020-01-12 22:19:05.787390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0409757
Z variance train             0.18247174
KL Divergence                13.007607
KL Loss                      1.3007607
QF Loss                      395.87146
VF Loss                      409.6503
Policy Loss                  -1123.3663
Q Predictions Mean           1119.868
Q Predictions Std            262.05234
Q Predictions Max            1402.8495
Q Predictions Min            92.88394
V Predictions Mean           1125.4325
V Predictions Std            256.38727
V Predictions Max            1411.3336
V Predictions Min            296.96805
Log Pis Mean                 0.016077958
Log Pis Std                  2.8034022
Log Pis Max                  21.774015
Log Pis Min                  -9.148444
Policy mu Mean               0.004146006
Policy mu Std                0.59234565
Policy mu Max                2.4801626
Policy mu Min                -2.7503457
Policy log std Mean          -1.0019997
Policy log std Std           0.243562
Policy log std Max           -0.33770102
Policy log std Min           -3.1438365
Z mean eval                  0.9169413
Z variance eval              0.13155898
total_rewards                [2399.17195903 2197.70019005  891.57920797 2771.42379593 3715.58884291
  165.57935887  573.65487674 1911.54086604 3519.1522208  3580.27965391]
total_rewards_mean           2172.567097225158
total_rewards_std            1219.8384221997096
total_rewards_max            3715.5888429137076
total_rewards_min            165.57935887397784
Number of train steps total  1588000
Number of env steps total    2725791
Number of rollouts total     0
Train Time (s)               153.14915715623647
(Previous) Eval Time (s)     24.639568706974387
Sample Time (s)              11.034196738153696
Epoch Time (s)               188.82292260136455
Total Train Time (s)         73581.23536546435
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:22:14.712199 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #396 | Epoch Duration: 188.92455410957336
2020-01-12 22:22:14.712726 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91332996
Z variance train             0.1312362
KL Divergence                12.735377
KL Loss                      1.2735378
QF Loss                      305.4831
VF Loss                      48.81358
Policy Loss                  -1072.6361
Q Predictions Mean           1068.5885
Q Predictions Std            292.12344
Q Predictions Max            1416.3973
Q Predictions Min            290.95685
V Predictions Mean           1074.0823
V Predictions Std            292.74033
V Predictions Max            1406.2949
V Predictions Min            294.73273
Log Pis Mean                 -0.2495603
Log Pis Std                  2.5231833
Log Pis Max                  8.01906
Log Pis Min                  -7.073303
Policy mu Mean               0.00891328
Policy mu Std                0.60072577
Policy mu Max                2.286135
Policy mu Min                -2.443389
Policy log std Mean          -0.9550033
Policy log std Std           0.24264991
Policy log std Max           -0.22867703
Policy log std Min           -2.1966248
Z mean eval                  0.92916584
Z variance eval              0.20817992
total_rewards                [3596.68746895 1360.27496081 3759.27683429  212.29955163 3497.70088531
 3493.94904721 3546.72943442 3476.57298275 3586.22576173 3481.10934012]
total_rewards_mean           3001.08262672265
total_rewards_std            1139.5328461948443
total_rewards_max            3759.2768342940985
total_rewards_min            212.29955162809583
Number of train steps total  1592000
Number of env steps total    2737160
Number of rollouts total     0
Train Time (s)               156.10114666400477
(Previous) Eval Time (s)     31.313529575243592
Sample Time (s)              12.52757032494992
Epoch Time (s)               199.94224656419829
Total Train Time (s)         73781.26257531671
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:25:34.742214 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #397 | Epoch Duration: 200.02920770645142
2020-01-12 22:25:34.742410 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9281479
Z variance train             0.20817685
KL Divergence                13.38682
KL Loss                      1.338682
QF Loss                      645.2851
VF Loss                      57.140568
Policy Loss                  -1122.6532
Q Predictions Mean           1119.0275
Q Predictions Std            270.4424
Q Predictions Max            1426.8435
Q Predictions Min            304.75906
V Predictions Mean           1121.9359
V Predictions Std            271.4148
V Predictions Max            1446.7365
V Predictions Min            304.69095
Log Pis Mean                 0.15524974
Log Pis Std                  2.9870818
Log Pis Max                  15.335439
Log Pis Min                  -7.00097
Policy mu Mean               0.0031785362
Policy mu Std                0.6208728
Policy mu Max                2.8535235
Policy mu Min                -2.5785244
Policy log std Mean          -1.0364399
Policy log std Std           0.28003013
Policy log std Max           -0.3664602
Policy log std Min           -2.5653517
Z mean eval                  1.0165315
Z variance eval              0.1580503
total_rewards                [2509.37013311 2686.39667087  691.69686206 3144.45536865 3128.64369681
 1039.78503167 2593.16653929 3163.99204423  225.65499008  142.75451329]
total_rewards_mean           1932.5915850036745
total_rewards_std            1191.9240321420198
total_rewards_max            3163.992044230212
total_rewards_min            142.75451328816246
Number of train steps total  1596000
Number of env steps total    2749257
Number of rollouts total     0
Train Time (s)               154.5582267967984
(Previous) Eval Time (s)     31.17493745405227
Sample Time (s)              12.081610423047096
Epoch Time (s)               197.81477467389777
Total Train Time (s)         73979.17486113682
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:28:52.659163 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #398 | Epoch Duration: 197.9166135787964
2020-01-12 22:28:52.659377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.010751
Z variance train             0.15734473
KL Divergence                13.988701
KL Loss                      1.3988701
QF Loss                      367.58633
VF Loss                      86.43002
Policy Loss                  -1125.0477
Q Predictions Mean           1120.274
Q Predictions Std            266.80075
Q Predictions Max            1433.8766
Q Predictions Min            289.10602
V Predictions Mean           1122.6533
V Predictions Std            269.26648
V Predictions Max            1431.6666
V Predictions Min            286.70807
Log Pis Mean                 0.32760203
Log Pis Std                  2.9205453
Log Pis Max                  8.442077
Log Pis Min                  -7.964823
Policy mu Mean               0.041190796
Policy mu Std                0.62785256
Policy mu Max                2.332108
Policy mu Min                -2.1288953
Policy log std Mean          -1.0242333
Policy log std Std           0.24234895
Policy log std Max           -0.42518842
Policy log std Min           -2.0705683
Z mean eval                  0.99128485
Z variance eval              0.079711735
total_rewards                [2574.19672759   57.85885721  606.58307927  632.73992075 1545.76379607
  487.67610197 3202.8776254   684.24244919  194.46125642 1282.63077672]
total_rewards_mean           1126.9030590596726
total_rewards_std            986.7024693279795
total_rewards_max            3202.8776254030618
total_rewards_min            57.85885721149427
Number of train steps total  1600000
Number of env steps total    2759053
Number of rollouts total     0
Train Time (s)               155.95915522705764
(Previous) Eval Time (s)     13.250663218088448
Sample Time (s)              12.921557479538023
Epoch Time (s)               182.1313759246841
Total Train Time (s)         74161.39794104453
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:31:54.887677 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #399 | Epoch Duration: 182.2281153202057
2020-01-12 22:31:54.888028 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99019825
Z variance train             0.07969177
KL Divergence                13.252669
KL Loss                      1.325267
QF Loss                      262.11038
VF Loss                      70.619354
Policy Loss                  -1149.037
Q Predictions Mean           1144.9396
Q Predictions Std            250.08781
Q Predictions Max            1419.2668
Q Predictions Min            292.35342
V Predictions Mean           1144.5502
V Predictions Std            248.29378
V Predictions Max            1418.673
V Predictions Min            301.69452
Log Pis Mean                 0.4730352
Log Pis Std                  2.4944334
Log Pis Max                  9.309877
Log Pis Min                  -8.168519
Policy mu Mean               -0.048233032
Policy mu Std                0.6507203
Policy mu Max                2.1737375
Policy mu Min                -2.1626868
Policy log std Mean          -0.9499507
Policy log std Std           0.22945416
Policy log std Max           -0.1426726
Policy log std Min           -2.2526112
Z mean eval                  1.0051458
Z variance eval              0.07877834
total_rewards                [3488.10907189 2194.13796508 3532.22597123 3366.37322263   20.03108013
 1411.98077261 3597.54901435 1756.49612556 1649.94601708 3450.65414223]
total_rewards_mean           2446.750338280566
total_rewards_std            1165.1363645121396
total_rewards_max            3597.5490143521483
total_rewards_min            20.03108013446075
Number of train steps total  1604000
Number of env steps total    2769976
Number of rollouts total     0
Train Time (s)               152.4514170079492
(Previous) Eval Time (s)     27.620732359588146
Sample Time (s)              12.927793037611991
Epoch Time (s)               192.99994240514934
Total Train Time (s)         74354.48551318422
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:35:07.978985 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #400 | Epoch Duration: 193.09077620506287
2020-01-12 22:35:07.979168 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0086113
Z variance train             0.07887299
KL Divergence                13.028774
KL Loss                      1.3028774
QF Loss                      340.75272
VF Loss                      73.542755
Policy Loss                  -1085.3966
Q Predictions Mean           1081.1063
Q Predictions Std            301.18927
Q Predictions Max            1412.1311
Q Predictions Min            264.10294
V Predictions Mean           1085.1909
V Predictions Std            300.6089
V Predictions Max            1413.51
V Predictions Min            273.7182
Log Pis Mean                 -0.20417176
Log Pis Std                  2.489364
Log Pis Max                  6.0393906
Log Pis Min                  -7.342661
Policy mu Mean               0.0063265003
Policy mu Std                0.58478546
Policy mu Max                2.5468736
Policy mu Min                -2.0264213
Policy log std Mean          -0.99835336
Policy log std Std           0.2608186
Policy log std Max           -0.29816908
Policy log std Min           -1.9963808
Z mean eval                  0.9222635
Z variance eval              0.058010977
total_rewards                [1689.35608063 2668.01918434 3147.62613776  370.0678458   140.50681724
  237.27338756  581.75611568 3471.92135756 3487.07641087 3445.82763879]
total_rewards_mean           1923.9430976225285
total_rewards_std            1396.5432090963238
total_rewards_max            3487.076410873299
total_rewards_min            140.50681723637257
Number of train steps total  1608000
Number of env steps total    2780076
Number of rollouts total     0
Train Time (s)               144.73098561819643
(Previous) Eval Time (s)     26.304136170074344
Sample Time (s)              11.894977784715593
Epoch Time (s)               182.93009957298636
Total Train Time (s)         74537.50452820398
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:38:11.001933 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #401 | Epoch Duration: 183.02259802818298
2020-01-12 22:38:11.002119 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9115802
Z variance train             0.058360964
KL Divergence                14.066717
KL Loss                      1.4066718
QF Loss                      185.11568
VF Loss                      51.25775
Policy Loss                  -1115.8164
Q Predictions Mean           1112.1323
Q Predictions Std            272.8249
Q Predictions Max            1409.9336
Q Predictions Min            274.6708
V Predictions Mean           1112.4095
V Predictions Std            273.70898
V Predictions Max            1405.9414
V Predictions Min            267.45392
Log Pis Mean                 0.47819847
Log Pis Std                  2.7422519
Log Pis Max                  10.2008295
Log Pis Min                  -9.004873
Policy mu Mean               -0.01302267
Policy mu Std                0.62376016
Policy mu Max                2.1076238
Policy mu Min                -2.2187948
Policy log std Mean          -1.0319895
Policy log std Std           0.25189462
Policy log std Max           -0.36823565
Policy log std Min           -2.0846305
Z mean eval                  1.006738
Z variance eval              0.09965535
total_rewards                [3790.23330972  683.56199081 3515.77439206 3483.44700399 3210.49037053
 1760.12574185 1414.0173022  3377.94867127 1410.38595141  712.13439078]
total_rewards_mean           2335.811912462913
total_rewards_std            1186.575845211895
total_rewards_max            3790.233309722328
total_rewards_min            683.5619908053222
Number of train steps total  1612000
Number of env steps total    2790402
Number of rollouts total     0
Train Time (s)               145.6855387990363
(Previous) Eval Time (s)     26.623129677958786
Sample Time (s)              11.613207587506622
Epoch Time (s)               183.9218760645017
Total Train Time (s)         74721.52739700722
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:41:15.030554 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #402 | Epoch Duration: 184.02825903892517
2020-01-12 22:41:15.030869 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0092934
Z variance train             0.09950353
KL Divergence                13.122034
KL Loss                      1.3122034
QF Loss                      408.72723
VF Loss                      74.89644
Policy Loss                  -1068.2855
Q Predictions Mean           1065.2727
Q Predictions Std            296.80646
Q Predictions Max            1377.4681
Q Predictions Min            248.98438
V Predictions Mean           1062.569
V Predictions Std            299.02585
V Predictions Max            1375.8561
V Predictions Min            245.1047
Log Pis Mean                 -0.17801157
Log Pis Std                  2.638937
Log Pis Max                  8.55203
Log Pis Min                  -7.639982
Policy mu Mean               0.00860361
Policy mu Std                0.60105586
Policy mu Max                2.5836592
Policy mu Min                -2.1887789
Policy log std Mean          -0.9613313
Policy log std Std           0.23998228
Policy log std Max           -0.19564098
Policy log std Min           -1.9142609
Z mean eval                  0.99985063
Z variance eval              0.06744353
total_rewards                [ 793.98261554 2236.18512732 2221.11242933 2828.49000251  367.03952166
 1437.9207869  2375.30332597  724.79287795 1961.54096567 2202.73414213]
total_rewards_mean           1714.9101794989579
total_rewards_std            788.9781153529485
total_rewards_max            2828.490002512055
total_rewards_min            367.0395216575558
Number of train steps total  1616000
Number of env steps total    2800541
Number of rollouts total     0
Train Time (s)               155.30553232412785
(Previous) Eval Time (s)     17.88006603671238
Sample Time (s)              12.15343527821824
Epoch Time (s)               185.33903363905847
Total Train Time (s)         74906.97159647476
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:44:20.479349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #403 | Epoch Duration: 185.44824385643005
2020-01-12 22:44:20.479694 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9951867
Z variance train             0.0671704
KL Divergence                13.088654
KL Loss                      1.3088654
QF Loss                      10907.98
VF Loss                      179.60635
Policy Loss                  -1127.7733
Q Predictions Mean           1123.8661
Q Predictions Std            238.03366
Q Predictions Max            1394.6606
Q Predictions Min            269.59677
V Predictions Mean           1133.7765
V Predictions Std            239.5595
V Predictions Max            1407.4987
V Predictions Min            253.63474
Log Pis Mean                 0.60773814
Log Pis Std                  2.831966
Log Pis Max                  8.758132
Log Pis Min                  -7.715802
Policy mu Mean               -0.036970604
Policy mu Std                0.63161445
Policy mu Max                2.3540518
Policy mu Min                -2.4532053
Policy log std Mean          -1.0426514
Policy log std Std           0.27334702
Policy log std Max           -0.2276454
Policy log std Min           -2.5089803
Z mean eval                  0.96793497
Z variance eval              0.11342861
total_rewards                [ 348.31401314  261.36719766 1362.35822751  702.67641559   43.27808306
 2626.20818599 1373.01046787  868.1609487  1101.77214074 1423.31642187]
total_rewards_mean           1011.0462102155718
total_rewards_std            713.7716897028516
total_rewards_max            2626.2081859870286
total_rewards_min            43.278083064953975
Number of train steps total  1620000
Number of env steps total    2811847
Number of rollouts total     0
Train Time (s)               154.24752862704918
(Previous) Eval Time (s)     24.278809285722673
Sample Time (s)              12.658774298150092
Epoch Time (s)               191.18511221092194
Total Train Time (s)         75098.28046153439
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:47:31.792108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #404 | Epoch Duration: 191.31222677230835
2020-01-12 22:47:31.792312 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96862423
Z variance train             0.113956906
KL Divergence                11.860609
KL Loss                      1.1860609
QF Loss                      297.4188
VF Loss                      85.46145
Policy Loss                  -1102.836
Q Predictions Mean           1100.2141
Q Predictions Std            256.9236
Q Predictions Max            1385.3191
Q Predictions Min            255.75063
V Predictions Mean           1108.8566
V Predictions Std            257.95032
V Predictions Max            1376.1711
V Predictions Min            256.6523
Log Pis Mean                 0.013633788
Log Pis Std                  2.6297765
Log Pis Max                  9.77361
Log Pis Min                  -6.740343
Policy mu Mean               0.02846745
Policy mu Std                0.6115846
Policy mu Max                2.333548
Policy mu Min                -2.2424855
Policy log std Mean          -1.0006111
Policy log std Std           0.23717676
Policy log std Max           -0.32820326
Policy log std Min           -2.0433674
Z mean eval                  0.91901225
Z variance eval              0.16683103
total_rewards                [3546.65884597 3628.54032286  186.09779538  556.28847425 1307.11160748
 2217.35139105 1073.68684026  792.00759249 1140.31155837 3697.53641744]
total_rewards_mean           1814.5590845566742
total_rewards_std            1286.0905799633229
total_rewards_max            3697.5364174439096
total_rewards_min            186.09779537804408
Number of train steps total  1624000
Number of env steps total    2822349
Number of rollouts total     0
Train Time (s)               153.57601160695776
(Previous) Eval Time (s)     17.195209776982665
Sample Time (s)              11.853267888072878
Epoch Time (s)               182.6244892720133
Total Train Time (s)         75281.01079714531
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:50:34.527569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #405 | Epoch Duration: 182.73506140708923
2020-01-12 22:50:34.527961 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9224512
Z variance train             0.16524322
KL Divergence                11.073491
KL Loss                      1.1073492
QF Loss                      297.77917
VF Loss                      77.81245
Policy Loss                  -1090.1626
Q Predictions Mean           1083.5923
Q Predictions Std            264.31128
Q Predictions Max            1376.3551
Q Predictions Min            226.86063
V Predictions Mean           1086.0227
V Predictions Std            264.49088
V Predictions Max            1356.8654
V Predictions Min            233.3221
Log Pis Mean                 0.34929535
Log Pis Std                  2.946172
Log Pis Max                  14.444134
Log Pis Min                  -9.192203
Policy mu Mean               -0.04804992
Policy mu Std                0.6349948
Policy mu Max                2.8160708
Policy mu Min                -2.7157536
Policy log std Mean          -1.0110204
Policy log std Std           0.25489193
Policy log std Max           -0.36340022
Policy log std Min           -2.1150951
Z mean eval                  0.8976551
Z variance eval              0.030966219
total_rewards                [ 264.69435297 3550.71243214  867.79395093 3423.66968768 2596.75690742
 3402.50018754 1170.02350054 2050.93565538 3228.03999137 2515.7243398 ]
total_rewards_mean           2307.085100575285
total_rewards_std            1121.1754051588455
total_rewards_max            3550.712432141842
total_rewards_min            264.6943529659498
Number of train steps total  1628000
Number of env steps total    2833321
Number of rollouts total     0
Train Time (s)               155.25630477862433
(Previous) Eval Time (s)     25.332323462236673
Sample Time (s)              12.373795459978282
Epoch Time (s)               192.96242370083928
Total Train Time (s)         75474.05881913286
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:53:47.579754 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #406 | Epoch Duration: 193.05157279968262
2020-01-12 22:53:47.579943 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8947837
Z variance train             0.030984676
KL Divergence                14.755705
KL Loss                      1.4755706
QF Loss                      528.7195
VF Loss                      477.5897
Policy Loss                  -1139.3326
Q Predictions Mean           1135.4032
Q Predictions Std            254.12444
Q Predictions Max            1412.0695
Q Predictions Min            277.36203
V Predictions Mean           1152.1984
V Predictions Std            257.19504
V Predictions Max            1449.6276
V Predictions Min            281.19415
Log Pis Mean                 0.28647125
Log Pis Std                  2.777952
Log Pis Max                  12.715866
Log Pis Min                  -8.155733
Policy mu Mean               -0.03230661
Policy mu Std                0.6354558
Policy mu Max                3.687905
Policy mu Min                -2.3128486
Policy log std Mean          -0.9968655
Policy log std Std           0.24307819
Policy log std Max           -0.38620698
Policy log std Min           -2.792676
Z mean eval                  1.0709819
Z variance eval              0.047082882
total_rewards                [ 275.60256128 2661.06927249 3526.05804792 3628.6359954  1863.78582971
 2350.35984902 3449.76277306 3421.78625558 1701.79787593 2592.49938589]
total_rewards_mean           2547.1357846282185
total_rewards_std            1005.1301617405643
total_rewards_max            3628.635995401435
total_rewards_min            275.60256128057426
Number of train steps total  1632000
Number of env steps total    2842802
Number of rollouts total     0
Train Time (s)               149.71840478712693
(Previous) Eval Time (s)     33.30803974997252
Sample Time (s)              12.469655907712877
Epoch Time (s)               195.49610044481233
Total Train Time (s)         75669.65465013077
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:57:03.180401 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #407 | Epoch Duration: 195.60028958320618
2020-01-12 22:57:03.180706 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0744317
Z variance train             0.04724563
KL Divergence                14.240313
KL Loss                      1.4240313
QF Loss                      1197.5608
VF Loss                      125.07004
Policy Loss                  -1118.8112
Q Predictions Mean           1117.172
Q Predictions Std            245.77513
Q Predictions Max            1428.6791
Q Predictions Min            260.77655
V Predictions Mean           1117.1123
V Predictions Std            247.24763
V Predictions Max            1428.1104
V Predictions Min            252.12679
Log Pis Mean                 0.3257307
Log Pis Std                  2.7005377
Log Pis Max                  8.7645855
Log Pis Min                  -6.417373
Policy mu Mean               0.009924113
Policy mu Std                0.59032536
Policy mu Max                1.9669101
Policy mu Min                -2.416938
Policy log std Mean          -1.0206088
Policy log std Std           0.2427495
Policy log std Max           -0.32574695
Policy log std Min           -2.3355055
Z mean eval                  0.9617669
Z variance eval              0.12487692
total_rewards                [3189.10920566 2817.49953045 2838.24247712 3331.55012212 3585.69928221
 3279.23912338 3288.85844171  205.7073408  3514.5764711   852.52669581]
total_rewards_mean           2690.300869034967
total_rewards_std            1115.1225723733403
total_rewards_max            3585.6992822144816
total_rewards_min            205.70734079742
Number of train steps total  1636000
Number of env steps total    2853449
Number of rollouts total     0
Train Time (s)               145.26164772268385
(Previous) Eval Time (s)     31.03256217110902
Sample Time (s)              12.375348755158484
Epoch Time (s)               188.66955864895135
Total Train Time (s)         75858.41937488224
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:00:11.949757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #408 | Epoch Duration: 188.76884293556213
2020-01-12 23:00:11.949979 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9601151
Z variance train             0.12591115
KL Divergence                13.169754
KL Loss                      1.3169755
QF Loss                      340.62408
VF Loss                      125.739204
Policy Loss                  -1135.4832
Q Predictions Mean           1131.0964
Q Predictions Std            250.48923
Q Predictions Max            1469.1925
Q Predictions Min            246.37955
V Predictions Mean           1143.3827
V Predictions Std            251.26245
V Predictions Max            1472.8507
V Predictions Min            256.1241
Log Pis Mean                 -0.114337206
Log Pis Std                  2.5759127
Log Pis Max                  6.9330554
Log Pis Min                  -8.135688
Policy mu Mean               -0.044684157
Policy mu Std                0.6074054
Policy mu Max                2.1647186
Policy mu Min                -2.1162004
Policy log std Mean          -0.98894846
Policy log std Std           0.23348011
Policy log std Max           -0.28121656
Policy log std Min           -1.9776442
Z mean eval                  0.91608846
Z variance eval              0.44213247
total_rewards                [1700.93657154  943.03297896  186.431378    774.78496827 2816.96313517
  438.0808013  3521.71094282  738.03293285  267.16388745 3539.50339091]
total_rewards_mean           1492.6640987278574
total_rewards_std            1257.4132643830633
total_rewards_max            3539.503390914507
total_rewards_min            186.4313779990299
Number of train steps total  1640000
Number of env steps total    2865629
Number of rollouts total     0
Train Time (s)               149.19044243684039
(Previous) Eval Time (s)     22.468032172881067
Sample Time (s)              12.16423610644415
Epoch Time (s)               183.8227107161656
Total Train Time (s)         76042.34692145744
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:03:15.882465 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #409 | Epoch Duration: 183.93229269981384
2020-01-12 23:03:15.882835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91781473
Z variance train             0.44250083
KL Divergence                12.993185
KL Loss                      1.2993186
QF Loss                      549.1829
VF Loss                      65.68995
Policy Loss                  -1066.0754
Q Predictions Mean           1059.8691
Q Predictions Std            277.3792
Q Predictions Max            1376.1335
Q Predictions Min            82.84005
V Predictions Mean           1063.5579
V Predictions Std            276.3486
V Predictions Max            1378.7655
V Predictions Min            238.363
Log Pis Mean                 0.1278583
Log Pis Std                  2.8460991
Log Pis Max                  8.735104
Log Pis Min                  -7.2958465
Policy mu Mean               -0.049363583
Policy mu Std                0.6347301
Policy mu Max                2.7696152
Policy mu Min                -2.4635923
Policy log std Mean          -1.0046574
Policy log std Std           0.24940802
Policy log std Max           -0.055687487
Policy log std Min           -1.8322968
Z mean eval                  1.0285044
Z variance eval              0.048641898
total_rewards                [ 655.94592462 1230.36468115 1292.4201732  3573.88711571 1557.31040691
 1207.25662127 1729.05681474 3349.77316769  856.34686485  232.47790882]
total_rewards_mean           1568.4839678947394
total_rewards_std            1032.7797285385213
total_rewards_max            3573.887115705783
total_rewards_min            232.47790881562062
Number of train steps total  1644000
Number of env steps total    2876780
Number of rollouts total     0
Train Time (s)               156.4626654391177
(Previous) Eval Time (s)     20.86139238020405
Sample Time (s)              12.670436256565154
Epoch Time (s)               189.9944940758869
Total Train Time (s)         76232.43508755323
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:06:25.980185 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #410 | Epoch Duration: 190.09709429740906
2020-01-12 23:06:25.980372 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.030714
Z variance train             0.049184132
KL Divergence                14.808832
KL Loss                      1.4808832
QF Loss                      473.5301
VF Loss                      216.80856
Policy Loss                  -1111.8079
Q Predictions Mean           1109.2306
Q Predictions Std            266.4902
Q Predictions Max            1405.4764
Q Predictions Min            271.32703
V Predictions Mean           1108.5884
V Predictions Std            268.42447
V Predictions Max            1389.0045
V Predictions Min            266.9193
Log Pis Mean                 0.05537325
Log Pis Std                  2.7108533
Log Pis Max                  11.562965
Log Pis Min                  -7.067201
Policy mu Mean               -0.0021542334
Policy mu Std                0.5933053
Policy mu Max                2.7744179
Policy mu Min                -2.29037
Policy log std Mean          -1.0341716
Policy log std Std           0.2582155
Policy log std Max           -0.3456753
Policy log std Min           -2.4645362
Z mean eval                  0.99262553
Z variance eval              0.12271931
total_rewards                [3539.07750028  573.9709319  1111.42306124  883.69375163 3506.03086208
 2529.10436584  688.14550423  403.2573191  3632.35451132 1595.4765638 ]
total_rewards_mean           1846.253437142351
total_rewards_std            1258.9081487900046
total_rewards_max            3632.354511323655
total_rewards_min            403.25731910484444
Number of train steps total  1648000
Number of env steps total    2885562
Number of rollouts total     0
Train Time (s)               154.97096049180254
(Previous) Eval Time (s)     28.37504075979814
Sample Time (s)              12.481939830817282
Epoch Time (s)               195.82794108241796
Total Train Time (s)         76428.36178417504
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:09:41.905379 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #411 | Epoch Duration: 195.92485857009888
2020-01-12 23:09:41.905580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9813365
Z variance train             0.121252455
KL Divergence                13.449715
KL Loss                      1.3449715
QF Loss                      532.7234
VF Loss                      81.20479
Policy Loss                  -1137.9982
Q Predictions Mean           1131.762
Q Predictions Std            234.05363
Q Predictions Max            1386.2443
Q Predictions Min            234.01302
V Predictions Mean           1138.1761
V Predictions Std            226.74721
V Predictions Max            1384.9797
V Predictions Min            246.45314
Log Pis Mean                 0.29241198
Log Pis Std                  3.2592454
Log Pis Max                  20.39815
Log Pis Min                  -8.491224
Policy mu Mean               -0.0002097683
Policy mu Std                0.653706
Policy mu Max                2.5051858
Policy mu Min                -3.4662309
Policy log std Mean          -1.038216
Policy log std Std           0.2538892
Policy log std Max           -0.0014657974
Policy log std Min           -2.5656834
Z mean eval                  0.93996847
Z variance eval              0.03801196
total_rewards                [2581.09940811  317.71482886 1567.70400598 1316.36500947  327.24536961
  280.45085401 2479.10976161 2866.92640999 1604.22874915 2304.65759842]
total_rewards_mean           1564.550199522468
total_rewards_std            943.9993260979458
total_rewards_max            2866.9264099921243
total_rewards_min            280.4508540116959
Number of train steps total  1652000
Number of env steps total    2896280
Number of rollouts total     0
Train Time (s)               156.22157031297684
(Previous) Eval Time (s)     20.141460770275444
Sample Time (s)              11.845009332057089
Epoch Time (s)               188.20804041530937
Total Train Time (s)         76616.65605483018
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:12:50.204304 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #412 | Epoch Duration: 188.29855823516846
2020-01-12 23:12:50.204578 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93888694
Z variance train             0.037969418
KL Divergence                15.792183
KL Loss                      1.5792183
QF Loss                      223.38094
VF Loss                      77.17287
Policy Loss                  -1103.386
Q Predictions Mean           1097.8545
Q Predictions Std            280.6521
Q Predictions Max            1405.646
Q Predictions Min            240.47903
V Predictions Mean           1104.4805
V Predictions Std            279.41064
V Predictions Max            1404.4865
V Predictions Min            255.054
Log Pis Mean                 0.653453
Log Pis Std                  2.8503866
Log Pis Max                  14.518463
Log Pis Min                  -6.3638716
Policy mu Mean               0.04155583
Policy mu Std                0.6321641
Policy mu Max                2.354663
Policy mu Min                -2.3572078
Policy log std Mean          -1.0101911
Policy log std Std           0.2652387
Policy log std Max           -0.26677734
Policy log std Min           -2.1763558
Z mean eval                  0.9775872
Z variance eval              0.03423094
total_rewards                [  65.68692063 1811.92750796 1934.87599718 2888.55726276 3670.91357593
  529.17892236 3378.94840373 3621.11538715 2021.86487699 3524.77916245]
total_rewards_mean           2344.784801715317
total_rewards_std            1232.564728024452
total_rewards_max            3670.9135759330934
total_rewards_min            65.68692062591875
Number of train steps total  1656000
Number of env steps total    2907378
Number of rollouts total     0
Train Time (s)               154.4405668983236
(Previous) Eval Time (s)     25.940056776162237
Sample Time (s)              11.924338568933308
Epoch Time (s)               192.30496224341914
Total Train Time (s)         76809.08524649125
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:16:02.637498 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #413 | Epoch Duration: 192.43275451660156
2020-01-12 23:16:02.637681 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9763341
Z variance train             0.03469326
KL Divergence                15.818953
KL Loss                      1.5818952
QF Loss                      814.0257
VF Loss                      98.67848
Policy Loss                  -1117.7451
Q Predictions Mean           1114.588
Q Predictions Std            246.31499
Q Predictions Max            1392.5452
Q Predictions Min            216.07573
V Predictions Mean           1124.8542
V Predictions Std            244.58707
V Predictions Max            1398.632
V Predictions Min            214.90994
Log Pis Mean                 0.3692861
Log Pis Std                  2.6423647
Log Pis Max                  13.655827
Log Pis Min                  -8.848842
Policy mu Mean               -0.013784019
Policy mu Std                0.6082532
Policy mu Max                2.2851787
Policy mu Min                -2.327499
Policy log std Mean          -1.0372182
Policy log std Std           0.24324411
Policy log std Max           -0.43578017
Policy log std Min           -2.4553428
Z mean eval                  0.96539986
Z variance eval              0.11309256
total_rewards                [1280.19568814  528.10572786  464.84137697 1400.6954481  3695.05999538
 3363.44526615 3766.87252798  857.52271537 1313.05984461 2514.0193903 ]
total_rewards_mean           1918.381798086118
total_rewards_std            1234.0689040383274
total_rewards_max            3766.8725279830137
total_rewards_min            464.8413769671108
Number of train steps total  1660000
Number of env steps total    2917816
Number of rollouts total     0
Train Time (s)               146.40055381366983
(Previous) Eval Time (s)     27.70593979768455
Sample Time (s)              11.897097694687545
Epoch Time (s)               186.00359130604193
Total Train Time (s)         76995.17955479398
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:19:08.737184 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #414 | Epoch Duration: 186.09934830665588
2020-01-12 23:19:08.737466 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9808518
Z variance train             0.11348933
KL Divergence                13.936327
KL Loss                      1.3936328
QF Loss                      11997.734
VF Loss                      583.7556
Policy Loss                  -1129.3893
Q Predictions Mean           1126.9924
Q Predictions Std            298.98288
Q Predictions Max            1423.6437
Q Predictions Min            -61.910023
V Predictions Mean           1141.8
V Predictions Std            293.07956
V Predictions Max            1446.797
V Predictions Min            272.99783
Log Pis Mean                 -0.09113977
Log Pis Std                  2.7416208
Log Pis Max                  11.3121
Log Pis Min                  -6.6643248
Policy mu Mean               -0.0057623424
Policy mu Std                0.58706945
Policy mu Max                1.9015441
Policy mu Min                -2.2217615
Policy log std Mean          -0.9968153
Policy log std Std           0.24928959
Policy log std Max           -0.39214644
Policy log std Min           -2.1489372
Z mean eval                  1.0014805
Z variance eval              0.08682105
total_rewards                [1813.81628661 3661.01490955 3039.97556733 1026.90080857 3483.00615876
 3571.96476327 3324.01641917  484.12052581  721.16370613 1863.90089278]
total_rewards_mean           2298.9880037980915
total_rewards_std            1195.9683789119488
total_rewards_max            3661.014909545657
total_rewards_min            484.1205258144153
Number of train steps total  1664000
Number of env steps total    2927820
Number of rollouts total     0
Train Time (s)               146.33085096813738
(Previous) Eval Time (s)     25.65144157782197
Sample Time (s)              12.288505043834448
Epoch Time (s)               184.2707975897938
Total Train Time (s)         77179.54220879357
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:22:13.106052 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #415 | Epoch Duration: 184.36837196350098
2020-01-12 23:22:13.106445 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0033443
Z variance train             0.086709544
KL Divergence                13.382925
KL Loss                      1.3382925
QF Loss                      5973.668
VF Loss                      132.66737
Policy Loss                  -1151.376
Q Predictions Mean           1147.8347
Q Predictions Std            238.32567
Q Predictions Max            1436.6492
Q Predictions Min            287.1265
V Predictions Mean           1145.1038
V Predictions Std            238.05464
V Predictions Max            1428.0895
V Predictions Min            279.99988
Log Pis Mean                 0.39423037
Log Pis Std                  2.4105456
Log Pis Max                  10.938554
Log Pis Min                  -5.5451455
Policy mu Mean               -0.020453546
Policy mu Std                0.60021275
Policy mu Max                2.0858054
Policy mu Min                -2.4451127
Policy log std Mean          -1.0485405
Policy log std Std           0.24691488
Policy log std Max           -0.2796077
Policy log std Min           -2.1091938
Z mean eval                  0.94014883
Z variance eval              0.0538132
total_rewards                [3313.2100572  3568.07461015 1759.60809659  497.1475296  3261.9194939
 2472.70486384 3345.405805    336.61358552 3593.97064783 3291.90896568]
total_rewards_mean           2544.0563655314404
total_rewards_std            1189.2179029386816
total_rewards_max            3593.9706478267044
total_rewards_min            336.6135855232684
Number of train steps total  1668000
Number of env steps total    2937247
Number of rollouts total     0
Train Time (s)               152.14923598291352
(Previous) Eval Time (s)     28.21739216800779
Sample Time (s)              11.411131941713393
Epoch Time (s)               191.7777600926347
Total Train Time (s)         77371.41717532929
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:25:24.984537 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #416 | Epoch Duration: 191.8778612613678
2020-01-12 23:25:24.984743 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93462926
Z variance train             0.053497832
KL Divergence                14.47287
KL Loss                      1.447287
QF Loss                      1172.7744
VF Loss                      98.05417
Policy Loss                  -1187.1371
Q Predictions Mean           1183.8271
Q Predictions Std            247.37619
Q Predictions Max            1442.896
Q Predictions Min            239.02603
V Predictions Mean           1192.858
V Predictions Std            248.6508
V Predictions Max            1446.9886
V Predictions Min            235.69289
Log Pis Mean                 0.52888155
Log Pis Std                  2.3745725
Log Pis Max                  8.82132
Log Pis Min                  -6.3358903
Policy mu Mean               0.0035130354
Policy mu Std                0.6243371
Policy mu Max                2.253912
Policy mu Min                -1.9903983
Policy log std Mean          -1.0403506
Policy log std Std           0.24515699
Policy log std Max           0.1843695
Policy log std Min           -2.0060644
Z mean eval                  0.9788097
Z variance eval              0.14469256
total_rewards                [1328.72523392 -316.67531722 3721.29745752 2716.01695022 2442.95169574
 1211.06993488 3573.46504769   12.99061928 -211.35642787  674.99675296]
total_rewards_mean           1515.348194712543
total_rewards_std            1443.3506873613103
total_rewards_max            3721.2974575171947
total_rewards_min            -316.6753172181087
Number of train steps total  1672000
Number of env steps total    2948457
Number of rollouts total     0
Train Time (s)               155.58559090038761
(Previous) Eval Time (s)     24.709924592636526
Sample Time (s)              11.128868691623211
Epoch Time (s)               191.42438418464735
Total Train Time (s)         77562.9293186781
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:28:36.502534 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #417 | Epoch Duration: 191.51761770248413
2020-01-12 23:28:36.502867 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97554
Z variance train             0.14622626
KL Divergence                12.459871
KL Loss                      1.2459872
QF Loss                      891.2073
VF Loss                      607.66473
Policy Loss                  -1148.7587
Q Predictions Mean           1143.5559
Q Predictions Std            260.70364
Q Predictions Max            1474.4816
Q Predictions Min            280.76135
V Predictions Mean           1150.4082
V Predictions Std            259.67017
V Predictions Max            1467.2919
V Predictions Min            285.5934
Log Pis Mean                 0.4532717
Log Pis Std                  2.8817914
Log Pis Max                  11.340348
Log Pis Min                  -7.4647546
Policy mu Mean               -0.053833194
Policy mu Std                0.6368782
Policy mu Max                2.1656823
Policy mu Min                -2.760436
Policy log std Mean          -1.0445852
Policy log std Std           0.2530295
Policy log std Max           -0.34330106
Policy log std Min           -2.15167
Z mean eval                  0.96132267
Z variance eval              0.055261202
total_rewards                [3326.83219334 3553.79176839 3571.36051218 1386.51936289 3501.12304109
 1660.02986527 1139.00322646 3557.36861396 3461.88036551 3473.39805436]
total_rewards_mean           2863.13070034505
total_rewards_std            970.257562290747
total_rewards_max            3571.360512175293
total_rewards_min            1139.0032264609222
Number of train steps total  1676000
Number of env steps total    2960826
Number of rollouts total     0
Train Time (s)               154.02694790810347
(Previous) Eval Time (s)     33.10198389785364
Sample Time (s)              12.944504613988101
Epoch Time (s)               200.0734364199452
Total Train Time (s)         77763.09640218224
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:31:56.673701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #418 | Epoch Duration: 200.17065978050232
2020-01-12 23:31:56.673889 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9667107
Z variance train             0.055029847
KL Divergence                13.852278
KL Loss                      1.3852278
QF Loss                      447.9926
VF Loss                      417.41043
Policy Loss                  -1155.5292
Q Predictions Mean           1143.9087
Q Predictions Std            229.27063
Q Predictions Max            1432.1268
Q Predictions Min            1.2719038
V Predictions Mean           1150.2598
V Predictions Std            218.70435
V Predictions Max            1421.3433
V Predictions Min            260.0745
Log Pis Mean                 0.831768
Log Pis Std                  2.632288
Log Pis Max                  13.286062
Log Pis Min                  -7.7046146
Policy mu Mean               -0.026334967
Policy mu Std                0.6615259
Policy mu Max                3.2142792
Policy mu Min                -2.7300775
Policy log std Mean          -1.0354618
Policy log std Std           0.23140714
Policy log std Max           -0.35268253
Policy log std Min           -2.1777983
Z mean eval                  0.92990905
Z variance eval              0.06700621
total_rewards                [1443.46589633  346.79026289  121.79793502 1537.68761218 3665.72966431
 1282.52226354 1753.86939298 3136.08353124 1088.08324897 1803.02899711]
total_rewards_mean           1617.9058804584452
total_rewards_std            1040.9291350372512
total_rewards_max            3665.7296643112318
total_rewards_min            121.79793502108353
Number of train steps total  1680000
Number of env steps total    2971415
Number of rollouts total     0
Train Time (s)               157.02904765168205
(Previous) Eval Time (s)     21.9490875499323
Sample Time (s)              12.10880900034681
Epoch Time (s)               191.08694420196116
Total Train Time (s)         77954.29188972339
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:35:07.873849 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #419 | Epoch Duration: 191.1998131275177
2020-01-12 23:35:07.874059 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9317854
Z variance train             0.06719952
KL Divergence                13.330717
KL Loss                      1.3330717
QF Loss                      709.58704
VF Loss                      120.28067
Policy Loss                  -1151.686
Q Predictions Mean           1145.8877
Q Predictions Std            226.4775
Q Predictions Max            1449.1167
Q Predictions Min            264.9384
V Predictions Mean           1148.8594
V Predictions Std            225.44844
V Predictions Max            1442.5426
V Predictions Min            261.7763
Log Pis Mean                 0.31691954
Log Pis Std                  2.5369132
Log Pis Max                  10.313698
Log Pis Min                  -8.334292
Policy mu Mean               -0.037496664
Policy mu Std                0.62106645
Policy mu Max                2.0924127
Policy mu Min                -2.1578765
Policy log std Mean          -1.0222551
Policy log std Std           0.23695107
Policy log std Max           -0.19348669
Policy log std Min           -2.214044
Z mean eval                  0.9527197
Z variance eval              0.058262367
total_rewards                [ 502.76150765  465.5139358  1551.56202861  312.89762374 1460.04147224
 2384.48292916 1760.53847505 1483.99366854  428.66400642  574.7776455 ]
total_rewards_mean           1092.5233292697092
total_rewards_std            683.5191878971808
total_rewards_max            2384.4829291570522
total_rewards_min            312.8976237403235
Number of train steps total  1684000
Number of env steps total    2983311
Number of rollouts total     0
Train Time (s)               154.2000241712667
(Previous) Eval Time (s)     17.31940729310736
Sample Time (s)              12.428962695877999
Epoch Time (s)               183.94839416025206
Total Train Time (s)         78138.33051297581
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:38:11.916685 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #420 | Epoch Duration: 184.0424680709839
2020-01-12 23:38:11.916886 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95706254
Z variance train             0.058393247
KL Divergence                14.347567
KL Loss                      1.4347566
QF Loss                      12116.185
VF Loss                      57.347923
Policy Loss                  -1218.0854
Q Predictions Mean           1213.0481
Q Predictions Std            234.0186
Q Predictions Max            1474.0493
Q Predictions Min            275.32767
V Predictions Mean           1220.0642
V Predictions Std            230.79369
V Predictions Max            1467.6558
V Predictions Min            293.32312
Log Pis Mean                 0.37548903
Log Pis Std                  2.6572902
Log Pis Max                  8.689292
Log Pis Min                  -8.92867
Policy mu Mean               -0.013387449
Policy mu Std                0.63379306
Policy mu Max                2.6898124
Policy mu Min                -2.1357923
Policy log std Mean          -1.0273833
Policy log std Std           0.22961617
Policy log std Max           -0.059039235
Policy log std Min           -2.0568032
Z mean eval                  1.0072119
Z variance eval              0.05061982
total_rewards                [ 849.58427116 2088.92882596 2547.73053585  423.79622474 2780.5587011
   73.29498246 2914.77643394   23.74985908  769.08315936 1538.41000671]
total_rewards_mean           1400.9913000356041
total_rewards_std            1063.9428454811136
total_rewards_max            2914.7764339403484
total_rewards_min            23.749859080006104
Number of train steps total  1688000
Number of env steps total    2993925
Number of rollouts total     0
Train Time (s)               146.12910269619897
(Previous) Eval Time (s)     20.916786100249738
Sample Time (s)              11.600009799934924
Epoch Time (s)               178.64589859638363
Total Train Time (s)         78317.07772767125
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:41:10.668626 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #421 | Epoch Duration: 178.7515950202942
2020-01-12 23:41:10.668822 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0058415
Z variance train             0.05102859
KL Divergence                14.169016
KL Loss                      1.4169016
QF Loss                      670.25354
VF Loss                      195.3543
Policy Loss                  -1263.5905
Q Predictions Mean           1256.3041
Q Predictions Std            174.06877
Q Predictions Max            1501.2533
Q Predictions Min            335.6498
V Predictions Mean           1262.5068
V Predictions Std            173.9047
V Predictions Max            1516.206
V Predictions Min            339.58817
Log Pis Mean                 0.7205797
Log Pis Std                  2.7707295
Log Pis Max                  15.975512
Log Pis Min                  -4.7889795
Policy mu Mean               -0.025922654
Policy mu Std                0.6541232
Policy mu Max                2.6182942
Policy mu Min                -2.493511
Policy log std Mean          -1.0525906
Policy log std Std           0.26709655
Policy log std Max           -0.27882516
Policy log std Min           -3.087914
Z mean eval                  1.1191959
Z variance eval              0.034593157
total_rewards                [3220.40498382 3256.24117627 3442.2948704   178.6247844  3208.95488437
 1521.09226275 3469.56633204 2050.82009506 3335.9007756  3258.86255959]
total_rewards_mean           2694.2762724286545
total_rewards_std            1042.470872870973
total_rewards_max            3469.566332039657
total_rewards_min            178.62478439932343
Number of train steps total  1692000
Number of env steps total    3003671
Number of rollouts total     0
Train Time (s)               145.54209599411115
(Previous) Eval Time (s)     30.009150844998658
Sample Time (s)              12.392041468527168
Epoch Time (s)               187.94328830763698
Total Train Time (s)         78505.1280228938
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:44:18.723838 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #422 | Epoch Duration: 188.0548496246338
2020-01-12 23:44:18.724184 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1163948
Z variance train             0.03445415
KL Divergence                15.157558
KL Loss                      1.5157559
QF Loss                      445.02435
VF Loss                      106.93751
Policy Loss                  -1172.2549
Q Predictions Mean           1165.1165
Q Predictions Std            202.4522
Q Predictions Max            1433.0253
Q Predictions Min            248.19629
V Predictions Mean           1165.2792
V Predictions Std            201.1939
V Predictions Max            1426.3633
V Predictions Min            255.40295
Log Pis Mean                 0.53747827
Log Pis Std                  2.3951132
Log Pis Max                  8.124689
Log Pis Min                  -8.122932
Policy mu Mean               -0.02162935
Policy mu Std                0.6251301
Policy mu Max                2.1415224
Policy mu Min                -2.3655753
Policy log std Mean          -1.0537205
Policy log std Std           0.24894582
Policy log std Max           -0.37253183
Policy log std Min           -2.093804
Z mean eval                  0.87028134
Z variance eval              0.13345876
total_rewards                [3560.58827022 3637.27735658 3287.36141513 2280.34675628 2358.80071717
 3632.54752531 2400.03869319 2540.22072184 1249.90077743 3625.77248055]
total_rewards_mean           2857.2854713701554
total_rewards_std            771.6363507391436
total_rewards_max            3637.2773565802318
total_rewards_min            1249.9007774309878
Number of train steps total  1696000
Number of env steps total    3015546
Number of rollouts total     0
Train Time (s)               155.595994703006
(Previous) Eval Time (s)     31.420724655035883
Sample Time (s)              11.636585192289203
Epoch Time (s)               198.6533045503311
Total Train Time (s)         78703.86780468235
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:47:37.467630 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #423 | Epoch Duration: 198.7432713508606
2020-01-12 23:47:37.467823 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87109995
Z variance train             0.13303182
KL Divergence                11.751453
KL Loss                      1.1751454
QF Loss                      421.2157
VF Loss                      182.49414
Policy Loss                  -1112.5775
Q Predictions Mean           1106.6521
Q Predictions Std            210.12311
Q Predictions Max            1347.8068
Q Predictions Min            243.56503
V Predictions Mean           1112.6981
V Predictions Std            206.26828
V Predictions Max            1359.7062
V Predictions Min            238.42737
Log Pis Mean                 0.48114467
Log Pis Std                  2.6486886
Log Pis Max                  14.617708
Log Pis Min                  -10.96224
Policy mu Mean               -0.01722417
Policy mu Std                0.6143338
Policy mu Max                3.2675445
Policy mu Min                -2.030616
Policy log std Mean          -1.0553669
Policy log std Std           0.25339755
Policy log std Max           -0.35937053
Policy log std Min           -2.5574193
Z mean eval                  1.0171025
Z variance eval              0.08371123
total_rewards                [3372.82860509 3524.17505052 2175.36032864  318.31975223 3289.00455232
  183.50361934 1401.09867369 3322.89899059 3647.39074883 3328.24266113]
total_rewards_mean           2456.282298238157
total_rewards_std            1285.7952219653328
total_rewards_max            3647.3907488261048
total_rewards_min            183.5036193415989
Number of train steps total  1700000
Number of env steps total    3026798
Number of rollouts total     0
Train Time (s)               155.14173313369974
(Previous) Eval Time (s)     35.93969185091555
Sample Time (s)              12.449007394257933
Epoch Time (s)               203.53043237887323
Total Train Time (s)         78907.48523473041
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:51:01.089811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #424 | Epoch Duration: 203.62184238433838
2020-01-12 23:51:01.090005 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0236164
Z variance train             0.08392816
KL Divergence                13.732601
KL Loss                      1.3732601
QF Loss                      496.17395
VF Loss                      56.985317
Policy Loss                  -1163.4974
Q Predictions Mean           1158.572
Q Predictions Std            205.52855
Q Predictions Max            1448.292
Q Predictions Min            279.03345
V Predictions Mean           1163.5999
V Predictions Std            205.74306
V Predictions Max            1451.171
V Predictions Min            274.63266
Log Pis Mean                 0.59927857
Log Pis Std                  2.5883765
Log Pis Max                  11.363991
Log Pis Min                  -7.7232056
Policy mu Mean               -0.023274342
Policy mu Std                0.61571944
Policy mu Max                2.1281343
Policy mu Min                -2.2544854
Policy log std Mean          -1.0759804
Policy log std Std           0.26547685
Policy log std Max           -0.4057405
Policy log std Min           -2.454711
Z mean eval                  1.0099783
Z variance eval              0.085369304
total_rewards                [  76.42651294 3514.75409431  151.25424926 3373.63431745 3103.68810761
  510.42984882  173.12785569 3021.22969356  741.27085175 3535.65739713]
total_rewards_mean           1820.1472928528208
total_rewards_std            1507.8407858731741
total_rewards_max            3535.657397129925
total_rewards_min            76.42651293950611
Number of train steps total  1704000
Number of env steps total    3037016
Number of rollouts total     0
Train Time (s)               154.86620753398165
(Previous) Eval Time (s)     24.66052071703598
Sample Time (s)              11.876470991410315
Epoch Time (s)               191.40319924242795
Total Train Time (s)         79098.98617824493
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:54:12.594842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #425 | Epoch Duration: 191.50469255447388
2020-01-12 23:54:12.595071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0143175
Z variance train             0.084544435
KL Divergence                14.409606
KL Loss                      1.4409606
QF Loss                      689.2378
VF Loss                      75.74426
Policy Loss                  -1168.1779
Q Predictions Mean           1162.5793
Q Predictions Std            201.47043
Q Predictions Max            1474.8597
Q Predictions Min            283.8174
V Predictions Mean           1170.2682
V Predictions Std            200.10445
V Predictions Max            1476.1302
V Predictions Min            280.3267
Log Pis Mean                 0.7861075
Log Pis Std                  2.7513914
Log Pis Max                  14.63126
Log Pis Min                  -7.774294
Policy mu Mean               0.0060732807
Policy mu Std                0.64932805
Policy mu Max                3.2971606
Policy mu Min                -2.2114656
Policy log std Mean          -1.04215
Policy log std Std           0.25491902
Policy log std Max           -0.29622954
Policy log std Min           -2.4540052
Z mean eval                  0.96989965
Z variance eval              0.14316593
total_rewards                [3393.99601105  268.22294001 2709.33745123 3476.30885359 3570.73049233
 3469.53077236 2489.33909427 3363.9452226  3468.87272937 3134.32639514]
total_rewards_mean           2934.4609961951633
total_rewards_std            952.0266979888053
total_rewards_max            3570.730492330422
total_rewards_min            268.22294000927775
Number of train steps total  1708000
Number of env steps total    3049037
Number of rollouts total     0
Train Time (s)               155.7562835761346
(Previous) Eval Time (s)     35.50675132870674
Sample Time (s)              11.249402253422886
Epoch Time (s)               202.51243715826422
Total Train Time (s)         79301.59367261594
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:57:35.207279 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #426 | Epoch Duration: 202.61196851730347
2020-01-12 23:57:35.207524 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9763797
Z variance train             0.14425954
KL Divergence                14.298589
KL Loss                      1.4298589
QF Loss                      237.84128
VF Loss                      60.31724
Policy Loss                  -1172.0524
Q Predictions Mean           1166.1102
Q Predictions Std            232.39078
Q Predictions Max            1427.3695
Q Predictions Min            317.0342
V Predictions Mean           1173.0754
V Predictions Std            232.53331
V Predictions Max            1421.3008
V Predictions Min            325.1723
Log Pis Mean                 0.6104338
Log Pis Std                  2.6718748
Log Pis Max                  10.194658
Log Pis Min                  -8.594357
Policy mu Mean               -0.025258463
Policy mu Std                0.6324533
Policy mu Max                1.9558936
Policy mu Min                -2.250618
Policy log std Mean          -1.1022154
Policy log std Std           0.2641225
Policy log std Max           -0.029629588
Policy log std Min           -2.3733075
Z mean eval                  1.0839759
Z variance eval              0.034915395
total_rewards                [3349.77766345 1333.4854897  3547.91895731  288.00938292 3487.09579398
 1482.72638277  212.51049323   64.0341015   444.42269764 3474.28133274]
total_rewards_mean           1768.4262295233143
total_rewards_std            1451.6293251739933
total_rewards_max            3547.9189573148224
total_rewards_min            64.034101499614
Number of train steps total  1712000
Number of env steps total    3060918
Number of rollouts total     0
Train Time (s)               149.01528962608427
(Previous) Eval Time (s)     20.928842425812036
Sample Time (s)              12.67668198607862
Epoch Time (s)               182.62081403797492
Total Train Time (s)         79484.32797676232
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:00:37.944886 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #427 | Epoch Duration: 182.7372031211853
2020-01-13 00:00:37.945071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0838518
Z variance train             0.03514116
KL Divergence                15.416842
KL Loss                      1.5416843
QF Loss                      12578.203
VF Loss                      78.57794
Policy Loss                  -1198.9397
Q Predictions Mean           1196.0771
Q Predictions Std            195.529
Q Predictions Max            1498.3198
Q Predictions Min            306.61536
V Predictions Mean           1203.1086
V Predictions Std            194.88614
V Predictions Max            1477.2698
V Predictions Min            306.90765
Log Pis Mean                 0.7490258
Log Pis Std                  2.8873549
Log Pis Max                  15.550429
Log Pis Min                  -6.9714994
Policy mu Mean               -0.029559068
Policy mu Std                0.64631623
Policy mu Max                3.7271001
Policy mu Min                -3.795836
Policy log std Mean          -1.0807867
Policy log std Std           0.25712353
Policy log std Max           0.041532874
Policy log std Min           -2.2885866
Z mean eval                  0.8906825
Z variance eval              0.0396999
total_rewards                [3137.42443088 3604.12553498 1667.47911653  669.99738987 2543.7817503
 1073.3446296    13.25553817 3563.68015357 1950.83200272 3209.4824592 ]
total_rewards_mean           2143.340300581982
total_rewards_std            1206.3527257386866
total_rewards_max            3604.125534975167
total_rewards_min            13.255538165629687
Number of train steps total  1716000
Number of env steps total    3071617
Number of rollouts total     0
Train Time (s)               146.66877563111484
(Previous) Eval Time (s)     27.823167771100998
Sample Time (s)              11.007491875905544
Epoch Time (s)               185.49943527812138
Total Train Time (s)         79669.92571902741
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:03:43.547994 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #428 | Epoch Duration: 185.60277199745178
2020-01-13 00:03:43.548240 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.893361
Z variance train             0.039594688
KL Divergence                14.064567
KL Loss                      1.4064567
QF Loss                      502.86746
VF Loss                      107.30055
Policy Loss                  -1181.9962
Q Predictions Mean           1176.4761
Q Predictions Std            221.9614
Q Predictions Max            1479.326
Q Predictions Min            88.67482
V Predictions Mean           1176.3892
V Predictions Std            219.70427
V Predictions Max            1463.9486
V Predictions Min            204.11409
Log Pis Mean                 0.9791949
Log Pis Std                  2.7110243
Log Pis Max                  13.136222
Log Pis Min                  -6.102696
Policy mu Mean               -0.07783581
Policy mu Std                0.6911593
Policy mu Max                2.3227997
Policy mu Min                -3.0802422
Policy log std Mean          -1.0513804
Policy log std Std           0.2891248
Policy log std Max           -0.27878374
Policy log std Min           -2.8634388
Z mean eval                  0.893788
Z variance eval              0.14875868
total_rewards                [2302.16637723 3052.02800132 1298.16446252  174.40734246 2603.33438976
 2050.43793233 1204.5920308  1103.910149    207.0332262  3552.65218785]
total_rewards_mean           1754.872609949319
total_rewards_std            1088.5871867836718
total_rewards_max            3552.652187852977
total_rewards_min            174.40734245934908
Number of train steps total  1720000
Number of env steps total    3082917
Number of rollouts total     0
Train Time (s)               150.5583564271219
(Previous) Eval Time (s)     18.137164204847068
Sample Time (s)              10.47136475564912
Epoch Time (s)               179.1668853876181
Total Train Time (s)         79849.18192174425
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:06:42.808702 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #429 | Epoch Duration: 179.26030158996582
2020-01-13 00:06:42.808905 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89260894
Z variance train             0.15098752
KL Divergence                12.441171
KL Loss                      1.2441171
QF Loss                      340.10596
VF Loss                      116.14165
Policy Loss                  -1200.8855
Q Predictions Mean           1196.7332
Q Predictions Std            202.21178
Q Predictions Max            1420.2455
Q Predictions Min            304.22714
V Predictions Mean           1195.7942
V Predictions Std            202.29414
V Predictions Max            1414.5289
V Predictions Min            310.5777
Log Pis Mean                 0.49016568
Log Pis Std                  2.5452194
Log Pis Max                  8.105939
Log Pis Min                  -7.3877196
Policy mu Mean               -0.009884113
Policy mu Std                0.61306536
Policy mu Max                1.99165
Policy mu Min                -2.6074057
Policy log std Mean          -1.0570986
Policy log std Std           0.24953233
Policy log std Max           -0.18691766
Policy log std Min           -2.120798
Z mean eval                  0.9718148
Z variance eval              0.06702489
total_rewards                [3533.1167883  3259.83860981 1452.24897381   29.84610174 3283.6701228
 1422.29507293   18.12291238 2398.85070267  164.90176424 1183.55932357]
total_rewards_mean           1674.645037226764
total_rewards_std            1310.0859137575185
total_rewards_max            3533.1167883018825
total_rewards_min            18.122912382641655
Number of train steps total  1724000
Number of env steps total    3094330
Number of rollouts total     0
Train Time (s)               156.14025880489498
(Previous) Eval Time (s)     30.110905314795673
Sample Time (s)              10.530124392360449
Epoch Time (s)               196.7812885120511
Total Train Time (s)         80046.09317206778
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:09:59.722370 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #430 | Epoch Duration: 196.91333198547363
2020-01-13 00:09:59.722497 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97034436
Z variance train             0.06665576
KL Divergence                13.353891
KL Loss                      1.3353891
QF Loss                      244.99042
VF Loss                      84.23326
Policy Loss                  -1215.7166
Q Predictions Mean           1209.4968
Q Predictions Std            208.48347
Q Predictions Max            1446.2197
Q Predictions Min            332.77307
V Predictions Mean           1218.6539
V Predictions Std            207.90096
V Predictions Max            1446.7495
V Predictions Min            338.68066
Log Pis Mean                 0.67794025
Log Pis Std                  2.7749968
Log Pis Max                  11.68982
Log Pis Min                  -7.9270077
Policy mu Mean               -0.04016804
Policy mu Std                0.6744037
Policy mu Max                2.3114116
Policy mu Min                -2.5356941
Policy log std Mean          -1.05262
Policy log std Std           0.271267
Policy log std Max           -0.28763586
Policy log std Min           -2.2469559
Z mean eval                  1.1596221
Z variance eval              0.06613246
total_rewards                [3586.83646743 1317.43556871 2897.03004798 1794.06126292 1700.77453982
 2649.63712792  601.3087404  3501.34436399 3511.70486492 3588.55580057]
total_rewards_mean           2514.868878466551
total_rewards_std            1034.930711236647
total_rewards_max            3588.555800566923
total_rewards_min            601.3087403977099
Number of train steps total  1728000
Number of env steps total    3105684
Number of rollouts total     0
Train Time (s)               156.55635457113385
(Previous) Eval Time (s)     29.464024554006755
Sample Time (s)              11.718356468714774
Epoch Time (s)               197.73873559385538
Total Train Time (s)         80243.92089327471
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:13:17.556152 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #431 | Epoch Duration: 197.83353805541992
2020-01-13 00:13:17.556378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1617525
Z variance train             0.066055946
KL Divergence                13.661083
KL Loss                      1.3661083
QF Loss                      276.05975
VF Loss                      99.72282
Policy Loss                  -1214.8046
Q Predictions Mean           1209.8197
Q Predictions Std            199.58876
Q Predictions Max            1449.7609
Q Predictions Min            295.74637
V Predictions Mean           1213.9243
V Predictions Std            196.71077
V Predictions Max            1448.2874
V Predictions Min            294.0969
Log Pis Mean                 0.84521556
Log Pis Std                  2.6290593
Log Pis Max                  12.598141
Log Pis Min                  -5.897646
Policy mu Mean               -0.018060055
Policy mu Std                0.6511793
Policy mu Max                2.8446927
Policy mu Min                -2.0782664
Policy log std Mean          -1.0565147
Policy log std Std           0.2580888
Policy log std Max           0.15679991
Policy log std Min           -2.1305056
Z mean eval                  1.1203
Z variance eval              0.2929257
total_rewards                [2321.94400241 3780.42693101 3192.10676888  358.97846653  787.60372456
  318.0210947  1713.218412    629.69578426  309.33120154 1172.98259435]
total_rewards_mean           1458.4308980229912
total_rewards_std            1193.9816230475278
total_rewards_max            3780.4269310115287
total_rewards_min            309.3312015389808
Number of train steps total  1732000
Number of env steps total    3116981
Number of rollouts total     0
Train Time (s)               156.97397910570726
(Previous) Eval Time (s)     23.160470891278237
Sample Time (s)              12.025093680713326
Epoch Time (s)               192.15954367769882
Total Train Time (s)         80436.16978724347
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:16:29.808550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #432 | Epoch Duration: 192.25202775001526
2020-01-13 00:16:29.808757 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1214858
Z variance train             0.29015422
KL Divergence                14.767169
KL Loss                      1.4767169
QF Loss                      395.57373
VF Loss                      144.11423
Policy Loss                  -1244.0332
Q Predictions Mean           1239.4844
Q Predictions Std            186.95818
Q Predictions Max            1534.6488
Q Predictions Min            326.62592
V Predictions Mean           1253.3406
V Predictions Std            188.30986
V Predictions Max            1548.7827
V Predictions Min            338.177
Log Pis Mean                 0.612398
Log Pis Std                  2.523637
Log Pis Max                  10.899405
Log Pis Min                  -5.3185887
Policy mu Mean               -0.022891402
Policy mu Std                0.6464778
Policy mu Max                2.120454
Policy mu Min                -2.506447
Policy log std Mean          -1.043827
Policy log std Std           0.24851637
Policy log std Max           -0.35540074
Policy log std Min           -2.1745353
Z mean eval                  0.9198972
Z variance eval              0.15226085
total_rewards                [3490.38950464 3275.25521414 3645.63951866 1758.35437554 2334.88005595
 2923.83954911 2724.5243327  1926.40232432 2506.86041205 3585.81915408]
total_rewards_mean           2817.1964441199966
total_rewards_std            648.3567416772798
total_rewards_max            3645.6395186563304
total_rewards_min            1758.3543755437174
Number of train steps total  1736000
Number of env steps total    3128323
Number of rollouts total     0
Train Time (s)               156.17823860794306
(Previous) Eval Time (s)     29.54304147697985
Sample Time (s)              14.0935587300919
Epoch Time (s)               199.8148388150148
Total Train Time (s)         80636.07600313844
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:19:49.717305 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #433 | Epoch Duration: 199.90841484069824
2020-01-13 00:19:49.717448 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91950625
Z variance train             0.15296634
KL Divergence                12.750565
KL Loss                      1.2750565
QF Loss                      387.31787
VF Loss                      51.377754
Policy Loss                  -1247.8323
Q Predictions Mean           1242.668
Q Predictions Std            257.59726
Q Predictions Max            1518.1532
Q Predictions Min            342.07166
V Predictions Mean           1248.317
V Predictions Std            257.68817
V Predictions Max            1503.9543
V Predictions Min            347.27588
Log Pis Mean                 0.66987514
Log Pis Std                  2.8283706
Log Pis Max                  8.792003
Log Pis Min                  -8.597033
Policy mu Mean               -0.024194269
Policy mu Std                0.6727882
Policy mu Max                2.5130186
Policy mu Min                -2.3767953
Policy log std Mean          -1.0249581
Policy log std Std           0.25654018
Policy log std Max           -0.34475774
Policy log std Min           -1.975437
Z mean eval                  0.9229903
Z variance eval              0.115974665
total_rewards                [2577.45417315 3235.0989002  3067.61257745  386.19347505 1410.9374817
 1596.59508091 3439.50114536  913.90517253 2185.16770958  643.72558696]
total_rewards_mean           1945.619130289133
total_rewards_std            1058.7153066820397
total_rewards_max            3439.5011453565207
total_rewards_min            386.19347505265483
Number of train steps total  1740000
Number of env steps total    3137648
Number of rollouts total     0
Train Time (s)               146.03523934958503
(Previous) Eval Time (s)     23.640980921220034
Sample Time (s)              11.027333414647728
Epoch Time (s)               180.7035536854528
Total Train Time (s)         80817.27390373452
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:22:50.920355 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #434 | Epoch Duration: 181.20278596878052
2020-01-13 00:22:50.920561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92485505
Z variance train             0.11587332
KL Divergence                13.658755
KL Loss                      1.3658756
QF Loss                      11623.315
VF Loss                      59.638405
Policy Loss                  -1227.986
Q Predictions Mean           1223.3005
Q Predictions Std            183.6499
Q Predictions Max            1436.5942
Q Predictions Min            328.6467
V Predictions Mean           1224.1838
V Predictions Std            183.70029
V Predictions Max            1423.514
V Predictions Min            329.06244
Log Pis Mean                 0.840242
Log Pis Std                  2.649914
Log Pis Max                  7.696944
Log Pis Min                  -9.18027
Policy mu Mean               -0.14209445
Policy mu Std                0.6896894
Policy mu Max                2.385094
Policy mu Min                -2.3066294
Policy log std Mean          -1.0185663
Policy log std Std           0.25031304
Policy log std Max           -0.20317966
Policy log std Min           -2.0021565
Z mean eval                  0.92185414
Z variance eval              0.10426848
total_rewards                [3125.88222761 3218.04369383 3403.35526482 1592.82892592  835.67196715
 3390.8612467  3224.54458875 3475.42544712  411.19550985 3159.82068194]
total_rewards_mean           2583.762955369611
total_rewards_std            1109.7149107076955
total_rewards_max            3475.4254471240533
total_rewards_min            411.1955098510529
Number of train steps total  1744000
Number of env steps total    3147701
Number of rollouts total     0
Train Time (s)               145.7733832099475
(Previous) Eval Time (s)     27.4394216039218
Sample Time (s)              12.595944990869612
Epoch Time (s)               185.8087498047389
Total Train Time (s)         81003.17285033548
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:25:56.823774 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #435 | Epoch Duration: 185.90305876731873
2020-01-13 00:25:56.824003 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92223656
Z variance train             0.104738235
KL Divergence                13.52689
KL Loss                      1.352689
QF Loss                      256.54105
VF Loss                      54.81294
Policy Loss                  -1211.6046
Q Predictions Mean           1206.6853
Q Predictions Std            206.06436
Q Predictions Max            1457.4321
Q Predictions Min            304.2269
V Predictions Mean           1213.9209
V Predictions Std            208.20941
V Predictions Max            1457.8602
V Predictions Min            303.04105
Log Pis Mean                 0.9247623
Log Pis Std                  2.41348
Log Pis Max                  8.954465
Log Pis Min                  -8.402182
Policy mu Mean               -0.02322953
Policy mu Std                0.64238286
Policy mu Max                2.9510143
Policy mu Min                -2.1415584
Policy log std Mean          -1.074611
Policy log std Std           0.2573541
Policy log std Max           -0.23116583
Policy log std Min           -2.239121
Z mean eval                  0.9571268
Z variance eval              0.12301634
total_rewards                [1386.53523583 1202.6788836  1255.70328754  523.49947033  770.6080261
 3188.66283504 1028.49305789 1079.05581774  776.2573309   745.16988548]
total_rewards_mean           1195.6663830447299
total_rewards_std            711.6880172505279
total_rewards_max            3188.662835041494
total_rewards_min            523.4994703286596
Number of train steps total  1748000
Number of env steps total    3159403
Number of rollouts total     0
Train Time (s)               154.22104819398373
(Previous) Eval Time (s)     13.69493463402614
Sample Time (s)              11.090422461275011
Epoch Time (s)               179.00640528928488
Total Train Time (s)         81182.26855289657
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:28:55.924088 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #436 | Epoch Duration: 179.0999345779419
2020-01-13 00:28:55.924292 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9552759
Z variance train             0.12376791
KL Divergence                14.889828
KL Loss                      1.4889828
QF Loss                      293.81888
VF Loss                      82.17607
Policy Loss                  -1222.1846
Q Predictions Mean           1219.3691
Q Predictions Std            225.8327
Q Predictions Max            1454.0444
Q Predictions Min            311.5835
V Predictions Mean           1227.3755
V Predictions Std            224.95477
V Predictions Max            1459.7673
V Predictions Min            323.83664
Log Pis Mean                 0.70925903
Log Pis Std                  2.4286406
Log Pis Max                  11.483162
Log Pis Min                  -5.7709484
Policy mu Mean               -0.04711231
Policy mu Std                0.62203795
Policy mu Max                2.187826
Policy mu Min                -2.302648
Policy log std Mean          -1.0649655
Policy log std Std           0.24254635
Policy log std Max           -0.36754555
Policy log std Min           -2.1254497
Z mean eval                  0.81281376
Z variance eval              0.7343356
total_rewards                [1388.82118121 3415.6484325  3217.13316334 3424.65181123 -166.28287496
  946.12347033  369.75687674 3377.20086702  417.37002163 2656.46710152]
total_rewards_mean           1904.689005055307
total_rewards_std            1381.71208661448
total_rewards_max            3424.6518112252943
total_rewards_min            -166.28287496422467
Number of train steps total  1752000
Number of env steps total    3169057
Number of rollouts total     0
Train Time (s)               155.8430254110135
(Previous) Eval Time (s)     27.535807483363897
Sample Time (s)              10.828938053920865
Epoch Time (s)               194.20777094829828
Total Train Time (s)         81376.57262040675
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:32:10.232462 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #437 | Epoch Duration: 194.3080232143402
2020-01-13 00:32:10.232650 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8065497
Z variance train             0.7306052
KL Divergence                10.427065
KL Loss                      1.0427065
QF Loss                      280.30432
VF Loss                      72.4862
Policy Loss                  -1263.8204
Q Predictions Mean           1259.8486
Q Predictions Std            230.7032
Q Predictions Max            1552.4937
Q Predictions Min            332.18292
V Predictions Mean           1258.074
V Predictions Std            230.45586
V Predictions Max            1544.3492
V Predictions Min            333.84225
Log Pis Mean                 0.51639724
Log Pis Std                  2.6287923
Log Pis Max                  10.690472
Log Pis Min                  -5.922366
Policy mu Mean               -0.0054309247
Policy mu Std                0.6425386
Policy mu Max                2.019349
Policy mu Min                -2.4287257
Policy log std Mean          -1.0347228
Policy log std Std           0.25221264
Policy log std Max           -0.2184366
Policy log std Min           -2.128376
Z mean eval                  1.203194
Z variance eval              0.10056503
total_rewards                [ 503.12909178  736.88233916 1768.53418321 2816.63465564 1403.54077607
 3791.7844917  2357.39090977 1391.54085843  931.33786374 3100.40499704]
total_rewards_mean           1880.1180166546878
total_rewards_std            1040.6717256500426
total_rewards_max            3791.784491696456
total_rewards_min            503.12909177774134
Number of train steps total  1756000
Number of env steps total    3180305
Number of rollouts total     0
Train Time (s)               154.6231912258081
(Previous) Eval Time (s)     21.149702557362616
Sample Time (s)              11.903265638742596
Epoch Time (s)               187.67615942191333
Total Train Time (s)         81564.33670177963
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:35:18.001115 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #438 | Epoch Duration: 187.768324136734
2020-01-13 00:35:18.001314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2065209
Z variance train             0.09924598
KL Divergence                13.810354
KL Loss                      1.3810354
QF Loss                      602.9557
VF Loss                      66.74631
Policy Loss                  -1226.4792
Q Predictions Mean           1218.8887
Q Predictions Std            194.77162
Q Predictions Max            1456.4565
Q Predictions Min            327.72748
V Predictions Mean           1223.196
V Predictions Std            193.58723
V Predictions Max            1461.881
V Predictions Min            318.38657
Log Pis Mean                 0.955446
Log Pis Std                  2.7127128
Log Pis Max                  14.108842
Log Pis Min                  -6.680163
Policy mu Mean               -0.08148201
Policy mu Std                0.65215063
Policy mu Max                2.158526
Policy mu Min                -2.6765447
Policy log std Mean          -1.0870013
Policy log std Std           0.2608939
Policy log std Max           -0.38887292
Policy log std Min           -2.1880202
Z mean eval                  1.0253456
Z variance eval              0.20061931
total_rewards                [2016.38145574 1282.37677727  221.99443816  824.75912614 1729.16600101
 3351.77715938 2922.77466593 2034.69379457 1260.77071277  558.34590609]
total_rewards_mean           1620.3040037060414
total_rewards_std            948.3802817470382
total_rewards_max            3351.777159384082
total_rewards_min            221.99443816337418
Number of train steps total  1760000
Number of env steps total    3192119
Number of rollouts total     0
Train Time (s)               156.94025003630668
(Previous) Eval Time (s)     24.231351213995367
Sample Time (s)              12.473620474804193
Epoch Time (s)               193.64522172510624
Total Train Time (s)         81758.07016242389
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:38:31.737053 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #439 | Epoch Duration: 193.73561596870422
2020-01-13 00:38:31.737172 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0197151
Z variance train             0.19652069
KL Divergence                13.985294
KL Loss                      1.3985294
QF Loss                      650.68884
VF Loss                      394.91684
Policy Loss                  -1149.0336
Q Predictions Mean           1143.4888
Q Predictions Std            249.13509
Q Predictions Max            1444.4241
Q Predictions Min            313.6968
V Predictions Mean           1157.2378
V Predictions Std            252.80785
V Predictions Max            1446.5948
V Predictions Min            315.2825
Log Pis Mean                 0.69080615
Log Pis Std                  2.7514088
Log Pis Max                  14.718237
Log Pis Min                  -5.8084593
Policy mu Mean               -0.045856155
Policy mu Std                0.6585222
Policy mu Max                2.0599687
Policy mu Min                -2.6807601
Policy log std Mean          -1.0209832
Policy log std Std           0.25660565
Policy log std Max           -0.25709134
Policy log std Min           -2.4515758
Z mean eval                  1.0127946
Z variance eval              0.11420778
total_rewards                [3452.1882514   841.23095969 1062.70851908   68.33009393  224.8665407
  183.9992521  2892.93353047  100.40284209   23.61216606 3589.99699146]
total_rewards_mean           1244.0269146976902
total_rewards_std            1401.2659906452666
total_rewards_max            3589.99699145672
total_rewards_min            23.612166062884164
Number of train steps total  1764000
Number of env steps total    3202459
Number of rollouts total     0
Train Time (s)               154.12005431903526
(Previous) Eval Time (s)     16.790514649823308
Sample Time (s)              12.843529464676976
Epoch Time (s)               183.75409843353555
Total Train Time (s)         81941.91376924934
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:41:35.585885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #440 | Epoch Duration: 183.84860634803772
2020-01-13 00:41:35.586078 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0156094
Z variance train             0.11461703
KL Divergence                14.383902
KL Loss                      1.4383901
QF Loss                      490.76038
VF Loss                      128.61476
Policy Loss                  -1191.0001
Q Predictions Mean           1186.3768
Q Predictions Std            209.69917
Q Predictions Max            1462.0322
Q Predictions Min            353.5152
V Predictions Mean           1187.3481
V Predictions Std            209.00024
V Predictions Max            1441.6887
V Predictions Min            350.7223
Log Pis Mean                 0.70386654
Log Pis Std                  2.8312953
Log Pis Max                  11.976581
Log Pis Min                  -8.216362
Policy mu Mean               -0.018116701
Policy mu Std                0.66084886
Policy mu Max                2.7396708
Policy mu Min                -2.3409998
Policy log std Mean          -1.058104
Policy log std Std           0.26687193
Policy log std Max           -0.30888915
Policy log std Min           -2.1297603
Z mean eval                  1.0336183
Z variance eval              0.13587055
total_rewards                [3432.9049502   214.14762653 3014.98517515 3606.43007833 3628.63544812
 3379.11928807  283.42832755 3420.12821929  176.14406244 2948.42213891]
total_rewards_mean           2410.4345314593347
total_rewards_std            1446.1152681007707
total_rewards_max            3628.6354481209755
total_rewards_min            176.14406244422946
Number of train steps total  1768000
Number of env steps total    3213750
Number of rollouts total     0
Train Time (s)               146.81335486704484
(Previous) Eval Time (s)     24.91494841594249
Sample Time (s)              11.4564024284482
Epoch Time (s)               183.18470571143553
Total Train Time (s)         82125.20878389664
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:44:38.888829 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #441 | Epoch Duration: 183.302588224411
2020-01-13 00:44:38.889103 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0286064
Z variance train             0.13391504
KL Divergence                13.045756
KL Loss                      1.3045757
QF Loss                      1314.9358
VF Loss                      63.35321
Policy Loss                  -1158.1388
Q Predictions Mean           1151.1721
Q Predictions Std            268.47205
Q Predictions Max            1482.8413
Q Predictions Min            328.4058
V Predictions Mean           1159.3029
V Predictions Std            267.7012
V Predictions Max            1488.8097
V Predictions Min            330.26782
Log Pis Mean                 0.7421463
Log Pis Std                  2.7289627
Log Pis Max                  8.359683
Log Pis Min                  -9.29933
Policy mu Mean               -0.061918404
Policy mu Std                0.65813744
Policy mu Max                1.9934592
Policy mu Min                -2.8524234
Policy log std Mean          -1.0420135
Policy log std Std           0.2859932
Policy log std Max           -0.11752218
Policy log std Min           -2.2059417
Z mean eval                  0.94862527
Z variance eval              0.14882925
total_rewards                [ 193.04311917 3539.96762096 3122.88059252 3168.0935114  3302.04632438
 3220.5866987  3693.32533407  114.01047329 3515.99883802 2402.91118857]
total_rewards_mean           2627.2863701083697
total_rewards_std            1280.5103834994952
total_rewards_max            3693.3253340666397
total_rewards_min            114.01047328642812
Number of train steps total  1772000
Number of env steps total    3224172
Number of rollouts total     0
Train Time (s)               146.6818850589916
(Previous) Eval Time (s)     26.812679717317224
Sample Time (s)              11.308640602976084
Epoch Time (s)               184.80320537928492
Total Train Time (s)         82310.0958378734
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:47:43.780443 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #442 | Epoch Duration: 184.89117431640625
2020-01-13 00:47:43.780644 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9461315
Z variance train             0.14923881
KL Divergence                13.050098
KL Loss                      1.3050098
QF Loss                      12482.06
VF Loss                      124.653275
Policy Loss                  -1208.4674
Q Predictions Mean           1205.4951
Q Predictions Std            229.23549
Q Predictions Max            1477.2388
Q Predictions Min            332.0607
V Predictions Mean           1213.2113
V Predictions Std            230.83147
V Predictions Max            1476.5612
V Predictions Min            304.09006
Log Pis Mean                 0.56029224
Log Pis Std                  2.5853019
Log Pis Max                  11.283522
Log Pis Min                  -5.8929787
Policy mu Mean               -0.03771814
Policy mu Std                0.6356836
Policy mu Max                2.0739448
Policy mu Min                -2.7042742
Policy log std Mean          -1.0802314
Policy log std Std           0.27119827
Policy log std Max           -0.21227294
Policy log std Min           -2.4561555
Z mean eval                  0.90859795
Z variance eval              0.28358293
total_rewards                [3610.50527256 2376.53641519 3749.5984564   105.68807539 1475.70239078
  -94.34636734 3688.91031047 3428.40525251  456.09029657 3648.72786961]
total_rewards_mean           2244.5817972139143
total_rewards_std            1531.1012973675788
total_rewards_max            3749.5984564011083
total_rewards_min            -94.34636734034477
Number of train steps total  1776000
Number of env steps total    3234773
Number of rollouts total     0
Train Time (s)               155.32065781299025
(Previous) Eval Time (s)     29.16787676885724
Sample Time (s)              11.896669452544302
Epoch Time (s)               196.3852040343918
Total Train Time (s)         82506.58048625011
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:51:00.269697 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #443 | Epoch Duration: 196.48889541625977
2020-01-13 00:51:00.269914 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9072838
Z variance train             0.2838375
KL Divergence                11.306942
KL Loss                      1.1306943
QF Loss                      317.18008
VF Loss                      99.39106
Policy Loss                  -1228.719
Q Predictions Mean           1222.6611
Q Predictions Std            241.50125
Q Predictions Max            1496.0763
Q Predictions Min            359.0595
V Predictions Mean           1221.9738
V Predictions Std            238.83032
V Predictions Max            1491.0695
V Predictions Min            357.2151
Log Pis Mean                 0.4803763
Log Pis Std                  2.7003448
Log Pis Max                  8.730457
Log Pis Min                  -7.71321
Policy mu Mean               -0.014150167
Policy mu Std                0.65713793
Policy mu Max                2.3847868
Policy mu Min                -2.3780324
Policy log std Mean          -1.0390182
Policy log std Std           0.25861973
Policy log std Max           -0.08721578
Policy log std Min           -2.1574268
Z mean eval                  1.2247496
Z variance eval              0.1496843
total_rewards                [3387.67419697 3352.79550996 3351.03226615 3368.45613266 3547.04028595
 3489.33454439 3206.22214806 1717.2938674  3490.87615102 3294.59560552]
total_rewards_mean           3220.5320708105364
total_rewards_std            510.0691639415147
total_rewards_max            3547.040285950553
total_rewards_min            1717.293867404232
Number of train steps total  1780000
Number of env steps total    3246242
Number of rollouts total     0
Train Time (s)               155.39765394013375
(Previous) Eval Time (s)     37.407337544020265
Sample Time (s)              11.998290662188083
Epoch Time (s)               204.8032821463421
Total Train Time (s)         82711.4717191835
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:54:25.166459 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #444 | Epoch Duration: 204.89635491371155
2020-01-13 00:54:25.166819 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #444 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2271068
Z variance train             0.15446644
KL Divergence                12.234687
KL Loss                      1.2234687
QF Loss                      397.73566
VF Loss                      66.856865
Policy Loss                  -1147.2792
Q Predictions Mean           1142.774
Q Predictions Std            182.13162
Q Predictions Max            1378.057
Q Predictions Min            313.4048
V Predictions Mean           1148.0381
V Predictions Std            181.2969
V Predictions Max            1360.5109
V Predictions Min            335.0933
Log Pis Mean                 0.5316107
Log Pis Std                  2.5561597
Log Pis Max                  9.865283
Log Pis Min                  -8.268704
Policy mu Mean               -0.010507414
Policy mu Std                0.62840897
Policy mu Max                2.1888034
Policy mu Min                -2.0903516
Policy log std Mean          -1.0706341
Policy log std Std           0.24684948
Policy log std Max           -0.31534338
Policy log std Min           -2.0937471
Z mean eval                  0.8950362
Z variance eval              0.14764227
total_rewards                [ 8.44170631e+02  1.05282901e+03  2.87465661e+02  5.94813062e+02
  3.01559801e+03  1.65432362e+02  9.82734363e+02  5.46736704e+02
 -1.63273314e-02  2.11023842e+02]
total_rewards_mean           770.0787321368614
total_rewards_std            822.0533855759876
total_rewards_max            3015.598013517057
total_rewards_min            -0.016327331411250423
Number of train steps total  1784000
Number of env steps total    3258116
Number of rollouts total     0
Train Time (s)               154.58934545703232
(Previous) Eval Time (s)     19.739386819303036
Sample Time (s)              12.503147145267576
Epoch Time (s)               186.83187942160293
Total Train Time (s)         82898.39085533889
Epoch                        445
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:57:32.089239 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #445 | Epoch Duration: 186.92222356796265
2020-01-13 00:57:32.089425 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89537793
Z variance train             0.14640746
KL Divergence                11.636014
KL Loss                      1.1636014
QF Loss                      298.2386
VF Loss                      99.34479
Policy Loss                  -1260.7435
Q Predictions Mean           1255.0781
Q Predictions Std            150.61148
Q Predictions Max            1462.6207
Q Predictions Min            369.32
V Predictions Mean           1260.2002
V Predictions Std            148.32108
V Predictions Max            1445.352
V Predictions Min            377.23257
Log Pis Mean                 0.6374849
Log Pis Std                  2.6020513
Log Pis Max                  9.041895
Log Pis Min                  -9.166976
Policy mu Mean               -0.013533248
Policy mu Std                0.6250738
Policy mu Max                2.174928
Policy mu Min                -2.6224177
Policy log std Mean          -1.0817262
Policy log std Std           0.25405544
Policy log std Max           -0.3171689
Policy log std Min           -2.2772305
Z mean eval                  0.8590458
Z variance eval              0.14189911
total_rewards                [3365.16356834  580.93385352 2737.79028253 2330.76010134 3095.85516365
 1142.060179   2716.97393666  -40.34251165 3647.16710058 3509.70336744]
total_rewards_mean           2308.606504143613
total_rewards_std            1232.2803852945833
total_rewards_max            3647.1671005836415
total_rewards_min            -40.34251165099214
Number of train steps total  1788000
Number of env steps total    3270331
Number of rollouts total     0
Train Time (s)               155.95496339397505
(Previous) Eval Time (s)     28.201375784818083
Sample Time (s)              12.748323714360595
Epoch Time (s)               196.90466289315373
Total Train Time (s)         83095.38401200855
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:00:49.087129 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #446 | Epoch Duration: 196.99755764007568
2020-01-13 01:00:49.087346 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8520244
Z variance train             0.13941106
KL Divergence                13.360502
KL Loss                      1.3360503
QF Loss                      282.53635
VF Loss                      131.19862
Policy Loss                  -1212.9698
Q Predictions Mean           1211.0732
Q Predictions Std            225.37695
Q Predictions Max            1467.995
Q Predictions Min            288.9732
V Predictions Mean           1221.6377
V Predictions Std            225.52292
V Predictions Max            1467.2634
V Predictions Min            308.60217
Log Pis Mean                 0.8541467
Log Pis Std                  2.423577
Log Pis Max                  13.219353
Log Pis Min                  -6.6720233
Policy mu Mean               -0.03438396
Policy mu Std                0.6362843
Policy mu Max                2.5271647
Policy mu Min                -2.252293
Policy log std Mean          -1.0609398
Policy log std Std           0.25156036
Policy log std Max           -0.29654068
Policy log std Min           -2.2244153
Z mean eval                  1.0103357
Z variance eval              0.17083792
total_rewards                [1919.61856116 -339.59267816 3213.32078376  222.41936568 1652.54855122
  650.2928095  3453.10279806  -78.29614718 3211.84132146 1367.89643955]
total_rewards_mean           1527.3151805047041
total_rewards_std            1346.0741009089488
total_rewards_max            3453.102798061962
total_rewards_min            -339.59267815555603
Number of train steps total  1792000
Number of env steps total    3281547
Number of rollouts total     0
Train Time (s)               150.28612108295783
(Previous) Eval Time (s)     32.19724460877478
Sample Time (s)              13.6089823897928
Epoch Time (s)               196.09234808152542
Total Train Time (s)         83291.56313243974
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:04:05.270664 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #447 | Epoch Duration: 196.183171749115
2020-01-13 01:04:05.270864 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0117898
Z variance train             0.17185396
KL Divergence                11.794322
KL Loss                      1.1794323
QF Loss                      232.3186
VF Loss                      55.818436
Policy Loss                  -1189.9587
Q Predictions Mean           1185.0854
Q Predictions Std            249.962
Q Predictions Max            1472.223
Q Predictions Min            306.95276
V Predictions Mean           1191.3986
V Predictions Std            250.29039
V Predictions Max            1476.6791
V Predictions Min            318.8466
Log Pis Mean                 0.814129
Log Pis Std                  2.8306336
Log Pis Max                  9.433075
Log Pis Min                  -7.576112
Policy mu Mean               -0.017547062
Policy mu Std                0.66011
Policy mu Max                2.3119404
Policy mu Min                -2.402186
Policy log std Mean          -1.0474725
Policy log std Std           0.27250051
Policy log std Max           -0.2034412
Policy log std Min           -2.2634056
Z mean eval                  0.93446416
Z variance eval              0.11976979
total_rewards                [ 722.75057382 2977.81881139  280.94773598 3598.66998868  195.39431288
 3509.54565641 3488.9046058  1405.3092403  3365.34811806 1068.18947607]
total_rewards_mean           2061.28785193883
total_rewards_std            1374.7396215794004
total_rewards_max            3598.669988678849
total_rewards_min            195.39431287968156
Number of train steps total  1796000
Number of env steps total    3292557
Number of rollouts total     0
Train Time (s)               145.33837824175134
(Previous) Eval Time (s)     24.89358245069161
Sample Time (s)              12.534236243460327
Epoch Time (s)               182.76619693590328
Total Train Time (s)         83474.45933496067
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:07:08.172455 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #448 | Epoch Duration: 182.90143585205078
2020-01-13 01:07:08.172716 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93539655
Z variance train             0.119258784
KL Divergence                11.822304
KL Loss                      1.1822304
QF Loss                      246.96631
VF Loss                      76.24971
Policy Loss                  -1192.533
Q Predictions Mean           1188.5571
Q Predictions Std            243.82216
Q Predictions Max            1436.916
Q Predictions Min            294.18472
V Predictions Mean           1189.3254
V Predictions Std            245.70988
V Predictions Max            1426.0109
V Predictions Min            290.93893
Log Pis Mean                 0.70258105
Log Pis Std                  2.3689983
Log Pis Max                  6.438652
Log Pis Min                  -6.130699
Policy mu Mean               -0.045046616
Policy mu Std                0.6269411
Policy mu Max                2.114289
Policy mu Min                -2.1853683
Policy log std Mean          -1.0647845
Policy log std Std           0.24611107
Policy log std Max           -0.3068565
Policy log std Min           -1.8917248
Z mean eval                  1.0486763
Z variance eval              0.2912019
total_rewards                [3588.37398444 2209.34904138 1967.19112373 3300.33651827 3441.30487328
 3339.25187765 2087.04962128 3310.61725869 1889.37462413 3633.31117115]
total_rewards_mean           2876.6160094005754
total_rewards_std            696.4444026460728
total_rewards_max            3633.311171147876
total_rewards_min            1889.374624133191
Number of train steps total  1800000
Number of env steps total    3303777
Number of rollouts total     0
Train Time (s)               148.95683728111908
(Previous) Eval Time (s)     30.394993360619992
Sample Time (s)              12.008568243589252
Epoch Time (s)               191.36039888532832
Total Train Time (s)         83665.91650875797
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:10:19.634181 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #449 | Epoch Duration: 191.46129846572876
2020-01-13 01:10:19.634373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0488704
Z variance train             0.2927156
KL Divergence                10.216116
KL Loss                      1.0216116
QF Loss                      1418.8237
VF Loss                      58.376343
Policy Loss                  -1120.2611
Q Predictions Mean           1114.946
Q Predictions Std            189.5891
Q Predictions Max            1373.8691
Q Predictions Min            284.5977
V Predictions Mean           1122.4746
V Predictions Std            187.48085
V Predictions Max            1386.0249
V Predictions Min            288.8189
Log Pis Mean                 0.47826442
Log Pis Std                  2.675541
Log Pis Max                  7.3097534
Log Pis Min                  -8.410018
Policy mu Mean               -0.047361955
Policy mu Std                0.5999516
Policy mu Max                2.4451969
Policy mu Min                -2.1468623
Policy log std Mean          -1.0710028
Policy log std Std           0.25139242
Policy log std Max           -0.1912328
Policy log std Min           -2.1603734
Z mean eval                  0.9078323
Z variance eval              0.12383701
total_rewards                [3240.08317211 3467.33623444 1118.41760652 1671.87490176  679.14296118
   43.04803559 3553.50819992 2430.62191445 1559.55924749  596.3343387 ]
total_rewards_mean           1835.992661216309
total_rewards_std            1210.130738272238
total_rewards_max            3553.50819992433
total_rewards_min            43.04803558861171
Number of train steps total  1804000
Number of env steps total    3314648
Number of rollouts total     0
Train Time (s)               158.0892867310904
(Previous) Eval Time (s)     19.839233440812677
Sample Time (s)              11.378828462678939
Epoch Time (s)               189.307348634582
Total Train Time (s)         83855.31604277482
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:13:29.044171 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #450 | Epoch Duration: 189.40960812568665
2020-01-13 01:13:29.044477 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9131299
Z variance train             0.12312585
KL Divergence                11.030597
KL Loss                      1.1030596
QF Loss                      353.3192
VF Loss                      167.6657
Policy Loss                  -1188.3594
Q Predictions Mean           1182.1384
Q Predictions Std            224.94771
Q Predictions Max            1420.7914
Q Predictions Min            303.3779
V Predictions Mean           1185.4968
V Predictions Std            224.8079
V Predictions Max            1411.3337
V Predictions Min            301.081
Log Pis Mean                 0.9650868
Log Pis Std                  2.9405951
Log Pis Max                  20.805168
Log Pis Min                  -7.268071
Policy mu Mean               -0.08675984
Policy mu Std                0.64445066
Policy mu Max                4.640289
Policy mu Min                -3.916966
Policy log std Mean          -1.084172
Policy log std Std           0.26235387
Policy log std Max           0.7755978
Policy log std Min           -2.2929058
Z mean eval                  0.96561575
Z variance eval              0.043078095
total_rewards                [1547.49119141 3466.20028554 2530.10455818 3017.04667502 3423.87741112
 3227.19445357 3542.5129892  2858.15243912 3285.3819139  3362.16512554]
total_rewards_mean           3026.0127042600375
total_rewards_std            574.4377356272614
total_rewards_max            3542.5129891968927
total_rewards_min            1547.4911914066226
Number of train steps total  1808000
Number of env steps total    3325204
Number of rollouts total     0
Train Time (s)               156.87208345206454
(Previous) Eval Time (s)     35.29917153995484
Sample Time (s)              11.564803844783455
Epoch Time (s)               203.73605883680284
Total Train Time (s)         84059.15132633038
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:16:52.882351 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #451 | Epoch Duration: 203.8376591205597
2020-01-13 01:16:52.882658 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9643834
Z variance train             0.043246284
KL Divergence                13.473818
KL Loss                      1.3473818
QF Loss                      312.87164
VF Loss                      130.9428
Policy Loss                  -1209.0167
Q Predictions Mean           1204.2788
Q Predictions Std            221.58876
Q Predictions Max            1461.6022
Q Predictions Min            283.27484
V Predictions Mean           1216.144
V Predictions Std            217.59908
V Predictions Max            1449.0819
V Predictions Min            295.80496
Log Pis Mean                 0.7321799
Log Pis Std                  2.6446824
Log Pis Max                  11.171226
Log Pis Min                  -6.6040363
Policy mu Mean               -0.05528322
Policy mu Std                0.6489567
Policy mu Max                2.1596172
Policy mu Min                -2.0396051
Policy log std Mean          -1.0228057
Policy log std Std           0.25110337
Policy log std Max           -0.25080758
Policy log std Min           -2.0539036
Z mean eval                  0.93567485
Z variance eval              0.17673427
total_rewards                [ 183.76294847 1680.25764888  342.83129889  658.24605258 1125.93383045
 2206.83475894 1027.27163662  157.6257431   128.39800566 2240.90325508]
total_rewards_mean           975.2065178668236
total_rewards_std            784.454664640567
total_rewards_max            2240.903255076402
total_rewards_min            128.3980056575018
Number of train steps total  1812000
Number of env steps total    3336678
Number of rollouts total     0
Train Time (s)               158.2118852850981
(Previous) Eval Time (s)     18.74398627318442
Sample Time (s)              12.863578875083476
Epoch Time (s)               189.819450433366
Total Train Time (s)         84249.0697812601
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:20:02.805587 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #452 | Epoch Duration: 189.9227192401886
2020-01-13 01:20:02.805921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9119464
Z variance train             0.17300145
KL Divergence                11.067175
KL Loss                      1.1067175
QF Loss                      877.1521
VF Loss                      138.86198
Policy Loss                  -1184.6848
Q Predictions Mean           1179.0212
Q Predictions Std            230.176
Q Predictions Max            1445.762
Q Predictions Min            -134.88817
V Predictions Mean           1189.3308
V Predictions Std            215.79541
V Predictions Max            1449.1393
V Predictions Min            305.93002
Log Pis Mean                 0.5913937
Log Pis Std                  2.7623007
Log Pis Max                  10.683633
Log Pis Min                  -8.884374
Policy mu Mean               -0.06980412
Policy mu Std                0.6102798
Policy mu Max                2.0101593
Policy mu Min                -2.4185026
Policy log std Mean          -1.0842726
Policy log std Std           0.26379725
Policy log std Max           -0.3810705
Policy log std Min           -2.888866
Z mean eval                  1.061204
Z variance eval              0.11719938
total_rewards                [1252.65887734 1770.92351793    6.14743181  155.73637371   82.4336351
 1698.75614777 1761.843056   1198.82958828  352.54332994  288.54523368]
total_rewards_mean           856.8417191559505
total_rewards_std            709.1709880100633
total_rewards_max            1770.9235179310033
total_rewards_min            6.147431809980688
Number of train steps total  1816000
Number of env steps total    3346623
Number of rollouts total     0
Train Time (s)               155.87476254208013
(Previous) Eval Time (s)     15.316036602947861
Sample Time (s)              11.13349477155134
Epoch Time (s)               182.32429391657934
Total Train Time (s)         84431.48379343841
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:23:05.223987 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #453 | Epoch Duration: 182.41781640052795
2020-01-13 01:23:05.224180 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0507969
Z variance train             0.11798284
KL Divergence                10.853295
KL Loss                      1.0853295
QF Loss                      800.1194
VF Loss                      270.30054
Policy Loss                  -1177.7909
Q Predictions Mean           1175.5923
Q Predictions Std            265.94873
Q Predictions Max            1444.646
Q Predictions Min            292.21378
V Predictions Mean           1180.4968
V Predictions Std            268.84576
V Predictions Max            1449.3341
V Predictions Min            298.12537
Log Pis Mean                 0.4495499
Log Pis Std                  2.9395428
Log Pis Max                  14.274422
Log Pis Min                  -7.1605377
Policy mu Mean               -0.03295576
Policy mu Std                0.630382
Policy mu Max                3.7762406
Policy mu Min                -2.3185894
Policy log std Mean          -1.0444366
Policy log std Std           0.25450438
Policy log std Max           -0.34543002
Policy log std Min           -2.4976425
Z mean eval                  0.9567261
Z variance eval              0.12169866
total_rewards                [1664.04299818 3720.34697204 3388.37172694 1324.96886957  412.09319864
 -530.66743465 3570.6214327    41.76989016  716.95661615  496.89607219]
total_rewards_mean           1480.5400341910395
total_rewards_std            1479.5297088912605
total_rewards_max            3720.3469720360845
total_rewards_min            -530.6674346544617
Number of train steps total  1820000
Number of env steps total    3355970
Number of rollouts total     0
Train Time (s)               147.24944340484217
(Previous) Eval Time (s)     22.737019226886332
Sample Time (s)              10.727197113912553
Epoch Time (s)               180.71365974564105
Total Train Time (s)         84612.30163716478
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:26:06.045870 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #454 | Epoch Duration: 180.82154822349548
2020-01-13 01:26:06.046058 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.955667
Z variance train             0.12128129
KL Divergence                12.601184
KL Loss                      1.2601184
QF Loss                      265.31082
VF Loss                      58.817276
Policy Loss                  -1278.0961
Q Predictions Mean           1273.1233
Q Predictions Std            192.81155
Q Predictions Max            1502.3832
Q Predictions Min            313.84952
V Predictions Mean           1278.6531
V Predictions Std            193.0521
V Predictions Max            1503.1603
V Predictions Min            304.62146
Log Pis Mean                 0.99173796
Log Pis Std                  2.8816955
Log Pis Max                  10.08102
Log Pis Min                  -7.954212
Policy mu Mean               -0.069168895
Policy mu Std                0.6580666
Policy mu Max                2.3864267
Policy mu Min                -2.4304192
Policy log std Mean          -1.0667784
Policy log std Std           0.27430356
Policy log std Max           -0.24710327
Policy log std Min           -2.4254599
Z mean eval                  0.8625237
Z variance eval              0.23489308
total_rewards                [ 163.11369994 3637.70489411  339.51910182 1441.82868081 3644.7162729
 3736.81854938 2287.85077984 1974.18781193 3767.862287     17.65536689]
total_rewards_mean           2101.125744461344
total_rewards_std            1479.2869368365803
total_rewards_max            3767.862287001308
total_rewards_min            17.655366885033207
Number of train steps total  1824000
Number of env steps total    3366849
Number of rollouts total     0
Train Time (s)               146.3574780188501
(Previous) Eval Time (s)     22.724041253793985
Sample Time (s)              11.41462202789262
Epoch Time (s)               180.4961413005367
Total Train Time (s)         84792.88589889323
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:29:06.634484 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #455 | Epoch Duration: 180.58827710151672
2020-01-13 01:29:06.634661 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8643309
Z variance train             0.23653674
KL Divergence                10.72661
KL Loss                      1.072661
QF Loss                      1337.2808
VF Loss                      374.10098
Policy Loss                  -1254.2552
Q Predictions Mean           1245.7784
Q Predictions Std            217.28456
Q Predictions Max            1500.959
Q Predictions Min            315.41425
V Predictions Mean           1241.7583
V Predictions Std            215.02391
V Predictions Max            1493.912
V Predictions Min            298.77008
Log Pis Mean                 0.4599343
Log Pis Std                  3.026776
Log Pis Max                  19.648287
Log Pis Min                  -7.5466413
Policy mu Mean               -0.034341082
Policy mu Std                0.6469818
Policy mu Max                2.695949
Policy mu Min                -2.6552904
Policy log std Mean          -1.0595357
Policy log std Std           0.2563189
Policy log std Max           -0.28661025
Policy log std Min           -2.271428
Z mean eval                  0.97492474
Z variance eval              0.18483591
total_rewards                [3602.61670461 2605.57137649 3685.45119458  388.71807767 3592.7531053
 3150.77863602 3687.47682047 3690.52306143 3520.80314904 3543.61641947]
total_rewards_mean           3146.8308545084865
total_rewards_std            973.7584968038146
total_rewards_max            3690.5230614339375
total_rewards_min            388.71807766521454
Number of train steps total  1828000
Number of env steps total    3378664
Number of rollouts total     0
Train Time (s)               152.78247792599723
(Previous) Eval Time (s)     34.39265306200832
Sample Time (s)              11.079637185670435
Epoch Time (s)               198.25476817367598
Total Train Time (s)         84991.2274331078
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:32:24.978450 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #456 | Epoch Duration: 198.34366488456726
2020-01-13 01:32:24.978588 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9715411
Z variance train             0.18435545
KL Divergence                11.325306
KL Loss                      1.1325306
QF Loss                      383.0523
VF Loss                      119.174835
Policy Loss                  -1213.5815
Q Predictions Mean           1209.1748
Q Predictions Std            229.79245
Q Predictions Max            1476.206
Q Predictions Min            250.30719
V Predictions Mean           1213.0856
V Predictions Std            228.81944
V Predictions Max            1466.9185
V Predictions Min            261.86423
Log Pis Mean                 1.3466047
Log Pis Std                  2.6874397
Log Pis Max                  14.560698
Log Pis Min                  -5.1736083
Policy mu Mean               -0.010759836
Policy mu Std                0.69181603
Policy mu Max                3.9030766
Policy mu Min                -3.4199805
Policy log std Mean          -1.0724885
Policy log std Std           0.26742658
Policy log std Max           0.11625373
Policy log std Min           -2.1113973
Z mean eval                  1.0848923
Z variance eval              0.138893
total_rewards                [ 461.65476523 3410.50955181  820.01416537 2280.35225066 2843.9054765
 1030.63121501 2499.76801697 2404.17653145 3646.93934101 3099.05366035]
total_rewards_mean           2249.7004974352594
total_rewards_std            1057.7717618897734
total_rewards_max            3646.9393410056095
total_rewards_min            461.65476522820666
Number of train steps total  1832000
Number of env steps total    3388921
Number of rollouts total     0
Train Time (s)               157.35155383357778
(Previous) Eval Time (s)     27.27370251668617
Sample Time (s)              11.877916345838457
Epoch Time (s)               196.5031726961024
Total Train Time (s)         85187.81958844978
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:35:41.576014 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #457 | Epoch Duration: 196.59730410575867
2020-01-13 01:35:41.576232 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0815077
Z variance train             0.1396719
KL Divergence                13.03298
KL Loss                      1.303298
QF Loss                      680.00397
VF Loss                      213.30325
Policy Loss                  -1227.0834
Q Predictions Mean           1226.4373
Q Predictions Std            221.99274
Q Predictions Max            1457.702
Q Predictions Min            298.49896
V Predictions Mean           1232.5554
V Predictions Std            223.24716
V Predictions Max            1462.4451
V Predictions Min            283.80618
Log Pis Mean                 0.37537247
Log Pis Std                  2.6919067
Log Pis Max                  10.028545
Log Pis Min                  -6.1194983
Policy mu Mean               -0.013459055
Policy mu Std                0.64227223
Policy mu Max                2.2306519
Policy mu Min                -2.2867205
Policy log std Mean          -1.029518
Policy log std Std           0.24414133
Policy log std Max           -0.34745246
Policy log std Min           -2.096403
Z mean eval                  0.9228605
Z variance eval              0.05648824
total_rewards                [ 341.54959511  615.27597136  362.87875154   51.94495638 3321.48532168
 3451.58029803  655.99263288  874.55271438 3621.26745328  751.03312308]
total_rewards_mean           1404.7560817732844
total_rewards_std            1368.0157974819379
total_rewards_max            3621.267453282606
total_rewards_min            51.94495637919632
Number of train steps total  1836000
Number of env steps total    3400876
Number of rollouts total     0
Train Time (s)               156.6567488219589
(Previous) Eval Time (s)     24.781037291977555
Sample Time (s)              11.782120005693287
Epoch Time (s)               193.21990611962974
Total Train Time (s)         85381.16432173504
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:38:54.929758 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #458 | Epoch Duration: 193.35332918167114
2020-01-13 01:38:54.930076 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9307076
Z variance train             0.05633851
KL Divergence                13.115963
KL Loss                      1.3115963
QF Loss                      445.0222
VF Loss                      80.68875
Policy Loss                  -1251.9872
Q Predictions Mean           1244.9633
Q Predictions Std            183.27582
Q Predictions Max            1616.0106
Q Predictions Min            311.69678
V Predictions Mean           1247.4651
V Predictions Std            183.441
V Predictions Max            1613.7686
V Predictions Min            304.00638
Log Pis Mean                 0.73629063
Log Pis Std                  2.8176267
Log Pis Max                  11.077629
Log Pis Min                  -6.2730103
Policy mu Mean               -0.064623274
Policy mu Std                0.6612305
Policy mu Max                2.3371572
Policy mu Min                -2.5680864
Policy log std Mean          -1.049899
Policy log std Std           0.24329555
Policy log std Max           -0.29385448
Policy log std Min           -2.1357203
Z mean eval                  1.0728462
Z variance eval              0.018600872
total_rewards                [ 263.27672897 1679.18990898 1764.85859294  624.78631941 3503.7253349
  454.39054337 3556.67119408 2122.10387649  940.80771117 1193.65396867]
total_rewards_mean           1610.3464178979136
total_rewards_std            1113.8961849359123
total_rewards_max            3556.6711940842906
total_rewards_min            263.27672896552343
Number of train steps total  1840000
Number of env steps total    3412191
Number of rollouts total     0
Train Time (s)               158.3069243002683
(Previous) Eval Time (s)     18.954176746308804
Sample Time (s)              12.240794050041586
Epoch Time (s)               189.50189509661868
Total Train Time (s)         85570.76208571903
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:42:04.532401 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #459 | Epoch Duration: 189.60212111473083
2020-01-13 01:42:04.532740 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #459 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0700624
Z variance train             0.01841927
KL Divergence                15.369431
KL Loss                      1.5369431
QF Loss                      456.82538
VF Loss                      112.39296
Policy Loss                  -1246.9694
Q Predictions Mean           1239.8179
Q Predictions Std            203.62816
Q Predictions Max            2244.5208
Q Predictions Min            248.58379
V Predictions Mean           1244.6614
V Predictions Std            202.4983
V Predictions Max            2268.538
V Predictions Min            230.5869
Log Pis Mean                 0.9151061
Log Pis Std                  3.0111098
Log Pis Max                  13.125711
Log Pis Min                  -6.501791
Policy mu Mean               -0.07353205
Policy mu Std                0.70747536
Policy mu Max                3.0667217
Policy mu Min                -3.0417123
Policy log std Mean          -1.0383122
Policy log std Std           0.2406115
Policy log std Max           -0.20376211
Policy log std Min           -2.0411031
Z mean eval                  0.9714797
Z variance eval              0.059071224
total_rewards                [  125.72644093  3555.08817249  3675.26085968  1332.787897
  -316.9475614   2332.11096476  -748.16425908  3236.30806043
  2234.81644873 -1390.84425382]
total_rewards_mean           1403.6142769723785
total_rewards_std            1781.529788106985
total_rewards_max            3675.2608596788514
total_rewards_min            -1390.844253820006
Number of train steps total  1844000
Number of env steps total    3423598
Number of rollouts total     0
Train Time (s)               154.02491983678192
(Previous) Eval Time (s)     28.194676832761616
Sample Time (s)              13.809603879693896
Epoch Time (s)               196.02920054923743
Total Train Time (s)         85766.8798130257
Epoch                        460
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:45:20.654417 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #460 | Epoch Duration: 196.12143540382385
2020-01-13 01:45:20.654613 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9675225
Z variance train             0.058732636
KL Divergence                14.494343
KL Loss                      1.4494343
QF Loss                      329.35486
VF Loss                      159.661
Policy Loss                  -1252.0675
Q Predictions Mean           1246.1415
Q Predictions Std            237.9668
Q Predictions Max            2687.8284
Q Predictions Min            37.742046
V Predictions Mean           1259.5309
V Predictions Std            238.19048
V Predictions Max            2794.2898
V Predictions Min            289.33728
Log Pis Mean                 0.953016
Log Pis Std                  3.2590737
Log Pis Max                  19.010078
Log Pis Min                  -7.1041017
Policy mu Mean               -0.05882886
Policy mu Std                0.7168505
Policy mu Max                3.4905236
Policy mu Min                -2.6515632
Policy log std Mean          -1.032587
Policy log std Std           0.24786682
Policy log std Max           0.2180227
Policy log std Min           -2.7340038
Z mean eval                  1.3479321
Z variance eval              1.2609997
total_rewards                [-1204.99290724  -153.44866208 -1110.88518718 -1024.56526855
 -1107.08495288 -1147.29547712 -1831.56201186  -263.09997826
  -497.28428743 -1211.75759108]
total_rewards_mean           -955.1976323681884
total_rewards_std            481.32548725468234
total_rewards_max            -153.44866207865525
total_rewards_min            -1831.562011855275
Number of train steps total  1848000
Number of env steps total    3435689
Number of rollouts total     0
Train Time (s)               145.62788562709466
(Previous) Eval Time (s)     28.501319308765233
Sample Time (s)              11.222723597195
Epoch Time (s)               185.3519285330549
Total Train Time (s)         85952.34885031357
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:48:26.129231 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #461 | Epoch Duration: 185.47446060180664
2020-01-13 01:48:26.129476 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3437138
Z variance train             1.275666
KL Divergence                22.05524
KL Loss                      2.2055242
QF Loss                      9303.874
VF Loss                      1396.841
Policy Loss                  -2009.4512
Q Predictions Mean           1897.0647
Q Predictions Std            521.6058
Q Predictions Max            5025.799
Q Predictions Min            552.1881
V Predictions Mean           2017.1971
V Predictions Std            528.2412
V Predictions Max            5090.659
V Predictions Min            513.0493
Log Pis Mean                 10.708737
Log Pis Std                  4.390694
Log Pis Max                  21.467686
Log Pis Min                  -1.2977687
Policy mu Mean               0.57279074
Policy mu Std                1.5632331
Policy mu Max                4.0805984
Policy mu Min                -3.789943
Policy log std Mean          -0.9754025
Policy log std Std           0.36520895
Policy log std Max           0.004839301
Policy log std Min           -2.9472485
Z mean eval                  1.8313977
Z variance eval              0.15702382
total_rewards                [-1228.72401993  -721.89903565 -1092.44763423 -1162.95128414
 -1176.20857588 -1259.02005844  -720.35937849  -554.01812533
 -1282.7926503  -1003.23006315]
total_rewards_mean           -1020.1650825542469
total_rewards_std            248.1753177057004
total_rewards_max            -554.0181253343912
total_rewards_min            -1282.7926503004865
Number of train steps total  1852000
Number of env steps total    3445632
Number of rollouts total     0
Train Time (s)               146.387982416898
(Previous) Eval Time (s)     37.601451041176915
Sample Time (s)              11.277534376364201
Epoch Time (s)               195.26696783443913
Total Train Time (s)         86147.70964983525
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:51:41.494486 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #462 | Epoch Duration: 195.36484026908875
2020-01-13 01:51:41.494705 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8375736
Z variance train             0.15692994
KL Divergence                30.101124
KL Loss                      3.0101125
QF Loss                      4569.579
VF Loss                      763.2567
Policy Loss                  -2435.973
Q Predictions Mean           2393.1729
Q Predictions Std            452.47894
Q Predictions Max            5198.005
Q Predictions Min            680.7157
V Predictions Mean           2429.566
V Predictions Std            463.63217
V Predictions Max            5323.5166
V Predictions Min            704.4107
Log Pis Mean                 5.6454754
Log Pis Std                  3.4505112
Log Pis Max                  16.898167
Log Pis Min                  -3.7259183
Policy mu Mean               0.2433016
Policy mu Std                1.1193708
Policy mu Max                3.6186104
Policy mu Min                -3.6239674
Policy log std Mean          -1.1417534
Policy log std Std           0.3623766
Policy log std Max           0.1028831
Policy log std Min           -2.3172135
Z mean eval                  1.5064553
Z variance eval              0.36936206
total_rewards                [  -15.39097755 -1650.58153818    -6.29233436 -1581.59029224
 -1538.47231723 -1661.74895076  -695.83224458  -647.77680299
  -118.14072883 -1735.46088091]
total_rewards_mean           -965.1287067619569
total_rewards_std            704.9308606152464
total_rewards_max            -6.292334356092611
total_rewards_min            -1735.460880910667
Number of train steps total  1856000
Number of env steps total    3455241
Number of rollouts total     0
Train Time (s)               155.83874588413164
(Previous) Eval Time (s)     32.84383060969412
Sample Time (s)              11.84323683893308
Epoch Time (s)               200.52581333275884
Total Train Time (s)         86348.33462292328
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:55:02.124944 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #463 | Epoch Duration: 200.6300573348999
2020-01-13 01:55:02.125260 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #463 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5068963
Z variance train             0.3703989
KL Divergence                29.065975
KL Loss                      2.9065976
QF Loss                      1398.0286
VF Loss                      885.5798
Policy Loss                  -2427.071
Q Predictions Mean           2414.1218
Q Predictions Std            436.07278
Q Predictions Max            5810.136
Q Predictions Min            811.8073
V Predictions Mean           2408.5425
V Predictions Std            439.76907
V Predictions Max            5821.5186
V Predictions Min            838.1353
Log Pis Mean                 2.751493
Log Pis Std                  3.4741054
Log Pis Max                  20.047932
Log Pis Min                  -3.5919576
Policy mu Mean               0.09968827
Policy mu Std                0.84843105
Policy mu Max                4.444823
Policy mu Min                -2.9808865
Policy log std Mean          -1.0762329
Policy log std Std           0.25913233
Policy log std Max           -0.20737088
Policy log std Min           -2.5306683
Z mean eval                  1.649677
Z variance eval              0.09449485
total_rewards                [ -975.62834349    -3.79698549 -1151.93974304 -1405.50389313
 -1327.04829197 -1058.16741598  -858.88150902  -535.02112735
 -1509.1356246    -31.56453966]
total_rewards_mean           -885.6687473724617
total_rewards_std            509.2511465392485
total_rewards_max            -3.796985486461879
total_rewards_min            -1509.1356246032383
Number of train steps total  1860000
Number of env steps total    3465787
Number of rollouts total     0
Train Time (s)               155.215238397941
(Previous) Eval Time (s)     31.847028187010437
Sample Time (s)              12.356147425249219
Epoch Time (s)               199.41841401020065
Total Train Time (s)         86547.83890439896
Epoch                        464
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:58:21.633359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #464 | Epoch Duration: 199.50790858268738
2020-01-13 01:58:21.633589 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6558739
Z variance train             0.09436588
KL Divergence                32.99464
KL Loss                      3.299464
QF Loss                      2597.4536
VF Loss                      492.97147
Policy Loss                  -2451.636
Q Predictions Mean           2423.767
Q Predictions Std            403.03238
Q Predictions Max            5700.271
Q Predictions Min            1472.6166
V Predictions Mean           2452.6384
V Predictions Std            411.32065
V Predictions Max            5769.8647
V Predictions Min            1518.505
Log Pis Mean                 3.7324312
Log Pis Std                  3.7645948
Log Pis Max                  20.74686
Log Pis Min                  -7.583216
Policy mu Mean               0.19407423
Policy mu Std                1.0274291
Policy mu Max                3.6114235
Policy mu Min                -3.8583739
Policy log std Mean          -1.0306243
Policy log std Std           0.32641754
Policy log std Max           -0.009143591
Policy log std Min           -2.104727
Z mean eval                  1.4670593
Z variance eval              0.04022694
total_rewards                [ -600.4442791   -597.34793685  -610.89934876  -611.92237831
 -1136.94994001  -874.46668766  -644.10624255  -242.12884497
 -1070.03093699  -522.61408405]
total_rewards_mean           -691.0910679249416
total_rewards_std            252.56174093249467
total_rewards_max            -242.1288449727212
total_rewards_min            -1136.9499400081365
Number of train steps total  1864000
Number of env steps total    3476740
Number of rollouts total     0
Train Time (s)               155.32623335439712
(Previous) Eval Time (s)     39.1166378618218
Sample Time (s)              12.497152728494257
Epoch Time (s)               206.94002394471318
Total Train Time (s)         86754.87209829828
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:01:48.672575 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #465 | Epoch Duration: 207.03877472877502
2020-01-13 02:01:48.672995 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #465 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4705396
Z variance train             0.039684854
KL Divergence                34.811302
KL Loss                      3.4811304
QF Loss                      1860.9951
VF Loss                      251.60751
Policy Loss                  -2455.9456
Q Predictions Mean           2439.9922
Q Predictions Std            498.89856
Q Predictions Max            5476.131
Q Predictions Min            1792.189
V Predictions Mean           2451.5605
V Predictions Std            508.34427
V Predictions Max            5485.5654
V Predictions Min            1865.7659
Log Pis Mean                 3.125389
Log Pis Std                  3.0373724
Log Pis Max                  14.421695
Log Pis Min                  -4.304636
Policy mu Mean               0.056924686
Policy mu Std                0.92460394
Policy mu Max                3.2702234
Policy mu Min                -2.8541641
Policy log std Mean          -1.081892
Policy log std Std           0.31865126
Policy log std Max           -0.20511395
Policy log std Min           -2.5438843
Z mean eval                  1.5339372
Z variance eval              0.057225578
total_rewards                [  133.8433251   -153.56753905   -42.95456686  -111.40241391
    -4.88242179   -46.15362596   -95.95826525  -592.67374849
   -88.14005566 -1389.59969161]
total_rewards_mean           -239.14890034860022
total_rewards_std            422.51754760808905
total_rewards_max            133.8433250954985
total_rewards_min            -1389.5996916108504
Number of train steps total  1868000
Number of env steps total    3487338
Number of rollouts total     0
Train Time (s)               155.50987715274096
(Previous) Eval Time (s)     27.589270228054374
Sample Time (s)              12.390494063030928
Epoch Time (s)               195.48964144382626
Total Train Time (s)         86950.45323932031
Epoch                        466
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:05:04.258229 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #466 | Epoch Duration: 195.58493638038635
2020-01-13 02:05:04.258447 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #466 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.53384
Z variance train             0.057561614
KL Divergence                37.62921
KL Loss                      3.762921
QF Loss                      2796.5308
VF Loss                      452.15607
Policy Loss                  -2462.885
Q Predictions Mean           2446.0586
Q Predictions Std            404.8417
Q Predictions Max            4816.201
Q Predictions Min            1774.5165
V Predictions Mean           2458.642
V Predictions Std            389.11377
V Predictions Max            4758.111
V Predictions Min            1930.8787
Log Pis Mean                 3.200127
Log Pis Std                  4.886862
Log Pis Max                  35.910347
Log Pis Min                  -8.014471
Policy mu Mean               0.1709156
Policy mu Std                0.97258073
Policy mu Max                4.3826013
Policy mu Min                -6.048238
Policy log std Mean          -1.0172975
Policy log std Std           0.34338868
Policy log std Max           1.654614
Policy log std Min           -2.481945
Z mean eval                  2.1115394
Z variance eval              1.9846064
total_rewards                [-1569.79678491 -1541.14441643 -1539.21352751 -1588.68883011
 -1586.59454838 -1546.95081984 -1603.60809781 -1601.3974497
 -1602.60883158 -1578.16293838]
total_rewards_mean           -1575.816624465217
total_rewards_std            24.173024935097914
total_rewards_max            -1539.213527513276
total_rewards_min            -1603.6080978060043
Number of train steps total  1872000
Number of env steps total    3496537
Number of rollouts total     0
Train Time (s)               147.1874412917532
(Previous) Eval Time (s)     37.757904454134405
Sample Time (s)              10.198910893406719
Epoch Time (s)               195.14425663929433
Total Train Time (s)         87145.68494963972
Epoch                        467
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:08:19.493908 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #467 | Epoch Duration: 195.23531246185303
2020-01-13 02:08:19.494099 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.104244
Z variance train             1.9859552
KL Divergence                46.25187
KL Loss                      4.625187
QF Loss                      2671.1362
VF Loss                      744.7527
Policy Loss                  -3377.26
Q Predictions Mean           3320.0103
Q Predictions Std            256.8821
Q Predictions Max            4748.6113
Q Predictions Min            2669.5024
V Predictions Mean           3369.7153
V Predictions Std            254.2407
V Predictions Max            4712.885
V Predictions Min            2657.6995
Log Pis Mean                 6.877804
Log Pis Std                  3.4533467
Log Pis Max                  17.766865
Log Pis Min                  -1.6849246
Policy mu Mean               0.12830679
Policy mu Std                1.2813418
Policy mu Max                3.3009722
Policy mu Min                -4.0496225
Policy log std Mean          -1.1012304
Policy log std Std           0.39060915
Policy log std Max           -0.07941997
Policy log std Min           -2.4677644
Z mean eval                  1.8881868
Z variance eval              1.9746933
total_rewards                [-649.73024981  -27.76163975  -41.51454344  -41.58334714  -85.88661337
  -78.65345344   81.98524214  -88.15332464  -66.53226801  -72.21405807]
total_rewards_mean           -107.00442555392746
total_rewards_std            186.9679504333822
total_rewards_max            81.9852421417807
total_rewards_min            -649.7302498080759
Number of train steps total  1876000
Number of env steps total    3506886
Number of rollouts total     0
Train Time (s)               146.1362286619842
(Previous) Eval Time (s)     36.63175381766632
Sample Time (s)              9.305538319051266
Epoch Time (s)               192.0735207987018
Total Train Time (s)         87337.84424523031
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:11:31.657474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #468 | Epoch Duration: 192.1632354259491
2020-01-13 02:11:31.657659 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8877052
Z variance train             1.9733584
KL Divergence                36.88369
KL Loss                      3.688369
QF Loss                      2525.3325
VF Loss                      2129.0356
Policy Loss                  -3484.0684
Q Predictions Mean           3462.833
Q Predictions Std            306.01807
Q Predictions Max            4708.0728
Q Predictions Min            -348.60083
V Predictions Mean           3467.0823
V Predictions Std            251.36989
V Predictions Max            4718.7627
V Predictions Min            872.4731
Log Pis Mean                 2.3749845
Log Pis Std                  3.034281
Log Pis Max                  22.303846
Log Pis Min                  -5.929846
Policy mu Mean               0.26923913
Policy mu Std                0.76303345
Policy mu Max                3.339601
Policy mu Min                -5.5510044
Policy log std Mean          -1.1324221
Policy log std Std           0.30110082
Policy log std Max           0.56741774
Policy log std Min           -2.4532852
Z mean eval                  1.511378
Z variance eval              0.6469886
total_rewards                [ 206.32473102  193.74885306 -100.70732976  193.14299031  167.5334714
  171.10799045  217.10214026  192.34129615  257.25404077  170.57083923]
total_rewards_mean           166.8419022897579
total_rewards_std            92.70408011745324
total_rewards_max            257.25404076775123
total_rewards_min            -100.70732975832178
Number of train steps total  1880000
Number of env steps total    3517107
Number of rollouts total     0
Train Time (s)               151.5053587188013
(Previous) Eval Time (s)     38.27368598198518
Sample Time (s)              11.236215603072196
Epoch Time (s)               201.01526030385867
Total Train Time (s)         87538.97572779749
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:14:52.794516 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #469 | Epoch Duration: 201.136714220047
2020-01-13 02:14:52.794701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5130684
Z variance train             0.6514498
KL Divergence                27.709202
KL Loss                      2.7709203
QF Loss                      1421.4337
VF Loss                      477.47623
Policy Loss                  -2628.4573
Q Predictions Mean           2617.288
Q Predictions Std            228.28343
Q Predictions Max            3992.0544
Q Predictions Min            2171.3823
V Predictions Mean           2642.5132
V Predictions Std            233.33405
V Predictions Max            4090.2915
V Predictions Min            2244.3438
Log Pis Mean                 1.3464617
Log Pis Std                  3.0846443
Log Pis Max                  16.358215
Log Pis Min                  -6.7212124
Policy mu Mean               0.012771241
Policy mu Std                0.758811
Policy mu Max                2.753052
Policy mu Min                -2.5987368
Policy log std Mean          -1.0670648
Policy log std Std           0.28474715
Policy log std Max           -0.11076856
Policy log std Min           -2.336464
Z mean eval                  1.651881
Z variance eval              0.15953156
total_rewards                [  132.92861726  -230.59497359    62.34665059  -404.36717016
  -637.27021955  -665.3895596     80.9541662   -183.52561986
  -131.73736852 -1131.41694561]
total_rewards_mean           -310.80724228344866
total_rewards_std            381.9402337680712
total_rewards_max            132.92861726032154
total_rewards_min            -1131.416945606462
Number of train steps total  1884000
Number of env steps total    3526751
Number of rollouts total     0
Train Time (s)               156.75627081422135
(Previous) Eval Time (s)     38.24716995516792
Sample Time (s)              12.27584118861705
Epoch Time (s)               207.27928195800632
Total Train Time (s)         87746.34475207841
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:18:20.167768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #470 | Epoch Duration: 207.37292790412903
2020-01-13 02:18:20.167956 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6463255
Z variance train             0.15928319
KL Divergence                26.47218
KL Loss                      2.647218
QF Loss                      1160.5433
VF Loss                      455.33432
Policy Loss                  -2483.851
Q Predictions Mean           2472.5767
Q Predictions Std            295.3593
Q Predictions Max            4573.889
Q Predictions Min            2196.8506
V Predictions Mean           2485.9932
V Predictions Std            290.12457
V Predictions Max            4568.028
V Predictions Min            2178.6272
Log Pis Mean                 1.2383931
Log Pis Std                  3.6525822
Log Pis Max                  29.329075
Log Pis Min                  -6.281073
Policy mu Mean               -0.23317403
Policy mu Std                0.83765787
Policy mu Max                3.6641645
Policy mu Min                -3.2340252
Policy log std Mean          -0.8694089
Policy log std Std           0.20962384
Policy log std Max           0.49293673
Policy log std Min           -1.9819367
Z mean eval                  1.3724445
Z variance eval              0.040557772
total_rewards                [ -701.8655357   -213.92625428 -1282.65360445   147.38106066
 -1433.92331772  -501.0359526   -989.13530484 -1548.07824513
 -1208.51203642 -1196.56325599]
total_rewards_mean           -892.8312446472988
total_rewards_std            529.9243137762738
total_rewards_max            147.38106065895784
total_rewards_min            -1548.0782451294128
Number of train steps total  1888000
Number of env steps total    3538764
Number of rollouts total     0
Train Time (s)               154.5295878490433
(Previous) Eval Time (s)     34.59819925809279
Sample Time (s)              12.944148647598922
Epoch Time (s)               202.07193575473502
Total Train Time (s)         87948.50755064562
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:21:42.335767 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #471 | Epoch Duration: 202.16765236854553
2020-01-13 02:21:42.335986 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3764166
Z variance train             0.040424313
KL Divergence                27.430431
KL Loss                      2.7430432
QF Loss                      1922.9053
VF Loss                      418.10126
Policy Loss                  -2344.7021
Q Predictions Mean           2329.1025
Q Predictions Std            522.8097
Q Predictions Max            5324.17
Q Predictions Min            2009.6099
V Predictions Mean           2347.9658
V Predictions Std            533.0293
V Predictions Max            5424.415
V Predictions Min            2021.0354
Log Pis Mean                 1.5231928
Log Pis Std                  3.6864562
Log Pis Max                  13.894294
Log Pis Min                  -10.548094
Policy mu Mean               -0.108149566
Policy mu Std                0.8771419
Policy mu Max                3.9705608
Policy mu Min                -2.9425447
Policy log std Mean          -0.9029944
Policy log std Std           0.25123522
Policy log std Max           0.4697739
Policy log std Min           -2.359798
Z mean eval                  2.2070887
Z variance eval              0.029800028
total_rewards                [-2109.28240386 -1561.31293955 -1587.6009717    -34.65849265
 -1032.03986411  -431.62683272 -1575.03922132 -1288.47319328
 -2063.83459115 -1499.26492321]
total_rewards_mean           -1318.3133433555574
total_rewards_std            626.7755539377654
total_rewards_max            -34.65849265036888
total_rewards_min            -2109.2824038636045
Number of train steps total  1892000
Number of env steps total    3548506
Number of rollouts total     0
Train Time (s)               156.7699905829504
(Previous) Eval Time (s)     33.442267037928104
Sample Time (s)              12.208178667351604
Epoch Time (s)               202.42043628823012
Total Train Time (s)         88151.03096219013
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:25:04.864680 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #472 | Epoch Duration: 202.52851724624634
2020-01-13 02:25:04.864943 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #472 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2085512
Z variance train             0.029182117
KL Divergence                47.091568
KL Loss                      4.709157
QF Loss                      8681.773
VF Loss                      1224.814
Policy Loss                  -3536.3477
Q Predictions Mean           3412.9873
Q Predictions Std            476.32193
Q Predictions Max            6515.452
Q Predictions Min            2675.5537
V Predictions Mean           3530.0376
V Predictions Std            485.99866
V Predictions Max            6722.547
V Predictions Min            2679.3345
Log Pis Mean                 11.765144
Log Pis Std                  4.1446996
Log Pis Max                  24.1194
Log Pis Min                  -2.4798625
Policy mu Mean               0.19813332
Policy mu Std                1.7121174
Policy mu Max                3.6062796
Policy mu Min                -3.8428705
Policy log std Mean          -0.91487235
Policy log std Std           0.35932347
Policy log std Max           0.10360038
Policy log std Min           -2.356411
Z mean eval                  2.1718335
Z variance eval              0.5872631
total_rewards                [ 18.01663442  30.256869    92.72074995 -22.62190939   7.3637615
  21.43119532 -89.65955084  97.11349658 -11.08262339  44.23150996]
total_rewards_mean           18.777013310364048
total_rewards_std            51.85155890576186
total_rewards_max            97.11349657974264
total_rewards_min            -89.65955084126195
Number of train steps total  1896000
Number of env steps total    3558858
Number of rollouts total     0
Train Time (s)               151.67419994296506
(Previous) Eval Time (s)     37.013111669104546
Sample Time (s)              12.178819119930267
Epoch Time (s)               200.86613073199987
Total Train Time (s)         88351.98635580251
Epoch                        473
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:28:25.824579 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #473 | Epoch Duration: 200.95946264266968
2020-01-13 02:28:25.824783 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1677806
Z variance train             0.5841539
KL Divergence                46.55629
KL Loss                      4.655629
QF Loss                      1940.3091
VF Loss                      601.46765
Policy Loss                  -3835.9368
Q Predictions Mean           3817.9644
Q Predictions Std            304.46622
Q Predictions Max            5885.3843
Q Predictions Min            2893.337
V Predictions Mean           3847.1462
V Predictions Std            306.98672
V Predictions Max            5987.678
V Predictions Min            2877.9065
Log Pis Mean                 3.5674095
Log Pis Std                  2.8162315
Log Pis Max                  12.050602
Log Pis Min                  -8.333241
Policy mu Mean               0.23021689
Policy mu Std                0.8687053
Policy mu Max                2.7837272
Policy mu Min                -2.5728374
Policy log std Mean          -1.171576
Policy log std Std           0.27529266
Policy log std Max           -0.29912752
Policy log std Min           -2.6179938
Z mean eval                  1.8064249
Z variance eval              0.18604465
total_rewards                [-1470.99372312    74.13602468   659.32242027  -368.98454889
  -850.80672751    96.04362818  -499.32114511 -1495.12213663
     3.17924843   112.63576128]
total_rewards_mean           -373.991119841861
total_rewards_std            676.1646216286244
total_rewards_max            659.3224202678535
total_rewards_min            -1495.1221366272475
Number of train steps total  1900000
Number of env steps total    3569425
Number of rollouts total     0
Train Time (s)               147.43013457208872
(Previous) Eval Time (s)     26.517106999177486
Sample Time (s)              11.543551869224757
Epoch Time (s)               185.49079344049096
Total Train Time (s)         88537.57717126422
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:31:31.419740 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #474 | Epoch Duration: 185.59480786323547
2020-01-13 02:31:31.419965 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8085451
Z variance train             0.18804342
KL Divergence                37.113716
KL Loss                      3.7113717
QF Loss                      70445.15
VF Loss                      2400.1938
Policy Loss                  -3087.977
Q Predictions Mean           3078.0557
Q Predictions Std            476.9553
Q Predictions Max            5525.264
Q Predictions Min            -146.44978
V Predictions Mean           3121.9404
V Predictions Std            505.3262
V Predictions Max            5608.5913
V Predictions Min            -24.747017
Log Pis Mean                 3.0020964
Log Pis Std                  3.7263348
Log Pis Max                  17.181757
Log Pis Min                  -5.6721992
Policy mu Mean               0.031168777
Policy mu Std                0.9728331
Policy mu Max                3.6208098
Policy mu Min                -4.6247277
Policy log std Mean          -0.9680705
Policy log std Std           0.2861239
Policy log std Max           0.038116693
Policy log std Min           -2.3827648
Z mean eval                  1.6374677
Z variance eval              0.25213757
total_rewards                [ -308.0476967   -744.21249037 -1146.8071778     64.89839202
  -692.16907679  -731.06756562   176.20732459  -762.49337452
  -730.71520477  -548.53635137]
total_rewards_mean           -542.2943221328567
total_rewards_std            385.76322057359846
total_rewards_max            176.20732459344967
total_rewards_min            -1146.8071777987327
Number of train steps total  1904000
Number of env steps total    3579909
Number of rollouts total     0
Train Time (s)               148.59202477522194
(Previous) Eval Time (s)     31.32321002194658
Sample Time (s)              10.258651015348732
Epoch Time (s)               190.17388581251726
Total Train Time (s)         88727.83991139848
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:34:41.686835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #475 | Epoch Duration: 190.26672840118408
2020-01-13 02:34:41.687041 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6501383
Z variance train             0.25051194
KL Divergence                29.77692
KL Loss                      2.9776921
QF Loss                      1539.2621
VF Loss                      968.79144
Policy Loss                  -2858.311
Q Predictions Mean           2845.1978
Q Predictions Std            455.0972
Q Predictions Max            4743.884
Q Predictions Min            2407.9543
V Predictions Mean           2836.1917
V Predictions Std            458.94678
V Predictions Max            4766.1064
V Predictions Min            2395.4785
Log Pis Mean                 1.5569141
Log Pis Std                  3.1118958
Log Pis Max                  10.879843
Log Pis Min                  -9.480036
Policy mu Mean               -0.04831212
Policy mu Std                0.8125181
Policy mu Max                2.77695
Policy mu Min                -2.5303268
Policy log std Mean          -1.0348387
Policy log std Std           0.26228806
Policy log std Max           0.17380798
Policy log std Min           -2.2581367
Z mean eval                  1.4659308
Z variance eval              0.14255208
total_rewards                [-365.63453864  138.05249148   33.22611279   65.09038335 -177.22415855
 -355.90503417 -156.54013552 -249.60501214 -308.80968218   31.13288171]
total_rewards_mean           -134.62166918688862
total_rewards_std            178.34653028521487
total_rewards_max            138.05249148228978
total_rewards_min            -365.63453864120123
Number of train steps total  1908000
Number of env steps total    3589201
Number of rollouts total     0
Train Time (s)               157.7367255068384
(Previous) Eval Time (s)     26.843141599092633
Sample Time (s)              12.169076247606426
Epoch Time (s)               196.74894335353747
Total Train Time (s)         88924.67588792462
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:37:58.527417 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #476 | Epoch Duration: 196.840234041214
2020-01-13 02:37:58.527592 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.464988
Z variance train             0.14470778
KL Divergence                28.989937
KL Loss                      2.8989937
QF Loss                      1688.063
VF Loss                      493.39706
Policy Loss                  -2464.1172
Q Predictions Mean           2451.4724
Q Predictions Std            326.96976
Q Predictions Max            3980.1375
Q Predictions Min            2028.0542
V Predictions Mean           2455.2056
V Predictions Std            332.6365
V Predictions Max            3970.9958
V Predictions Min            1997.677
Log Pis Mean                 2.1050289
Log Pis Std                  3.334293
Log Pis Max                  10.0509615
Log Pis Min                  -9.6533
Policy mu Mean               -0.0011637739
Policy mu Std                0.8959143
Policy mu Max                3.095164
Policy mu Min                -2.9874072
Policy log std Mean          -1.011713
Policy log std Std           0.3028885
Policy log std Max           -0.14779437
Policy log std Min           -2.3732734
Z mean eval                  1.3616287
Z variance eval              0.059483536
total_rewards                [ -67.09960373 -490.73534416   -1.67859603 -100.56066037 -131.47374077
   -3.39421353  -21.3189905   -10.58671169 -533.67741467 -101.58614859]
total_rewards_mean           -146.21114240349237
total_rewards_std            188.32328290178071
total_rewards_max            -1.678596025784616
total_rewards_min            -533.6774146695341
Number of train steps total  1912000
Number of env steps total    3601323
Number of rollouts total     0
Train Time (s)               156.81388277281076
(Previous) Eval Time (s)     29.874452830292284
Sample Time (s)              12.023861976340413
Epoch Time (s)               198.71219757944345
Total Train Time (s)         89123.47853773879
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:41:17.335227 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #477 | Epoch Duration: 198.80748748779297
2020-01-13 02:41:17.335425 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3670542
Z variance train             0.058624603
KL Divergence                28.83055
KL Loss                      2.883055
QF Loss                      938.06604
VF Loss                      256.89975
Policy Loss                  -2291.1792
Q Predictions Mean           2282.1108
Q Predictions Std            243.62788
Q Predictions Max            3351.432
Q Predictions Min            1066.9342
V Predictions Mean           2293.8008
V Predictions Std            242.16576
V Predictions Max            3353.8315
V Predictions Min            1053.6154
Log Pis Mean                 1.890149
Log Pis Std                  2.8925586
Log Pis Max                  17.532288
Log Pis Min                  -6.417572
Policy mu Mean               0.07339918
Policy mu Std                0.81272876
Policy mu Max                2.7186255
Policy mu Min                -2.5021768
Policy log std Mean          -1.0206597
Policy log std Std           0.31945157
Policy log std Max           -0.21443748
Policy log std Min           -3.3049417
Z mean eval                  1.3460915
Z variance eval              0.18903759
total_rewards                [ 175.92485354   85.80921396   32.27848008  103.95394195  -14.12768667
    5.31072366 -534.04041542   23.57582059  -92.42746577   99.40432649]
total_rewards_mean           -11.433820760160433
total_rewards_std            187.9522842453893
total_rewards_max            175.9248535374344
total_rewards_min            -534.0404154182312
Number of train steps total  1916000
Number of env steps total    3612323
Number of rollouts total     0
Train Time (s)               156.0955765149556
(Previous) Eval Time (s)     36.05135988164693
Sample Time (s)              11.515338053461164
Epoch Time (s)               203.6622744500637
Total Train Time (s)         89327.2317202054
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:44:41.093587 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #478 | Epoch Duration: 203.75800228118896
2020-01-13 02:44:41.093837 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3455818
Z variance train             0.18940254
KL Divergence                22.142014
KL Loss                      2.2142015
QF Loss                      528.17334
VF Loss                      121.26129
Policy Loss                  -2058.0725
Q Predictions Mean           2053.1514
Q Predictions Std            158.23024
Q Predictions Max            2741.1316
Q Predictions Min            1726.5397
V Predictions Mean           2055.4307
V Predictions Std            154.13692
V Predictions Max            2755.7617
V Predictions Min            1755.4749
Log Pis Mean                 1.6197436
Log Pis Std                  2.8884976
Log Pis Max                  12.108721
Log Pis Min                  -7.958538
Policy mu Mean               0.0065767295
Policy mu Std                0.76225674
Policy mu Max                2.4216673
Policy mu Min                -2.8668067
Policy log std Mean          -1.0493013
Policy log std Std           0.26838413
Policy log std Max           -0.2801854
Policy log std Min           -2.3451433
Z mean eval                  1.086322
Z variance eval              1.4962488
total_rewards                [ 571.85293817   51.90948321  128.37297224 -393.8762518  -230.25825955
  -24.99107511   23.02336537  -58.14479045 -331.67955086  -77.80455554]
total_rewards_mean           -34.159572431592515
total_rewards_std            257.5420199587362
total_rewards_max            571.8529381697474
total_rewards_min            -393.87625179930825
Number of train steps total  1920000
Number of env steps total    3621053
Number of rollouts total     0
Train Time (s)               156.0752785447985
(Previous) Eval Time (s)     37.73319547390565
Sample Time (s)              12.679944318253547
Epoch Time (s)               206.4884183369577
Total Train Time (s)         89533.81129262643
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:48:07.678620 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #479 | Epoch Duration: 206.58460545539856
2020-01-13 02:48:07.678855 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0844413
Z variance train             1.4981116
KL Divergence                15.095649
KL Loss                      1.5095649
QF Loss                      785.6883
VF Loss                      1063.8011
Policy Loss                  -2299.7239
Q Predictions Mean           2297.2024
Q Predictions Std            160.44185
Q Predictions Max            2761.3652
Q Predictions Min            437.4043
V Predictions Mean           2285.7812
V Predictions Std            143.23083
V Predictions Max            2735.1963
V Predictions Min            790.53986
Log Pis Mean                 0.9358182
Log Pis Std                  2.723105
Log Pis Max                  7.695134
Log Pis Min                  -6.6436396
Policy mu Mean               0.05017925
Policy mu Std                0.6933471
Policy mu Max                2.1826282
Policy mu Min                -2.3004081
Policy log std Mean          -1.0410205
Policy log std Std           0.28418067
Policy log std Max           0.04163885
Policy log std Min           -2.725298
Z mean eval                  1.0994899
Z variance eval              0.1535901
total_rewards                [ 230.71784875  731.75761516  209.40203671   12.97097248 -524.65737505
 1413.2348816   372.92298838  986.75316909   45.67479912  104.12567993]
total_rewards_mean           358.2902616164431
total_rewards_std            524.1353055003145
total_rewards_max            1413.2348816028732
total_rewards_min            -524.6573750483459
Number of train steps total  1924000
Number of env steps total    3630078
Number of rollouts total     0
Train Time (s)               146.9065451528877
(Previous) Eval Time (s)     28.457637226209044
Sample Time (s)              12.342356280889362
Epoch Time (s)               187.7065386599861
Total Train Time (s)         89721.62160738604
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:51:15.493771 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #480 | Epoch Duration: 187.81474494934082
2020-01-13 02:51:15.493985 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0967361
Z variance train             0.15503374
KL Divergence                13.270209
KL Loss                      1.327021
QF Loss                      940.3413
VF Loss                      122.47278
Policy Loss                  -1723.9142
Q Predictions Mean           1721.0698
Q Predictions Std            75.0796
Q Predictions Max            1921.7606
Q Predictions Min            1423.1536
V Predictions Mean           1727.1226
V Predictions Std            71.87636
V Predictions Max            1920.989
V Predictions Min            1430.3363
Log Pis Mean                 0.7706996
Log Pis Std                  2.1356866
Log Pis Max                  5.8758016
Log Pis Min                  -5.661238
Policy mu Mean               0.019178526
Policy mu Std                0.6161614
Policy mu Max                2.1085618
Policy mu Min                -2.4611032
Policy log std Mean          -1.0970309
Policy log std Std           0.21986507
Policy log std Max           -0.44118
Policy log std Min           -2.028706
Z mean eval                  0.99225795
Z variance eval              0.21327397
total_rewards                [1056.35357193  393.70937789 1711.27838695   47.67443356  456.48259339
 1186.98270875 1386.63954273  312.14155718  460.19561567  242.66180996]
total_rewards_mean           725.4119598019778
total_rewards_std            533.6274017521843
total_rewards_max            1711.2783869472705
total_rewards_min            47.67443356397398
Number of train steps total  1928000
Number of env steps total    3641954
Number of rollouts total     0
Train Time (s)               147.78048055199906
(Previous) Eval Time (s)     20.516153757926077
Sample Time (s)              11.815248299390078
Epoch Time (s)               180.11188260931522
Total Train Time (s)         89901.8319723974
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:54:15.708662 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #481 | Epoch Duration: 180.21452260017395
2020-01-13 02:54:15.708850 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0199561
Z variance train             0.2100027
KL Divergence                11.268215
KL Loss                      1.1268215
QF Loss                      1128.2477
VF Loss                      444.1781
Policy Loss                  -1496.203
Q Predictions Mean           1491.2056
Q Predictions Std            121.019485
Q Predictions Max            1719.3634
Q Predictions Min            799.21606
V Predictions Mean           1491.9397
V Predictions Std            110.11837
V Predictions Max            1719.7905
V Predictions Min            948.596
Log Pis Mean                 1.080584
Log Pis Std                  2.7013621
Log Pis Max                  14.305279
Log Pis Min                  -5.007361
Policy mu Mean               -0.0110668605
Policy mu Std                0.6507311
Policy mu Max                3.727755
Policy mu Min                -2.7475138
Policy log std Mean          -1.1065046
Policy log std Std           0.23939224
Policy log std Max           -0.21726733
Policy log std Min           -2.1546326
Z mean eval                  1.0281537
Z variance eval              0.11372882
total_rewards                [ 223.09966672  224.63855993  272.37660361 1278.15040726 1233.22174122
  844.90940618  605.54766164  132.22864883  627.23619219   19.30098185]
total_rewards_mean           546.0709869428223
total_rewards_std            428.81652444021864
total_rewards_max            1278.1504072634011
total_rewards_min            19.30098184866982
Number of train steps total  1932000
Number of env steps total    3652481
Number of rollouts total     0
Train Time (s)               154.2237919261679
(Previous) Eval Time (s)     12.371468075085431
Sample Time (s)              11.190975163597614
Epoch Time (s)               177.78623516485095
Total Train Time (s)         90079.71914189914
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:57:13.600669 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #482 | Epoch Duration: 177.8916699886322
2020-01-13 02:57:13.600881 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0299575
Z variance train             0.113900706
KL Divergence                12.915306
KL Loss                      1.2915306
QF Loss                      488.30124
VF Loss                      240.70033
Policy Loss                  -1500.4496
Q Predictions Mean           1496.2737
Q Predictions Std            137.85965
Q Predictions Max            1741.5146
Q Predictions Min            994.6639
V Predictions Mean           1499.0709
V Predictions Std            135.34367
V Predictions Max            1725.9753
V Predictions Min            1009.8266
Log Pis Mean                 0.5812944
Log Pis Std                  2.2714357
Log Pis Max                  6.756836
Log Pis Min                  -7.444729
Policy mu Mean               0.003610616
Policy mu Std                0.6231733
Policy mu Max                2.1516078
Policy mu Min                -2.2910082
Policy log std Mean          -1.0661137
Policy log std Std           0.2045464
Policy log std Max           -0.33058417
Policy log std Min           -2.0879807
Z mean eval                  0.88468564
Z variance eval              0.05836014
total_rewards                [1894.30887092 3129.77307893  400.1981261  2930.73592089 3090.84698216
 2147.40424836  750.72091745 2189.48494239 1337.68395347 2171.1915472 ]
total_rewards_mean           2004.2348587875053
total_rewards_std            893.8266546846922
total_rewards_max            3129.773078927155
total_rewards_min            400.19812609901436
Number of train steps total  1936000
Number of env steps total    3664445
Number of rollouts total     0
Train Time (s)               157.25302554573864
(Previous) Eval Time (s)     31.92729904083535
Sample Time (s)              12.531807195860893
Epoch Time (s)               201.71213178243488
Total Train Time (s)         90281.52216790151
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:00:35.409198 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #483 | Epoch Duration: 201.80812239646912
2020-01-13 03:00:35.409483 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8847786
Z variance train             0.05847159
KL Divergence                11.940444
KL Loss                      1.1940445
QF Loss                      429.94937
VF Loss                      118.7641
Policy Loss                  -1357.3978
Q Predictions Mean           1351.5105
Q Predictions Std            178.43466
Q Predictions Max            1577.8124
Q Predictions Min            778.52185
V Predictions Mean           1356.5674
V Predictions Std            180.09094
V Predictions Max            1570.3536
V Predictions Min            768.2548
Log Pis Mean                 0.55510694
Log Pis Std                  2.466086
Log Pis Max                  8.8101635
Log Pis Min                  -6.410637
Policy mu Mean               0.03814994
Policy mu Std                0.6240757
Policy mu Max                1.9363247
Policy mu Min                -2.4548826
Policy log std Mean          -1.071042
Policy log std Std           0.23500696
Policy log std Max           -0.35070145
Policy log std Min           -2.275991
Z mean eval                  1.0720505
Z variance eval              0.33122426
total_rewards                [  55.43864696  418.05529884  543.11427088  119.92608543  573.05963144
  590.31743365 2321.09525235 1968.43653329  849.68157684  786.22853302]
total_rewards_mean           822.5353262696286
total_rewards_std            707.1610199878392
total_rewards_max            2321.0952523456085
total_rewards_min            55.43864696220638
Number of train steps total  1940000
Number of env steps total    3676297
Number of rollouts total     0
Train Time (s)               156.22344792308286
(Previous) Eval Time (s)     17.32925790315494
Sample Time (s)              11.617081863805652
Epoch Time (s)               185.16978769004345
Total Train Time (s)         90466.78213822236
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:03:40.673672 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #484 | Epoch Duration: 185.2640242576599
2020-01-13 03:03:40.673871 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.070938
Z variance train             0.3307286
KL Divergence                10.859671
KL Loss                      1.0859671
QF Loss                      472.09503
VF Loss                      87.05776
Policy Loss                  -1450.0492
Q Predictions Mean           1446.8813
Q Predictions Std            163.25644
Q Predictions Max            1697.912
Q Predictions Min            793.7174
V Predictions Mean           1454.6849
V Predictions Std            163.51389
V Predictions Max            1673.9355
V Predictions Min            797.45
Log Pis Mean                 0.08129963
Log Pis Std                  2.1681275
Log Pis Max                  9.063774
Log Pis Min                  -5.71247
Policy mu Mean               0.031218437
Policy mu Std                0.6076
Policy mu Max                2.4014516
Policy mu Min                -1.9831285
Policy log std Mean          -1.0050879
Policy log std Std           0.19335048
Policy log std Max           -0.26674616
Policy log std Min           -2.0512927
Z mean eval                  0.77631056
Z variance eval              0.16933446
total_rewards                [3182.48979096  323.19765545  601.70560034  526.21808933 3497.51703597
  571.77095553 2913.87087505 1722.03262659  359.51454997 3285.93556783]
total_rewards_mean           1698.4252747016235
total_rewards_std            1302.5889419593213
total_rewards_max            3497.5170359663675
total_rewards_min            323.1976554458289
Number of train steps total  1944000
Number of env steps total    3688686
Number of rollouts total     0
Train Time (s)               157.89984565600753
(Previous) Eval Time (s)     27.19442773377523
Sample Time (s)              12.048894727602601
Epoch Time (s)               197.14316811738536
Total Train Time (s)         90664.0243445728
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:06:57.920786 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #485 | Epoch Duration: 197.24676275253296
2020-01-13 03:06:57.920993 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7748818
Z variance train             0.16926901
KL Divergence                9.857824
KL Loss                      0.98578244
QF Loss                      370.4488
VF Loss                      942.504
Policy Loss                  -1226.5463
Q Predictions Mean           1222.0278
Q Predictions Std            183.9265
Q Predictions Max            1450.9952
Q Predictions Min            43.59958
V Predictions Mean           1224.154
V Predictions Std            172.68806
V Predictions Max            1451.4462
V Predictions Min            535.8017
Log Pis Mean                 0.47056216
Log Pis Std                  2.5539834
Log Pis Max                  8.822739
Log Pis Min                  -9.104761
Policy mu Mean               0.0063110767
Policy mu Std                0.61808413
Policy mu Max                2.4105277
Policy mu Min                -2.0642793
Policy log std Mean          -1.0481054
Policy log std Std           0.23279092
Policy log std Max           -0.22646797
Policy log std Min           -2.4265833
Z mean eval                  0.97461814
Z variance eval              0.14691249
total_rewards                [1553.24655696  289.34914552  818.39273265  829.73978591 1301.73851479
  723.09277037  377.7268719  2158.75918434  725.03476453  820.40450079]
total_rewards_mean           959.7484827769846
total_rewards_std            535.0144994178199
total_rewards_max            2158.7591843444648
total_rewards_min            289.34914552323164
Number of train steps total  1948000
Number of env steps total    3700189
Number of rollouts total     0
Train Time (s)               154.03655574191362
(Previous) Eval Time (s)     16.46603644406423
Sample Time (s)              11.779820902273059
Epoch Time (s)               182.2824130882509
Total Train Time (s)         90846.39790165285
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:10:00.299722 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #486 | Epoch Duration: 182.37858057022095
2020-01-13 03:10:00.299941 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9740728
Z variance train             0.14668079
KL Divergence                10.568987
KL Loss                      1.0568987
QF Loss                      13605.193
VF Loss                      57.09163
Policy Loss                  -1265.0077
Q Predictions Mean           1260.7251
Q Predictions Std            218.32559
Q Predictions Max            1546.1681
Q Predictions Min            467.451
V Predictions Mean           1267.2063
V Predictions Std            218.79762
V Predictions Max            1552.5444
V Predictions Min            464.44064
Log Pis Mean                 0.17483309
Log Pis Std                  2.5611231
Log Pis Max                  6.623026
Log Pis Min                  -8.177667
Policy mu Mean               0.017744936
Policy mu Std                0.62942964
Policy mu Max                2.3577976
Policy mu Min                -2.550344
Policy log std Mean          -1.0117452
Policy log std Std           0.25007394
Policy log std Max           -0.3026806
Policy log std Min           -2.2807155
Z mean eval                  0.9137982
Z variance eval              0.4056898
total_rewards                [3284.46059136 3226.35226826 3514.7731891  3086.76191194 2245.54712459
 3194.36208146 3281.58165539 3384.28413219 3093.17119842 3140.8443202 ]
total_rewards_mean           3145.2138472911497
total_rewards_std            325.00121631847674
total_rewards_max            3514.7731891045887
total_rewards_min            2245.5471245938465
Number of train steps total  1952000
Number of env steps total    3710517
Number of rollouts total     0
Train Time (s)               146.46870141895488
(Previous) Eval Time (s)     35.90183064667508
Sample Time (s)              12.422869224566966
Epoch Time (s)               194.79340129019693
Total Train Time (s)         91041.28845147276
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:13:15.194787 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #487 | Epoch Duration: 194.89470148086548
2020-01-13 03:13:15.194961 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9133965
Z variance train             0.4057835
KL Divergence                9.436678
KL Loss                      0.9436678
QF Loss                      1592.4642
VF Loss                      127.57171
Policy Loss                  -1104.947
Q Predictions Mean           1100.2898
Q Predictions Std            219.00735
Q Predictions Max            1355.1962
Q Predictions Min            172.04335
V Predictions Mean           1105.7231
V Predictions Std            215.6126
V Predictions Max            1356.9199
V Predictions Min            397.6741
Log Pis Mean                 0.19803198
Log Pis Std                  2.5617537
Log Pis Max                  11.562245
Log Pis Min                  -6.8019934
Policy mu Mean               -0.007658816
Policy mu Std                0.5976412
Policy mu Max                3.0493608
Policy mu Min                -2.3360412
Policy log std Mean          -1.0504856
Policy log std Std           0.23447995
Policy log std Max           -0.3715179
Policy log std Min           -2.1943092
Z mean eval                  0.78319144
Z variance eval              0.33449095
total_rewards                [ 975.78531003  403.5556957  3264.4265885  1425.83504647 3121.55906162
 3439.55364161 3305.07617166 3275.3924633  2896.59265945 3316.97977698]
total_rewards_mean           2542.4756415321594
total_rewards_std            1085.4337942908942
total_rewards_max            3439.553641607851
total_rewards_min            403.55569570355726
Number of train steps total  1956000
Number of env steps total    3720643
Number of rollouts total     0
Train Time (s)               147.04821848496795
(Previous) Eval Time (s)     28.137658598367125
Sample Time (s)              11.110798901878297
Epoch Time (s)               186.29667598521337
Total Train Time (s)         91227.67006479204
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:16:21.581272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #488 | Epoch Duration: 186.3861644268036
2020-01-13 03:16:21.581461 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79240984
Z variance train             0.33480826
KL Divergence                9.263448
KL Loss                      0.9263448
QF Loss                      866.0349
VF Loss                      67.86053
Policy Loss                  -1213.0598
Q Predictions Mean           1205.5325
Q Predictions Std            214.2181
Q Predictions Max            1446.5461
Q Predictions Min            441.66727
V Predictions Mean           1212.346
V Predictions Std            212.1815
V Predictions Max            1453.3553
V Predictions Min            441.08405
Log Pis Mean                 0.30084664
Log Pis Std                  2.5945544
Log Pis Max                  9.118002
Log Pis Min                  -8.220424
Policy mu Mean               0.017102491
Policy mu Std                0.6287512
Policy mu Max                2.8581245
Policy mu Min                -2.1216755
Policy log std Mean          -1.0449991
Policy log std Std           0.23455487
Policy log std Max           -0.2697904
Policy log std Min           -2.2631178
Z mean eval                  0.7719073
Z variance eval              0.115203716
total_rewards                [1825.74080744 1352.04720357  951.02162677   65.39068228  636.97010254
   62.00534905  286.77516228 2775.25341135 1622.66836347 1041.94904149]
total_rewards_mean           1061.9821750236647
total_rewards_std            818.8147104489158
total_rewards_max            2775.253411350576
total_rewards_min            62.00534905307855
Number of train steps total  1960000
Number of env steps total    3731277
Number of rollouts total     0
Train Time (s)               156.2592238667421
(Previous) Eval Time (s)     14.65529271075502
Sample Time (s)              11.405473788734525
Epoch Time (s)               182.31999036623165
Total Train Time (s)         91410.08609912498
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:19:24.002952 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #489 | Epoch Duration: 182.4213309288025
2020-01-13 03:19:24.003236 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77323925
Z variance train             0.115926884
KL Divergence                11.102877
KL Loss                      1.1102877
QF Loss                      702.8611
VF Loss                      66.39022
Policy Loss                  -1229.4756
Q Predictions Mean           1224.6167
Q Predictions Std            285.58395
Q Predictions Max            1519.1298
Q Predictions Min            349.32675
V Predictions Mean           1229.0828
V Predictions Std            285.10065
V Predictions Max            1501.6543
V Predictions Min            350.64655
Log Pis Mean                 0.21299879
Log Pis Std                  2.3978975
Log Pis Max                  8.878485
Log Pis Min                  -5.968558
Policy mu Mean               0.024339492
Policy mu Std                0.58987266
Policy mu Max                2.319182
Policy mu Min                -2.4222422
Policy log std Mean          -1.0408123
Policy log std Std           0.23297267
Policy log std Max           -0.24619997
Policy log std Min           -2.2820582
Z mean eval                  0.80931294
Z variance eval              0.26483506
total_rewards                [2760.9613509  2659.33987167 2479.99607873 3237.76903092 3371.76183579
 1848.31692853  512.03563195  637.64347819 3182.40143228 1508.44598807]
total_rewards_mean           2219.867162702484
total_rewards_std            995.3559160525939
total_rewards_max            3371.7618357889855
total_rewards_min            512.0356319500252
Number of train steps total  1964000
Number of env steps total    3742318
Number of rollouts total     0
Train Time (s)               156.1744965412654
(Previous) Eval Time (s)     28.645975910127163
Sample Time (s)              12.430069982539862
Epoch Time (s)               197.25054243393242
Total Train Time (s)         91607.43752974365
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:22:41.360243 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #490 | Epoch Duration: 197.35682439804077
2020-01-13 03:22:41.360569 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8146478
Z variance train             0.26378483
KL Divergence                8.249653
KL Loss                      0.8249653
QF Loss                      338.3971
VF Loss                      142.017
Policy Loss                  -1125.6927
Q Predictions Mean           1119.463
Q Predictions Std            222.02876
Q Predictions Max            1391.247
Q Predictions Min            347.08847
V Predictions Mean           1116.4434
V Predictions Std            222.06879
V Predictions Max            1389.6492
V Predictions Min            343.55875
Log Pis Mean                 0.6099752
Log Pis Std                  2.3823879
Log Pis Max                  8.708969
Log Pis Min                  -5.4163
Policy mu Mean               -0.025924623
Policy mu Std                0.64141214
Policy mu Max                2.0927675
Policy mu Min                -2.7672582
Policy log std Mean          -1.0334961
Policy log std Std           0.22908227
Policy log std Max           -0.33405966
Policy log std Min           -1.839479
Z mean eval                  0.8733013
Z variance eval              0.13095024
total_rewards                [ 308.90379882 1665.63202622 3211.19356801 2933.08157705 1275.88410139
  904.55755295 1943.72852706  265.05634497  712.44919887 1638.34168695]
total_rewards_mean           1485.8828382283123
total_rewards_std            958.7592287434688
total_rewards_max            3211.193568013182
total_rewards_min            265.05634496911335
Number of train steps total  1968000
Number of env steps total    3752827
Number of rollouts total     0
Train Time (s)               155.5984173170291
(Previous) Eval Time (s)     24.541277300100774
Sample Time (s)              13.114550909493119
Epoch Time (s)               193.25424552662298
Total Train Time (s)         91800.80156697286
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:25:54.729749 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #491 | Epoch Duration: 193.3689205646515
2020-01-13 03:25:54.730145 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87180203
Z variance train             0.13089153
KL Divergence                9.914138
KL Loss                      0.9914138
QF Loss                      248.85701
VF Loss                      72.33217
Policy Loss                  -1211.2716
Q Predictions Mean           1209.3444
Q Predictions Std            258.79523
Q Predictions Max            1515.919
Q Predictions Min            363.30432
V Predictions Mean           1209.1125
V Predictions Std            258.14868
V Predictions Max            1507.8699
V Predictions Min            364.617
Log Pis Mean                 0.5213634
Log Pis Std                  2.653518
Log Pis Max                  10.845838
Log Pis Min                  -9.813751
Policy mu Mean               0.047015693
Policy mu Std                0.6068443
Policy mu Max                2.3506968
Policy mu Min                -2.3114407
Policy log std Mean          -1.0436965
Policy log std Std           0.24050844
Policy log std Max           -0.1826666
Policy log std Min           -2.0578675
Z mean eval                  0.8750206
Z variance eval              0.15984781
total_rewards                [1428.65912586  590.89336228 2473.45764977 2539.11065663 1306.81652392
 1445.52319066 3365.46962965 3362.14689675 2121.59747197 3342.80250624]
total_rewards_mean           2197.6477013724125
total_rewards_std            936.0540623255897
total_rewards_max            3365.46962965306
total_rewards_min            590.8933622754644
Number of train steps total  1972000
Number of env steps total    3764418
Number of rollouts total     0
Train Time (s)               156.20857019722462
(Previous) Eval Time (s)     26.470679733902216
Sample Time (s)              13.698197953402996
Epoch Time (s)               196.37744788452983
Total Train Time (s)         91997.26519981446
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:29:11.197753 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #492 | Epoch Duration: 196.46733903884888
2020-01-13 03:29:11.197936 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86604464
Z variance train             0.1617158
KL Divergence                8.841335
KL Loss                      0.8841335
QF Loss                      1123.41
VF Loss                      123.496086
Policy Loss                  -1212.1776
Q Predictions Mean           1208.4171
Q Predictions Std            233.8579
Q Predictions Max            1445.9946
Q Predictions Min            314.41843
V Predictions Mean           1218.8213
V Predictions Std            234.76825
V Predictions Max            1440.0653
V Predictions Min            324.38235
Log Pis Mean                 0.5935321
Log Pis Std                  2.7486844
Log Pis Max                  10.919751
Log Pis Min                  -9.4812565
Policy mu Mean               0.034412302
Policy mu Std                0.6159943
Policy mu Max                3.675852
Policy mu Min                -3.5251398
Policy log std Mean          -1.0775102
Policy log std Std           0.23522589
Policy log std Max           -0.0054041147
Policy log std Min           -2.0246522
Z mean eval                  0.7549162
Z variance eval              0.24231625
total_rewards                [3249.5087859  3248.41450629 3335.2354799   578.32311288 3287.8692738
 3279.15653477 3644.55605672 3396.01560758  351.01018738 3259.39387046]
total_rewards_mean           2762.948341568554
total_rewards_std            1155.7007162286313
total_rewards_max            3644.556056717033
total_rewards_min            351.01018738247194
Number of train steps total  1976000
Number of env steps total    3774568
Number of rollouts total     0
Train Time (s)               151.58570497995242
(Previous) Eval Time (s)     30.57145654084161
Sample Time (s)              10.826602808199823
Epoch Time (s)               192.98376432899386
Total Train Time (s)         92190.33616726892
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:32:24.273225 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #493 | Epoch Duration: 193.07514548301697
2020-01-13 03:32:24.273418 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75748026
Z variance train             0.24209991
KL Divergence                7.978837
KL Loss                      0.7978837
QF Loss                      313.72046
VF Loss                      58.540302
Policy Loss                  -1198.1495
Q Predictions Mean           1191.5188
Q Predictions Std            235.41492
Q Predictions Max            1429.8146
Q Predictions Min            313.37994
V Predictions Mean           1200.7
V Predictions Std            236.63637
V Predictions Max            1427.6719
V Predictions Min            304.8554
Log Pis Mean                 0.3162272
Log Pis Std                  2.5864444
Log Pis Max                  8.876523
Log Pis Min                  -9.164942
Policy mu Mean               0.055672877
Policy mu Std                0.6175199
Policy mu Max                2.4924994
Policy mu Min                -2.2099724
Policy log std Mean          -1.0488988
Policy log std Std           0.22904898
Policy log std Max           -0.28621984
Policy log std Min           -2.2382379
Z mean eval                  0.737934
Z variance eval              0.16595066
total_rewards                [3442.50093384   56.78375081 3306.49187713 3286.51438232 1553.82031789
 3433.98107717 1697.7687779  2360.33522628  254.16029353 3359.90946   ]
total_rewards_mean           2275.2266096882477
total_rewards_std            1258.3844799887768
total_rewards_max            3442.500933841198
total_rewards_min            56.78375080832636
Number of train steps total  1980000
Number of env steps total    3785475
Number of rollouts total     0
Train Time (s)               147.2775862440467
(Previous) Eval Time (s)     26.31016763485968
Sample Time (s)              12.583026391919702
Epoch Time (s)               186.17078027082607
Total Train Time (s)         92376.60488932068
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:35:30.546937 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #494 | Epoch Duration: 186.2733714580536
2020-01-13 03:35:30.547143 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7401204
Z variance train             0.16697687
KL Divergence                8.509519
KL Loss                      0.85095185
QF Loss                      309.35242
VF Loss                      146.13654
Policy Loss                  -1160.943
Q Predictions Mean           1157.1512
Q Predictions Std            289.73187
Q Predictions Max            1454.701
Q Predictions Min            22.846712
V Predictions Mean           1161.4801
V Predictions Std            292.92697
V Predictions Max            1445.3857
V Predictions Min            11.570965
Log Pis Mean                 0.04908684
Log Pis Std                  2.7851067
Log Pis Max                  9.927481
Log Pis Min                  -7.956107
Policy mu Mean               0.008682311
Policy mu Std                0.61373824
Policy mu Max                2.1750782
Policy mu Min                -2.488887
Policy log std Mean          -1.0162327
Policy log std Std           0.24393865
Policy log std Max           -0.20714766
Policy log std Min           -2.677575
Z mean eval                  0.6808321
Z variance eval              0.21811633
total_rewards                [  87.5905694   794.05419582 1114.87516796 3176.4654041  3272.53574333
  136.58108066 2335.95156166 1636.92117076  141.37540401 2151.18770072]
total_rewards_mean           1484.75379984143
total_rewards_std            1159.2262740784663
total_rewards_max            3272.535743327403
total_rewards_min            87.59056940494125
Number of train steps total  1984000
Number of env steps total    3797524
Number of rollouts total     0
Train Time (s)               150.39080640021712
(Previous) Eval Time (s)     21.100904310587794
Sample Time (s)              11.30593330739066
Epoch Time (s)               182.79764401819557
Total Train Time (s)         92559.48826488154
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:38:33.435077 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #495 | Epoch Duration: 182.8877625465393
2020-01-13 03:38:33.435285 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67667615
Z variance train             0.22213677
KL Divergence                7.899561
KL Loss                      0.7899561
QF Loss                      11523.546
VF Loss                      43.852554
Policy Loss                  -1138.7397
Q Predictions Mean           1133.7496
Q Predictions Std            300.68356
Q Predictions Max            1443.4652
Q Predictions Min            278.4529
V Predictions Mean           1138.2054
V Predictions Std            301.21188
V Predictions Max            1437.2173
V Predictions Min            262.88712
Log Pis Mean                 0.28486758
Log Pis Std                  2.6931634
Log Pis Max                  8.027833
Log Pis Min                  -8.627378
Policy mu Mean               0.034481607
Policy mu Std                0.6148598
Policy mu Max                1.9771924
Policy mu Min                -2.2534592
Policy log std Mean          -1.0274484
Policy log std Std           0.25198781
Policy log std Max           -0.07892692
Policy log std Min           -2.0000036
Z mean eval                  0.677036
Z variance eval              0.21725643
total_rewards                [2303.09797975 1362.20050355 1248.27776517 1863.82754982  544.47613287
  235.87013185 3558.53796102 2845.04244045  620.3250398  2042.22927483]
total_rewards_mean           1662.3884779105356
total_rewards_std            1011.019187162384
total_rewards_max            3558.5379610195932
total_rewards_min            235.8701318522575
Number of train steps total  1988000
Number of env steps total    3808433
Number of rollouts total     0
Train Time (s)               157.78421488637105
(Previous) Eval Time (s)     18.097000695299357
Sample Time (s)              11.915323622524738
Epoch Time (s)               187.79653920419514
Total Train Time (s)         92747.37358478596
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:41:41.325714 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #496 | Epoch Duration: 187.89027667045593
2020-01-13 03:41:41.325927 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67169034
Z variance train             0.21702206
KL Divergence                7.6998463
KL Loss                      0.76998466
QF Loss                      884.56555
VF Loss                      158.0368
Policy Loss                  -1188.5665
Q Predictions Mean           1185.4739
Q Predictions Std            257.21143
Q Predictions Max            1458.9612
Q Predictions Min            239.10762
V Predictions Mean           1191.2258
V Predictions Std            257.36273
V Predictions Max            1450.0658
V Predictions Min            248.8356
Log Pis Mean                 0.57877576
Log Pis Std                  2.5923944
Log Pis Max                  7.4365907
Log Pis Min                  -5.696145
Policy mu Mean               -0.024243403
Policy mu Std                0.63060427
Policy mu Max                2.4070437
Policy mu Min                -2.081682
Policy log std Mean          -1.043837
Policy log std Std           0.23665667
Policy log std Max           -0.19883835
Policy log std Min           -1.9593438
Z mean eval                  0.7500289
Z variance eval              0.12948295
total_rewards                [1289.03914117 2903.76120099 2251.25307374  727.90907256  533.58905341
  227.51235262  869.25459569  757.22384785 3152.00605949  790.50557443]
total_rewards_mean           1350.205397194988
total_rewards_std            984.1955503001486
total_rewards_max            3152.0060594866018
total_rewards_min            227.51235262122918
Number of train steps total  1992000
Number of env steps total    3819106
Number of rollouts total     0
Train Time (s)               157.90452619222924
(Previous) Eval Time (s)     21.393290624022484
Sample Time (s)              11.366341033019125
Epoch Time (s)               190.66415784927085
Total Train Time (s)         92938.13063910557
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:44:52.087589 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #497 | Epoch Duration: 190.7615053653717
2020-01-13 03:44:52.087801 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7501462
Z variance train             0.12984902
KL Divergence                8.30725
KL Loss                      0.830725
QF Loss                      352.8753
VF Loss                      48.423634
Policy Loss                  -1155.3792
Q Predictions Mean           1149.897
Q Predictions Std            255.63521
Q Predictions Max            1402.4197
Q Predictions Min            294.16083
V Predictions Mean           1155.3538
V Predictions Std            255.64458
V Predictions Max            1411.9086
V Predictions Min            295.80566
Log Pis Mean                 0.32520798
Log Pis Std                  2.6786482
Log Pis Max                  17.53635
Log Pis Min                  -5.3240356
Policy mu Mean               -0.0006571533
Policy mu Std                0.616159
Policy mu Max                2.2597363
Policy mu Min                -2.5909846
Policy log std Mean          -1.0424864
Policy log std Std           0.25918207
Policy log std Max           -0.30778182
Policy log std Min           -2.5973296
Z mean eval                  0.7226556
Z variance eval              0.28818575
total_rewards                [ 958.28950923 2022.85575265  769.52603031 3362.09023382 3454.93285095
 2255.92504817 1544.68696848 2457.81229944 3309.15053342  209.02063446]
total_rewards_mean           2034.4289860934678
total_rewards_std            1093.796008062887
total_rewards_max            3454.9328509539755
total_rewards_min            209.02063445900802
Number of train steps total  1996000
Number of env steps total    3830506
Number of rollouts total     0
Train Time (s)               158.59571590879932
(Previous) Eval Time (s)     26.91185570694506
Sample Time (s)              13.276686748024076
Epoch Time (s)               198.78425836376846
Total Train Time (s)         93137.0171995163
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:48:10.979541 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #498 | Epoch Duration: 198.89156031608582
2020-01-13 03:48:10.979840 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7199866
Z variance train             0.28788155
KL Divergence                6.7552
KL Loss                      0.67552
QF Loss                      446.31073
VF Loss                      283.17218
Policy Loss                  -1141.0815
Q Predictions Mean           1135.9098
Q Predictions Std            262.05185
Q Predictions Max            1414.523
Q Predictions Min            284.95105
V Predictions Mean           1141.9662
V Predictions Std            261.2735
V Predictions Max            1415.5896
V Predictions Min            277.36514
Log Pis Mean                 0.33774906
Log Pis Std                  2.6714911
Log Pis Max                  13.973667
Log Pis Min                  -6.3091288
Policy mu Mean               -0.0022649793
Policy mu Std                0.62326884
Policy mu Max                2.7160196
Policy mu Min                -2.378961
Policy log std Mean          -1.0448613
Policy log std Std           0.25916636
Policy log std Max           -0.31769818
Policy log std Min           -2.0741653
Z mean eval                  0.7024981
Z variance eval              0.25757602
total_rewards                [3491.18713374  277.72841342 3288.06231464  135.75356385 3367.19677197
 2227.97359049 2242.99783041  152.56801931  697.45901591  462.04328889]
total_rewards_mean           1634.2969942628865
total_rewards_std            1358.0193887924224
total_rewards_max            3491.187133735996
total_rewards_min            135.7535638545575
Number of train steps total  2000000
Number of env steps total    3841391
Number of rollouts total     0
Train Time (s)               155.48280394962057
(Previous) Eval Time (s)     22.30032926471904
Sample Time (s)              9.39986155508086
Epoch Time (s)               187.18299476942047
Total Train Time (s)         93324.29207923869
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:51:18.259151 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #499 | Epoch Duration: 187.27912163734436
2020-01-13 03:51:18.259437 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Iteration #499 | Started Training: True
2020-01-13 03:51:19.251262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] Variant:
2020-01-13 03:51:19.251827 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20_seed56",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015107745
Z variance train             0.69259006
KL Divergence                0.14977556
KL Loss                      0.014977557
QF Loss                      46.331024
VF Loss                      16.467674
Policy Loss                  -4.023477
Q Predictions Mean           0.0041415626
Q Predictions Std            0.0027838328
Q Predictions Max            0.0146425795
Q Predictions Min            -0.0018293844
V Predictions Mean           0.004016267
V Predictions Std            0.0015991185
V Predictions Max            0.008371308
V Predictions Min            1.0664808e-05
Log Pis Mean                 -4.0536647
Log Pis Std                  0.55837053
Log Pis Max                  -2.2691817
Log Pis Min                  -5.739599
Policy mu Mean               -0.0007698768
Policy mu Std                0.0014816081
Policy mu Max                0.0040149908
Policy mu Min                -0.004992895
Policy log std Mean          0.00074010243
Policy log std Std           0.0011658955
Policy log std Max           0.004144796
Policy log std Min           -0.003478533
Z mean eval                  1.0256958
Z variance eval              0.03827204
total_rewards                [-142.90677729 -123.32252894 -150.12502523 -139.04942806 -156.42701259
 -139.444603   -125.99907129 -162.8277051  -123.53700147 -135.88975397]
total_rewards_mean           -139.9528906953836
total_rewards_std            12.904242331790373
total_rewards_max            -123.32252894442762
total_rewards_min            -162.82770510292605
Number of train steps total  4000
Number of env steps total    14000
Number of rollouts total     0
Train Time (s)               135.1696987678297
(Previous) Eval Time (s)     0
Sample Time (s)              20.58117772405967
Epoch Time (s)               155.75087649188936
Total Train Time (s)         184.57353916717693
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:54:23.920438 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #0 | Epoch Duration: 184.57739162445068
2020-01-13 03:54:23.920696 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0417631
Z variance train             0.03664141
KL Divergence                10.514332
KL Loss                      1.0514332
QF Loss                      59.857693
VF Loss                      9.289874
Policy Loss                  -48.22554
Q Predictions Mean           42.48163
Q Predictions Std            18.279009
Q Predictions Max            93.997505
Q Predictions Min            -11.66238
V Predictions Mean           48.38044
V Predictions Std            17.458164
V Predictions Max            98.38198
V Predictions Min            6.0290623
Log Pis Mean                 -3.4644556
Log Pis Std                  1.0639559
Log Pis Max                  -0.09244096
Log Pis Min                  -7.9761
Policy mu Mean               0.02983544
Policy mu Std                0.3474364
Policy mu Max                1.42376
Policy mu Min                -1.597566
Policy log std Mean          -0.30943048
Policy log std Std           0.069340155
Policy log std Max           -0.14784056
Policy log std Min           -0.54502374
Z mean eval                  1.2237481
Z variance eval              0.025730107
total_rewards                [-104.45898172 -104.31502126 -165.65707366 -135.52606683  -98.11510974
 -107.03961969  -99.79397038 -124.32233853 -130.99353185 -129.61461923]
total_rewards_mean           -119.98363328863495
total_rewards_std            20.249323503762618
total_rewards_max            -98.11510973767759
total_rewards_min            -165.65707365923572
Number of train steps total  8000
Number of env steps total    26000
Number of rollouts total     0
Train Time (s)               135.3266730220057
(Previous) Eval Time (s)     29.190223225858063
Sample Time (s)              9.898626110050827
Epoch Time (s)               174.4155223579146
Total Train Time (s)         359.07478751055896
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:57:18.422445 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #1 | Epoch Duration: 174.50158095359802
2020-01-13 03:57:18.422634 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2211206
Z variance train             0.025687436
KL Divergence                13.108749
KL Loss                      1.3108749
QF Loss                      73.985794
VF Loss                      10.430853
Policy Loss                  -95.1689
Q Predictions Mean           87.944305
Q Predictions Std            32.02994
Q Predictions Max            180.71939
Q Predictions Min            38.674313
V Predictions Mean           95.37352
V Predictions Std            30.76746
V Predictions Max            183.48087
V Predictions Min            45.207077
Log Pis Mean                 -3.3032477
Log Pis Std                  1.3092169
Log Pis Max                  0.22357267
Log Pis Min                  -7.995988
Policy mu Mean               0.003072439
Policy mu Std                0.42127132
Policy mu Max                1.5579543
Policy mu Min                -1.3545934
Policy log std Mean          -0.33296305
Policy log std Std           0.07548411
Policy log std Max           -0.16987516
Policy log std Min           -0.6580149
Z mean eval                  1.3173906
Z variance eval              0.025655767
total_rewards                [-28.52697784   7.81355156 -13.60704546 -55.864784   -51.99874588
 -67.28123797 -40.09576258 -41.08447268 -44.31871717 -29.26379325]
total_rewards_mean           -36.42279852827694
total_rewards_std            20.643207646122434
total_rewards_max            7.8135515570331044
total_rewards_min            -67.28123796623257
Number of train steps total  12000
Number of env steps total    38000
Number of rollouts total     0
Train Time (s)               139.58098481502384
(Previous) Eval Time (s)     28.24533577496186
Sample Time (s)              9.881705069448799
Epoch Time (s)               177.7080256594345
Total Train Time (s)         536.9230066128075
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:00:16.272219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #2 | Epoch Duration: 177.84943437576294
2020-01-13 04:00:16.272447 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3127165
Z variance train             0.025629496
KL Divergence                14.6262
KL Loss                      1.46262
QF Loss                      73.100204
VF Loss                      19.786041
Policy Loss                  -128.82664
Q Predictions Mean           125.66351
Q Predictions Std            38.509205
Q Predictions Max            240.32428
Q Predictions Min            54.57587
V Predictions Mean           130.3121
V Predictions Std            38.382797
V Predictions Max            234.53748
V Predictions Min            55.123665
Log Pis Mean                 -3.1382446
Log Pis Std                  1.5086672
Log Pis Max                  5.7533703
Log Pis Min                  -7.577321
Policy mu Mean               0.005984696
Policy mu Std                0.43812537
Policy mu Max                1.716581
Policy mu Min                -1.3873512
Policy log std Mean          -0.33384976
Policy log std Std           0.0807139
Policy log std Max           -0.16063413
Policy log std Min           -0.67838037
Z mean eval                  1.3755088
Z variance eval              0.024776427
total_rewards                [ 19.15571105 189.16534856 -18.70612017  45.78703285  77.18448995
  12.39832166  67.83417428 182.02533129  75.58477946 175.31687172]
total_rewards_mean           82.57459406458139
total_rewards_std            71.20823724536663
total_rewards_max            189.16534855720215
total_rewards_min            -18.706120167639643
Number of train steps total  16000
Number of env steps total    50000
Number of rollouts total     0
Train Time (s)               144.92921394202858
(Previous) Eval Time (s)     29.649947706144303
Sample Time (s)              10.334115873090923
Epoch Time (s)               184.9132775212638
Total Train Time (s)         721.9183142436668
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:03:21.269201 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #3 | Epoch Duration: 184.9965717792511
2020-01-13 04:03:21.269501 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3716915
Z variance train             0.024731299
KL Divergence                16.90746
KL Loss                      1.690746
QF Loss                      169.8247
VF Loss                      23.795696
Policy Loss                  -150.97406
Q Predictions Mean           148.77383
Q Predictions Std            48.9284
Q Predictions Max            296.14877
Q Predictions Min            61.08474
V Predictions Mean           154.15846
V Predictions Std            49.035534
V Predictions Max            298.77774
V Predictions Min            66.32259
Log Pis Mean                 -3.120642
Log Pis Std                  1.424811
Log Pis Max                  1.5427815
Log Pis Min                  -6.905998
Policy mu Mean               -0.022883518
Policy mu Std                0.41397294
Policy mu Max                1.7168179
Policy mu Min                -1.530792
Policy log std Mean          -0.32380208
Policy log std Std           0.07896493
Policy log std Max           -0.15063521
Policy log std Min           -0.7356856
Z mean eval                  1.3836472
Z variance eval              0.029779803
total_rewards                [ 855.65517241 1137.63770659  447.68830521  158.83821378  973.82622981
  936.94782396 1025.05641371 1062.98334437  634.16871113  982.18773725]
total_rewards_mean           821.4989658221618
total_rewards_std            296.1688558234679
total_rewards_max            1137.6377065864108
total_rewards_min            158.83821378237644
Number of train steps total  20000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               143.4624906051904
(Previous) Eval Time (s)     30.030264096334577
Sample Time (s)              10.409957405179739
Epoch Time (s)               183.9027121067047
Total Train Time (s)         905.9051445052028
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:06:25.260349 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #4 | Epoch Duration: 183.9906153678894
2020-01-13 04:06:25.260628 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3828983
Z variance train             0.029681295
KL Divergence                15.695513
KL Loss                      1.5695513
QF Loss                      83.09689
VF Loss                      11.161845
Policy Loss                  -183.80461
Q Predictions Mean           176.54773
Q Predictions Std            60.430542
Q Predictions Max            328.97162
Q Predictions Min            61.44467
V Predictions Mean           183.47455
V Predictions Std            60.534115
V Predictions Max            332.15182
V Predictions Min            79.200066
Log Pis Mean                 -3.1222565
Log Pis Std                  1.457507
Log Pis Max                  3.825158
Log Pis Min                  -8.374736
Policy mu Mean               0.016841358
Policy mu Std                0.45043907
Policy mu Max                2.0616362
Policy mu Min                -1.9694142
Policy log std Mean          -0.33246216
Policy log std Std           0.087583154
Policy log std Max           -0.08212168
Policy log std Min           -0.7211883
Z mean eval                  1.4370174
Z variance eval              0.062488187
total_rewards                [ 640.77661363  274.76512936  445.97975978 1743.79431477 1698.25846607
 1432.87023876 1684.44298758 1335.63260216  451.48972859 1649.5760709 ]
total_rewards_mean           1135.7585911597635
total_rewards_std            575.3031447053886
total_rewards_max            1743.7943147709348
total_rewards_min            274.76512935929225
Number of train steps total  24000
Number of env steps total    74000
Number of rollouts total     0
Train Time (s)               144.5262325843796
(Previous) Eval Time (s)     31.06749932700768
Sample Time (s)              9.794116429518908
Epoch Time (s)               185.3878483409062
Total Train Time (s)         1091.379744711332
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:09:30.733965 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #5 | Epoch Duration: 185.473149061203
2020-01-13 04:09:30.734171 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4394903
Z variance train             0.06280731
KL Divergence                14.83344
KL Loss                      1.483344
QF Loss                      96.6248
VF Loss                      16.07418
Policy Loss                  -226.1052
Q Predictions Mean           220.7142
Q Predictions Std            80.07861
Q Predictions Max            451.52295
Q Predictions Min            88.428345
V Predictions Mean           225.49138
V Predictions Std            80.52923
V Predictions Max            435.49176
V Predictions Min            100.400764
Log Pis Mean                 -2.9268596
Log Pis Std                  1.6014009
Log Pis Max                  2.9643326
Log Pis Min                  -6.443238
Policy mu Mean               -0.042586714
Policy mu Std                0.48837912
Policy mu Max                1.7946221
Policy mu Min                -1.5977334
Policy log std Mean          -0.34433648
Policy log std Std           0.094233155
Policy log std Max           -0.17555693
Policy log std Min           -0.91650814
Z mean eval                  1.5428356
Z variance eval              0.049679853
total_rewards                [2011.19290184 2190.53213608 1779.9249671  2009.54261371 2043.77655428
  715.27618903 1975.0241682  1929.5674816  2180.86329292 2101.47701225]
total_rewards_mean           1893.7177317012042
total_rewards_std            409.0254216699854
total_rewards_max            2190.53213607915
total_rewards_min            715.2761890251838
Number of train steps total  28000
Number of env steps total    86000
Number of rollouts total     0
Train Time (s)               143.76087479991838
(Previous) Eval Time (s)     29.776785694994032
Sample Time (s)              9.69826276646927
Epoch Time (s)               183.23592326138169
Total Train Time (s)         1274.7033358654007
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:12:34.058867 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #6 | Epoch Duration: 183.3245232105255
2020-01-13 04:12:34.059131 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #6 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5420594
Z variance train             0.04967355
KL Divergence                16.659971
KL Loss                      1.6659971
QF Loss                      315.93787
VF Loss                      23.249805
Policy Loss                  -242.95569
Q Predictions Mean           239.06415
Q Predictions Std            98.799095
Q Predictions Max            528.3048
Q Predictions Min            115.899574
V Predictions Mean           243.40158
V Predictions Std            99.13904
V Predictions Max            526.9321
V Predictions Min            115.15481
Log Pis Mean                 -2.5185337
Log Pis Std                  1.8782654
Log Pis Max                  5.2011137
Log Pis Min                  -6.962307
Policy mu Mean               -0.015966164
Policy mu Std                0.52780694
Policy mu Max                2.0171916
Policy mu Min                -1.9548225
Policy log std Mean          -0.35512245
Policy log std Std           0.10895775
Policy log std Max           -0.09002298
Policy log std Min           -1.02182
Z mean eval                  1.6425301
Z variance eval              0.034885477
total_rewards                [2400.00136015 2401.43390219 2619.59700887 2519.51685132 2422.7933659
 2453.35009662 2503.96227283 2491.5622501  2445.75059411 2574.99173896]
total_rewards_mean           2483.2959441054
total_rewards_std            69.56998836279563
total_rewards_max            2619.597008869601
total_rewards_min            2400.001360150706
Number of train steps total  32000
Number of env steps total    98000
Number of rollouts total     0
Train Time (s)               135.1293052448891
(Previous) Eval Time (s)     29.148590783122927
Sample Time (s)              9.782862472813576
Epoch Time (s)               174.0607585008256
Total Train Time (s)         1448.8738327701576
Epoch                        7
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:15:28.230421 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #7 | Epoch Duration: 174.1710877418518
2020-01-13 04:15:28.230647 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6445417
Z variance train             0.034927085
KL Divergence                18.042824
KL Loss                      1.8042824
QF Loss                      127.019295
VF Loss                      36.175797
Policy Loss                  -303.01776
Q Predictions Mean           294.76462
Q Predictions Std            129.2916
Q Predictions Max            687.1975
Q Predictions Min            129.34276
V Predictions Mean           301.51675
V Predictions Std            130.08394
V Predictions Max            684.4927
V Predictions Min            129.86626
Log Pis Mean                 -2.163064
Log Pis Std                  2.2145302
Log Pis Max                  5.4016247
Log Pis Min                  -5.916836
Policy mu Mean               -0.043593224
Policy mu Std                0.62046224
Policy mu Max                2.062754
Policy mu Min                -2.3176289
Policy log std Mean          -0.39098796
Policy log std Std           0.14314833
Policy log std Max           -0.14937966
Policy log std Min           -1.2775968
Z mean eval                  1.7445408
Z variance eval              0.05919212
total_rewards                [2843.10600668 2663.96139459 2840.73505958 2649.92767026 2774.23326425
 2902.13440623 2738.78058471 2824.48279761 2761.5133004  2836.26318204]
total_rewards_mean           2783.513766635337
total_rewards_std            77.50261318897893
total_rewards_max            2902.1344062275057
total_rewards_min            2649.927670261687
Number of train steps total  36000
Number of env steps total    110000
Number of rollouts total     0
Train Time (s)               136.02701795333996
(Previous) Eval Time (s)     29.46350857615471
Sample Time (s)              9.812893980648369
Epoch Time (s)               175.30342051014304
Total Train Time (s)         1624.2626554192975
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:18:23.621125 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #8 | Epoch Duration: 175.39025211334229
2020-01-13 04:18:23.621390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7468193
Z variance train             0.05931946
KL Divergence                19.001722
KL Loss                      1.9001722
QF Loss                      164.75446
VF Loss                      34.524612
Policy Loss                  -316.3597
Q Predictions Mean           310.58667
Q Predictions Std            156.90396
Q Predictions Max            756.94995
Q Predictions Min            130.48213
V Predictions Mean           315.16348
V Predictions Std            155.79672
V Predictions Max            745.4276
V Predictions Min            136.95897
Log Pis Mean                 -2.294313
Log Pis Std                  2.4314578
Log Pis Max                  5.8937774
Log Pis Min                  -8.309108
Policy mu Mean               0.030981028
Policy mu Std                0.63284576
Policy mu Max                2.2234957
Policy mu Min                -2.4730527
Policy log std Mean          -0.38885424
Policy log std Std           0.1527178
Policy log std Max           -0.1300377
Policy log std Min           -1.6185329
Z mean eval                  1.9087309
Z variance eval              0.034889363
total_rewards                [ 586.12702516 2834.0862094  1788.2150089  2952.38149097 2771.43316973
 2993.49088716 3123.57567697 2751.48458213 2942.05174323 2941.78253465]
total_rewards_mean           2568.4628328288804
total_rewards_std            748.252667496856
total_rewards_max            3123.5756769682516
total_rewards_min            586.1270251635506
Number of train steps total  40000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               139.33203822607175
(Previous) Eval Time (s)     30.45475267106667
Sample Time (s)              9.741734382230788
Epoch Time (s)               179.5285252793692
Total Train Time (s)         1803.8814905546606
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:21:23.240531 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #9 | Epoch Duration: 179.6189534664154
2020-01-13 04:21:23.240765 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #9 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9109049
Z variance train             0.034960017
KL Divergence                22.360939
KL Loss                      2.236094
QF Loss                      218.84306
VF Loss                      31.833996
Policy Loss                  -381.51318
Q Predictions Mean           372.70822
Q Predictions Std            209.43826
Q Predictions Max            942.408
Q Predictions Min            136.9262
V Predictions Mean           379.15616
V Predictions Std            210.68253
V Predictions Max            941.18915
V Predictions Min            136.1458
Log Pis Mean                 -2.0302649
Log Pis Std                  2.654279
Log Pis Max                  6.3034534
Log Pis Min                  -7.7427616
Policy mu Mean               -0.056155074
Policy mu Std                0.65981376
Policy mu Max                2.0682673
Policy mu Min                -2.2433944
Policy log std Mean          -0.3962377
Policy log std Std           0.17061424
Policy log std Max           -0.16713831
Policy log std Min           -1.582621
Z mean eval                  2.0370061
Z variance eval              0.030260349
total_rewards                [3216.49864318 3373.03997529 3283.97297142 3160.68967044 3139.9842226
 3360.30436792 3367.34085274 3292.21871131 3376.02412653 3216.8702292 ]
total_rewards_mean           3278.6943770629587
total_rewards_std            85.99969987061766
total_rewards_max            3376.024126530642
total_rewards_min            3139.9842226032274
Number of train steps total  44000
Number of env steps total    134000
Number of rollouts total     0
Train Time (s)               145.5234956261702
(Previous) Eval Time (s)     30.005542759317905
Sample Time (s)              10.507124262861907
Epoch Time (s)               186.03616264835
Total Train Time (s)         1990.0095025063492
Epoch                        10
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:24:29.370704 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #10 | Epoch Duration: 186.12975978851318
2020-01-13 04:24:29.371029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0360026
Z variance train             0.030228361
KL Divergence                25.421942
KL Loss                      2.5421941
QF Loss                      167.70357
VF Loss                      47.110382
Policy Loss                  -459.5985
Q Predictions Mean           451.8736
Q Predictions Std            257.75766
Q Predictions Max            1015.97626
Q Predictions Min            139.42593
V Predictions Mean           459.86664
V Predictions Std            256.99426
V Predictions Max            1007.1075
V Predictions Min            145.88136
Log Pis Mean                 -1.640378
Log Pis Std                  2.6879005
Log Pis Max                  6.6033874
Log Pis Min                  -6.999361
Policy mu Mean               -0.010499154
Policy mu Std                0.73554885
Policy mu Max                2.67506
Policy mu Min                -2.0956612
Policy log std Mean          -0.41938755
Policy log std Std           0.16956227
Policy log std Max           -0.14304288
Policy log std Min           -1.5932713
Z mean eval                  2.088719
Z variance eval              0.0333396
total_rewards                [3303.02192321 3207.89683964 3417.45803637 3255.30739892 3264.02272269
 3391.1786908   551.89985266 1944.87918999 3690.95178193 3259.29370947]
total_rewards_mean           2928.591014569056
total_rewards_std            905.3924366830859
total_rewards_max            3690.9517819316848
total_rewards_min            551.8998526588961
Number of train steps total  48000
Number of env steps total    146000
Number of rollouts total     0
Train Time (s)               144.48169105360284
(Previous) Eval Time (s)     27.671779538039118
Sample Time (s)              10.016145713627338
Epoch Time (s)               182.1696163052693
Total Train Time (s)         2172.2632115068845
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:27:31.624945 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #11 | Epoch Duration: 182.25357055664062
2020-01-13 04:27:31.625155 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.085892
Z variance train             0.033216156
KL Divergence                26.090431
KL Loss                      2.6090431
QF Loss                      291.6256
VF Loss                      61.000023
Policy Loss                  -512.66785
Q Predictions Mean           502.23526
Q Predictions Std            293.34406
Q Predictions Max            1108.88
Q Predictions Min            125.631645
V Predictions Mean           515.7207
V Predictions Std            296.8542
V Predictions Max            1129.8606
V Predictions Min            143.65698
Log Pis Mean                 -1.6002401
Log Pis Std                  2.7057092
Log Pis Max                  8.177647
Log Pis Min                  -7.414344
Policy mu Mean               -0.035372917
Policy mu Std                0.7033298
Policy mu Max                2.3424191
Policy mu Min                -2.2803743
Policy log std Mean          -0.428413
Policy log std Std           0.18532293
Policy log std Max           -0.15736386
Policy log std Min           -1.5418373
Z mean eval                  2.1781394
Z variance eval              0.0333805
total_rewards                [3627.15393226 3399.63803219 3700.7953177  3535.39134297 3622.10569688
 3687.80604704 3440.6597011  3754.21643921 3456.04171341 3532.17264194]
total_rewards_mean           3575.598086470981
total_rewards_std            114.87246774667308
total_rewards_max            3754.216439209252
total_rewards_min            3399.6380321917113
Number of train steps total  52000
Number of env steps total    158000
Number of rollouts total     0
Train Time (s)               144.84725447325036
(Previous) Eval Time (s)     30.07397956121713
Sample Time (s)              10.296244546305388
Epoch Time (s)               185.21747858077288
Total Train Time (s)         2357.5684253107756
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:30:36.931073 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #12 | Epoch Duration: 185.3057701587677
2020-01-13 04:30:36.931301 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #12 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1762526
Z variance train             0.033425134
KL Divergence                26.009548
KL Loss                      2.6009548
QF Loss                      600.0072
VF Loss                      86.35329
Policy Loss                  -530.9685
Q Predictions Mean           520.9466
Q Predictions Std            334.75516
Q Predictions Max            1230.6084
Q Predictions Min            140.67706
V Predictions Mean           536.80414
V Predictions Std            337.49582
V Predictions Max            1242.9822
V Predictions Min            152.92342
Log Pis Mean                 -1.5598468
Log Pis Std                  2.7517388
Log Pis Max                  8.482935
Log Pis Min                  -7.192613
Policy mu Mean               -0.0748916
Policy mu Std                0.72596675
Policy mu Max                2.3527985
Policy mu Min                -2.5379438
Policy log std Mean          -0.41959366
Policy log std Std           0.16837575
Policy log std Max           -0.15485859
Policy log std Min           -1.6184722
Z mean eval                  2.124622
Z variance eval              0.031225126
total_rewards                [3636.07098698 3631.87323206 3712.94370525 3962.13065355 3854.13157805
 3787.21512846 3914.40001626 3848.3629897  3750.78059012  355.64823078]
total_rewards_mean           3445.3557111209075
total_rewards_std            1035.170538894677
total_rewards_max            3962.1306535527833
total_rewards_min            355.6482307794189
Number of train steps total  56000
Number of env steps total    170000
Number of rollouts total     0
Train Time (s)               143.527571155224
(Previous) Eval Time (s)     30.46967876702547
Sample Time (s)              9.137081005610526
Epoch Time (s)               183.13433092786
Total Train Time (s)         2540.7812796384096
Epoch                        13
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:33:40.145214 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #13 | Epoch Duration: 183.21377205848694
2020-01-13 04:33:40.145393 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.227717
Z variance train             0.02874679
KL Divergence                26.188766
KL Loss                      2.6188767
QF Loss                      780.8178
VF Loss                      100.7383
Policy Loss                  -550.42816
Q Predictions Mean           542.33215
Q Predictions Std            360.23068
Q Predictions Max            1297.1665
Q Predictions Min            119.03455
V Predictions Mean           553.9824
V Predictions Std            363.2006
V Predictions Max            1303.0824
V Predictions Min            136.49727
Log Pis Mean                 -1.647366
Log Pis Std                  2.7591066
Log Pis Max                  7.939071
Log Pis Min                  -6.227255
Policy mu Mean               -0.036202524
Policy mu Std                0.70289916
Policy mu Max                2.2701442
Policy mu Min                -2.6456738
Policy log std Mean          -0.4306701
Policy log std Std           0.19197294
Policy log std Max           -0.1047246
Policy log std Min           -1.5626104
Z mean eval                  2.0834286
Z variance eval              0.04036904
total_rewards                [3912.31956699 3836.22063694 3763.45249836 3860.83554306 4003.50926297
 4106.80825461 3982.96969358 3814.56330703 4201.70617097 4007.36768032]
total_rewards_mean           3948.9752614833646
total_rewards_std            130.62715798580794
total_rewards_max            4201.706170973098
total_rewards_min            3763.4524983627116
Number of train steps total  60000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               136.17868360690773
(Previous) Eval Time (s)     29.47298334678635
Sample Time (s)              9.46779740601778
Epoch Time (s)               175.11946435971186
Total Train Time (s)         2715.978063723538
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:36:35.343209 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #14 | Epoch Duration: 175.19766283035278
2020-01-13 04:36:35.343394 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0812023
Z variance train             0.04005206
KL Divergence                24.159883
KL Loss                      2.4159884
QF Loss                      269.65912
VF Loss                      77.09909
Policy Loss                  -590.57495
Q Predictions Mean           581.2316
Q Predictions Std            375.46603
Q Predictions Max            1365.9534
Q Predictions Min            129.46933
V Predictions Mean           584.9343
V Predictions Std            375.7126
V Predictions Max            1351.6685
V Predictions Min            136.57303
Log Pis Mean                 -1.3395694
Log Pis Std                  2.8993192
Log Pis Max                  7.541504
Log Pis Min                  -6.913801
Policy mu Mean               0.017010804
Policy mu Std                0.75831497
Policy mu Max                2.560572
Policy mu Min                -2.2179778
Policy log std Mean          -0.4341651
Policy log std Std           0.18985143
Policy log std Max           0.04626164
Policy log std Min           -1.6777205
Z mean eval                  2.15639
Z variance eval              0.018573845
total_rewards                [3945.58046096 4220.94580097 4024.13684278 2458.72207811 4060.36271591
 3775.72387136 3924.19714662 4008.41502216 4268.21352796 4116.60474594]
total_rewards_mean           3880.2902212784525
total_rewards_std            492.93913717162457
total_rewards_max            4268.213527961186
total_rewards_min            2458.722078108466
Number of train steps total  64000
Number of env steps total    194000
Number of rollouts total     0
Train Time (s)               136.0381448729895
(Previous) Eval Time (s)     29.1315353740938
Sample Time (s)              9.793008456937969
Epoch Time (s)               174.96268870402128
Total Train Time (s)         2891.024079713039
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:39:30.390357 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #15 | Epoch Duration: 175.04682302474976
2020-01-13 04:39:30.390554 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #15 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1560109
Z variance train             0.018591741
KL Divergence                27.455746
KL Loss                      2.7455747
QF Loss                      256.09094
VF Loss                      51.13497
Policy Loss                  -628.5214
Q Predictions Mean           623.729
Q Predictions Std            427.99777
Q Predictions Max            1447.118
Q Predictions Min            109.91141
V Predictions Mean           628.1433
V Predictions Std            429.28458
V Predictions Max            1437.2018
V Predictions Min            111.93628
Log Pis Mean                 -1.3209217
Log Pis Std                  3.027526
Log Pis Max                  9.375058
Log Pis Min                  -6.195577
Policy mu Mean               -0.03234281
Policy mu Std                0.76144284
Policy mu Max                2.6741767
Policy mu Min                -3.0504224
Policy log std Mean          -0.44179294
Policy log std Std           0.18850854
Policy log std Max           -0.16483758
Policy log std Min           -1.8026974
Z mean eval                  2.1643376
Z variance eval              0.021905273
total_rewards                [3931.65543911 3986.29410851 3841.54039886 3979.4679843  4185.2588604
 4011.72114932 4026.50278836 4041.69620796 4028.05555706 4044.62236598]
total_rewards_mean           4007.6814859853594
total_rewards_std            83.35301982133022
total_rewards_max            4185.258860396818
total_rewards_min            3841.540398856878
Number of train steps total  68000
Number of env steps total    206000
Number of rollouts total     0
Train Time (s)               140.37818847596645
(Previous) Eval Time (s)     29.636836634017527
Sample Time (s)              9.637842336669564
Epoch Time (s)               179.65286744665354
Total Train Time (s)         3070.7604709006846
Epoch                        16
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:42:30.128631 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #16 | Epoch Duration: 179.73792266845703
2020-01-13 04:42:30.128918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.168
Z variance train             0.022010658
KL Divergence                30.48648
KL Loss                      3.048648
QF Loss                      194.4691
VF Loss                      92.87509
Policy Loss                  -586.7053
Q Predictions Mean           577.2095
Q Predictions Std            442.55322
Q Predictions Max            1506.7148
Q Predictions Min            114.36398
V Predictions Mean           580.9556
V Predictions Std            443.63297
V Predictions Max            1496.9319
V Predictions Min            116.44871
Log Pis Mean                 -1.588352
Log Pis Std                  3.0819478
Log Pis Max                  10.096727
Log Pis Min                  -9.722386
Policy mu Mean               -0.023022177
Policy mu Std                0.7089354
Policy mu Max                2.5599248
Policy mu Min                -2.3732564
Policy log std Mean          -0.43543497
Policy log std Std           0.18922606
Policy log std Max           -0.18052675
Policy log std Min           -1.8358722
Z mean eval                  2.1376603
Z variance eval              0.010108475
total_rewards                [4323.54406317 4196.10113319 4488.89769579 4125.37215829 3976.00631517
 4314.71664031 4341.55639276 4443.34965304 4427.20118819 4317.55442791]
total_rewards_mean           4295.429966781452
total_rewards_std            148.75164278299883
total_rewards_max            4488.897695789037
total_rewards_min            3976.006315173197
Number of train steps total  72000
Number of env steps total    218000
Number of rollouts total     0
Train Time (s)               146.32717904122546
(Previous) Eval Time (s)     29.67210314096883
Sample Time (s)              8.717916850466281
Epoch Time (s)               184.71719903266057
Total Train Time (s)         3255.5569341504015
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:45:34.925936 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #17 | Epoch Duration: 184.79668378829956
2020-01-13 04:45:34.926154 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1420865
Z variance train             0.01018998
KL Divergence                30.990833
KL Loss                      3.0990834
QF Loss                      326.7068
VF Loss                      171.19576
Policy Loss                  -645.9472
Q Predictions Mean           633.59717
Q Predictions Std            478.03458
Q Predictions Max            1528.694
Q Predictions Min            108.33403
V Predictions Mean           635.39935
V Predictions Std            479.2504
V Predictions Max            1509.122
V Predictions Min            117.70548
Log Pis Mean                 -1.4966679
Log Pis Std                  3.168276
Log Pis Max                  12.573307
Log Pis Min                  -5.6261196
Policy mu Mean               0.044510394
Policy mu Std                0.7506248
Policy mu Max                2.7421257
Policy mu Min                -2.5264802
Policy log std Mean          -0.44282043
Policy log std Std           0.20217356
Policy log std Max           -0.15446725
Policy log std Min           -1.7667996
Z mean eval                  2.1536717
Z variance eval              0.012165952
total_rewards                [4006.44583234 4497.05333432 4079.63741918 4640.68642854 4450.07806226
 4803.53429324 4627.94236285 4309.71624647 4409.14310914 4599.91244478]
total_rewards_mean           4442.414953313202
total_rewards_std            239.24491365700183
total_rewards_max            4803.534293242833
total_rewards_min            4006.445832341439
Number of train steps total  76000
Number of env steps total    230000
Number of rollouts total     0
Train Time (s)               145.14398198202252
(Previous) Eval Time (s)     28.78586185723543
Sample Time (s)              10.034160948358476
Epoch Time (s)               183.96400478761643
Total Train Time (s)         3439.6087293094024
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:48:38.980159 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #18 | Epoch Duration: 184.0538375377655
2020-01-13 04:48:38.980382 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1567967
Z variance train             0.0121422
KL Divergence                30.461346
KL Loss                      3.0461347
QF Loss                      231.95047
VF Loss                      61.116776
Policy Loss                  -652.9917
Q Predictions Mean           642.42786
Q Predictions Std            470.12903
Q Predictions Max            1555.6818
Q Predictions Min            101.82293
V Predictions Mean           652.36487
V Predictions Std            473.4002
V Predictions Max            1563.0844
V Predictions Min            112.6152
Log Pis Mean                 -1.4672794
Log Pis Std                  2.771547
Log Pis Max                  9.089682
Log Pis Min                  -6.460285
Policy mu Mean               -0.005866179
Policy mu Std                0.7090728
Policy mu Max                2.524079
Policy mu Min                -2.383123
Policy log std Mean          -0.44240746
Policy log std Std           0.20956212
Policy log std Max           -0.06296131
Policy log std Min           -1.7830443
Z mean eval                  2.1302464
Z variance eval              0.021251814
total_rewards                [4363.74121888 4189.17263375 4401.1186752  4413.78017297 4511.95851607
 4251.12407394 4407.78787941 4569.43828854 4239.90288398 4507.96367541]
total_rewards_mean           4385.598801815455
total_rewards_std            120.26473057913094
total_rewards_max            4569.438288537868
total_rewards_min            4189.172633746299
Number of train steps total  80000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               145.51250000856817
(Previous) Eval Time (s)     30.985371564049274
Sample Time (s)              10.058291838504374
Epoch Time (s)               186.55616341112182
Total Train Time (s)         3626.2524492447264
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:51:45.624280 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #19 | Epoch Duration: 186.6437270641327
2020-01-13 04:51:45.624493 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.130591
Z variance train             0.021382548
KL Divergence                28.324394
KL Loss                      2.8324394
QF Loss                      331.3884
VF Loss                      71.1032
Policy Loss                  -687.73627
Q Predictions Mean           683.3706
Q Predictions Std            493.80222
Q Predictions Max            1653.3263
Q Predictions Min            109.87888
V Predictions Mean           689.3702
V Predictions Std            494.74017
V Predictions Max            1621.7692
V Predictions Min            108.67218
Log Pis Mean                 -1.3409259
Log Pis Std                  3.297848
Log Pis Max                  9.738718
Log Pis Min                  -7.89439
Policy mu Mean               -0.041907463
Policy mu Std                0.76117015
Policy mu Max                3.0115852
Policy mu Min                -2.364581
Policy log std Mean          -0.45343503
Policy log std Std           0.20496918
Policy log std Max           0.09873229
Policy log std Min           -1.8285434
Z mean eval                  2.1448584
Z variance eval              0.019967139
total_rewards                [4253.45022951 4355.97794446 4295.13854697 4322.51323413 4285.26647418
 4253.52946319 4151.70789816 4289.65401263 4357.53102068 4330.50815898]
total_rewards_mean           4289.527698290418
total_rewards_std            57.83505892367004
total_rewards_max            4357.531020676772
total_rewards_min            4151.707898158287
Number of train steps total  84000
Number of env steps total    254000
Number of rollouts total     0
Train Time (s)               144.083226907067
(Previous) Eval Time (s)     30.77234004996717
Sample Time (s)              13.676509617827833
Epoch Time (s)               188.532076574862
Total Train Time (s)         3814.883813721128
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:54:54.257768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #20 | Epoch Duration: 188.633118391037
2020-01-13 04:54:54.257991 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1436436
Z variance train             0.01993153
KL Divergence                28.53073
KL Loss                      2.853073
QF Loss                      342.41486
VF Loss                      184.85005
Policy Loss                  -681.49115
Q Predictions Mean           673.95624
Q Predictions Std            494.54364
Q Predictions Max            1662.2656
Q Predictions Min            92.576515
V Predictions Mean           670.4573
V Predictions Std            493.7701
V Predictions Max            1648.7828
V Predictions Min            99.10451
Log Pis Mean                 -1.3790026
Log Pis Std                  3.0705378
Log Pis Max                  7.560112
Log Pis Min                  -6.9278307
Policy mu Mean               0.024438642
Policy mu Std                0.7482956
Policy mu Max                2.493583
Policy mu Min                -2.6068683
Policy log std Mean          -0.44727182
Policy log std Std           0.21511582
Policy log std Max           -0.0851683
Policy log std Min           -1.7632575
Z mean eval                  2.1527429
Z variance eval              0.026894584
total_rewards                [4278.5236842  4624.15770525 4490.41587118 4352.03043083 4460.13082051
 4431.86865917 4485.96962047 4638.82115741 4257.97471884 4350.88133349]
total_rewards_mean           4437.077400135008
total_rewards_std            123.8440217441765
total_rewards_max            4638.821157406979
total_rewards_min            4257.974718835467
Number of train steps total  88000
Number of env steps total    266000
Number of rollouts total     0
Train Time (s)               135.80928570544347
(Previous) Eval Time (s)     29.26618640497327
Sample Time (s)              9.776092582382262
Epoch Time (s)               174.851564692799
Total Train Time (s)         3989.8180725253187
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:57:49.195442 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #21 | Epoch Duration: 174.93724465370178
2020-01-13 04:57:49.195769 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1489587
Z variance train             0.02699602
KL Divergence                28.67499
KL Loss                      2.867499
QF Loss                      382.85568
VF Loss                      190.84865
Policy Loss                  -696.4181
Q Predictions Mean           689.45325
Q Predictions Std            540.96655
Q Predictions Max            1691.5641
Q Predictions Min            76.65658
V Predictions Mean           705.0094
V Predictions Std            542.18335
V Predictions Max            1684.986
V Predictions Min            90.26904
Log Pis Mean                 -1.3285109
Log Pis Std                  3.2333457
Log Pis Max                  8.773729
Log Pis Min                  -6.0632634
Policy mu Mean               0.03206118
Policy mu Std                0.7571548
Policy mu Max                2.4250805
Policy mu Min                -2.6268053
Policy log std Mean          -0.45324895
Policy log std Std           0.22530477
Policy log std Max           -0.18276295
Policy log std Min           -2.0907576
Z mean eval                  2.1034696
Z variance eval              0.012544232
total_rewards                [4508.7953424  4590.00270581 4478.14366653 4689.3375336  4778.05999114
 4364.29345017 4456.02586868 4678.04087447 4705.05716615 4497.09983877]
total_rewards_mean           4574.485643771712
total_rewards_std            126.66723752908682
total_rewards_max            4778.059991143529
total_rewards_min            4364.29345016883
Number of train steps total  92000
Number of env steps total    278000
Number of rollouts total     0
Train Time (s)               136.93847764795646
(Previous) Eval Time (s)     29.659422919154167
Sample Time (s)              9.67853239690885
Epoch Time (s)               176.27643296401948
Total Train Time (s)         4166.179544260725
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:00:45.556064 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #22 | Epoch Duration: 176.36005640029907
2020-01-13 05:00:45.556261 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #22 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1014817
Z variance train             0.012486455
KL Divergence                28.906452
KL Loss                      2.8906453
QF Loss                      229.36212
VF Loss                      44.130836
Policy Loss                  -645.7749
Q Predictions Mean           637.2941
Q Predictions Std            529.80927
Q Predictions Max            1708.951
Q Predictions Min            67.01189
V Predictions Mean           646.35004
V Predictions Std            529.95575
V Predictions Max            1720.7213
V Predictions Min            71.77211
Log Pis Mean                 -1.5745406
Log Pis Std                  3.0480723
Log Pis Max                  11.487847
Log Pis Min                  -7.2893543
Policy mu Mean               0.015818255
Policy mu Std                0.71036273
Policy mu Max                2.4802086
Policy mu Min                -2.3022852
Policy log std Mean          -0.4477997
Policy log std Std           0.22469881
Policy log std Max           -0.11985628
Policy log std Min           -1.8561778
Z mean eval                  2.152614
Z variance eval              0.0064386735
total_rewards                [4386.50136399 4422.26333637 4541.62185822 4588.36982374 4620.0424404
 4531.79886835 4428.4804518  4526.60347199 4407.08605277 4514.1287171 ]
total_rewards_mean           4496.689638472763
total_rewards_std            76.44195013385107
total_rewards_max            4620.042440398259
total_rewards_min            4386.501363986796
Number of train steps total  96000
Number of env steps total    290000
Number of rollouts total     0
Train Time (s)               139.99108413187787
(Previous) Eval Time (s)     29.834366826806217
Sample Time (s)              9.704217810183764
Epoch Time (s)               179.52966876886785
Total Train Time (s)         4345.799460324924
Epoch                        23
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:03:45.178846 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #23 | Epoch Duration: 179.62241077423096
2020-01-13 05:03:45.179215 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1560915
Z variance train             0.006420909
KL Divergence                31.44335
KL Loss                      3.144335
QF Loss                      234.54868
VF Loss                      96.42402
Policy Loss                  -718.91345
Q Predictions Mean           711.1576
Q Predictions Std            558.226
Q Predictions Max            1762.4148
Q Predictions Min            82.48784
V Predictions Mean           722.9
V Predictions Std            559.8438
V Predictions Max            1755.1619
V Predictions Min            89.61056
Log Pis Mean                 -1.4393816
Log Pis Std                  3.034569
Log Pis Max                  9.084289
Log Pis Min                  -6.348898
Policy mu Mean               0.0034131955
Policy mu Std                0.7578485
Policy mu Max                2.61989
Policy mu Min                -2.4492407
Policy log std Mean          -0.45058176
Policy log std Std           0.22086625
Policy log std Max           -0.1475388
Policy log std Min           -1.8913441
Z mean eval                  2.1043952
Z variance eval              0.012276087
total_rewards                [4158.29490261 4418.41680707 4469.18038547 4407.71484567 4385.38706083
 4427.22344896 4563.33203754 4370.76581201 4344.05107295 4358.07081193]
total_rewards_mean           4390.243718504051
total_rewards_std            97.99444516326724
total_rewards_max            4563.332037542755
total_rewards_min            4158.294902608507
Number of train steps total  100000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               145.693601696752
(Previous) Eval Time (s)     30.00818700855598
Sample Time (s)              10.205019845161587
Epoch Time (s)               185.90680855046958
Total Train Time (s)         4531.793544896413
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:06:51.173631 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #24 | Epoch Duration: 185.99419045448303
2020-01-13 05:06:51.173899 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1015556
Z variance train             0.012275374
KL Divergence                30.165888
KL Loss                      3.016589
QF Loss                      270.86206
VF Loss                      152.7073
Policy Loss                  -686.7179
Q Predictions Mean           682.7369
Q Predictions Std            565.0525
Q Predictions Max            1764.8596
Q Predictions Min            69.8864
V Predictions Mean           692.0461
V Predictions Std            566.40765
V Predictions Max            1754.1198
V Predictions Min            76.27146
Log Pis Mean                 -1.3101013
Log Pis Std                  3.1710107
Log Pis Max                  12.364924
Log Pis Min                  -6.7979608
Policy mu Mean               -0.030437822
Policy mu Std                0.7459782
Policy mu Max                3.7669668
Policy mu Min                -2.5283887
Policy log std Mean          -0.43772817
Policy log std Std           0.20911577
Policy log std Max           -0.13612133
Policy log std Min           -1.961273
Z mean eval                  2.109567
Z variance eval              0.006008694
total_rewards                [4674.41131747 4706.86633592 4615.96564803 4693.39674345 4815.51554771
 4794.01590176 4827.26734046 4859.91484356 4734.45355073 4752.2211    ]
total_rewards_mean           4747.402832908334
total_rewards_std            72.9408472656618
total_rewards_max            4859.9148435589705
total_rewards_min            4615.96564803397
Number of train steps total  104000
Number of env steps total    314000
Number of rollouts total     0
Train Time (s)               145.0594505816698
(Previous) Eval Time (s)     29.29925661208108
Sample Time (s)              10.269540433771908
Epoch Time (s)               184.6282476275228
Total Train Time (s)         4716.536315409467
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:09:55.918236 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #25 | Epoch Duration: 184.74416065216064
2020-01-13 05:09:55.918580 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1069324
Z variance train             0.0059761778
KL Divergence                32.467567
KL Loss                      3.2467568
QF Loss                      430.35516
VF Loss                      113.64252
Policy Loss                  -652.6116
Q Predictions Mean           642.47876
Q Predictions Std            570.6855
Q Predictions Max            1746.0643
Q Predictions Min            61.094395
V Predictions Mean           658.38696
V Predictions Std            571.68555
V Predictions Max            1751.9493
V Predictions Min            75.52189
Log Pis Mean                 -1.4582086
Log Pis Std                  3.262673
Log Pis Max                  8.994139
Log Pis Min                  -7.873481
Policy mu Mean               -0.004438695
Policy mu Std                0.7295299
Policy mu Max                2.6047447
Policy mu Min                -2.411281
Policy log std Mean          -0.44278923
Policy log std Std           0.22586991
Policy log std Max           -0.14189085
Policy log std Min           -1.9744833
Z mean eval                  2.1199965
Z variance eval              0.017043285
total_rewards                [4670.9383559  4963.41743254 4833.32986848 4644.41411435 4702.44808469
 4780.15379029 4579.02243871 4646.41647444 4722.98193126 4672.46482013]
total_rewards_mean           4721.5587310801175
total_rewards_std            105.676828886763
total_rewards_max            4963.417432538868
total_rewards_min            4579.022438713819
Number of train steps total  108000
Number of env steps total    326000
Number of rollouts total     0
Train Time (s)               145.3807795541361
(Previous) Eval Time (s)     29.825206984300166
Sample Time (s)              10.13071264559403
Epoch Time (s)               185.3366991840303
Total Train Time (s)         4901.9714841274545
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:13:01.354561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #26 | Epoch Duration: 185.43572068214417
2020-01-13 05:13:01.354799 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1186569
Z variance train             0.016959604
KL Divergence                30.437723
KL Loss                      3.0437725
QF Loss                      248.0378
VF Loss                      99.18346
Policy Loss                  -707.2911
Q Predictions Mean           703.9597
Q Predictions Std            602.25256
Q Predictions Max            1820.4639
Q Predictions Min            68.527336
V Predictions Mean           707.2534
V Predictions Std            607.2852
V Predictions Max            1816.116
V Predictions Min            63.56658
Log Pis Mean                 -1.4303405
Log Pis Std                  3.1259248
Log Pis Max                  9.80846
Log Pis Min                  -6.4317484
Policy mu Mean               -0.053317606
Policy mu Std                0.757048
Policy mu Max                2.4817348
Policy mu Min                -2.964065
Policy log std Mean          -0.43340537
Policy log std Std           0.22247656
Policy log std Max           -0.1546616
Policy log std Min           -2.13376
Z mean eval                  2.1110215
Z variance eval              0.0215013
total_rewards                [4942.847207   4818.81870314 4786.85754587 4915.88387349  866.93114477
 4791.0969494  4994.24376896 4907.19255862 4908.89085153 4877.68052453]
total_rewards_mean           4481.044312731652
total_rewards_std            1206.36877496575
total_rewards_max            4994.243768963913
total_rewards_min            866.9311447664874
Number of train steps total  112000
Number of env steps total    338000
Number of rollouts total     0
Train Time (s)               144.18067615991458
(Previous) Eval Time (s)     30.826987565029413
Sample Time (s)              10.120251310057938
Epoch Time (s)               185.12791503500193
Total Train Time (s)         5087.17973590875
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:16:06.563983 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #27 | Epoch Duration: 185.2090072631836
2020-01-13 05:16:06.564208 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1119301
Z variance train             0.021515464
KL Divergence                29.851763
KL Loss                      2.9851763
QF Loss                      602.24805
VF Loss                      112.76834
Policy Loss                  -680.94464
Q Predictions Mean           673.10913
Q Predictions Std            593.21497
Q Predictions Max            1885.1666
Q Predictions Min            63.88822
V Predictions Mean           682.6601
V Predictions Std            595.27637
V Predictions Max            1879.8964
V Predictions Min            62.724743
Log Pis Mean                 -1.3530844
Log Pis Std                  3.280138
Log Pis Max                  12.090601
Log Pis Min                  -7.5672026
Policy mu Mean               0.0058047753
Policy mu Std                0.7358404
Policy mu Max                2.6127095
Policy mu Min                -3.117839
Policy log std Mean          -0.44839573
Policy log std Std           0.22369616
Policy log std Max           -0.10885444
Policy log std Min           -1.8908439
Z mean eval                  2.1111743
Z variance eval              0.0100240065
total_rewards                [4825.47685068 4572.37104485 5061.02095815 4676.97503541 4794.68229416
 5176.89254421 5346.16674642 5189.94592126 4962.34596905 4854.72137394]
total_rewards_mean           4946.059873811193
total_rewards_std            233.27646108741465
total_rewards_max            5346.166746415366
total_rewards_min            4572.371044848234
Number of train steps total  116000
Number of env steps total    350000
Number of rollouts total     0
Train Time (s)               136.56897647678852
(Previous) Eval Time (s)     29.90249990299344
Sample Time (s)              9.793058508541435
Epoch Time (s)               176.2645348883234
Total Train Time (s)         5263.535866845865
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:19:02.922485 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #28 | Epoch Duration: 176.35808873176575
2020-01-13 05:19:02.922811 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.111857
Z variance train             0.01001667
KL Divergence                30.850431
KL Loss                      3.0850432
QF Loss                      406.57465
VF Loss                      84.1924
Policy Loss                  -729.58185
Q Predictions Mean           724.7718
Q Predictions Std            627.0113
Q Predictions Max            1905.2603
Q Predictions Min            57.441727
V Predictions Mean           731.7296
V Predictions Std            627.35535
V Predictions Max            1906.0038
V Predictions Min            59.71011
Log Pis Mean                 -1.3786867
Log Pis Std                  3.4349482
Log Pis Max                  10.065784
Log Pis Min                  -6.592848
Policy mu Mean               0.02619291
Policy mu Std                0.73529124
Policy mu Max                2.7412038
Policy mu Min                -2.2242105
Policy log std Mean          -0.4527944
Policy log std Std           0.22347276
Policy log std Max           -0.13007146
Policy log std Min           -1.9190077
Z mean eval                  2.1680627
Z variance eval              0.016040947
total_rewards                [4807.82000717 5162.92191458 4862.63675134 4833.73281823 4992.91345187
 5060.2391279  4673.11463257 4746.20707863 4741.3568128  4870.5026323 ]
total_rewards_mean           4875.144522739092
total_rewards_std            145.84613957364127
total_rewards_max            5162.921914582679
total_rewards_min            4673.114632574176
Number of train steps total  120000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               135.70186604978517
(Previous) Eval Time (s)     29.753253877628595
Sample Time (s)              8.3936552926898
Epoch Time (s)               173.84877522010356
Total Train Time (s)         5437.576032161713
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:21:56.963072 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #29 | Epoch Duration: 174.0400424003601
2020-01-13 05:21:56.963316 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1663036
Z variance train             0.016079992
KL Divergence                30.404533
KL Loss                      3.0404534
QF Loss                      563.7984
VF Loss                      62.089672
Policy Loss                  -714.21295
Q Predictions Mean           704.1423
Q Predictions Std            616.4818
Q Predictions Max            1927.1195
Q Predictions Min            59.486504
V Predictions Mean           714.4134
V Predictions Std            620.5377
V Predictions Max            1916.7892
V Predictions Min            71.528946
Log Pis Mean                 -1.3700418
Log Pis Std                  3.3520048
Log Pis Max                  11.7546215
Log Pis Min                  -7.4433756
Policy mu Mean               -0.043243315
Policy mu Std                0.71753204
Policy mu Max                3.0051122
Policy mu Min                -2.603621
Policy log std Mean          -0.43904528
Policy log std Std           0.21353832
Policy log std Max           -0.13361132
Policy log std Min           -2.0866098
Z mean eval                  2.0805879
Z variance eval              0.011595969
total_rewards                [5113.48249276 5135.22408429 4987.15902774 5194.39066094 5030.82394674
 5047.94210136 5077.93156216 5255.90487718 4968.09959184 5242.75514117]
total_rewards_mean           5105.371348616238
total_rewards_std            96.3546198117572
total_rewards_max            5255.904877175152
total_rewards_min            4968.099591842125
Number of train steps total  124000
Number of env steps total    374000
Number of rollouts total     0
Train Time (s)               140.85038622980937
(Previous) Eval Time (s)     29.891151153016835
Sample Time (s)              9.359172977972776
Epoch Time (s)               180.10071036079898
Total Train Time (s)         5617.780532153789
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:24:57.168925 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #30 | Epoch Duration: 180.20545268058777
2020-01-13 05:24:57.169133 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0811143
Z variance train             0.011618823
KL Divergence                30.354874
KL Loss                      3.0354874
QF Loss                      280.776
VF Loss                      126.556145
Policy Loss                  -774.7683
Q Predictions Mean           769.2843
Q Predictions Std            639.33417
Q Predictions Max            1975.0485
Q Predictions Min            43.74199
V Predictions Mean           776.7469
V Predictions Std            642.0582
V Predictions Max            1951.678
V Predictions Min            59.901176
Log Pis Mean                 -1.2383507
Log Pis Std                  3.4634314
Log Pis Max                  11.389447
Log Pis Min                  -8.429118
Policy mu Mean               -0.026933393
Policy mu Std                0.76745445
Policy mu Max                2.6364625
Policy mu Min                -2.3934
Policy log std Mean          -0.45716357
Policy log std Std           0.21763717
Policy log std Max           -0.112641275
Policy log std Min           -1.7996583
Z mean eval                  2.132667
Z variance eval              0.011667515
total_rewards                [4784.90890619 4528.57320011 4889.22805569 4780.41956832 4480.03486013
 4756.62020714 4698.20453827 4687.77857377 4778.69819182 4745.00179581]
total_rewards_mean           4712.946789726059
total_rewards_std            117.11392104957731
total_rewards_max            4889.228055685549
total_rewards_min            4480.034860127498
Number of train steps total  128000
Number of env steps total    386000
Number of rollouts total     0
Train Time (s)               146.40916913514957
(Previous) Eval Time (s)     29.203535475302488
Sample Time (s)              10.153424886520952
Epoch Time (s)               185.766129496973
Total Train Time (s)         5803.640927994158
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:28:03.032544 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #31 | Epoch Duration: 185.86324071884155
2020-01-13 05:28:03.032832 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1307087
Z variance train             0.0116647165
KL Divergence                32.182602
KL Loss                      3.2182603
QF Loss                      311.78613
VF Loss                      168.12373
Policy Loss                  -663.3345
Q Predictions Mean           660.07745
Q Predictions Std            643.90356
Q Predictions Max            1969.8213
Q Predictions Min            54.821613
V Predictions Mean           662.2733
V Predictions Std            648.0559
V Predictions Max            1978.194
V Predictions Min            60.533672
Log Pis Mean                 -1.6306324
Log Pis Std                  3.2567031
Log Pis Max                  11.8490715
Log Pis Min                  -5.9382443
Policy mu Mean               -0.033399824
Policy mu Std                0.7032704
Policy mu Max                3.0315473
Policy mu Min                -3.0781054
Policy log std Mean          -0.42198253
Policy log std Std           0.20011961
Policy log std Max           -0.13612092
Policy log std Min           -1.8319712
Z mean eval                  2.11301
Z variance eval              0.014936668
total_rewards                [5433.1608387  5135.58947173 5476.30756074  361.42995491 5349.49380355
 5118.88633009 5268.01580436 5432.71259084 5206.52451457 5222.33425102]
total_rewards_mean           4800.445512051221
total_rewards_std            1484.5346498554034
total_rewards_max            5476.3075607402625
total_rewards_min            361.4299549093059
Number of train steps total  132000
Number of env steps total    398000
Number of rollouts total     0
Train Time (s)               145.38885322399437
(Previous) Eval Time (s)     30.179380156099796
Sample Time (s)              9.809914517216384
Epoch Time (s)               185.37814789731055
Total Train Time (s)         5989.124340560287
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:31:08.517136 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #32 | Epoch Duration: 185.4840636253357
2020-01-13 05:31:08.517472 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #32 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1112041
Z variance train             0.014915159
KL Divergence                33.03687
KL Loss                      3.3036869
QF Loss                      256.3758
VF Loss                      249.41118
Policy Loss                  -766.58545
Q Predictions Mean           762.4038
Q Predictions Std            674.1757
Q Predictions Max            2005.0723
Q Predictions Min            -13.12916
V Predictions Mean           778.55194
V Predictions Std            679.4114
V Predictions Max            2007.1013
V Predictions Min            -21.549023
Log Pis Mean                 -1.1181793
Log Pis Std                  3.3534179
Log Pis Max                  9.639143
Log Pis Min                  -5.9578457
Policy mu Mean               0.0021903014
Policy mu Std                0.77222115
Policy mu Max                2.7209527
Policy mu Min                -2.2654984
Policy log std Mean          -0.4551076
Policy log std Std           0.24342433
Policy log std Max           -0.09902355
Policy log std Min           -2.0581264
Z mean eval                  2.127005
Z variance eval              0.01039577
total_rewards                [5300.83096513 5353.5809404  5497.65532438 5213.80424065 5350.5527771
 5277.05594688 5444.93077508 5300.55184499 5394.45409285 5168.47018729]
total_rewards_mean           5330.18870947615
total_rewards_std            95.16526482731577
total_rewards_max            5497.655324380367
total_rewards_min            5168.470187293002
Number of train steps total  136000
Number of env steps total    410000
Number of rollouts total     0
Train Time (s)               144.64169518183917
(Previous) Eval Time (s)     31.07165264338255
Sample Time (s)              10.133738869801164
Epoch Time (s)               185.84708669502288
Total Train Time (s)         6175.058829740621
Epoch                        33
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:34:14.453183 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #33 | Epoch Duration: 185.93549919128418
2020-01-13 05:34:14.453462 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1236777
Z variance train             0.010397362
KL Divergence                34.706795
KL Loss                      3.4706795
QF Loss                      347.06653
VF Loss                      144.34308
Policy Loss                  -725.11383
Q Predictions Mean           713.9959
Q Predictions Std            667.07324
Q Predictions Max            2025.7898
Q Predictions Min            42.64721
V Predictions Mean           730.64124
V Predictions Std            670.2611
V Predictions Max            2018.187
V Predictions Min            42.875153
Log Pis Mean                 -1.1803313
Log Pis Std                  3.6233332
Log Pis Max                  15.080845
Log Pis Min                  -5.1907196
Policy mu Mean               -0.06262204
Policy mu Std                0.7540308
Policy mu Max                2.3648534
Policy mu Min                -2.5772035
Policy log std Mean          -0.4431738
Policy log std Std           0.22888418
Policy log std Max           -0.1306504
Policy log std Min           -1.9986396
Z mean eval                  2.1250343
Z variance eval              0.008559846
total_rewards                [5273.91599055 5209.32288153 5293.51067445 5356.64445065 5200.54020577
 5191.52684763 5312.09851736 5336.2667891  5294.41391835 5400.30824165]
total_rewards_mean           5286.854851704283
total_rewards_std            66.05963099987049
total_rewards_max            5400.308241645335
total_rewards_min            5191.52684763333
Number of train steps total  140000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               144.823901578784
(Previous) Eval Time (s)     30.424145264085382
Sample Time (s)              10.149825940839946
Epoch Time (s)               185.39787278370932
Total Train Time (s)         6360.544444364961
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:37:19.940029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #34 | Epoch Duration: 185.48636531829834
2020-01-13 05:37:19.940263 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.125375
Z variance train             0.008522726
KL Divergence                33.586365
KL Loss                      3.3586366
QF Loss                      457.00793
VF Loss                      76.90333
Policy Loss                  -797.9235
Q Predictions Mean           793.6618
Q Predictions Std            676.78705
Q Predictions Max            2026.4607
Q Predictions Min            34.352238
V Predictions Mean           800.93774
V Predictions Std            675.83484
V Predictions Max            2029.3434
V Predictions Min            50.302105
Log Pis Mean                 -1.2723565
Log Pis Std                  3.394568
Log Pis Max                  10.749321
Log Pis Min                  -6.1693077
Policy mu Mean               -0.009927802
Policy mu Std                0.77478814
Policy mu Max                3.0453033
Policy mu Min                -2.9576368
Policy log std Mean          -0.46181366
Policy log std Std           0.23282771
Policy log std Max           -0.14758363
Policy log std Min           -1.9649429
Z mean eval                  2.089369
Z variance eval              0.024710737
total_rewards                [5274.15073092 5277.6265512  5400.34284242 5132.29817512 5169.28050867
 5187.34027239 5047.72803838 5158.64583696 5156.78661368 5128.73778141]
total_rewards_mean           5193.29373511451
total_rewards_std            94.20288613609317
total_rewards_max            5400.342842421068
total_rewards_min            5047.728038382331
Number of train steps total  144000
Number of env steps total    434000
Number of rollouts total     0
Train Time (s)               136.50363826099783
(Previous) Eval Time (s)     29.57113266317174
Sample Time (s)              8.391968079842627
Epoch Time (s)               174.4667390040122
Total Train Time (s)         6535.091781661846
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:40:14.488496 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #35 | Epoch Duration: 174.54808020591736
2020-01-13 05:40:14.488689 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0930984
Z variance train             0.024696026
KL Divergence                30.17097
KL Loss                      3.0170972
QF Loss                      172.45114
VF Loss                      80.69656
Policy Loss                  -705.8486
Q Predictions Mean           699.07886
Q Predictions Std            676.1801
Q Predictions Max            2030.0559
Q Predictions Min            47.719612
V Predictions Mean           705.38635
V Predictions Std            679.897
V Predictions Max            2023.9681
V Predictions Min            56.16746
Log Pis Mean                 -1.8382403
Log Pis Std                  3.1650422
Log Pis Max                  8.768512
Log Pis Min                  -7.194309
Policy mu Mean               -0.02230967
Policy mu Std                0.67155063
Policy mu Max                2.4408631
Policy mu Min                -2.1666954
Policy log std Mean          -0.43884453
Policy log std Std           0.22316152
Policy log std Max           -0.13469201
Policy log std Min           -2.2042902
Z mean eval                  2.0887468
Z variance eval              0.012059931
total_rewards                [5413.81159856 5205.85019167 5218.36484802 5552.19500094 5117.67533731
 4964.18769714 5189.58329396 5320.84851921 4921.2417794  5406.32321664]
total_rewards_mean           5231.008148284702
total_rewards_std            189.1788143678505
total_rewards_max            5552.195000940107
total_rewards_min            4921.241779400807
Number of train steps total  148000
Number of env steps total    446000
Number of rollouts total     0
Train Time (s)               135.7681331699714
(Previous) Eval Time (s)     28.03786137374118
Sample Time (s)              9.4532196004875
Epoch Time (s)               173.2592141442001
Total Train Time (s)         6708.441079930868
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:43:07.839223 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #36 | Epoch Duration: 173.35036516189575
2020-01-13 05:43:07.839427 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0873275
Z variance train             0.012058547
KL Divergence                33.247093
KL Loss                      3.3247094
QF Loss                      1128.5049
VF Loss                      109.85789
Policy Loss                  -751.4971
Q Predictions Mean           742.8972
Q Predictions Std            696.0854
Q Predictions Max            2101.0364
Q Predictions Min            26.854395
V Predictions Mean           748.8655
V Predictions Std            697.5204
V Predictions Max            2096.1687
V Predictions Min            49.611507
Log Pis Mean                 -1.2866598
Log Pis Std                  3.6699426
Log Pis Max                  14.814001
Log Pis Min                  -6.015686
Policy mu Mean               0.008934085
Policy mu Std                0.770703
Policy mu Max                3.8101344
Policy mu Min                -2.626891
Policy log std Mean          -0.44958162
Policy log std Std           0.2225797
Policy log std Max           -0.115511954
Policy log std Min           -2.03924
Z mean eval                  2.0796592
Z variance eval              0.011098171
total_rewards                [5334.95663493 5137.06467131 5305.51999883 5304.98581315 5205.28929179
 5398.36318466 5326.17878741 5179.74984137 5415.36462827 5242.2251229 ]
total_rewards_mean           5284.969797462492
total_rewards_std            87.18024104325632
total_rewards_max            5415.364628267873
total_rewards_min            5137.064671312709
Number of train steps total  152000
Number of env steps total    458000
Number of rollouts total     0
Train Time (s)               141.29155340697616
(Previous) Eval Time (s)     29.704610521905124
Sample Time (s)              9.959739256184548
Epoch Time (s)               180.95590318506584
Total Train Time (s)         6889.479961981531
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:46:08.879567 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #37 | Epoch Duration: 181.03998470306396
2020-01-13 05:46:08.879799 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.08241
Z variance train             0.011104988
KL Divergence                33.25738
KL Loss                      3.3257382
QF Loss                      232.23781
VF Loss                      69.57449
Policy Loss                  -792.38257
Q Predictions Mean           782.9426
Q Predictions Std            688.2336
Q Predictions Max            2098.1836
Q Predictions Min            44.27765
V Predictions Mean           789.11664
V Predictions Std            686.8351
V Predictions Max            2081.9678
V Predictions Min            52.04581
Log Pis Mean                 -1.5241786
Log Pis Std                  3.0974643
Log Pis Max                  10.123113
Log Pis Min                  -6.7821503
Policy mu Mean               0.03577825
Policy mu Std                0.70882696
Policy mu Max                2.3377357
Policy mu Min                -2.4868283
Policy log std Mean          -0.44641578
Policy log std Std           0.22087532
Policy log std Max           -0.11658883
Policy log std Min           -2.0143352
Z mean eval                  2.0239816
Z variance eval              0.023644825
total_rewards                [5311.37461803 5491.95275994 5473.11379197 5461.74755427 5274.13830178
 5450.28773243 5352.84344463 5463.35674725 5555.57090106 5274.2170013 ]
total_rewards_mean           5410.8602852662
total_rewards_std            94.29751148752156
total_rewards_max            5555.570901056541
total_rewards_min            5274.138301780462
Number of train steps total  156000
Number of env steps total    470000
Number of rollouts total     0
Train Time (s)               145.92083815531805
(Previous) Eval Time (s)     30.142375172115862
Sample Time (s)              8.880198231432587
Epoch Time (s)               184.9434115588665
Total Train Time (s)         7074.771609743126
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:49:14.172679 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #38 | Epoch Duration: 185.2927234172821
2020-01-13 05:49:14.172885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0242171
Z variance train             0.023517527
KL Divergence                29.768917
KL Loss                      2.9768918
QF Loss                      242.06262
VF Loss                      135.959
Policy Loss                  -721.5627
Q Predictions Mean           713.3756
Q Predictions Std            681.03906
Q Predictions Max            2063.7078
Q Predictions Min            46.594822
V Predictions Mean           717.7269
V Predictions Std            687.16626
V Predictions Max            2073.2273
V Predictions Min            46.73326
Log Pis Mean                 -1.4594488
Log Pis Std                  3.3349922
Log Pis Max                  8.617645
Log Pis Min                  -6.7347
Policy mu Mean               -0.0882413
Policy mu Std                0.7164073
Policy mu Max                2.4818325
Policy mu Min                -2.9175324
Policy log std Mean          -0.44580665
Policy log std Std           0.22036304
Policy log std Max           -0.18558769
Policy log std Min           -1.921897
Z mean eval                  2.0659957
Z variance eval              0.013402997
total_rewards                [5493.85811213 5479.77025608 5487.46470401 5627.98518818 1401.08158981
 5501.11524576 5575.36324504 5474.63890624 5472.98551158 5364.02374197]
total_rewards_mean           5087.828650080254
total_rewards_std            1230.642417467878
total_rewards_max            5627.9851881796985
total_rewards_min            1401.0815898083601
Number of train steps total  160000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               144.9335070680827
(Previous) Eval Time (s)     29.64245746191591
Sample Time (s)              10.204035125672817
Epoch Time (s)               184.77999965567142
Total Train Time (s)         7259.633317616768
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:52:19.036262 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #39 | Epoch Duration: 184.86322021484375
2020-01-13 05:52:19.036497 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0619087
Z variance train             0.013420628
KL Divergence                32.927216
KL Loss                      3.2927215
QF Loss                      432.8795
VF Loss                      69.76184
Policy Loss                  -755.7325
Q Predictions Mean           743.81085
Q Predictions Std            689.38525
Q Predictions Max            2126.041
Q Predictions Min            42.328392
V Predictions Mean           755.6765
V Predictions Std            688.52423
V Predictions Max            2110.7336
V Predictions Min            46.544228
Log Pis Mean                 -1.2135423
Log Pis Std                  3.58145
Log Pis Max                  18.754414
Log Pis Min                  -6.35511
Policy mu Mean               -0.02385517
Policy mu Std                0.7419053
Policy mu Max                3.1129413
Policy mu Min                -3.2565775
Policy log std Mean          -0.4567825
Policy log std Std           0.24729285
Policy log std Max           -0.17240947
Policy log std Min           -2.0791461
Z mean eval                  2.046611
Z variance eval              0.01066195
total_rewards                [5529.94467473 5710.50265451 5483.81300358 5212.03384876 5455.19799368
 5298.76837771 5038.14248341 5384.20853456 5639.82622532 5307.03173254]
total_rewards_mean           5405.946952879515
total_rewards_std            191.29672179803694
total_rewards_max            5710.502654511004
total_rewards_min            5038.142483407778
Number of train steps total  164000
Number of env steps total    494000
Number of rollouts total     0
Train Time (s)               145.95017660036683
(Previous) Eval Time (s)     30.924102149903774
Sample Time (s)              10.130169194191694
Epoch Time (s)               187.0044479444623
Total Train Time (s)         7446.745163288899
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:55:26.149369 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #40 | Epoch Duration: 187.1126971244812
2020-01-13 05:55:26.149601 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0459092
Z variance train             0.010700364
KL Divergence                34.749542
KL Loss                      3.4749544
QF Loss                      330.9669
VF Loss                      162.09317
Policy Loss                  -825.4133
Q Predictions Mean           809.49207
Q Predictions Std            727.688
Q Predictions Max            2180.005
Q Predictions Min            48.849503
V Predictions Mean           817.70374
V Predictions Std            726.067
V Predictions Max            2183.1904
V Predictions Min            52.15864
Log Pis Mean                 -1.3157625
Log Pis Std                  3.472956
Log Pis Max                  15.361692
Log Pis Min                  -6.770859
Policy mu Mean               0.0033701009
Policy mu Std                0.7615785
Policy mu Max                3.378579
Policy mu Min                -2.7804766
Policy log std Mean          -0.47537985
Policy log std Std           0.23499778
Policy log std Max           -0.19121401
Policy log std Min           -2.1054826
Z mean eval                  2.0245106
Z variance eval              0.013568342
total_rewards                [5569.97933644 5289.78454067 5341.23824577 5739.04796749 5439.13624062
 5766.06998646 1863.40697228 5771.21655172 5899.66477882 5460.67905476]
total_rewards_mean           5214.022367502885
total_rewards_std            1133.4790595155189
total_rewards_max            5899.664778822243
total_rewards_min            1863.4069722804672
Number of train steps total  168000
Number of env steps total    506000
Number of rollouts total     0
Train Time (s)               144.16163227893412
(Previous) Eval Time (s)     30.401015628129244
Sample Time (s)              9.78693269053474
Epoch Time (s)               184.3495805975981
Total Train Time (s)         7631.172810378019
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:58:30.578314 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #41 | Epoch Duration: 184.4285604953766
2020-01-13 05:58:30.578521 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0223992
Z variance train             0.013627904
KL Divergence                34.138607
KL Loss                      3.4138608
QF Loss                      351.7688
VF Loss                      111.29303
Policy Loss                  -744.191
Q Predictions Mean           737.3537
Q Predictions Std            725.1245
Q Predictions Max            2174.7258
Q Predictions Min            29.611792
V Predictions Mean           746.2742
V Predictions Std            728.67725
V Predictions Max            2177.8867
V Predictions Min            48.65062
Log Pis Mean                 -1.445747
Log Pis Std                  3.5766366
Log Pis Max                  9.892241
Log Pis Min                  -7.48555
Policy mu Mean               0.015087773
Policy mu Std                0.7478343
Policy mu Max                3.2389936
Policy mu Min                -2.3513424
Policy log std Mean          -0.43230143
Policy log std Std           0.23825783
Policy log std Max           -0.11919823
Policy log std Min           -2.1189148
Z mean eval                  2.0257082
Z variance eval              0.013302381
total_rewards                [5389.82703121 5632.84405194 5748.95998634 5415.69896913 5602.08546265
 5643.4935983  5300.92257808 5457.77165824 5400.71454473 5629.55573936]
total_rewards_mean           5522.187361998166
total_rewards_std            138.93155577335028
total_rewards_max            5748.959986336664
total_rewards_min            5300.922578084906
Number of train steps total  172000
Number of env steps total    518000
Number of rollouts total     0
Train Time (s)               136.38128370186314
(Previous) Eval Time (s)     29.56881877500564
Sample Time (s)              9.726124956738204
Epoch Time (s)               175.67622743360698
Total Train Time (s)         7807.0858525079675
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:26.492609 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #42 | Epoch Duration: 175.91394424438477
2020-01-13 06:01:26.492797 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.028072
Z variance train             0.0133163165
KL Divergence                33.51174
KL Loss                      3.351174
QF Loss                      167.13824
VF Loss                      67.8954
Policy Loss                  -626.7362
Q Predictions Mean           618.28705
Q Predictions Std            666.8469
Q Predictions Max            2276.362
Q Predictions Min            37.0786
V Predictions Mean           621.95013
V Predictions Std            665.74725
V Predictions Max            2279.5066
V Predictions Min            41.056465
Log Pis Mean                 -1.9568083
Log Pis Std                  3.1081111
Log Pis Max                  12.2612
Log Pis Min                  -7.6645765
Policy mu Mean               0.009987526
Policy mu Std                0.65283734
Policy mu Max                2.6159077
Policy mu Min                -2.9470804
Policy log std Mean          -0.40909562
Policy log std Std           0.20550963
Policy log std Max           -0.09007484
Policy log std Min           -2.2105868
Z mean eval                  1.9998331
Z variance eval              0.015191587
total_rewards                [5333.46985972 5620.06031599 5338.95435507 5007.98680638 2902.99968361
 5422.14880173 5123.28270024 5195.33759645 5121.50982454 2591.87261752]
total_rewards_mean           4765.762256125842
total_rewards_std            1024.9280485186036
total_rewards_max            5620.060315992689
total_rewards_min            2591.872617517799
Number of train steps total  176000
Number of env steps total    530000
Number of rollouts total     0
Train Time (s)               136.66602864395827
(Previous) Eval Time (s)     28.56791253387928
Sample Time (s)              9.697803395800292
Epoch Time (s)               174.93174457363784
Total Train Time (s)         7982.102426167112
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:21.510934 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #43 | Epoch Duration: 175.01798248291016
2020-01-13 06:04:21.511226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0013242
Z variance train             0.015229998
KL Divergence                33.781242
KL Loss                      3.3781242
QF Loss                      2346.8125
VF Loss                      102.80548
Policy Loss                  -755.1904
Q Predictions Mean           753.85345
Q Predictions Std            739.6439
Q Predictions Max            2225.803
Q Predictions Min            42.663425
V Predictions Mean           757.31335
V Predictions Std            741.23224
V Predictions Max            2224.4165
V Predictions Min            44.712395
Log Pis Mean                 -1.3382711
Log Pis Std                  3.4608383
Log Pis Max                  12.64476
Log Pis Min                  -7.0084515
Policy mu Mean               -0.00047723143
Policy mu Std                0.7108425
Policy mu Max                2.4458432
Policy mu Min                -2.4688253
Policy log std Mean          -0.4501547
Policy log std Std           0.23968478
Policy log std Max           -0.15693119
Policy log std Min           -1.9646797
Z mean eval                  1.9579818
Z variance eval              0.013540564
total_rewards                [6046.26768063 6083.1590032  5770.64077372 5636.30462868 5701.48935783
 5801.07523684 3539.73521096 6071.73362264 5959.66180835 5948.87849363]
total_rewards_mean           5655.894581648079
total_rewards_std            721.1670745600624
total_rewards_max            6083.15900319873
total_rewards_min            3539.735210962765
Number of train steps total  180000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               140.2927076742053
(Previous) Eval Time (s)     29.36977302795276
Sample Time (s)              9.674066637642682
Epoch Time (s)               179.33654733980075
Total Train Time (s)         8161.725898680277
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:21.136968 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #44 | Epoch Duration: 179.62553310394287
2020-01-13 06:07:21.137309 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9547112
Z variance train             0.013472214
KL Divergence                35.073185
KL Loss                      3.5073185
QF Loss                      299.46506
VF Loss                      174.56305
Policy Loss                  -776.86426
Q Predictions Mean           766.5794
Q Predictions Std            739.317
Q Predictions Max            2184.7747
Q Predictions Min            44.77331
V Predictions Mean           783.205
V Predictions Std            743.0344
V Predictions Max            2187.8677
V Predictions Min            38.266518
Log Pis Mean                 -1.187521
Log Pis Std                  3.8141181
Log Pis Max                  15.618246
Log Pis Min                  -9.7429
Policy mu Mean               -0.033216614
Policy mu Std                0.77083015
Policy mu Max                3.0505178
Policy mu Min                -3.2505
Policy log std Mean          -0.45530033
Policy log std Std           0.22809207
Policy log std Max           -0.1685845
Policy log std Min           -2.0226736
Z mean eval                  1.9959366
Z variance eval              0.011198312
total_rewards                [5136.6288537  5121.92056295 5185.09741802 5225.39496705 5070.79400524
 5254.81550699 5180.04705121 5205.42855253 5074.29492644 5227.75627187]
total_rewards_mean           5168.217811600034
total_rewards_std            61.300009268274074
total_rewards_max            5254.815506992342
total_rewards_min            5070.794005240026
Number of train steps total  184000
Number of env steps total    554000
Number of rollouts total     0
Train Time (s)               146.38729037716985
(Previous) Eval Time (s)     29.891559289302677
Sample Time (s)              10.316315712872893
Epoch Time (s)               186.59516537934542
Total Train Time (s)         8348.406463594642
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:27.820561 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #45 | Epoch Duration: 186.68300938606262
2020-01-13 06:10:27.820948 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9951019
Z variance train             0.011227387
KL Divergence                35.187634
KL Loss                      3.5187633
QF Loss                      177.42548
VF Loss                      75.05576
Policy Loss                  -779.0234
Q Predictions Mean           770.44763
Q Predictions Std            765.7434
Q Predictions Max            2302.1384
Q Predictions Min            35.769066
V Predictions Mean           781.68274
V Predictions Std            766.5565
V Predictions Max            2289.6772
V Predictions Min            44.110893
Log Pis Mean                 -1.101001
Log Pis Std                  3.7829368
Log Pis Max                  14.134817
Log Pis Min                  -7.4491644
Policy mu Mean               -0.055205733
Policy mu Std                0.75155884
Policy mu Max                2.3074992
Policy mu Min                -2.757326
Policy log std Mean          -0.45108792
Policy log std Std           0.24164055
Policy log std Max           -0.12751514
Policy log std Min           -2.287738
Z mean eval                  2.0252297
Z variance eval              0.010684384
total_rewards                [5586.96404037 5647.94146236 5657.92902475 5511.71519512 5593.56276381
 5481.37669242 5473.60572403 5644.93123478 5507.73958869 5453.95803264]
total_rewards_mean           5555.972375896872
total_rewards_std            74.95430447337071
total_rewards_max            5657.929024753799
total_rewards_min            5453.958032636678
Number of train steps total  188000
Number of env steps total    566000
Number of rollouts total     0
Train Time (s)               145.38473775284365
(Previous) Eval Time (s)     29.79464071802795
Sample Time (s)              10.364772672299296
Epoch Time (s)               185.5441511431709
Total Train Time (s)         8534.033692013007
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:33.449701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #46 | Epoch Duration: 185.6285116672516
2020-01-13 06:13:33.450022 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #46 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.022629
Z variance train             0.010740251
KL Divergence                35.947765
KL Loss                      3.5947766
QF Loss                      663.33624
VF Loss                      237.8605
Policy Loss                  -767.93353
Q Predictions Mean           762.2193
Q Predictions Std            735.24316
Q Predictions Max            2291.898
Q Predictions Min            36.065548
V Predictions Mean           761.3637
V Predictions Std            737.35
V Predictions Max            2268.31
V Predictions Min            34.546623
Log Pis Mean                 -1.4086276
Log Pis Std                  3.276019
Log Pis Max                  9.829756
Log Pis Min                  -6.0065937
Policy mu Mean               -0.009749838
Policy mu Std                0.7359832
Policy mu Max                2.714432
Policy mu Min                -3.1117702
Policy log std Mean          -0.44244492
Policy log std Std           0.2232737
Policy log std Max           -0.12022716
Policy log std Min           -2.0728297
Z mean eval                  2.0227783
Z variance eval              0.0122182965
total_rewards                [5905.37153623 5995.27921646 5741.05884778 6012.52774576 6206.1421376
 5906.27981982 6132.20205308 5979.78647092 5996.63591432 5998.34250131]
total_rewards_mean           5987.362624327927
total_rewards_std            119.9021897555574
total_rewards_max            6206.142137600635
total_rewards_min            5741.058847775811
Number of train steps total  192000
Number of env steps total    578000
Number of rollouts total     0
Train Time (s)               145.88038295600563
(Previous) Eval Time (s)     30.094539104029536
Sample Time (s)              8.615548849571496
Epoch Time (s)               184.59047090960667
Total Train Time (s)         8718.716361828614
Epoch                        47
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:16:38.133565 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #47 | Epoch Duration: 184.68335437774658
2020-01-13 06:16:38.133795 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020514
Z variance train             0.012190766
KL Divergence                36.49637
KL Loss                      3.649637
QF Loss                      672.4306
VF Loss                      82.735016
Policy Loss                  -701.0707
Q Predictions Mean           688.7511
Q Predictions Std            708.65735
Q Predictions Max            2271.6125
Q Predictions Min            32.854378
V Predictions Mean           704.5564
V Predictions Std            711.8039
V Predictions Max            2281.5364
V Predictions Min            41.600475
Log Pis Mean                 -1.7622938
Log Pis Std                  3.2515333
Log Pis Max                  8.603565
Log Pis Min                  -9.376663
Policy mu Mean               0.02100342
Policy mu Std                0.6964792
Policy mu Max                2.602166
Policy mu Min                -4.0878415
Policy log std Mean          -0.43501893
Policy log std Std           0.21704914
Policy log std Max           -0.13475406
Policy log std Min           -2.1087604
Z mean eval                  2.0214353
Z variance eval              0.007575405
total_rewards                [5704.76426025 6042.72244848 5708.00278718 6018.5094497  6160.12235388
 5910.37081751 6006.93089241 5874.50881057 5951.32345422 5828.25646094]
total_rewards_mean           5920.5511735145465
total_rewards_std            138.8549765502233
total_rewards_max            6160.122353877564
total_rewards_min            5704.764260251925
Number of train steps total  196000
Number of env steps total    590000
Number of rollouts total     0
Train Time (s)               145.1507929409854
(Previous) Eval Time (s)     29.680855418089777
Sample Time (s)              9.939929692540318
Epoch Time (s)               184.7715780516155
Total Train Time (s)         8903.561380140949
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:19:42.986853 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #48 | Epoch Duration: 184.8529052734375
2020-01-13 06:19:42.987039 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #48 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020366
Z variance train             0.0075940983
KL Divergence                37.225876
KL Loss                      3.7225876
QF Loss                      138.6568
VF Loss                      118.63945
Policy Loss                  -791.9998
Q Predictions Mean           784.7882
Q Predictions Std            780.82
Q Predictions Max            2317.0781
Q Predictions Min            29.061998
V Predictions Mean           791.0008
V Predictions Std            784.4512
V Predictions Max            2323.135
V Predictions Min            39.230427
Log Pis Mean                 -1.5225763
Log Pis Std                  3.376581
Log Pis Max                  10.226857
Log Pis Min                  -6.3134823
Policy mu Mean               0.02187184
Policy mu Std                0.7207163
Policy mu Max                2.457533
Policy mu Min                -2.486671
Policy log std Mean          -0.4383665
Policy log std Std           0.23262133
Policy log std Max           -0.06257227
Policy log std Min           -2.234241
Z mean eval                  1.9986794
Z variance eval              0.012147497
total_rewards                [4937.57589549 5424.41366842 5397.53097908 5603.00829508 5552.2801411
 5740.14147581 5427.60769725 5542.55120591 5375.32751268 5485.64379448]
total_rewards_mean           5448.608066530147
total_rewards_std            199.98379674786847
total_rewards_max            5740.14147581393
total_rewards_min            4937.575895488668
Number of train steps total  200000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               136.84946279413998
(Previous) Eval Time (s)     28.259859466925263
Sample Time (s)              9.960918233729899
Epoch Time (s)               175.07024049479514
Total Train Time (s)         9078.709592363331
Epoch                        49
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:22:38.136452 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #49 | Epoch Duration: 175.1492691040039
2020-01-13 06:22:38.136651 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9997886
Z variance train             0.012166022
KL Divergence                34.557003
KL Loss                      3.4557004
QF Loss                      300.1447
VF Loss                      117.547714
Policy Loss                  -709.0722
Q Predictions Mean           699.94525
Q Predictions Std            744.76697
Q Predictions Max            2273.5496
Q Predictions Min            39.53849
V Predictions Mean           707.1188
V Predictions Std            743.399
V Predictions Max            2262.2986
V Predictions Min            39.582207
Log Pis Mean                 -1.5905968
Log Pis Std                  3.557801
Log Pis Max                  18.643559
Log Pis Min                  -7.3986583
Policy mu Mean               -0.022298692
Policy mu Std                0.72428006
Policy mu Max                3.5669618
Policy mu Min                -3.6168427
Policy log std Mean          -0.43313673
Policy log std Std           0.22697999
Policy log std Max           -0.1456872
Policy log std Min           -2.1493595
Z mean eval                  2.0200567
Z variance eval              0.022085
total_rewards                [6196.12090309 6327.35218959 6192.16531401 6374.31732235 6415.13280655
 6425.11530134 6509.86579824 6401.25520093 6241.30025099 3649.88368891]
total_rewards_mean           6073.25087760102
total_rewards_std            813.8984298711019
total_rewards_max            6509.8657982385575
total_rewards_min            3649.883688909649
Number of train steps total  204000
Number of env steps total    614000
Number of rollouts total     0
Train Time (s)               136.49422949412838
(Previous) Eval Time (s)     28.590703245718032
Sample Time (s)              9.858901346568018
Epoch Time (s)               174.94383408641443
Total Train Time (s)         9253.73437367659
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:25:33.162655 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #50 | Epoch Duration: 175.0258595943451
2020-01-13 06:25:33.162842 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0228329
Z variance train             0.022205295
KL Divergence                34.83658
KL Loss                      3.4836578
QF Loss                      238.09766
VF Loss                      134.26517
Policy Loss                  -773.56476
Q Predictions Mean           765.28455
Q Predictions Std            775.1428
Q Predictions Max            2357.061
Q Predictions Min            29.248209
V Predictions Mean           770.372
V Predictions Std            771.3907
V Predictions Max            2362.0613
V Predictions Min            31.201408
Log Pis Mean                 -1.1980177
Log Pis Std                  3.9365504
Log Pis Max                  21.077526
Log Pis Min                  -7.0957804
Policy mu Mean               -0.04984587
Policy mu Std                0.76138204
Policy mu Max                4.1796007
Policy mu Min                -3.1591907
Policy log std Mean          -0.45645896
Policy log std Std           0.23393579
Policy log std Max           -0.061897874
Policy log std Min           -2.0190425
Z mean eval                  2.0216248
Z variance eval              0.012937794
total_rewards                [5616.30520717 5802.79707214 5698.42690402 5974.3138509  5605.38547804
 1193.45023746 6100.34024832 6094.67375726 5705.02182129 5626.82307114]
total_rewards_mean           5341.7537647744575
total_rewards_std            1394.588878844147
total_rewards_max            6100.34024831757
total_rewards_min            1193.4502374642677
Number of train steps total  208000
Number of env steps total    626000
Number of rollouts total     0
Train Time (s)               141.50344343297184
(Previous) Eval Time (s)     30.107366323005408
Sample Time (s)              8.209112584590912
Epoch Time (s)               179.81992234056816
Total Train Time (s)         9433.635950988159
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:28:33.065871 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #51 | Epoch Duration: 179.9028856754303
2020-01-13 06:28:33.066070 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.020715
Z variance train             0.012893537
KL Divergence                36.347546
KL Loss                      3.6347547
QF Loss                      264.14468
VF Loss                      131.97061
Policy Loss                  -793.7319
Q Predictions Mean           785.55115
Q Predictions Std            778.5765
Q Predictions Max            2386.1743
Q Predictions Min            39.65179
V Predictions Mean           802.04895
V Predictions Std            778.99536
V Predictions Max            2394.6665
V Predictions Min            26.23598
Log Pis Mean                 -1.36414
Log Pis Std                  3.4621432
Log Pis Max                  15.368341
Log Pis Min                  -8.164765
Policy mu Mean               4.2557716e-05
Policy mu Std                0.733253
Policy mu Max                2.6704123
Policy mu Min                -3.1985502
Policy log std Mean          -0.45124778
Policy log std Std           0.24137267
Policy log std Max           -0.14931118
Policy log std Min           -2.226027
Z mean eval                  2.011811
Z variance eval              0.024778197
total_rewards                [6255.57402531 6350.06137658 6383.70941585 6458.70815181 6144.06044722
 6326.90801051 6264.44217686 6635.03739276 6368.93525968 6388.10820033]
total_rewards_mean           6357.554445690354
total_rewards_std            124.34666609675156
total_rewards_max            6635.03739275713
total_rewards_min            6144.060447219421
Number of train steps total  212000
Number of env steps total    638000
Number of rollouts total     0
Train Time (s)               146.00531670963392
(Previous) Eval Time (s)     30.054063067305833
Sample Time (s)              10.064983546268195
Epoch Time (s)               186.12436332320794
Total Train Time (s)         9619.853362502996
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:31:39.285283 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #52 | Epoch Duration: 186.21905398368835
2020-01-13 06:31:39.285522 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0130982
Z variance train             0.024825275
KL Divergence                36.523193
KL Loss                      3.6523194
QF Loss                      177.52187
VF Loss                      65.01386
Policy Loss                  -719.1867
Q Predictions Mean           710.6627
Q Predictions Std            766.6698
Q Predictions Max            2394.4631
Q Predictions Min            28.318262
V Predictions Mean           719.22375
V Predictions Std            769.8434
V Predictions Max            2401.3123
V Predictions Min            37.287132
Log Pis Mean                 -1.4834121
Log Pis Std                  3.5309596
Log Pis Max                  23.326643
Log Pis Min                  -5.845746
Policy mu Mean               0.012658595
Policy mu Std                0.7435501
Policy mu Max                3.588356
Policy mu Min                -3.3916745
Policy log std Mean          -0.4346198
Policy log std Std           0.21300694
Policy log std Max           -0.14701214
Policy log std Min           -1.9203289
Z mean eval                  2.0847006
Z variance eval              0.015446501
total_rewards                [6025.52523882 5983.95081071 6296.63738066 6105.82708826 6011.73232854
 6152.8257387  6061.46131356 6280.25019008 6105.77763339 6104.7717107 ]
total_rewards_mean           6112.875943343587
total_rewards_std            100.33417752075411
total_rewards_max            6296.637380658303
total_rewards_min            5983.950810714743
Number of train steps total  216000
Number of env steps total    650000
Number of rollouts total     0
Train Time (s)               145.7795650921762
(Previous) Eval Time (s)     27.729448957834393
Sample Time (s)              10.250517348293215
Epoch Time (s)               183.7595313983038
Total Train Time (s)         9803.918827573303
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:34:43.351919 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #53 | Epoch Duration: 184.06622123718262
2020-01-13 06:34:43.352123 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.079867
Z variance train             0.015394999
KL Divergence                35.514133
KL Loss                      3.5514133
QF Loss                      537.34106
VF Loss                      83.23999
Policy Loss                  -715.6819
Q Predictions Mean           713.14355
Q Predictions Std            740.8512
Q Predictions Max            2413.464
Q Predictions Min            37.475346
V Predictions Mean           718.9589
V Predictions Std            742.64606
V Predictions Max            2404.3345
V Predictions Min            29.783394
Log Pis Mean                 -1.3223438
Log Pis Std                  3.7855055
Log Pis Max                  16.112503
Log Pis Min                  -8.583845
Policy mu Mean               0.014840692
Policy mu Std                0.743543
Policy mu Max                2.9102461
Policy mu Min                -2.5136375
Policy log std Mean          -0.4404409
Policy log std Std           0.23722972
Policy log std Max           -0.13505581
Policy log std Min           -2.199373
Z mean eval                  2.0024207
Z variance eval              0.015083341
total_rewards                [6009.66442587 6092.00307437 6009.16927719 6124.67009831 5935.03373819
 5964.27323624 5841.73725813 5781.12302662 5912.0799988  5958.66268148]
total_rewards_mean           5962.841681520826
total_rewards_std            99.12981984924888
total_rewards_max            6124.670098313331
total_rewards_min            5781.123026622072
Number of train steps total  220000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               146.5333203957416
(Previous) Eval Time (s)     30.662334742955863
Sample Time (s)              10.043531232513487
Epoch Time (s)               187.23918637121096
Total Train Time (s)         9991.322638502344
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:37:50.757399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #54 | Epoch Duration: 187.40513134002686
2020-01-13 06:37:50.757597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.001494
Z variance train             0.015063735
KL Divergence                35.826508
KL Loss                      3.582651
QF Loss                      588.49646
VF Loss                      95.29492
Policy Loss                  -750.9711
Q Predictions Mean           742.3648
Q Predictions Std            772.2203
Q Predictions Max            2526.168
Q Predictions Min            23.207182
V Predictions Mean           752.2582
V Predictions Std            780.677
V Predictions Max            2521.678
V Predictions Min            29.817118
Log Pis Mean                 -1.3247252
Log Pis Std                  3.7245533
Log Pis Max                  17.207088
Log Pis Min                  -6.634151
Policy mu Mean               -0.024117835
Policy mu Std                0.74851793
Policy mu Max                3.1816857
Policy mu Min                -2.7364032
Policy log std Mean          -0.45783707
Policy log std Std           0.25216967
Policy log std Max           -0.14771533
Policy log std Min           -2.2913451
Z mean eval                  2.0410383
Z variance eval              0.010049472
total_rewards                [5607.26902556 5644.62454966 2118.43142305 2211.704396   5642.01568762
 5734.70921207 5941.78518451 5570.69501941 5462.08998715 5887.03560918]
total_rewards_mean           4982.036009421957
total_rewards_std            1415.0658113794118
total_rewards_max            5941.785184507168
total_rewards_min            2118.4314230524674
Number of train steps total  224000
Number of env steps total    674000
Number of rollouts total     0
Train Time (s)               144.9160492317751
(Previous) Eval Time (s)     29.940693771932274
Sample Time (s)              10.105729040689766
Epoch Time (s)               184.96247204439715
Total Train Time (s)         10176.36445143586
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:40:55.800550 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #55 | Epoch Duration: 185.04280805587769
2020-01-13 06:40:55.800744 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0399833
Z variance train             0.010072621
KL Divergence                37.29926
KL Loss                      3.7299259
QF Loss                      211.71658
VF Loss                      38.691998
Policy Loss                  -782.91907
Q Predictions Mean           774.9159
Q Predictions Std            794.50305
Q Predictions Max            2414.2388
Q Predictions Min            23.070051
V Predictions Mean           783.19855
V Predictions Std            798.3661
V Predictions Max            2421.9614
V Predictions Min            40.185593
Log Pis Mean                 -1.7102668
Log Pis Std                  3.2495668
Log Pis Max                  13.61177
Log Pis Min                  -7.509185
Policy mu Mean               -0.054950777
Policy mu Std                0.7219232
Policy mu Max                2.9777331
Policy mu Min                -2.9590662
Policy log std Mean          -0.43351316
Policy log std Std           0.20816247
Policy log std Max           -0.15943322
Policy log std Min           -2.354859
Z mean eval                  2.0726452
Z variance eval              0.011493018
total_rewards                [6213.39579829 6324.62065921 6359.92668939 6333.07425372 6195.67253832
 6127.12646183 6513.2713117  6203.19302294 6370.03561885 6209.13818508]
total_rewards_mean           6284.945453930175
total_rewards_std            109.2299251039626
total_rewards_max            6513.2713116959685
total_rewards_min            6127.126461826021
Number of train steps total  228000
Number of env steps total    686000
Number of rollouts total     0
Train Time (s)               136.65489468770102
(Previous) Eval Time (s)     29.311760658863932
Sample Time (s)              9.249615291599184
Epoch Time (s)               175.21627063816413
Total Train Time (s)         10351.663042532746
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:43:51.101207 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #56 | Epoch Duration: 175.30029845237732
2020-01-13 06:43:51.101513 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0752823
Z variance train             0.011493772
KL Divergence                37.084053
KL Loss                      3.7084053
QF Loss                      320.82874
VF Loss                      91.77863
Policy Loss                  -731.3432
Q Predictions Mean           724.66394
Q Predictions Std            782.56775
Q Predictions Max            2488.246
Q Predictions Min            12.080773
V Predictions Mean           733.37854
V Predictions Std            789.5003
V Predictions Max            2488.1099
V Predictions Min            27.999922
Log Pis Mean                 -1.5012782
Log Pis Std                  3.4209752
Log Pis Max                  10.709225
Log Pis Min                  -8.692492
Policy mu Mean               0.02107889
Policy mu Std                0.7494929
Policy mu Max                2.923206
Policy mu Min                -3.4715009
Policy log std Mean          -0.43566823
Policy log std Std           0.22600444
Policy log std Max           -0.1626581
Policy log std Min           -2.1621392
Z mean eval                  2.0319107
Z variance eval              0.011216151
total_rewards                [6323.27529509 6233.79883859 6426.09091679 6376.95310045 6175.77442611
 6253.84257941 6189.84438361 6216.26680382 6310.02100532 6291.14173983]
total_rewards_mean           6279.700908901015
total_rewards_std            77.14363167085715
total_rewards_max            6426.090916786859
total_rewards_min            6175.7744261058015
Number of train steps total  232000
Number of env steps total    698000
Number of rollouts total     0
Train Time (s)               136.54908023308963
(Previous) Eval Time (s)     29.112394374795258
Sample Time (s)              9.713238656055182
Epoch Time (s)               175.37471326394007
Total Train Time (s)         10527.118064801209
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:46:46.557518 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #57 | Epoch Duration: 175.45578575134277
2020-01-13 06:46:46.557734 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0309176
Z variance train             0.011210425
KL Divergence                37.552868
KL Loss                      3.755287
QF Loss                      765.89966
VF Loss                      113.75896
Policy Loss                  -870.97235
Q Predictions Mean           864.92725
Q Predictions Std            830.0247
Q Predictions Max            2484.472
Q Predictions Min            1.4011962
V Predictions Mean           875.3922
V Predictions Std            830.66425
V Predictions Max            2474.3567
V Predictions Min            5.7734723
Log Pis Mean                 -0.49818736
Log Pis Std                  4.3156123
Log Pis Max                  22.120754
Log Pis Min                  -5.668517
Policy mu Mean               -0.0032747108
Policy mu Std                0.85680974
Policy mu Max                3.2178266
Policy mu Min                -3.9606266
Policy log std Mean          -0.4664111
Policy log std Std           0.24193934
Policy log std Max           -0.09159917
Policy log std Min           -2.087293
Z mean eval                  2.0310092
Z variance eval              0.101059236
total_rewards                [6245.2245674  6348.32517433 6341.11839365 6332.01283946 6395.87450023
 6334.89580136 6289.00459752 6202.61758663 6251.49971547 6226.43935613]
total_rewards_mean           6296.7012532182125
total_rewards_std            59.765971385092044
total_rewards_max            6395.874500234962
total_rewards_min            6202.617586634584
Number of train steps total  236000
Number of env steps total    710000
Number of rollouts total     0
Train Time (s)               141.60514053795487
(Previous) Eval Time (s)     30.621792658697814
Sample Time (s)              9.757855520118028
Epoch Time (s)               181.9847887167707
Total Train Time (s)         10709.18862709403
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:49:48.629377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #58 | Epoch Duration: 182.07149171829224
2020-01-13 06:49:48.629576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0341835
Z variance train             0.100820564
KL Divergence                32.55957
KL Loss                      3.2559571
QF Loss                      215.61174
VF Loss                      85.60598
Policy Loss                  -900.8065
Q Predictions Mean           890.8659
Q Predictions Std            880.4361
Q Predictions Max            2577.471
Q Predictions Min            7.570378
V Predictions Mean           896.32605
V Predictions Std            879.7057
V Predictions Max            2581.0115
V Predictions Min            21.164135
Log Pis Mean                 -1.2818806
Log Pis Std                  3.4292347
Log Pis Max                  17.136395
Log Pis Min                  -6.3677235
Policy mu Mean               -0.10774199
Policy mu Std                0.77872866
Policy mu Max                3.4362895
Policy mu Min                -4.063019
Policy log std Mean          -0.45525658
Policy log std Std           0.23672932
Policy log std Max           -0.094130754
Policy log std Min           -2.107652
Z mean eval                  2.0841107
Z variance eval              0.019792726
total_rewards                [5995.95094864 6304.12952301 6265.00543231 5991.71055564 6204.25930113
 6233.23377586 6441.06292188 6240.76505834 6203.43652506 6401.27111282]
total_rewards_mean           6228.08251546927
total_rewards_std            139.1475883332303
total_rewards_max            6441.062921881841
total_rewards_min            5991.710555637286
Number of train steps total  240000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               146.80725737893954
(Previous) Eval Time (s)     30.090622069779783
Sample Time (s)              9.617476588115096
Epoch Time (s)               186.51535603683442
Total Train Time (s)         10895.783924493473
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:52:55.226191 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #59 | Epoch Duration: 186.5964720249176
2020-01-13 06:52:55.226382 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0853515
Z variance train             0.019811848
KL Divergence                34.170506
KL Loss                      3.4170506
QF Loss                      751.3261
VF Loss                      62.373405
Policy Loss                  -771.0377
Q Predictions Mean           765.3185
Q Predictions Std            806.8498
Q Predictions Max            2498.7222
Q Predictions Min            14.610027
V Predictions Mean           770.515
V Predictions Std            807.965
V Predictions Max            2498.4827
V Predictions Min            23.997192
Log Pis Mean                 -1.2919998
Log Pis Std                  3.6155052
Log Pis Max                  16.01455
Log Pis Min                  -7.4917984
Policy mu Mean               0.040800486
Policy mu Std                0.76959974
Policy mu Max                2.6661005
Policy mu Min                -2.931451
Policy log std Mean          -0.44043204
Policy log std Std           0.24020322
Policy log std Max           -0.06021738
Policy log std Min           -2.3952565
Z mean eval                  2.0630558
Z variance eval              0.026995635
total_rewards                [6370.1920269  6146.16146701 6249.23076618 6164.1191507  5848.06748432
 6191.88025358 5754.76411196 6168.98222234 6300.02597081 6119.03227351]
total_rewards_mean           6131.24557272978
total_rewards_std            181.10322929855212
total_rewards_max            6370.192026897823
total_rewards_min            5754.764111957032
Number of train steps total  244000
Number of env steps total    734000
Number of rollouts total     0
Train Time (s)               146.3035283833742
(Previous) Eval Time (s)     29.670186700765043
Sample Time (s)              10.22651551431045
Epoch Time (s)               186.2002305984497
Total Train Time (s)         11082.146471789572
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:01.589267 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #60 | Epoch Duration: 186.36274981498718
2020-01-13 06:56:01.589416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.067231
Z variance train             0.026877647
KL Divergence                34.368607
KL Loss                      3.4368608
QF Loss                      225.0141
VF Loss                      157.39056
Policy Loss                  -780.4479
Q Predictions Mean           774.26764
Q Predictions Std            816.712
Q Predictions Max            2592.868
Q Predictions Min            8.497872
V Predictions Mean           771.391
V Predictions Std            815.8172
V Predictions Max            2572.148
V Predictions Min            24.295061
Log Pis Mean                 -1.123083
Log Pis Std                  3.7649522
Log Pis Max                  22.64935
Log Pis Min                  -7.9086943
Policy mu Mean               -0.028985629
Policy mu Std                0.76789945
Policy mu Max                3.153464
Policy mu Min                -3.719109
Policy log std Mean          -0.42850134
Policy log std Std           0.22554928
Policy log std Max           -0.07855612
Policy log std Min           -2.2403002
Z mean eval                  2.0211747
Z variance eval              0.018558025
total_rewards                [6433.3849868  6360.93778705 6417.65578558 6349.74203388 6542.80815699
 6311.56601459 6285.4622675  6301.87403421 6690.16385276 6407.95818502]
total_rewards_mean           6410.155310437165
total_rewards_std            118.18097622325108
total_rewards_max            6690.16385275586
total_rewards_min            6285.462267498598
Number of train steps total  248000
Number of env steps total    746000
Number of rollouts total     0
Train Time (s)               147.1963484417647
(Previous) Eval Time (s)     30.253149345051497
Sample Time (s)              10.38230992294848
Epoch Time (s)               187.8318077097647
Total Train Time (s)         11270.05816411553
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:59:09.504453 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #61 | Epoch Duration: 187.91487550735474
2020-01-13 06:59:09.504700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0219684
Z variance train             0.018581294
KL Divergence                34.45094
KL Loss                      3.4450939
QF Loss                      878.1045
VF Loss                      85.503685
Policy Loss                  -731.6569
Q Predictions Mean           726.3269
Q Predictions Std            777.0303
Q Predictions Max            2540.7393
Q Predictions Min            13.938679
V Predictions Mean           730.9416
V Predictions Std            782.4795
V Predictions Max            2550.2869
V Predictions Min            22.52729
Log Pis Mean                 -1.5788031
Log Pis Std                  3.2153296
Log Pis Max                  10.207809
Log Pis Min                  -7.1961718
Policy mu Mean               0.0153930085
Policy mu Std                0.6979507
Policy mu Max                3.0012193
Policy mu Min                -2.6345224
Policy log std Mean          -0.43904033
Policy log std Std           0.22110085
Policy log std Max           -0.12390125
Policy log std Min           -2.2432415
Z mean eval                  2.0845323
Z variance eval              0.022334734
total_rewards                [6366.61701621 6384.11024446 6568.73303968 6295.42817957 6102.76233589
 6183.61101141 6330.61750433 6171.23505039 6264.14353238 6184.54369322]
total_rewards_mean           6285.180160754356
total_rewards_std            128.89422545269178
total_rewards_max            6568.733039680914
total_rewards_min            6102.762335892759
Number of train steps total  252000
Number of env steps total    758000
Number of rollouts total     0
Train Time (s)               145.5235785022378
(Previous) Eval Time (s)     29.591422019992024
Sample Time (s)              9.253565735649318
Epoch Time (s)               184.36856625787914
Total Train Time (s)         11454.50898807589
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:02:13.956100 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #62 | Epoch Duration: 184.45122504234314
2020-01-13 07:02:13.956302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0824246
Z variance train             0.022309205
KL Divergence                36.19129
KL Loss                      3.6191292
QF Loss                      322.16986
VF Loss                      70.66058
Policy Loss                  -807.82043
Q Predictions Mean           798.75244
Q Predictions Std            850.1262
Q Predictions Max            2629.7883
Q Predictions Min            15.207573
V Predictions Mean           810.43176
V Predictions Std            849.1843
V Predictions Max            2633.8652
V Predictions Min            23.480202
Log Pis Mean                 -1.3488173
Log Pis Std                  3.5960279
Log Pis Max                  16.258965
Log Pis Min                  -8.409865
Policy mu Mean               0.038637545
Policy mu Std                0.771289
Policy mu Max                3.528965
Policy mu Min                -3.12379
Policy log std Mean          -0.44522572
Policy log std Std           0.2243221
Policy log std Max           -0.16598448
Policy log std Min           -1.9016123
Z mean eval                  2.0575664
Z variance eval              0.010132386
total_rewards                [6132.84645368 6366.42455312 6116.25993302 6399.38152619 6435.38697597
 6074.41544407 6125.11308572 6290.26757432 6428.52856672 6094.38175663]
total_rewards_mean           6246.300586945788
total_rewards_std            143.4747337144928
total_rewards_max            6435.386975974041
total_rewards_min            6074.415444071763
Number of train steps total  256000
Number of env steps total    770000
Number of rollouts total     0
Train Time (s)               137.21608006302267
(Previous) Eval Time (s)     29.720430211164057
Sample Time (s)              9.89917317731306
Epoch Time (s)               176.8356834514998
Total Train Time (s)         11631.435193000827
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:05:10.884768 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #63 | Epoch Duration: 176.92829942703247
2020-01-13 07:05:10.884971 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0587547
Z variance train             0.010155772
KL Divergence                36.21942
KL Loss                      3.6219423
QF Loss                      350.5406
VF Loss                      69.47083
Policy Loss                  -849.3924
Q Predictions Mean           842.1324
Q Predictions Std            860.4691
Q Predictions Max            2566.3105
Q Predictions Min            27.225986
V Predictions Mean           850.25104
V Predictions Std            855.89294
V Predictions Max            2549.6206
V Predictions Min            18.834291
Log Pis Mean                 -1.4086952
Log Pis Std                  3.2453396
Log Pis Max                  14.813059
Log Pis Min                  -6.4579306
Policy mu Mean               -0.0577248
Policy mu Std                0.7476513
Policy mu Max                2.4120786
Policy mu Min                -2.8667145
Policy log std Mean          -0.44939974
Policy log std Std           0.22550818
Policy log std Max           -0.1722877
Policy log std Min           -2.1234238
Z mean eval                  2.0970235
Z variance eval              0.009141954
total_rewards                [6813.19063628 6496.18668873 6573.46624873 6507.26001662 6440.65337778
 6462.32074609 6370.5955731  6446.04585438 6593.72901707 6757.03985634]
total_rewards_mean           6546.048801512634
total_rewards_std            134.83356852011465
total_rewards_max            6813.190636281009
total_rewards_min            6370.59557309754
Number of train steps total  260000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               136.8551266877912
(Previous) Eval Time (s)     28.946287341881543
Sample Time (s)              9.329092440195382
Epoch Time (s)               175.13050646986812
Total Train Time (s)         11806.647242192179
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:08:06.098032 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #64 | Epoch Duration: 175.21290016174316
2020-01-13 07:08:06.098255 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.097899
Z variance train             0.009149035
KL Divergence                37.78331
KL Loss                      3.778331
QF Loss                      731.89276
VF Loss                      70.59705
Policy Loss                  -836.2
Q Predictions Mean           829.17035
Q Predictions Std            858.44446
Q Predictions Max            2690.2883
Q Predictions Min            11.755645
V Predictions Mean           836.34296
V Predictions Std            861.8573
V Predictions Max            2688.2659
V Predictions Min            19.816572
Log Pis Mean                 -1.4623241
Log Pis Std                  3.2128038
Log Pis Max                  11.183438
Log Pis Min                  -6.821582
Policy mu Mean               -0.09639517
Policy mu Std                0.7436377
Policy mu Max                2.5424304
Policy mu Min                -3.4023108
Policy log std Mean          -0.44705358
Policy log std Std           0.23831262
Policy log std Max           -0.17251745
Policy log std Min           -1.8957052
Z mean eval                  2.0977204
Z variance eval              0.008191605
total_rewards                [5612.61133237 5857.92466128 5997.70710036 5853.44185776 5771.17277938
 5807.62818952 5911.30532305 5990.87683841 5808.12703633 5913.56048911]
total_rewards_mean           5852.435560757928
total_rewards_std            107.51423265077445
total_rewards_max            5997.707100363842
total_rewards_min            5612.611332372267
Number of train steps total  264000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               142.88722837343812
(Previous) Eval Time (s)     30.58816342614591
Sample Time (s)              9.553132633678615
Epoch Time (s)               183.02852443326265
Total Train Time (s)         11989.77243155893
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:11:09.225288 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #65 | Epoch Duration: 183.1268548965454
2020-01-13 07:11:09.225522 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0980892
Z variance train             0.008169186
KL Divergence                37.021835
KL Loss                      3.7021835
QF Loss                      242.921
VF Loss                      101.806595
Policy Loss                  -808.25806
Q Predictions Mean           801.36475
Q Predictions Std            844.2115
Q Predictions Max            2601.8503
Q Predictions Min            27.310837
V Predictions Mean           803.95905
V Predictions Std            845.62274
V Predictions Max            2587.27
V Predictions Min            25.614859
Log Pis Mean                 -1.4002728
Log Pis Std                  3.3946464
Log Pis Max                  11.336259
Log Pis Min                  -5.9935427
Policy mu Mean               -0.053187817
Policy mu Std                0.74165964
Policy mu Max                2.9654157
Policy mu Min                -2.8074777
Policy log std Mean          -0.43778172
Policy log std Std           0.22546455
Policy log std Max           -0.11639367
Policy log std Min           -2.2684927
Z mean eval                  2.0876184
Z variance eval              0.016662026
total_rewards                [6360.07636812 6505.3540382  6449.05345397 6699.85198675 6458.85734186
 6452.14763292 6344.38639216 6404.10236575 6427.14408154 6687.89964141]
total_rewards_mean           6478.887330268617
total_rewards_std            116.48819084300024
total_rewards_max            6699.851986745947
total_rewards_min            6344.386392160023
Number of train steps total  268000
Number of env steps total    806000
Number of rollouts total     0
Train Time (s)               146.8734187236987
(Previous) Eval Time (s)     30.47038916684687
Sample Time (s)              10.475639813113958
Epoch Time (s)               187.81944770365953
Total Train Time (s)         12177.674428273924
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:14:17.128399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #66 | Epoch Duration: 187.9026997089386
2020-01-13 07:14:17.128601 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #66 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0879111
Z variance train             0.016592646
KL Divergence                35.975502
KL Loss                      3.5975502
QF Loss                      394.7705
VF Loss                      212.69884
Policy Loss                  -781.58484
Q Predictions Mean           775.0259
Q Predictions Std            826.3335
Q Predictions Max            2626.0715
Q Predictions Min            1.3439921
V Predictions Mean           789.65076
V Predictions Std            830.18256
V Predictions Max            2642.961
V Predictions Min            -1.2743202
Log Pis Mean                 -1.0049441
Log Pis Std                  4.1029935
Log Pis Max                  29.4178
Log Pis Min                  -6.3625846
Policy mu Mean               -0.037278686
Policy mu Std                0.7849453
Policy mu Max                3.766023
Policy mu Min                -4.378941
Policy log std Mean          -0.4545412
Policy log std Std           0.23014368
Policy log std Max           -0.16515332
Policy log std Min           -2.2658677
Z mean eval                  2.1196606
Z variance eval              0.030474503
total_rewards                [6484.79431641 6443.5368431  6531.01526325 6247.27149829 6260.2987938
 6400.69096296 6723.45823186 6621.85864955 6545.54292361 6588.96921251]
total_rewards_mean           6484.743669534025
total_rewards_std            144.22798981346327
total_rewards_max            6723.45823185709
total_rewards_min            6247.271498287647
Number of train steps total  272000
Number of env steps total    818000
Number of rollouts total     0
Train Time (s)               146.02240215800703
(Previous) Eval Time (s)     28.665760532952845
Sample Time (s)              10.138199139852077
Epoch Time (s)               184.82636183081195
Total Train Time (s)         12362.581625858322
Epoch                        67
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:17:22.037375 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #67 | Epoch Duration: 184.90862584114075
2020-01-13 07:17:22.037582 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.123031
Z variance train             0.030573254
KL Divergence                34.447403
KL Loss                      3.4447403
QF Loss                      308.62152
VF Loss                      321.8829
Policy Loss                  -856.62836
Q Predictions Mean           845.5367
Q Predictions Std            843.5463
Q Predictions Max            2630.4436
Q Predictions Min            18.243519
V Predictions Mean           864.38586
V Predictions Std            853.7292
V Predictions Max            2671.7188
V Predictions Min            29.57282
Log Pis Mean                 -0.82533944
Log Pis Std                  4.4015236
Log Pis Max                  27.680353
Log Pis Min                  -7.2369275
Policy mu Mean               -0.027511457
Policy mu Std                0.8367875
Policy mu Max                3.466505
Policy mu Min                -3.752751
Policy log std Mean          -0.45784363
Policy log std Std           0.22754945
Policy log std Max           -0.17017949
Policy log std Min           -2.1027927
Z mean eval                  2.0819879
Z variance eval              0.03330638
total_rewards                [6574.58632018 6595.58962956 6799.62688276 6643.38593174 6637.76132859
 6530.70301412 6619.98852944 6800.95030599 6877.44161103 6348.59684261]
total_rewards_mean           6642.863039603161
total_rewards_std            145.3313759312994
total_rewards_max            6877.441611033236
total_rewards_min            6348.596842605074
Number of train steps total  276000
Number of env steps total    830000
Number of rollouts total     0
Train Time (s)               147.89630915923044
(Previous) Eval Time (s)     30.448077380657196
Sample Time (s)              10.302103366702795
Epoch Time (s)               188.64648990659043
Total Train Time (s)         12551.310798921622
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:20:30.773052 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #68 | Epoch Duration: 188.73532056808472
2020-01-13 07:20:30.773334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0812538
Z variance train             0.033280134
KL Divergence                33.456295
KL Loss                      3.3456295
QF Loss                      353.64917
VF Loss                      95.30408
Policy Loss                  -779.6816
Q Predictions Mean           773.2162
Q Predictions Std            830.7581
Q Predictions Max            2661.9802
Q Predictions Min            18.905039
V Predictions Mean           785.7062
V Predictions Std            831.7262
V Predictions Max            2656.8967
V Predictions Min            19.61838
Log Pis Mean                 -0.99311787
Log Pis Std                  3.9309545
Log Pis Max                  24.429218
Log Pis Min                  -6.563342
Policy mu Mean               -0.01312505
Policy mu Std                0.7650897
Policy mu Max                3.1983604
Policy mu Min                -4.321917
Policy log std Mean          -0.45243225
Policy log std Std           0.2481923
Policy log std Max           -0.12100753
Policy log std Min           -2.205553
Z mean eval                  2.1139324
Z variance eval              0.011336083
total_rewards                [6608.76528687 6593.85894023 6341.15303118 6488.10640037 6673.50829262
 6489.17226835 6328.09197035 6442.03726463 6730.65654861 6453.46375924]
total_rewards_mean           6514.881376244128
total_rewards_std            127.39746220389581
total_rewards_max            6730.6565486055
total_rewards_min            6328.0919703521695
Number of train steps total  280000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               145.71024894108996
(Previous) Eval Time (s)     28.347351814154536
Sample Time (s)              10.079691198654473
Epoch Time (s)               184.13729195389897
Total Train Time (s)         12735.533161858562
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:23:34.992235 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #69 | Epoch Duration: 184.21867203712463
2020-01-13 07:23:34.992440 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #69 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1124444
Z variance train             0.011336419
KL Divergence                37.875526
KL Loss                      3.7875526
QF Loss                      276.01514
VF Loss                      94.648834
Policy Loss                  -864.4716
Q Predictions Mean           855.6941
Q Predictions Std            884.8962
Q Predictions Max            2686.0486
Q Predictions Min            -22.247665
V Predictions Mean           861.6914
V Predictions Std            885.81714
V Predictions Max            2677.923
V Predictions Min            -4.853763
Log Pis Mean                 -0.8568133
Log Pis Std                  3.9086823
Log Pis Max                  17.933487
Log Pis Min                  -6.284458
Policy mu Mean               0.029262086
Policy mu Std                0.80626285
Policy mu Max                3.0108733
Policy mu Min                -3.509879
Policy log std Mean          -0.4636415
Policy log std Std           0.22356936
Policy log std Max           -0.15024126
Policy log std Min           -1.9933683
Z mean eval                  2.0911803
Z variance eval              0.012289772
total_rewards                [6203.38445153 6482.69394202 6399.91858511 6347.11918706 6489.9626014
 6421.59437013 6430.93969376 6340.91328639 6362.4993399  6495.93792081]
total_rewards_mean           6397.49633781233
total_rewards_std            84.76328256675062
total_rewards_max            6495.937920809328
total_rewards_min            6203.384451530085
Number of train steps total  284000
Number of env steps total    854000
Number of rollouts total     0
Train Time (s)               136.9689394137822
(Previous) Eval Time (s)     28.54556140722707
Sample Time (s)              9.672037093434483
Epoch Time (s)               175.18653791444376
Total Train Time (s)         12910.810417836998
Epoch                        70
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:26:30.271698 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #70 | Epoch Duration: 175.27910327911377
2020-01-13 07:26:30.271918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0899749
Z variance train             0.012307909
KL Divergence                38.619167
KL Loss                      3.8619168
QF Loss                      232.86732
VF Loss                      108.915855
Policy Loss                  -903.5672
Q Predictions Mean           897.1828
Q Predictions Std            922.0072
Q Predictions Max            2724.7188
Q Predictions Min            -9.4624
V Predictions Mean           903.60724
V Predictions Std            923.8631
V Predictions Max            2747.462
V Predictions Min            0.38629067
Log Pis Mean                 -1.0423926
Log Pis Std                  3.5040038
Log Pis Max                  10.858874
Log Pis Min                  -6.455991
Policy mu Mean               -0.031762745
Policy mu Std                0.80567884
Policy mu Max                2.7344728
Policy mu Min                -3.0028439
Policy log std Mean          -0.47408858
Policy log std Std           0.24076946
Policy log std Max           -0.14937961
Policy log std Min           -2.10766
Z mean eval                  2.110599
Z variance eval              0.012153321
total_rewards                [6150.29913438 5852.29309285 5986.84198943 5972.75356448 5960.02535079
 6073.42077258 4364.24970351  801.68215146 5812.72922746 5773.51656389]
total_rewards_mean           5274.781155083609
total_rewards_std            1567.7193655078597
total_rewards_max            6150.299134382287
total_rewards_min            801.6821514613205
Number of train steps total  288000
Number of env steps total    866000
Number of rollouts total     0
Train Time (s)               137.14946652762592
(Previous) Eval Time (s)     29.63227978302166
Sample Time (s)              9.713988360017538
Epoch Time (s)               176.49573467066512
Total Train Time (s)         13087.38766539609
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:29:26.849933 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #71 | Epoch Duration: 176.57785654067993
2020-01-13 07:29:26.850128 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1086354
Z variance train             0.012157956
KL Divergence                38.719612
KL Loss                      3.8719614
QF Loss                      436.4615
VF Loss                      96.89441
Policy Loss                  -751.9231
Q Predictions Mean           742.3923
Q Predictions Std            845.91693
Q Predictions Max            2778.2952
Q Predictions Min            13.757522
V Predictions Mean           752.8681
V Predictions Std            852.3013
V Predictions Max            2789.9126
V Predictions Min            13.964774
Log Pis Mean                 -1.1267648
Log Pis Std                  3.6889517
Log Pis Max                  20.19771
Log Pis Min                  -6.084217
Policy mu Mean               -0.07314942
Policy mu Std                0.7564247
Policy mu Max                2.9918113
Policy mu Min                -3.3133438
Policy log std Mean          -0.44740438
Policy log std Std           0.21413617
Policy log std Max           -0.13953781
Policy log std Min           -1.9615941
Z mean eval                  2.1063764
Z variance eval              0.0114703765
total_rewards                [6384.61311199 6313.08888656 6090.02418263 6405.65340391 2538.25239238
 6391.77191916 6179.58686901 6373.68625657 6167.08784955 6490.53658773]
total_rewards_mean           5933.430145948703
total_rewards_std            1138.0647859613425
total_rewards_max            6490.536587731553
total_rewards_min            2538.252392376063
Number of train steps total  292000
Number of env steps total    878000
Number of rollouts total     0
Train Time (s)               142.91108814440668
(Previous) Eval Time (s)     28.806983451824635
Sample Time (s)              9.76675279578194
Epoch Time (s)               181.48482439201325
Total Train Time (s)         13268.967613958754
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:32:28.432586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #72 | Epoch Duration: 181.58228158950806
2020-01-13 07:32:28.432935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.103329
Z variance train             0.011470596
KL Divergence                39.949986
KL Loss                      3.9949987
QF Loss                      299.96375
VF Loss                      46.19597
Policy Loss                  -780.39355
Q Predictions Mean           772.00476
Q Predictions Std            860.889
Q Predictions Max            2736.397
Q Predictions Min            13.141107
V Predictions Mean           778.73145
V Predictions Std            860.34906
V Predictions Max            2738.055
V Predictions Min            10.566427
Log Pis Mean                 -1.5203233
Log Pis Std                  3.2201877
Log Pis Max                  10.739794
Log Pis Min                  -6.266714
Policy mu Mean               0.03097452
Policy mu Std                0.72115916
Policy mu Max                2.6327868
Policy mu Min                -2.38406
Policy log std Mean          -0.446349
Policy log std Std           0.23033412
Policy log std Max           -0.07541394
Policy log std Min           -2.0123277
Z mean eval                  2.2019203
Z variance eval              0.006598731
total_rewards                [5685.33022337 5752.43233413 5746.61372629 6120.38280041 5594.96967253
 5863.12899693 5843.73921492 5656.52283544 6078.00148747 6082.30178236]
total_rewards_mean           5842.342307385193
total_rewards_std            181.23989848999764
total_rewards_max            6120.3828004148145
total_rewards_min            5594.969672534106
Number of train steps total  296000
Number of env steps total    890000
Number of rollouts total     0
Train Time (s)               147.21350488904864
(Previous) Eval Time (s)     29.390954123344272
Sample Time (s)              9.87610414205119
Epoch Time (s)               186.4805631544441
Total Train Time (s)         13455.533374398481
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:35:34.999999 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #73 | Epoch Duration: 186.56684565544128
2020-01-13 07:35:35.000226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.209863
Z variance train             0.0065701036
KL Divergence                41.257305
KL Loss                      4.1257305
QF Loss                      494.68982
VF Loss                      82.483734
Policy Loss                  -833.2441
Q Predictions Mean           832.93164
Q Predictions Std            875.6959
Q Predictions Max            2761.9998
Q Predictions Min            6.910645
V Predictions Mean           833.2639
V Predictions Std            877.1724
V Predictions Max            2727.815
V Predictions Min            13.022754
Log Pis Mean                 -1.0802882
Log Pis Std                  3.791965
Log Pis Max                  20.252258
Log Pis Min                  -8.098682
Policy mu Mean               -0.09928683
Policy mu Std                0.7807346
Policy mu Max                2.7686079
Policy mu Min                -3.0948822
Policy log std Mean          -0.4460752
Policy log std Std           0.21414821
Policy log std Max           -0.05368632
Policy log std Min           -1.7591075
Z mean eval                  2.0730557
Z variance eval              0.01591972
total_rewards                [6608.70319722 6700.53359986 6691.97239184 6617.70517186 6561.22800561
 6655.18526714 6240.93455113 6667.174275   6614.32987328 6464.25433616]
total_rewards_mean           6582.202066907799
total_rewards_std            131.3045207358823
total_rewards_max            6700.533599855802
total_rewards_min            6240.934551134966
Number of train steps total  300000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               145.8157407878898
(Previous) Eval Time (s)     29.4497754490003
Sample Time (s)              10.13529523415491
Epoch Time (s)               185.40081147104502
Total Train Time (s)         13641.206930060871
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:38:40.675126 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #74 | Epoch Duration: 185.67473220825195
2020-01-13 07:38:40.675378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0720563
Z variance train             0.015931606
KL Divergence                39.25828
KL Loss                      3.9258282
QF Loss                      768.62946
VF Loss                      107.2471
Policy Loss                  -797.45734
Q Predictions Mean           795.4379
Q Predictions Std            871.58325
Q Predictions Max            2750.6804
Q Predictions Min            5.0575905
V Predictions Mean           796.62946
V Predictions Std            874.47656
V Predictions Max            2749.2815
V Predictions Min            9.657604
Log Pis Mean                 -1.3079457
Log Pis Std                  3.2226787
Log Pis Max                  10.540916
Log Pis Min                  -6.4716883
Policy mu Mean               0.03928903
Policy mu Std                0.74910116
Policy mu Max                2.6906693
Policy mu Min                -2.3988044
Policy log std Mean          -0.4526156
Policy log std Std           0.23830636
Policy log std Max           -0.14509493
Policy log std Min           -2.0055928
Z mean eval                  2.143462
Z variance eval              0.016688589
total_rewards                [6620.28095832 6771.85029657 6769.25175108 6577.25861626 6908.34864686
 6691.70096844 6857.7844319  6868.67820502 6851.25722309 7083.35809743]
total_rewards_mean           6799.976919497541
total_rewards_std            140.74568323231924
total_rewards_max            7083.358097429029
total_rewards_min            6577.2586162588395
Number of train steps total  304000
Number of env steps total    914000
Number of rollouts total     0
Train Time (s)               148.00684638507664
(Previous) Eval Time (s)     29.34542348328978
Sample Time (s)              10.326973338611424
Epoch Time (s)               187.67924320697784
Total Train Time (s)         13828.968359329738
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:41:48.438248 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #75 | Epoch Duration: 187.76271796226501
2020-01-13 07:41:48.438454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1395898
Z variance train             0.016732372
KL Divergence                38.970016
KL Loss                      3.8970017
QF Loss                      877.72095
VF Loss                      82.382034
Policy Loss                  -837.6265
Q Predictions Mean           827.8145
Q Predictions Std            898.2625
Q Predictions Max            2726.7603
Q Predictions Min            10.481644
V Predictions Mean           834.7314
V Predictions Std            898.7692
V Predictions Max            2730.8262
V Predictions Min            -1.3769736
Log Pis Mean                 -1.127365
Log Pis Std                  3.7420564
Log Pis Max                  17.902077
Log Pis Min                  -8.899679
Policy mu Mean               0.073464006
Policy mu Std                0.788701
Policy mu Max                3.1921813
Policy mu Min                -2.9769986
Policy log std Mean          -0.45739627
Policy log std Std           0.2331701
Policy log std Max           -0.09977648
Policy log std Min           -2.1605384
Z mean eval                  2.0641928
Z variance eval              0.06708085
total_rewards                [6214.36897143 5669.39823858 5765.49412968 5832.8219851  5852.78544472
 6364.67133025 5883.30894144 5837.10794745 6041.61427083 6074.70498434]
total_rewards_mean           5953.627624380475
total_rewards_std            204.64838401163718
total_rewards_max            6364.671330249783
total_rewards_min            5669.398238581793
Number of train steps total  308000
Number of env steps total    926000
Number of rollouts total     0
Train Time (s)               146.52410517586395
(Previous) Eval Time (s)     28.66956129297614
Sample Time (s)              9.95577214146033
Epoch Time (s)               185.14943861030042
Total Train Time (s)         14014.204332933761
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:44:53.676132 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #76 | Epoch Duration: 185.23752117156982
2020-01-13 07:44:53.676359 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #76 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0644054
Z variance train             0.066518344
KL Divergence                35.79416
KL Loss                      3.579416
QF Loss                      171.58041
VF Loss                      50.042686
Policy Loss                  -726.89386
Q Predictions Mean           721.94104
Q Predictions Std            819.93304
Q Predictions Max            2721.839
Q Predictions Min            2.5528169
V Predictions Mean           724.61365
V Predictions Std            819.848
V Predictions Max            2721.6008
V Predictions Min            4.0663843
Log Pis Mean                 -1.6259139
Log Pis Std                  3.5123205
Log Pis Max                  18.46413
Log Pis Min                  -6.4318104
Policy mu Mean               -0.028187266
Policy mu Std                0.72614163
Policy mu Max                2.910152
Policy mu Min                -2.9961596
Policy log std Mean          -0.44800767
Policy log std Std           0.20380548
Policy log std Max           -0.12269321
Policy log std Min           -2.0781476
Z mean eval                  2.1072514
Z variance eval              0.015229335
total_rewards                [6768.98923571 6817.78914042 6929.05379255 7041.63428851 6890.5130514
 6659.74979526 7025.77260893 6902.78564708 7065.6143337  6851.65417242]
total_rewards_mean           6895.35560659754
total_rewards_std            121.66069006327372
total_rewards_max            7065.6143336975565
total_rewards_min            6659.749795255695
Number of train steps total  312000
Number of env steps total    938000
Number of rollouts total     0
Train Time (s)               137.5395537437871
(Previous) Eval Time (s)     28.78566810907796
Sample Time (s)              9.78655539918691
Epoch Time (s)               176.11177725205198
Total Train Time (s)         14190.404832569417
Epoch                        77
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:47:49.879403 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #77 | Epoch Duration: 176.20281863212585
2020-01-13 07:47:49.879726 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.107661
Z variance train             0.015274493
KL Divergence                37.65572
KL Loss                      3.765572
QF Loss                      181.3273
VF Loss                      89.70382
Policy Loss                  -914.85864
Q Predictions Mean           906.50146
Q Predictions Std            924.31604
Q Predictions Max            2795.6897
Q Predictions Min            -22.110786
V Predictions Mean           912.4735
V Predictions Std            922.78845
V Predictions Max            2783.6497
V Predictions Min            1.1185127
Log Pis Mean                 -0.77952594
Log Pis Std                  4.045228
Log Pis Max                  14.842594
Log Pis Min                  -9.918242
Policy mu Mean               0.037626714
Policy mu Std                0.8306497
Policy mu Max                2.819519
Policy mu Min                -2.546375
Policy log std Mean          -0.4650805
Policy log std Std           0.22881065
Policy log std Max           -0.12167463
Policy log std Min           -2.2754438
Z mean eval                  2.0753872
Z variance eval              0.040185064
total_rewards                [5803.57520441 5966.75826069 5956.83319298 5880.86742794 6059.51509992
 5855.99083142 6183.19682482 6104.92850497 5837.64320624 6003.51029711]
total_rewards_mean           5965.28188504977
total_rewards_std            117.86177821871243
total_rewards_max            6183.196824818563
total_rewards_min            5803.575204410383
Number of train steps total  316000
Number of env steps total    950000
Number of rollouts total     0
Train Time (s)               137.6191544481553
(Previous) Eval Time (s)     28.547579146921635
Sample Time (s)              10.003092363476753
Epoch Time (s)               176.1698259585537
Total Train Time (s)         14366.656896264758
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:50:46.133109 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #78 | Epoch Duration: 176.25318360328674
2020-01-13 07:50:46.133354 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.075023
Z variance train             0.04035277
KL Divergence                34.725437
KL Loss                      3.4725437
QF Loss                      256.9309
VF Loss                      139.7943
Policy Loss                  -858.60016
Q Predictions Mean           856.4757
Q Predictions Std            913.4222
Q Predictions Max            2845.8606
Q Predictions Min            -5.727179
V Predictions Mean           863.5735
V Predictions Std            911.33044
V Predictions Max            2831.8708
V Predictions Min            -10.161127
Log Pis Mean                 -1.1151247
Log Pis Std                  3.5725782
Log Pis Max                  11.242191
Log Pis Min                  -6.9923887
Policy mu Mean               -0.016199965
Policy mu Std                0.77404904
Policy mu Max                2.9752784
Policy mu Min                -2.544873
Policy log std Mean          -0.46372736
Policy log std Std           0.2517232
Policy log std Max           -0.11322236
Policy log std Min           -2.2262397
Z mean eval                  2.1234295
Z variance eval              0.028355395
total_rewards                [6402.81937198 6947.56546644 7035.77767899 6706.96743263 6625.81093428
 7040.94206924 6974.44433398 6872.53979186 6689.49328334 6702.60963842]
total_rewards_mean           6799.897000116094
total_rewards_std            197.37235366918458
total_rewards_max            7040.942069237025
total_rewards_min            6402.819371982405
Number of train steps total  320000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               143.87163301184773
(Previous) Eval Time (s)     31.03043479193002
Sample Time (s)              9.789462517015636
Epoch Time (s)               184.6915303207934
Total Train Time (s)         14551.705746451393
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:53:51.184632 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #79 | Epoch Duration: 185.051020860672
2020-01-13 07:53:51.184981 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1226258
Z variance train             0.028382689
KL Divergence                35.845955
KL Loss                      3.5845954
QF Loss                      190.48853
VF Loss                      48.90324
Policy Loss                  -894.4213
Q Predictions Mean           892.14014
Q Predictions Std            914.0419
Q Predictions Max            2864.5193
Q Predictions Min            -22.006582
V Predictions Mean           893.37585
V Predictions Std            912.39575
V Predictions Max            2847.3186
V Predictions Min            -19.865715
Log Pis Mean                 -1.010568
Log Pis Std                  3.3458807
Log Pis Max                  12.43478
Log Pis Min                  -6.000437
Policy mu Mean               0.014524044
Policy mu Std                0.7957377
Policy mu Max                2.4158564
Policy mu Min                -2.430751
Policy log std Mean          -0.47428903
Policy log std Std           0.21037886
Policy log std Max           0.10106343
Policy log std Min           -1.7857852
Z mean eval                  2.1216083
Z variance eval              0.017464476
total_rewards                [6602.20704266 6572.65354004 6762.0458665  6566.67012461 6207.67577564
 6590.84794882 6765.7775252  6923.97348763 6727.19029189 6546.1354046 ]
total_rewards_mean           6626.517700757911
total_rewards_std            180.72420684969654
total_rewards_max            6923.973487626854
total_rewards_min            6207.675775642939
Number of train steps total  324000
Number of env steps total    974000
Number of rollouts total     0
Train Time (s)               146.3639643918723
(Previous) Eval Time (s)     29.45736665278673
Sample Time (s)              9.355880638118833
Epoch Time (s)               185.17721168277785
Total Train Time (s)         14736.965306313708
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:56:56.445137 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #80 | Epoch Duration: 185.25994229316711
2020-01-13 07:56:56.445338 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1216648
Z variance train             0.017448038
KL Divergence                36.828815
KL Loss                      3.6828816
QF Loss                      344.6653
VF Loss                      71.737724
Policy Loss                  -871.1462
Q Predictions Mean           862.0591
Q Predictions Std            887.08295
Q Predictions Max            2811.7422
Q Predictions Min            -16.467
V Predictions Mean           869.47327
V Predictions Std            892.29266
V Predictions Max            2808.5542
V Predictions Min            -2.2316785
Log Pis Mean                 -1.19888
Log Pis Std                  3.7101643
Log Pis Max                  22.482307
Log Pis Min                  -8.784005
Policy mu Mean               0.03867738
Policy mu Std                0.7993944
Policy mu Max                3.6879964
Policy mu Min                -3.1515384
Policy log std Mean          -0.4596672
Policy log std Std           0.23741831
Policy log std Max           -0.07823227
Policy log std Min           -2.0651965
Z mean eval                  2.1415844
Z variance eval              0.020922218
total_rewards                [6996.4425789  6949.29640345 6723.05136449 6953.84236433 7014.61045066
 6969.66433945 6795.00308255 6810.96162126 7077.3095489  6902.5360303 ]
total_rewards_mean           6919.271778427581
total_rewards_std            105.17275337230262
total_rewards_max            7077.30954889602
total_rewards_min            6723.051364487596
Number of train steps total  328000
Number of env steps total    986000
Number of rollouts total     0
Train Time (s)               146.5783069645986
(Previous) Eval Time (s)     29.705738943070173
Sample Time (s)              10.142988996580243
Epoch Time (s)               186.427034904249
Total Train Time (s)         14923.472778168973
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:00:02.955334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #81 | Epoch Duration: 186.5098376274109
2020-01-13 08:00:02.955559 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1385903
Z variance train             0.020840166
KL Divergence                38.191593
KL Loss                      3.8191593
QF Loss                      301.6637
VF Loss                      201.78592
Policy Loss                  -938.6257
Q Predictions Mean           933.34937
Q Predictions Std            965.8454
Q Predictions Max            2803.867
Q Predictions Min            212.04608
V Predictions Mean           943.14844
V Predictions Std            973.2076
V Predictions Max            2817.1025
V Predictions Min            224.27473
Log Pis Mean                 -0.7894893
Log Pis Std                  3.7080758
Log Pis Max                  17.465088
Log Pis Min                  -7.4430103
Policy mu Mean               -0.08491242
Policy mu Std                0.815066
Policy mu Max                3.6227384
Policy mu Min                -3.5572686
Policy log std Mean          -0.48050177
Policy log std Std           0.23806494
Policy log std Max           -0.16177145
Policy log std Min           -2.2461364
Z mean eval                  2.1197398
Z variance eval              0.012035527
total_rewards                [6827.15052324 6663.65946145 6977.37095269 6740.52078231 6735.57066738
 6633.30794612 6769.89049036 6471.24163853 6632.44932568 6753.43980066]
total_rewards_mean           6720.460158842526
total_rewards_std            127.36772174006553
total_rewards_max            6977.370952693733
total_rewards_min            6471.241638526632
Number of train steps total  332000
Number of env steps total    998000
Number of rollouts total     0
Train Time (s)               147.92764376895502
(Previous) Eval Time (s)     29.64452743716538
Sample Time (s)              9.964282738044858
Epoch Time (s)               187.53645394416526
Total Train Time (s)         15111.094883355778
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:03:10.578939 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #82 | Epoch Duration: 187.6232078075409
2020-01-13 08:03:10.579139 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1182537
Z variance train             0.011981698
KL Divergence                39.790783
KL Loss                      3.9790783
QF Loss                      160.92587
VF Loss                      68.45426
Policy Loss                  -697.1734
Q Predictions Mean           689.7821
Q Predictions Std            778.19977
Q Predictions Max            2776.0764
Q Predictions Min            -9.571152
V Predictions Mean           697.35864
V Predictions Std            781.98096
V Predictions Max            2760.876
V Predictions Min            1.2414672
Log Pis Mean                 -1.5832491
Log Pis Std                  3.035222
Log Pis Max                  11.2933035
Log Pis Min                  -8.788147
Policy mu Mean               0.014168147
Policy mu Std                0.7278374
Policy mu Max                2.8008378
Policy mu Min                -2.4588666
Policy log std Mean          -0.44744968
Policy log std Std           0.21207964
Policy log std Max           -0.16043182
Policy log std Min           -2.0622003
Z mean eval                  2.109975
Z variance eval              0.010242576
total_rewards                [5734.20343909 5474.66967979 6420.02040381 6159.00268084 5525.19729515
 6159.72393784 5470.41125458 5802.34217127 6103.89223156 6262.39720046]
total_rewards_mean           5911.186029437973
total_rewards_std            334.5994057918568
total_rewards_max            6420.020403807021
total_rewards_min            5470.411254575778
Number of train steps total  336000
Number of env steps total    1010000
Number of rollouts total     0
Train Time (s)               146.25258690817282
(Previous) Eval Time (s)     28.68271677568555
Sample Time (s)              10.177431489806622
Epoch Time (s)               185.112735173665
Total Train Time (s)         15296.286340100225
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:06:15.772033 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #83 | Epoch Duration: 185.19273400306702
2020-01-13 08:06:15.772227 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1084397
Z variance train             0.010212548
KL Divergence                40.43563
KL Loss                      4.0435634
QF Loss                      897.2361
VF Loss                      70.74095
Policy Loss                  -867.486
Q Predictions Mean           860.54944
Q Predictions Std            898.9669
Q Predictions Max            2871.3274
Q Predictions Min            5.695102
V Predictions Mean           869.2261
V Predictions Std            899.2529
V Predictions Max            2865.252
V Predictions Min            1.4953486
Log Pis Mean                 -1.0312836
Log Pis Std                  3.6679192
Log Pis Max                  18.604095
Log Pis Min                  -8.241976
Policy mu Mean               -0.048197523
Policy mu Std                0.8103704
Policy mu Max                3.876639
Policy mu Min                -4.00885
Policy log std Mean          -0.4684472
Policy log std Std           0.22988404
Policy log std Max           -0.14874804
Policy log std Min           -2.1250706
Z mean eval                  2.1369581
Z variance eval              0.016321678
total_rewards                [6836.21575625 6880.85842947 7015.23551172 6823.89357003 6696.15423733
 6946.51118131 7275.34876948 7014.45433019 7012.48330028 7010.96090499]
total_rewards_mean           6951.211599104031
total_rewards_std            148.306323250736
total_rewards_max            7275.348769477548
total_rewards_min            6696.154237328006
Number of train steps total  340000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               137.40736260218546
(Previous) Eval Time (s)     28.615891305729747
Sample Time (s)              9.719627189449966
Epoch Time (s)               175.74288109736517
Total Train Time (s)         15472.110885482747
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:09:11.598192 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #84 | Epoch Duration: 175.82582998275757
2020-01-13 08:09:11.598371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1338294
Z variance train             0.016360752
KL Divergence                38.32895
KL Loss                      3.832895
QF Loss                      1862.0471
VF Loss                      262.69125
Policy Loss                  -923.9741
Q Predictions Mean           915.4725
Q Predictions Std            921.4901
Q Predictions Max            2809.2964
Q Predictions Min            -10.709495
V Predictions Mean           927.8811
V Predictions Std            924.6102
V Predictions Max            2818.6338
V Predictions Min            2.1767378
Log Pis Mean                 -0.5816431
Log Pis Std                  3.9373446
Log Pis Max                  20.615225
Log Pis Min                  -6.5302267
Policy mu Mean               -7.990593e-05
Policy mu Std                0.8264314
Policy mu Max                2.7736273
Policy mu Min                -3.870148
Policy log std Mean          -0.48921403
Policy log std Std           0.23188251
Policy log std Max           -0.13026576
Policy log std Min           -2.2231758
Z mean eval                  2.168918
Z variance eval              0.013807083
total_rewards                [6978.07765734 6776.51978848 6795.56337341 6863.01494642 6860.04579974
 6811.89162482 6639.8372295  6697.84733067 7049.4402147  6822.05698843]
total_rewards_mean           6829.429495349478
total_rewards_std            114.07616258427103
total_rewards_max            7049.440214699176
total_rewards_min            6639.837229500642
Number of train steps total  344000
Number of env steps total    1034000
Number of rollouts total     0
Train Time (s)               137.90662700822577
(Previous) Eval Time (s)     28.86975440196693
Sample Time (s)              9.748807264026254
Epoch Time (s)               176.52518867421895
Total Train Time (s)         15648.717366035096
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:12:08.208135 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #85 | Epoch Duration: 176.6096019744873
2020-01-13 08:12:08.208437 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.171674
Z variance train             0.013835764
KL Divergence                39.17444
KL Loss                      3.917444
QF Loss                      436.05994
VF Loss                      81.8331
Policy Loss                  -740.81586
Q Predictions Mean           734.6778
Q Predictions Std            863.06635
Q Predictions Max            2844.4124
Q Predictions Min            1.6617168
V Predictions Mean           741.424
V Predictions Std            861.75006
V Predictions Max            2823.7427
V Predictions Min            10.274017
Log Pis Mean                 -1.4432409
Log Pis Std                  3.1989067
Log Pis Max                  13.319553
Log Pis Min                  -7.650645
Policy mu Mean               -0.012385174
Policy mu Std                0.73886806
Policy mu Max                2.9070382
Policy mu Min                -2.585845
Policy log std Mean          -0.44474602
Policy log std Std           0.22066075
Policy log std Max           -0.154584
Policy log std Min           -2.2033162
Z mean eval                  2.1572373
Z variance eval              0.011007262
total_rewards                [4887.73730186 4793.55914394 4557.09011792 5575.98292293 5189.97839945
 4662.33818539 4782.8255905  5174.67742085 1149.41279729 5245.43552819]
total_rewards_mean           4601.903740831568
total_rewards_std            1187.9976657783843
total_rewards_max            5575.982922927902
total_rewards_min            1149.4127972865256
Number of train steps total  348000
Number of env steps total    1046000
Number of rollouts total     0
Train Time (s)               144.6358111090958
(Previous) Eval Time (s)     28.72180488705635
Sample Time (s)              9.555418741423637
Epoch Time (s)               182.9130347375758
Total Train Time (s)         15831.710077526513
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:15:11.201313 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #86 | Epoch Duration: 182.992693901062
2020-01-13 08:15:11.201467 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #86 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1598763
Z variance train             0.010987815
KL Divergence                39.18953
KL Loss                      3.918953
QF Loss                      326.682
VF Loss                      109.606705
Policy Loss                  -826.69867
Q Predictions Mean           817.6255
Q Predictions Std            884.91547
Q Predictions Max            2856.5112
Q Predictions Min            -13.055023
V Predictions Mean           821.452
V Predictions Std            885.272
V Predictions Max            2839.4236
V Predictions Min            1.7300992
Log Pis Mean                 -1.1384351
Log Pis Std                  3.1626904
Log Pis Max                  11.743075
Log Pis Min                  -6.2654033
Policy mu Mean               -0.07074263
Policy mu Std                0.7696405
Policy mu Max                2.648986
Policy mu Min                -2.3790786
Policy log std Mean          -0.46211067
Policy log std Std           0.20692372
Policy log std Max           -0.17911112
Policy log std Min           -2.0891018
Z mean eval                  2.1379528
Z variance eval              0.017911403
total_rewards                [6310.76729872 5924.17167274 5544.07142647 5983.89202361 5920.3459984
 5992.03628072 5936.79647409 6044.83854255 5853.810492   6533.73788779]
total_rewards_mean           6004.446809708288
total_rewards_std            250.78271582436304
total_rewards_max            6533.737887790943
total_rewards_min            5544.071426468975
Number of train steps total  352000
Number of env steps total    1058000
Number of rollouts total     0
Train Time (s)               146.68573481589556
(Previous) Eval Time (s)     30.516102810855955
Sample Time (s)              10.559965161141008
Epoch Time (s)               187.76180278789252
Total Train Time (s)         16019.561457824428
Epoch                        87
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:18:19.055366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #87 | Epoch Duration: 187.85377311706543
2020-01-13 08:18:19.055597 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1386607
Z variance train             0.017831381
KL Divergence                37.763424
KL Loss                      3.7763424
QF Loss                      282.00436
VF Loss                      127.74231
Policy Loss                  -844.9407
Q Predictions Mean           837.93176
Q Predictions Std            917.1455
Q Predictions Max            2848.1787
Q Predictions Min            7.4304175
V Predictions Mean           842.7115
V Predictions Std            915.7265
V Predictions Max            2830.4111
V Predictions Min            5.429343
Log Pis Mean                 -0.7708367
Log Pis Std                  3.9747198
Log Pis Max                  17.395409
Log Pis Min                  -7.302376
Policy mu Mean               0.011534912
Policy mu Std                0.83221835
Policy mu Max                3.2145493
Policy mu Min                -3.407707
Policy log std Mean          -0.48480198
Policy log std Std           0.24387099
Policy log std Max           -0.1726312
Policy log std Min           -2.409352
Z mean eval                  2.1508892
Z variance eval              0.013806468
total_rewards                [6925.65874547 7364.69096567 6988.98311765 6945.28778225 7352.53377367
 6958.50251423 7011.55919971 7056.43211887 7142.99352774 7123.93733755]
total_rewards_mean           7087.05790828099
total_rewards_std            151.97961762894417
total_rewards_max            7364.690965667184
total_rewards_min            6925.658745467878
Number of train steps total  356000
Number of env steps total    1070000
Number of rollouts total     0
Train Time (s)               146.8011883702129
(Previous) Eval Time (s)     30.274173467885703
Sample Time (s)              9.494975087232888
Epoch Time (s)               186.5703369253315
Total Train Time (s)         16206.212696733419
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:21:25.709067 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #88 | Epoch Duration: 186.65330338478088
2020-01-13 08:21:25.709283 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.151824
Z variance train             0.013827667
KL Divergence                39.204407
KL Loss                      3.9204407
QF Loss                      645.071
VF Loss                      201.73352
Policy Loss                  -786.49243
Q Predictions Mean           774.5729
Q Predictions Std            891.9523
Q Predictions Max            2786.0803
Q Predictions Min            0.15568978
V Predictions Mean           777.1234
V Predictions Std            889.7269
V Predictions Max            2774.6106
V Predictions Min            9.530337
Log Pis Mean                 -1.0299344
Log Pis Std                  3.657962
Log Pis Max                  13.3240185
Log Pis Min                  -7.6611466
Policy mu Mean               -0.008356319
Policy mu Std                0.79738975
Policy mu Max                2.9893312
Policy mu Min                -3.5325544
Policy log std Mean          -0.46186915
Policy log std Std           0.2177811
Policy log std Max           -0.099464804
Policy log std Min           -1.8418865
Z mean eval                  2.16768
Z variance eval              0.0068011954
total_rewards                [6960.83601041 6937.72564689 7043.93048779 6986.43408723 7131.79656546
 6996.45175634 6873.46045076 7044.20799741 6906.59396595 6798.60198155]
total_rewards_mean           6968.003894979532
total_rewards_std            90.51171515686276
total_rewards_max            7131.7965654612135
total_rewards_min            6798.601981554777
Number of train steps total  360000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               148.12755434261635
(Previous) Eval Time (s)     30.120596444234252
Sample Time (s)              10.270863976795226
Epoch Time (s)               188.51901476364583
Total Train Time (s)         16394.840090105776
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:24:34.338527 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #89 | Epoch Duration: 188.62905144691467
2020-01-13 08:24:34.338817 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #89 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1668532
Z variance train             0.0068083317
KL Divergence                41.099834
KL Loss                      4.1099834
QF Loss                      364.66406
VF Loss                      285.66946
Policy Loss                  -816.9397
Q Predictions Mean           809.7075
Q Predictions Std            906.44293
Q Predictions Max            2863.0542
Q Predictions Min            -6.3987455
V Predictions Mean           820.44995
V Predictions Std            912.0888
V Predictions Max            2884.876
V Predictions Min            -0.10938877
Log Pis Mean                 -1.0049229
Log Pis Std                  3.310014
Log Pis Max                  13.308472
Log Pis Min                  -7.98476
Policy mu Mean               0.01475931
Policy mu Std                0.7848655
Policy mu Max                3.3948786
Policy mu Min                -3.490846
Policy log std Mean          -0.46094832
Policy log std Std           0.21848713
Policy log std Max           -0.1586433
Policy log std Min           -2.2828865
Z mean eval                  2.1345382
Z variance eval              0.012528298
total_rewards                [7085.42798699 7103.37531195 7329.76854166 6952.98157225 7148.3228971
 7097.27037763 7040.95037432 7196.7974443  7202.05135806 7275.11130073]
total_rewards_mean           7143.205716499884
total_rewards_std            105.94432585538485
total_rewards_max            7329.7685416585355
total_rewards_min            6952.981572253309
Number of train steps total  364000
Number of env steps total    1094000
Number of rollouts total     0
Train Time (s)               144.69379201019183
(Previous) Eval Time (s)     29.30580636765808
Sample Time (s)              10.274700044188648
Epoch Time (s)               184.27429842203856
Total Train Time (s)         16579.195167525206
Epoch                        90
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:27:38.695197 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #90 | Epoch Duration: 184.35618019104004
2020-01-13 08:27:38.695424 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.138411
Z variance train             0.012501249
KL Divergence                40.487377
KL Loss                      4.048738
QF Loss                      276.9211
VF Loss                      87.644966
Policy Loss                  -804.57904
Q Predictions Mean           802.58093
Q Predictions Std            902.3791
Q Predictions Max            2856.3003
Q Predictions Min            -19.35761
V Predictions Mean           804.3336
V Predictions Std            901.41895
V Predictions Max            2836.0928
V Predictions Min            -13.099412
Log Pis Mean                 -0.9297917
Log Pis Std                  3.389282
Log Pis Max                  20.230879
Log Pis Min                  -7.311487
Policy mu Mean               -0.042041466
Policy mu Std                0.80900997
Policy mu Max                3.7501395
Policy mu Min                -3.701105
Policy log std Mean          -0.47735092
Policy log std Std           0.22686651
Policy log std Max           -0.13402021
Policy log std Min           -2.250983
Z mean eval                  2.1857212
Z variance eval              0.055604927
total_rewards                [6937.5337121  6875.66141863 7020.71995699 6930.23561153 6983.42251508
 7111.37589811 7279.01367092 7171.01548756 7119.39004132 6955.89643425]
total_rewards_mean           7038.426474648465
total_rewards_std            120.77499850087408
total_rewards_max            7279.0136709210265
total_rewards_min            6875.661418628235
Number of train steps total  368000
Number of env steps total    1106000
Number of rollouts total     0
Train Time (s)               137.98790862364694
(Previous) Eval Time (s)     29.742380713112652
Sample Time (s)              9.477267762646079
Epoch Time (s)               177.20755709940568
Total Train Time (s)         16756.48143596109
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:30:35.983089 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #91 | Epoch Duration: 177.28750324249268
2020-01-13 08:30:35.983302 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1846573
Z variance train             0.055136513
KL Divergence                38.37542
KL Loss                      3.837542
QF Loss                      135.26628
VF Loss                      38.963406
Policy Loss                  -658.5161
Q Predictions Mean           651.61395
Q Predictions Std            789.0112
Q Predictions Max            2965.503
Q Predictions Min            -9.541314
V Predictions Mean           658.6643
V Predictions Std            791.47595
V Predictions Max            2960.3972
V Predictions Min            -5.4580736
Log Pis Mean                 -1.1080592
Log Pis Std                  3.7707863
Log Pis Max                  13.166012
Log Pis Min                  -7.4634247
Policy mu Mean               0.02935552
Policy mu Std                0.7731495
Policy mu Max                2.8673892
Policy mu Min                -2.4333496
Policy log std Mean          -0.45267895
Policy log std Std           0.20616364
Policy log std Max           -0.15514876
Policy log std Min           -2.3126714
Z mean eval                  2.191526
Z variance eval              0.022609407
total_rewards                [7141.90851416 7259.24869322 7355.56017724 7160.39183817 7209.98816067
 7012.83256864 7026.38848544 7076.46386673 7509.79976675 7177.27503462]
total_rewards_mean           7192.985710564292
total_rewards_std            144.6328681522298
total_rewards_max            7509.799766751789
total_rewards_min            7012.832568635219
Number of train steps total  372000
Number of env steps total    1118000
Number of rollouts total     0
Train Time (s)               137.29667988512665
(Previous) Eval Time (s)     29.788107856176794
Sample Time (s)              9.44582693791017
Epoch Time (s)               176.5306146792136
Total Train Time (s)         16933.117551984265
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:33:32.621171 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #92 | Epoch Duration: 176.6377203464508
2020-01-13 08:33:32.621373 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #92 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1919131
Z variance train             0.022719514
KL Divergence                38.569588
KL Loss                      3.8569589
QF Loss                      289.72598
VF Loss                      67.08942
Policy Loss                  -780.08685
Q Predictions Mean           776.72253
Q Predictions Std            904.9005
Q Predictions Max            3008.444
Q Predictions Min            -20.92029
V Predictions Mean           775.7489
V Predictions Std            904.14465
V Predictions Max            3002.8552
V Predictions Min            -24.526348
Log Pis Mean                 -1.1202036
Log Pis Std                  3.6495695
Log Pis Max                  13.801452
Log Pis Min                  -6.590475
Policy mu Mean               0.013944048
Policy mu Std                0.7895491
Policy mu Max                2.9705224
Policy mu Min                -3.3228776
Policy log std Mean          -0.46897343
Policy log std Std           0.22618952
Policy log std Max           -0.09771299
Policy log std Min           -2.18535
Z mean eval                  2.153774
Z variance eval              0.014937038
total_rewards                [7195.55806288 7513.21930672 7336.97534537 7310.26055201 7301.5804041
 7322.92983398 7404.19521699 7372.29985199 7554.05333195 7356.3562823 ]
total_rewards_mean           7366.742818828321
total_rewards_std            98.80704441526524
total_rewards_max            7554.053331948682
total_rewards_min            7195.558062876313
Number of train steps total  376000
Number of env steps total    1130000
Number of rollouts total     0
Train Time (s)               145.7833464546129
(Previous) Eval Time (s)     31.05979442410171
Sample Time (s)              10.034471673890948
Epoch Time (s)               186.87761255260557
Total Train Time (s)         17120.077132986393
Epoch                        93
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:36:39.582730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #93 | Epoch Duration: 186.96121168136597
2020-01-13 08:36:39.582945 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #93 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1531005
Z variance train             0.014880342
KL Divergence                39.65573
KL Loss                      3.965573
QF Loss                      1097.2878
VF Loss                      159.76454
Policy Loss                  -815.99976
Q Predictions Mean           810.032
Q Predictions Std            898.5083
Q Predictions Max            2979.1936
Q Predictions Min            246.65099
V Predictions Mean           822.1813
V Predictions Std            900.81506
V Predictions Max            2956.529
V Predictions Min            250.95323
Log Pis Mean                 -1.0668304
Log Pis Std                  3.2828248
Log Pis Max                  14.348874
Log Pis Min                  -6.2275834
Policy mu Mean               -0.050406378
Policy mu Std                0.79259175
Policy mu Max                3.0481238
Policy mu Min                -2.393388
Policy log std Mean          -0.47353974
Policy log std Std           0.2171418
Policy log std Max           -0.175056
Policy log std Min           -2.2492409
Z mean eval                  2.1828783
Z variance eval              0.015224342
total_rewards                [6977.23364124 7181.35101805 7356.37125076 7239.29318885 7271.9943446
 7087.59131892 7053.01286546 7156.17463574 7165.75533497 7306.6888123 ]
total_rewards_mean           7179.546641089219
total_rewards_std            112.10938240522542
total_rewards_max            7356.3712507556365
total_rewards_min            6977.233641235661
Number of train steps total  380000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               146.34396222420037
(Previous) Eval Time (s)     28.854121081065387
Sample Time (s)              10.28339993627742
Epoch Time (s)               185.48148324154317
Total Train Time (s)         17305.63843659032
Epoch                        94
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:39:45.146658 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #94 | Epoch Duration: 185.56355500221252
2020-01-13 08:39:45.146877 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1849082
Z variance train             0.015224462
KL Divergence                40.93875
KL Loss                      4.0938754
QF Loss                      1050.1091
VF Loss                      68.793655
Policy Loss                  -764.3312
Q Predictions Mean           760.76514
Q Predictions Std            872.5721
Q Predictions Max            2924.3645
Q Predictions Min            -20.299065
V Predictions Mean           766.9523
V Predictions Std            870.5845
V Predictions Max            2905.0059
V Predictions Min            -21.862305
Log Pis Mean                 -1.1259516
Log Pis Std                  3.9065607
Log Pis Max                  21.30284
Log Pis Min                  -7.9842544
Policy mu Mean               -0.042863205
Policy mu Std                0.7734029
Policy mu Max                3.656938
Policy mu Min                -3.4012666
Policy log std Mean          -0.4516324
Policy log std Std           0.22190492
Policy log std Max           -0.109794065
Policy log std Min           -2.1031191
Z mean eval                  2.1902707
Z variance eval              0.017510008
total_rewards                [7150.85700833 7223.44901481 7353.49370356 7368.3566138  7212.79850984
 6975.43559089 7210.64991407 7231.43332126 7031.06499198 7226.80244959]
total_rewards_mean           7198.434111812911
total_rewards_std            116.53175301025975
total_rewards_max            7368.356613803927
total_rewards_min            6975.435590891781
Number of train steps total  384000
Number of env steps total    1154000
Number of rollouts total     0
Train Time (s)               145.83098520012572
(Previous) Eval Time (s)     30.52102330699563
Sample Time (s)              10.298401455394924
Epoch Time (s)               186.65040996251628
Total Train Time (s)         17492.38800918497
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:42:51.898504 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #95 | Epoch Duration: 186.75145483016968
2020-01-13 08:42:51.898741 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1905258
Z variance train             0.017493378
KL Divergence                39.696484
KL Loss                      3.9696484
QF Loss                      156.6101
VF Loss                      52.827465
Policy Loss                  -777.69226
Q Predictions Mean           773.507
Q Predictions Std            867.2593
Q Predictions Max            2933.1978
Q Predictions Min            -9.068343
V Predictions Mean           773.50385
V Predictions Std            866.9157
V Predictions Max            2899.343
V Predictions Min            -15.252382
Log Pis Mean                 -1.4247267
Log Pis Std                  3.4304366
Log Pis Max                  15.536846
Log Pis Min                  -8.037222
Policy mu Mean               -0.061797272
Policy mu Std                0.7626139
Policy mu Max                2.9012685
Policy mu Min                -3.2370641
Policy log std Mean          -0.4534743
Policy log std Std           0.2156979
Policy log std Max           -0.1475393
Policy log std Min           -2.1520262
Z mean eval                  2.1863163
Z variance eval              0.02975117
total_rewards                [6917.15598702 7339.34704826 7360.86374627 7325.37573188 7216.73673882
 7283.29814052 7255.77600022 7234.91442383 7250.46871913 7309.88501204]
total_rewards_mean           7249.382154799186
total_rewards_std            119.4985638972134
total_rewards_max            7360.863746273129
total_rewards_min            6917.155987017881
Number of train steps total  388000
Number of env steps total    1166000
Number of rollouts total     0
Train Time (s)               147.54212893825024
(Previous) Eval Time (s)     29.38499680440873
Sample Time (s)              10.177734774071723
Epoch Time (s)               187.1048605167307
Total Train Time (s)         17679.573612894863
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:45:59.086108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #96 | Epoch Duration: 187.18721556663513
2020-01-13 08:45:59.086304 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.191056
Z variance train             0.029570187
KL Divergence                38.86869
KL Loss                      3.8868692
QF Loss                      1001.3581
VF Loss                      91.10362
Policy Loss                  -885.7645
Q Predictions Mean           881.67163
Q Predictions Std            949.9729
Q Predictions Max            2967.6536
Q Predictions Min            -24.541798
V Predictions Mean           881.58887
V Predictions Std            952.91656
V Predictions Max            2952.1628
V Predictions Min            -15.492004
Log Pis Mean                 -0.71399426
Log Pis Std                  3.6957922
Log Pis Max                  15.342832
Log Pis Min                  -8.227686
Policy mu Mean               0.0024136566
Policy mu Std                0.83975935
Policy mu Max                3.410483
Policy mu Min                -3.2070956
Policy log std Mean          -0.48269382
Policy log std Std           0.22257803
Policy log std Max           -0.12552464
Policy log std Min           -2.141197
Z mean eval                  2.1938977
Z variance eval              0.02061842
total_rewards                [7143.1566521  7337.93429805 7268.91715046 7242.4762717  7111.44202929
 7222.76768273 7211.34613492 7252.90639142 7366.48184157 7294.71389353]
total_rewards_mean           7245.214234576893
total_rewards_std            75.06210879307986
total_rewards_max            7366.481841574325
total_rewards_min            7111.442029289855
Number of train steps total  392000
Number of env steps total    1178000
Number of rollouts total     0
Train Time (s)               143.51547492016107
(Previous) Eval Time (s)     29.810646147001535
Sample Time (s)              9.7128892573528
Epoch Time (s)               183.0390103245154
Total Train Time (s)         17862.715399510693
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:49:02.229747 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #97 | Epoch Duration: 183.1432933807373
2020-01-13 08:49:02.229957 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.196473
Z variance train             0.020694159
KL Divergence                39.26442
KL Loss                      3.926442
QF Loss                      114.76902
VF Loss                      71.83162
Policy Loss                  -820.6816
Q Predictions Mean           817.3686
Q Predictions Std            948.8011
Q Predictions Max            3122.1255
Q Predictions Min            -12.958345
V Predictions Mean           815.02216
V Predictions Std            947.7155
V Predictions Max            3081.0837
V Predictions Min            -7.743105
Log Pis Mean                 -1.3031343
Log Pis Std                  3.3698668
Log Pis Max                  13.028511
Log Pis Min                  -6.842313
Policy mu Mean               -0.008379918
Policy mu Std                0.7837248
Policy mu Max                2.6699462
Policy mu Min                -2.710268
Policy log std Mean          -0.4662417
Policy log std Std           0.22629222
Policy log std Max           -0.09551525
Policy log std Min           -2.4126985
Z mean eval                  2.1930175
Z variance eval              0.053611856
total_rewards                [6409.48859902 6684.45320408 6717.42589068 6594.20266426 6623.21176915
 6459.16858691 6459.78424338 6360.74939188 6427.58725551 6640.33405667]
total_rewards_mean           6537.640566154243
total_rewards_std            121.2390086597826
total_rewards_max            6717.425890677888
total_rewards_min            6360.7493918813525
Number of train steps total  396000
Number of env steps total    1190000
Number of rollouts total     0
Train Time (s)               137.92322055995464
(Previous) Eval Time (s)     29.46925922203809
Sample Time (s)              9.720700500532985
Epoch Time (s)               177.11318028252572
Total Train Time (s)         18039.91165467864
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:51:59.428000 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #98 | Epoch Duration: 177.19789338111877
2020-01-13 08:51:59.428194 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2014155
Z variance train             0.05348625
KL Divergence                38.211323
KL Loss                      3.8211324
QF Loss                      1277.3934
VF Loss                      255.74005
Policy Loss                  -826.03546
Q Predictions Mean           822.6831
Q Predictions Std            932.7851
Q Predictions Max            2987.728
Q Predictions Min            -6.812786
V Predictions Mean           819.1771
V Predictions Std            929.5567
V Predictions Max            2978.907
V Predictions Min            -16.381464
Log Pis Mean                 -0.36795303
Log Pis Std                  4.2309384
Log Pis Max                  15.991217
Log Pis Min                  -5.545556
Policy mu Mean               0.033419076
Policy mu Std                0.86983913
Policy mu Max                3.3337493
Policy mu Min                -2.9415267
Policy log std Mean          -0.45215666
Policy log std Std           0.2330683
Policy log std Max           -0.14094937
Policy log std Min           -2.2541516
Z mean eval                  2.1529553
Z variance eval              0.03471035
total_rewards                [7426.27877432 7244.27957433 7574.11292395 7508.52541491 7439.46392018
 7818.91212769 7282.59658782 7580.87970493 7454.28607947 7374.9656393 ]
total_rewards_mean           7470.430074690999
total_rewards_std            156.38032002708817
total_rewards_max            7818.9121276938595
total_rewards_min            7244.279574333321
Number of train steps total  400000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               137.1593086067587
(Previous) Eval Time (s)     28.355185375083238
Sample Time (s)              9.764369353652
Epoch Time (s)               175.27886333549395
Total Train Time (s)         18215.35665887827
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:54:54.875413 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #99 | Epoch Duration: 175.44705152511597
2020-01-13 08:54:54.875701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1502762
Z variance train             0.03484256
KL Divergence                37.893417
KL Loss                      3.7893417
QF Loss                      892.2882
VF Loss                      166.67255
Policy Loss                  -844.48065
Q Predictions Mean           841.2219
Q Predictions Std            959.17615
Q Predictions Max            2963.6938
Q Predictions Min            268.00235
V Predictions Mean           842.31116
V Predictions Std            959.70966
V Predictions Max            2966.2869
V Predictions Min            263.87488
Log Pis Mean                 -1.0378156
Log Pis Std                  3.358537
Log Pis Max                  10.517792
Log Pis Min                  -7.4165945
Policy mu Mean               0.040102523
Policy mu Std                0.82633674
Policy mu Max                2.9638283
Policy mu Min                -2.53134
Policy log std Mean          -0.47501302
Policy log std Std           0.22287256
Policy log std Max           -0.10600354
Policy log std Min           -1.9854656
Z mean eval                  2.183825
Z variance eval              0.022083445
total_rewards                [7388.64816447 7528.6378229  7563.24480917 7611.81243515 7414.80069125
 7446.62234939 7404.3221184  7657.03511448 7639.08140209 7583.15675635]
total_rewards_mean           7523.73616636388
total_rewards_std            97.09185821685243
total_rewards_max            7657.0351144837705
total_rewards_min            7388.648164466697
Number of train steps total  404000
Number of env steps total    1214000
Number of rollouts total     0
Train Time (s)               145.3866060078144
(Previous) Eval Time (s)     30.986039170995355
Sample Time (s)              8.417126053012908
Epoch Time (s)               184.78977123182267
Total Train Time (s)         18400.24097031355
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:57:59.761197 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #100 | Epoch Duration: 184.8853030204773
2020-01-13 08:57:59.761421 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1850836
Z variance train             0.022031613
KL Divergence                39.41105
KL Loss                      3.941105
QF Loss                      255.42673
VF Loss                      101.56149
Policy Loss                  -818.3731
Q Predictions Mean           818.40656
Q Predictions Std            946.024
Q Predictions Max            2954.5078
Q Predictions Min            -14.13798
V Predictions Mean           817.1457
V Predictions Std            945.81366
V Predictions Max            2933.232
V Predictions Min            -15.145747
Log Pis Mean                 -0.86168593
Log Pis Std                  3.4820106
Log Pis Max                  12.008327
Log Pis Min                  -6.654962
Policy mu Mean               0.043342784
Policy mu Std                0.8157829
Policy mu Max                2.5499098
Policy mu Min                -2.5734963
Policy log std Mean          -0.47231174
Policy log std Std           0.22794463
Policy log std Max           -0.16691908
Policy log std Min           -1.8895938
Z mean eval                  2.1929119
Z variance eval              0.025793135
total_rewards                [6944.02166907 7125.0191041  7103.17314255 7456.7855614  7041.91999455
 7006.2152085  7095.35148727 7195.84563464 7146.29641172 7125.54760612]
total_rewards_mean           7124.017581992664
total_rewards_std            130.63906954601964
total_rewards_max            7456.785561400118
total_rewards_min            6944.021669065823
Number of train steps total  408000
Number of env steps total    1226000
Number of rollouts total     0
Train Time (s)               146.32866420783103
(Previous) Eval Time (s)     30.182315890677273
Sample Time (s)              10.541102498304099
Epoch Time (s)               187.0520825968124
Total Train Time (s)         18587.382559809834
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:01:06.905678 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #101 | Epoch Duration: 187.14409041404724
2020-01-13 09:01:06.905937 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #101 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1919062
Z variance train             0.025789088
KL Divergence                40.347797
KL Loss                      4.03478
QF Loss                      243.56398
VF Loss                      36.777428
Policy Loss                  -815.84845
Q Predictions Mean           813.5459
Q Predictions Std            915.0013
Q Predictions Max            3044.2314
Q Predictions Min            -25.393776
V Predictions Mean           814.6905
V Predictions Std            918.3212
V Predictions Max            3056.6885
V Predictions Min            -21.18024
Log Pis Mean                 -0.7618853
Log Pis Std                  3.718732
Log Pis Max                  16.128119
Log Pis Min                  -8.5450325
Policy mu Mean               -0.08163043
Policy mu Std                0.8218756
Policy mu Max                3.1442566
Policy mu Min                -3.4204652
Policy log std Mean          -0.47068226
Policy log std Std           0.21736822
Policy log std Max           -0.15842035
Policy log std Min           -2.3529162
Z mean eval                  2.259646
Z variance eval              0.029343063
total_rewards                [7535.49672783 7688.76621612 7593.08880542 7561.48912045 7593.222375
 7518.95406399 7839.66860144 7494.65662088 7703.76887407 7473.3007837 ]
total_rewards_mean           7600.241218890429
total_rewards_std            107.49125567116444
total_rewards_max            7839.668601444021
total_rewards_min            7473.30078369943
Number of train steps total  412000
Number of env steps total    1238000
Number of rollouts total     0
Train Time (s)               145.55661057680845
(Previous) Eval Time (s)     29.352758693974465
Sample Time (s)              8.314478011336178
Epoch Time (s)               183.2238472821191
Total Train Time (s)         18770.68556644628
Epoch                        102
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:04:10.210157 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #102 | Epoch Duration: 183.3040497303009
2020-01-13 09:04:10.210342 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.263139
Z variance train             0.029141447
KL Divergence                40.79373
KL Loss                      4.0793734
QF Loss                      1691.0225
VF Loss                      71.98889
Policy Loss                  -778.4118
Q Predictions Mean           777.7716
Q Predictions Std            921.9068
Q Predictions Max            3140.9656
Q Predictions Min            -20.376003
V Predictions Mean           777.16113
V Predictions Std            916.06964
V Predictions Max            3104.9976
V Predictions Min            -21.230757
Log Pis Mean                 -0.9564443
Log Pis Std                  3.6666825
Log Pis Max                  20.13485
Log Pis Min                  -9.965647
Policy mu Mean               0.0312063
Policy mu Std                0.82235074
Policy mu Max                3.1271636
Policy mu Min                -2.614649
Policy log std Mean          -0.4719391
Policy log std Std           0.21007198
Policy log std Max           -0.06748626
Policy log std Min           -1.7785454
Z mean eval                  2.204769
Z variance eval              0.027566269
total_rewards                [7439.85330332 7398.2247965  7446.94849599 7455.28942532 7290.51625299
 7539.77896398 7297.89671372 7553.32379108 7318.09884571 7482.20213905]
total_rewards_mean           7422.213272765584
total_rewards_std            89.91180703216322
total_rewards_max            7553.323791075037
total_rewards_min            7290.516252994274
Number of train steps total  416000
Number of env steps total    1250000
Number of rollouts total     0
Train Time (s)               148.26390442810953
(Previous) Eval Time (s)     30.400100947823375
Sample Time (s)              10.245551762636751
Epoch Time (s)               188.90955713856965
Total Train Time (s)         18959.68132229848
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:07:19.209158 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #103 | Epoch Duration: 188.99865770339966
2020-01-13 09:07:19.209445 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1984546
Z variance train             0.027702082
KL Divergence                40.44167
KL Loss                      4.044167
QF Loss                      196.23099
VF Loss                      65.70462
Policy Loss                  -797.94714
Q Predictions Mean           795.8574
Q Predictions Std            914.2229
Q Predictions Max            3082.6106
Q Predictions Min            226.483
V Predictions Mean           798.1433
V Predictions Std            917.8869
V Predictions Max            3075.4392
V Predictions Min            212.81161
Log Pis Mean                 -0.8689893
Log Pis Std                  3.5523927
Log Pis Max                  14.472754
Log Pis Min                  -6.5236573
Policy mu Mean               -0.007673913
Policy mu Std                0.8098498
Policy mu Max                2.7159975
Policy mu Min                -2.8328636
Policy log std Mean          -0.47057378
Policy log std Std           0.20891596
Policy log std Max           -0.1503135
Policy log std Min           -1.9735777
Z mean eval                  2.2237992
Z variance eval              0.017811975
total_rewards                [7333.77209059 7350.89861319 7383.57216173 7285.19845133 7316.83726004
 7178.95597178 7314.48978356 7316.90911616 7220.71291774 7100.51554444]
total_rewards_mean           7280.186191055136
total_rewards_std            82.77696315437979
total_rewards_max            7383.572161729575
total_rewards_min            7100.515544442881
Number of train steps total  420000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               144.32140888180584
(Previous) Eval Time (s)     28.514428025111556
Sample Time (s)              10.103233359754086
Epoch Time (s)               182.93907026667148
Total Train Time (s)         19142.75573984068
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:10:22.285366 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #104 | Epoch Duration: 183.07573556900024
2020-01-13 09:10:22.285636 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2245371
Z variance train             0.017855674
KL Divergence                42.084305
KL Loss                      4.208431
QF Loss                      1148.3152
VF Loss                      58.9529
Policy Loss                  -785.4485
Q Predictions Mean           779.98615
Q Predictions Std            895.99603
Q Predictions Max            3054.9607
Q Predictions Min            284.68222
V Predictions Mean           784.38367
V Predictions Std            898.19324
V Predictions Max            3034.8286
V Predictions Min            293.9151
Log Pis Mean                 -0.88675064
Log Pis Std                  3.520896
Log Pis Max                  14.961544
Log Pis Min                  -5.9191985
Policy mu Mean               -0.0047612847
Policy mu Std                0.78379387
Policy mu Max                2.9623442
Policy mu Min                -3.2791002
Policy log std Mean          -0.46971747
Policy log std Std           0.2230571
Policy log std Max           0.030361772
Policy log std Min           -2.0982814
Z mean eval                  2.2226036
Z variance eval              0.014225401
total_rewards                [6984.55358881 6978.92058664 7378.73637546 7071.55571916 7083.04296682
 7222.21336818 7025.83750282 7221.65638927 7346.22344531 7008.63389089]
total_rewards_mean           7132.137383336716
total_rewards_std            141.654784784276
total_rewards_max            7378.736375458924
total_rewards_min            6978.920586640403
Number of train steps total  424000
Number of env steps total    1274000
Number of rollouts total     0
Train Time (s)               137.21192203788087
(Previous) Eval Time (s)     28.78846654901281
Sample Time (s)              9.847833341918886
Epoch Time (s)               175.84822192881256
Total Train Time (s)         19318.6850092588
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:13:18.216411 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #105 | Epoch Duration: 175.93058443069458
2020-01-13 09:13:18.216643 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.223888
Z variance train             0.014249936
KL Divergence                43.604893
KL Loss                      4.3604894
QF Loss                      119.22039
VF Loss                      123.562645
Policy Loss                  -818.7313
Q Predictions Mean           816.048
Q Predictions Std            954.95825
Q Predictions Max            3114.7327
Q Predictions Min            272.23706
V Predictions Mean           824.18396
V Predictions Std            952.8415
V Predictions Max            3114.1677
V Predictions Min            284.96216
Log Pis Mean                 -1.1399887
Log Pis Std                  3.2087357
Log Pis Max                  17.010223
Log Pis Min                  -6.6473255
Policy mu Mean               0.023059288
Policy mu Std                0.7718747
Policy mu Max                3.4011762
Policy mu Min                -2.8211477
Policy log std Mean          -0.47199073
Policy log std Std           0.24302234
Policy log std Max           -0.13219649
Policy log std Min           -2.2195084
Z mean eval                  2.2237446
Z variance eval              0.014580054
total_rewards                [7234.90297435 7551.87095078 7772.33348516 7614.04364118 7581.51061724
 7688.33225248 7383.45445348 7565.29983211 7436.03802203 7332.20195845]
total_rewards_mean           7515.998818725359
total_rewards_std            158.0462443957316
total_rewards_max            7772.333485156508
total_rewards_min            7234.902974349169
Number of train steps total  428000
Number of env steps total    1286000
Number of rollouts total     0
Train Time (s)               138.0795650910586
(Previous) Eval Time (s)     29.787486935034394
Sample Time (s)              9.87748417025432
Epoch Time (s)               177.74453619634733
Total Train Time (s)         19496.517926813103
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:16:16.051348 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #106 | Epoch Duration: 177.83454298973083
2020-01-13 09:16:16.051556 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.22356
Z variance train             0.014562368
KL Divergence                43.5185
KL Loss                      4.35185
QF Loss                      412.80026
VF Loss                      282.21124
Policy Loss                  -836.15985
Q Predictions Mean           830.34906
Q Predictions Std            952.9315
Q Predictions Max            3113.8728
Q Predictions Min            283.39996
V Predictions Mean           835.5029
V Predictions Std            949.4398
V Predictions Max            3099.179
V Predictions Min            283.22678
Log Pis Mean                 -1.0782642
Log Pis Std                  3.1824517
Log Pis Max                  10.119001
Log Pis Min                  -7.1467476
Policy mu Mean               0.020529972
Policy mu Std                0.8144505
Policy mu Max                2.6802542
Policy mu Min                -2.575575
Policy log std Mean          -0.47437778
Policy log std Std           0.22575618
Policy log std Max           -0.12841745
Policy log std Min           -2.0889475
Z mean eval                  2.2172346
Z variance eval              0.019844595
total_rewards                [7392.64613414 7583.45180553 7503.45847779 7593.41394636 7677.69811664
 7507.30470949 7430.94194425 7434.11000066 7464.62566835 7828.25192325]
total_rewards_mean           7541.590272644295
total_rewards_std            126.3609235437965
total_rewards_max            7828.251923246445
total_rewards_min            7392.64613413828
Number of train steps total  432000
Number of env steps total    1298000
Number of rollouts total     0
Train Time (s)               145.92928672209382
(Previous) Eval Time (s)     30.048463243991137
Sample Time (s)              10.151229731272906
Epoch Time (s)               186.12897969735786
Total Train Time (s)         19682.733186606318
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:19:22.269277 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #107 | Epoch Duration: 186.21757197380066
2020-01-13 09:19:22.269455 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2196183
Z variance train             0.020238416
KL Divergence                44.225666
KL Loss                      4.422567
QF Loss                      251.97511
VF Loss                      58.042374
Policy Loss                  -842.5406
Q Predictions Mean           837.40436
Q Predictions Std            970.10333
Q Predictions Max            3155.1536
Q Predictions Min            -64.84943
V Predictions Mean           842.4465
V Predictions Std            971.5691
V Predictions Max            3167.6118
V Predictions Min            -60.730648
Log Pis Mean                 -0.90478235
Log Pis Std                  3.630805
Log Pis Max                  22.175795
Log Pis Min                  -6.1283817
Policy mu Mean               0.030934637
Policy mu Std                0.81717294
Policy mu Max                3.535415
Policy mu Min                -3.025215
Policy log std Mean          -0.484557
Policy log std Std           0.22372088
Policy log std Max           -0.0036236346
Policy log std Min           -2.296067
Z mean eval                  2.2063746
Z variance eval              0.008482935
total_rewards                [7625.03471435 7901.71217036 7829.1941674  7424.79142972 7955.7734466
 7521.22570804 7946.15454319 8083.66940076 7786.58653679 7852.9501378 ]
total_rewards_mean           7792.709225501009
total_rewards_std            197.19381925200744
total_rewards_max            8083.6694007613205
total_rewards_min            7424.791429717124
Number of train steps total  436000
Number of env steps total    1310000
Number of rollouts total     0
Train Time (s)               146.43708127271384
(Previous) Eval Time (s)     30.298924059141427
Sample Time (s)              10.313030926976353
Epoch Time (s)               187.04903625883162
Total Train Time (s)         19869.862418119796
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:22:29.401778 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #108 | Epoch Duration: 187.1321403980255
2020-01-13 09:22:29.402069 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2075906
Z variance train             0.008486632
KL Divergence                45.00098
KL Loss                      4.500098
QF Loss                      136.34128
VF Loss                      36.408005
Policy Loss                  -751.5427
Q Predictions Mean           747.4059
Q Predictions Std            905.4206
Q Predictions Max            3145.8506
Q Predictions Min            -67.94037
V Predictions Mean           753.10095
V Predictions Std            902.0452
V Predictions Max            3133.3948
V Predictions Min            -70.80477
Log Pis Mean                 -1.1784468
Log Pis Std                  3.3054292
Log Pis Max                  21.485918
Log Pis Min                  -8.1268215
Policy mu Mean               -0.02761712
Policy mu Std                0.79171777
Policy mu Max                3.1536665
Policy mu Min                -3.206079
Policy log std Mean          -0.47303608
Policy log std Std           0.20731479
Policy log std Max           -0.09937996
Policy log std Min           -2.035439
Z mean eval                  2.1967258
Z variance eval              0.045300983
total_rewards                [7390.70098817 7728.98897094 7567.34715269 7723.65148983 7484.15158065
 7613.24092501 7606.76861862 7385.8246864  7424.23490251 7688.65773353]
total_rewards_mean           7561.356704836724
total_rewards_std            126.54394828016187
total_rewards_max            7728.9889709390145
total_rewards_min            7385.824686403929
Number of train steps total  440000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               145.47276504104957
(Previous) Eval Time (s)     30.64741423819214
Sample Time (s)              10.235449726227671
Epoch Time (s)               186.35562900546938
Total Train Time (s)         20056.334754546173
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:25:35.876538 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #109 | Epoch Duration: 186.47426748275757
2020-01-13 09:25:35.876847 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1926265
Z variance train             0.04509055
KL Divergence                42.14749
KL Loss                      4.2147493
QF Loss                      178.88013
VF Loss                      60.85398
Policy Loss                  -747.7448
Q Predictions Mean           744.765
Q Predictions Std            873.9301
Q Predictions Max            3019.1396
Q Predictions Min            -84.481026
V Predictions Mean           747.4973
V Predictions Std            872.36194
V Predictions Max            3013.4282
V Predictions Min            -82.41804
Log Pis Mean                 -1.1979858
Log Pis Std                  3.1440835
Log Pis Max                  11.63908
Log Pis Min                  -7.3957887
Policy mu Mean               0.017356055
Policy mu Std                0.7686747
Policy mu Max                2.557853
Policy mu Min                -2.612749
Policy log std Mean          -0.4786397
Policy log std Std           0.21117504
Policy log std Max           -0.09445757
Policy log std Min           -1.9690275
Z mean eval                  2.2523656
Z variance eval              0.04678189
total_rewards                [7558.67054958 7622.77197527 7660.2293128  7475.63314769 7742.94664503
 7848.62212787 7720.47501395 7634.93959142 7730.79486743 7609.63097832]
total_rewards_mean           7660.471420934594
total_rewards_std            99.96759766052118
total_rewards_max            7848.622127868885
total_rewards_min            7475.633147685608
Number of train steps total  444000
Number of env steps total    1334000
Number of rollouts total     0
Train Time (s)               147.2752164406702
(Previous) Eval Time (s)     29.641784945037216
Sample Time (s)              10.456611029803753
Epoch Time (s)               187.37361241551116
Total Train Time (s)         20243.81676131999
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:28:43.360923 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #110 | Epoch Duration: 187.48386549949646
2020-01-13 09:28:43.361268 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.246756
Z variance train             0.046766482
KL Divergence                42.58892
KL Loss                      4.258892
QF Loss                      172.90765
VF Loss                      150.24132
Policy Loss                  -765.20483
Q Predictions Mean           762.8902
Q Predictions Std            892.2823
Q Predictions Max            3100.761
Q Predictions Min            -71.55751
V Predictions Mean           771.29895
V Predictions Std            898.7847
V Predictions Max            3102.3909
V Predictions Min            -87.76018
Log Pis Mean                 -1.2011342
Log Pis Std                  3.1162112
Log Pis Max                  10.5549965
Log Pis Min                  -6.605483
Policy mu Mean               0.04201593
Policy mu Std                0.7780863
Policy mu Max                2.9121737
Policy mu Min                -2.3909698
Policy log std Mean          -0.46497333
Policy log std Std           0.23464017
Policy log std Max           -0.056801602
Policy log std Min           -2.2883332
Z mean eval                  2.183273
Z variance eval              0.018677097
total_rewards                [7707.03665228 7585.5895378  7539.58311453 7446.13333816 7596.21452555
 7465.71760138 7669.01753506 7353.12927679 7592.6555317  7175.66145051]
total_rewards_mean           7513.0738563761815
total_rewards_std            150.76469211667938
total_rewards_max            7707.036652275068
total_rewards_min            7175.661450512589
Number of train steps total  448000
Number of env steps total    1346000
Number of rollouts total     0
Train Time (s)               143.8184125390835
(Previous) Eval Time (s)     28.20409240014851
Sample Time (s)              10.219197491183877
Epoch Time (s)               182.2417024304159
Total Train Time (s)         20426.141498050652
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:31:45.687714 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #111 | Epoch Duration: 182.32617783546448
2020-01-13 09:31:45.687940 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1826348
Z variance train             0.01879129
KL Divergence                42.22451
KL Loss                      4.222451
QF Loss                      206.06401
VF Loss                      95.76503
Policy Loss                  -882.7896
Q Predictions Mean           883.3083
Q Predictions Std            999.9417
Q Predictions Max            3271.894
Q Predictions Min            287.31995
V Predictions Mean           887.8906
V Predictions Std            999.5885
V Predictions Max            3283.94
V Predictions Min            297.58414
Log Pis Mean                 -0.9252335
Log Pis Std                  3.0141208
Log Pis Max                  12.473076
Log Pis Min                  -8.697085
Policy mu Mean               0.037422102
Policy mu Std                0.8005461
Policy mu Max                2.3322036
Policy mu Min                -2.2429545
Policy log std Mean          -0.5067703
Policy log std Std           0.21344991
Policy log std Max           -0.1438653
Policy log std Min           -1.840647
Z mean eval                  2.2359657
Z variance eval              0.013674935
total_rewards                [7494.53446305 7825.58279254 7399.45571705 7355.78801653 7461.22832919
 7559.91191433 7619.92980231 7821.93362326 7468.64548656 7442.52709212]
total_rewards_mean           7544.953723694057
total_rewards_std            156.24827647788595
total_rewards_max            7825.582792540799
total_rewards_min            7355.788016525212
Number of train steps total  452000
Number of env steps total    1358000
Number of rollouts total     0
Train Time (s)               137.73497638199478
(Previous) Eval Time (s)     29.358930736780167
Sample Time (s)              9.85877746436745
Epoch Time (s)               176.9526845831424
Total Train Time (s)         20603.268309738953
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:34:42.816334 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #112 | Epoch Duration: 177.12823104858398
2020-01-13 09:34:42.816565 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.232862
Z variance train             0.013810867
KL Divergence                45.940186
KL Loss                      4.5940185
QF Loss                      146.23193
VF Loss                      165.98283
Policy Loss                  -855.5809
Q Predictions Mean           852.97015
Q Predictions Std            975.0821
Q Predictions Max            3192.0466
Q Predictions Min            293.09326
V Predictions Mean           858.30664
V Predictions Std            981.2876
V Predictions Max            3197.4294
V Predictions Min            288.4859
Log Pis Mean                 -0.67765635
Log Pis Std                  3.6512249
Log Pis Max                  16.290539
Log Pis Min                  -7.3673573
Policy mu Mean               0.024092183
Policy mu Std                0.8620214
Policy mu Max                3.3655772
Policy mu Min                -2.4886863
Policy log std Mean          -0.4765075
Policy log std Std           0.21727757
Policy log std Max           -0.017930806
Policy log std Min           -2.0563807
Z mean eval                  2.2354367
Z variance eval              0.014173689
total_rewards                [7728.60054953 7588.29293513 7901.61980403 7798.69502798 7813.93325999
 7470.55346128 7665.18181613 7760.04975631 7770.92519219 7764.04749817]
total_rewards_mean           7726.189930074317
total_rewards_std            116.79290871396343
total_rewards_max            7901.619804025242
total_rewards_min            7470.553461282525
Number of train steps total  456000
Number of env steps total    1370000
Number of rollouts total     0
Train Time (s)               138.51774484757334
(Previous) Eval Time (s)     29.678686894942075
Sample Time (s)              9.880238896701485
Epoch Time (s)               178.0766706392169
Total Train Time (s)         20781.48799269041
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:37:41.037918 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #113 | Epoch Duration: 178.2211880683899
2020-01-13 09:37:41.038127 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2382798
Z variance train             0.0141950445
KL Divergence                45.282703
KL Loss                      4.5282702
QF Loss                      223.00438
VF Loss                      123.6035
Policy Loss                  -915.35645
Q Predictions Mean           912.7423
Q Predictions Std            1043.2008
Q Predictions Max            3237.5745
Q Predictions Min            302.98605
V Predictions Mean           915.60254
V Predictions Std            1042.3616
V Predictions Max            3226.0203
V Predictions Min            310.2083
Log Pis Mean                 -0.2796647
Log Pis Std                  3.7402773
Log Pis Max                  14.70418
Log Pis Min                  -7.5020285
Policy mu Mean               0.06090576
Policy mu Std                0.88315564
Policy mu Max                2.5759358
Policy mu Min                -3.365698
Policy log std Mean          -0.502865
Policy log std Std           0.239471
Policy log std Max           -0.12129706
Policy log std Min           -2.0866854
Z mean eval                  2.202918
Z variance eval              0.06189554
total_rewards                [7511.56257637 7607.0714765  7847.70638621 7976.78130124 7814.27519258
 7628.93309462 7788.73459796 7726.94266861 7686.65079145 7774.53888495]
total_rewards_mean           7736.319697048324
total_rewards_std            127.20909640979134
total_rewards_max            7976.7813012352835
total_rewards_min            7511.562576368229
Number of train steps total  460000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               145.87254969682544
(Previous) Eval Time (s)     30.22844075737521
Sample Time (s)              10.007150039542466
Epoch Time (s)               186.10814049374312
Total Train Time (s)         20967.675118437503
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:40:47.227076 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #114 | Epoch Duration: 186.18880152702332
2020-01-13 09:40:47.227317 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.20611
Z variance train             0.061774034
KL Divergence                40.942013
KL Loss                      4.0942016
QF Loss                      1148.5571
VF Loss                      72.34895
Policy Loss                  -804.75146
Q Predictions Mean           801.9972
Q Predictions Std            944.69763
Q Predictions Max            3252.1523
Q Predictions Min            313.61273
V Predictions Mean           799.75195
V Predictions Std            942.6725
V Predictions Max            3235.6584
V Predictions Min            309.6569
Log Pis Mean                 -0.77399164
Log Pis Std                  3.0164137
Log Pis Max                  10.959011
Log Pis Min                  -6.2076983
Policy mu Mean               0.021607125
Policy mu Std                0.8124362
Policy mu Max                2.450832
Policy mu Min                -2.5266252
Policy log std Mean          -0.45426953
Policy log std Std           0.21829264
Policy log std Max           -0.13017642
Policy log std Min           -2.041825
Z mean eval                  2.2222943
Z variance eval              0.041331984
total_rewards                [7370.28384971 7771.83718736 7855.38567701 7412.58632627 7403.62991997
 7421.8344045  7589.80536112 7726.08431048 7685.31464939 7207.54550362]
total_rewards_mean           7544.430718942972
total_rewards_std            199.84201277731185
total_rewards_max            7855.385677008821
total_rewards_min            7207.54550361864
Number of train steps total  464000
Number of env steps total    1394000
Number of rollouts total     0
Train Time (s)               146.33459432702512
(Previous) Eval Time (s)     30.293746382929385
Sample Time (s)              10.652891591191292
Epoch Time (s)               187.2812323011458
Total Train Time (s)         21155.038578430656
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:43:54.592384 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #115 | Epoch Duration: 187.36491870880127
2020-01-13 09:43:54.592566 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2223012
Z variance train             0.041321408
KL Divergence                42.414623
KL Loss                      4.241462
QF Loss                      811.1994
VF Loss                      56.575455
Policy Loss                  -917.7302
Q Predictions Mean           915.9201
Q Predictions Std            1029.9489
Q Predictions Max            3160.3271
Q Predictions Min            -112.02828
V Predictions Mean           915.5137
V Predictions Std            1029.6766
V Predictions Max            3150.0085
V Predictions Min            -112.02686
Log Pis Mean                 -0.71007264
Log Pis Std                  3.667181
Log Pis Max                  14.464552
Log Pis Min                  -8.135126
Policy mu Mean               0.05764766
Policy mu Std                0.8082468
Policy mu Max                2.5641637
Policy mu Min                -2.3831358
Policy log std Mean          -0.503859
Policy log std Std           0.2393854
Policy log std Max           -0.08500105
Policy log std Min           -2.182989
Z mean eval                  2.354433
Z variance eval              0.12821388
total_rewards                [7084.42188004 7313.84136155 7048.13110526 7190.93751214 7093.15711718
 7052.04578811 7055.77019996 7055.15425171 7225.06688846 7101.03789046]
total_rewards_mean           7121.956399486985
total_rewards_std            86.06197531247801
total_rewards_max            7313.841361553938
total_rewards_min            7048.131105256373
Number of train steps total  468000
Number of env steps total    1406000
Number of rollouts total     0
Train Time (s)               145.95339677203447
(Previous) Eval Time (s)     30.83973478106782
Sample Time (s)              10.55989340832457
Epoch Time (s)               187.35302496142685
Total Train Time (s)         21342.479972757865
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:47:02.037594 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #116 | Epoch Duration: 187.4448537826538
2020-01-13 09:47:02.037910 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3553085
Z variance train             0.12828366
KL Divergence                39.559437
KL Loss                      3.9559438
QF Loss                      584.44946
VF Loss                      57.45391
Policy Loss                  -889.4915
Q Predictions Mean           886.16235
Q Predictions Std            1000.04956
Q Predictions Max            3101.7966
Q Predictions Min            284.6941
V Predictions Mean           891.4599
V Predictions Std            998.76654
V Predictions Max            3087.1543
V Predictions Min            300.0021
Log Pis Mean                 -0.44193038
Log Pis Std                  3.9860985
Log Pis Max                  13.381711
Log Pis Min                  -7.544877
Policy mu Mean               -0.036845937
Policy mu Std                0.880516
Policy mu Max                2.6252186
Policy mu Min                -2.7471972
Policy log std Mean          -0.47033063
Policy log std Std           0.2187872
Policy log std Max           -0.14470248
Policy log std Min           -2.1836898
Z mean eval                  2.2302983
Z variance eval              0.10639505
total_rewards                [7193.6693421  7422.44415804 7184.40550128 7491.01546555 7530.37876481
 7581.39124091 7440.41467374 7278.05133069 7617.25926832 7343.28429581]
total_rewards_mean           7408.2314041246555
total_rewards_std            146.28322271817703
total_rewards_max            7617.259268317615
total_rewards_min            7184.405501283189
Number of train steps total  472000
Number of env steps total    1418000
Number of rollouts total     0
Train Time (s)               148.14752635918558
(Previous) Eval Time (s)     30.08403381658718
Sample Time (s)              10.564242916181684
Epoch Time (s)               188.79580309195444
Total Train Time (s)         21531.357387172524
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:50:10.916351 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #117 | Epoch Duration: 188.87822222709656
2020-01-13 09:50:10.916552 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2243695
Z variance train             0.10616028
KL Divergence                38.37422
KL Loss                      3.8374221
QF Loss                      445.96738
VF Loss                      49.267654
Policy Loss                  -814.4026
Q Predictions Mean           811.2479
Q Predictions Std            953.46423
Q Predictions Max            3200.123
Q Predictions Min            283.5124
V Predictions Mean           816.7113
V Predictions Std            957.14276
V Predictions Max            3193.886
V Predictions Min            294.34763
Log Pis Mean                 -1.3894701
Log Pis Std                  3.3239179
Log Pis Max                  11.1967945
Log Pis Min                  -10.720165
Policy mu Mean               0.052517492
Policy mu Std                0.7794981
Policy mu Max                2.64321
Policy mu Min                -2.636556
Policy log std Mean          -0.4762245
Policy log std Std           0.21631187
Policy log std Max           -0.11662373
Policy log std Min           -1.9078938
Z mean eval                  2.223112
Z variance eval              0.043899477
total_rewards                [7941.69354689 7671.35828163 7879.60582898 8179.11678282 7827.70689439
 7899.23297138 7939.25148093 7430.75372185 7875.24406582 7802.72228658]
total_rewards_mean           7844.668586127531
total_rewards_std            184.0535992182523
total_rewards_max            8179.116782818698
total_rewards_min            7430.753721851927
Number of train steps total  476000
Number of env steps total    1430000
Number of rollouts total     0
Train Time (s)               142.45159365609288
(Previous) Eval Time (s)     28.714097384363413
Sample Time (s)              10.387479118071496
Epoch Time (s)               181.5531701585278
Total Train Time (s)         21712.988547781482
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:53:12.550178 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #118 | Epoch Duration: 181.6334674358368
2020-01-13 09:53:12.550397 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2259505
Z variance train             0.044067424
KL Divergence                41.14789
KL Loss                      4.114789
QF Loss                      176.48923
VF Loss                      164.78093
Policy Loss                  -835.7743
Q Predictions Mean           834.04596
Q Predictions Std            973.55023
Q Predictions Max            3280.3044
Q Predictions Min            307.57843
V Predictions Mean           824.65857
V Predictions Std            972.2909
V Predictions Max            3269.281
V Predictions Min            302.6784
Log Pis Mean                 -0.816705
Log Pis Std                  3.307246
Log Pis Max                  12.056761
Log Pis Min                  -7.325316
Policy mu Mean               0.0068968176
Policy mu Std                0.81755006
Policy mu Max                2.8611345
Policy mu Min                -2.531086
Policy log std Mean          -0.489846
Policy log std Std           0.22595014
Policy log std Max           0.0085808635
Policy log std Min           -2.0700583
Z mean eval                  2.2926939
Z variance eval              0.040789157
total_rewards                [7554.46551744 7984.63731699 7938.09826977 7803.99729262 8018.66010397
 8037.25677148 7682.97132625 7761.01967479 7840.80594729 7728.47169612]
total_rewards_mean           7835.038391672888
total_rewards_std            150.76072400005137
total_rewards_max            8037.256771480702
total_rewards_min            7554.465517437335
Number of train steps total  480000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               137.99296158691868
(Previous) Eval Time (s)     28.21878684218973
Sample Time (s)              9.47610557358712
Epoch Time (s)               175.68785400269553
Total Train Time (s)         21888.755087023135
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:56:08.318013 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #119 | Epoch Duration: 175.76744318008423
2020-01-13 09:56:08.318190 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #119 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.294119
Z variance train             0.04072555
KL Divergence                43.172577
KL Loss                      4.317258
QF Loss                      1370.9766
VF Loss                      107.45368
Policy Loss                  -817.01544
Q Predictions Mean           814.3051
Q Predictions Std            967.0383
Q Predictions Max            3317.118
Q Predictions Min            326.58057
V Predictions Mean           823.9796
V Predictions Std            971.2531
V Predictions Max            3326.713
V Predictions Min            336.1234
Log Pis Mean                 -0.8939111
Log Pis Std                  3.3166058
Log Pis Max                  13.300394
Log Pis Min                  -5.8486633
Policy mu Mean               0.083397865
Policy mu Std                0.7987623
Policy mu Max                2.7080655
Policy mu Min                -2.518773
Policy log std Mean          -0.4651324
Policy log std Std           0.21485431
Policy log std Max           -0.050148368
Policy log std Min           -2.1036713
Z mean eval                  2.200752
Z variance eval              0.03131457
total_rewards                [7068.36913751 7228.56460735 7073.23003465 7423.73973244 7068.2704855
 7196.98154038 7194.98479255 7058.67680835 7455.59028612 7477.00921901]
total_rewards_mean           7224.541664384675
total_rewards_std            160.5208567446532
total_rewards_max            7477.009219005899
total_rewards_min            7058.67680834641
Number of train steps total  484000
Number of env steps total    1454000
Number of rollouts total     0
Train Time (s)               138.91425392916426
(Previous) Eval Time (s)     28.800435048062354
Sample Time (s)              10.149996370077133
Epoch Time (s)               177.86468534730375
Total Train Time (s)         22066.70735274302
Epoch                        120
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:59:06.273204 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #120 | Epoch Duration: 177.95486640930176
2020-01-13 09:59:06.273454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2012606
Z variance train             0.031474017
KL Divergence                42.467644
KL Loss                      4.2467647
QF Loss                      243.62924
VF Loss                      78.64425
Policy Loss                  -848.9891
Q Predictions Mean           843.8964
Q Predictions Std            1003.7488
Q Predictions Max            3429.2864
Q Predictions Min            317.34286
V Predictions Mean           842.8695
V Predictions Std            1003.10974
V Predictions Max            3402.2134
V Predictions Min            316.64377
Log Pis Mean                 -0.8915557
Log Pis Std                  3.4669597
Log Pis Max                  16.71345
Log Pis Min                  -10.484776
Policy mu Mean               -0.031039672
Policy mu Std                0.81377345
Policy mu Max                2.5480478
Policy mu Min                -2.5974882
Policy log std Mean          -0.47486022
Policy log std Std           0.21498354
Policy log std Max           -0.15780336
Policy log std Min           -1.9370519
Z mean eval                  2.2257762
Z variance eval              0.03460444
total_rewards                [7398.20089046 7835.86555261 7559.08515778 7559.38312333 7461.18904434
 7589.25863375 7837.80674635 7465.52084092 7722.47426901 7612.31538384]
total_rewards_mean           7604.109964239115
total_rewards_std            144.45845177281956
total_rewards_max            7837.806746346282
total_rewards_min            7398.200890456817
Number of train steps total  488000
Number of env steps total    1466000
Number of rollouts total     0
Train Time (s)               148.02842339826748
(Previous) Eval Time (s)     31.101976403966546
Sample Time (s)              10.126758829690516
Epoch Time (s)               189.25715863192454
Total Train Time (s)         22256.050679621752
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:02:15.618525 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #121 | Epoch Duration: 189.34489941596985
2020-01-13 10:02:15.618761 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2280364
Z variance train             0.034588836
KL Divergence                43.28274
KL Loss                      4.3282743
QF Loss                      214.40416
VF Loss                      106.46232
Policy Loss                  -778.12537
Q Predictions Mean           775.9131
Q Predictions Std            928.24884
Q Predictions Max            3293.2996
Q Predictions Min            262.9043
V Predictions Mean           785.1864
V Predictions Std            930.59393
V Predictions Max            3291.8167
V Predictions Min            253.46655
Log Pis Mean                 -0.89002734
Log Pis Std                  3.440557
Log Pis Max                  12.615843
Log Pis Min                  -7.284406
Policy mu Mean               0.04450779
Policy mu Std                0.7940537
Policy mu Max                2.864062
Policy mu Min                -2.2841349
Policy log std Mean          -0.5015888
Policy log std Std           0.21707204
Policy log std Max           -0.1001277
Policy log std Min           -1.9389348
Z mean eval                  2.2327304
Z variance eval              0.09985479
total_rewards                [7528.54008052 7649.56966702 7723.56787839 7586.1512845  7608.96609009
 7701.26184584 7480.17692613 7525.59602023 7683.4931292  7447.6194226 ]
total_rewards_mean           7593.494234453528
total_rewards_std            91.11533682232651
total_rewards_max            7723.567878387103
total_rewards_min            7447.619422599521
Number of train steps total  492000
Number of env steps total    1478000
Number of rollouts total     0
Train Time (s)               146.73119621537626
(Previous) Eval Time (s)     30.634357939008623
Sample Time (s)              10.196111775003374
Epoch Time (s)               187.56166592938825
Total Train Time (s)         22443.696008553263
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:05:23.267025 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #122 | Epoch Duration: 187.64808011054993
2020-01-13 10:05:23.267435 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.237209
Z variance train             0.10053166
KL Divergence                42.284252
KL Loss                      4.2284255
QF Loss                      151.264
VF Loss                      36.29997
Policy Loss                  -880.0988
Q Predictions Mean           877.1037
Q Predictions Std            1004.6884
Q Predictions Max            3315.4814
Q Predictions Min            333.48624
V Predictions Mean           877.8091
V Predictions Std            1004.8879
V Predictions Max            3315.4622
V Predictions Min            337.13428
Log Pis Mean                 -0.99523103
Log Pis Std                  3.2112565
Log Pis Max                  12.2981415
Log Pis Min                  -7.221841
Policy mu Mean               0.039755028
Policy mu Std                0.7966065
Policy mu Max                2.5029788
Policy mu Min                -2.4983916
Policy log std Mean          -0.48848602
Policy log std Std           0.23486413
Policy log std Max           -0.027126461
Policy log std Min           -2.2743063
Z mean eval                  2.2710752
Z variance eval              0.01721206
total_rewards                [7919.44324895 7848.34887091 7899.12348199 8125.03401631 8297.57246362
 7664.52563014 7985.03186079 8049.89637137 7864.40328036 8040.88467225]
total_rewards_mean           7969.426389669473
total_rewards_std            164.26007413162029
total_rewards_max            8297.572463619532
total_rewards_min            7664.525630138718
Number of train steps total  496000
Number of env steps total    1490000
Number of rollouts total     0
Train Time (s)               145.02622993802652
(Previous) Eval Time (s)     29.844561234116554
Sample Time (s)              10.151365553960204
Epoch Time (s)               185.02215672610328
Total Train Time (s)         22628.799404986203
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:08:28.371921 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #123 | Epoch Duration: 185.10424089431763
2020-01-13 10:08:28.372107 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2748682
Z variance train             0.017124562
KL Divergence                44.67023
KL Loss                      4.4670234
QF Loss                      220.6031
VF Loss                      79.27967
Policy Loss                  -814.5572
Q Predictions Mean           810.68585
Q Predictions Std            959.0151
Q Predictions Max            3352.9482
Q Predictions Min            333.31125
V Predictions Mean           810.80634
V Predictions Std            958.11206
V Predictions Max            3331.944
V Predictions Min            331.37976
Log Pis Mean                 -0.8560496
Log Pis Std                  3.4069185
Log Pis Max                  16.303246
Log Pis Min                  -6.456212
Policy mu Mean               0.07998626
Policy mu Std                0.7941235
Policy mu Max                2.7458053
Policy mu Min                -2.9204068
Policy log std Mean          -0.5021436
Policy log std Std           0.23356274
Policy log std Max           0.037012726
Policy log std Min           -1.9449236
Z mean eval                  2.2585816
Z variance eval              0.025999596
total_rewards                [7753.59192206 8208.95093069 8131.19591821 8023.63016972 7992.71541247
 8129.16522411 8042.88769118 8034.91150147 8256.6797209  8136.57235783]
total_rewards_mean           8071.030084862667
total_rewards_std            132.6751039179846
total_rewards_max            8256.679720898825
total_rewards_min            7753.591922061082
Number of train steps total  500000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               148.04334585601464
(Previous) Eval Time (s)     30.526003857143223
Sample Time (s)              10.67124067991972
Epoch Time (s)               189.24059039307758
Total Train Time (s)         22818.131934927776
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:11:37.706287 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #124 | Epoch Duration: 189.33402848243713
2020-01-13 10:11:37.706477 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2624342
Z variance train             0.026170794
KL Divergence                45.77014
KL Loss                      4.5770144
QF Loss                      657.14087
VF Loss                      168.91217
Policy Loss                  -836.42017
Q Predictions Mean           831.5294
Q Predictions Std            966.3386
Q Predictions Max            3308.9324
Q Predictions Min            326.41168
V Predictions Mean           832.9625
V Predictions Std            965.99695
V Predictions Max            3320.8616
V Predictions Min            325.58228
Log Pis Mean                 -1.0579256
Log Pis Std                  3.305986
Log Pis Max                  11.471533
Log Pis Min                  -9.999442
Policy mu Mean               0.035107028
Policy mu Std                0.7838379
Policy mu Max                2.4771917
Policy mu Min                -3.0554087
Policy log std Mean          -0.502237
Policy log std Std           0.23946714
Policy log std Max           0.013207674
Policy log std Min           -2.3112879
Z mean eval                  2.2492874
Z variance eval              0.030723045
total_rewards                [8159.60735527 8060.96131988 8044.31621445 7988.53587793 8310.04751852
 8163.19750292 8157.17808799 7871.90936855 8034.05034534 8169.032685  ]
total_rewards_mean           8095.883627585557
total_rewards_std            115.30653384388152
total_rewards_max            8310.047518517817
total_rewards_min            7871.909368550721
Number of train steps total  504000
Number of env steps total    1514000
Number of rollouts total     0
Train Time (s)               142.488460295368
(Previous) Eval Time (s)     29.22485596500337
Sample Time (s)              8.802326050586998
Epoch Time (s)               180.51564231095836
Total Train Time (s)         22998.724657955114
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:14:38.301048 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #125 | Epoch Duration: 180.5944287776947
2020-01-13 10:14:38.301231 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.250403
Z variance train             0.030858397
KL Divergence                44.656982
KL Loss                      4.4656982
QF Loss                      1301.01
VF Loss                      67.73529
Policy Loss                  -801.20197
Q Predictions Mean           799.969
Q Predictions Std            937.1815
Q Predictions Max            3263.8357
Q Predictions Min            331.32227
V Predictions Mean           804.1586
V Predictions Std            933.9575
V Predictions Max            3256.9998
V Predictions Min            333.10242
Log Pis Mean                 -0.6704382
Log Pis Std                  3.7261765
Log Pis Max                  16.440765
Log Pis Min                  -8.83617
Policy mu Mean               0.0034507215
Policy mu Std                0.8429099
Policy mu Max                2.6916919
Policy mu Min                -3.0967789
Policy log std Mean          -0.49163032
Policy log std Std           0.22808945
Policy log std Max           -0.055211425
Policy log std Min           -2.4517074
Z mean eval                  2.252512
Z variance eval              0.05074016
total_rewards                [7624.31792345 7853.14367688 7916.65778676 8172.09932822 7702.08909019
 7889.82298552 8076.3081238  7798.70978848 8043.4153675  8021.14662673]
total_rewards_mean           7909.771069753238
total_rewards_std            163.5291853773476
total_rewards_max            8172.099328219878
total_rewards_min            7624.317923449611
Number of train steps total  508000
Number of env steps total    1526000
Number of rollouts total     0
Train Time (s)               138.2671211110428
(Previous) Eval Time (s)     29.45742355333641
Sample Time (s)              9.828351887408644
Epoch Time (s)               177.55289655178785
Total Train Time (s)         23176.362701359205
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:17:35.942441 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #126 | Epoch Duration: 177.64105367660522
2020-01-13 10:17:35.942713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2516809
Z variance train             0.050857715
KL Divergence                44.82486
KL Loss                      4.4824862
QF Loss                      81.56642
VF Loss                      61.548943
Policy Loss                  -724.8973
Q Predictions Mean           724.1273
Q Predictions Std            868.1152
Q Predictions Max            3276.8362
Q Predictions Min            330.60138
V Predictions Mean           719.63416
V Predictions Std            867.7142
V Predictions Max            3262.6865
V Predictions Min            336.53656
Log Pis Mean                 -0.7420804
Log Pis Std                  3.2507164
Log Pis Max                  12.997391
Log Pis Min                  -10.303421
Policy mu Mean               -0.007999453
Policy mu Std                0.800462
Policy mu Max                2.4126575
Policy mu Min                -2.632082
Policy log std Mean          -0.49179065
Policy log std Std           0.21896218
Policy log std Max           -0.089259
Policy log std Min           -2.0387816
Z mean eval                  2.1986432
Z variance eval              0.037109006
total_rewards                [7416.81035907 7390.097209   7191.13388486 7410.37798278 7499.11299558
 7735.19554583 7592.77434795 7312.56749462 7364.89835464 7627.00843641]
total_rewards_mean           7453.99766107412
total_rewards_std            153.20141114793756
total_rewards_max            7735.195545831496
total_rewards_min            7191.133884860905
Number of train steps total  512000
Number of env steps total    1538000
Number of rollouts total     0
Train Time (s)               140.08238823898137
(Previous) Eval Time (s)     29.05524042621255
Sample Time (s)              9.869412596803159
Epoch Time (s)               179.00704126199707
Total Train Time (s)         23355.45496279141
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:20:35.034244 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #127 | Epoch Duration: 179.09133648872375
2020-01-13 10:20:35.034371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1987245
Z variance train             0.037143204
KL Divergence                41.886612
KL Loss                      4.188661
QF Loss                      277.80237
VF Loss                      36.941612
Policy Loss                  -768.63916
Q Predictions Mean           766.6791
Q Predictions Std            918.8564
Q Predictions Max            3300.096
Q Predictions Min            323.5407
V Predictions Mean           768.67725
V Predictions Std            918.5479
V Predictions Max            3293.6104
V Predictions Min            330.42233
Log Pis Mean                 -1.0939082
Log Pis Std                  2.9786677
Log Pis Max                  13.063374
Log Pis Min                  -8.175571
Policy mu Mean               0.06512297
Policy mu Std                0.7721148
Policy mu Max                2.5810487
Policy mu Min                -3.2685199
Policy log std Mean          -0.48444724
Policy log std Std           0.21638882
Policy log std Max           -0.11996108
Policy log std Min           -1.8642559
Z mean eval                  2.1773422
Z variance eval              0.17377838
total_rewards                [7834.85826982 7844.11096145 7908.55948434 7824.81653757 8076.63823519
 7840.04310896 7891.88437537 7800.84379565 8019.39653522 7775.21095742]
total_rewards_mean           7881.636226099099
total_rewards_std            91.78350310720327
total_rewards_max            8076.638235193928
total_rewards_min            7775.210957422052
Number of train steps total  516000
Number of env steps total    1550000
Number of rollouts total     0
Train Time (s)               148.2820712979883
(Previous) Eval Time (s)     30.56023940583691
Sample Time (s)              9.623132708948106
Epoch Time (s)               188.4654434127733
Total Train Time (s)         23544.00076702563
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:23:43.581716 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #128 | Epoch Duration: 188.54724645614624
2020-01-13 10:23:43.581868 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1758435
Z variance train             0.17339633
KL Divergence                39.119293
KL Loss                      3.9119294
QF Loss                      185.79037
VF Loss                      85.88685
Policy Loss                  -1006.61285
Q Predictions Mean           1006.6796
Q Predictions Std            1143.6677
Q Predictions Max            3548.2288
Q Predictions Min            342.49402
V Predictions Mean           1000.27356
V Predictions Std            1140.5438
V Predictions Max            3522.494
V Predictions Min            345.67877
Log Pis Mean                 -0.38314897
Log Pis Std                  3.8179948
Log Pis Max                  14.218898
Log Pis Min                  -7.1466894
Policy mu Mean               -0.020120356
Policy mu Std                0.87264425
Policy mu Max                2.7448275
Policy mu Min                -3.0314007
Policy log std Mean          -0.47863698
Policy log std Std           0.24450925
Policy log std Max           -0.122178435
Policy log std Min           -2.1003258
Z mean eval                  2.264125
Z variance eval              0.051839583
total_rewards                [7485.39697394 7393.09924324 7543.83190973 7881.63377692 7736.83904088
 7388.2317725  7665.97522607 7547.49909272 7454.25451274 7577.21479786]
total_rewards_mean           7567.397634659572
total_rewards_std            148.4000561459306
total_rewards_max            7881.633776923094
total_rewards_min            7388.23177250114
Number of train steps total  520000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               146.92050045821816
(Previous) Eval Time (s)     30.05653619673103
Sample Time (s)              9.634802786167711
Epoch Time (s)               186.6118394411169
Total Train Time (s)         23730.694866571575
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:26:50.279003 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #129 | Epoch Duration: 186.6970090866089
2020-01-13 10:26:50.279275 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2610118
Z variance train             0.051816754
KL Divergence                42.589966
KL Loss                      4.2589965
QF Loss                      1341.8599
VF Loss                      120.94327
Policy Loss                  -960.3408
Q Predictions Mean           957.1363
Q Predictions Std            1066.7155
Q Predictions Max            3402.5037
Q Predictions Min            339.63815
V Predictions Mean           964.59247
V Predictions Std            1070.7018
V Predictions Max            3402.8247
V Predictions Min            339.8914
Log Pis Mean                 -0.37302676
Log Pis Std                  3.7996528
Log Pis Max                  12.652477
Log Pis Min                  -10.303897
Policy mu Mean               0.086205415
Policy mu Std                0.8765675
Policy mu Max                2.9717028
Policy mu Min                -2.8169734
Policy log std Mean          -0.49773988
Policy log std Std           0.23587744
Policy log std Max           -0.10706338
Policy log std Min           -2.2096844
Z mean eval                  2.218779
Z variance eval              0.03929327
total_rewards                [7960.46332977 8352.38485053 7990.49929262 8163.15863117 8139.00864951
 8080.241682   7986.21133466 7902.58884592 8017.19489166 8092.73387226]
total_rewards_mean           8068.4485380104725
total_rewards_std            122.44739186600135
total_rewards_max            8352.384850533177
total_rewards_min            7902.588845920879
Number of train steps total  524000
Number of env steps total    1574000
Number of rollouts total     0
Train Time (s)               144.89495957270265
(Previous) Eval Time (s)     30.92275742581114
Sample Time (s)              9.510002214461565
Epoch Time (s)               185.32771921297535
Total Train Time (s)         23916.10463733971
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:29:55.690913 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #130 | Epoch Duration: 185.41147565841675
2020-01-13 10:29:55.691127 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #130 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2172844
Z variance train             0.039256305
KL Divergence                43.249214
KL Loss                      4.3249216
QF Loss                      345.76657
VF Loss                      51.662823
Policy Loss                  -871.8397
Q Predictions Mean           867.05115
Q Predictions Std            1006.7028
Q Predictions Max            3444.228
Q Predictions Min            344.43066
V Predictions Mean           867.18506
V Predictions Std            1006.7969
V Predictions Max            3422.4763
V Predictions Min            340.59048
Log Pis Mean                 -0.842108
Log Pis Std                  3.2182646
Log Pis Max                  11.072126
Log Pis Min                  -8.768251
Policy mu Mean               -0.007700991
Policy mu Std                0.8253099
Policy mu Max                2.8761663
Policy mu Min                -3.0561838
Policy log std Mean          -0.4890224
Policy log std Std           0.24724585
Policy log std Max           -0.09940535
Policy log std Min           -2.2135785
Z mean eval                  2.2243702
Z variance eval              0.049817942
total_rewards                [7566.01226157 7674.70426005 7876.35046558 7854.81179947 7818.765653
 7698.1552299  7671.62359746 7787.40713881 7943.05095884 7720.08268782]
total_rewards_mean           7761.096405248973
total_rewards_std            108.79432692872295
total_rewards_max            7943.050958837654
total_rewards_min            7566.012261567582
Number of train steps total  528000
Number of env steps total    1586000
Number of rollouts total     0
Train Time (s)               146.8582285209559
(Previous) Eval Time (s)     29.799095917027444
Sample Time (s)              10.634241920430213
Epoch Time (s)               187.29156635841355
Total Train Time (s)         24103.47421319876
Epoch                        131
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:33:03.062523 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #131 | Epoch Duration: 187.3712077140808
2020-01-13 10:33:03.062730 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.222925
Z variance train             0.049779717
KL Divergence                42.46879
KL Loss                      4.246879
QF Loss                      360.05774
VF Loss                      119.18646
Policy Loss                  -934.2176
Q Predictions Mean           928.2705
Q Predictions Std            1071.3677
Q Predictions Max            3472.9785
Q Predictions Min            338.194
V Predictions Mean           932.64465
V Predictions Std            1070.1959
V Predictions Max            3459.0813
V Predictions Min            340.69125
Log Pis Mean                 -0.2551142
Log Pis Std                  3.7615857
Log Pis Max                  19.82215
Log Pis Min                  -7.6205163
Policy mu Mean               0.09378811
Policy mu Std                0.85993636
Policy mu Max                4.253767
Policy mu Min                -2.9740777
Policy log std Mean          -0.52100253
Policy log std Std           0.24485803
Policy log std Max           -0.15471344
Policy log std Min           -1.9833763
Z mean eval                  2.2042596
Z variance eval              0.02083245
total_rewards                [7921.07700971 8033.85743107 8067.08467784 8319.16393924 8108.93608943
 8313.80345858 8224.72937655 8035.42023921 8098.04283677 8161.99803154]
total_rewards_mean           8128.411308993118
total_rewards_std            121.16097707630759
total_rewards_max            8319.163939237475
total_rewards_min            7921.077009711422
Number of train steps total  532000
Number of env steps total    1598000
Number of rollouts total     0
Train Time (s)               140.40443410398439
(Previous) Eval Time (s)     28.904852716252208
Sample Time (s)              9.903342127799988
Epoch Time (s)               179.21262894803658
Total Train Time (s)         24282.76426912751
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:36:02.355300 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #132 | Epoch Duration: 179.29240942001343
2020-01-13 10:36:02.355537 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2039876
Z variance train             0.020796804
KL Divergence                44.56324
KL Loss                      4.456324
QF Loss                      351.67062
VF Loss                      177.11269
Policy Loss                  -832.31903
Q Predictions Mean           828.339
Q Predictions Std            963.832
Q Predictions Max            3399.5671
Q Predictions Min            331.0883
V Predictions Mean           833.19775
V Predictions Std            964.7724
V Predictions Max            3417.8977
V Predictions Min            336.7418
Log Pis Mean                 -0.510007
Log Pis Std                  3.2082074
Log Pis Max                  11.00568
Log Pis Min                  -6.6041727
Policy mu Mean               0.102952205
Policy mu Std                0.82066274
Policy mu Max                2.9617395
Policy mu Min                -2.447607
Policy log std Mean          -0.499146
Policy log std Std           0.23317185
Policy log std Max           -0.11711264
Policy log std Min           -2.1217518
Z mean eval                  2.235373
Z variance eval              0.06400778
total_rewards                [8263.20361981 8254.28298728 8267.53988725 8557.6946612  8402.96175888
 8462.32874701 8415.16895608 8409.76597457 8355.2479153  8254.26629758]
total_rewards_mean           8364.24608049531
total_rewards_std            98.50722551353907
total_rewards_max            8557.694661199537
total_rewards_min            8254.266297577227
Number of train steps total  536000
Number of env steps total    1610000
Number of rollouts total     0
Train Time (s)               137.63101284205914
(Previous) Eval Time (s)     29.31223239330575
Sample Time (s)              9.989039117936045
Epoch Time (s)               176.93228435330093
Total Train Time (s)         24459.778262368403
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:38:59.371111 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #133 | Epoch Duration: 177.01540637016296
2020-01-13 10:38:59.371325 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2387543
Z variance train             0.06350505
KL Divergence                42.68445
KL Loss                      4.268445
QF Loss                      275.10135
VF Loss                      162.93661
Policy Loss                  -957.7121
Q Predictions Mean           953.9785
Q Predictions Std            1060.7157
Q Predictions Max            3452.0903
Q Predictions Min            339.79303
V Predictions Mean           961.89825
V Predictions Std            1061.8247
V Predictions Max            3483.7297
V Predictions Min            346.99344
Log Pis Mean                 -0.33058307
Log Pis Std                  3.4093664
Log Pis Max                  12.345338
Log Pis Min                  -8.100277
Policy mu Mean               0.07611847
Policy mu Std                0.8729784
Policy mu Max                2.8931103
Policy mu Min                -3.294944
Policy log std Mean          -0.5291233
Policy log std Std           0.22619604
Policy log std Max           -0.16041738
Policy log std Min           -2.092811
Z mean eval                  2.2413545
Z variance eval              0.022229228
total_rewards                [7904.55088415 8000.02114532 8010.14201198 8198.1320224  8112.80465216
 8122.88779088 8034.67789438 7900.88438498 8102.55558142 8093.38537885]
total_rewards_mean           8048.004174652315
total_rewards_std            91.38759297348474
total_rewards_max            8198.132022402573
total_rewards_min            7900.8843849762925
Number of train steps total  540000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               141.5760863511823
(Previous) Eval Time (s)     29.353432320058346
Sample Time (s)              9.755320924334228
Epoch Time (s)               180.68483959557489
Total Train Time (s)         24640.54763538111
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:42:00.143385 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #134 | Epoch Duration: 180.77190923690796
2020-01-13 10:42:00.143576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2419848
Z variance train             0.022164118
KL Divergence                45.35719
KL Loss                      4.535719
QF Loss                      214.8299
VF Loss                      147.26575
Policy Loss                  -1040.247
Q Predictions Mean           1038.0402
Q Predictions Std            1118.1243
Q Predictions Max            3496.8503
Q Predictions Min            357.79395
V Predictions Mean           1036.942
V Predictions Std            1115.7097
V Predictions Max            3477.6257
V Predictions Min            360.81015
Log Pis Mean                 -0.049642127
Log Pis Std                  4.059059
Log Pis Max                  17.762892
Log Pis Min                  -6.6521616
Policy mu Mean               0.082284704
Policy mu Std                0.9043703
Policy mu Max                3.4069586
Policy mu Min                -3.1014822
Policy log std Mean          -0.5142433
Policy log std Std           0.25313857
Policy log std Max           -0.0024974048
Policy log std Min           -2.4505553
Z mean eval                  2.2627861
Z variance eval              0.03895054
total_rewards                [8099.87109516 7901.74002165 7961.09065601 8213.96624676 8040.86151985
 8293.67077079 8213.84473871 8067.24984837 8095.82940948 8230.79382907]
total_rewards_mean           8111.891813586514
total_rewards_std            119.30647022647767
total_rewards_max            8293.67077079333
total_rewards_min            7901.740021653855
Number of train steps total  544000
Number of env steps total    1634000
Number of rollouts total     0
Train Time (s)               148.29791210684925
(Previous) Eval Time (s)     30.361366869416088
Sample Time (s)              10.176583805121481
Epoch Time (s)               188.83586278138682
Total Train Time (s)         24829.461013182532
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:45:09.058884 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #135 | Epoch Duration: 188.91516137123108
2020-01-13 10:45:09.059074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2623343
Z variance train             0.039047852
KL Divergence                44.98422
KL Loss                      4.498422
QF Loss                      147.15765
VF Loss                      84.82121
Policy Loss                  -868.6917
Q Predictions Mean           865.5844
Q Predictions Std            1016.29645
Q Predictions Max            3391.2915
Q Predictions Min            324.7739
V Predictions Mean           863.8078
V Predictions Std            1011.1932
V Predictions Max            3378.2437
V Predictions Min            324.55405
Log Pis Mean                 -0.9975493
Log Pis Std                  3.26175
Log Pis Max                  14.369514
Log Pis Min                  -6.6475754
Policy mu Mean               0.0424099
Policy mu Std                0.8073026
Policy mu Max                2.6989303
Policy mu Min                -2.2366452
Policy log std Mean          -0.48304585
Policy log std Std           0.21865295
Policy log std Max           -0.062424958
Policy log std Min           -1.8774002
Z mean eval                  2.2305307
Z variance eval              0.02695414
total_rewards                [8316.844475   8289.16672765 8565.89481844 8432.72538277 8422.28534991
 8167.92233219 8403.64075487 8306.56819927 8189.51629856 8222.07626107]
total_rewards_mean           8331.664059972303
total_rewards_std            118.38605184462044
total_rewards_max            8565.894818439734
total_rewards_min            8167.922332187777
Number of train steps total  548000
Number of env steps total    1646000
Number of rollouts total     0
Train Time (s)               147.804934122134
(Previous) Eval Time (s)     29.2205831669271
Sample Time (s)              9.466749873943627
Epoch Time (s)               186.49226716300473
Total Train Time (s)         25016.036421648227
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:48:15.637298 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #136 | Epoch Duration: 186.5780589580536
2020-01-13 10:48:15.637614 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #136 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.232759
Z variance train             0.027003402
KL Divergence                45.854023
KL Loss                      4.5854025
QF Loss                      265.92474
VF Loss                      52.41188
Policy Loss                  -840.68445
Q Predictions Mean           840.3934
Q Predictions Std            974.69995
Q Predictions Max            3416.5034
Q Predictions Min            349.60406
V Predictions Mean           837.3015
V Predictions Std            972.443
V Predictions Max            3424.436
V Predictions Min            347.19025
Log Pis Mean                 -0.72055364
Log Pis Std                  3.4878454
Log Pis Max                  14.943825
Log Pis Min                  -5.9655313
Policy mu Mean               0.043547194
Policy mu Std                0.8263264
Policy mu Max                2.6698658
Policy mu Min                -3.0998652
Policy log std Mean          -0.5029783
Policy log std Std           0.23037194
Policy log std Max           -0.109910816
Policy log std Min           -2.0362082
Z mean eval                  2.2184138
Z variance eval              0.02185737
total_rewards                [7682.47228683 7895.34943365 7933.41204112 7820.20262859 8162.4278468
 7817.90711752 7840.64176596 7907.6972473  7812.24095245 7715.15545916]
total_rewards_mean           7858.750677938804
total_rewards_std            126.04295753151969
total_rewards_max            8162.4278468015555
total_rewards_min            7682.472286832342
Number of train steps total  552000
Number of env steps total    1658000
Number of rollouts total     0
Train Time (s)               146.77782084513456
(Previous) Eval Time (s)     30.971691037993878
Sample Time (s)              10.110755920410156
Epoch Time (s)               187.8602678035386
Total Train Time (s)         25203.983751546126
Epoch                        137
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:51:23.587335 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #137 | Epoch Duration: 187.9494867324829
2020-01-13 10:51:23.587654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2223227
Z variance train             0.021829333
KL Divergence                45.533234
KL Loss                      4.5533233
QF Loss                      1685.1869
VF Loss                      76.88954
Policy Loss                  -959.57306
Q Predictions Mean           955.8024
Q Predictions Std            1069.5463
Q Predictions Max            3626.6333
Q Predictions Min            369.36633
V Predictions Mean           959.9254
V Predictions Std            1067.3517
V Predictions Max            3601.6433
V Predictions Min            376.9864
Log Pis Mean                 -0.61820257
Log Pis Std                  3.6565976
Log Pis Max                  10.482538
Log Pis Min                  -8.412802
Policy mu Mean               0.071501635
Policy mu Std                0.85967153
Policy mu Max                2.427768
Policy mu Min                -3.787291
Policy log std Mean          -0.49825034
Policy log std Std           0.25443047
Policy log std Max           -0.10334617
Policy log std Min           -2.4697654
Z mean eval                  2.2030323
Z variance eval              0.02012843
total_rewards                [7753.95985801 8114.35641272 8078.32863705 8127.02543118 8096.90060109
 7839.376919   8217.51946787 8034.78134537 8133.35424102 7953.43756734]
total_rewards_mean           8034.904048066392
total_rewards_std            136.8818562479901
total_rewards_max            8217.5194678746
total_rewards_min            7753.959858008553
Number of train steps total  556000
Number of env steps total    1670000
Number of rollouts total     0
Train Time (s)               146.0535150631331
(Previous) Eval Time (s)     29.622234331909567
Sample Time (s)              10.680300275795162
Epoch Time (s)               186.35604967083782
Total Train Time (s)         25390.41871084692
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:54:30.024101 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #138 | Epoch Duration: 186.4362552165985
2020-01-13 10:54:30.024372 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2030272
Z variance train             0.020085813
KL Divergence                45.674324
KL Loss                      4.5674324
QF Loss                      181.05405
VF Loss                      44.213318
Policy Loss                  -904.63904
Q Predictions Mean           900.9701
Q Predictions Std            1024.3329
Q Predictions Max            3588.182
Q Predictions Min            366.3472
V Predictions Mean           903.1544
V Predictions Std            1021.2892
V Predictions Max            3596.6045
V Predictions Min            376.3716
Log Pis Mean                 -0.76195383
Log Pis Std                  3.1161206
Log Pis Max                  15.532793
Log Pis Min                  -6.646266
Policy mu Mean               0.037660636
Policy mu Std                0.81321603
Policy mu Max                2.687109
Policy mu Min                -3.2212913
Policy log std Mean          -0.51918024
Policy log std Std           0.2367195
Policy log std Max           -0.13080123
Policy log std Min           -2.2262893
Z mean eval                  2.188692
Z variance eval              0.033699844
total_rewards                [8094.25841502 8399.48307159 8132.46259464 8518.03093389 8195.50339183
 8332.02344895 8386.12184945 8241.06213942 8363.69852326 8424.20347961]
total_rewards_mean           8308.684784767524
total_rewards_std            130.15305980263375
total_rewards_max            8518.030933888876
total_rewards_min            8094.258415024421
Number of train steps total  560000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               139.66554106213152
(Previous) Eval Time (s)     29.48345213709399
Sample Time (s)              10.682612034026533
Epoch Time (s)               179.83160523325205
Total Train Time (s)         25570.333674478345
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:57:29.941189 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #139 | Epoch Duration: 179.91662120819092
2020-01-13 10:57:29.941399 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.185077
Z variance train             0.03358511
KL Divergence                44.433517
KL Loss                      4.4433517
QF Loss                      1631.5887
VF Loss                      122.45282
Policy Loss                  -865.50134
Q Predictions Mean           859.8165
Q Predictions Std            963.99133
Q Predictions Max            3481.7114
Q Predictions Min            359.874
V Predictions Mean           865.8188
V Predictions Std            970.0924
V Predictions Max            3489.8652
V Predictions Min            373.6952
Log Pis Mean                 -0.576596
Log Pis Std                  3.249903
Log Pis Max                  14.717731
Log Pis Min                  -6.973957
Policy mu Mean               0.04694088
Policy mu Std                0.82081777
Policy mu Max                3.5345142
Policy mu Min                -2.5150368
Policy log std Mean          -0.5094299
Policy log std Std           0.25841364
Policy log std Max           -0.11281064
Policy log std Min           -2.2652235
Z mean eval                  2.1482954
Z variance eval              0.07059306
total_rewards                [8471.50928183 8263.6547208  8177.42607495 8025.28141723 8179.33415585
 8286.42456559 8153.07762902 8415.63480162 8356.02568068 8058.02019303]
total_rewards_mean           8238.638852058744
total_rewards_std            139.633236663552
total_rewards_max            8471.509281825001
total_rewards_min            8025.281417228427
Number of train steps total  564000
Number of env steps total    1694000
Number of rollouts total     0
Train Time (s)               138.6226914790459
(Previous) Eval Time (s)     28.666053956840187
Sample Time (s)              8.744897747412324
Epoch Time (s)               176.0336431832984
Total Train Time (s)         25746.46199508896
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:00:26.072390 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #140 | Epoch Duration: 176.13080620765686
2020-01-13 11:00:26.072702 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1492968
Z variance train             0.07072438
KL Divergence                42.31694
KL Loss                      4.231694
QF Loss                      257.05084
VF Loss                      94.92305
Policy Loss                  -1006.57306
Q Predictions Mean           1001.1874
Q Predictions Std            1101.5427
Q Predictions Max            3558.1743
Q Predictions Min            358.16623
V Predictions Mean           1003.59656
V Predictions Std            1103.5714
V Predictions Max            3546.2478
V Predictions Min            366.30716
Log Pis Mean                 -0.38647908
Log Pis Std                  3.6629355
Log Pis Max                  12.437338
Log Pis Min                  -8.199776
Policy mu Mean               0.04298391
Policy mu Std                0.87494457
Policy mu Max                2.9445953
Policy mu Min                -3.3016362
Policy log std Mean          -0.5155181
Policy log std Std           0.233676
Policy log std Max           -0.10855231
Policy log std Min           -2.1403918
Z mean eval                  2.1687412
Z variance eval              0.03375037
total_rewards                [7916.72939856 8205.65110638 8444.90926576 8223.74685248 8417.65334063
 8579.34228252 2130.34910722 8341.04550973 8065.78570051 8256.47812814]
total_rewards_mean           7658.169069190471
total_rewards_std            1851.4330571605312
total_rewards_max            8579.342282520893
total_rewards_min            2130.3491072195716
Number of train steps total  568000
Number of env steps total    1706000
Number of rollouts total     0
Train Time (s)               141.61712857102975
(Previous) Eval Time (s)     29.731934366282076
Sample Time (s)              9.711050622165203
Epoch Time (s)               181.06011355947703
Total Train Time (s)         25927.60590399336
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:03:27.218044 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #141 | Epoch Duration: 181.1451609134674
2020-01-13 11:03:27.218237 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1717255
Z variance train             0.033770252
KL Divergence                45.765427
KL Loss                      4.576543
QF Loss                      272.999
VF Loss                      152.81812
Policy Loss                  -1035.7562
Q Predictions Mean           1036.0215
Q Predictions Std            1125.4829
Q Predictions Max            3550.3704
Q Predictions Min            378.8138
V Predictions Mean           1037.3767
V Predictions Std            1114.8871
V Predictions Max            3526.9402
V Predictions Min            389.33932
Log Pis Mean                 0.017832547
Log Pis Std                  3.777489
Log Pis Max                  13.274071
Log Pis Min                  -6.5853105
Policy mu Mean               0.058466837
Policy mu Std                0.8929138
Policy mu Max                2.6412728
Policy mu Min                -2.7223184
Policy log std Mean          -0.511761
Policy log std Std           0.23024018
Policy log std Max           -0.16059543
Policy log std Min           -2.033002
Z mean eval                  2.1734455
Z variance eval              0.018120896
total_rewards                [8341.60203439 8434.77206791 8475.47951262 8207.20816837 8502.34960201
 8541.61621716 8195.23187068 8158.8722167  7974.33941518 8482.62919323]
total_rewards_mean           8331.410029824512
total_rewards_std            178.62170413408398
total_rewards_max            8541.61621715982
total_rewards_min            7974.339415181298
Number of train steps total  572000
Number of env steps total    1718000
Number of rollouts total     0
Train Time (s)               149.00553187727928
(Previous) Eval Time (s)     29.615966683719307
Sample Time (s)              10.348102482035756
Epoch Time (s)               188.96960104303434
Total Train Time (s)         26116.654187864624
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:06:36.269902 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #142 | Epoch Duration: 189.05148649215698
2020-01-13 11:06:36.270286 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1716118
Z variance train             0.018112982
KL Divergence                46.889503
KL Loss                      4.6889505
QF Loss                      108.66034
VF Loss                      42.176464
Policy Loss                  -917.2148
Q Predictions Mean           914.7392
Q Predictions Std            1026.0352
Q Predictions Max            3544.734
Q Predictions Min            380.39587
V Predictions Mean           920.8008
V Predictions Std            1026.6125
V Predictions Max            3547.058
V Predictions Min            392.66992
Log Pis Mean                 -0.89202577
Log Pis Std                  3.0667152
Log Pis Max                  11.075102
Log Pis Min                  -6.596294
Policy mu Mean               0.018273847
Policy mu Std                0.81233454
Policy mu Max                3.253326
Policy mu Min                -2.74833
Policy log std Mean          -0.49143758
Policy log std Std           0.224236
Policy log std Max           -0.13267028
Policy log std Min           -1.9026294
Z mean eval                  2.176345
Z variance eval              0.022573091
total_rewards                [8176.93304521 8327.15727469 8513.29628333 8449.02412729 8317.81218338
 8435.28856656 8349.75240081 8315.25745005 8475.02443027 8348.37919253]
total_rewards_mean           8370.792495410753
total_rewards_std            93.68733778136159
total_rewards_max            8513.296283328234
total_rewards_min            8176.933045214281
Number of train steps total  576000
Number of env steps total    1730000
Number of rollouts total     0
Train Time (s)               147.6482689450495
(Previous) Eval Time (s)     29.95967560634017
Sample Time (s)              10.223689344711602
Epoch Time (s)               187.83163389610127
Total Train Time (s)         26304.56645362079
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:09:44.183474 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #143 | Epoch Duration: 187.91291332244873
2020-01-13 11:09:44.183700 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1787498
Z variance train             0.022561952
KL Divergence                47.308125
KL Loss                      4.7308125
QF Loss                      140.30885
VF Loss                      81.62327
Policy Loss                  -855.3838
Q Predictions Mean           851.1732
Q Predictions Std            966.24005
Q Predictions Max            3559.3552
Q Predictions Min            384.80353
V Predictions Mean           849.1803
V Predictions Std            966.70703
V Predictions Max            3525.5916
V Predictions Min            382.78326
Log Pis Mean                 -0.6547499
Log Pis Std                  3.490593
Log Pis Max                  17.394258
Log Pis Min                  -6.6622286
Policy mu Mean               0.018473836
Policy mu Std                0.8142593
Policy mu Max                2.7029917
Policy mu Min                -3.5589645
Policy log std Mean          -0.49341562
Policy log std Std           0.22853847
Policy log std Max           -0.115179926
Policy log std Min           -2.1738548
Z mean eval                  2.2499185
Z variance eval              0.028241068
total_rewards                [7765.62180704 8004.04515866 8047.95174436 7908.60832345 7876.70410611
 8109.3539122  7926.55068242 7823.0352433  7936.40066621 7835.6893447 ]
total_rewards_mean           7923.396098844775
total_rewards_std            100.91287424689098
total_rewards_max            8109.353912199164
total_rewards_min            7765.621807039343
Number of train steps total  580000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               147.10853546392173
(Previous) Eval Time (s)     30.939175076317042
Sample Time (s)              10.136338997632265
Epoch Time (s)               188.18404953787103
Total Train Time (s)         26492.8372672759
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:12:52.457634 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #144 | Epoch Duration: 188.2737398147583
2020-01-13 11:12:52.458018 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #144 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2469194
Z variance train             0.028144618
KL Divergence                47.29487
KL Loss                      4.729487
QF Loss                      120.347275
VF Loss                      44.02611
Policy Loss                  -945.2226
Q Predictions Mean           944.47925
Q Predictions Std            1066.3464
Q Predictions Max            3571.8738
Q Predictions Min            397.65732
V Predictions Mean           943.78864
V Predictions Std            1062.8496
V Predictions Max            3542.303
V Predictions Min            393.83026
Log Pis Mean                 -0.6736293
Log Pis Std                  3.3001277
Log Pis Max                  10.797032
Log Pis Min                  -6.461631
Policy mu Mean               0.006950704
Policy mu Std                0.82083994
Policy mu Max                3.5443857
Policy mu Min                -3.2741888
Policy log std Mean          -0.49904677
Policy log std Std           0.22338507
Policy log std Max           -0.12269206
Policy log std Min           -1.8185148
Z mean eval                  2.1668143
Z variance eval              0.034760572
total_rewards                [7795.34503475 8159.70861641 7913.48361879 7797.1608207  7764.715437
 8208.39650026 8207.75385941 7954.99317465 7676.50912748 8025.87969631]
total_rewards_mean           7950.394588575511
total_rewards_std            184.58159605662226
total_rewards_max            8208.39650025795
total_rewards_min            7676.509127478919
Number of train steps total  584000
Number of env steps total    1754000
Number of rollouts total     0
Train Time (s)               146.72189998207614
(Previous) Eval Time (s)     29.47909742873162
Sample Time (s)              10.066885977983475
Epoch Time (s)               186.26788338879123
Total Train Time (s)         26679.18685878953
Epoch                        145
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:15:58.810062 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #145 | Epoch Duration: 186.35174989700317
2020-01-13 11:15:58.810370 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.16067
Z variance train             0.03491925
KL Divergence                46.195908
KL Loss                      4.6195908
QF Loss                      108.560165
VF Loss                      137.05289
Policy Loss                  -978.1629
Q Predictions Mean           977.0746
Q Predictions Std            1067.9042
Q Predictions Max            3518.857
Q Predictions Min            393.68115
V Predictions Mean           980.699
V Predictions Std            1073.6798
V Predictions Max            3514.9055
V Predictions Min            394.637
Log Pis Mean                 -0.44817752
Log Pis Std                  3.6176713
Log Pis Max                  15.72006
Log Pis Min                  -7.287092
Policy mu Mean               0.08802574
Policy mu Std                0.8803269
Policy mu Max                2.750769
Policy mu Min                -2.962512
Policy log std Mean          -0.49383286
Policy log std Std           0.23356396
Policy log std Max           -0.103658274
Policy log std Min           -2.1011124
Z mean eval                  2.2152634
Z variance eval              0.054644138
total_rewards                [6854.47414647 7718.51505692 7766.08154682 7252.39962001 7877.23409471
 7423.29879081 7468.40955098 7946.98993338 7893.06971649 7595.97527202]
total_rewards_mean           7579.644772862206
total_rewards_std            323.3924158879938
total_rewards_max            7946.989933384826
total_rewards_min            6854.474146472708
Number of train steps total  588000
Number of env steps total    1766000
Number of rollouts total     0
Train Time (s)               138.68886513682082
(Previous) Eval Time (s)     28.269139660988003
Sample Time (s)              9.371137093752623
Epoch Time (s)               176.32914189156145
Total Train Time (s)         26855.595317708794
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:18:55.219836 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #146 | Epoch Duration: 176.4092779159546
2020-01-13 11:18:55.220053 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2085633
Z variance train             0.05450545
KL Divergence                45.15218
KL Loss                      4.5152183
QF Loss                      188.5307
VF Loss                      127.48637
Policy Loss                  -992.61224
Q Predictions Mean           989.46295
Q Predictions Std            1100.0321
Q Predictions Max            3502.4219
Q Predictions Min            389.97638
V Predictions Mean           997.8947
V Predictions Std            1103.971
V Predictions Max            3529.1755
V Predictions Min            395.58096
Log Pis Mean                 -0.44736385
Log Pis Std                  3.5215902
Log Pis Max                  10.425259
Log Pis Min                  -5.7723255
Policy mu Mean               0.06753543
Policy mu Std                0.8427409
Policy mu Max                2.6122077
Policy mu Min                -2.678588
Policy log std Mean          -0.4852033
Policy log std Std           0.24644853
Policy log std Max           -0.0941357
Policy log std Min           -2.0046868
Z mean eval                  2.205701
Z variance eval              0.026103502
total_rewards                [8118.04190141 8176.71715112 8330.86549354 8249.32542379 8198.26870886
 8225.41651062 8092.53184116 8364.01192446 8430.05040504 8372.84030672]
total_rewards_mean           8255.806966671895
total_rewards_std            108.42928290616615
total_rewards_max            8430.050405044627
total_rewards_min            8092.531841158328
Number of train steps total  592000
Number of env steps total    1778000
Number of rollouts total     0
Train Time (s)               138.26249262178317
(Previous) Eval Time (s)     28.797908112872392
Sample Time (s)              9.548860437702388
Epoch Time (s)               176.60926117235795
Total Train Time (s)         27032.28604117129
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:21:51.915416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #147 | Epoch Duration: 176.6951413154602
2020-01-13 11:21:51.915769 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.206962
Z variance train             0.02603669
KL Divergence                48.490204
KL Loss                      4.8490205
QF Loss                      198.23404
VF Loss                      143.72153
Policy Loss                  -918.561
Q Predictions Mean           914.1483
Q Predictions Std            1017.66986
Q Predictions Max            3582.7717
Q Predictions Min            394.85
V Predictions Mean           916.2964
V Predictions Std            1013.29675
V Predictions Max            3538.5464
V Predictions Min            400.25714
Log Pis Mean                 -0.6952983
Log Pis Std                  3.5611858
Log Pis Max                  11.727971
Log Pis Min                  -7.294753
Policy mu Mean               -0.00819838
Policy mu Std                0.8318244
Policy mu Max                2.7766924
Policy mu Min                -2.5570283
Policy log std Mean          -0.51063573
Policy log std Std           0.24416886
Policy log std Max           -0.11204159
Policy log std Min           -2.0376244
Z mean eval                  2.102614
Z variance eval              0.12778005
total_rewards                [8220.51675014 7708.9953958  8407.85243674 8496.50574242 8348.34114174
 8580.75973488 8438.00771009 8386.58781971 8476.5118092  8645.30401626]
total_rewards_mean           8370.938255698882
total_rewards_std            247.71477118065107
total_rewards_max            8645.304016260541
total_rewards_min            7708.995395797754
Number of train steps total  596000
Number of env steps total    1790000
Number of rollouts total     0
Train Time (s)               142.27736702328548
(Previous) Eval Time (s)     30.32547368714586
Sample Time (s)              8.94315970968455
Epoch Time (s)               181.5460004201159
Total Train Time (s)         27213.925034072716
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:24:53.554449 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #148 | Epoch Duration: 181.6384313106537
2020-01-13 11:24:53.554651 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1055434
Z variance train             0.1276926
KL Divergence                43.35855
KL Loss                      4.335855
QF Loss                      245.03069
VF Loss                      133.3502
Policy Loss                  -843.82574
Q Predictions Mean           838.3596
Q Predictions Std            951.2645
Q Predictions Max            3415.147
Q Predictions Min            362.89038
V Predictions Mean           836.0829
V Predictions Std            948.92676
V Predictions Max            3406.9856
V Predictions Min            368.63504
Log Pis Mean                 -0.4627629
Log Pis Std                  3.396911
Log Pis Max                  11.131153
Log Pis Min                  -8.456253
Policy mu Mean               0.030740852
Policy mu Std                0.8462595
Policy mu Max                3.013537
Policy mu Min                -2.5468633
Policy log std Mean          -0.5043103
Policy log std Std           0.24886185
Policy log std Max           -0.070535004
Policy log std Min           -2.292109
Z mean eval                  2.1960814
Z variance eval              0.032143585
total_rewards                [8130.69564892 7992.32624735 8494.04130584 8434.84662175 8534.9343467
 8520.89829893 8410.87701062 8670.99474364 8377.5060921  8581.31991075]
total_rewards_mean           8414.844022659769
total_rewards_std            196.55542456053303
total_rewards_max            8670.994743636002
total_rewards_min            7992.326247348571
Number of train steps total  600000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               149.33736945083365
(Previous) Eval Time (s)     28.090297194197774
Sample Time (s)              10.196435452438891
Epoch Time (s)               187.6241020974703
Total Train Time (s)         27401.722536771093
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:28:01.354378 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #149 | Epoch Duration: 187.79957175254822
2020-01-13 11:28:01.354586 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1945271
Z variance train             0.03191274
KL Divergence                46.25786
KL Loss                      4.625786
QF Loss                      775.32556
VF Loss                      194.0231
Policy Loss                  -1002.09247
Q Predictions Mean           1004.39404
Q Predictions Std            1093.3777
Q Predictions Max            3574.0425
Q Predictions Min            387.03534
V Predictions Mean           1013.29126
V Predictions Std            1091.8798
V Predictions Max            3568.6072
V Predictions Min            397.01248
Log Pis Mean                 -0.41965052
Log Pis Std                  3.5642405
Log Pis Max                  11.715264
Log Pis Min                  -8.099316
Policy mu Mean               0.051492024
Policy mu Std                0.87209743
Policy mu Max                2.5454862
Policy mu Min                -2.6318808
Policy log std Mean          -0.50167084
Policy log std Std           0.22551638
Policy log std Max           -0.06813264
Policy log std Min           -1.9083257
Z mean eval                  2.155246
Z variance eval              0.022399625
total_rewards                [8607.36041003 8807.65818939 8801.42298653 8698.43524751 8681.8746652
 8867.81971521 8935.86526514 8760.13301041 8472.16116383 8897.46557614]
total_rewards_mean           8753.019622938536
total_rewards_std            134.53409296513925
total_rewards_max            8935.865265144022
total_rewards_min            8472.161163832285
Number of train steps total  604000
Number of env steps total    1814000
Number of rollouts total     0
Train Time (s)               147.3363598510623
(Previous) Eval Time (s)     29.879186275880784
Sample Time (s)              10.248502959962934
Epoch Time (s)               187.46404908690602
Total Train Time (s)         27589.281292010564
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:31:08.915377 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #150 | Epoch Duration: 187.56063532829285
2020-01-13 11:31:08.915570 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1547155
Z variance train             0.022518836
KL Divergence                47.404297
KL Loss                      4.74043
QF Loss                      256.48688
VF Loss                      75.91529
Policy Loss                  -992.201
Q Predictions Mean           991.39526
Q Predictions Std            1099.2003
Q Predictions Max            3692.956
Q Predictions Min            417.94598
V Predictions Mean           993.89825
V Predictions Std            1102.1956
V Predictions Max            3700.8477
V Predictions Min            390.35043
Log Pis Mean                 -0.1663377
Log Pis Std                  4.0353765
Log Pis Max                  16.229597
Log Pis Min                  -5.8489585
Policy mu Mean               0.044575855
Policy mu Std                0.8793151
Policy mu Max                3.2494922
Policy mu Min                -2.700223
Policy log std Mean          -0.52686363
Policy log std Std           0.2522707
Policy log std Max           -0.09054983
Policy log std Min           -2.124131
Z mean eval                  2.1817386
Z variance eval              0.03514453
total_rewards                [8262.8706516  8461.60993809 8764.34912284 8540.09214642 8610.60387473
 8531.48604987 8409.32708409 8607.79765021 8705.11446669 8719.97741647]
total_rewards_mean           8561.322840100105
total_rewards_std            146.66818475925425
total_rewards_max            8764.349122837319
total_rewards_min            8262.870651604255
Number of train steps total  608000
Number of env steps total    1826000
Number of rollouts total     0
Train Time (s)               147.80432791402563
(Previous) Eval Time (s)     30.34348106570542
Sample Time (s)              10.242589383386075
Epoch Time (s)               188.39039836311713
Total Train Time (s)         27777.777761233505
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:34:17.413075 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #151 | Epoch Duration: 188.4973738193512
2020-01-13 11:34:17.413226 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1868093
Z variance train             0.034972716
KL Divergence                47.25806
KL Loss                      4.725806
QF Loss                      1982.8296
VF Loss                      108.704636
Policy Loss                  -937.9909
Q Predictions Mean           935.67535
Q Predictions Std            1040.4353
Q Predictions Max            3667.7405
Q Predictions Min            415.29492
V Predictions Mean           932.8441
V Predictions Std            1036.8679
V Predictions Max            3650.461
V Predictions Min            415.92593
Log Pis Mean                 -0.092122495
Log Pis Std                  3.5978491
Log Pis Max                  12.7207365
Log Pis Min                  -7.3469033
Policy mu Mean               0.07749698
Policy mu Std                0.866819
Policy mu Max                2.6699462
Policy mu Min                -2.5000176
Policy log std Mean          -0.49992618
Policy log std Std           0.23620218
Policy log std Max           -0.10484932
Policy log std Min           -2.0615244
Z mean eval                  2.2023687
Z variance eval              0.044835307
total_rewards                [8220.69048737 8560.07784312 8437.26827609 8471.46673781 8374.44825901
 8577.26336653 8525.18554398 8535.38984726 8705.56751349 8511.38649901]
total_rewards_mean           8491.874437367327
total_rewards_std            123.17450831486124
total_rewards_max            8705.567513493192
total_rewards_min            8220.690487370637
Number of train steps total  612000
Number of env steps total    1838000
Number of rollouts total     0
Train Time (s)               148.04452622309327
(Previous) Eval Time (s)     29.118592251092196
Sample Time (s)              9.33984117442742
Epoch Time (s)               186.5029596486129
Total Train Time (s)         27964.357852202374
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:37:23.996464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #152 | Epoch Duration: 186.58311009407043
2020-01-13 11:37:23.996675 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2060943
Z variance train             0.04463592
KL Divergence                46.811844
KL Loss                      4.6811843
QF Loss                      181.62057
VF Loss                      43.599487
Policy Loss                  -982.5604
Q Predictions Mean           981.80725
Q Predictions Std            1096.9316
Q Predictions Max            3747.7546
Q Predictions Min            423.6278
V Predictions Mean           983.92346
V Predictions Std            1094.0532
V Predictions Max            3710.9856
V Predictions Min            428.91013
Log Pis Mean                 -0.82850885
Log Pis Std                  3.372351
Log Pis Max                  12.322427
Log Pis Min                  -7.001683
Policy mu Mean               -0.011787762
Policy mu Std                0.82584757
Policy mu Max                3.1993186
Policy mu Min                -2.8255088
Policy log std Mean          -0.4845331
Policy log std Std           0.22063337
Policy log std Max           -0.12245214
Policy log std Min           -1.8984147
Z mean eval                  2.1854167
Z variance eval              0.03947995
total_rewards                [8476.67459235 8779.37246379 8450.33586675 9039.24537163 8679.18961989
 8741.95118168 8710.46935242 8769.86780349 8745.24072343 8594.23972217]
total_rewards_mean           8698.658669758594
total_rewards_std            159.3712288778828
total_rewards_max            9039.24537163152
total_rewards_min            8450.335866746138
Number of train steps total  616000
Number of env steps total    1850000
Number of rollouts total     0
Train Time (s)               139.03246581507847
(Previous) Eval Time (s)     28.980010621715337
Sample Time (s)              9.779454745352268
Epoch Time (s)               177.79193118214607
Total Train Time (s)         28142.24498588359
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:40:21.886301 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #153 | Epoch Duration: 177.88947081565857
2020-01-13 11:40:21.886514 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1830328
Z variance train             0.039579898
KL Divergence                47.93748
KL Loss                      4.7937484
QF Loss                      639.4772
VF Loss                      101.40291
Policy Loss                  -1034.8179
Q Predictions Mean           1032.1671
Q Predictions Std            1111.3291
Q Predictions Max            3729.31
Q Predictions Min            398.50317
V Predictions Mean           1040.5721
V Predictions Std            1116.2089
V Predictions Max            3747.5032
V Predictions Min            404.65588
Log Pis Mean                 -0.4237611
Log Pis Std                  3.8210914
Log Pis Max                  13.990115
Log Pis Min                  -8.398929
Policy mu Mean               0.06511638
Policy mu Std                0.8804356
Policy mu Max                3.1477387
Policy mu Min                -2.9513342
Policy log std Mean          -0.5017607
Policy log std Std           0.2612086
Policy log std Max           -0.102843165
Policy log std Min           -2.5016274
Z mean eval                  2.1402385
Z variance eval              0.029461423
total_rewards                [7460.50964465 7670.66853423 7396.00577156 7274.7702716  7483.27715655
 7723.28405145 7401.4778014  7584.5914216  7272.71692133 7382.41545989]
total_rewards_mean           7464.971703425303
total_rewards_std            145.7539455774119
total_rewards_max            7723.284051450611
total_rewards_min            7272.716921329067
Number of train steps total  620000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               138.7877790192142
(Previous) Eval Time (s)     29.494442731142044
Sample Time (s)              9.71515161730349
Epoch Time (s)               177.99737336765975
Total Train Time (s)         28320.332520689815
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:43:19.976148 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #154 | Epoch Duration: 178.0894799232483
2020-01-13 11:43:19.976369 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1396544
Z variance train             0.029382577
KL Divergence                48.257942
KL Loss                      4.825794
QF Loss                      104.7632
VF Loss                      76.090034
Policy Loss                  -956.5761
Q Predictions Mean           955.19165
Q Predictions Std            1062.946
Q Predictions Max            3762.3535
Q Predictions Min            420.196
V Predictions Mean           960.42303
V Predictions Std            1064.8745
V Predictions Max            3758.3467
V Predictions Min            427.48312
Log Pis Mean                 -0.65334487
Log Pis Std                  3.725331
Log Pis Max                  14.085333
Log Pis Min                  -6.9621763
Policy mu Mean               0.14456354
Policy mu Std                0.8585484
Policy mu Max                2.8113418
Policy mu Min                -2.8405418
Policy log std Mean          -0.4775673
Policy log std Std           0.22460005
Policy log std Max           -0.092613965
Policy log std Min           -1.850003
Z mean eval                  2.1248848
Z variance eval              0.027565112
total_rewards                [8279.18580107 8287.97668422 8666.52930888 8499.38551141 8696.84463524
 8770.27692608 8615.47956094 8579.193668   8701.23568385 8547.83225433]
total_rewards_mean           8564.394003401187
total_rewards_std            159.4263550062697
total_rewards_max            8770.276926083556
total_rewards_min            8279.185801065145
Number of train steps total  624000
Number of env steps total    1874000
Number of rollouts total     0
Train Time (s)               144.46016362681985
(Previous) Eval Time (s)     30.379987614694983
Sample Time (s)              9.718787060119212
Epoch Time (s)               184.55893830163404
Total Train Time (s)         28504.971292742994
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:46:24.616861 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #155 | Epoch Duration: 184.6403408050537
2020-01-13 11:46:24.617050 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.127646
Z variance train             0.0276617
KL Divergence                49.039196
KL Loss                      4.9039197
QF Loss                      120.23288
VF Loss                      53.347874
Policy Loss                  -957.4368
Q Predictions Mean           956.4235
Q Predictions Std            1062.9421
Q Predictions Max            3670.1978
Q Predictions Min            423.72787
V Predictions Mean           961.8767
V Predictions Std            1060.3633
V Predictions Max            3654.935
V Predictions Min            430.4898
Log Pis Mean                 -0.6219578
Log Pis Std                  3.552361
Log Pis Max                  12.152086
Log Pis Min                  -10.418669
Policy mu Mean               0.05757178
Policy mu Std                0.8665121
Policy mu Max                2.5921223
Policy mu Min                -2.8131833
Policy log std Mean          -0.4722687
Policy log std Std           0.21534915
Policy log std Max           -0.11196807
Policy log std Min           -1.9895319
Z mean eval                  2.114313
Z variance eval              0.045393478
total_rewards                [8528.81439481 8811.29682797 8802.19168307 8585.75707285 8755.91336019
 8386.51704653 8481.94388083 8514.41777361 8608.89702594 8526.13313973]
total_rewards_mean           8600.188220552642
total_rewards_std            136.922863494649
total_rewards_max            8811.296827969563
total_rewards_min            8386.517046532268
Number of train steps total  628000
Number of env steps total    1886000
Number of rollouts total     0
Train Time (s)               148.61310618184507
(Previous) Eval Time (s)     29.862470478750765
Sample Time (s)              10.408858647104353
Epoch Time (s)               188.8844353077002
Total Train Time (s)         28693.941311164293
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:49:33.589495 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #156 | Epoch Duration: 188.9722979068756
2020-01-13 11:49:33.589701 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1171176
Z variance train             0.04585295
KL Divergence                48.5512
KL Loss                      4.85512
QF Loss                      106.99804
VF Loss                      126.66464
Policy Loss                  -955.689
Q Predictions Mean           952.1184
Q Predictions Std            1045.0936
Q Predictions Max            3660.8723
Q Predictions Min            424.3985
V Predictions Mean           956.6178
V Predictions Std            1047.4104
V Predictions Max            3660.3303
V Predictions Min            427.03137
Log Pis Mean                 -0.5165478
Log Pis Std                  3.7175944
Log Pis Max                  14.841507
Log Pis Min                  -7.3378897
Policy mu Mean               0.029712193
Policy mu Std                0.84549093
Policy mu Max                3.2281477
Policy mu Min                -3.241565
Policy log std Mean          -0.49266252
Policy log std Std           0.23431638
Policy log std Max           -0.102323264
Policy log std Min           -2.0229764
Z mean eval                  2.149187
Z variance eval              0.042993844
total_rewards                [8282.98240833 8667.30176043 8425.43399938 8341.45286498 8790.80728978
 8804.43525717 8661.44908625 8684.53993453 8734.29557902 8555.50871255]
total_rewards_mean           8594.820689240383
total_rewards_std            176.4143705965199
total_rewards_max            8804.435257166075
total_rewards_min            8282.982408325952
Number of train steps total  632000
Number of env steps total    1898000
Number of rollouts total     0
Train Time (s)               147.76119852624834
(Previous) Eval Time (s)     30.36403524596244
Sample Time (s)              10.12054289598018
Epoch Time (s)               188.24577666819096
Total Train Time (s)         28882.267989005893
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:52:41.919982 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #157 | Epoch Duration: 188.33009243011475
2020-01-13 11:52:41.920371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1423697
Z variance train             0.043072052
KL Divergence                48.911617
KL Loss                      4.891162
QF Loss                      1911.1869
VF Loss                      35.46434
Policy Loss                  -1033.8604
Q Predictions Mean           1038.2355
Q Predictions Std            1130.2196
Q Predictions Max            3715.772
Q Predictions Min            432.3995
V Predictions Mean           1033.136
V Predictions Std            1126.3965
V Predictions Max            3693.2556
V Predictions Min            430.75012
Log Pis Mean                 -0.48902404
Log Pis Std                  3.5732906
Log Pis Max                  12.321733
Log Pis Min                  -6.528973
Policy mu Mean               0.029267281
Policy mu Std                0.8571983
Policy mu Max                2.8353326
Policy mu Min                -2.447666
Policy log std Mean          -0.487558
Policy log std Std           0.23550117
Policy log std Max           -0.117170736
Policy log std Min           -2.3037312
Z mean eval                  2.0993862
Z variance eval              0.07513456
total_rewards                [8414.39409768 8994.42638068 8935.80223142 8956.01389585 8936.84634674
 8887.64648043 9005.63483749 8798.58253418 9055.57127066 8965.24043398]
total_rewards_mean           8895.015850911208
total_rewards_std            173.29558305956954
total_rewards_max            9055.571270660357
total_rewards_min            8414.394097678542
Number of train steps total  636000
Number of env steps total    1910000
Number of rollouts total     0
Train Time (s)               148.90919490205124
(Previous) Eval Time (s)     29.320739227347076
Sample Time (s)              10.120643921662122
Epoch Time (s)               188.35057805106044
Total Train Time (s)         29070.702752627898
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:55:50.362275 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #158 | Epoch Duration: 188.44164109230042
2020-01-13 11:55:50.362664 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1019769
Z variance train             0.07486199
KL Divergence                47.4388
KL Loss                      4.7438803
QF Loss                      131.62767
VF Loss                      78.35807
Policy Loss                  -1018.49115
Q Predictions Mean           1016.4502
Q Predictions Std            1107.6648
Q Predictions Max            3741.8596
Q Predictions Min            434.1249
V Predictions Mean           1019.6417
V Predictions Std            1101.7777
V Predictions Max            3705.251
V Predictions Min            432.8506
Log Pis Mean                 -0.718588
Log Pis Std                  3.554472
Log Pis Max                  12.983827
Log Pis Min                  -6.1694045
Policy mu Mean               0.007900869
Policy mu Std                0.84985924
Policy mu Max                3.490955
Policy mu Min                -2.9115243
Policy log std Mean          -0.48373973
Policy log std Std           0.24873488
Policy log std Max           -0.11668843
Policy log std Min           -2.4860635
Z mean eval                  2.0359313
Z variance eval              0.15866081
total_rewards                [8494.1391949  8796.14142386 8609.37908591 8732.12775843 8994.61255993
 8568.5641419  8537.20241142 8731.41484327 8701.62179888 8697.27344177]
total_rewards_mean           8686.247666027042
total_rewards_std            138.0387182396435
total_rewards_max            8994.612559928646
total_rewards_min            8494.139194901523
Number of train steps total  640000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               146.56379760801792
(Previous) Eval Time (s)     29.410056767053902
Sample Time (s)              10.108592167962343
Epoch Time (s)               186.08244654303417
Total Train Time (s)         29256.885088548996
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:58:56.540560 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #159 | Epoch Duration: 186.1775677204132
2020-01-13 11:58:56.540780 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.038518
Z variance train             0.15851434
KL Divergence                43.32673
KL Loss                      4.332673
QF Loss                      236.57748
VF Loss                      97.11302
Policy Loss                  -1056.7646
Q Predictions Mean           1054.6855
Q Predictions Std            1112.8207
Q Predictions Max            3770.092
Q Predictions Min            449.99716
V Predictions Mean           1057.4009
V Predictions Std            1115.8022
V Predictions Max            3763.8777
V Predictions Min            444.22662
Log Pis Mean                 -0.2331002
Log Pis Std                  4.0263195
Log Pis Max                  17.49754
Log Pis Min                  -7.0812306
Policy mu Mean               0.033255104
Policy mu Std                0.88721377
Policy mu Max                2.8004773
Policy mu Min                -3.2599444
Policy log std Mean          -0.4961891
Policy log std Std           0.2713414
Policy log std Max           -0.0758504
Policy log std Min           -2.1955829
Z mean eval                  2.088977
Z variance eval              0.052288257
total_rewards                [ 872.14177753 8472.07508144 8565.92208946 8570.56069249 8521.31552799
 8532.05627957 8516.28831067 8647.01374244 8282.41485526 8672.34595283]
total_rewards_mean           7765.213430967779
total_rewards_std            2299.9047611812316
total_rewards_max            8672.345952828644
total_rewards_min            872.1417775318987
Number of train steps total  644000
Number of env steps total    1934000
Number of rollouts total     0
Train Time (s)               139.19680281635374
(Previous) Eval Time (s)     29.47788847517222
Sample Time (s)              10.102482394780964
Epoch Time (s)               178.77717368630692
Total Train Time (s)         29435.74489072524
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:01:55.403155 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #160 | Epoch Duration: 178.86221027374268
2020-01-13 12:01:55.403509 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0907037
Z variance train             0.052385516
KL Divergence                47.517445
KL Loss                      4.7517447
QF Loss                      196.12802
VF Loss                      68.12969
Policy Loss                  -1187.8673
Q Predictions Mean           1186.1699
Q Predictions Std            1223.6632
Q Predictions Max            3783.9285
Q Predictions Min            450.96832
V Predictions Mean           1185.8989
V Predictions Std            1218.7838
V Predictions Max            3774.3684
V Predictions Min            455.77518
Log Pis Mean                 -0.2771459
Log Pis Std                  3.905691
Log Pis Max                  12.35335
Log Pis Min                  -8.542013
Policy mu Mean               0.032076564
Policy mu Std                0.8934086
Policy mu Max                2.7043915
Policy mu Min                -2.9539065
Policy log std Mean          -0.48482463
Policy log std Std           0.25277996
Policy log std Max           -0.06858444
Policy log std Min           -2.7407053
Z mean eval                  2.0936055
Z variance eval              0.06686712
total_rewards                [8611.32901492 8504.17820141 8521.08869644 8574.76214874 8259.36465904
 8491.60458181 8380.13546023 8553.0191832  8198.45383683 8483.37975183]
total_rewards_mean           8457.731553444519
total_rewards_std            129.205346795666
total_rewards_max            8611.32901491626
total_rewards_min            8198.453836832692
Number of train steps total  648000
Number of env steps total    1946000
Number of rollouts total     0
Train Time (s)               138.11878685979173
(Previous) Eval Time (s)     29.07811583392322
Sample Time (s)              9.654133355244994
Epoch Time (s)               176.85103604895994
Total Train Time (s)         29612.74193705665
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:52.404166 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #161 | Epoch Duration: 177.0005190372467
2020-01-13 12:04:52.404297 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.092524
Z variance train             0.06706377
KL Divergence                48.18185
KL Loss                      4.8181853
QF Loss                      143.26582
VF Loss                      45.129936
Policy Loss                  -1040.7449
Q Predictions Mean           1040.3982
Q Predictions Std            1130.6501
Q Predictions Max            3728.0435
Q Predictions Min            446.6929
V Predictions Mean           1037.3105
V Predictions Std            1126.7078
V Predictions Max            3719.5122
V Predictions Min            446.99216
Log Pis Mean                 -0.41796237
Log Pis Std                  3.4052596
Log Pis Max                  12.762218
Log Pis Min                  -8.659999
Policy mu Mean               0.07660728
Policy mu Std                0.8789874
Policy mu Max                2.921904
Policy mu Min                -2.8081465
Policy log std Mean          -0.49949923
Policy log std Std           0.24428444
Policy log std Max           -0.11676003
Policy log std Min           -2.192954
Z mean eval                  2.0813148
Z variance eval              0.034179825
total_rewards                [8626.3044334  8781.15844789 8574.01519872 8868.33608389 8772.92516082
 8688.74247587 8685.54100629 8909.23153121 8721.08969443 8669.31765003]
total_rewards_mean           8729.66616825309
total_rewards_std            99.11811690845755
total_rewards_max            8909.231531208652
total_rewards_min            8574.015198720972
Number of train steps total  652000
Number of env steps total    1958000
Number of rollouts total     0
Train Time (s)               146.35174747090787
(Previous) Eval Time (s)     30.569273192901164
Sample Time (s)              9.372865123208612
Epoch Time (s)               186.29388578701764
Total Train Time (s)         29799.12605552608
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:07:58.793694 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #162 | Epoch Duration: 186.38920426368713
2020-01-13 12:07:58.794071 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0804863
Z variance train             0.03419448
KL Divergence                50.39032
KL Loss                      5.039032
QF Loss                      118.69335
VF Loss                      101.9218
Policy Loss                  -1018.22284
Q Predictions Mean           1016.0299
Q Predictions Std            1092.7087
Q Predictions Max            3774.8235
Q Predictions Min            436.17014
V Predictions Mean           1018.8371
V Predictions Std            1092.9938
V Predictions Max            3780.468
V Predictions Min            445.99518
Log Pis Mean                 -0.4794345
Log Pis Std                  3.8801067
Log Pis Max                  15.348597
Log Pis Min                  -7.6340714
Policy mu Mean               0.10174144
Policy mu Std                0.86293733
Policy mu Max                3.2753627
Policy mu Min                -3.2078245
Policy log std Mean          -0.48254827
Policy log std Std           0.2439983
Policy log std Max           -0.07415205
Policy log std Min           -2.3840494
Z mean eval                  2.080271
Z variance eval              0.044998292
total_rewards                [8482.57132657 8755.24359321 8570.02004013 8699.49387683 8641.38570555
 9132.20363051 9019.37561403 8729.67898742 8636.35691457 8823.0660457 ]
total_rewards_mean           8748.939573452399
total_rewards_std            188.56941508499602
total_rewards_max            9132.203630510576
total_rewards_min            8482.571326570614
Number of train steps total  656000
Number of env steps total    1970000
Number of rollouts total     0
Train Time (s)               147.44083258556202
(Previous) Eval Time (s)     30.815295004751533
Sample Time (s)              10.51669149659574
Epoch Time (s)               188.7728190869093
Total Train Time (s)         29987.98277012864
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:11:07.651885 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #163 | Epoch Duration: 188.85756492614746
2020-01-13 12:11:07.652111 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0788012
Z variance train             0.044786803
KL Divergence                50.523678
KL Loss                      5.0523677
QF Loss                      189.00824
VF Loss                      62.05076
Policy Loss                  -1074.9923
Q Predictions Mean           1072.2725
Q Predictions Std            1128.38
Q Predictions Max            3768.2617
Q Predictions Min            441.76245
V Predictions Mean           1070.5956
V Predictions Std            1126.8524
V Predictions Max            3763.9702
V Predictions Min            441.331
Log Pis Mean                 -0.58906305
Log Pis Std                  3.7530127
Log Pis Max                  17.239937
Log Pis Min                  -6.8967333
Policy mu Mean               0.065567635
Policy mu Std                0.8683863
Policy mu Max                3.1504638
Policy mu Min                -2.958657
Policy log std Mean          -0.47259292
Policy log std Std           0.25310633
Policy log std Max           -0.074973226
Policy log std Min           -2.5040793
Z mean eval                  2.065192
Z variance eval              0.029512847
total_rewards                [8728.60839423 9123.88031343 8785.49767038 8996.59719434 8833.21091745
 9029.57233837 8751.51379763 9073.9180536  9094.66433892 9133.16273314]
total_rewards_mean           8955.062575148075
total_rewards_std            154.08597792893508
total_rewards_max            9133.16273313538
total_rewards_min            8728.608394225766
Number of train steps total  660000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               147.34508167533204
(Previous) Eval Time (s)     30.548857225105166
Sample Time (s)              10.322490381542593
Epoch Time (s)               188.2164292819798
Total Train Time (s)         30176.30661080405
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:14:15.978847 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #164 | Epoch Duration: 188.3265643119812
2020-01-13 12:14:15.979074 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0653358
Z variance train             0.029497555
KL Divergence                51.008327
KL Loss                      5.100833
QF Loss                      192.37903
VF Loss                      24.635382
Policy Loss                  -985.9562
Q Predictions Mean           987.50104
Q Predictions Std            1060.8931
Q Predictions Max            3839.9624
Q Predictions Min            407.3807
V Predictions Mean           986.5171
V Predictions Std            1060.9158
V Predictions Max            3829.36
V Predictions Min            375.559
Log Pis Mean                 -0.510213
Log Pis Std                  3.4253006
Log Pis Max                  11.3540125
Log Pis Min                  -7.5761433
Policy mu Mean               0.05341028
Policy mu Std                0.83715177
Policy mu Max                2.504739
Policy mu Min                -2.6280622
Policy log std Mean          -0.47995055
Policy log std Std           0.25422564
Policy log std Max           -0.11248653
Policy log std Min           -2.632633
Z mean eval                  2.0572486
Z variance eval              0.027313525
total_rewards                [8414.4886776  8357.18391078 8107.50615249 8328.22705949 8267.37140704
 8452.60861146 8560.04222005 8218.24790022 8492.55711032 8336.54437556]
total_rewards_mean           8353.477742499992
total_rewards_std            127.55497765967962
total_rewards_max            8560.04222004893
total_rewards_min            8107.506152487046
Number of train steps total  664000
Number of env steps total    1994000
Number of rollouts total     0
Train Time (s)               149.34385490324348
(Previous) Eval Time (s)     29.38843216560781
Sample Time (s)              10.336214213632047
Epoch Time (s)               189.06850128248334
Total Train Time (s)         30365.456127294805
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:17:25.130935 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #165 | Epoch Duration: 189.14977288246155
2020-01-13 12:17:25.131371 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0592177
Z variance train             0.027386133
KL Divergence                51.509186
KL Loss                      5.1509185
QF Loss                      243.35056
VF Loss                      152.94676
Policy Loss                  -1169.4037
Q Predictions Mean           1169.5459
Q Predictions Std            1197.1067
Q Predictions Max            3846.7192
Q Predictions Min            458.2905
V Predictions Mean           1165.673
V Predictions Std            1197.1488
V Predictions Max            3845.6072
V Predictions Min            455.76926
Log Pis Mean                 -0.38107604
Log Pis Std                  4.040452
Log Pis Max                  14.450258
Log Pis Min                  -6.8665442
Policy mu Mean               0.070813395
Policy mu Std                0.90103245
Policy mu Max                3.352597
Policy mu Min                -2.9588563
Policy log std Mean          -0.5023472
Policy log std Std           0.2580431
Policy log std Max           -0.09949902
Policy log std Min           -2.4583118
Z mean eval                  2.0619712
Z variance eval              0.052271686
total_rewards                [8226.14447878 8502.56639844 8717.5035838  8497.39435372 8278.60614236
 8305.79711046 8564.22811279 8467.46620158 8534.3377758  8677.13990548]
total_rewards_mean           8477.118406321753
total_rewards_std            155.41997553448772
total_rewards_max            8717.50358380224
total_rewards_min            8226.14447877769
Number of train steps total  668000
Number of env steps total    2006000
Number of rollouts total     0
Train Time (s)               146.21844824496657
(Previous) Eval Time (s)     29.044337684754282
Sample Time (s)              10.441966796759516
Epoch Time (s)               185.70475272648036
Total Train Time (s)         30551.243156235665
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:20:30.918576 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #166 | Epoch Duration: 185.7870306968689
2020-01-13 12:20:30.918722 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.061555
Z variance train             0.052122883
KL Divergence                51.110584
KL Loss                      5.1110587
QF Loss                      2305.6284
VF Loss                      76.98999
Policy Loss                  -1033.9968
Q Predictions Mean           1034.1218
Q Predictions Std            1114.0656
Q Predictions Max            3846.504
Q Predictions Min            466.44806
V Predictions Mean           1038.5042
V Predictions Std            1115.5817
V Predictions Max            3854.1284
V Predictions Min            467.35068
Log Pis Mean                 -0.29161742
Log Pis Std                  3.8608086
Log Pis Max                  13.962753
Log Pis Min                  -5.6271005
Policy mu Mean               0.02971225
Policy mu Std                0.8664263
Policy mu Max                2.6862745
Policy mu Min                -3.0667257
Policy log std Mean          -0.50445455
Policy log std Std           0.26162484
Policy log std Max           -0.13356945
Policy log std Min           -2.248378
Z mean eval                  2.011781
Z variance eval              0.050130874
total_rewards                [8987.81034936 9020.74190607 9243.38878654 9083.79504363 9034.4403238
 8942.02140973 9266.76650974 9064.48232079 9171.70013617 8982.64791257]
total_rewards_mean           9079.779469839297
total_rewards_std            106.22754438750276
total_rewards_max            9266.766509735076
total_rewards_min            8942.021409727266
Number of train steps total  672000
Number of env steps total    2018000
Number of rollouts total     0
Train Time (s)               138.90807302715257
(Previous) Eval Time (s)     28.903620639815927
Sample Time (s)              9.522300300654024
Epoch Time (s)               177.33399396762252
Total Train Time (s)         30728.656737839803
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:23:28.333875 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #167 | Epoch Duration: 177.41504502296448
2020-01-13 12:23:28.334016 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0116751
Z variance train             0.05016293
KL Divergence                50.308357
KL Loss                      5.0308356
QF Loss                      118.93103
VF Loss                      68.106544
Policy Loss                  -1056.5422
Q Predictions Mean           1054.0464
Q Predictions Std            1143.218
Q Predictions Max            3868.3706
Q Predictions Min            451.56537
V Predictions Mean           1054.0314
V Predictions Std            1135.4818
V Predictions Max            3852.9734
V Predictions Min            457.7945
Log Pis Mean                 -0.39427558
Log Pis Std                  3.7918506
Log Pis Max                  14.154652
Log Pis Min                  -6.3506284
Policy mu Mean               0.024261795
Policy mu Std                0.84954107
Policy mu Max                2.9915388
Policy mu Min                -2.9648955
Policy log std Mean          -0.5058425
Policy log std Std           0.25481188
Policy log std Max           -0.13026544
Policy log std Min           -2.6480656
Z mean eval                  1.9921631
Z variance eval              0.024620848
total_rewards                [8762.5317907  9261.919872   8755.49818921 9274.93605347 8952.06999482
 6153.68428407 9157.65519715 9228.24002931 8929.00766266 9019.71386734]
total_rewards_mean           8749.525694072556
total_rewards_std            884.2611616641001
total_rewards_max            9274.93605347022
total_rewards_min            6153.684284073283
Number of train steps total  676000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               138.8907105117105
(Previous) Eval Time (s)     29.542864105664194
Sample Time (s)              9.589354590512812
Epoch Time (s)               178.0229292078875
Total Train Time (s)         30906.76571068773
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:26:26.447451 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #168 | Epoch Duration: 178.11330556869507
2020-01-13 12:26:26.447699 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #168 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9928373
Z variance train             0.024756106
KL Divergence                51.449814
KL Loss                      5.1449814
QF Loss                      1835.0958
VF Loss                      40.2664
Policy Loss                  -975.5558
Q Predictions Mean           973.15186
Q Predictions Std            1055.018
Q Predictions Max            3773.9263
Q Predictions Min            461.101
V Predictions Mean           978.67737
V Predictions Std            1054.8064
V Predictions Max            3767.4727
V Predictions Min            467.48196
Log Pis Mean                 -0.70400316
Log Pis Std                  3.4757066
Log Pis Max                  12.072732
Log Pis Min                  -7.1400423
Policy mu Mean               0.029558904
Policy mu Std                0.836216
Policy mu Max                2.925242
Policy mu Min                -2.5921323
Policy log std Mean          -0.47579083
Policy log std Std           0.2564754
Policy log std Max           -0.092990994
Policy log std Min           -2.5380125
Z mean eval                  2.0424314
Z variance eval              0.028655168
total_rewards                [8305.03382643 9654.91634205 9030.52344567 9060.14512969 9193.123224
 9073.20582401 9190.39759017 8695.81786359  967.32962219 9340.51895545]
total_rewards_mean           8251.101182324233
total_rewards_std            2451.92023459167
total_rewards_max            9654.916342048868
total_rewards_min            967.3296221913628
Number of train steps total  680000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               147.35599661711603
(Previous) Eval Time (s)     31.01493593584746
Sample Time (s)              9.902735934592783
Epoch Time (s)               188.27366848755628
Total Train Time (s)         31095.125047461595
Epoch                        169
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:29:34.810879 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #169 | Epoch Duration: 188.36294388771057
2020-01-13 12:29:34.811644 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0417747
Z variance train             0.0286634
KL Divergence                51.866726
KL Loss                      5.1866727
QF Loss                      153.32265
VF Loss                      113.81043
Policy Loss                  -954.59064
Q Predictions Mean           948.28674
Q Predictions Std            1014.69556
Q Predictions Max            3815.9248
Q Predictions Min            470.61414
V Predictions Mean           958.1064
V Predictions Std            1015.2483
V Predictions Max            3817.5708
V Predictions Min            474.9649
Log Pis Mean                 -0.6078588
Log Pis Std                  3.5283787
Log Pis Max                  14.541546
Log Pis Min                  -7.6056013
Policy mu Mean               0.16008733
Policy mu Std                0.850935
Policy mu Max                3.6215177
Policy mu Min                -3.1743245
Policy log std Mean          -0.49440864
Policy log std Std           0.24288784
Policy log std Max           -0.10002375
Policy log std Min           -2.3150685
Z mean eval                  2.0093029
Z variance eval              0.031214258
total_rewards                [8549.10570954 8730.71517282 9014.54035357 8946.56376616 8655.08737275
 9038.77294568 8507.87223674 8872.10956159 8991.87202497 8900.83588834]
total_rewards_mean           8820.747503216184
total_rewards_std            186.14123740693003
total_rewards_max            9038.772945681256
total_rewards_min            8507.872236744302
Number of train steps total  684000
Number of env steps total    2054000
Number of rollouts total     0
Train Time (s)               146.89505851874128
(Previous) Eval Time (s)     30.21684702625498
Sample Time (s)              9.99187989672646
Epoch Time (s)               187.10378544172272
Total Train Time (s)         31282.319178858772
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:32:42.006029 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #170 | Epoch Duration: 187.1939561367035
2020-01-13 12:32:42.006274 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0064855
Z variance train             0.031226119
KL Divergence                51.432915
KL Loss                      5.1432915
QF Loss                      114.3945
VF Loss                      45.19129
Policy Loss                  -1001.857
Q Predictions Mean           1002.36865
Q Predictions Std            1079.2767
Q Predictions Max            3881.6711
Q Predictions Min            470.9236
V Predictions Mean           1004.51025
V Predictions Std            1078.3473
V Predictions Max            3902.6091
V Predictions Min            472.53302
Log Pis Mean                 -0.6200917
Log Pis Std                  3.4119606
Log Pis Max                  12.907988
Log Pis Min                  -7.58204
Policy mu Mean               0.034051143
Policy mu Std                0.85709935
Policy mu Max                2.863758
Policy mu Min                -3.207958
Policy log std Mean          -0.47071448
Policy log std Std           0.22804256
Policy log std Max           -0.091442764
Policy log std Min           -2.1367588
Z mean eval                  1.9648384
Z variance eval              0.04554338
total_rewards                [8847.78217009 8712.28298854 8870.47886701 8934.71803446 8962.22594662
 9025.40461268 9267.97497828 8999.93763121 9044.8551606  9137.93090971]
total_rewards_mean           8980.359129917611
total_rewards_std            147.66548519632843
total_rewards_max            9267.974978279452
total_rewards_min            8712.282988535431
Number of train steps total  688000
Number of env steps total    2066000
Number of rollouts total     0
Train Time (s)               147.3518476788886
(Previous) Eval Time (s)     29.82857843581587
Sample Time (s)              10.67811676999554
Epoch Time (s)               187.8585428847
Total Train Time (s)         31470.261907854117
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:49.951360 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #171 | Epoch Duration: 187.9449121952057
2020-01-13 12:35:49.951583 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9676096
Z variance train             0.045858227
KL Divergence                48.77925
KL Loss                      4.8779254
QF Loss                      173.60751
VF Loss                      76.366974
Policy Loss                  -1011.24506
Q Predictions Mean           1006.8497
Q Predictions Std            1083.1375
Q Predictions Max            3850.974
Q Predictions Min            461.4361
V Predictions Mean           1006.597
V Predictions Std            1080.275
V Predictions Max            3838.498
V Predictions Min            464.43948
Log Pis Mean                 -0.39600682
Log Pis Std                  3.5285997
Log Pis Max                  18.906393
Log Pis Min                  -7.4345784
Policy mu Mean               0.045785483
Policy mu Std                0.8536841
Policy mu Max                3.3581035
Policy mu Min                -3.4611664
Policy log std Mean          -0.5053821
Policy log std Std           0.23366924
Policy log std Max           -0.13571404
Policy log std Min           -2.5069427
Z mean eval                  1.9423927
Z variance eval              0.037884925
total_rewards                [8395.00593493 8549.02962012 9061.88296279 8500.30715355 8271.18377525
 9151.87336865 8365.09516125 8622.56035803 8099.47202785 8122.39533893]
total_rewards_mean           8513.880570136458
total_rewards_std            337.7480658977902
total_rewards_max            9151.873368654617
total_rewards_min            8099.472027849242
Number of train steps total  692000
Number of env steps total    2078000
Number of rollouts total     0
Train Time (s)               148.62380821397528
(Previous) Eval Time (s)     30.341711704153568
Sample Time (s)              10.478574963286519
Epoch Time (s)               189.44409488141537
Total Train Time (s)         31659.789719273802
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:38:59.481777 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #172 | Epoch Duration: 189.53003096580505
2020-01-13 12:38:59.482014 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9430269
Z variance train             0.037840333
KL Divergence                48.610435
KL Loss                      4.8610435
QF Loss                      162.73528
VF Loss                      59.6011
Policy Loss                  -1036.9028
Q Predictions Mean           1034.1572
Q Predictions Std            1125.5632
Q Predictions Max            3881.0437
Q Predictions Min            475.47528
V Predictions Mean           1037.8306
V Predictions Std            1127.9014
V Predictions Max            3898.7031
V Predictions Min            479.79605
Log Pis Mean                 -0.51255834
Log Pis Std                  3.558608
Log Pis Max                  11.006218
Log Pis Min                  -7.129802
Policy mu Mean               0.106965184
Policy mu Std                0.85607195
Policy mu Max                3.0427248
Policy mu Min                -2.2160244
Policy log std Mean          -0.46735254
Policy log std Std           0.23061386
Policy log std Max           -0.03921634
Policy log std Min           -2.3067317
Z mean eval                  1.9647042
Z variance eval              0.064683415
total_rewards                [9040.54456897 8842.90977615 8540.85725857 8900.814265   8881.12376202
 8852.50528707 8739.56049391 8619.91879473 8990.05058118 8837.44843216]
total_rewards_mean           8824.573321975973
total_rewards_std            146.26161023522806
total_rewards_max            9040.544568966698
total_rewards_min            8540.857258570255
Number of train steps total  696000
Number of env steps total    2090000
Number of rollouts total     0
Train Time (s)               144.3755367831327
(Previous) Eval Time (s)     28.610009549185634
Sample Time (s)              10.33257382037118
Epoch Time (s)               183.31812015268952
Total Train Time (s)         31843.265702241566
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:42:02.960515 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #173 | Epoch Duration: 183.47832918167114
2020-01-13 12:42:02.960764 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9670372
Z variance train             0.06476463
KL Divergence                48.9779
KL Loss                      4.8977904
QF Loss                      119.911705
VF Loss                      30.988598
Policy Loss                  -1115.8229
Q Predictions Mean           1115.0107
Q Predictions Std            1155.6947
Q Predictions Max            3930.6052
Q Predictions Min            488.97
V Predictions Mean           1116.1906
V Predictions Std            1157.0376
V Predictions Max            3911.0432
V Predictions Min            488.26144
Log Pis Mean                 -0.41412494
Log Pis Std                  3.599601
Log Pis Max                  11.660397
Log Pis Min                  -9.209082
Policy mu Mean               0.039444033
Policy mu Std                0.8980873
Policy mu Max                2.7892418
Policy mu Min                -2.9835293
Policy log std Mean          -0.48089132
Policy log std Std           0.24042454
Policy log std Max           -0.09311283
Policy log std Min           -2.0323386
Z mean eval                  1.9533596
Z variance eval              0.041765608
total_rewards                [9146.52828445 9288.04528486 9287.88134137 9314.72617275 9465.97744975
 9451.42155093 8928.93268398 9198.17006079 9403.69084592 9239.1211002 ]
total_rewards_mean           9272.44947750025
total_rewards_std            151.48109230548775
total_rewards_max            9465.97744975406
total_rewards_min            8928.93268397701
Number of train steps total  700000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               138.9276871001348
(Previous) Eval Time (s)     29.451921520754695
Sample Time (s)              9.564154892228544
Epoch Time (s)               177.94376351311803
Total Train Time (s)         32021.330171806738
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:45:01.027313 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #174 | Epoch Duration: 178.06636786460876
2020-01-13 12:45:01.027532 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9521786
Z variance train             0.041797552
KL Divergence                51.291817
KL Loss                      5.129182
QF Loss                      192.09938
VF Loss                      73.07231
Policy Loss                  -1076.8768
Q Predictions Mean           1074.4991
Q Predictions Std            1145.4336
Q Predictions Max            3970.5522
Q Predictions Min            483.74466
V Predictions Mean           1080.1007
V Predictions Std            1143.9653
V Predictions Max            3955.6682
V Predictions Min            487.94687
Log Pis Mean                 -0.55175006
Log Pis Std                  3.3956506
Log Pis Max                  15.893473
Log Pis Min                  -6.610014
Policy mu Mean               0.044412564
Policy mu Std                0.8560575
Policy mu Max                2.8504782
Policy mu Min                -3.1650023
Policy log std Mean          -0.5039368
Policy log std Std           0.26914015
Policy log std Max           -0.11204374
Policy log std Min           -2.8798537
Z mean eval                  1.9407545
Z variance eval              0.055985563
total_rewards                [8837.51843679 8878.89440639 9030.71989035 8931.00136285 8838.28311978
 8643.19162903 8785.95207406 8989.71668174 8888.58292669 8668.64457843]
total_rewards_mean           8849.250510612172
total_rewards_std            118.79152540093764
total_rewards_max            9030.719890345516
total_rewards_min            8643.191629030449
Number of train steps total  704000
Number of env steps total    2114000
Number of rollouts total     0
Train Time (s)               139.09171475702897
(Previous) Eval Time (s)     30.094175776001066
Sample Time (s)              9.530290581285954
Epoch Time (s)               178.716181114316
Total Train Time (s)         32200.127687871456
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:47:59.827494 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #175 | Epoch Duration: 178.7997977733612
2020-01-13 12:47:59.827713 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9393566
Z variance train             0.055832904
KL Divergence                50.320232
KL Loss                      5.0320234
QF Loss                      4296.388
VF Loss                      46.93524
Policy Loss                  -1060.5804
Q Predictions Mean           1059.8915
Q Predictions Std            1112.8181
Q Predictions Max            4011.789
Q Predictions Min            482.82608
V Predictions Mean           1062.5701
V Predictions Std            1113.1864
V Predictions Max            4007.9363
V Predictions Min            491.83676
Log Pis Mean                 -0.47311157
Log Pis Std                  3.1847038
Log Pis Max                  9.594635
Log Pis Min                  -5.2763834
Policy mu Mean               0.06509998
Policy mu Std                0.84872156
Policy mu Max                2.852513
Policy mu Min                -2.7651014
Policy log std Mean          -0.47645307
Policy log std Std           0.22505325
Policy log std Max           -0.07202971
Policy log std Min           -2.1265278
Z mean eval                  1.9331948
Z variance eval              0.05834096
total_rewards                [8503.19347832 8589.48907388 8892.46325628 8750.17914026 8908.30831355
 9093.27750557 8759.41102539 8334.67829388 9039.70899621 9143.1088798 ]
total_rewards_mean           8801.38179631477
total_rewards_std            251.89674212205912
total_rewards_max            9143.10887980114
total_rewards_min            8334.678293877123
Number of train steps total  708000
Number of env steps total    2126000
Number of rollouts total     0
Train Time (s)               147.63156989216805
(Previous) Eval Time (s)     30.38207650044933
Sample Time (s)              10.313375811558217
Epoch Time (s)               188.3270222041756
Total Train Time (s)         32388.535402645823
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:51:08.237654 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #176 | Epoch Duration: 188.40978121757507
2020-01-13 12:51:08.237866 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #176 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9339005
Z variance train             0.05834223
KL Divergence                50.229855
KL Loss                      5.0229855
QF Loss                      204.52425
VF Loss                      128.11517
Policy Loss                  -1003.05536
Q Predictions Mean           997.51917
Q Predictions Std            1068.8357
Q Predictions Max            3899.3225
Q Predictions Min            488.45255
V Predictions Mean           1000.7956
V Predictions Std            1065.8785
V Predictions Max            3880.2
V Predictions Min            492.42236
Log Pis Mean                 -0.72949904
Log Pis Std                  3.3396888
Log Pis Max                  13.449586
Log Pis Min                  -6.707367
Policy mu Mean               0.024607474
Policy mu Std                0.83597344
Policy mu Max                2.7199783
Policy mu Min                -2.9641297
Policy log std Mean          -0.47630802
Policy log std Std           0.23861484
Policy log std Max           -0.07149264
Policy log std Min           -2.5776117
Z mean eval                  1.9364363
Z variance eval              0.049440607
total_rewards                [8603.99464059 8819.00558038 8913.80303427 8598.02355624 8857.9484151
 9102.53641043 8641.61755579 8588.96076069 8733.15329951 9178.5405722 ]
total_rewards_mean           8803.758382518527
total_rewards_std            201.16012945759678
total_rewards_max            9178.540572197648
total_rewards_min            8588.96076068663
Number of train steps total  712000
Number of env steps total    2138000
Number of rollouts total     0
Train Time (s)               147.24362300289795
(Previous) Eval Time (s)     29.182817824184895
Sample Time (s)              9.199539371300489
Epoch Time (s)               185.62598019838333
Total Train Time (s)         32574.25195428217
Epoch                        177
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:54:13.956835 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #177 | Epoch Duration: 185.71880316734314
2020-01-13 12:54:13.957108 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9361403
Z variance train             0.04952144
KL Divergence                50.998905
KL Loss                      5.0998907
QF Loss                      122.471664
VF Loss                      46.86341
Policy Loss                  -1123.6644
Q Predictions Mean           1119.7548
Q Predictions Std            1177.932
Q Predictions Max            3946.0225
Q Predictions Min            486.47363
V Predictions Mean           1121.508
V Predictions Std            1176.6084
V Predictions Max            3928.236
V Predictions Min            486.73532
Log Pis Mean                 -0.56523764
Log Pis Std                  3.5589895
Log Pis Max                  12.658583
Log Pis Min                  -8.538107
Policy mu Mean               0.039446253
Policy mu Std                0.84595627
Policy mu Max                2.9054801
Policy mu Min                -2.788606
Policy log std Mean          -0.4908106
Policy log std Std           0.2515977
Policy log std Max           -0.048332155
Policy log std Min           -2.5367289
Z mean eval                  1.9408255
Z variance eval              0.058695506
total_rewards                [8231.13624803 8109.04264903 8225.10950982 8513.59099069 8963.15941257
 8056.83696758 8432.68250843 8569.35385626 8416.60950502 8350.68689367]
total_rewards_mean           8386.820854109621
total_rewards_std            249.45736480477737
total_rewards_max            8963.159412566474
total_rewards_min            8056.836967582703
Number of train steps total  716000
Number of env steps total    2150000
Number of rollouts total     0
Train Time (s)               146.22352354088798
(Previous) Eval Time (s)     30.276424020994455
Sample Time (s)              10.606714885681868
Epoch Time (s)               187.1066624475643
Total Train Time (s)         32761.43847739324
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:57:21.146867 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #178 | Epoch Duration: 187.18956851959229
2020-01-13 12:57:21.147219 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9418011
Z variance train             0.058627028
KL Divergence                49.030354
KL Loss                      4.9030356
QF Loss                      97.09429
VF Loss                      47.56856
Policy Loss                  -1057.3707
Q Predictions Mean           1055.7228
Q Predictions Std            1139.593
Q Predictions Max            4029.3718
Q Predictions Min            481.11252
V Predictions Mean           1060.9369
V Predictions Std            1137.5897
V Predictions Max            4015.4326
V Predictions Min            486.88736
Log Pis Mean                 -0.5348885
Log Pis Std                  3.827223
Log Pis Max                  19.504189
Log Pis Min                  -7.4101176
Policy mu Mean               0.07398491
Policy mu Std                0.8860419
Policy mu Max                3.0662193
Policy mu Min                -3.4262702
Policy log std Mean          -0.47833022
Policy log std Std           0.25796318
Policy log std Max           -0.11561161
Policy log std Min           -2.5490515
Z mean eval                  1.9412243
Z variance eval              0.037696026
total_rewards                [9018.12613881 9389.04729295 9017.64329431 9222.64448849 9185.71627475
 7601.40539873 8923.02793312 8629.86899351 9052.82669775 8744.17698593]
total_rewards_mean           8878.448349834889
total_rewards_std            474.924762416413
total_rewards_max            9389.047292952473
total_rewards_min            7601.405398725975
Number of train steps total  720000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               148.16451917402446
(Previous) Eval Time (s)     29.893246869090945
Sample Time (s)              10.557952008210123
Epoch Time (s)               188.61571805132553
Total Train Time (s)         32950.13556086831
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:00:29.845776 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #179 | Epoch Duration: 188.69835543632507
2020-01-13 13:00:29.845974 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #179 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9367956
Z variance train             0.037942886
KL Divergence                49.78205
KL Loss                      4.978205
QF Loss                      117.694664
VF Loss                      82.3996
Policy Loss                  -1021.34894
Q Predictions Mean           1019.3909
Q Predictions Std            1105.4117
Q Predictions Max            4012.132
Q Predictions Min            492.43774
V Predictions Mean           1023.9137
V Predictions Std            1103.8093
V Predictions Max            3966.5808
V Predictions Min            496.23145
Log Pis Mean                 -0.7225971
Log Pis Std                  3.477234
Log Pis Max                  12.280769
Log Pis Min                  -6.236669
Policy mu Mean               0.09823251
Policy mu Std                0.8453424
Policy mu Max                2.7182631
Policy mu Min                -2.6215374
Policy log std Mean          -0.48751318
Policy log std Std           0.2371777
Policy log std Max           -0.10988352
Policy log std Min           -2.6464076
Z mean eval                  1.9079382
Z variance eval              0.07056258
total_rewards                [8985.32081107 9507.01356089 8942.11950867 9151.68349206 9051.7434156
 9113.42337464 8950.46186629 9207.65229514 9183.37001555 9141.80944354]
total_rewards_mean           9123.459778345376
total_rewards_std            156.86405581949512
total_rewards_max            9507.01356088754
total_rewards_min            8942.119508674434
Number of train steps total  724000
Number of env steps total    2174000
Number of rollouts total     0
Train Time (s)               143.3023061589338
(Previous) Eval Time (s)     29.362628073897213
Sample Time (s)              9.718804797623307
Epoch Time (s)               182.3837390304543
Total Train Time (s)         33132.64071074175
Epoch                        180
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:03:32.353272 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #180 | Epoch Duration: 182.50715827941895
2020-01-13 13:03:32.353454 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090945
Z variance train             0.070080325
KL Divergence                49.00385
KL Loss                      4.900385
QF Loss                      213.30762
VF Loss                      167.18324
Policy Loss                  -1099.7386
Q Predictions Mean           1093.2861
Q Predictions Std            1166.8926
Q Predictions Max            4013.5623
Q Predictions Min            470.58786
V Predictions Mean           1096.4291
V Predictions Std            1159.369
V Predictions Max            3981.045
V Predictions Min            493.043
Log Pis Mean                 -0.08214054
Log Pis Std                  4.2250586
Log Pis Max                  16.084963
Log Pis Min                  -11.045612
Policy mu Mean               0.08019078
Policy mu Std                0.9050186
Policy mu Max                3.2994976
Policy mu Min                -3.9725585
Policy log std Mean          -0.5070669
Policy log std Std           0.273952
Policy log std Max           -0.08461636
Policy log std Min           -2.7833862
Z mean eval                  1.9454508
Z variance eval              0.052446842
total_rewards                [8925.17875768 8712.03749641 8575.85511486 8975.00973277 9324.11454388
 8539.21916313 9008.75589457 8428.27420141 8714.41952442 8451.9823945 ]
total_rewards_mean           8765.484682362461
total_rewards_std            272.9955040590547
total_rewards_max            9324.114543875112
total_rewards_min            8428.274201407858
Number of train steps total  728000
Number of env steps total    2186000
Number of rollouts total     0
Train Time (s)               139.15647706016898
(Previous) Eval Time (s)     29.550926784984767
Sample Time (s)              9.771641636732966
Epoch Time (s)               178.47904548188671
Total Train Time (s)         33311.28298304463
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:06:30.998329 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #181 | Epoch Duration: 178.64473009109497
2020-01-13 13:06:30.998533 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9479742
Z variance train             0.05261262
KL Divergence                51.367516
KL Loss                      5.1367517
QF Loss                      192.61458
VF Loss                      142.67879
Policy Loss                  -1115.1973
Q Predictions Mean           1109.5247
Q Predictions Std            1175.656
Q Predictions Max            3934.6567
Q Predictions Min            501.13794
V Predictions Mean           1107.7196
V Predictions Std            1171.1675
V Predictions Max            3921.7703
V Predictions Min            497.76764
Log Pis Mean                 -0.41840714
Log Pis Std                  3.876518
Log Pis Max                  21.364971
Log Pis Min                  -8.471304
Policy mu Mean               0.006785799
Policy mu Std                0.8625613
Policy mu Max                2.8059278
Policy mu Min                -3.4685175
Policy log std Mean          -0.48070726
Policy log std Std           0.24398468
Policy log std Max           -0.08523244
Policy log std Min           -2.5041075
Z mean eval                  1.925317
Z variance eval              0.078164145
total_rewards                [8701.5537345  9101.68118792 8788.9724376  8930.34879401 9016.40996717
 8970.14135815 8960.02494283 9061.8366054  9047.61445739 8956.60803861]
total_rewards_mean           8953.519152356785
total_rewards_std            117.43979875963157
total_rewards_max            9101.681187920613
total_rewards_min            8701.553734498273
Number of train steps total  732000
Number of env steps total    2198000
Number of rollouts total     0
Train Time (s)               140.0440906570293
(Previous) Eval Time (s)     30.003740685991943
Sample Time (s)              9.20689451135695
Epoch Time (s)               179.2547258543782
Total Train Time (s)         33490.61950517632
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:09:30.336485 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #182 | Epoch Duration: 179.3378026485443
2020-01-13 13:09:30.336652 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.921369
Z variance train             0.07802439
KL Divergence                50.826122
KL Loss                      5.0826125
QF Loss                      299.59686
VF Loss                      189.92339
Policy Loss                  -1030.5309
Q Predictions Mean           1025.836
Q Predictions Std            1105.8052
Q Predictions Max            3911.8152
Q Predictions Min            480.88785
V Predictions Mean           1038.8424
V Predictions Std            1109.7521
V Predictions Max            3914.9912
V Predictions Min            485.08926
Log Pis Mean                 -0.4642915
Log Pis Std                  3.4850738
Log Pis Max                  14.5157795
Log Pis Min                  -6.714938
Policy mu Mean               0.12583391
Policy mu Std                0.8531608
Policy mu Max                3.3320043
Policy mu Min                -2.8375134
Policy log std Mean          -0.4851304
Policy log std Std           0.24261391
Policy log std Max           -0.09127593
Policy log std Min           -2.5609212
Z mean eval                  1.9254701
Z variance eval              0.08996547
total_rewards                [8927.65177671 9359.78429033 9351.10748854 9631.80423924 9585.85163599
 9418.19994587 9059.52019492 9046.03548232 9343.73385404 9175.25741285]
total_rewards_mean           9289.894632082449
total_rewards_std            221.22080951849486
total_rewards_max            9631.804239242118
total_rewards_min            8927.651776713785
Number of train steps total  736000
Number of env steps total    2210000
Number of rollouts total     0
Train Time (s)               149.61264483397827
(Previous) Eval Time (s)     31.383650433272123
Sample Time (s)              10.012826483231038
Epoch Time (s)               191.00912175048143
Total Train Time (s)         33681.71343564289
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:12:41.433234 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #183 | Epoch Duration: 191.09643650054932
2020-01-13 13:12:41.433464 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9239031
Z variance train             0.09004324
KL Divergence                52.28631
KL Loss                      5.228631
QF Loss                      2574.7725
VF Loss                      51.616764
Policy Loss                  -1107.1185
Q Predictions Mean           1108.9635
Q Predictions Std            1166.8344
Q Predictions Max            4040.808
Q Predictions Min            519.4063
V Predictions Mean           1109.9285
V Predictions Std            1165.8997
V Predictions Max            4023.188
V Predictions Min            521.2471
Log Pis Mean                 0.024978474
Log Pis Std                  3.833364
Log Pis Max                  15.110693
Log Pis Min                  -6.639738
Policy mu Mean               0.06110699
Policy mu Std                0.9086543
Policy mu Max                3.0431836
Policy mu Min                -3.4720562
Policy log std Mean          -0.49914297
Policy log std Std           0.2666703
Policy log std Max           -0.08988309
Policy log std Min           -2.6452806
Z mean eval                  1.9570885
Z variance eval              0.061071627
total_rewards                [4781.59942777 9219.82226957 9618.19571416 9487.92481085 9164.55304494
 9470.51259143 9677.27034387 9507.32926776 9511.34217927 9664.57266151]
total_rewards_mean           9010.312231111635
total_rewards_std            1418.8045641858948
total_rewards_max            9677.270343869046
total_rewards_min            4781.599427770526
Number of train steps total  740000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               147.70548482099548
(Previous) Eval Time (s)     29.46096076304093
Sample Time (s)              9.629806211218238
Epoch Time (s)               186.79625179525465
Total Train Time (s)         33868.58921069559
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:15:48.311814 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #184 | Epoch Duration: 186.87818694114685
2020-01-13 13:15:48.312038 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.95275
Z variance train             0.060998697
KL Divergence                51.906155
KL Loss                      5.1906157
QF Loss                      105.72724
VF Loss                      82.007126
Policy Loss                  -1032.5393
Q Predictions Mean           1033.1185
Q Predictions Std            1085.0953
Q Predictions Max            3962.337
Q Predictions Min            513.8967
V Predictions Mean           1034.9559
V Predictions Std            1086.3969
V Predictions Max            3972.6108
V Predictions Min            514.1047
Log Pis Mean                 -0.86006814
Log Pis Std                  3.7084157
Log Pis Max                  17.966967
Log Pis Min                  -6.619138
Policy mu Mean               0.07863775
Policy mu Std                0.81172997
Policy mu Max                3.0636256
Policy mu Min                -3.3132331
Policy log std Mean          -0.45299062
Policy log std Std           0.22764637
Policy log std Max           -0.05371517
Policy log std Min           -2.3840466
Z mean eval                  1.9401417
Z variance eval              0.10120217
total_rewards                [8935.89206188 9025.46480388 8986.41690747 8804.47110284 9225.91642328
 9437.79211727 9329.17822258 9035.5328887  9439.35541408 9302.70350287]
total_rewards_mean           9152.272344483988
total_rewards_std            211.72843744272132
total_rewards_max            9439.35541407722
total_rewards_min            8804.471102843727
Number of train steps total  744000
Number of env steps total    2234000
Number of rollouts total     0
Train Time (s)               147.19213108997792
(Previous) Eval Time (s)     31.037403407972306
Sample Time (s)              10.039826205000281
Epoch Time (s)               188.2693607029505
Total Train Time (s)         34056.96176856756
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:18:56.687606 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #185 | Epoch Duration: 188.37540936470032
2020-01-13 13:18:56.687874 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9401144
Z variance train             0.10132667
KL Divergence                50.202328
KL Loss                      5.0202327
QF Loss                      121.527405
VF Loss                      35.610394
Policy Loss                  -995.97284
Q Predictions Mean           993.3054
Q Predictions Std            1050.2698
Q Predictions Max            3979.8418
Q Predictions Min            502.5866
V Predictions Mean           995.7721
V Predictions Std            1049.021
V Predictions Max            3962.6257
V Predictions Min            503.65533
Log Pis Mean                 -0.5127485
Log Pis Std                  3.2812312
Log Pis Max                  15.736429
Log Pis Min                  -6.8817043
Policy mu Mean               -0.0049005947
Policy mu Std                0.82111794
Policy mu Max                2.5955892
Policy mu Min                -3.277822
Policy log std Mean          -0.48445547
Policy log std Std           0.22502509
Policy log std Max           -0.01312539
Policy log std Min           -2.6254475
Z mean eval                  1.9359424
Z variance eval              0.05198931
total_rewards                [9163.61609877 9270.49481424 9375.97207214 9313.50232901 9359.12338433
 9316.65101532 9436.14941364 9418.07206833 9522.14142503 9044.7418427 ]
total_rewards_mean           9322.046446352293
total_rewards_std            130.88880081649398
total_rewards_max            9522.14142503067
total_rewards_min            9044.741842700574
Number of train steps total  748000
Number of env steps total    2246000
Number of rollouts total     0
Train Time (s)               147.19583628699183
(Previous) Eval Time (s)     29.715112154837698
Sample Time (s)              10.618488805368543
Epoch Time (s)               187.52943724719808
Total Train Time (s)         34244.57641534507
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:22:04.305479 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #186 | Epoch Duration: 187.61740374565125
2020-01-13 13:22:04.305807 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9344747
Z variance train             0.051930297
KL Divergence                50.700226
KL Loss                      5.0700226
QF Loss                      203.98708
VF Loss                      45.143238
Policy Loss                  -930.1241
Q Predictions Mean           928.5874
Q Predictions Std            978.7939
Q Predictions Max            3982.1345
Q Predictions Min            477.18207
V Predictions Mean           933.5711
V Predictions Std            977.20294
V Predictions Max            3975.6624
V Predictions Min            493.06418
Log Pis Mean                 -0.9660952
Log Pis Std                  3.217488
Log Pis Max                  11.186579
Log Pis Min                  -6.917834
Policy mu Mean               0.08048938
Policy mu Std                0.79021776
Policy mu Max                2.5808325
Policy mu Min                -3.0778372
Policy log std Mean          -0.4564418
Policy log std Std           0.23572214
Policy log std Max           -0.03513211
Policy log std Min           -2.4575586
Z mean eval                  1.9503477
Z variance eval              0.16381209
total_rewards                [8756.61163363 8957.5091237  9061.97525354 8884.51249983 9315.92161007
 8676.57549625 9128.42802192 9029.11688959 9006.02016989 8624.13756595]
total_rewards_mean           8944.080826436975
total_rewards_std            202.4876197869683
total_rewards_max            9315.921610071728
total_rewards_min            8624.137565946878
Number of train steps total  752000
Number of env steps total    2258000
Number of rollouts total     0
Train Time (s)               141.85815311828628
(Previous) Eval Time (s)     28.233587838709354
Sample Time (s)              10.710410868749022
Epoch Time (s)               180.80215182574466
Total Train Time (s)         34425.468005931005
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:25:05.199128 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #187 | Epoch Duration: 180.89312720298767
2020-01-13 13:25:05.199416 UTC | [2020_01_11_02_30_29] [2020_01_12_01_55_52] [2020_01_13_03_51_19] Iteration #187 | Started Training: True
