---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00092889863
Z variance train             0.6928836
KL Divergence                0.14944687
KL Loss                      0.0149446875
QF Loss                      211.64459
VF Loss                      29.417334
Policy Loss                  -5.3879366
Q Predictions Mean           0.0029920149
Q Predictions Std            0.0017975824
Q Predictions Max            0.0076784114
Q Predictions Min            -0.0026010005
V Predictions Mean           0.00033025967
V Predictions Std            0.0023158917
V Predictions Max            0.007400641
V Predictions Min            -0.004998319
Log Pis Mean                 -5.4070196
Log Pis Std                  0.6253165
Log Pis Max                  -3.767221
Log Pis Min                  -6.833845
Policy mu Mean               0.0015256859
Policy mu Std                0.0016553933
Policy mu Max                0.005054727
Policy mu Min                -0.0033204472
Policy log std Mean          0.00036570974
Policy log std Std           0.0018290252
Policy log std Max           0.0050726114
Policy log std Min           -0.004632369
Z mean eval                  1.5301851
Z variance eval              0.0025412918
total_rewards                [-11.99852044 231.1790254  130.34427545  72.19508922   8.53792858
  34.25276702   7.8140692    5.92465526  62.88037106  54.77340232]
total_rewards_mean           59.59030630723432
total_rewards_std            69.6963395201281
total_rewards_max            231.17902539502074
total_rewards_min            -11.99852044170203
Number of train steps total  4000
Number of env steps total    5831
Number of rollouts total     0
Train Time (s)               141.62186042871326
(Previous) Eval Time (s)     0
Sample Time (s)              12.86952779442072
Epoch Time (s)               154.49138822313398
Total Train Time (s)         168.0706324656494
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:24.593867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #0 | Epoch Duration: 168.0723021030426
2020-01-11 08:23:24.593998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.535223
Z variance train             0.002539057
KL Divergence                21.485203
KL Loss                      2.1485202
QF Loss                      223.86017
VF Loss                      38.405045
Policy Loss                  -93.17576
Q Predictions Mean           84.424446
Q Predictions Std            26.785002
Q Predictions Max            166.342
Q Predictions Min            0.011278097
V Predictions Mean           94.5982
V Predictions Std            20.81994
V Predictions Max            161.74763
V Predictions Min            15.021339
Log Pis Mean                 -2.0361335
Log Pis Std                  1.7150192
Log Pis Max                  1.6322354
Log Pis Min                  -8.368288
Policy mu Mean               -0.049447227
Policy mu Std                0.40883377
Policy mu Max                1.4428058
Policy mu Min                -1.5870926
Policy log std Mean          -0.84241354
Policy log std Std           0.10696146
Policy log std Max           -0.2869303
Policy log std Min           -1.1868913
Z mean eval                  1.5809927
Z variance eval              0.001588004
total_rewards                [-99.9503157  -12.4779703  -35.22147832 -11.84326064 -32.87498228
  -6.69572589 -66.31007209  -3.19158989 -13.46108049 -38.90492701]
total_rewards_mean           -32.093140262482144
total_rewards_std            29.07660113637623
total_rewards_max            -3.191589894287707
total_rewards_min            -99.95031570284881
Number of train steps total  8000
Number of env steps total    9819
Number of rollouts total     0
Train Time (s)               143.63312068395317
(Previous) Eval Time (s)     7.723152302205563
Sample Time (s)              7.964425989892334
Epoch Time (s)               159.32069897605106
Total Train Time (s)         327.68515238165855
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:26:04.221305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #1 | Epoch Duration: 159.62717843055725
2020-01-11 08:26:04.221544 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5847409
Z variance train             0.0015810305
KL Divergence                23.011051
KL Loss                      2.3011053
QF Loss                      222.69705
VF Loss                      65.89524
Policy Loss                  -170.9411
Q Predictions Mean           162.13777
Q Predictions Std            32.08539
Q Predictions Max            241.68143
Q Predictions Min            -7.0972652
V Predictions Mean           172.93689
V Predictions Std            28.921238
V Predictions Max            235.83528
V Predictions Min            67.134964
Log Pis Mean                 -1.2251359
Log Pis Std                  2.0212312
Log Pis Max                  3.1696727
Log Pis Min                  -8.284529
Policy mu Mean               0.019192772
Policy mu Std                0.5818333
Policy mu Max                1.7446042
Policy mu Min                -2.046539
Policy log std Mean          -0.8290905
Policy log std Std           0.116126984
Policy log std Max           -0.42125756
Policy log std Min           -1.2268164
Z mean eval                  1.56933
Z variance eval              0.0015684605
total_rewards                [-198.57388954   -8.56420794   17.38501423  -27.82821409   11.28844701
 -210.64904419 -262.30720097    0.42635258  -12.16887372 -193.56165552]
total_rewards_mean           -88.4553272144037
total_rewards_std            106.42275538715091
total_rewards_max            17.385014231902016
total_rewards_min            -262.3072009711935
Number of train steps total  12000
Number of env steps total    12747
Number of rollouts total     0
Train Time (s)               140.50160865997896
(Previous) Eval Time (s)     11.179489087779075
Sample Time (s)              7.812925790436566
Epoch Time (s)               159.4940235381946
Total Train Time (s)         487.2798255495727
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:28:43.805377 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #2 | Epoch Duration: 159.58366918563843
2020-01-11 08:28:43.805505 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5637276
Z variance train             0.0015736436
KL Divergence                22.281536
KL Loss                      2.2281537
QF Loss                      272.26343
VF Loss                      70.36281
Policy Loss                  -215.00937
Q Predictions Mean           207.462
Q Predictions Std            31.022535
Q Predictions Max            337.45187
Q Predictions Min            84.76316
V Predictions Mean           217.98495
V Predictions Std            26.762302
V Predictions Max            349.05933
V Predictions Min            126.4937
Log Pis Mean                 -1.2424325
Log Pis Std                  2.3547451
Log Pis Max                  6.6250844
Log Pis Min                  -7.117813
Policy mu Mean               -0.057376362
Policy mu Std                0.61623734
Policy mu Max                1.8418559
Policy mu Min                -2.0078223
Policy log std Mean          -0.7802205
Policy log std Std           0.13433044
Policy log std Max           -0.3382483
Policy log std Min           -1.2722962
Z mean eval                  1.5246235
Z variance eval              0.006447082
total_rewards                [ 15.76361833  -4.82105768   3.19790462  36.85960806  12.41773092
 -75.2109068   87.05118901   3.29508395 -26.68325748  14.51092664]
total_rewards_mean           6.638083956494185
total_rewards_std            39.39817359304591
total_rewards_max            87.05118900777097
total_rewards_min            -75.21090680186745
Number of train steps total  16000
Number of env steps total    16348
Number of rollouts total     0
Train Time (s)               141.14424989419058
(Previous) Eval Time (s)     6.201557786203921
Sample Time (s)              7.594909273087978
Epoch Time (s)               154.94071695348248
Total Train Time (s)         642.3184388526715
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:18.845530 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #3 | Epoch Duration: 155.03992128372192
2020-01-11 08:31:18.845703 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5229677
Z variance train             0.006447412
KL Divergence                21.944626
KL Loss                      2.1944625
QF Loss                      223.55347
VF Loss                      61.42443
Policy Loss                  -227.44536
Q Predictions Mean           221.08647
Q Predictions Std            35.831135
Q Predictions Max            303.8636
Q Predictions Min            9.025495
V Predictions Mean           226.3139
V Predictions Std            29.409395
V Predictions Max            308.42575
V Predictions Min            116.1748
Log Pis Mean                 -1.7763858
Log Pis Std                  1.9836893
Log Pis Max                  3.798101
Log Pis Min                  -6.8104277
Policy mu Mean               -0.020057712
Policy mu Std                0.52545786
Policy mu Max                1.8466108
Policy mu Min                -1.9005436
Policy log std Mean          -0.79882586
Policy log std Std           0.13195549
Policy log std Max           -0.35789466
Policy log std Min           -1.4384389
Z mean eval                  1.4661572
Z variance eval              0.0029452401
total_rewards                [  9.0875484    9.56543034  18.64689646  69.09405464  29.87363921
  25.58990524 -11.45955574  14.57518121   2.72133534   5.603759  ]
total_rewards_mean           17.329819412073174
total_rewards_std            20.548460759838914
total_rewards_max            69.09405464230038
total_rewards_min            -11.459555741330945
Number of train steps total  20000
Number of env steps total    19120
Number of rollouts total     0
Train Time (s)               141.4204975985922
(Previous) Eval Time (s)     3.608809073921293
Sample Time (s)              7.535192318726331
Epoch Time (s)               152.56449899123982
Total Train Time (s)         794.9778623855673
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:51.509020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #4 | Epoch Duration: 152.66314315795898
2020-01-11 08:33:51.509336 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #4 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4681956
Z variance train             0.0029230432
KL Divergence                22.827301
KL Loss                      2.28273
QF Loss                      232.92577
VF Loss                      80.777214
Policy Loss                  -238.6563
Q Predictions Mean           233.85172
Q Predictions Std            28.142174
Q Predictions Max            311.70865
Q Predictions Min            155.69048
V Predictions Mean           238.39505
V Predictions Std            24.666147
V Predictions Max            313.77658
V Predictions Min            160.97974
Log Pis Mean                 -1.9109137
Log Pis Std                  1.9385749
Log Pis Max                  4.23965
Log Pis Min                  -7.059726
Policy mu Mean               0.018550433
Policy mu Std                0.49743122
Policy mu Max                1.7828345
Policy mu Min                -1.8451283
Policy log std Mean          -0.79878724
Policy log std Std           0.130593
Policy log std Max           -0.39536387
Policy log std Min           -1.2830074
Z mean eval                  1.4265143
Z variance eval              0.00870553
total_rewards                [61.81620524 39.00791879 31.32552528  1.28925902 12.04592351 47.20110153
 88.62110633 23.2593107  72.04828406  4.85902427]
total_rewards_mean           38.147365872693776
total_rewards_std            27.84942743406518
total_rewards_max            88.62110632830243
total_rewards_min            1.2892590220563989
Number of train steps total  24000
Number of env steps total    21945
Number of rollouts total     0
Train Time (s)               142.34915408678353
(Previous) Eval Time (s)     9.12030332768336
Sample Time (s)              7.958405234850943
Epoch Time (s)               159.42786264931783
Total Train Time (s)         954.4953376962803
Epoch                        5
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:36:31.028090 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #5 | Epoch Duration: 159.51849365234375
2020-01-11 08:36:31.028384 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4245279
Z variance train             0.008695195
KL Divergence                19.56926
KL Loss                      1.956926
QF Loss                      182.95715
VF Loss                      60.661797
Policy Loss                  -240.242
Q Predictions Mean           232.25183
Q Predictions Std            39.559616
Q Predictions Max            330.07562
Q Predictions Min            13.048765
V Predictions Mean           240.83942
V Predictions Std            29.853954
V Predictions Max            333.95178
V Predictions Min            95.88535
Log Pis Mean                 -1.8827777
Log Pis Std                  2.479256
Log Pis Max                  10.450271
Log Pis Min                  -8.377997
Policy mu Mean               -0.057779387
Policy mu Std                0.486935
Policy mu Max                1.8166187
Policy mu Min                -2.4269278
Policy log std Mean          -0.8028295
Policy log std Std           0.13313067
Policy log std Max           -0.34320432
Policy log std Min           -1.4443687
Z mean eval                  1.3936964
Z variance eval              0.012122951
total_rewards                [ 63.08266912  -5.08313512  10.90323213  -0.78961681  -3.50698179
  19.04527882  62.1231199   70.93976698  81.16355859 196.95696796]
total_rewards_mean           49.48348597692742
total_rewards_std            58.553339896394974
total_rewards_max            196.95696796360414
total_rewards_min            -5.083135122718842
Number of train steps total  28000
Number of env steps total    25122
Number of rollouts total     0
Train Time (s)               141.0259569203481
(Previous) Eval Time (s)     12.509683795273304
Sample Time (s)              8.143986309878528
Epoch Time (s)               161.67962702549994
Total Train Time (s)         1116.2801077309996
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:39:12.810764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #6 | Epoch Duration: 161.78217101097107
2020-01-11 08:39:12.810892 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3888234
Z variance train             0.01214722
KL Divergence                21.653728
KL Loss                      2.1653728
QF Loss                      230.39511
VF Loss                      54.237774
Policy Loss                  -244.51013
Q Predictions Mean           234.93526
Q Predictions Std            42.85603
Q Predictions Max            321.99234
Q Predictions Min            44.611565
V Predictions Mean           244.38263
V Predictions Std            35.896656
V Predictions Max            343.5984
V Predictions Min            98.79386
Log Pis Mean                 -1.5492263
Log Pis Std                  2.284382
Log Pis Max                  10.800283
Log Pis Min                  -9.009415
Policy mu Mean               0.012119962
Policy mu Std                0.52301115
Policy mu Max                1.6772113
Policy mu Min                -2.2616794
Policy log std Mean          -0.82523024
Policy log std Std           0.13013531
Policy log std Max           -0.38950455
Policy log std Min           -1.6412618
Z mean eval                  1.3252556
Z variance eval              0.014640711
total_rewards                [ 26.97490129  -3.10828046  24.05578818 162.05284903 137.55739021
  22.73140524  60.38425851  -0.76946509 103.60972601   6.35335486]
total_rewards_mean           53.9841927778124
total_rewards_std            56.82880115935116
total_rewards_max            162.05284902866063
total_rewards_min            -3.108280464580658
Number of train steps total  32000
Number of env steps total    27752
Number of rollouts total     0
Train Time (s)               141.66262299614027
(Previous) Eval Time (s)     6.1946642198599875
Sample Time (s)              7.561860636807978
Epoch Time (s)               155.41914785280824
Total Train Time (s)         1271.784595437348
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:48.317165 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #7 | Epoch Duration: 155.50616693496704
2020-01-11 08:41:48.317334 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3260273
Z variance train             0.014675239
KL Divergence                18.621807
KL Loss                      1.8621807
QF Loss                      350.96072
VF Loss                      82.78835
Policy Loss                  -255.03926
Q Predictions Mean           245.40047
Q Predictions Std            49.360344
Q Predictions Max            343.35062
Q Predictions Min            -34.725334
V Predictions Mean           253.01462
V Predictions Std            36.268757
V Predictions Max            349.01245
V Predictions Min            78.95007
Log Pis Mean                 -2.0546694
Log Pis Std                  2.5965145
Log Pis Max                  7.766448
Log Pis Min                  -10.340362
Policy mu Mean               -0.025781583
Policy mu Std                0.4996835
Policy mu Max                1.8409452
Policy mu Min                -2.394346
Policy log std Mean          -0.7924251
Policy log std Std           0.13332906
Policy log std Max           -0.38683924
Policy log std Min           -1.3487005
Z mean eval                  1.3092388
Z variance eval              0.014167669
total_rewards                [ 66.8551516   48.77715333  34.8906112  212.01620819  80.66291007
  34.29739489  86.07957251 100.57046924  67.83447783  38.73317447]
total_rewards_mean           77.07171233402231
total_rewards_std            49.9252085420889
total_rewards_max            212.0162081946058
total_rewards_min            34.29739488554038
Number of train steps total  36000
Number of env steps total    30732
Number of rollouts total     0
Train Time (s)               141.59395197592676
(Previous) Eval Time (s)     9.97757881693542
Sample Time (s)              7.443995798006654
Epoch Time (s)               159.01552659086883
Total Train Time (s)         1430.8868555328809
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:44:27.419918 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #8 | Epoch Duration: 159.10246181488037
2020-01-11 08:44:27.420054 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3006485
Z variance train             0.0141130965
KL Divergence                20.000929
KL Loss                      2.000093
QF Loss                      157.65189
VF Loss                      55.50096
Policy Loss                  -254.50287
Q Predictions Mean           248.23474
Q Predictions Std            42.05442
Q Predictions Max            347.63684
Q Predictions Min            -27.538713
V Predictions Mean           255.735
V Predictions Std            37.110832
V Predictions Max            338.49475
V Predictions Min            43.253876
Log Pis Mean                 -1.9482127
Log Pis Std                  2.1965797
Log Pis Max                  9.361324
Log Pis Min                  -8.634858
Policy mu Mean               -0.03703468
Policy mu Std                0.5086903
Policy mu Max                1.9998645
Policy mu Min                -2.1424518
Policy log std Mean          -0.79773045
Policy log std Std           0.12146983
Policy log std Max           -0.33567077
Policy log std Min           -1.3661306
Z mean eval                  1.2752041
Z variance eval              0.016947975
total_rewards                [  2.70478373  90.67964086 146.95622658 111.71119741  29.85432744
   9.23387788 245.96026817  59.28532194  40.93132791  83.83418997]
total_rewards_mean           82.1151161893172
total_rewards_std            69.69075082615733
total_rewards_max            245.96026817052143
total_rewards_min            2.704783728490112
Number of train steps total  40000
Number of env steps total    34546
Number of rollouts total     0
Train Time (s)               140.58767930371687
(Previous) Eval Time (s)     8.869370306842029
Sample Time (s)              7.52882967563346
Epoch Time (s)               156.98587928619236
Total Train Time (s)         1587.9685080777854
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:47:04.504788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #9 | Epoch Duration: 157.08458042144775
2020-01-11 08:47:04.505105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #9 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2716494
Z variance train             0.016949352
KL Divergence                19.9461
KL Loss                      1.9946101
QF Loss                      118.43383
VF Loss                      47.96852
Policy Loss                  -265.51157
Q Predictions Mean           256.20065
Q Predictions Std            44.505463
Q Predictions Max            347.91415
Q Predictions Min            -32.078987
V Predictions Mean           266.38898
V Predictions Std            36.518963
V Predictions Max            346.9044
V Predictions Min            130.16882
Log Pis Mean                 -2.1776364
Log Pis Std                  2.1260383
Log Pis Max                  6.473493
Log Pis Min                  -7.971364
Policy mu Mean               0.031690158
Policy mu Std                0.4746193
Policy mu Max                1.9738665
Policy mu Min                -2.08809
Policy log std Mean          -0.79450125
Policy log std Std           0.11448454
Policy log std Max           -0.42741913
Policy log std Min           -1.2942061
Z mean eval                  1.2249701
Z variance eval              0.052916147
total_rewards                [ 57.76202872  73.40496994 181.26054651  25.11614882 233.6490263
  88.3178351    3.37968662 155.59808507 100.30297112 132.17303837]
total_rewards_mean           105.0964336569937
total_rewards_std            67.75163207505022
total_rewards_max            233.64902630475905
total_rewards_min            3.3796866191873063
Number of train steps total  44000
Number of env steps total    37295
Number of rollouts total     0
Train Time (s)               141.0189774800092
(Previous) Eval Time (s)     11.385064295958728
Sample Time (s)              6.7983630443923175
Epoch Time (s)               159.20240482036024
Total Train Time (s)         1747.2674076114781
Epoch                        10
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:43.803550 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #10 | Epoch Duration: 159.29822492599487
2020-01-11 08:49:43.803733 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2274332
Z variance train             0.0522726
KL Divergence                18.917606
KL Loss                      1.8917607
QF Loss                      152.22437
VF Loss                      45.540207
Policy Loss                  -263.60446
Q Predictions Mean           254.6348
Q Predictions Std            47.285706
Q Predictions Max            350.06577
Q Predictions Min            -5.8703737
V Predictions Mean           264.7847
V Predictions Std            38.881603
V Predictions Max            356.51883
V Predictions Min            144.98279
Log Pis Mean                 -1.769011
Log Pis Std                  2.4823027
Log Pis Max                  13.799524
Log Pis Min                  -8.403636
Policy mu Mean               0.008301479
Policy mu Std                0.50083345
Policy mu Max                1.9684383
Policy mu Min                -2.7843988
Policy log std Mean          -0.81688654
Policy log std Std           0.1297674
Policy log std Max           -0.39615852
Policy log std Min           -1.4771612
Z mean eval                  1.194039
Z variance eval              0.04699449
total_rewards                [115.17910326  18.41261368 185.49495632 300.75029527  96.39503332
  77.76595561 171.68611045 119.93004134   6.24970028 219.63874577]
total_rewards_mean           131.1502555296516
total_rewards_std            85.98813457401033
total_rewards_max            300.7502952745831
total_rewards_min            6.249700284703346
Number of train steps total  48000
Number of env steps total    40980
Number of rollouts total     0
Train Time (s)               142.55426561599597
(Previous) Eval Time (s)     10.617417114321142
Sample Time (s)              7.6141731617972255
Epoch Time (s)               160.78585589211434
Total Train Time (s)         1908.1353521449491
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:24.671906 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #11 | Epoch Duration: 160.86804866790771
2020-01-11 08:52:24.672029 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1936382
Z variance train             0.046965867
KL Divergence                15.472868
KL Loss                      1.5472869
QF Loss                      172.62578
VF Loss                      42.26564
Policy Loss                  -278.46985
Q Predictions Mean           270.30652
Q Predictions Std            47.19061
Q Predictions Max            384.00308
Q Predictions Min            95.54654
V Predictions Mean           278.08527
V Predictions Std            41.89321
V Predictions Max            403.81485
V Predictions Min            138.6223
Log Pis Mean                 -2.1741982
Log Pis Std                  2.1110692
Log Pis Max                  12.234837
Log Pis Min                  -9.71999
Policy mu Mean               0.011330564
Policy mu Std                0.45181355
Policy mu Max                2.4419782
Policy mu Min                -1.5957676
Policy log std Mean          -0.80341935
Policy log std Std           0.10872408
Policy log std Max           -0.4506765
Policy log std Min           -1.2434838
Z mean eval                  1.2311864
Z variance eval              0.03882878
total_rewards                [ 31.086504   222.22875562  86.51658983  13.64942101  56.58313109
  98.59159622 339.00125684 169.91858588 105.93535643 112.35327836]
total_rewards_mean           123.58644752762237
total_rewards_std            92.65473969122814
total_rewards_max            339.0012568357105
total_rewards_min            13.649421006091753
Number of train steps total  52000
Number of env steps total    44834
Number of rollouts total     0
Train Time (s)               141.20389555813745
(Previous) Eval Time (s)     7.6674763658083975
Sample Time (s)              6.962390806060284
Epoch Time (s)               155.83376273000613
Total Train Time (s)         2064.0558333857916
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:55:00.593033 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #12 | Epoch Duration: 155.92090559005737
2020-01-11 08:55:00.593163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2292631
Z variance train             0.038883634
KL Divergence                17.949032
KL Loss                      1.7949032
QF Loss                      179.11816
VF Loss                      63.425453
Policy Loss                  -286.91293
Q Predictions Mean           279.31064
Q Predictions Std            54.804264
Q Predictions Max            391.30582
Q Predictions Min            -36.565144
V Predictions Mean           287.46466
V Predictions Std            43.118183
V Predictions Max            394.88406
V Predictions Min            117.56519
Log Pis Mean                 -2.0359697
Log Pis Std                  2.0702584
Log Pis Max                  9.949184
Log Pis Min                  -7.864011
Policy mu Mean               -0.027216857
Policy mu Std                0.45063484
Policy mu Max                1.9094499
Policy mu Min                -1.7193376
Policy log std Mean          -0.8094741
Policy log std Std           0.11764505
Policy log std Max           -0.35417628
Policy log std Min           -1.6728528
Z mean eval                  1.2352687
Z variance eval              0.05452934
total_rewards                [157.41277309   9.59449926   2.60967416 136.06163572 194.74370301
 165.84939817 184.63262655  15.41792686 159.52794001  58.48004511]
total_rewards_mean           108.4330221933601
total_rewards_std            73.78369938533017
total_rewards_max            194.74370300613242
total_rewards_min            2.6096741637623806
Number of train steps total  56000
Number of env steps total    47686
Number of rollouts total     0
Train Time (s)               141.74132389202714
(Previous) Eval Time (s)     14.031895081046969
Sample Time (s)              8.05537430010736
Epoch Time (s)               163.82859327318147
Total Train Time (s)         2227.97193700308
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:57:44.509742 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #13 | Epoch Duration: 163.91648244857788
2020-01-11 08:57:44.509876 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2521077
Z variance train             0.054572888
KL Divergence                17.619154
KL Loss                      1.7619154
QF Loss                      210.2005
VF Loss                      98.92843
Policy Loss                  -293.5371
Q Predictions Mean           280.96783
Q Predictions Std            53.73496
Q Predictions Max            378.65903
Q Predictions Min            -20.573502
V Predictions Mean           286.9347
V Predictions Std            38.751392
V Predictions Max            380.85995
V Predictions Min            180.48601
Log Pis Mean                 -1.9800464
Log Pis Std                  2.2025857
Log Pis Max                  9.677994
Log Pis Min                  -7.6182184
Policy mu Mean               0.01583523
Policy mu Std                0.47452483
Policy mu Max                2.0204568
Policy mu Min                -1.8740348
Policy log std Mean          -0.82482666
Policy log std Std           0.11782867
Policy log std Max           -0.44659817
Policy log std Min           -1.5502508
Z mean eval                  1.2409363
Z variance eval              0.027026331
total_rewards                [506.08046489 335.24534864  19.08297732 264.49959995  62.75656632
  10.709165    68.46317252  38.12536161 270.84284868 258.73018687]
total_rewards_mean           183.45356918015523
total_rewards_std            158.98740169572852
total_rewards_max            506.0804648922434
total_rewards_min            10.709164999195615
Number of train steps total  60000
Number of env steps total    50498
Number of rollouts total     0
Train Time (s)               142.0682172542438
(Previous) Eval Time (s)     11.628335029818118
Sample Time (s)              7.92507941974327
Epoch Time (s)               161.62163170380518
Total Train Time (s)         2389.684918063227
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:26.225030 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #14 | Epoch Duration: 161.71502447128296
2020-01-11 09:00:26.225275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2448213
Z variance train             0.026712283
KL Divergence                17.539194
KL Loss                      1.7539195
QF Loss                      189.98056
VF Loss                      66.2955
Policy Loss                  -295.80194
Q Predictions Mean           289.14203
Q Predictions Std            52.320538
Q Predictions Max            411.57263
Q Predictions Min            -52.74068
V Predictions Mean           295.95557
V Predictions Std            42.59757
V Predictions Max            406.15912
V Predictions Min            102.23615
Log Pis Mean                 -1.7238072
Log Pis Std                  2.30844
Log Pis Max                  10.706467
Log Pis Min                  -13.135392
Policy mu Mean               -0.007913358
Policy mu Std                0.46483576
Policy mu Max                2.1267335
Policy mu Min                -2.5228608
Policy log std Mean          -0.8282003
Policy log std Std           0.108290866
Policy log std Max           -0.49230516
Policy log std Min           -1.3651485
Z mean eval                  1.0587561
Z variance eval              1.4937489
total_rewards                [346.63370201   3.40999653 300.82231335  65.24704057  40.63206447
  37.30127364 226.49318252 258.47541891 179.41056966   9.36401156]
total_rewards_mean           146.77895732239887
total_rewards_std            123.65438109333498
total_rewards_max            346.63370200744134
total_rewards_min            3.409996529751911
Number of train steps total  64000
Number of env steps total    53562
Number of rollouts total     0
Train Time (s)               143.38752017496154
(Previous) Eval Time (s)     11.41858685715124
Sample Time (s)              8.045400435570627
Epoch Time (s)               162.8515074676834
Total Train Time (s)         2552.6244476125576
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:09.164343 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #15 | Epoch Duration: 162.93888187408447
2020-01-11 09:03:09.164510 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0588167
Z variance train             1.4898326
KL Divergence                11.715773
KL Loss                      1.1715773
QF Loss                      2022.6699
VF Loss                      286.55435
Policy Loss                  -128.27718
Q Predictions Mean           118.53653
Q Predictions Std            67.2674
Q Predictions Max            255.98137
Q Predictions Min            -284.23486
V Predictions Mean           129.56226
V Predictions Std            57.908237
V Predictions Max            242.4132
V Predictions Min            -142.46873
Log Pis Mean                 -1.9090765
Log Pis Std                  2.458514
Log Pis Max                  9.876293
Log Pis Min                  -8.280579
Policy mu Mean               -0.040639494
Policy mu Std                0.5146521
Policy mu Max                2.6097124
Policy mu Min                -2.2331896
Policy log std Mean          -0.80797243
Policy log std Std           0.11892134
Policy log std Max           -0.28898108
Policy log std Min           -1.2553627
Z mean eval                  1.8488992
Z variance eval              0.081937194
total_rewards                [295.913051    36.29379566 202.09364123 106.99973945 345.54634259
  -5.77244881 313.10082713 327.87760705 342.17394187 226.83301881]
total_rewards_mean           219.1059515975186
total_rewards_std            124.34068170829724
total_rewards_max            345.5463425905481
total_rewards_min            -5.77244880781257
Number of train steps total  68000
Number of env steps total    57289
Number of rollouts total     0
Train Time (s)               144.97877884283662
(Previous) Eval Time (s)     13.927145711146295
Sample Time (s)              7.886932319961488
Epoch Time (s)               166.7928568739444
Total Train Time (s)         2719.5112504861318
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:05:56.053421 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #16 | Epoch Duration: 166.88872146606445
2020-01-11 09:05:56.053666 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8527167
Z variance train             0.08201
KL Divergence                19.298386
KL Loss                      1.9298385
QF Loss                      293.32727
VF Loss                      58.260406
Policy Loss                  -298.72116
Q Predictions Mean           289.9552
Q Predictions Std            63.506527
Q Predictions Max            408.04047
Q Predictions Min            -73.28572
V Predictions Mean           296.273
V Predictions Std            49.75334
V Predictions Max            415.0613
V Predictions Min            134.35818
Log Pis Mean                 -2.049823
Log Pis Std                  2.178531
Log Pis Max                  13.97377
Log Pis Min                  -7.276039
Policy mu Mean               -0.04580277
Policy mu Std                0.44421032
Policy mu Max                1.9261246
Policy mu Min                -3.279918
Policy log std Mean          -0.8269598
Policy log std Std           0.10514535
Policy log std Max           -0.36929253
Policy log std Min           -1.192596
Z mean eval                  1.614989
Z variance eval              0.025012514
total_rewards                [268.82863782 229.27390657 249.74659039 353.24339315 602.32021944
 201.7135997   66.43372248 249.13206742  37.30292237 222.0211047 ]
total_rewards_mean           248.00161640551346
total_rewards_std            147.50753406866755
total_rewards_max            602.320219442386
total_rewards_min            37.30292237426643
Number of train steps total  72000
Number of env steps total    60964
Number of rollouts total     0
Train Time (s)               143.37837423523888
(Previous) Eval Time (s)     14.41211416432634
Sample Time (s)              7.78039714274928
Epoch Time (s)               165.5708855423145
Total Train Time (s)         2885.16665915912
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:41.708019 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #17 | Epoch Duration: 165.65420532226562
2020-01-11 09:08:41.708205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6186485
Z variance train             0.025127774
KL Divergence                20.569925
KL Loss                      2.0569925
QF Loss                      193.87666
VF Loss                      45.22505
Policy Loss                  -279.23798
Q Predictions Mean           270.48114
Q Predictions Std            58.081463
Q Predictions Max            420.7239
Q Predictions Min            -26.581661
V Predictions Mean           278.6746
V Predictions Std            51.00408
V Predictions Max            409.18378
V Predictions Min            101.19509
Log Pis Mean                 -1.873828
Log Pis Std                  2.2422404
Log Pis Max                  17.395588
Log Pis Min                  -7.6207347
Policy mu Mean               -0.027827777
Policy mu Std                0.44692746
Policy mu Max                2.1661773
Policy mu Min                -3.6022441
Policy log std Mean          -0.8244444
Policy log std Std           0.1083318
Policy log std Max           -0.46018952
Policy log std Min           -1.3018069
Z mean eval                  1.5015248
Z variance eval              0.7662692
total_rewards                [152.15254175 225.17801905 127.9437396  302.20359838 220.05585799
  48.43475032  98.08006492 414.18376375 519.41795981 250.04929316]
total_rewards_mean           235.7699588747831
total_rewards_std            137.81708075643488
total_rewards_max            519.4179598143894
total_rewards_min            48.4347503172058
Number of train steps total  76000
Number of env steps total    64758
Number of rollouts total     0
Train Time (s)               143.72319936798885
(Previous) Eval Time (s)     15.006077724974602
Sample Time (s)              7.306839283090085
Epoch Time (s)               166.03611637605354
Total Train Time (s)         3051.293725831434
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:11:27.836857 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #18 | Epoch Duration: 166.12850713729858
2020-01-11 09:11:27.837065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5032921
Z variance train             0.76977134
KL Divergence                18.992323
KL Loss                      1.8992323
QF Loss                      671.24695
VF Loss                      138.83588
Policy Loss                  -222.22127
Q Predictions Mean           215.94748
Q Predictions Std            59.541687
Q Predictions Max            322.37076
Q Predictions Min            -93.81781
V Predictions Mean           223.08824
V Predictions Std            56.508057
V Predictions Max            319.17032
V Predictions Min            -44.83928
Log Pis Mean                 -1.8412473
Log Pis Std                  2.5843418
Log Pis Max                  11.5242405
Log Pis Min                  -8.095678
Policy mu Mean               0.0065205633
Policy mu Std                0.4775082
Policy mu Max                3.1156282
Policy mu Min                -3.0713654
Policy log std Mean          -0.80672747
Policy log std Std           0.10518376
Policy log std Max           -0.4360979
Policy log std Min           -1.4103628
Z mean eval                  1.5659702
Z variance eval              0.08519671
total_rewards                [352.21881295 316.49720052 247.39372845 233.68928728 267.68200589
 298.18362719 369.59564698  26.08095415 434.36360688 113.38317099]
total_rewards_mean           265.90880413000997
total_rewards_std            115.040760409786
total_rewards_max            434.3636068831716
total_rewards_min            26.08095414550003
Number of train steps total  80000
Number of env steps total    68203
Number of rollouts total     0
Train Time (s)               144.4419537349604
(Previous) Eval Time (s)     14.555694070179015
Sample Time (s)              7.253929130267352
Epoch Time (s)               166.25157693540677
Total Train Time (s)         3217.6433167150244
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:14:14.187467 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #19 | Epoch Duration: 166.35027384757996
2020-01-11 09:14:14.187638 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5655575
Z variance train             0.08465521
KL Divergence                17.616304
KL Loss                      1.7616304
QF Loss                      177.31882
VF Loss                      57.578163
Policy Loss                  -294.08224
Q Predictions Mean           284.17853
Q Predictions Std            60.35532
Q Predictions Max            400.77774
Q Predictions Min            -76.69588
V Predictions Mean           293.966
V Predictions Std            52.520905
V Predictions Max            395.28995
V Predictions Min            164.30649
Log Pis Mean                 -2.2181654
Log Pis Std                  1.9603051
Log Pis Max                  8.806093
Log Pis Min                  -9.184178
Policy mu Mean               0.0016970392
Policy mu Std                0.41476235
Policy mu Max                2.1269524
Policy mu Min                -2.1040452
Policy log std Mean          -0.8174001
Policy log std Std           0.09693909
Policy log std Max           -0.4814718
Policy log std Min           -1.3366938
Z mean eval                  1.5024348
Z variance eval              0.08193548
total_rewards                [127.85180996   8.157573   111.96237289 329.87033876  86.77304458
 416.76689973 221.03051555 240.97657915   9.72749056 221.78225667]
total_rewards_mean           177.48988808466186
total_rewards_std            126.5568824072273
total_rewards_max            416.7668997278629
total_rewards_min            8.157573000407616
Number of train steps total  84000
Number of env steps total    71066
Number of rollouts total     0
Train Time (s)               142.53482521604747
(Previous) Eval Time (s)     8.342148256953806
Sample Time (s)              7.468750944826752
Epoch Time (s)               158.34572441782802
Total Train Time (s)         3376.096176865045
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:16:52.640217 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #20 | Epoch Duration: 158.45246052742004
2020-01-11 09:16:52.640346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4981943
Z variance train             0.08244977
KL Divergence                16.088373
KL Loss                      1.6088374
QF Loss                      207.05843
VF Loss                      93.13861
Policy Loss                  -294.05203
Q Predictions Mean           285.94122
Q Predictions Std            62.23448
Q Predictions Max            425.43704
Q Predictions Min            120.31994
V Predictions Mean           300.91284
V Predictions Std            59.534122
V Predictions Max            426.5782
V Predictions Min            159.7103
Log Pis Mean                 -2.2562847
Log Pis Std                  1.8100909
Log Pis Max                  6.431778
Log Pis Min                  -8.03288
Policy mu Mean               -0.012776082
Policy mu Std                0.41358668
Policy mu Max                2.6456568
Policy mu Min                -2.2154357
Policy log std Mean          -0.82336783
Policy log std Std           0.09999219
Policy log std Max           -0.52522075
Policy log std Min           -1.35631
Z mean eval                  1.4743296
Z variance eval              0.092788436
total_rewards                [293.18976313 171.11514385 334.66350532  90.31564907  26.35651398
 406.93175549 269.63931987 592.5441753   42.75987275  81.18221033]
total_rewards_mean           230.86979090843852
total_rewards_std            173.4674737006214
total_rewards_max            592.5441752960861
total_rewards_min            26.356513976082972
Number of train steps total  88000
Number of env steps total    73850
Number of rollouts total     0
Train Time (s)               143.6683506811969
(Previous) Eval Time (s)     11.781096684746444
Sample Time (s)              7.013875283300877
Epoch Time (s)               162.46332264924422
Total Train Time (s)         3538.6411225702614
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:19:35.185634 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #21 | Epoch Duration: 162.54519653320312
2020-01-11 09:19:35.185768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4752138
Z variance train             0.09330125
KL Divergence                17.032389
KL Loss                      1.7032388
QF Loss                      211.0748
VF Loss                      55.888504
Policy Loss                  -319.42764
Q Predictions Mean           309.96014
Q Predictions Std            68.95718
Q Predictions Max            444.88144
Q Predictions Min            -70.65219
V Predictions Mean           319.13043
V Predictions Std            60.189083
V Predictions Max            447.16458
V Predictions Min            5.262998
Log Pis Mean                 -2.1116743
Log Pis Std                  2.2307985
Log Pis Max                  6.1221905
Log Pis Min                  -8.911749
Policy mu Mean               0.013008196
Policy mu Std                0.44260246
Policy mu Max                2.334398
Policy mu Min                -2.5458162
Policy log std Mean          -0.8271872
Policy log std Std           0.114999756
Policy log std Max           -0.51716894
Policy log std Min           -1.3650633
Z mean eval                  1.3903623
Z variance eval              0.6875854
total_rewards                [ 63.74746979 249.96287943 438.65335772 245.88785345 250.77000321
 368.00362111 332.38331739 395.71358642 287.68479416 373.75321587]
total_rewards_mean           300.6560098567862
total_rewards_std            101.64477461835655
total_rewards_max            438.65335772234044
total_rewards_min            63.74746979119476
Number of train steps total  92000
Number of env steps total    77681
Number of rollouts total     0
Train Time (s)               142.7529658190906
(Previous) Eval Time (s)     15.884361335076392
Sample Time (s)              7.100043709855527
Epoch Time (s)               165.73737086402252
Total Train Time (s)         3704.494678440038
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:22:21.041264 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #22 | Epoch Duration: 165.85537815093994
2020-01-11 09:22:21.041416 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3871938
Z variance train             0.69348097
KL Divergence                14.421608
KL Loss                      1.4421608
QF Loss                      337.36447
VF Loss                      78.72338
Policy Loss                  -303.72055
Q Predictions Mean           292.19946
Q Predictions Std            64.52302
Q Predictions Max            430.70395
Q Predictions Min            26.926544
V Predictions Mean           302.93048
V Predictions Std            59.956234
V Predictions Max            434.84653
V Predictions Min            101.955925
Log Pis Mean                 -2.2468586
Log Pis Std                  2.124006
Log Pis Max                  10.372297
Log Pis Min                  -10.432875
Policy mu Mean               -0.004841093
Policy mu Std                0.40892076
Policy mu Max                1.7377211
Policy mu Min                -2.6567407
Policy log std Mean          -0.80307055
Policy log std Std           0.098330505
Policy log std Max           -0.44332024
Policy log std Min           -1.299946
Z mean eval                  1.4131432
Z variance eval              0.15631346
total_rewards                [246.58095466 124.03198135 395.9003044   49.09799333 316.11446728
 285.66156198 160.64477439 171.11617651 118.80788625 150.54414958]
total_rewards_mean           201.85002497209933
total_rewards_std            100.64624502868733
total_rewards_max            395.9003043983193
total_rewards_min            49.09799332662413
Number of train steps total  96000
Number of env steps total    80414
Number of rollouts total     0
Train Time (s)               141.5497364392504
(Previous) Eval Time (s)     8.805050702765584
Sample Time (s)              6.915667461231351
Epoch Time (s)               157.27045460324734
Total Train Time (s)         3861.8546038009226
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:58.401790 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #23 | Epoch Duration: 157.36025142669678
2020-01-11 09:24:58.401955 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4139732
Z variance train             0.15594356
KL Divergence                15.520876
KL Loss                      1.5520877
QF Loss                      192.63638
VF Loss                      54.832005
Policy Loss                  -319.97522
Q Predictions Mean           312.87827
Q Predictions Std            65.37383
Q Predictions Max            469.3539
Q Predictions Min            5.033638
V Predictions Mean           318.47568
V Predictions Std            61.24233
V Predictions Max            453.18173
V Predictions Min            -44.648167
Log Pis Mean                 -2.0431437
Log Pis Std                  2.681402
Log Pis Max                  16.09293
Log Pis Min                  -10.850538
Policy mu Mean               0.01553829
Policy mu Std                0.4562821
Policy mu Max                2.7348514
Policy mu Min                -2.2647343
Policy log std Mean          -0.8198958
Policy log std Std           0.10336813
Policy log std Max           -0.36551303
Policy log std Min           -1.2241317
Z mean eval                  1.3098786
Z variance eval              0.080687486
total_rewards                [581.86826413 541.26648134 264.38845191  66.39073959 570.76130508
 151.08914333 486.43352493  12.48396833 314.23556636 349.85761407]
total_rewards_mean           333.8775059070619
total_rewards_std            199.40444740854227
total_rewards_max            581.8682641285448
total_rewards_min            12.483968327974656
Number of train steps total  100000
Number of env steps total    83946
Number of rollouts total     0
Train Time (s)               142.9686995120719
(Previous) Eval Time (s)     16.685245614033192
Sample Time (s)              7.064676808658987
Epoch Time (s)               166.7186219347641
Total Train Time (s)         4028.660490890965
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:27:45.208505 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #24 | Epoch Duration: 166.80641984939575
2020-01-11 09:27:45.208670 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3081201
Z variance train             0.08075199
KL Divergence                18.646107
KL Loss                      1.8646107
QF Loss                      240.99005
VF Loss                      69.98252
Policy Loss                  -334.93954
Q Predictions Mean           325.36362
Q Predictions Std            71.093285
Q Predictions Max            457.85498
Q Predictions Min            13.229513
V Predictions Mean           336.22168
V Predictions Std            63.43798
V Predictions Max            449.2353
V Predictions Min            189.83778
Log Pis Mean                 -1.9100759
Log Pis Std                  2.2490897
Log Pis Max                  10.036042
Log Pis Min                  -11.21586
Policy mu Mean               -0.023853466
Policy mu Std                0.4612702
Policy mu Max                2.657051
Policy mu Min                -2.586003
Policy log std Mean          -0.8394362
Policy log std Std           0.11208384
Policy log std Max           -0.5099423
Policy log std Min           -1.4350185
Z mean eval                  1.2259628
Z variance eval              0.15652607
total_rewards                [561.21885508 213.14550686 519.51753997  10.41608691 543.15843348
 151.92207822  40.40494806 386.76133859  89.67416288 324.00214691]
total_rewards_mean           284.02210969714616
total_rewards_std            201.50834545794294
total_rewards_max            561.2188550813192
total_rewards_min            10.416086910486815
Number of train steps total  104000
Number of env steps total    87403
Number of rollouts total     0
Train Time (s)               142.75435244105756
(Previous) Eval Time (s)     12.072514201048762
Sample Time (s)              6.117637334857136
Epoch Time (s)               160.94450397696346
Total Train Time (s)         4189.697303767782
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:26.249137 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #25 | Epoch Duration: 161.04030323028564
2020-01-11 09:30:26.249428 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #25 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2195035
Z variance train             0.15512276
KL Divergence                17.382479
KL Loss                      1.7382479
QF Loss                      238.93893
VF Loss                      45.25714
Policy Loss                  -330.92038
Q Predictions Mean           321.8761
Q Predictions Std            77.6279
Q Predictions Max            450.77884
Q Predictions Min            -31.453953
V Predictions Mean           331.1342
V Predictions Std            65.79694
V Predictions Max            445.78934
V Predictions Min            164.49243
Log Pis Mean                 -1.9123558
Log Pis Std                  2.228312
Log Pis Max                  10.719575
Log Pis Min                  -8.109683
Policy mu Mean               0.020845769
Policy mu Std                0.4579276
Policy mu Max                2.7725403
Policy mu Min                -2.0386605
Policy log std Mean          -0.843554
Policy log std Std           0.113587715
Policy log std Max           -0.44719946
Policy log std Min           -1.5740663
Z mean eval                  1.1309605
Z variance eval              0.16333702
total_rewards                [213.92989556  68.02926084 188.59257649 125.49175944  54.9466313
 475.04275066 721.93340853 387.90477344 134.08081699 208.81590506]
total_rewards_mean           257.87677782959776
total_rewards_std            199.65706880576437
total_rewards_max            721.9334085291596
total_rewards_min            54.946631297471605
Number of train steps total  108000
Number of env steps total    91708
Number of rollouts total     0
Train Time (s)               141.64102173689753
(Previous) Eval Time (s)     8.60058242501691
Sample Time (s)              6.343710031360388
Epoch Time (s)               156.58531419327483
Total Train Time (s)         4346.379768752959
Epoch                        26
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:33:02.932888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #26 | Epoch Duration: 156.6832504272461
2020-01-11 09:33:02.933076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1205807
Z variance train             0.16398205
KL Divergence                16.551863
KL Loss                      1.6551863
QF Loss                      173.3744
VF Loss                      65.40105
Policy Loss                  -335.28363
Q Predictions Mean           327.718
Q Predictions Std            75.40283
Q Predictions Max            463.47305
Q Predictions Min            59.821976
V Predictions Mean           339.85916
V Predictions Std            70.591255
V Predictions Max            469.45285
V Predictions Min            127.38439
Log Pis Mean                 -1.9890933
Log Pis Std                  2.3838682
Log Pis Max                  10.665473
Log Pis Min                  -7.6427603
Policy mu Mean               -0.0028432868
Policy mu Std                0.4588486
Policy mu Max                2.9649334
Policy mu Min                -2.0214546
Policy log std Mean          -0.8449781
Policy log std Std           0.11363183
Policy log std Max           -0.5502223
Policy log std Min           -1.5646765
Z mean eval                  1.1037648
Z variance eval              0.13311133
total_rewards                [ 70.51086802 219.11133819 339.46985459 120.91933211 316.57819443
 673.47218648 489.76897173 270.12625988 276.70674817  76.17429613]
total_rewards_mean           285.28380497265516
total_rewards_std            178.31765567582684
total_rewards_max            673.472186478164
total_rewards_min            70.51086801652134
Number of train steps total  112000
Number of env steps total    94507
Number of rollouts total     0
Train Time (s)               144.19412518804893
(Previous) Eval Time (s)     12.658020064700395
Sample Time (s)              8.327515542972833
Epoch Time (s)               165.17966079572216
Total Train Time (s)         4511.645366039593
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:48.198860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #27 | Epoch Duration: 165.2656307220459
2020-01-11 09:35:48.199034 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1019944
Z variance train             0.1334705
KL Divergence                17.18074
KL Loss                      1.7180741
QF Loss                      214.6241
VF Loss                      49.03959
Policy Loss                  -358.36777
Q Predictions Mean           349.3233
Q Predictions Std            80.814865
Q Predictions Max            492.40616
Q Predictions Min            20.09486
V Predictions Mean           361.51193
V Predictions Std            74.49082
V Predictions Max            495.45294
V Predictions Min            208.2307
Log Pis Mean                 -2.003181
Log Pis Std                  2.085034
Log Pis Max                  5.253095
Log Pis Min                  -10.26448
Policy mu Mean               0.020853147
Policy mu Std                0.44186527
Policy mu Max                2.1138086
Policy mu Min                -2.032359
Policy log std Mean          -0.83340275
Policy log std Std           0.11321932
Policy log std Max           -0.5148459
Policy log std Min           -1.3710018
Z mean eval                  1.1192663
Z variance eval              0.108401515
total_rewards                [316.44744569  45.15213591 461.37600326 142.24978323 104.61286767
 506.50163878 329.65259699 360.12653954 348.54768216  25.94038984]
total_rewards_mean           264.0607083072814
total_rewards_std            163.09753329677372
total_rewards_max            506.5016387794414
total_rewards_min            25.940389840973236
Number of train steps total  116000
Number of env steps total    100101
Number of rollouts total     0
Train Time (s)               143.20220974413678
(Previous) Eval Time (s)     11.985057478770614
Sample Time (s)              7.961622848175466
Epoch Time (s)               163.14889007108286
Total Train Time (s)         4674.883919271175
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:38:31.437996 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #28 | Epoch Duration: 163.23882794380188
2020-01-11 09:38:31.438170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.116224
Z variance train             0.10759542
KL Divergence                19.444387
KL Loss                      1.9444388
QF Loss                      232.53821
VF Loss                      119.171455
Policy Loss                  -360.52274
Q Predictions Mean           349.4389
Q Predictions Std            85.880936
Q Predictions Max            518.9741
Q Predictions Min            -29.775343
V Predictions Mean           368.8484
V Predictions Std            77.473694
V Predictions Max            538.94586
V Predictions Min            0.036931574
Log Pis Mean                 -2.01465
Log Pis Std                  2.733683
Log Pis Max                  19.02517
Log Pis Min                  -10.701426
Policy mu Mean               -0.012105611
Policy mu Std                0.4366371
Policy mu Max                3.1537638
Policy mu Min                -2.7296937
Policy log std Mean          -0.86076105
Policy log std Std           0.11782113
Policy log std Max           -0.43276638
Policy log std Min           -1.5738311
Z mean eval                  1.1106718
Z variance eval              0.10046746
total_rewards                [449.86018573 186.30581641 213.91841337  50.95165404 517.18930189
 402.77505018 655.61109069 409.85901451  33.90257992 219.12176694]
total_rewards_mean           313.94948736785966
total_rewards_std            194.03220327946957
total_rewards_max            655.6110906935247
total_rewards_min            33.902579924261836
Number of train steps total  120000
Number of env steps total    103341
Number of rollouts total     0
Train Time (s)               142.08452523406595
(Previous) Eval Time (s)     14.1843277993612
Sample Time (s)              8.319545150268823
Epoch Time (s)               164.58839818369597
Total Train Time (s)         4839.563770557288
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:41:16.118008 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #29 | Epoch Duration: 164.67972087860107
2020-01-11 09:41:16.118132 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1056046
Z variance train             0.099327974
KL Divergence                19.248423
KL Loss                      1.9248422
QF Loss                      338.3604
VF Loss                      113.61623
Policy Loss                  -362.89432
Q Predictions Mean           352.21918
Q Predictions Std            89.36734
Q Predictions Max            510.61313
Q Predictions Min            -26.054409
V Predictions Mean           367.72214
V Predictions Std            80.495155
V Predictions Max            517.4721
V Predictions Min            132.83145
Log Pis Mean                 -2.249192
Log Pis Std                  2.1486652
Log Pis Max                  7.29768
Log Pis Min                  -9.67733
Policy mu Mean               -0.0005794205
Policy mu Std                0.44045898
Policy mu Max                2.9191291
Policy mu Min                -2.2857935
Policy log std Mean          -0.82686794
Policy log std Std           0.113437556
Policy log std Max           -0.42223835
Policy log std Min           -1.31878
Z mean eval                  1.074774
Z variance eval              0.09478013
total_rewards                [ 210.74335057  283.60044467  299.809604   1120.881135    500.56943974
  407.56122299  405.1170959    25.00055703   76.20834919  104.03909275]
total_rewards_mean           343.35302918428147
total_rewards_std            298.3692195936439
total_rewards_max            1120.8811349985583
total_rewards_min            25.000557031206267
Number of train steps total  124000
Number of env steps total    106912
Number of rollouts total     0
Train Time (s)               143.6474451040849
(Previous) Eval Time (s)     10.709175459109247
Sample Time (s)              7.593364006374031
Epoch Time (s)               161.9499845695682
Total Train Time (s)         5001.608041541185
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:58.165383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #30 | Epoch Duration: 162.047123670578
2020-01-11 09:43:58.165640 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0755671
Z variance train             0.09470978
KL Divergence                18.9091
KL Loss                      1.89091
QF Loss                      264.11978
VF Loss                      95.569565
Policy Loss                  -384.71353
Q Predictions Mean           375.18594
Q Predictions Std            88.98485
Q Predictions Max            559.04584
Q Predictions Min            -14.313609
V Predictions Mean           386.8661
V Predictions Std            80.2772
V Predictions Max            562.9017
V Predictions Min            179.62364
Log Pis Mean                 -1.9375725
Log Pis Std                  2.3986297
Log Pis Max                  12.750274
Log Pis Min                  -7.17223
Policy mu Mean               -0.009041311
Policy mu Std                0.45056105
Policy mu Max                2.3169467
Policy mu Min                -2.6601737
Policy log std Mean          -0.8321742
Policy log std Std           0.1185514
Policy log std Max           -0.4286998
Policy log std Min           -1.3970866
Z mean eval                  1.1547363
Z variance eval              0.12876478
total_rewards                [272.84418594 198.14864978  33.84387483 139.66647204 674.70174621
 117.6859803  110.53438757 359.0885685  458.52091433 563.14932796]
total_rewards_mean           292.81841074471515
total_rewards_std            203.60408477841216
total_rewards_max            674.7017462086388
total_rewards_min            33.843874827480235
Number of train steps total  128000
Number of env steps total    110805
Number of rollouts total     0
Train Time (s)               142.86400828510523
(Previous) Eval Time (s)     8.992753934115171
Sample Time (s)              7.71446796413511
Epoch Time (s)               159.5712301833555
Total Train Time (s)         5161.373150805477
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:37.930277 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #31 | Epoch Duration: 159.76445198059082
2020-01-11 09:46:37.930440 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1450804
Z variance train             0.12800312
KL Divergence                17.86685
KL Loss                      1.786685
QF Loss                      257.07666
VF Loss                      78.816154
Policy Loss                  -384.28223
Q Predictions Mean           375.40405
Q Predictions Std            99.13603
Q Predictions Max            552.61456
Q Predictions Min            -59.88419
V Predictions Mean           385.71667
V Predictions Std            89.25545
V Predictions Max            554.1905
V Predictions Min            24.373487
Log Pis Mean                 -1.7707058
Log Pis Std                  2.2552295
Log Pis Max                  7.109766
Log Pis Min                  -7.683359
Policy mu Mean               -0.033412416
Policy mu Std                0.43847066
Policy mu Max                1.7211605
Policy mu Min                -2.6917052
Policy log std Mean          -0.8844969
Policy log std Std           0.11824624
Policy log std Max           -0.47739404
Policy log std Min           -1.3613063
Z mean eval                  1.1032331
Z variance eval              0.106402494
total_rewards                [374.92541288 408.06952451 363.31595295 415.52254661 391.33211651
 410.37240015 576.225536   524.80027439 126.27610574 106.46515777]
total_rewards_mean           369.73050274957916
total_rewards_std            141.7811119557516
total_rewards_max            576.2255359955942
total_rewards_min            106.46515777472476
Number of train steps total  132000
Number of env steps total    113690
Number of rollouts total     0
Train Time (s)               142.8146190578118
(Previous) Eval Time (s)     13.2027652929537
Sample Time (s)              8.376736132893711
Epoch Time (s)               164.3941204836592
Total Train Time (s)         5325.858129440807
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:49:22.417775 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #32 | Epoch Duration: 164.4871861934662
2020-01-11 09:49:22.418016 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1087506
Z variance train             0.10542886
KL Divergence                18.54756
KL Loss                      1.854756
QF Loss                      264.89352
VF Loss                      67.68289
Policy Loss                  -405.21594
Q Predictions Mean           396.46823
Q Predictions Std            91.16578
Q Predictions Max            561.1896
Q Predictions Min            100.052444
V Predictions Mean           401.8074
V Predictions Std            84.94592
V Predictions Max            559.67523
V Predictions Min            232.39539
Log Pis Mean                 -1.8012497
Log Pis Std                  2.162829
Log Pis Max                  8.087252
Log Pis Min                  -8.35373
Policy mu Mean               0.025496434
Policy mu Std                0.4199973
Policy mu Max                2.3041568
Policy mu Min                -2.1440327
Policy log std Mean          -0.8576665
Policy log std Std           0.1143531
Policy log std Max           -0.53531015
Policy log std Min           -1.403902
Z mean eval                  1.1221493
Z variance eval              0.101386234
total_rewards                [284.94949633 594.59187618 685.04315966 354.66537626 443.64580125
  39.23062143  44.51729652  96.68778371  18.91409825  91.22666047]
total_rewards_mean           265.34721700517264
total_rewards_std            233.25670862552153
total_rewards_max            685.0431596570926
total_rewards_min            18.91409825049008
Number of train steps total  136000
Number of env steps total    117696
Number of rollouts total     0
Train Time (s)               142.12019307166338
(Previous) Eval Time (s)     11.238026249688119
Sample Time (s)              8.747813567053527
Epoch Time (s)               162.10603288840503
Total Train Time (s)         5488.053823657334
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:04.613171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #33 | Epoch Duration: 162.19497275352478
2020-01-11 09:52:04.613337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1171304
Z variance train             0.10234468
KL Divergence                19.944416
KL Loss                      1.9944416
QF Loss                      277.0011
VF Loss                      56.285686
Policy Loss                  -397.01846
Q Predictions Mean           390.45837
Q Predictions Std            99.35573
Q Predictions Max            594.55273
Q Predictions Min            66.78801
V Predictions Mean           396.06927
V Predictions Std            93.08624
V Predictions Max            596.4248
V Predictions Min            218.38644
Log Pis Mean                 -1.7749093
Log Pis Std                  2.1505601
Log Pis Max                  6.5904665
Log Pis Min                  -7.284731
Policy mu Mean               0.029525515
Policy mu Std                0.45406467
Policy mu Max                2.8583255
Policy mu Min                -2.2743094
Policy log std Mean          -0.84704053
Policy log std Std           0.11979663
Policy log std Max           -0.36370206
Policy log std Min           -1.4752563
Z mean eval                  1.0854514
Z variance eval              0.055853046
total_rewards                [1016.03468982  102.43047738   38.81594039  155.04266388   10.63897794
  926.40723984  571.15600769 1198.28833341  337.92570883  608.54651794]
total_rewards_mean           496.5286557105069
total_rewards_std            413.271903860628
total_rewards_max            1198.2883334143291
total_rewards_min            10.63897793972126
Number of train steps total  140000
Number of env steps total    120739
Number of rollouts total     0
Train Time (s)               144.71449408773333
(Previous) Eval Time (s)     11.321788186673075
Sample Time (s)              8.24483651155606
Epoch Time (s)               164.28111878596246
Total Train Time (s)         5652.424280517735
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:54:48.986430 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #34 | Epoch Duration: 164.3729374408722
2020-01-11 09:54:48.986701 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0820919
Z variance train             0.056214966
KL Divergence                20.59255
KL Loss                      2.0592551
QF Loss                      232.02417
VF Loss                      65.56311
Policy Loss                  -388.45895
Q Predictions Mean           382.77142
Q Predictions Std            97.52831
Q Predictions Max            552.40515
Q Predictions Min            87.5926
V Predictions Mean           391.41852
V Predictions Std            93.366905
V Predictions Max            553.24976
V Predictions Min            197.76437
Log Pis Mean                 -2.0016265
Log Pis Std                  2.2006228
Log Pis Max                  8.782451
Log Pis Min                  -8.318294
Policy mu Mean               -0.018898422
Policy mu Std                0.41575983
Policy mu Max                2.4420671
Policy mu Min                -1.8765944
Policy log std Mean          -0.8600266
Policy log std Std           0.12425919
Policy log std Max           -0.4328881
Policy log std Min           -1.4726084
Z mean eval                  1.0805526
Z variance eval              0.10727088
total_rewards                [313.46257816 280.14411366 688.3029371  354.60468415 289.24591321
 267.95366718 575.48134954 397.09077334 513.63651022  23.03796012]
total_rewards_mean           370.2960486681885
total_rewards_std            177.123893139607
total_rewards_max            688.3029370965892
total_rewards_min            23.037960123213534
Number of train steps total  144000
Number of env steps total    124222
Number of rollouts total     0
Train Time (s)               144.09971705824137
(Previous) Eval Time (s)     14.909898562822491
Sample Time (s)              7.055587999988347
Epoch Time (s)               166.0652036210522
Total Train Time (s)         5818.579128027428
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:57:35.140063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #35 | Epoch Duration: 166.1531891822815
2020-01-11 09:57:35.140183 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #35 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0774615
Z variance train             0.10640633
KL Divergence                19.953634
KL Loss                      1.9953635
QF Loss                      192.32544
VF Loss                      58.29748
Policy Loss                  -404.74268
Q Predictions Mean           394.31952
Q Predictions Std            101.491356
Q Predictions Max            559.32043
Q Predictions Min            -36.205006
V Predictions Mean           407.19858
V Predictions Std            94.912636
V Predictions Max            570.7277
V Predictions Min            164.02367
Log Pis Mean                 -1.8818517
Log Pis Std                  2.4786916
Log Pis Max                  17.84372
Log Pis Min                  -8.235384
Policy mu Mean               -0.011347462
Policy mu Std                0.44506493
Policy mu Max                3.0210001
Policy mu Min                -2.646601
Policy log std Mean          -0.83684033
Policy log std Std           0.11376637
Policy log std Max           -0.42856455
Policy log std Min           -1.6592407
Z mean eval                  1.2089663
Z variance eval              0.08615413
total_rewards                [ 446.44947821  270.33032014  298.2945075   126.15877202  434.1032674
  311.3045004    95.27419322   85.39282321  347.73114975 1242.17465963]
total_rewards_mean           365.72136715047566
total_rewards_std            317.0820345079829
total_rewards_max            1242.1746596337462
total_rewards_min            85.39282321352356
Number of train steps total  148000
Number of env steps total    127664
Number of rollouts total     0
Train Time (s)               144.86841916199774
(Previous) Eval Time (s)     14.143510308116674
Sample Time (s)              7.499639661051333
Epoch Time (s)               166.51156913116574
Total Train Time (s)         5985.171309363563
Epoch                        36
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:00:21.733669 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #36 | Epoch Duration: 166.59339451789856
2020-01-11 10:00:21.733797 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2114908
Z variance train             0.085985385
KL Divergence                19.30655
KL Loss                      1.9306549
QF Loss                      364.92087
VF Loss                      50.93561
Policy Loss                  -393.2883
Q Predictions Mean           380.23694
Q Predictions Std            110.175896
Q Predictions Max            561.61304
Q Predictions Min            -38.21148
V Predictions Mean           390.89255
V Predictions Std            98.04447
V Predictions Max            567.275
V Predictions Min            149.67651
Log Pis Mean                 -2.003271
Log Pis Std                  2.65161
Log Pis Max                  21.054302
Log Pis Min                  -7.614522
Policy mu Mean               -0.0067068674
Policy mu Std                0.44692856
Policy mu Max                2.8535385
Policy mu Min                -3.140146
Policy log std Mean          -0.82663226
Policy log std Std           0.11832117
Policy log std Max           -0.26653123
Policy log std Min           -1.3466125
Z mean eval                  1.166592
Z variance eval              0.118464805
total_rewards                [ 392.78013666  496.72851534  146.27478842  484.23726545  594.59691145
  732.24569635  980.09649335 1408.65646473  856.11026762  437.91149333]
total_rewards_mean           652.9638032695893
total_rewards_std            339.5000586202499
total_rewards_max            1408.65646473404
total_rewards_min            146.2747884196358
Number of train steps total  152000
Number of env steps total    131631
Number of rollouts total     0
Train Time (s)               145.6553304749541
(Previous) Eval Time (s)     21.486014015972614
Sample Time (s)              7.998161303810775
Epoch Time (s)               175.1395057947375
Total Train Time (s)         6160.401113722008
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:03:16.967403 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #37 | Epoch Duration: 175.23349714279175
2020-01-11 10:03:16.967584 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.169514
Z variance train             0.119818665
KL Divergence                18.922022
KL Loss                      1.8922023
QF Loss                      277.3725
VF Loss                      59.06952
Policy Loss                  -432.26447
Q Predictions Mean           423.54898
Q Predictions Std            102.55293
Q Predictions Max            589.3574
Q Predictions Min            47.20288
V Predictions Mean           433.8764
V Predictions Std            97.152374
V Predictions Max            590.3503
V Predictions Min            144.30835
Log Pis Mean                 -1.824514
Log Pis Std                  2.4808707
Log Pis Max                  16.950676
Log Pis Min                  -8.916624
Policy mu Mean               -0.013823075
Policy mu Std                0.44914782
Policy mu Max                2.6909401
Policy mu Min                -2.9332314
Policy log std Mean          -0.8534274
Policy log std Std           0.12831454
Policy log std Max           -0.43703684
Policy log std Min           -1.525892
Z mean eval                  1.1108648
Z variance eval              0.14158583
total_rewards                [ 354.09818568  744.45663244  167.6259722   812.10725668   44.80068687
  312.89839213  619.32085183 1333.18439032  391.56255955  172.86063211]
total_rewards_mean           495.2915559803323
total_rewards_std            368.5287083734181
total_rewards_max            1333.184390323913
total_rewards_min            44.8006868689949
Number of train steps total  156000
Number of env steps total    135763
Number of rollouts total     0
Train Time (s)               144.78843928780407
(Previous) Eval Time (s)     16.07586873881519
Sample Time (s)              7.218191341962665
Epoch Time (s)               168.08249936858192
Total Train Time (s)         6328.583807923365
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:05.149489 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #38 | Epoch Duration: 168.18178486824036
2020-01-11 10:06:05.149620 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.107848
Z variance train             0.14127623
KL Divergence                20.28285
KL Loss                      2.028285
QF Loss                      301.11603
VF Loss                      52.111256
Policy Loss                  -399.09488
Q Predictions Mean           387.49146
Q Predictions Std            114.35835
Q Predictions Max            573.1845
Q Predictions Min            -42.548542
V Predictions Mean           399.9793
V Predictions Std            103.950195
V Predictions Max            561.6219
V Predictions Min            -35.892723
Log Pis Mean                 -1.6304306
Log Pis Std                  2.6533976
Log Pis Max                  18.23146
Log Pis Min                  -7.3345366
Policy mu Mean               0.022104356
Policy mu Std                0.49876192
Policy mu Max                2.4252317
Policy mu Min                -3.2537959
Policy log std Mean          -0.8653359
Policy log std Std           0.12933648
Policy log std Max           -0.42672294
Policy log std Min           -1.5144281
Z mean eval                  1.1532648
Z variance eval              0.21501406
total_rewards                [1181.77390096  325.19325102  389.81044161  407.94083937  500.24371839
  913.21291908  652.29230105  468.69615645  599.8552847  1461.46593674]
total_rewards_mean           690.0484749391502
total_rewards_std            358.3449634023701
total_rewards_max            1461.4659367404163
total_rewards_min            325.19325102470697
Number of train steps total  160000
Number of env steps total    139073
Number of rollouts total     0
Train Time (s)               143.53997314628214
(Previous) Eval Time (s)     23.24765849392861
Sample Time (s)              8.252730077598244
Epoch Time (s)               175.040361717809
Total Train Time (s)         6503.714907421265
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:00.281108 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #39 | Epoch Duration: 175.1313922405243
2020-01-11 10:09:00.281238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1569419
Z variance train             0.21455328
KL Divergence                18.94858
KL Loss                      1.894858
QF Loss                      253.76994
VF Loss                      60.13419
Policy Loss                  -422.27512
Q Predictions Mean           416.12405
Q Predictions Std            112.46446
Q Predictions Max            604.76
Q Predictions Min            -23.900085
V Predictions Mean           419.17084
V Predictions Std            111.00799
V Predictions Max            600.30646
V Predictions Min            -29.649628
Log Pis Mean                 -2.0392485
Log Pis Std                  2.6080012
Log Pis Max                  16.287262
Log Pis Min                  -12.933151
Policy mu Mean               -0.015865663
Policy mu Std                0.45737308
Policy mu Max                2.6745486
Policy mu Min                -2.148734
Policy log std Mean          -0.8463681
Policy log std Std           0.124303296
Policy log std Max           -0.45534164
Policy log std Min           -1.4163418
Z mean eval                  1.0344149
Z variance eval              1.0279735
total_rewards                [ 275.62267831  717.27599735  389.37949323  523.48705352  857.30717809
  625.03086375  580.60854046 1329.48598239  365.66169039  481.74051035]
total_rewards_mean           614.5599987852561
total_rewards_std            289.02053647879967
total_rewards_max            1329.4859823876536
total_rewards_min            275.6226783125579
Number of train steps total  164000
Number of env steps total    142362
Number of rollouts total     0
Train Time (s)               145.80130076408386
(Previous) Eval Time (s)     18.753162696957588
Sample Time (s)              7.356286248657852
Epoch Time (s)               171.9107497096993
Total Train Time (s)         6675.709654392209
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:11:52.276124 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #40 | Epoch Duration: 171.99479508399963
2020-01-11 10:11:52.276249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0375884
Z variance train             1.0273321
KL Divergence                16.016464
KL Loss                      1.6016464
QF Loss                      562.09424
VF Loss                      91.77645
Policy Loss                  -329.7248
Q Predictions Mean           322.99152
Q Predictions Std            105.45879
Q Predictions Max            505.58032
Q Predictions Min            38.69886
V Predictions Mean           329.2992
V Predictions Std            104.02642
V Predictions Max            498.72333
V Predictions Min            59.004265
Log Pis Mean                 -1.6766592
Log Pis Std                  2.4995358
Log Pis Max                  17.546389
Log Pis Min                  -7.8786497
Policy mu Mean               -0.016046189
Policy mu Std                0.4523378
Policy mu Max                2.1652222
Policy mu Min                -3.0731206
Policy log std Mean          -0.8728728
Policy log std Std           0.12458295
Policy log std Max           -0.43571922
Policy log std Min           -1.5650992
Z mean eval                  1.1235473
Z variance eval              0.111778006
total_rewards                [ 365.57508995  650.16445598  393.67397311  794.5175645   201.30308041
  541.70569119  458.15066747  331.55452806 1213.75443674  832.04152406]
total_rewards_mean           578.2441011460123
total_rewards_std            286.04637284982357
total_rewards_max            1213.7544367429819
total_rewards_min            201.30308040802714
Number of train steps total  168000
Number of env steps total    145495
Number of rollouts total     0
Train Time (s)               142.7106529213488
(Previous) Eval Time (s)     18.914740149397403
Sample Time (s)              7.063490350265056
Epoch Time (s)               168.68888342101127
Total Train Time (s)         6844.502658782061
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:14:41.069997 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #41 | Epoch Duration: 168.79365611076355
2020-01-11 10:14:41.070122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1239116
Z variance train             0.11242819
KL Divergence                19.393522
KL Loss                      1.9393523
QF Loss                      336.48267
VF Loss                      55.35859
Policy Loss                  -447.10968
Q Predictions Mean           436.60904
Q Predictions Std            118.344246
Q Predictions Max            635.5365
Q Predictions Min            15.78018
V Predictions Mean           447.72296
V Predictions Std            110.6588
V Predictions Max            627.29395
V Predictions Min            138.97182
Log Pis Mean                 -1.5737216
Log Pis Std                  2.3392277
Log Pis Max                  15.517468
Log Pis Min                  -7.8833036
Policy mu Mean               -0.018977834
Policy mu Std                0.45593154
Policy mu Max                2.9571888
Policy mu Min                -2.9259932
Policy log std Mean          -0.8705722
Policy log std Std           0.13160574
Policy log std Max           -0.36511382
Policy log std Min           -1.4446695
Z mean eval                  1.1812575
Z variance eval              0.18275
total_rewards                [ 447.45003392  100.6457406   183.69656933  385.98890658  842.61548828
  505.27695373 1647.5700297   477.36416452  877.53542823  185.18689655]
total_rewards_mean           565.3330211446915
total_rewards_std            436.9314064493013
total_rewards_max            1647.5700296953087
total_rewards_min            100.64574059872149
Number of train steps total  172000
Number of env steps total    148272
Number of rollouts total     0
Train Time (s)               144.4593676137738
(Previous) Eval Time (s)     12.339523398783058
Sample Time (s)              7.748739567119628
Epoch Time (s)               164.54763057967648
Total Train Time (s)         7009.23375492543
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:25.804423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #42 | Epoch Duration: 164.73418736457825
2020-01-11 10:17:25.804629 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1822789
Z variance train             0.1837117
KL Divergence                19.95278
KL Loss                      1.995278
QF Loss                      326.78162
VF Loss                      60.028664
Policy Loss                  -460.39432
Q Predictions Mean           452.65707
Q Predictions Std            122.139336
Q Predictions Max            641.58484
Q Predictions Min            10.830648
V Predictions Mean           460.5127
V Predictions Std            116.1928
V Predictions Max            637.81274
V Predictions Min            24.339104
Log Pis Mean                 -1.6683629
Log Pis Std                  2.7771008
Log Pis Max                  22.87386
Log Pis Min                  -9.261114
Policy mu Mean               -0.016543102
Policy mu Std                0.46934265
Policy mu Max                3.236747
Policy mu Min                -2.8891222
Policy log std Mean          -0.8758836
Policy log std Std           0.13685928
Policy log std Max           -0.45066583
Policy log std Min           -1.3091595
Z mean eval                  1.2178797
Z variance eval              0.2217432
total_rewards                [ 80.73226569 141.28005613 137.51389543 419.31362649 166.90016491
 117.83291832 824.1877877  875.20526426 393.46608983 592.24417239]
total_rewards_mean           374.86762411563467
total_rewards_std            284.34717071425166
total_rewards_max            875.2052642632648
total_rewards_min            80.7322656850848
Number of train steps total  176000
Number of env steps total    152113
Number of rollouts total     0
Train Time (s)               144.15347577026114
(Previous) Eval Time (s)     10.012605761177838
Sample Time (s)              8.380314327776432
Epoch Time (s)               162.5463958592154
Total Train Time (s)         7171.8760355310515
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:20:08.449075 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #43 | Epoch Duration: 162.64426732063293
2020-01-11 10:20:08.449329 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2129208
Z variance train             0.22267666
KL Divergence                18.1316
KL Loss                      1.81316
QF Loss                      472.5645
VF Loss                      63.956783
Policy Loss                  -450.86716
Q Predictions Mean           440.3175
Q Predictions Std            127.359726
Q Predictions Max            656.7356
Q Predictions Min            -4.4115133
V Predictions Mean           452.6147
V Predictions Std            121.625694
V Predictions Max            654.8582
V Predictions Min            249.65504
Log Pis Mean                 -2.1662233
Log Pis Std                  2.337334
Log Pis Max                  8.707562
Log Pis Min                  -8.090741
Policy mu Mean               -0.0058332407
Policy mu Std                0.45021224
Policy mu Max                2.1389844
Policy mu Min                -1.9273968
Policy log std Mean          -0.8546637
Policy log std Std           0.13224895
Policy log std Max           -0.45453888
Policy log std Min           -1.464488
Z mean eval                  1.2265797
Z variance eval              0.15401678
total_rewards                [  55.34839188  678.86257003  218.42507828 1193.6458483   628.73320853
  542.91819965  384.77594805  850.55942109  205.60678131  109.38213257]
total_rewards_mean           486.8257579686575
total_rewards_std            343.83610204516884
total_rewards_max            1193.6458483026865
total_rewards_min            55.34839188411003
Number of train steps total  180000
Number of env steps total    155067
Number of rollouts total     0
Train Time (s)               143.78009784501046
(Previous) Eval Time (s)     13.679471131879836
Sample Time (s)              8.480724306311458
Epoch Time (s)               165.94029328320175
Total Train Time (s)         7337.909032422584
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:22:54.481600 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #44 | Epoch Duration: 166.03210139274597
2020-01-11 10:22:54.481725 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2346087
Z variance train             0.15553173
KL Divergence                21.24101
KL Loss                      2.1241012
QF Loss                      476.06665
VF Loss                      119.4325
Policy Loss                  -447.03455
Q Predictions Mean           435.75143
Q Predictions Std            141.91544
Q Predictions Max            645.5941
Q Predictions Min            -96.41351
V Predictions Mean           440.56635
V Predictions Std            127.09387
V Predictions Max            642.2706
V Predictions Min            125.50493
Log Pis Mean                 -1.6776934
Log Pis Std                  2.4760766
Log Pis Max                  16.118256
Log Pis Min                  -7.290431
Policy mu Mean               -0.029087197
Policy mu Std                0.46315044
Policy mu Max                2.4780755
Policy mu Min                -1.8865812
Policy log std Mean          -0.8612047
Policy log std Std           0.13726176
Policy log std Max           -0.51196325
Policy log std Min           -1.4981601
Z mean eval                  1.1671879
Z variance eval              0.1268945
total_rewards                [946.26200104 378.30612579 387.2850044  251.47966967 392.05165218
 554.49147957 472.187705   403.37664326 198.06694924 312.2258187 ]
total_rewards_mean           429.57330488416636
total_rewards_std            197.4794869928987
total_rewards_max            946.262001035935
total_rewards_min            198.06694924020996
Number of train steps total  184000
Number of env steps total    158522
Number of rollouts total     0
Train Time (s)               142.2499960870482
(Previous) Eval Time (s)     12.907164838165045
Sample Time (s)              6.542645736597478
Epoch Time (s)               161.69980666181073
Total Train Time (s)         7499.703178117052
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:25:36.278289 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #45 | Epoch Duration: 161.79645442962646
2020-01-11 10:25:36.278472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1664449
Z variance train             0.12658267
KL Divergence                20.287424
KL Loss                      2.0287426
QF Loss                      289.86472
VF Loss                      109.83557
Policy Loss                  -459.06097
Q Predictions Mean           455.1936
Q Predictions Std            130.3462
Q Predictions Max            703.8639
Q Predictions Min            21.09851
V Predictions Mean           464.00397
V Predictions Std            128.5451
V Predictions Max            709.96576
V Predictions Min            52.22766
Log Pis Mean                 -1.7389636
Log Pis Std                  2.3588812
Log Pis Max                  10.02162
Log Pis Min                  -9.704734
Policy mu Mean               0.01531207
Policy mu Std                0.44409183
Policy mu Max                2.6559582
Policy mu Min                -2.1453145
Policy log std Mean          -0.87302923
Policy log std Std           0.1414183
Policy log std Max           -0.39293912
Policy log std Min           -1.5950279
Z mean eval                  1.1685212
Z variance eval              0.12687364
total_rewards                [ 324.00375289  404.49662352   65.9169403    45.91591395  446.45132995
  554.91034002  132.2667169   579.83384577 1205.06759038 1204.02707024]
total_rewards_mean           496.2890123916105
total_rewards_std            396.84210438434826
total_rewards_max            1205.0675903836202
total_rewards_min            45.915913950692236
Number of train steps total  188000
Number of env steps total    162353
Number of rollouts total     0
Train Time (s)               142.82717890990898
(Previous) Eval Time (s)     14.884181051049381
Sample Time (s)              7.260327175725251
Epoch Time (s)               164.9716871366836
Total Train Time (s)         7664.786807407159
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:21.361692 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #46 | Epoch Duration: 165.0830910205841
2020-01-11 10:28:21.361818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1690638
Z variance train             0.12602279
KL Divergence                21.660154
KL Loss                      2.1660154
QF Loss                      634.85034
VF Loss                      80.66729
Policy Loss                  -476.44818
Q Predictions Mean           465.8277
Q Predictions Std            136.4248
Q Predictions Max            683.3386
Q Predictions Min            4.6299553
V Predictions Mean           475.81458
V Predictions Std            130.34077
V Predictions Max            687.03265
V Predictions Min            60.544838
Log Pis Mean                 -1.4601258
Log Pis Std                  2.756897
Log Pis Max                  16.965364
Log Pis Min                  -6.9199514
Policy mu Mean               0.0098048225
Policy mu Std                0.50248516
Policy mu Max                3.1438785
Policy mu Min                -3.940904
Policy log std Mean          -0.8837291
Policy log std Std           0.14938414
Policy log std Max           -0.5071338
Policy log std Min           -1.4933319
Z mean eval                  1.1742878
Z variance eval              0.19760832
total_rewards                [ 649.9848343   609.84874144 1860.09043579 1319.61534853  587.60013564
  366.31052644  724.12362074  927.06635247  968.01798401  715.68456121]
total_rewards_mean           872.8342540559457
total_rewards_std            411.07761904451445
total_rewards_max            1860.0904357867066
total_rewards_min            366.3105264377391
Number of train steps total  192000
Number of env steps total    165120
Number of rollouts total     0
Train Time (s)               145.37884745607153
(Previous) Eval Time (s)     21.1364226359874
Sample Time (s)              7.407612290699035
Epoch Time (s)               173.92288238275796
Total Train Time (s)         7838.79842199944
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:15.376387 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #47 | Epoch Duration: 174.01446151733398
2020-01-11 10:31:15.376576 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1728784
Z variance train             0.19838464
KL Divergence                18.426031
KL Loss                      1.8426031
QF Loss                      381.31586
VF Loss                      85.003685
Policy Loss                  -481.64392
Q Predictions Mean           472.50595
Q Predictions Std            150.38268
Q Predictions Max            680.355
Q Predictions Min            -55.04061
V Predictions Mean           486.29166
V Predictions Std            139.83498
V Predictions Max            684.70264
V Predictions Min            27.450062
Log Pis Mean                 -1.6055529
Log Pis Std                  2.7865846
Log Pis Max                  15.212225
Log Pis Min                  -7.0745764
Policy mu Mean               -0.015426891
Policy mu Std                0.46545613
Policy mu Max                3.3916767
Policy mu Min                -2.917479
Policy log std Mean          -0.87306
Policy log std Std           0.13725083
Policy log std Max           -0.53647536
Policy log std Min           -1.4637125
Z mean eval                  1.2098489
Z variance eval              0.12895748
total_rewards                [  70.61085765  191.33427564 1026.67854069  404.68192154  439.68728001
  635.13397212 1376.53680768  678.23885699  853.67510567  162.84922954]
total_rewards_mean           583.9426847516817
total_rewards_std            394.5127431903948
total_rewards_max            1376.5368076769719
total_rewards_min            70.6108576524567
Number of train steps total  196000
Number of env steps total    169752
Number of rollouts total     0
Train Time (s)               142.59764869278297
(Previous) Eval Time (s)     15.199745423160493
Sample Time (s)              8.037779527250677
Epoch Time (s)               165.83517364319414
Total Train Time (s)         8004.721827631351
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:01.303194 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #48 | Epoch Duration: 165.92644691467285
2020-01-11 10:34:01.303486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2125552
Z variance train             0.12765834
KL Divergence                20.270243
KL Loss                      2.0270243
QF Loss                      410.83368
VF Loss                      106.321526
Policy Loss                  -469.78656
Q Predictions Mean           459.47705
Q Predictions Std            153.11336
Q Predictions Max            677.8222
Q Predictions Min            -29.434946
V Predictions Mean           471.0127
V Predictions Std            142.72656
V Predictions Max            693.6159
V Predictions Min            17.027264
Log Pis Mean                 -1.4696815
Log Pis Std                  2.9109979
Log Pis Max                  16.687752
Log Pis Min                  -8.809909
Policy mu Mean               0.009598843
Policy mu Std                0.49257377
Policy mu Max                4.037844
Policy mu Min                -2.6921659
Policy log std Mean          -0.88788426
Policy log std Std           0.14631861
Policy log std Max           -0.52571493
Policy log std Min           -1.5694311
Z mean eval                  1.1687399
Z variance eval              0.069232896
total_rewards                [ 124.19570495 1475.23839395 1939.49671793  529.74209896   83.66546649
  525.24989924 1749.67587019   71.2675836  1979.46154038  769.57924576]
total_rewards_mean           924.757252145504
total_rewards_std            744.4541382724644
total_rewards_max            1979.46154037792
total_rewards_min            71.26758360234244
Number of train steps total  200000
Number of env steps total    172564
Number of rollouts total     0
Train Time (s)               142.71135110221803
(Previous) Eval Time (s)     12.167868859134614
Sample Time (s)              8.056229673326015
Epoch Time (s)               162.93544963467866
Total Train Time (s)         8167.748153268825
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:44.330491 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #49 | Epoch Duration: 163.02677536010742
2020-01-11 10:36:44.330765 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1691247
Z variance train             0.06910814
KL Divergence                20.760818
KL Loss                      2.076082
QF Loss                      285.96063
VF Loss                      63.182583
Policy Loss                  -480.4419
Q Predictions Mean           471.9278
Q Predictions Std            140.52518
Q Predictions Max            682.0389
Q Predictions Min            153.84991
V Predictions Mean           477.67657
V Predictions Std            133.59401
V Predictions Max            673.72687
V Predictions Min            239.94986
Log Pis Mean                 -1.4970994
Log Pis Std                  2.2811983
Log Pis Max                  5.89834
Log Pis Min                  -8.412144
Policy mu Mean               -0.025159663
Policy mu Std                0.46869996
Policy mu Max                3.0730767
Policy mu Min                -2.3382413
Policy log std Mean          -0.8941153
Policy log std Std           0.13692102
Policy log std Max           -0.5214796
Policy log std Min           -1.5978582
Z mean eval                  1.204637
Z variance eval              0.09859077
total_rewards                [ 410.73898781  237.38163064  316.91710966  813.85880179  514.05550493
  253.2967944   477.26272481   94.7483893   156.79962355 1487.31469467]
total_rewards_mean           476.23742615639384
total_rewards_std            390.0895684968289
total_rewards_max            1487.3146946722554
total_rewards_min            94.74838929988107
Number of train steps total  204000
Number of env steps total    175096
Number of rollouts total     0
Train Time (s)               143.06494116224349
(Previous) Eval Time (s)     13.924872046802193
Sample Time (s)              7.849474349524826
Epoch Time (s)               164.8392875585705
Total Train Time (s)         8332.691558903083
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:29.273391 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #50 | Epoch Duration: 164.94245219230652
2020-01-11 10:39:29.273520 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2016355
Z variance train             0.0975174
KL Divergence                21.494123
KL Loss                      2.1494124
QF Loss                      424.98697
VF Loss                      69.00369
Policy Loss                  -478.51047
Q Predictions Mean           468.61496
Q Predictions Std            143.13135
Q Predictions Max            685.3
Q Predictions Min            117.146355
V Predictions Mean           481.33978
V Predictions Std            136.73254
V Predictions Max            686.91406
V Predictions Min            219.76372
Log Pis Mean                 -1.800879
Log Pis Std                  2.5858011
Log Pis Max                  13.303343
Log Pis Min                  -8.269268
Policy mu Mean               -0.019699503
Policy mu Std                0.4663795
Policy mu Max                2.6751075
Policy mu Min                -1.8309547
Policy log std Mean          -0.86197686
Policy log std Std           0.13322358
Policy log std Max           -0.48302287
Policy log std Min           -1.472672
Z mean eval                  1.1889696
Z variance eval              0.116606906
total_rewards                [135.03279248 910.68769439 778.69223115 927.22800686 494.27036736
 394.69919017 758.02812562 512.14420801 647.49360589  90.71615135]
total_rewards_mean           564.8992373259125
total_rewards_std            280.5448594363429
total_rewards_max            927.2280068589282
total_rewards_min            90.71615134530279
Number of train steps total  208000
Number of env steps total    178693
Number of rollouts total     0
Train Time (s)               145.8926000930369
(Previous) Eval Time (s)     11.205335995182395
Sample Time (s)              7.551695164293051
Epoch Time (s)               164.64963125251234
Total Train Time (s)         8497.566082716454
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:14.150912 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #51 | Epoch Duration: 164.8772885799408
2020-01-11 10:42:14.151078 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1928624
Z variance train             0.11767354
KL Divergence                21.20564
KL Loss                      2.1205642
QF Loss                      445.6084
VF Loss                      84.89739
Policy Loss                  -477.75284
Q Predictions Mean           465.0235
Q Predictions Std            145.60803
Q Predictions Max            670.15985
Q Predictions Min            59.85801
V Predictions Mean           475.49896
V Predictions Std            138.14053
V Predictions Max            662.50836
V Predictions Min            177.9396
Log Pis Mean                 -1.5849783
Log Pis Std                  2.726274
Log Pis Max                  14.110834
Log Pis Min                  -8.443644
Policy mu Mean               -0.018637791
Policy mu Std                0.5119774
Policy mu Max                2.957389
Policy mu Min                -4.134094
Policy log std Mean          -0.86951673
Policy log std Std           0.13868164
Policy log std Max           -0.51493156
Policy log std Min           -1.4649253
Z mean eval                  1.2274773
Z variance eval              0.059693117
total_rewards                [1273.5646998   435.81180665  379.38996036  442.36170108  381.70752697
  199.24539452  237.51520993  483.55221433   40.01962627  258.85652593]
total_rewards_mean           413.2024665839032
total_rewards_std            314.3884002163227
total_rewards_max            1273.5646997998067
total_rewards_min            40.01962626646295
Number of train steps total  212000
Number of env steps total    181357
Number of rollouts total     0
Train Time (s)               144.65228182589635
(Previous) Eval Time (s)     14.006449289154261
Sample Time (s)              6.718503509648144
Epoch Time (s)               165.37723462469876
Total Train Time (s)         8663.037482446525
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:44:59.621483 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #52 | Epoch Duration: 165.4702866077423
2020-01-11 10:44:59.621615 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2259809
Z variance train             0.059520386
KL Divergence                22.230179
KL Loss                      2.223018
QF Loss                      408.9403
VF Loss                      98.581924
Policy Loss                  -497.87463
Q Predictions Mean           489.16974
Q Predictions Std            152.22012
Q Predictions Max            764.08716
Q Predictions Min            14.297397
V Predictions Mean           497.80804
V Predictions Std            145.71841
V Predictions Max            769.1171
V Predictions Min            195.4393
Log Pis Mean                 -1.5614474
Log Pis Std                  2.8758788
Log Pis Max                  25.8279
Log Pis Min                  -7.589221
Policy mu Mean               -0.023855131
Policy mu Std                0.48865083
Policy mu Max                3.2825649
Policy mu Min                -3.5346909
Policy log std Mean          -0.8975897
Policy log std Std           0.15578564
Policy log std Max           -0.46957773
Policy log std Min           -1.588601
Z mean eval                  1.1689332
Z variance eval              0.03220611
total_rewards                [1647.53710908 1009.33871706  243.99373022 1889.39659315  935.83655092
  210.5615695   435.83784451 1151.81494945  817.40495713  208.17475747]
total_rewards_mean           854.9896778494622
total_rewards_std            565.744485482758
total_rewards_max            1889.3965931511293
total_rewards_min            208.1747574656016
Number of train steps total  216000
Number of env steps total    185162
Number of rollouts total     0
Train Time (s)               145.0184268350713
(Previous) Eval Time (s)     15.362902639899403
Sample Time (s)              7.97019478213042
Epoch Time (s)               168.35152425710112
Total Train Time (s)         8831.496851180214
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:48.081153 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #53 | Epoch Duration: 168.45944786071777
2020-01-11 10:47:48.081283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1686115
Z variance train             0.032246478
KL Divergence                23.41534
KL Loss                      2.3415341
QF Loss                      479.4784
VF Loss                      109.89279
Policy Loss                  -488.93015
Q Predictions Mean           479.9027
Q Predictions Std            167.17554
Q Predictions Max            720.8208
Q Predictions Min            -29.510443
V Predictions Mean           491.87634
V Predictions Std            160.48055
V Predictions Max            719.26337
V Predictions Min            68.676056
Log Pis Mean                 -1.542728
Log Pis Std                  2.6841564
Log Pis Max                  15.118633
Log Pis Min                  -7.488576
Policy mu Mean               0.010496601
Policy mu Std                0.49727094
Policy mu Max                3.2836618
Policy mu Min                -2.7486224
Policy log std Mean          -0.878568
Policy log std Std           0.14188401
Policy log std Max           -0.47321156
Policy log std Min           -1.4945273
Z mean eval                  1.210197
Z variance eval              0.02971777
total_rewards                [ 699.71755661 1085.2120407   750.57658584  730.79696093  347.14235631
  494.33484803  763.00692842 1291.4293188   167.83732977  141.83016131]
total_rewards_mean           647.1884086719829
total_rewards_std            352.0397787380997
total_rewards_max            1291.4293188001548
total_rewards_min            141.83016131316296
Number of train steps total  220000
Number of env steps total    188505
Number of rollouts total     0
Train Time (s)               144.62049697712064
(Previous) Eval Time (s)     15.125950478948653
Sample Time (s)              7.183299260679632
Epoch Time (s)               166.92974671674892
Total Train Time (s)         8998.52644388238
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:35.114148 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #54 | Epoch Duration: 167.03275275230408
2020-01-11 10:50:35.114357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2083272
Z variance train             0.029755052
KL Divergence                23.398241
KL Loss                      2.3398242
QF Loss                      543.2139
VF Loss                      180.6368
Policy Loss                  -514.0864
Q Predictions Mean           500.65665
Q Predictions Std            171.09041
Q Predictions Max            758.0776
Q Predictions Min            -63.255
V Predictions Mean           521.2175
V Predictions Std            156.97435
V Predictions Max            757.955
V Predictions Min            98.457
Log Pis Mean                 -1.2720447
Log Pis Std                  3.015277
Log Pis Max                  16.505337
Log Pis Min                  -8.804215
Policy mu Mean               0.024098087
Policy mu Std                0.51071084
Policy mu Max                2.820166
Policy mu Min                -2.3773272
Policy log std Mean          -0.893276
Policy log std Std           0.16153163
Policy log std Max           -0.35764182
Policy log std Min           -1.8261765
Z mean eval                  1.1876359
Z variance eval              0.033648796
total_rewards                [ 778.60465585  805.56729409  304.34159451 1879.91455406 1151.40974269
  559.44696016   63.47006349  501.63509613  985.49948559  989.74292001]
total_rewards_mean           801.9632366571807
total_rewards_std            479.1250235429383
total_rewards_max            1879.9145540589031
total_rewards_min            63.47006349070058
Number of train steps total  224000
Number of env steps total    191140
Number of rollouts total     0
Train Time (s)               145.64703004434705
(Previous) Eval Time (s)     16.744545691180974
Sample Time (s)              7.669225509278476
Epoch Time (s)               170.0608012448065
Total Train Time (s)         9168.673815289978
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:25.261547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #55 | Epoch Duration: 170.14702653884888
2020-01-11 10:53:25.261731 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.191396
Z variance train             0.033742674
KL Divergence                23.444592
KL Loss                      2.3444593
QF Loss                      281.79254
VF Loss                      73.51439
Policy Loss                  -508.23465
Q Predictions Mean           501.35602
Q Predictions Std            163.97076
Q Predictions Max            734.5771
Q Predictions Min            201.2461
V Predictions Mean           505.0125
V Predictions Std            159.48674
V Predictions Max            725.7277
V Predictions Min            205.18596
Log Pis Mean                 -1.5633518
Log Pis Std                  2.7111273
Log Pis Max                  10.009955
Log Pis Min                  -8.05175
Policy mu Mean               -0.018966947
Policy mu Std                0.48334798
Policy mu Max                2.3409321
Policy mu Min                -2.3813267
Policy log std Mean          -0.90132743
Policy log std Std           0.16444
Policy log std Max           -0.34631544
Policy log std Min           -1.7046839
Z mean eval                  1.2029397
Z variance eval              0.057627857
total_rewards                [1963.12866071  568.76620747 1181.20971931  459.99637155 2044.61916775
  301.69301642 1813.19258348  666.64600124 1735.26606132 2200.58364853]
total_rewards_mean           1293.5101437777903
total_rewards_std            700.7013936263695
total_rewards_max            2200.583648525958
total_rewards_min            301.69301641671944
Number of train steps total  228000
Number of env steps total    194460
Number of rollouts total     0
Train Time (s)               143.47309887502342
(Previous) Eval Time (s)     18.041773489676416
Sample Time (s)              6.5194517485797405
Epoch Time (s)               168.03432411327958
Total Train Time (s)         9337.043763888534
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:56:13.635628 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #56 | Epoch Duration: 168.37367129325867
2020-01-11 10:56:13.636012 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #56 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1986845
Z variance train             0.057873167
KL Divergence                22.263008
KL Loss                      2.226301
QF Loss                      460.4098
VF Loss                      72.19021
Policy Loss                  -525.57526
Q Predictions Mean           516.35803
Q Predictions Std            171.59584
Q Predictions Max            763.7723
Q Predictions Min            -27.108917
V Predictions Mean           528.8555
V Predictions Std            164.4663
V Predictions Max            753.67694
V Predictions Min            -17.140556
Log Pis Mean                 -1.2298514
Log Pis Std                  2.6803238
Log Pis Max                  12.328424
Log Pis Min                  -7.8007755
Policy mu Mean               -0.030963248
Policy mu Std                0.5028134
Policy mu Max                2.2610962
Policy mu Min                -2.4717991
Policy log std Mean          -0.9080126
Policy log std Std           0.16461067
Policy log std Max           -0.36675897
Policy log std Min           -1.6186333
Z mean eval                  1.2081642
Z variance eval              0.12534028
total_rewards                [ 380.49559135  547.0129587   729.77565152   61.79194898  635.8535536
  439.69651104 1384.33209655 1101.82661018  441.86165152  131.36692456]
total_rewards_mean           585.4013498007519
total_rewards_std            386.520684943556
total_rewards_max            1384.3320965462012
total_rewards_min            61.791948983798406
Number of train steps total  232000
Number of env steps total    199919
Number of rollouts total     0
Train Time (s)               145.58043051883578
(Previous) Eval Time (s)     10.963053070940077
Sample Time (s)              6.8337507313117385
Epoch Time (s)               163.3772343210876
Total Train Time (s)         9500.514939548448
Epoch                        57
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:57.107339 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #57 | Epoch Duration: 163.47110795974731
2020-01-11 10:58:57.107557 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2110854
Z variance train             0.12502155
KL Divergence                19.470215
KL Loss                      1.9470215
QF Loss                      605.7673
VF Loss                      91.20628
Policy Loss                  -525.65924
Q Predictions Mean           511.75153
Q Predictions Std            193.82027
Q Predictions Max            794.82086
Q Predictions Min            -15.523285
V Predictions Mean           528.1444
V Predictions Std            184.53658
V Predictions Max            801.66425
V Predictions Min            28.902649
Log Pis Mean                 -1.4001656
Log Pis Std                  2.9913642
Log Pis Max                  20.700794
Log Pis Min                  -8.17602
Policy mu Mean               -0.007393729
Policy mu Std                0.5172099
Policy mu Max                4.8256183
Policy mu Min                -2.8748932
Policy log std Mean          -0.88795865
Policy log std Std           0.16170108
Policy log std Max           -0.08808488
Policy log std Min           -1.5344931
Z mean eval                  1.162922
Z variance eval              0.106311664
total_rewards                [ 798.9398399  1230.17773255  591.64635929  992.94639751  612.23278298
  964.29783251  604.702612   1528.05529857  213.34985071   20.91603987]
total_rewards_mean           755.7264745874774
total_rewards_std            427.5135336557937
total_rewards_max            1528.0552985652012
total_rewards_min            20.9160398671749
Number of train steps total  236000
Number of env steps total    202346
Number of rollouts total     0
Train Time (s)               145.65775942895561
(Previous) Eval Time (s)     13.49333707196638
Sample Time (s)              7.8150487476959825
Epoch Time (s)               166.96614524861798
Total Train Time (s)         9667.579115648754
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:44.172479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #58 | Epoch Duration: 167.06473398208618
2020-01-11 11:01:44.172708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1620739
Z variance train             0.10626538
KL Divergence                19.720673
KL Loss                      1.9720672
QF Loss                      448.07922
VF Loss                      182.11197
Policy Loss                  -505.52875
Q Predictions Mean           493.3727
Q Predictions Std            181.62595
Q Predictions Max            763.214
Q Predictions Min            -64.07356
V Predictions Mean           505.99573
V Predictions Std            173.59831
V Predictions Max            769.3136
V Predictions Min            61.100418
Log Pis Mean                 -1.2049539
Log Pis Std                  3.167538
Log Pis Max                  13.696207
Log Pis Min                  -8.312223
Policy mu Mean               -0.029980896
Policy mu Std                0.5279167
Policy mu Max                3.344237
Policy mu Min                -2.5231411
Policy log std Mean          -0.8952067
Policy log std Std           0.17648388
Policy log std Max           -0.44702458
Policy log std Min           -1.9041862
Z mean eval                  1.1940835
Z variance eval              0.050596543
total_rewards                [ 177.4461733   631.4180695  1050.7002551   230.55158745   24.50135131
  715.73023012   61.40467708  510.92590398  647.28300165  712.94055234]
total_rewards_mean           476.29018018135747
total_rewards_std            319.95672109079294
total_rewards_max            1050.7002551023743
total_rewards_min            24.50135130544469
Number of train steps total  240000
Number of env steps total    205971
Number of rollouts total     0
Train Time (s)               146.059640141204
(Previous) Eval Time (s)     8.901139779947698
Sample Time (s)              7.758357693441212
Epoch Time (s)               162.7191376145929
Total Train Time (s)         9830.381129050162
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:26.975912 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #59 | Epoch Duration: 162.8030915260315
2020-01-11 11:04:26.976035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.193649
Z variance train             0.050615728
KL Divergence                21.815569
KL Loss                      2.181557
QF Loss                      305.5191
VF Loss                      113.45659
Policy Loss                  -530.486
Q Predictions Mean           515.4376
Q Predictions Std            180.64067
Q Predictions Max            806.4705
Q Predictions Min            -22.963858
V Predictions Mean           536.76184
V Predictions Std            169.76593
V Predictions Max            812.91315
V Predictions Min            211.92586
Log Pis Mean                 -1.1353728
Log Pis Std                  2.808301
Log Pis Max                  14.564884
Log Pis Min                  -7.0454845
Policy mu Mean               -0.0148404725
Policy mu Std                0.51081187
Policy mu Max                3.6031916
Policy mu Min                -2.3169436
Policy log std Mean          -0.89904004
Policy log std Std           0.16742921
Policy log std Max           -0.41326147
Policy log std Min           -1.8564217
Z mean eval                  1.1796849
Z variance eval              0.080148496
total_rewards                [ 540.49465547  197.25624056  334.60775719  384.15894054 1788.63924888
  368.45713707  733.82524993 2110.19041141 1064.02695804  689.86541958]
total_rewards_mean           821.1522018667907
total_rewards_std            614.990838337754
total_rewards_max            2110.190411406472
total_rewards_min            197.25624056135476
Number of train steps total  244000
Number of env steps total    208598
Number of rollouts total     0
Train Time (s)               147.5125327897258
(Previous) Eval Time (s)     14.250645985361189
Sample Time (s)              7.497349225450307
Epoch Time (s)               169.2605280005373
Total Train Time (s)         9999.731873961631
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:16.327105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #60 | Epoch Duration: 169.3509771823883
2020-01-11 11:07:16.327232 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1766732
Z variance train             0.07939742
KL Divergence                22.330832
KL Loss                      2.2330832
QF Loss                      4015.3535
VF Loss                      103.6001
Policy Loss                  -537.9781
Q Predictions Mean           531.29407
Q Predictions Std            180.43587
Q Predictions Max            795.34576
Q Predictions Min            -12.932467
V Predictions Mean           542.4768
V Predictions Std            174.08707
V Predictions Max            780.2293
V Predictions Min            183.75117
Log Pis Mean                 -1.357462
Log Pis Std                  3.093511
Log Pis Max                  18.898102
Log Pis Min                  -7.7587013
Policy mu Mean               -0.025407357
Policy mu Std                0.5077554
Policy mu Max                2.5849571
Policy mu Min                -3.1531007
Policy log std Mean          -0.90022254
Policy log std Std           0.16845179
Policy log std Max           -0.5226278
Policy log std Min           -1.5226599
Z mean eval                  1.1725438
Z variance eval              0.05266854
total_rewards                [2324.11898973 1794.8145223   421.77469012  667.10284091  437.31592409
  108.25021931 1705.28564266   20.59212606  965.3831801   521.29368489]
total_rewards_mean           896.5931820166448
total_rewards_std            743.1092297604364
total_rewards_max            2324.1189897284617
total_rewards_min            20.592126060330948
Number of train steps total  248000
Number of env steps total    212184
Number of rollouts total     0
Train Time (s)               146.39338508294895
(Previous) Eval Time (s)     13.19941621599719
Sample Time (s)              7.505658559501171
Epoch Time (s)               167.0984598584473
Total Train Time (s)         10166.917104917578
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:03.514781 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #61 | Epoch Duration: 167.18743658065796
2020-01-11 11:10:03.514920 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1682441
Z variance train             0.052749235
KL Divergence                21.749916
KL Loss                      2.1749916
QF Loss                      448.87677
VF Loss                      70.01537
Policy Loss                  -530.75525
Q Predictions Mean           520.9248
Q Predictions Std            201.15506
Q Predictions Max            785.869
Q Predictions Min            -36.41402
V Predictions Mean           528.64514
V Predictions Std            190.6842
V Predictions Max            784.6578
V Predictions Min            59.133133
Log Pis Mean                 -1.2077556
Log Pis Std                  2.850972
Log Pis Max                  9.984343
Log Pis Min                  -7.609031
Policy mu Mean               0.0033782842
Policy mu Std                0.52997416
Policy mu Max                2.591133
Policy mu Min                -2.5500693
Policy log std Mean          -0.9090992
Policy log std Std           0.17431392
Policy log std Max           -0.5031723
Policy log std Min           -1.835084
Z mean eval                  1.1492426
Z variance eval              0.04744603
total_rewards                [1191.39094066  778.81054461  587.82954001 1718.39243651 1335.21121076
  482.53305901 1056.37137446 1356.55819144  497.7197834    87.29619094]
total_rewards_mean           909.2113271809278
total_rewards_std            478.0026509098685
total_rewards_max            1718.3924365125183
total_rewards_min            87.29619094255621
Number of train steps total  252000
Number of env steps total    215526
Number of rollouts total     0
Train Time (s)               144.87780703417957
(Previous) Eval Time (s)     11.603846397716552
Sample Time (s)              7.325318258721381
Epoch Time (s)               163.8069716906175
Total Train Time (s)         10330.817349550314
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:47.415571 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #62 | Epoch Duration: 163.90055465698242
2020-01-11 11:12:47.415702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1480523
Z variance train             0.047475733
KL Divergence                21.718962
KL Loss                      2.1718962
QF Loss                      454.0916
VF Loss                      59.53043
Policy Loss                  -564.6147
Q Predictions Mean           559.07605
Q Predictions Std            180.76613
Q Predictions Max            817.7505
Q Predictions Min            228.67972
V Predictions Mean           564.0128
V Predictions Std            174.2315
V Predictions Max            802.52136
V Predictions Min            240.74207
Log Pis Mean                 -1.2289044
Log Pis Std                  2.8373845
Log Pis Max                  15.109342
Log Pis Min                  -9.380263
Policy mu Mean               -0.0025259163
Policy mu Std                0.50392705
Policy mu Max                3.276153
Policy mu Min                -2.9705327
Policy log std Mean          -0.9050647
Policy log std Std           0.16990425
Policy log std Max           -0.44745532
Policy log std Min           -1.5802724
Z mean eval                  1.1764027
Z variance eval              0.036305018
total_rewards                [505.86885595 395.16073939 630.88634971  38.41663221 652.94683253
 448.63558998 255.10514806 344.79850151 435.61126649 182.81214707]
total_rewards_mean           389.02420628920356
total_rewards_std            182.45710755704067
total_rewards_max            652.9468325278463
total_rewards_min            38.41663221360851
Number of train steps total  256000
Number of env steps total    218187
Number of rollouts total     0
Train Time (s)               146.71021054219455
(Previous) Eval Time (s)     12.643354796338826
Sample Time (s)              7.611896583810449
Epoch Time (s)               166.96546192234382
Total Train Time (s)         10497.867624740116
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:34.466017 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #63 | Epoch Duration: 167.0502257347107
2020-01-11 11:15:34.466145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1761144
Z variance train             0.036503635
KL Divergence                22.210514
KL Loss                      2.2210515
QF Loss                      450.27777
VF Loss                      125.47168
Policy Loss                  -565.55536
Q Predictions Mean           556.4415
Q Predictions Std            192.25621
Q Predictions Max            837.07043
Q Predictions Min            1.3808293
V Predictions Mean           559.62
V Predictions Std            185.53252
V Predictions Max            832.70105
V Predictions Min            -69.207565
Log Pis Mean                 -1.1439279
Log Pis Std                  2.9237041
Log Pis Max                  12.659861
Log Pis Min                  -9.977952
Policy mu Mean               0.026167758
Policy mu Std                0.52628815
Policy mu Max                2.6626554
Policy mu Min                -2.7006483
Policy log std Mean          -0.91413736
Policy log std Std           0.18321835
Policy log std Max           -0.41981268
Policy log std Min           -1.9410775
Z mean eval                  1.2476206
Z variance eval              0.03441837
total_rewards                [ 415.08722261  388.77766089  440.662486    945.2787124    49.12853242
  683.91594638 2147.77100017  739.12653478  554.57979196  537.34829067]
total_rewards_mean           690.167617827663
total_rewards_std            536.0552401409033
total_rewards_max            2147.7710001694386
total_rewards_min            49.12853241529048
Number of train steps total  260000
Number of env steps total    222025
Number of rollouts total     0
Train Time (s)               144.99840764701366
(Previous) Eval Time (s)     17.54786908160895
Sample Time (s)              7.2969104326330125
Epoch Time (s)               169.84318716125563
Total Train Time (s)         10667.799364191946
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:24.403514 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #64 | Epoch Duration: 169.93721890449524
2020-01-11 11:18:24.403845 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #64 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2521436
Z variance train             0.03446696
KL Divergence                22.566778
KL Loss                      2.2566779
QF Loss                      566.31366
VF Loss                      68.73735
Policy Loss                  -578.7175
Q Predictions Mean           567.6881
Q Predictions Std            197.5294
Q Predictions Max            857.94165
Q Predictions Min            16.151617
V Predictions Mean           579.36426
V Predictions Std            191.58789
V Predictions Max            856.31396
V Predictions Min            121.06173
Log Pis Mean                 -1.2690308
Log Pis Std                  2.463572
Log Pis Max                  8.549877
Log Pis Min                  -7.554186
Policy mu Mean               0.010125352
Policy mu Std                0.5068425
Policy mu Max                2.4531374
Policy mu Min                -2.3228273
Policy log std Mean          -0.9109024
Policy log std Std           0.17052326
Policy log std Max           -0.42549625
Policy log std Min           -1.6141441
Z mean eval                  1.1788485
Z variance eval              0.039462756
total_rewards                [ 93.28578196 647.84227666 453.19769431 741.67999178 819.67215416
 289.29224063 103.71253846 426.73548145 644.52574783 573.28573725]
total_rewards_mean           479.3229644479655
total_rewards_std            240.59427447561384
total_rewards_max            819.6721541588771
total_rewards_min            93.2857819601447
Number of train steps total  264000
Number of env steps total    224854
Number of rollouts total     0
Train Time (s)               147.3579461509362
(Previous) Eval Time (s)     10.60470942594111
Sample Time (s)              7.1996478023938835
Epoch Time (s)               165.16230337927118
Total Train Time (s)         10833.064951566514
Epoch                        65
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:09.671911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #65 | Epoch Duration: 165.26778197288513
2020-01-11 11:21:09.672171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1778384
Z variance train             0.039107427
KL Divergence                22.860828
KL Loss                      2.286083
QF Loss                      402.75085
VF Loss                      73.14051
Policy Loss                  -575.33655
Q Predictions Mean           568.0021
Q Predictions Std            192.05121
Q Predictions Max            894.55664
Q Predictions Min            137.97128
V Predictions Mean           572.1835
V Predictions Std            187.13562
V Predictions Max            889.22064
V Predictions Min            223.672
Log Pis Mean                 -1.3041342
Log Pis Std                  2.8242078
Log Pis Max                  16.842049
Log Pis Min                  -12.164366
Policy mu Mean               -0.018628336
Policy mu Std                0.48438618
Policy mu Max                2.9595141
Policy mu Min                -2.2498002
Policy log std Mean          -0.92169464
Policy log std Std           0.18036461
Policy log std Max           -0.4575413
Policy log std Min           -1.6247513
Z mean eval                  1.1842961
Z variance eval              0.042488027
total_rewards                [ 374.47148863 2452.65796741 1515.72093258 1053.69635779 1249.67519105
  448.93710239  737.47132337  116.25336478  248.73256577 1118.56145253]
total_rewards_mean           931.6177746299163
total_rewards_std            672.1598169858394
total_rewards_max            2452.6579674064233
total_rewards_min            116.25336477936955
Number of train steps total  268000
Number of env steps total    228597
Number of rollouts total     0
Train Time (s)               145.6176477218978
(Previous) Eval Time (s)     14.368300931993872
Sample Time (s)              7.542430481407791
Epoch Time (s)               167.52837913529947
Total Train Time (s)         11000.6951410966
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:23:57.303908 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #66 | Epoch Duration: 167.63154649734497
2020-01-11 11:23:57.304189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #66 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1862152
Z variance train             0.041885562
KL Divergence                23.029747
KL Loss                      2.3029747
QF Loss                      412.20612
VF Loss                      82.44042
Policy Loss                  -587.6076
Q Predictions Mean           580.9691
Q Predictions Std            205.51228
Q Predictions Max            857.88245
Q Predictions Min            65.859566
V Predictions Mean           590.3017
V Predictions Std            198.85799
V Predictions Max            857.81757
V Predictions Min            227.12262
Log Pis Mean                 -1.4149303
Log Pis Std                  2.5676053
Log Pis Max                  15.8277445
Log Pis Min                  -7.327388
Policy mu Mean               -0.016270421
Policy mu Std                0.48032874
Policy mu Max                2.8190913
Policy mu Min                -3.254139
Policy log std Mean          -0.90494144
Policy log std Std           0.16896936
Policy log std Max           -0.43769157
Policy log std Min           -1.74901
Z mean eval                  1.2015154
Z variance eval              0.04447937
total_rewards                [ 874.96651345  443.91825978  711.58641014  223.8890038   275.6321617
 1710.28846265  186.8194744  1561.01342873  268.04014966  630.79575207]
total_rewards_mean           688.6949616383101
total_rewards_std            521.399729735447
total_rewards_max            1710.288462650176
total_rewards_min            186.81947440243465
Number of train steps total  272000
Number of env steps total    231399
Number of rollouts total     0
Train Time (s)               145.70753440912813
(Previous) Eval Time (s)     8.780565604101866
Sample Time (s)              7.811157495249063
Epoch Time (s)               162.29925750847906
Total Train Time (s)         11163.087145016063
Epoch                        67
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:39.696457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #67 | Epoch Duration: 162.39203023910522
2020-01-11 11:26:39.696667 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1978905
Z variance train             0.044437375
KL Divergence                22.475143
KL Loss                      2.2475145
QF Loss                      597.8252
VF Loss                      156.11815
Policy Loss                  -591.7343
Q Predictions Mean           581.86096
Q Predictions Std            202.51329
Q Predictions Max            867.9819
Q Predictions Min            -78.78413
V Predictions Mean           587.0591
V Predictions Std            188.80185
V Predictions Max            854.69965
V Predictions Min            241.62602
Log Pis Mean                 -1.1974347
Log Pis Std                  3.060159
Log Pis Max                  26.74112
Log Pis Min                  -8.173272
Policy mu Mean               0.008200331
Policy mu Std                0.52975804
Policy mu Max                4.3237734
Policy mu Min                -2.9604397
Policy log std Mean          -0.90741014
Policy log std Std           0.17492327
Policy log std Max           -0.42844763
Policy log std Min           -1.6582165
Z mean eval                  1.1943462
Z variance eval              0.027115092
total_rewards                [1407.14407095 2505.32075518  628.86985125  411.52508085 1388.25345124
   91.28292072  467.64511475  766.48656747  854.39571076  242.54954106]
total_rewards_mean           876.3473064223593
total_rewards_std            683.5398180318082
total_rewards_max            2505.3207551765645
total_rewards_min            91.28292071886972
Number of train steps total  276000
Number of env steps total    234159
Number of rollouts total     0
Train Time (s)               145.34792062593624
(Previous) Eval Time (s)     15.6193733131513
Sample Time (s)              8.289206983987242
Epoch Time (s)               169.25650092307478
Total Train Time (s)         11332.435701126698
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:29.046277 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #68 | Epoch Duration: 169.34948205947876
2020-01-11 11:29:29.046459 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1984478
Z variance train             0.026985735
KL Divergence                24.135145
KL Loss                      2.4135146
QF Loss                      457.78085
VF Loss                      145.74036
Policy Loss                  -569.8852
Q Predictions Mean           557.9758
Q Predictions Std            209.04285
Q Predictions Max            903.32214
Q Predictions Min            -31.897861
V Predictions Mean           570.442
V Predictions Std            201.91888
V Predictions Max            893.5568
V Predictions Min            230.00691
Log Pis Mean                 -1.2580252
Log Pis Std                  3.5599291
Log Pis Max                  31.03843
Log Pis Min                  -9.049278
Policy mu Mean               -0.019928867
Policy mu Std                0.5239402
Policy mu Max                4.5744195
Policy mu Min                -2.2167838
Policy log std Mean          -0.9310645
Policy log std Std           0.19526295
Policy log std Max           -0.4760112
Policy log std Min           -1.7727239
Z mean eval                  1.1102941
Z variance eval              0.4296381
total_rewards                [1588.41654142    8.40587661 1768.91700963 1945.51808344  168.06813606
  170.68262317  270.88611468 1025.49422573  462.77102397 1010.92104497]
total_rewards_mean           842.0080679698997
total_rewards_std            690.361168712848
total_rewards_max            1945.518083444307
total_rewards_min            8.405876613803429
Number of train steps total  280000
Number of env steps total    237064
Number of rollouts total     0
Train Time (s)               147.27738384110853
(Previous) Eval Time (s)     14.961424937006086
Sample Time (s)              8.72213316615671
Epoch Time (s)               170.96094194427133
Total Train Time (s)         11503.485785778612
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:20.096456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #69 | Epoch Duration: 171.04987621307373
2020-01-11 11:32:20.096589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.106844
Z variance train             0.43025368
KL Divergence                20.62694
KL Loss                      2.062694
QF Loss                      569.30347
VF Loss                      192.98987
Policy Loss                  -529.07874
Q Predictions Mean           517.68506
Q Predictions Std            195.46786
Q Predictions Max            817.6206
Q Predictions Min            188.38437
V Predictions Mean           521.36536
V Predictions Std            188.85822
V Predictions Max            805.86475
V Predictions Min            190.49971
Log Pis Mean                 -0.9981887
Log Pis Std                  2.5934327
Log Pis Max                  6.619376
Log Pis Min                  -10.872068
Policy mu Mean               -0.02070236
Policy mu Std                0.4860093
Policy mu Max                2.5311997
Policy mu Min                -1.9834288
Policy log std Mean          -0.94966525
Policy log std Std           0.17201659
Policy log std Max           -0.510164
Policy log std Min           -1.5209315
Z mean eval                  1.1928855
Z variance eval              0.033166043
total_rewards                [ 432.1705123   360.2768177   666.66277516  350.15806604 1059.20178896
  641.43408093  677.0800499   864.63138106 1008.07398936  595.61408841]
total_rewards_mean           665.530354982508
total_rewards_std            237.62457141120763
total_rewards_max            1059.2017889618478
total_rewards_min            350.1580660442629
Number of train steps total  284000
Number of env steps total    239625
Number of rollouts total     0
Train Time (s)               144.57700593862683
(Previous) Eval Time (s)     12.756388587877154
Sample Time (s)              7.448132732883096
Epoch Time (s)               164.78152725938708
Total Train Time (s)         11668.352172604296
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:35:04.965064 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #70 | Epoch Duration: 164.86834859848022
2020-01-11 11:35:04.965232 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1908218
Z variance train             0.033374347
KL Divergence                22.907366
KL Loss                      2.2907367
QF Loss                      412.74646
VF Loss                      67.2799
Policy Loss                  -594.5225
Q Predictions Mean           586.29016
Q Predictions Std            217.95517
Q Predictions Max            891.043
Q Predictions Min            -65.76719
V Predictions Mean           594.2102
V Predictions Std            209.15768
V Predictions Max            881.2198
V Predictions Min            40.102875
Log Pis Mean                 -1.2280188
Log Pis Std                  3.1310394
Log Pis Max                  14.481965
Log Pis Min                  -10.242387
Policy mu Mean               -0.032090373
Policy mu Std                0.5097552
Policy mu Max                2.8792431
Policy mu Min                -3.0756602
Policy log std Mean          -0.93487656
Policy log std Std           0.17915244
Policy log std Max           -0.5468421
Policy log std Min           -1.7792441
Z mean eval                  1.1911122
Z variance eval              0.034483347
total_rewards                [ 368.51842244 1727.35816265 2234.80780654 1480.308205    252.53931517
  278.74813517 1494.50109912    4.24924509 1670.18075287 1116.6931717 ]
total_rewards_mean           1062.790431574676
total_rewards_std            736.3118195527749
total_rewards_max            2234.807806538758
total_rewards_min            4.2492450914355056
Number of train steps total  288000
Number of env steps total    242322
Number of rollouts total     0
Train Time (s)               146.29736779723316
(Previous) Eval Time (s)     13.72249829210341
Sample Time (s)              8.127529131248593
Epoch Time (s)               168.14739522058517
Total Train Time (s)         11836.59748648433
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:37:53.211070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #71 | Epoch Duration: 168.2457127571106
2020-01-11 11:37:53.211217 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1950262
Z variance train             0.0348149
KL Divergence                23.056095
KL Loss                      2.3056095
QF Loss                      479.51233
VF Loss                      182.4699
Policy Loss                  -608.30566
Q Predictions Mean           598.341
Q Predictions Std            208.0658
Q Predictions Max            952.279
Q Predictions Min            187.40433
V Predictions Mean           616.63873
V Predictions Std            207.5545
V Predictions Max            961.76807
V Predictions Min            221.68887
Log Pis Mean                 -0.9951528
Log Pis Std                  3.018466
Log Pis Max                  13.589036
Log Pis Min                  -7.909141
Policy mu Mean               -0.0086485995
Policy mu Std                0.54513526
Policy mu Max                3.139247
Policy mu Min                -2.3188472
Policy log std Mean          -0.9403769
Policy log std Std           0.18905187
Policy log std Max           -0.37306803
Policy log std Min           -2.1724472
Z mean eval                  1.1590444
Z variance eval              0.06651694
total_rewards                [ 369.24238014  531.58858261 2157.61803733  631.45620408 1491.37391229
  101.29510071 1442.64001135 2144.66164776 1940.82154045  777.89035649]
total_rewards_mean           1158.8587773225804
total_rewards_std            730.1085206589632
total_rewards_max            2157.6180373332627
total_rewards_min            101.29510071156321
Number of train steps total  292000
Number of env steps total    245065
Number of rollouts total     0
Train Time (s)               145.56687718257308
(Previous) Eval Time (s)     15.572324868291616
Sample Time (s)              7.322826127056032
Epoch Time (s)               168.46202817792073
Total Train Time (s)         12005.14681625925
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:40:41.761877 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #72 | Epoch Duration: 168.5505485534668
2020-01-11 11:40:41.762048 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1574109
Z variance train             0.067137554
KL Divergence                20.961794
KL Loss                      2.0961795
QF Loss                      491.3337
VF Loss                      91.12757
Policy Loss                  -583.9868
Q Predictions Mean           575.80835
Q Predictions Std            218.1354
Q Predictions Max            892.04425
Q Predictions Min            118.163826
V Predictions Mean           586.2054
V Predictions Std            214.96144
V Predictions Max            891.2259
V Predictions Min            246.23174
Log Pis Mean                 -1.3174487
Log Pis Std                  2.5781205
Log Pis Max                  10.253751
Log Pis Min                  -8.097942
Policy mu Mean               0.031232849
Policy mu Std                0.47649896
Policy mu Max                2.2131138
Policy mu Min                -1.9319377
Policy log std Mean          -0.9205375
Policy log std Std           0.18173124
Policy log std Max           -0.2892357
Policy log std Min           -1.9316912
Z mean eval                  1.1755259
Z variance eval              0.12066598
total_rewards                [ 857.58087066 1249.9774407    55.04381158  441.06687821   98.21929604
  438.05557115   65.86461058 1272.20502111  878.64803022  833.84315735]
total_rewards_mean           619.050468759411
total_rewards_std            442.14520055956757
total_rewards_max            1272.2050211113647
total_rewards_min            55.04381157707085
Number of train steps total  296000
Number of env steps total    247465
Number of rollouts total     0
Train Time (s)               145.2628927147016
(Previous) Eval Time (s)     10.245931656099856
Sample Time (s)              7.09354940475896
Epoch Time (s)               162.6023737755604
Total Train Time (s)         12167.841603682842
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:43:24.457847 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #73 | Epoch Duration: 162.6956820487976
2020-01-11 11:43:24.457983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1780112
Z variance train             0.120635614
KL Divergence                19.49668
KL Loss                      1.9496679
QF Loss                      664.0967
VF Loss                      195.65477
Policy Loss                  -607.5032
Q Predictions Mean           597.9317
Q Predictions Std            211.65715
Q Predictions Max            898.25616
Q Predictions Min            18.4478
V Predictions Mean           618.2589
V Predictions Std            201.99304
V Predictions Max            911.7309
V Predictions Min            247.53888
Log Pis Mean                 -0.9022729
Log Pis Std                  2.8033662
Log Pis Max                  13.504318
Log Pis Min                  -7.383351
Policy mu Mean               -0.02652555
Policy mu Std                0.5146108
Policy mu Max                2.8369093
Policy mu Min                -2.399173
Policy log std Mean          -0.93629265
Policy log std Std           0.19222523
Policy log std Max           -0.3023929
Policy log std Min           -1.9044845
Z mean eval                  1.1955941
Z variance eval              0.037993662
total_rewards                [1053.09964403   14.29276404 2328.35643047  424.25220931  888.80937947
 1078.54162852  518.9020348   902.5058258   740.9281389   891.84111862]
total_rewards_mean           884.152917394162
total_rewards_std            572.2375614252022
total_rewards_max            2328.3564304668853
total_rewards_min            14.292764038053631
Number of train steps total  300000
Number of env steps total    250315
Number of rollouts total     0
Train Time (s)               145.34925869014114
(Previous) Eval Time (s)     11.937703642994165
Sample Time (s)              7.9312200476415455
Epoch Time (s)               165.21818238077685
Total Train Time (s)         12333.170657932758
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:46:09.788896 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #74 | Epoch Duration: 165.33080077171326
2020-01-11 11:46:09.789071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1965722
Z variance train             0.038133193
KL Divergence                22.17488
KL Loss                      2.217488
QF Loss                      323.65573
VF Loss                      90.95753
Policy Loss                  -637.8068
Q Predictions Mean           632.38306
Q Predictions Std            221.61322
Q Predictions Max            930.2376
Q Predictions Min            229.96722
V Predictions Mean           641.1261
V Predictions Std            219.68393
V Predictions Max            923.04535
V Predictions Min            248.60034
Log Pis Mean                 -1.3949517
Log Pis Std                  2.6735637
Log Pis Max                  16.512585
Log Pis Min                  -9.400387
Policy mu Mean               -0.011744375
Policy mu Std                0.48765987
Policy mu Max                2.173401
Policy mu Min                -2.183971
Policy log std Mean          -0.9088788
Policy log std Std           0.18210602
Policy log std Max           -0.45705277
Policy log std Min           -2.0488656
Z mean eval                  1.1797367
Z variance eval              0.028470606
total_rewards                [ 898.05703698  179.07803473 2134.68032782  957.9734905  1449.31683277
 1006.56847663 2586.12410013 1989.92741536 2310.7796511    39.93069916]
total_rewards_mean           1355.2436065170675
total_rewards_std            839.5916734237022
total_rewards_max            2586.1241001265284
total_rewards_min            39.93069915692171
Number of train steps total  304000
Number of env steps total    253402
Number of rollouts total     0
Train Time (s)               142.05999666964635
(Previous) Eval Time (s)     18.496867510024458
Sample Time (s)              8.715543296653777
Epoch Time (s)               169.2724074763246
Total Train Time (s)         12502.542221820448
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:59.161632 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #75 | Epoch Duration: 169.3724296092987
2020-01-11 11:48:59.161799 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1787584
Z variance train             0.028506484
KL Divergence                22.44624
KL Loss                      2.244624
QF Loss                      467.267
VF Loss                      88.57054
Policy Loss                  -654.2046
Q Predictions Mean           649.178
Q Predictions Std            218.82193
Q Predictions Max            938.23
Q Predictions Min            16.882387
V Predictions Mean           650.36176
V Predictions Std            216.98122
V Predictions Max            936.8679
V Predictions Min            -25.961697
Log Pis Mean                 -0.7221592
Log Pis Std                  2.8386211
Log Pis Max                  18.145832
Log Pis Min                  -7.1435432
Policy mu Mean               -0.044053487
Policy mu Std                0.5335096
Policy mu Max                1.8864218
Policy mu Min                -3.1535828
Policy log std Mean          -0.9527377
Policy log std Std           0.19534427
Policy log std Max           -0.358438
Policy log std Min           -2.1091099
Z mean eval                  1.1629044
Z variance eval              0.029047167
total_rewards                [ 747.56575335  748.7873226    93.82500465  166.58559334 1180.07266539
  381.78688653  927.35308837 1120.39213684 1735.7401453   745.39516595]
total_rewards_mean           784.7503762322102
total_rewards_std            471.1435227253208
total_rewards_max            1735.7401452991892
total_rewards_min            93.82500465394878
Number of train steps total  308000
Number of env steps total    255772
Number of rollouts total     0
Train Time (s)               145.94489480787888
(Previous) Eval Time (s)     12.891144715249538
Sample Time (s)              6.410765573848039
Epoch Time (s)               165.24680509697646
Total Train Time (s)         12667.888774365652
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:44.509031 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #76 | Epoch Duration: 165.3471188545227
2020-01-11 11:51:44.509148 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1667107
Z variance train             0.029182892
KL Divergence                23.134527
KL Loss                      2.3134527
QF Loss                      516.948
VF Loss                      168.00244
Policy Loss                  -635.6484
Q Predictions Mean           622.23676
Q Predictions Std            230.87439
Q Predictions Max            951.2812
Q Predictions Min            -81.49465
V Predictions Mean           631.77124
V Predictions Std            219.59987
V Predictions Max            939.5853
V Predictions Min            47.46036
Log Pis Mean                 -0.6784406
Log Pis Std                  2.8866103
Log Pis Max                  18.232296
Log Pis Min                  -7.031427
Policy mu Mean               0.0010977632
Policy mu Std                0.5412015
Policy mu Max                4.8293347
Policy mu Min                -2.6357067
Policy log std Mean          -0.9536775
Policy log std Std           0.19188868
Policy log std Max           -0.47896048
Policy log std Min           -1.8168457
Z mean eval                  1.1334348
Z variance eval              0.03486127
total_rewards                [ 882.80109398  949.23384985 2609.83467727 1326.73255538 2809.80760598
 1403.20347188  772.78587999  657.98206205 1252.70063107  405.66690009]
total_rewards_mean           1307.0748727534678
total_rewards_std            761.2721879135897
total_rewards_max            2809.807605982538
total_rewards_min            405.66690009019646
Number of train steps total  312000
Number of env steps total    259429
Number of rollouts total     0
Train Time (s)               146.42652733437717
(Previous) Eval Time (s)     13.212060304824263
Sample Time (s)              6.477035508491099
Epoch Time (s)               166.11562314769253
Total Train Time (s)         12834.138829899486
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:54:30.761200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #77 | Epoch Duration: 166.25194454193115
2020-01-11 11:54:30.761379 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1334127
Z variance train             0.03491328
KL Divergence                21.726698
KL Loss                      2.17267
QF Loss                      587.5047
VF Loss                      118.79895
Policy Loss                  -608.1577
Q Predictions Mean           599.248
Q Predictions Std            240.47638
Q Predictions Max            918.1063
Q Predictions Min            -10.536973
V Predictions Mean           611.7899
V Predictions Std            231.19887
V Predictions Max            927.0451
V Predictions Min            62.869427
Log Pis Mean                 -0.90719885
Log Pis Std                  3.4787054
Log Pis Max                  21.747845
Log Pis Min                  -7.9671745
Policy mu Mean               -0.027473044
Policy mu Std                0.56969285
Policy mu Max                3.4802895
Policy mu Min                -3.1552327
Policy log std Mean          -0.9283242
Policy log std Std           0.19802523
Policy log std Max           -0.43912524
Policy log std Min           -2.0202146
Z mean eval                  1.123616
Z variance eval              0.04259572
total_rewards                [ 309.6076911  1017.56467836  286.69824443  174.11102425   54.98010368
  174.18478848 2701.9012492  1337.49167197  805.92842908  418.80624593]
total_rewards_mean           728.127412647789
total_rewards_std            767.43382961923
total_rewards_max            2701.9012492006714
total_rewards_min            54.98010368435315
Number of train steps total  316000
Number of env steps total    262039
Number of rollouts total     0
Train Time (s)               146.60701792640612
(Previous) Eval Time (s)     7.101592499297112
Sample Time (s)              7.718628770206124
Epoch Time (s)               161.42723919590935
Total Train Time (s)         12995.656002090313
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:12.278991 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #78 | Epoch Duration: 161.51748704910278
2020-01-11 11:57:12.279122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1234571
Z variance train             0.04282393
KL Divergence                21.279045
KL Loss                      2.1279047
QF Loss                      660.9391
VF Loss                      101.64008
Policy Loss                  -640.8829
Q Predictions Mean           632.63916
Q Predictions Std            239.63953
Q Predictions Max            987.09827
Q Predictions Min            16.99297
V Predictions Mean           641.2323
V Predictions Std            233.74147
V Predictions Max            982.77844
V Predictions Min            137.69565
Log Pis Mean                 -1.0797414
Log Pis Std                  2.5968745
Log Pis Max                  11.374531
Log Pis Min                  -7.3145943
Policy mu Mean               -0.015661165
Policy mu Std                0.51131696
Policy mu Max                2.3013883
Policy mu Min                -1.8826041
Policy log std Mean          -0.92535317
Policy log std Std           0.18450071
Policy log std Max           -0.4441803
Policy log std Min           -1.7828376
Z mean eval                  1.1254175
Z variance eval              0.029694999
total_rewards                [2501.14330658 1107.66419177  249.78756715  333.1736951   183.87026633
  955.0474593  1315.40998908  709.4674421  2463.47516566 1334.67884594]
total_rewards_mean           1115.3717928998717
total_rewards_std            790.2621657631513
total_rewards_max            2501.1433065798187
total_rewards_min            183.87026632898417
Number of train steps total  320000
Number of env steps total    266853
Number of rollouts total     0
Train Time (s)               145.33782531600446
(Previous) Eval Time (s)     11.790554250124842
Sample Time (s)              8.79061400797218
Epoch Time (s)               165.91899357410148
Total Train Time (s)         13161.664081514813
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:58.292322 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #79 | Epoch Duration: 166.0130536556244
2020-01-11 11:59:58.292616 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1239557
Z variance train             0.029876536
KL Divergence                23.928654
KL Loss                      2.3928654
QF Loss                      546.9822
VF Loss                      87.734535
Policy Loss                  -656.543
Q Predictions Mean           647.76904
Q Predictions Std            243.46603
Q Predictions Max            982.89453
Q Predictions Min            4.853164
V Predictions Mean           654.6562
V Predictions Std            235.36185
V Predictions Max            973.3772
V Predictions Min            87.067894
Log Pis Mean                 -0.5896331
Log Pis Std                  3.3161938
Log Pis Max                  18.773563
Log Pis Min                  -8.539778
Policy mu Mean               0.010550283
Policy mu Std                0.5552607
Policy mu Max                2.1321833
Policy mu Min                -3.173548
Policy log std Mean          -0.9611871
Policy log std Std           0.20795907
Policy log std Max           -0.47318318
Policy log std Min           -2.083742
Z mean eval                  1.1464139
Z variance eval              0.058595754
total_rewards                [  85.94429151  329.95467555 1558.7712623   741.50338527  500.32456414
 1129.46735775  736.95887329  314.67330534 1690.92562655 1216.93700527]
total_rewards_mean           830.546034696053
total_rewards_std            520.2017369491078
total_rewards_max            1690.925626554838
total_rewards_min            85.94429150970441
Number of train steps total  324000
Number of env steps total    270538
Number of rollouts total     0
Train Time (s)               145.01222174428403
(Previous) Eval Time (s)     12.39139118976891
Sample Time (s)              8.10503421863541
Epoch Time (s)               165.50864715268835
Total Train Time (s)         13327.274320170749
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:43.900322 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #80 | Epoch Duration: 165.60749769210815
2020-01-11 12:02:43.900438 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1441114
Z variance train             0.058782004
KL Divergence                21.86949
KL Loss                      2.186949
QF Loss                      700.3443
VF Loss                      272.6529
Policy Loss                  -670.8493
Q Predictions Mean           662.6105
Q Predictions Std            224.32056
Q Predictions Max            988.322
Q Predictions Min            76.643974
V Predictions Mean           681.6992
V Predictions Std            220.95715
V Predictions Max            996.89197
V Predictions Min            87.089325
Log Pis Mean                 -0.53722
Log Pis Std                  2.9157064
Log Pis Max                  18.555622
Log Pis Min                  -9.182005
Policy mu Mean               0.017583413
Policy mu Std                0.5839557
Policy mu Max                4.9496293
Policy mu Min                -2.7460673
Policy log std Mean          -0.95473707
Policy log std Std           0.20739906
Policy log std Max           0.13755167
Policy log std Min           -1.8641407
Z mean eval                  1.1662866
Z variance eval              0.080158226
total_rewards                [1009.61114601  333.48835652 2905.89534645 1280.03361592  297.80567921
 1614.78316899  622.05893324 2834.56114781 1252.53904164 2807.29333694]
total_rewards_mean           1495.8069772714978
total_rewards_std            969.8718932352222
total_rewards_max            2905.895346446139
total_rewards_min            297.80567920732636
Number of train steps total  328000
Number of env steps total    273406
Number of rollouts total     0
Train Time (s)               145.9088009428233
(Previous) Eval Time (s)     16.56766366586089
Sample Time (s)              7.225104488898069
Epoch Time (s)               169.70156909758225
Total Train Time (s)         13497.08461338235
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:33.715093 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #81 | Epoch Duration: 169.8145170211792
2020-01-11 12:05:33.715342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1700454
Z variance train             0.080901906
KL Divergence                20.109024
KL Loss                      2.0109024
QF Loss                      547.6885
VF Loss                      284.7756
Policy Loss                  -651.15125
Q Predictions Mean           640.9755
Q Predictions Std            254.21387
Q Predictions Max            1011.2229
Q Predictions Min            -45.124226
V Predictions Mean           647.98486
V Predictions Std            244.64342
V Predictions Max            999.21875
V Predictions Min            26.54129
Log Pis Mean                 -0.71812874
Log Pis Std                  3.2249918
Log Pis Max                  16.31097
Log Pis Min                  -7.287881
Policy mu Mean               -0.022526477
Policy mu Std                0.5321134
Policy mu Max                2.9969172
Policy mu Min                -2.571599
Policy log std Mean          -0.9470017
Policy log std Std           0.20914848
Policy log std Max           -0.3785131
Policy log std Min           -2.5000718
Z mean eval                  1.1613231
Z variance eval              0.03246496
total_rewards                [1588.24558894  405.01642554 2827.32649018  610.04430064  187.14571762
  511.03835997 1576.13162466 1190.93123057 1486.22146396 2077.2511116 ]
total_rewards_mean           1245.9352313680943
total_rewards_std            790.661983319767
total_rewards_max            2827.326490176144
total_rewards_min            187.14571761753038
Number of train steps total  332000
Number of env steps total    276287
Number of rollouts total     0
Train Time (s)               145.7578132650815
(Previous) Eval Time (s)     11.085906475782394
Sample Time (s)              8.652552721090615
Epoch Time (s)               165.4962724619545
Total Train Time (s)         13662.91829563398
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:08:19.552653 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #82 | Epoch Duration: 165.83712124824524
2020-01-11 12:08:19.552822 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1564596
Z variance train             0.032665145
KL Divergence                21.413742
KL Loss                      2.1413743
QF Loss                      634.7092
VF Loss                      124.0933
Policy Loss                  -650.3334
Q Predictions Mean           640.9228
Q Predictions Std            247.32837
Q Predictions Max            1013.30585
Q Predictions Min            120.43795
V Predictions Mean           656.0747
V Predictions Std            243.84027
V Predictions Max            1019.2425
V Predictions Min            79.43256
Log Pis Mean                 -0.55366
Log Pis Std                  3.821808
Log Pis Max                  28.09946
Log Pis Min                  -7.635487
Policy mu Mean               -0.0013755136
Policy mu Std                0.6041694
Policy mu Max                3.494892
Policy mu Min                -3.9366252
Policy log std Mean          -0.9352991
Policy log std Std           0.19903138
Policy log std Max           -0.3540693
Policy log std Min           -2.182852
Z mean eval                  1.1830701
Z variance eval              0.023309793
total_rewards                [1166.73359209 1553.86167387 2027.40216141 2622.04656101  548.80533152
  583.63927729 1363.63423219   81.7807398  1819.36245719  317.06487223]
total_rewards_mean           1208.4330898594073
total_rewards_std            779.5353829218657
total_rewards_max            2622.04656100999
total_rewards_min            81.78073980363732
Number of train steps total  336000
Number of env steps total    278805
Number of rollouts total     0
Train Time (s)               146.99228800972924
(Previous) Eval Time (s)     15.519741042051464
Sample Time (s)              7.905120305716991
Epoch Time (s)               170.4171493574977
Total Train Time (s)         13833.466852859128
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:10.097945 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #83 | Epoch Duration: 170.5450041294098
2020-01-11 12:11:10.098076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1872823
Z variance train             0.023116682
KL Divergence                22.699482
KL Loss                      2.2699482
QF Loss                      598.1145
VF Loss                      109.138466
Policy Loss                  -699.76025
Q Predictions Mean           688.10925
Q Predictions Std            238.76738
Q Predictions Max            1028.5194
Q Predictions Min            218.72662
V Predictions Mean           695.23804
V Predictions Std            231.37582
V Predictions Max            1025.8087
V Predictions Min            221.83905
Log Pis Mean                 -0.8134088
Log Pis Std                  3.0228884
Log Pis Max                  15.970894
Log Pis Min                  -8.445982
Policy mu Mean               0.020059146
Policy mu Std                0.55988866
Policy mu Max                2.0699623
Policy mu Min                -3.0091195
Policy log std Mean          -0.95306057
Policy log std Std           0.19820295
Policy log std Max           -0.20887232
Policy log std Min           -2.2471964
Z mean eval                  1.1572545
Z variance eval              0.03840958
total_rewards                [ 184.55112184 2256.33560273  669.82955915  967.70619829 2831.84057711
 1635.13063399  969.73191601 1816.06703953 1532.01407672  527.39906593]
total_rewards_mean           1339.0605791307642
total_rewards_std            783.3309440352436
total_rewards_max            2831.8405771111466
total_rewards_min            184.5511218353626
Number of train steps total  340000
Number of env steps total    281339
Number of rollouts total     0
Train Time (s)               146.23861079197377
(Previous) Eval Time (s)     13.228446173015982
Sample Time (s)              7.517776522319764
Epoch Time (s)               166.98483348730952
Total Train Time (s)         14000.545443301555
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:13:57.180795 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #84 | Epoch Duration: 167.082617521286
2020-01-11 12:13:57.180949 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1514196
Z variance train             0.038580656
KL Divergence                22.377077
KL Loss                      2.2377079
QF Loss                      626.558
VF Loss                      193.33472
Policy Loss                  -646.2271
Q Predictions Mean           635.7528
Q Predictions Std            248.67126
Q Predictions Max            1000.27655
Q Predictions Min            1.9575622
V Predictions Mean           640.78564
V Predictions Std            240.27463
V Predictions Max            996.6964
V Predictions Min            185.79114
Log Pis Mean                 -0.7474805
Log Pis Std                  3.500153
Log Pis Max                  19.118553
Log Pis Min                  -6.795967
Policy mu Mean               0.016106602
Policy mu Std                0.5634297
Policy mu Max                3.5357828
Policy mu Min                -3.3186378
Policy log std Mean          -0.94904757
Policy log std Std           0.2029897
Policy log std Max           -0.4987305
Policy log std Min           -1.8660424
Z mean eval                  1.1339571
Z variance eval              0.01703647
total_rewards                [3011.93241248  923.45987897  745.99701452   14.93975909 1427.67758613
   67.32856126  133.73738396  458.7703334   377.10221619 1947.51734008]
total_rewards_mean           910.8462486056026
total_rewards_std            916.0252761028892
total_rewards_max            3011.9324124753703
total_rewards_min            14.939759085964628
Number of train steps total  344000
Number of env steps total    283838
Number of rollouts total     0
Train Time (s)               145.92108394484967
(Previous) Eval Time (s)     7.221071666106582
Sample Time (s)              6.445917547214776
Epoch Time (s)               159.58807315817103
Total Train Time (s)         14160.227921927348
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:36.864529 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #85 | Epoch Duration: 159.68343997001648
2020-01-11 12:16:36.864702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1361444
Z variance train             0.017005976
KL Divergence                23.2451
KL Loss                      2.32451
QF Loss                      610.19855
VF Loss                      157.26207
Policy Loss                  -675.98364
Q Predictions Mean           667.0516
Q Predictions Std            255.17226
Q Predictions Max            1034.1118
Q Predictions Min            -29.67717
V Predictions Mean           680.14716
V Predictions Std            252.24939
V Predictions Max            1032.1815
V Predictions Min            29.625849
Log Pis Mean                 -0.86052084
Log Pis Std                  3.207926
Log Pis Max                  12.931082
Log Pis Min                  -12.2335
Policy mu Mean               0.00025814865
Policy mu Std                0.5639686
Policy mu Max                2.2138886
Policy mu Min                -2.8003957
Policy log std Mean          -0.94029206
Policy log std Std           0.2006926
Policy log std Max           -0.33707052
Policy log std Min           -2.1112323
Z mean eval                  1.118305
Z variance eval              0.03736175
total_rewards                [1234.40283128 1045.54002548 1300.26567004 1271.15148673  441.31982877
  761.48085467 2876.02133171 1465.63929359 2560.635338   1372.28492333]
total_rewards_mean           1432.874158359309
total_rewards_std            708.969000758311
total_rewards_max            2876.0213317060425
total_rewards_min            441.31982876711226
Number of train steps total  348000
Number of env steps total    287337
Number of rollouts total     0
Train Time (s)               146.02213972015306
(Previous) Eval Time (s)     10.794711973052472
Sample Time (s)              6.946343493647873
Epoch Time (s)               163.7631951868534
Total Train Time (s)         14324.130545349792
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:20.767218 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #86 | Epoch Duration: 163.9023892879486
2020-01-11 12:19:20.767346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.120793
Z variance train             0.037114535
KL Divergence                21.512436
KL Loss                      2.1512437
QF Loss                      858.5605
VF Loss                      163.63998
Policy Loss                  -684.5798
Q Predictions Mean           673.01294
Q Predictions Std            244.36823
Q Predictions Max            1027.8954
Q Predictions Min            1.771877
V Predictions Mean           689.83344
V Predictions Std            238.9582
V Predictions Max            1023.55426
V Predictions Min            152.38753
Log Pis Mean                 -0.7973733
Log Pis Std                  3.152714
Log Pis Max                  20.5378
Log Pis Min                  -8.1095495
Policy mu Mean               -0.014202878
Policy mu Std                0.5548434
Policy mu Max                3.2039883
Policy mu Min                -2.7833405
Policy log std Mean          -0.9485576
Policy log std Std           0.2089324
Policy log std Max           -0.30112118
Policy log std Min           -1.9974856
Z mean eval                  1.1496637
Z variance eval              0.06625487
total_rewards                [1242.35414625  791.90623794  408.70349497  325.57171038  382.86744397
  709.59916015  462.14687324  536.32802198   10.36932057 1202.56467058]
total_rewards_mean           607.2411080028871
total_rewards_std            367.93918035382364
total_rewards_max            1242.354146251948
total_rewards_min            10.369320567678908
Number of train steps total  352000
Number of env steps total    290050
Number of rollouts total     0
Train Time (s)               145.77912659430876
(Previous) Eval Time (s)     11.772004297934473
Sample Time (s)              7.118670864962041
Epoch Time (s)               164.66980175720528
Total Train Time (s)         14488.88751319144
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:05.525367 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #87 | Epoch Duration: 164.75792288780212
2020-01-11 12:22:05.525499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.152003
Z variance train             0.0652714
KL Divergence                20.553986
KL Loss                      2.0553987
QF Loss                      658.4581
VF Loss                      159.36105
Policy Loss                  -677.74615
Q Predictions Mean           672.5143
Q Predictions Std            260.55643
Q Predictions Max            1012.9764
Q Predictions Min            204.30428
V Predictions Mean           674.4408
V Predictions Std            255.28354
V Predictions Max            1003.1269
V Predictions Min            197.4955
Log Pis Mean                 -0.3178062
Log Pis Std                  3.7143419
Log Pis Max                  24.468616
Log Pis Min                  -6.5106997
Policy mu Mean               -0.05316739
Policy mu Std                0.5924162
Policy mu Max                3.325255
Policy mu Min                -5.197674
Policy log std Mean          -0.96360004
Policy log std Std           0.20526576
Policy log std Max           -0.43909973
Policy log std Min           -1.7358116
Z mean eval                  1.1572117
Z variance eval              0.04384597
total_rewards                [2710.35432372 2646.3577647   745.9656204   215.39027766 1092.45519273
 2887.61901115 2820.93643564 1114.72410679  313.95080465 2445.93458911]
total_rewards_mean           1699.3688126565714
total_rewards_std            1043.3982592931745
total_rewards_max            2887.619011147355
total_rewards_min            215.3902776631208
Number of train steps total  356000
Number of env steps total    294494
Number of rollouts total     0
Train Time (s)               146.32640221202746
(Previous) Eval Time (s)     15.193536568898708
Sample Time (s)              7.154351927340031
Epoch Time (s)               168.6742907082662
Total Train Time (s)         14657.651511703618
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:24:54.289696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #88 | Epoch Duration: 168.76410579681396
2020-01-11 12:24:54.289815 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1507107
Z variance train             0.04381284
KL Divergence                21.546776
KL Loss                      2.1546776
QF Loss                      632.627
VF Loss                      132.04419
Policy Loss                  -725.859
Q Predictions Mean           715.35315
Q Predictions Std            245.41554
Q Predictions Max            1044.6503
Q Predictions Min            256.75375
V Predictions Mean           728.7958
V Predictions Std            240.59712
V Predictions Max            1044.5939
V Predictions Min            265.7505
Log Pis Mean                 -0.2653486
Log Pis Std                  3.4064138
Log Pis Max                  17.51432
Log Pis Min                  -8.873028
Policy mu Mean               -0.022627711
Policy mu Std                0.5901002
Policy mu Max                3.1041403
Policy mu Min                -3.0744576
Policy log std Mean          -0.9740984
Policy log std Std           0.21368043
Policy log std Max           -0.36718842
Policy log std Min           -2.032976
Z mean eval                  1.177572
Z variance eval              0.048391946
total_rewards                [ 996.16016973  951.68551592  806.38856885 2798.1621086  1532.88009167
  565.77029754  925.15004504 1559.48220821 2431.18146229  158.39719706]
total_rewards_mean           1272.5257664903882
total_rewards_std            779.6302709820496
total_rewards_max            2798.162108598809
total_rewards_min            158.39719705669592
Number of train steps total  360000
Number of env steps total    297079
Number of rollouts total     0
Train Time (s)               145.8743278319016
(Previous) Eval Time (s)     17.20375247206539
Sample Time (s)              6.747130289673805
Epoch Time (s)               169.8252105936408
Total Train Time (s)         14827.616396201774
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:44.257084 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #89 | Epoch Duration: 169.9671688079834
2020-01-11 12:27:44.257237 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1769294
Z variance train             0.048384763
KL Divergence                20.218945
KL Loss                      2.0218945
QF Loss                      739.48926
VF Loss                      182.01231
Policy Loss                  -686.5805
Q Predictions Mean           674.91064
Q Predictions Std            268.46948
Q Predictions Max            1037.924
Q Predictions Min            24.267397
V Predictions Mean           693.0956
V Predictions Std            261.79932
V Predictions Max            1037.574
V Predictions Min            247.29588
Log Pis Mean                 -0.3302831
Log Pis Std                  3.3538265
Log Pis Max                  17.357841
Log Pis Min                  -9.317745
Policy mu Mean               -0.053360596
Policy mu Std                0.5545301
Policy mu Max                2.62041
Policy mu Min                -2.3876843
Policy log std Mean          -0.96939564
Policy log std Std           0.2192933
Policy log std Max           -0.47655138
Policy log std Min           -2.0211866
Z mean eval                  1.1690383
Z variance eval              0.03969432
total_rewards                [ 690.7911426  1127.80812824  384.47198023  430.32901901  260.96834633
 2243.6888453   399.29882398  839.23438738 1467.97711036 2562.32025053]
total_rewards_mean           1040.6888033978337
total_rewards_std            770.6006341019672
total_rewards_max            2562.3202505325185
total_rewards_min            260.96834633290825
Number of train steps total  364000
Number of env steps total    299747
Number of rollouts total     0
Train Time (s)               145.16508227493614
(Previous) Eval Time (s)     12.394671720918268
Sample Time (s)              6.292104282416403
Epoch Time (s)               163.8518582782708
Total Train Time (s)         14991.553204536438
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:28.194698 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #90 | Epoch Duration: 163.93734335899353
2020-01-11 12:30:28.194816 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #90 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1678836
Z variance train             0.0399056
KL Divergence                22.549728
KL Loss                      2.254973
QF Loss                      593.4066
VF Loss                      117.2023
Policy Loss                  -693.0806
Q Predictions Mean           679.49384
Q Predictions Std            271.55322
Q Predictions Max            1046.0001
Q Predictions Min            -4.348925
V Predictions Mean           693.3878
V Predictions Std            262.0332
V Predictions Max            1032.5762
V Predictions Min            185.8291
Log Pis Mean                 -0.41461897
Log Pis Std                  3.2751007
Log Pis Max                  22.26662
Log Pis Min                  -5.8123856
Policy mu Mean               -0.028186193
Policy mu Std                0.5674376
Policy mu Max                3.7860255
Policy mu Min                -3.3135376
Policy log std Mean          -0.943563
Policy log std Std           0.20416471
Policy log std Max           -0.29065013
Policy log std Min           -1.8006809
Z mean eval                  1.1952822
Z variance eval              0.010127473
total_rewards                [1513.49346233  557.36032079 1613.68153965 2332.61679267  657.4198303
 1477.11227872  599.15866479 1439.69563886 1405.04597051 1039.381693  ]
total_rewards_mean           1263.496619163091
total_rewards_std            527.4836274796226
total_rewards_max            2332.616792673744
total_rewards_min            557.360320790883
Number of train steps total  368000
Number of env steps total    302684
Number of rollouts total     0
Train Time (s)               144.4797490555793
(Previous) Eval Time (s)     10.718638488091528
Sample Time (s)              6.985424851067364
Epoch Time (s)               162.1838123947382
Total Train Time (s)         15153.822351466864
Epoch                        91
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:10.464866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #91 | Epoch Duration: 162.26996064186096
2020-01-11 12:33:10.464982 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1957158
Z variance train             0.010155366
KL Divergence                24.712896
KL Loss                      2.4712896
QF Loss                      501.10004
VF Loss                      151.96216
Policy Loss                  -710.2552
Q Predictions Mean           700.16626
Q Predictions Std            268.29773
Q Predictions Max            1056.0751
Q Predictions Min            49.630928
V Predictions Mean           703.09875
V Predictions Std            261.60352
V Predictions Max            1051.6449
V Predictions Min            224.73639
Log Pis Mean                 -0.5337684
Log Pis Std                  2.663738
Log Pis Max                  12.15313
Log Pis Min                  -6.6912355
Policy mu Mean               -0.005980752
Policy mu Std                0.53784007
Policy mu Max                2.4469178
Policy mu Min                -2.3142493
Policy log std Mean          -0.9636756
Policy log std Std           0.20794153
Policy log std Max           -0.4691312
Policy log std Min           -1.9651415
Z mean eval                  1.1664493
Z variance eval              0.01583558
total_rewards                [1037.48553778 1291.43275741 2876.17769455 2976.14613863 1147.77500258
  381.13055949 2778.76689813 2966.78159182   55.15575124  870.41587419]
total_rewards_mean           1638.1267805839275
total_rewards_std            1085.6370334098501
total_rewards_max            2976.146138630738
total_rewards_min            55.15575123989386
Number of train steps total  372000
Number of env steps total    305226
Number of rollouts total     0
Train Time (s)               146.0667089158669
(Previous) Eval Time (s)     19.500028122216463
Sample Time (s)              6.392521204892546
Epoch Time (s)               171.95925824297592
Total Train Time (s)         15325.869676528499
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:36:02.516318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #92 | Epoch Duration: 172.05123805999756
2020-01-11 12:36:02.516463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.165091
Z variance train             0.015827607
KL Divergence                23.27862
KL Loss                      2.327862
QF Loss                      596.73035
VF Loss                      249.19112
Policy Loss                  -698.9291
Q Predictions Mean           693.45386
Q Predictions Std            274.28546
Q Predictions Max            1052.9686
Q Predictions Min            -4.108209
V Predictions Mean           705.33386
V Predictions Std            269.18796
V Predictions Max            1059.6
V Predictions Min            179.88629
Log Pis Mean                 -0.16160071
Log Pis Std                  3.6876628
Log Pis Max                  19.919449
Log Pis Min                  -10.157824
Policy mu Mean               -0.013657363
Policy mu Std                0.5919783
Policy mu Max                3.2827032
Policy mu Min                -4.608652
Policy log std Mean          -0.98561347
Policy log std Std           0.21637255
Policy log std Max           -0.35837084
Policy log std Min           -2.2010345
Z mean eval                  1.0984145
Z variance eval              0.03080832
total_rewards                [ 306.49413619 1036.27205492 2071.92407297  131.52504369  958.30413996
 1723.7100899  1791.24066188 1399.05838084  644.5606887  1084.00797243]
total_rewards_mean           1114.709724146773
total_rewards_std            608.1242852949645
total_rewards_max            2071.9240729657413
total_rewards_min            131.5250436852101
Number of train steps total  376000
Number of env steps total    307541
Number of rollouts total     0
Train Time (s)               146.11783630307764
(Previous) Eval Time (s)     15.072116056457162
Sample Time (s)              7.089943575207144
Epoch Time (s)               168.27989593474194
Total Train Time (s)         15494.235586226918
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:38:50.882539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #93 | Epoch Duration: 168.3659725189209
2020-01-11 12:38:50.882679 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1065959
Z variance train             0.030614942
KL Divergence                24.376501
KL Loss                      2.4376502
QF Loss                      1318.8671
VF Loss                      181.21417
Policy Loss                  -699.25824
Q Predictions Mean           684.4751
Q Predictions Std            284.08942
Q Predictions Max            1071.1694
Q Predictions Min            48.88388
V Predictions Mean           698.3362
V Predictions Std            272.47632
V Predictions Max            1051.1831
V Predictions Min            97.17395
Log Pis Mean                 -0.6645451
Log Pis Std                  3.1281502
Log Pis Max                  17.0873
Log Pis Min                  -10.864947
Policy mu Mean               -0.03710409
Policy mu Std                0.5616592
Policy mu Max                3.2425091
Policy mu Min                -3.9673727
Policy log std Mean          -0.9726176
Policy log std Std           0.21102254
Policy log std Max           -0.39001107
Policy log std Min           -2.0269694
Z mean eval                  1.1563785
Z variance eval              0.013169205
total_rewards                [2588.14191509 2988.94978087 1203.3358382   671.43822726 1064.03649011
  447.96529182  584.77872761 1650.99022915  145.03605003  430.48240274]
total_rewards_mean           1177.5154952886141
total_rewards_std            909.5411144167842
total_rewards_max            2988.949780871374
total_rewards_min            145.03605003131753
Number of train steps total  380000
Number of env steps total    310116
Number of rollouts total     0
Train Time (s)               146.2868282981217
(Previous) Eval Time (s)     12.145781306084245
Sample Time (s)              7.784666991792619
Epoch Time (s)               166.21727659599856
Total Train Time (s)         15660.545310323592
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:37.192990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #94 | Epoch Duration: 166.31022214889526
2020-01-11 12:41:37.193103 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.158774
Z variance train             0.012800259
KL Divergence                25.049818
KL Loss                      2.5049818
QF Loss                      372.80756
VF Loss                      160.30547
Policy Loss                  -703.6202
Q Predictions Mean           696.8865
Q Predictions Std            277.72504
Q Predictions Max            1088.8235
Q Predictions Min            51.698444
V Predictions Mean           711.5539
V Predictions Std            276.78986
V Predictions Max            1085.6079
V Predictions Min            63.374283
Log Pis Mean                 -0.86673266
Log Pis Std                  3.0326743
Log Pis Max                  11.569282
Log Pis Min                  -6.5945573
Policy mu Mean               -0.014072791
Policy mu Std                0.5430429
Policy mu Max                3.1972888
Policy mu Min                -3.3296762
Policy log std Mean          -0.948483
Policy log std Std           0.19919308
Policy log std Max           -0.4168571
Policy log std Min           -2.0011983
Z mean eval                  1.1487606
Z variance eval              0.024283882
total_rewards                [1766.33279641 2707.0132719   184.7734423   825.75728022  389.49253994
  338.72578759 2827.72355338 1342.96264683 3085.11767263 2895.68361896]
total_rewards_mean           1636.3582610153198
total_rewards_std            1111.581241601937
total_rewards_max            3085.1176726330577
total_rewards_min            184.77344230233757
Number of train steps total  384000
Number of env steps total    313768
Number of rollouts total     0
Train Time (s)               144.721858096309
(Previous) Eval Time (s)     18.09333844576031
Sample Time (s)              6.791068407241255
Epoch Time (s)               169.60626494931057
Total Train Time (s)         15830.247561837547
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:26.896722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #95 | Epoch Duration: 169.703528881073
2020-01-11 12:44:26.896853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1486022
Z variance train             0.024163824
KL Divergence                22.665247
KL Loss                      2.2665248
QF Loss                      1852.6862
VF Loss                      2634.5234
Policy Loss                  -757.12317
Q Predictions Mean           749.1384
Q Predictions Std            271.91025
Q Predictions Max            1093.0219
Q Predictions Min            -7.1939
V Predictions Mean           760.8563
V Predictions Std            260.05554
V Predictions Max            1086.4974
V Predictions Min            174.35805
Log Pis Mean                 -0.29968694
Log Pis Std                  3.3469603
Log Pis Max                  22.817307
Log Pis Min                  -6.745676
Policy mu Mean               -0.024890028
Policy mu Std                0.5841865
Policy mu Max                3.83722
Policy mu Min                -5.50219
Policy log std Mean          -0.98278487
Policy log std Std           0.20567176
Policy log std Max           -0.33490795
Policy log std Min           -2.0268636
Z mean eval                  1.2101891
Z variance eval              0.016104836
total_rewards                [2802.33166221 1481.06639677 3118.90561809  518.18932153 1322.24877189
  450.10555303 2881.52695648  658.9175349  2860.93220979 1278.20173412]
total_rewards_mean           1737.2425758806753
total_rewards_std            1018.3140328069459
total_rewards_max            3118.9056180906105
total_rewards_min            450.1055530281762
Number of train steps total  388000
Number of env steps total    316317
Number of rollouts total     0
Train Time (s)               146.30361416982487
(Previous) Eval Time (s)     20.63978747278452
Sample Time (s)              8.137791307177395
Epoch Time (s)               175.08119294978678
Total Train Time (s)         16005.41932959389
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:47:22.070392 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #96 | Epoch Duration: 175.17343306541443
2020-01-11 12:47:22.070563 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2090911
Z variance train             0.01620726
KL Divergence                22.381315
KL Loss                      2.2381315
QF Loss                      708.172
VF Loss                      157.56332
Policy Loss                  -708.38617
Q Predictions Mean           697.8377
Q Predictions Std            265.68808
Q Predictions Max            1066.219
Q Predictions Min            20.906893
V Predictions Mean           707.0325
V Predictions Std            256.83694
V Predictions Max            1066.9412
V Predictions Min            149.57849
Log Pis Mean                 -0.24312851
Log Pis Std                  4.055923
Log Pis Max                  27.142365
Log Pis Min                  -9.223588
Policy mu Mean               -0.0014690142
Policy mu Std                0.6104463
Policy mu Max                3.364459
Policy mu Min                -4.307612
Policy log std Mean          -0.984323
Policy log std Std           0.22234745
Policy log std Max           -0.4377197
Policy log std Min           -2.3252716
Z mean eval                  1.1952647
Z variance eval              0.013889837
total_rewards                [ 434.70138284  836.87874998  267.57227054   52.56181961 1158.03846859
  729.63317008  554.45315962 1119.19887521 2110.00399596  288.39000699]
total_rewards_mean           755.1431899419515
total_rewards_std            568.3312741096571
total_rewards_max            2110.003995963932
total_rewards_min            52.5618196058897
Number of train steps total  392000
Number of env steps total    319294
Number of rollouts total     0
Train Time (s)               146.41809606691822
(Previous) Eval Time (s)     8.218322292901576
Sample Time (s)              9.25502912281081
Epoch Time (s)               163.8914474826306
Total Train Time (s)         16169.396505737212
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:50:06.053543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #97 | Epoch Duration: 163.98272681236267
2020-01-11 12:50:06.053682 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1973459
Z variance train             0.013905828
KL Divergence                22.65769
KL Loss                      2.265769
QF Loss                      633.28015
VF Loss                      126.27298
Policy Loss                  -753.2395
Q Predictions Mean           742.3233
Q Predictions Std            267.80133
Q Predictions Max            1099.7433
Q Predictions Min            44.12876
V Predictions Mean           754.5243
V Predictions Std            263.89697
V Predictions Max            1100.5187
V Predictions Min            91.097565
Log Pis Mean                 -0.4226552
Log Pis Std                  3.4011922
Log Pis Max                  18.999058
Log Pis Min                  -8.031449
Policy mu Mean               -0.0205201
Policy mu Std                0.5746166
Policy mu Max                2.360625
Policy mu Min                -3.1164129
Policy log std Mean          -0.9708313
Policy log std Std           0.21898258
Policy log std Max           -0.37513423
Policy log std Min           -2.6870103
Z mean eval                  1.1499422
Z variance eval              0.011868866
total_rewards                [1407.83341189 2147.23305094 1389.65267012  406.62885198 1233.61730161
  904.45695467 2154.43311456 2395.72411442 1445.88177148  997.46997807]
total_rewards_mean           1448.2931219727511
total_rewards_std            593.2964813140984
total_rewards_max            2395.7241144203294
total_rewards_min            406.62885197634427
Number of train steps total  396000
Number of env steps total    321831
Number of rollouts total     0
Train Time (s)               145.45225416403264
(Previous) Eval Time (s)     13.852588579058647
Sample Time (s)              7.584994349163026
Epoch Time (s)               166.8898370922543
Total Train Time (s)         16336.377725211903
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:53.033823 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #98 | Epoch Duration: 166.980046749115
2020-01-11 12:52:53.033944 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.155693
Z variance train             0.01179162
KL Divergence                23.352032
KL Loss                      2.3352032
QF Loss                      640.82153
VF Loss                      117.52988
Policy Loss                  -748.0136
Q Predictions Mean           736.937
Q Predictions Std            282.7084
Q Predictions Max            1097.2827
Q Predictions Min            -42.550358
V Predictions Mean           746.09186
V Predictions Std            274.9746
V Predictions Max            1090.6128
V Predictions Min            6.8195896
Log Pis Mean                 -0.6096846
Log Pis Std                  3.4557238
Log Pis Max                  18.691929
Log Pis Min                  -9.321843
Policy mu Mean               -0.014266798
Policy mu Std                0.58208466
Policy mu Max                3.525084
Policy mu Min                -3.0468276
Policy log std Mean          -0.94919944
Policy log std Std           0.20852037
Policy log std Max           -0.26660234
Policy log std Min           -1.8011134
Z mean eval                  1.088807
Z variance eval              0.011834802
total_rewards                [ 496.12344149 2436.60049468 2925.51939621  535.31306189 1468.77076109
 2785.32309348 2702.1824141  3158.36296297 2588.10758863 2158.38518617]
total_rewards_mean           2125.468840071323
total_rewards_std            916.5965601844817
total_rewards_max            3158.3629629731213
total_rewards_min            496.12344148570145
Number of train steps total  400000
Number of env steps total    325517
Number of rollouts total     0
Train Time (s)               144.21574826771393
(Previous) Eval Time (s)     20.791508980095387
Sample Time (s)              6.185577047523111
Epoch Time (s)               171.19283429533243
Total Train Time (s)         16507.65464559151
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:44.312488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #99 | Epoch Duration: 171.27845120429993
2020-01-11 12:55:44.312615 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0947878
Z variance train             0.011745921
KL Divergence                22.461605
KL Loss                      2.2461605
QF Loss                      796.7204
VF Loss                      112.49472
Policy Loss                  -775.1483
Q Predictions Mean           766.2647
Q Predictions Std            275.08997
Q Predictions Max            1135.3416
Q Predictions Min            251.3718
V Predictions Mean           769.57745
V Predictions Std            272.68832
V Predictions Max            1122.2083
V Predictions Min            243.39609
Log Pis Mean                 -0.6811141
Log Pis Std                  2.6385753
Log Pis Max                  9.84305
Log Pis Min                  -7.392235
Policy mu Mean               0.0029400517
Policy mu Std                0.5481214
Policy mu Max                2.7221384
Policy mu Min                -2.2527013
Policy log std Mean          -0.9657392
Policy log std Std           0.20721012
Policy log std Max           -0.47321266
Policy log std Min           -1.997512
Z mean eval                  1.1098852
Z variance eval              0.021087835
total_rewards                [2721.30347004 1055.94075127  752.6214436  2226.22501823 3217.45034498
  655.99847982  500.88402211 3124.19547404 1642.50898292 2417.80895712]
total_rewards_mean           1831.4936944133337
total_rewards_std            991.8047989556362
total_rewards_max            3217.450344977977
total_rewards_min            500.88402211324836
Number of train steps total  404000
Number of env steps total    327921
Number of rollouts total     0
Train Time (s)               147.86903319740668
(Previous) Eval Time (s)     14.517943400889635
Sample Time (s)              7.164438769221306
Epoch Time (s)               169.55141536751762
Total Train Time (s)         16677.291517934762
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:33.954340 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #100 | Epoch Duration: 169.64157390594482
2020-01-11 12:58:33.954812 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1072153
Z variance train             0.021007728
KL Divergence                21.91859
KL Loss                      2.191859
QF Loss                      531.49695
VF Loss                      120.90107
Policy Loss                  -779.5021
Q Predictions Mean           773.59436
Q Predictions Std            286.46155
Q Predictions Max            1133.8395
Q Predictions Min            220.97748
V Predictions Mean           786.05707
V Predictions Std            281.35596
V Predictions Max            1149.4432
V Predictions Min            234.13954
Log Pis Mean                 -0.17853877
Log Pis Std                  3.4604363
Log Pis Max                  18.736485
Log Pis Min                  -10.934325
Policy mu Mean               -0.021103814
Policy mu Std                0.5886114
Policy mu Max                3.3126814
Policy mu Min                -4.747613
Policy log std Mean          -1.003055
Policy log std Std           0.22048515
Policy log std Max           -0.25547242
Policy log std Min           -1.9088387
Z mean eval                  1.1460905
Z variance eval              0.018091412
total_rewards                [2025.92646211  630.26619806 2361.3340113  3148.04023553 1181.00210876
  214.99475176  562.92368365 1477.04591492 3178.97905452 2845.18118355]
total_rewards_mean           1762.5693604150395
total_rewards_std            1051.7443545758815
total_rewards_max            3178.9790545191254
total_rewards_min            214.9947517595345
Number of train steps total  408000
Number of env steps total    330297
Number of rollouts total     0
Train Time (s)               145.16057990677655
(Previous) Eval Time (s)     20.37189507810399
Sample Time (s)              6.530568069778383
Epoch Time (s)               172.06304305465892
Total Train Time (s)         16849.45786704868
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:01:26.119977 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #101 | Epoch Duration: 172.16478300094604
2020-01-11 13:01:26.120110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1405001
Z variance train             0.01820501
KL Divergence                22.138355
KL Loss                      2.2138355
QF Loss                      709.8332
VF Loss                      133.37119
Policy Loss                  -757.12476
Q Predictions Mean           747.2445
Q Predictions Std            304.28583
Q Predictions Max            1144.9956
Q Predictions Min            -4.924961
V Predictions Mean           761.14954
V Predictions Std            290.97586
V Predictions Max            1144.938
V Predictions Min            47.360855
Log Pis Mean                 -0.24369118
Log Pis Std                  3.1858442
Log Pis Max                  12.626875
Log Pis Min                  -9.76733
Policy mu Mean               -0.051606756
Policy mu Std                0.56956065
Policy mu Max                2.550212
Policy mu Min                -2.5201714
Policy log std Mean          -0.98977995
Policy log std Std           0.22588028
Policy log std Max           -0.42940855
Policy log std Min           -2.0093114
Z mean eval                  1.1619273
Z variance eval              0.046116155
total_rewards                [ 830.43358175 1196.76061442 1413.41595065 3016.26292126   16.50809203
  438.40379694 1280.26419892  288.77077574 1927.65799543 1008.14408534]
total_rewards_mean           1141.6622012469797
total_rewards_std            826.4787943106139
total_rewards_max            3016.2629212586544
total_rewards_min            16.50809202505524
Number of train steps total  412000
Number of env steps total    333166
Number of rollouts total     0
Train Time (s)               144.58454751130193
(Previous) Eval Time (s)     15.44269262906164
Sample Time (s)              8.581397536210716
Epoch Time (s)               168.6086376765743
Total Train Time (s)         17018.153917507734
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:04:14.817129 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #102 | Epoch Duration: 168.69692206382751
2020-01-11 13:04:14.817249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.158937
Z variance train             0.046702646
KL Divergence                21.461466
KL Loss                      2.1461465
QF Loss                      605.9132
VF Loss                      125.102325
Policy Loss                  -788.2413
Q Predictions Mean           775.64386
Q Predictions Std            290.7283
Q Predictions Max            1150.4915
Q Predictions Min            -47.808903
V Predictions Mean           791.24414
V Predictions Std            275.40735
V Predictions Max            1147.8689
V Predictions Min            181.15305
Log Pis Mean                 -0.093719505
Log Pis Std                  3.561202
Log Pis Max                  18.020082
Log Pis Min                  -6.6424947
Policy mu Mean               -0.043385252
Policy mu Std                0.61562765
Policy mu Max                3.8445044
Policy mu Min                -3.8493035
Policy log std Mean          -0.9850975
Policy log std Std           0.22398353
Policy log std Max           -0.44034627
Policy log std Min           -1.954793
Z mean eval                  1.093516
Z variance eval              0.024501178
total_rewards                [1955.23277736 2588.54866277  341.61805986 1068.53346151  595.58243997
   93.19103506 2234.63126934 3192.74230184 3008.19276865 1575.13926589]
total_rewards_mean           1665.3412042238033
total_rewards_std            1054.9523000342128
total_rewards_max            3192.742301835806
total_rewards_min            93.19103505574638
Number of train steps total  416000
Number of env steps total    335963
Number of rollouts total     0
Train Time (s)               145.69733853498474
(Previous) Eval Time (s)     18.00498979911208
Sample Time (s)              6.760023392736912
Epoch Time (s)               170.46235172683373
Total Train Time (s)         17188.70465751039
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:07:05.368555 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #103 | Epoch Duration: 170.55121421813965
2020-01-11 13:07:05.368682 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0948398
Z variance train             0.024547461
KL Divergence                22.4237
KL Loss                      2.2423701
QF Loss                      567.9689
VF Loss                      119.583374
Policy Loss                  -777.2063
Q Predictions Mean           768.7827
Q Predictions Std            289.64508
Q Predictions Max            1137.793
Q Predictions Min            -37.487392
V Predictions Mean           776.41705
V Predictions Std            280.53635
V Predictions Max            1129.8636
V Predictions Min            248.38048
Log Pis Mean                 -0.5215587
Log Pis Std                  3.0410347
Log Pis Max                  14.903803
Log Pis Min                  -9.107825
Policy mu Mean               0.00046239654
Policy mu Std                0.55645114
Policy mu Max                3.1373613
Policy mu Min                -2.1840882
Policy log std Mean          -0.9823598
Policy log std Std           0.21449608
Policy log std Max           -0.43117487
Policy log std Min           -1.9425483
Z mean eval                  1.1133336
Z variance eval              0.011859143
total_rewards                [1681.8424543  1105.47121507  556.41106065 1154.847507   3111.53200782
 1422.42333775  662.37869489 2811.6729443   925.55056714 1232.18549274]
total_rewards_mean           1466.431528165464
total_rewards_std            813.2531723120134
total_rewards_max            3111.532007820324
total_rewards_min            556.4110606544187
Number of train steps total  420000
Number of env steps total    339588
Number of rollouts total     0
Train Time (s)               146.08545700274408
(Previous) Eval Time (s)     18.629552795086056
Sample Time (s)              7.612528318539262
Epoch Time (s)               172.3275381163694
Total Train Time (s)         17361.11670349026
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:57.781707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #104 | Epoch Duration: 172.41293597221375
2020-01-11 13:09:57.781833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #104 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1079347
Z variance train             0.0118673565
KL Divergence                22.759466
KL Loss                      2.2759466
QF Loss                      583.70074
VF Loss                      234.84769
Policy Loss                  -763.46
Q Predictions Mean           754.65735
Q Predictions Std            292.52438
Q Predictions Max            1127.5881
Q Predictions Min            14.086769
V Predictions Mean           770.3439
V Predictions Std            286.06714
V Predictions Max            1123.3588
V Predictions Min            82.5953
Log Pis Mean                 -0.4076208
Log Pis Std                  3.4565976
Log Pis Max                  17.129555
Log Pis Min                  -8.518882
Policy mu Mean               0.0023096288
Policy mu Std                0.56029576
Policy mu Max                3.868135
Policy mu Min                -2.9384136
Policy log std Mean          -0.97923774
Policy log std Std           0.21944983
Policy log std Max           -0.4104355
Policy log std Min           -1.8858435
Z mean eval                  1.0902888
Z variance eval              0.015230209
total_rewards                [281.36680639 370.00542064 268.01643439 729.07014447 622.34905031
 446.88260868 229.51411283 304.14782428 204.51546967 651.13037908]
total_rewards_mean           410.6998250744972
total_rewards_std            181.85331830944733
total_rewards_max            729.0701444704268
total_rewards_min            204.51546967258537
Number of train steps total  424000
Number of env steps total    342688
Number of rollouts total     0
Train Time (s)               145.19038172019646
(Previous) Eval Time (s)     6.6308051170781255
Sample Time (s)              8.526674808934331
Epoch Time (s)               160.3478616462089
Total Train Time (s)         17521.572602323256
Epoch                        105
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:38.240112 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #105 | Epoch Duration: 160.45818066596985
2020-01-11 13:12:38.240270 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.091731
Z variance train             0.0152480155
KL Divergence                22.108086
KL Loss                      2.2108085
QF Loss                      962.6921
VF Loss                      319.30505
Policy Loss                  -742.72955
Q Predictions Mean           733.3528
Q Predictions Std            297.1388
Q Predictions Max            1105.9468
Q Predictions Min            -50.126534
V Predictions Mean           750.77936
V Predictions Std            286.72168
V Predictions Max            1106.4374
V Predictions Min            223.31343
Log Pis Mean                 -0.11983769
Log Pis Std                  3.2451167
Log Pis Max                  13.55097
Log Pis Min                  -7.698344
Policy mu Mean               -0.03139042
Policy mu Std                0.57138175
Policy mu Max                2.9030232
Policy mu Min                -2.7540312
Policy log std Mean          -0.9834851
Policy log std Std           0.22277096
Policy log std Max           -0.41732872
Policy log std Min           -1.9762437
Z mean eval                  1.139682
Z variance eval              0.017588565
total_rewards                [ 554.5109127  1240.29252785 2111.92504271  849.35226961  339.18896132
 1734.21944634 1044.26154059 2436.69690435 1809.07181333 3318.884842  ]
total_rewards_mean           1543.8404260783377
total_rewards_std            873.5719539619129
total_rewards_max            3318.8848419972282
total_rewards_min            339.18896131567476
Number of train steps total  428000
Number of env steps total    345852
Number of rollouts total     0
Train Time (s)               146.15916937496513
(Previous) Eval Time (s)     15.702843122184277
Sample Time (s)              8.206489744130522
Epoch Time (s)               170.06850224127993
Total Train Time (s)         17691.732505166903
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:28.402897 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #106 | Epoch Duration: 170.1624994277954
2020-01-11 13:15:28.403070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1376431
Z variance train             0.017529521
KL Divergence                22.269829
KL Loss                      2.2269828
QF Loss                      707.5207
VF Loss                      116.84682
Policy Loss                  -784.10394
Q Predictions Mean           777.73096
Q Predictions Std            283.14798
Q Predictions Max            1126.3881
Q Predictions Min            -6.7757883
V Predictions Mean           787.70605
V Predictions Std            274.56662
V Predictions Max            1121.4684
V Predictions Min            146.53888
Log Pis Mean                 -0.3884652
Log Pis Std                  3.1416285
Log Pis Max                  16.878458
Log Pis Min                  -7.1797256
Policy mu Mean               0.004430514
Policy mu Std                0.5948968
Policy mu Max                3.108049
Policy mu Min                -2.2929935
Policy log std Mean          -0.9858088
Policy log std Std           0.21748239
Policy log std Max           -0.39260173
Policy log std Min           -1.9982555
Z mean eval                  1.110493
Z variance eval              0.015003353
total_rewards                [ 771.27427661 3171.82654543  976.73422696  669.82271994 1386.23800083
  297.84122888 1523.49884564 1003.88270597  369.22555306  336.59315975]
total_rewards_mean           1050.6937263071254
total_rewards_std            812.8507662619545
total_rewards_max            3171.826545431122
total_rewards_min            297.841228875394
Number of train steps total  432000
Number of env steps total    348305
Number of rollouts total     0
Train Time (s)               145.05629389500245
(Previous) Eval Time (s)     9.33940897276625
Sample Time (s)              6.942872306797653
Epoch Time (s)               161.33857517456636
Total Train Time (s)         17853.17759832507
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:18:09.848634 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #107 | Epoch Duration: 161.44544291496277
2020-01-11 13:18:09.848759 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1141436
Z variance train             0.014991343
KL Divergence                22.918182
KL Loss                      2.2918184
QF Loss                      557.9184
VF Loss                      104.85771
Policy Loss                  -777.14435
Q Predictions Mean           770.60657
Q Predictions Std            292.146
Q Predictions Max            1120.7074
Q Predictions Min            221.12077
V Predictions Mean           779.62994
V Predictions Std            289.98355
V Predictions Max            1125.089
V Predictions Min            241.22606
Log Pis Mean                 -0.2780812
Log Pis Std                  2.987207
Log Pis Max                  8.8146925
Log Pis Min                  -7.1192284
Policy mu Mean               -0.041338876
Policy mu Std                0.5548393
Policy mu Max                2.169575
Policy mu Min                -2.8656533
Policy log std Mean          -0.98298436
Policy log std Std           0.21430518
Policy log std Max           -0.4690602
Policy log std Min           -2.0710216
Z mean eval                  1.1347368
Z variance eval              0.01300587
total_rewards                [3358.63694515 3243.38978965 2978.02783484 2423.55026275 3249.76460213
 3099.76737293 2862.48454719 1073.34061715  254.71236961 2318.27042244]
total_rewards_mean           2486.1944763845104
total_rewards_std            984.1390712563355
total_rewards_max            3358.6369451543655
total_rewards_min            254.71236961134613
Number of train steps total  436000
Number of env steps total    351946
Number of rollouts total     0
Train Time (s)               143.3681975803338
(Previous) Eval Time (s)     22.00700111174956
Sample Time (s)              6.580912579316646
Epoch Time (s)               171.9561112714
Total Train Time (s)         18025.223663368262
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:21:01.898201 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #108 | Epoch Duration: 172.04932236671448
2020-01-11 13:21:01.898436 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1264746
Z variance train             0.012920347
KL Divergence                22.408194
KL Loss                      2.2408195
QF Loss                      664.35046
VF Loss                      130.03043
Policy Loss                  -789.0646
Q Predictions Mean           781.67914
Q Predictions Std            299.85587
Q Predictions Max            1177.6361
Q Predictions Min            220.8374
V Predictions Mean           792.731
V Predictions Std            295.84766
V Predictions Max            1182.3464
V Predictions Min            243.32999
Log Pis Mean                 -0.12940627
Log Pis Std                  3.1856086
Log Pis Max                  17.121582
Log Pis Min                  -9.211852
Policy mu Mean               0.0018686512
Policy mu Std                0.5743395
Policy mu Max                2.93911
Policy mu Min                -3.2671506
Policy log std Mean          -1.0146351
Policy log std Std           0.22208492
Policy log std Max           -0.5509609
Policy log std Min           -1.9729114
Z mean eval                  1.0632346
Z variance eval              0.06271459
total_rewards                [1419.79094407  176.68896762 2186.11792833  114.25418695 3282.41539171
 1250.32059803  309.53831837  610.35487117  637.90131921 1086.8675368 ]
total_rewards_mean           1107.4250062259362
total_rewards_std            947.0685331215664
total_rewards_max            3282.4153917103476
total_rewards_min            114.25418694830176
Number of train steps total  440000
Number of env steps total    354602
Number of rollouts total     0
Train Time (s)               147.16504768375307
(Previous) Eval Time (s)     8.912616008892655
Sample Time (s)              6.24251659354195
Epoch Time (s)               162.32018028618768
Total Train Time (s)         18187.644375630654
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:23:44.319382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #109 | Epoch Duration: 162.4207899570465
2020-01-11 13:23:44.319508 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0650977
Z variance train             0.06351333
KL Divergence                19.299395
KL Loss                      1.9299395
QF Loss                      961.2118
VF Loss                      180.88171
Policy Loss                  -751.3659
Q Predictions Mean           744.553
Q Predictions Std            296.8538
Q Predictions Max            1149.7534
Q Predictions Min            1.8192642
V Predictions Mean           745.8214
V Predictions Std            288.94077
V Predictions Max            1142.0504
V Predictions Min            178.0063
Log Pis Mean                 -0.28806782
Log Pis Std                  3.393254
Log Pis Max                  26.303593
Log Pis Min                  -7.6877837
Policy mu Mean               -0.049852286
Policy mu Std                0.5645577
Policy mu Max                4.50384
Policy mu Min                -3.517124
Policy log std Mean          -1.001616
Policy log std Std           0.21574455
Policy log std Max           -0.40612137
Policy log std Min           -2.0201688
Z mean eval                  1.1123317
Z variance eval              0.042539693
total_rewards                [ 851.79268904   67.35586199  638.41863597  876.69348525 1830.79112419
 1364.31015282 1506.28598766  676.68070326 2890.44625121  611.92480544]
total_rewards_mean           1131.4699696838607
total_rewards_std            759.8077769461206
total_rewards_max            2890.4462512106684
total_rewards_min            67.35586198858807
Number of train steps total  444000
Number of env steps total    357321
Number of rollouts total     0
Train Time (s)               145.71812780061737
(Previous) Eval Time (s)     10.904018293134868
Sample Time (s)              7.836933283135295
Epoch Time (s)               164.45907937688753
Total Train Time (s)         18352.209876586217
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:26:28.887126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #110 | Epoch Duration: 164.56750893592834
2020-01-11 13:26:28.887296 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1142796
Z variance train             0.04244256
KL Divergence                19.936144
KL Loss                      1.9936144
QF Loss                      610.2262
VF Loss                      149.24849
Policy Loss                  -803.8073
Q Predictions Mean           799.4297
Q Predictions Std            309.98456
Q Predictions Max            1206.3232
Q Predictions Min            220.98717
V Predictions Mean           803.2378
V Predictions Std            308.94016
V Predictions Max            1216.9696
V Predictions Min            218.17996
Log Pis Mean                 -0.6016295
Log Pis Std                  2.8040755
Log Pis Max                  7.461034
Log Pis Min                  -7.844962
Policy mu Mean               -0.027157415
Policy mu Std                0.5314222
Policy mu Max                2.9167614
Policy mu Min                -2.0892131
Policy log std Mean          -0.9979858
Policy log std Std           0.23374864
Policy log std Max           -0.24660176
Policy log std Min           -2.231967
Z mean eval                  1.0962559
Z variance eval              0.068515584
total_rewards                [3127.24339342  600.10851231 1038.48258076   37.6174002  1458.20659268
  493.44647622  313.02959449  215.991175    413.33260323 2936.72091858]
total_rewards_mean           1063.4179246890267
total_rewards_std            1059.2797073051606
total_rewards_max            3127.2433934154365
total_rewards_min            37.61740020066902
Number of train steps total  448000
Number of env steps total    359640
Number of rollouts total     0
Train Time (s)               148.03547236230224
(Previous) Eval Time (s)     10.237329179886729
Sample Time (s)              7.173160215839744
Epoch Time (s)               165.44596175802872
Total Train Time (s)         18517.74702981161
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:29:14.425501 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #111 | Epoch Duration: 165.53805875778198
2020-01-11 13:29:14.425690 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1007845
Z variance train             0.06738579
KL Divergence                20.55057
KL Loss                      2.055057
QF Loss                      844.05554
VF Loss                      152.93173
Policy Loss                  -826.0296
Q Predictions Mean           812.8591
Q Predictions Std            299.61008
Q Predictions Max            1170.5828
Q Predictions Min            -54.481926
V Predictions Mean           821.66907
V Predictions Std            285.50525
V Predictions Max            1162.0289
V Predictions Min            8.166493
Log Pis Mean                 0.0015540197
Log Pis Std                  3.5131993
Log Pis Max                  18.864506
Log Pis Min                  -8.552836
Policy mu Mean               -0.031143097
Policy mu Std                0.6017298
Policy mu Max                3.779499
Policy mu Min                -3.665219
Policy log std Mean          -0.9972335
Policy log std Std           0.24193016
Policy log std Max           -0.2684976
Policy log std Min           -2.091721
Z mean eval                  1.1575718
Z variance eval              0.14074609
total_rewards                [2807.51707773  153.83197055  345.13563274  815.69711946   88.32394371
 1597.74416934 3118.54812305 1958.34781443  598.90683725 1357.65780305]
total_rewards_mean           1284.1710491319832
total_rewards_std            1025.7838074351826
total_rewards_max            3118.548123052793
total_rewards_min            88.32394371210445
Number of train steps total  452000
Number of env steps total    362101
Number of rollouts total     0
Train Time (s)               145.8675218471326
(Previous) Eval Time (s)     12.04956129193306
Sample Time (s)              7.221450561191887
Epoch Time (s)               165.13853370025754
Total Train Time (s)         18682.996818778105
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:31:59.677783 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #112 | Epoch Duration: 165.25193977355957
2020-01-11 13:31:59.678003 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #112 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.158783
Z variance train             0.14072946
KL Divergence                19.506124
KL Loss                      1.9506124
QF Loss                      637.75977
VF Loss                      82.26194
Policy Loss                  -847.2464
Q Predictions Mean           838.91724
Q Predictions Std            280.86154
Q Predictions Max            1212.4432
Q Predictions Min            214.18076
V Predictions Mean           844.8906
V Predictions Std            277.86703
V Predictions Max            1203.4551
V Predictions Min            241.79773
Log Pis Mean                 -0.21704742
Log Pis Std                  2.7732646
Log Pis Max                  7.299719
Log Pis Min                  -9.178445
Policy mu Mean               -0.016332876
Policy mu Std                0.568777
Policy mu Max                2.410482
Policy mu Min                -2.2627478
Policy log std Mean          -0.97884774
Policy log std Std           0.2239548
Policy log std Max           -0.3464225
Policy log std Min           -2.1338074
Z mean eval                  1.0762233
Z variance eval              0.04188323
total_rewards                [ 280.70772731 3152.00213053 1178.35152769 2985.4713831  1149.730792
 3182.00149219 2922.57228139   53.09297738 1341.20500724 3133.29243409]
total_rewards_mean           1937.8427752920004
total_rewards_std            1198.779966765256
total_rewards_max            3182.0014921908696
total_rewards_min            53.09297738480873
Number of train steps total  456000
Number of env steps total    364976
Number of rollouts total     0
Train Time (s)               147.0285026789643
(Previous) Eval Time (s)     18.32986605213955
Sample Time (s)              7.296320957131684
Epoch Time (s)               172.65468968823552
Total Train Time (s)         18855.742109728046
Epoch                        113
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:34:52.423708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #113 | Epoch Duration: 172.74556303024292
2020-01-11 13:34:52.423841 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0741285
Z variance train             0.041281085
KL Divergence                19.655607
KL Loss                      1.9655608
QF Loss                      1252.2927
VF Loss                      141.26262
Policy Loss                  -833.6307
Q Predictions Mean           823.9245
Q Predictions Std            325.68436
Q Predictions Max            1221.3701
Q Predictions Min            -16.45568
V Predictions Mean           828.15424
V Predictions Std            316.39224
V Predictions Max            1209.888
V Predictions Min            64.496025
Log Pis Mean                 0.026444271
Log Pis Std                  3.2785823
Log Pis Max                  24.56185
Log Pis Min                  -7.563376
Policy mu Mean               -0.050203897
Policy mu Std                0.59129006
Policy mu Max                3.6517045
Policy mu Min                -2.9535682
Policy log std Mean          -1.0252507
Policy log std Std           0.2352871
Policy log std Max           -0.30474758
Policy log std Min           -2.119114
Z mean eval                  1.1181791
Z variance eval              0.07384904
total_rewards                [3302.66407892  252.81865491 3247.90314111 2040.77039573 2508.31257012
  195.20332217 3063.16212959 2303.12298299 3005.10866679  909.86464443]
total_rewards_mean           2082.893058676354
total_rewards_std            1147.880513708567
total_rewards_max            3302.6640789234484
total_rewards_min            195.20332216799778
Number of train steps total  460000
Number of env steps total    368224
Number of rollouts total     0
Train Time (s)               143.07454365910962
(Previous) Eval Time (s)     16.752303816378117
Sample Time (s)              7.17329386388883
Epoch Time (s)               167.00014133937657
Total Train Time (s)         19022.83209104603
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:37:39.515362 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #114 | Epoch Duration: 167.09140944480896
2020-01-11 13:37:39.515559 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1198484
Z variance train             0.07357232
KL Divergence                18.869167
KL Loss                      1.8869168
QF Loss                      721.9949
VF Loss                      338.5764
Policy Loss                  -820.83325
Q Predictions Mean           811.26013
Q Predictions Std            319.23022
Q Predictions Max            1228.756
Q Predictions Min            28.432516
V Predictions Mean           816.7013
V Predictions Std            309.85477
V Predictions Max            1196.1532
V Predictions Min            106.95497
Log Pis Mean                 0.0705123
Log Pis Std                  3.5994918
Log Pis Max                  25.379889
Log Pis Min                  -8.950703
Policy mu Mean               -0.0037961444
Policy mu Std                0.5961969
Policy mu Max                3.7860563
Policy mu Min                -3.6053324
Policy log std Mean          -1.0151339
Policy log std Std           0.2359282
Policy log std Max           -0.35711545
Policy log std Min           -2.0203762
Z mean eval                  1.0442896
Z variance eval              0.033058953
total_rewards                [ 378.37100212  944.174279    999.17839212 3213.44305158  684.58483088
   72.51001301  603.22171442 3345.85031713  956.19110149 3313.25613965]
total_rewards_mean           1451.078084140583
total_rewards_std            1233.9935117437997
total_rewards_max            3345.850317133366
total_rewards_min            72.51001300757778
Number of train steps total  464000
Number of env steps total    370797
Number of rollouts total     0
Train Time (s)               141.6773382802494
(Previous) Eval Time (s)     12.781843268312514
Sample Time (s)              6.528920614160597
Epoch Time (s)               160.9881021627225
Total Train Time (s)         19183.901787471958
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:40:20.585663 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #115 | Epoch Duration: 161.06996965408325
2020-01-11 13:40:20.585788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0454704
Z variance train             0.033035774
KL Divergence                21.396027
KL Loss                      2.1396027
QF Loss                      963.95044
VF Loss                      225.24586
Policy Loss                  -813.3948
Q Predictions Mean           800.2603
Q Predictions Std            333.2494
Q Predictions Max            1195.6041
Q Predictions Min            -15.766907
V Predictions Mean           815.8063
V Predictions Std            322.7096
V Predictions Max            1201.5968
V Predictions Min            11.40728
Log Pis Mean                 0.33205962
Log Pis Std                  4.3462234
Log Pis Max                  40.76696
Log Pis Min                  -6.420763
Policy mu Mean               -0.07857177
Policy mu Std                0.65163046
Policy mu Max                4.1485887
Policy mu Min                -5.110573
Policy log std Mean          -0.99122614
Policy log std Std           0.2431058
Policy log std Max           0.5428557
Policy log std Min           -2.0877612
Z mean eval                  1.1838945
Z variance eval              0.11544298
total_rewards                [1445.60035308   39.29605364  186.83197526 1949.20775481 2008.26616561
  682.17361656  106.36151959   33.08511209   43.52855991  841.1785322 ]
total_rewards_mean           733.5529642751753
total_rewards_std            759.2759311487102
total_rewards_max            2008.2661656085897
total_rewards_min            33.08511209022925
Number of train steps total  468000
Number of env steps total    374365
Number of rollouts total     0
Train Time (s)               146.26029290491715
(Previous) Eval Time (s)     7.909762565046549
Sample Time (s)              6.757122308481485
Epoch Time (s)               160.92717777844518
Total Train Time (s)         19345.036679753568
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:43:01.722412 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #116 | Epoch Duration: 161.13653349876404
2020-01-11 13:43:01.722543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1836476
Z variance train             0.11543697
KL Divergence                16.526268
KL Loss                      1.6526269
QF Loss                      739.63367
VF Loss                      197.33356
Policy Loss                  -806.0248
Q Predictions Mean           797.91345
Q Predictions Std            302.04163
Q Predictions Max            1134.0165
Q Predictions Min            0.45107245
V Predictions Mean           808.6334
V Predictions Std            292.07043
V Predictions Max            1146.9442
V Predictions Min            1.6439189
Log Pis Mean                 0.13778126
Log Pis Std                  3.5950212
Log Pis Max                  20.444538
Log Pis Min                  -7.1859617
Policy mu Mean               -0.036690447
Policy mu Std                0.6340593
Policy mu Max                4.841943
Policy mu Min                -3.0908892
Policy log std Mean          -1.0199001
Policy log std Std           0.21961606
Policy log std Max           -0.2550336
Policy log std Min           -2.096149
Z mean eval                  1.1245385
Z variance eval              0.018563803
total_rewards                [  90.87363243 1453.27185427  915.24731646  921.5523142   154.01014529
  166.38119978  234.86799941 1686.51649763   47.48567448   88.12179672]
total_rewards_mean           575.8328430661766
total_rewards_std            587.5612162812413
total_rewards_max            1686.516497625463
total_rewards_min            47.48567447743983
Number of train steps total  472000
Number of env steps total    378066
Number of rollouts total     0
Train Time (s)               146.6417863056995
(Previous) Eval Time (s)     7.572695892769843
Sample Time (s)              7.856334446929395
Epoch Time (s)               162.07081664539874
Total Train Time (s)         19507.19564145012
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:45:43.883471 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #117 | Epoch Duration: 162.16083240509033
2020-01-11 13:45:43.883597 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1161608
Z variance train             0.018682083
KL Divergence                21.170584
KL Loss                      2.1170585
QF Loss                      631.997
VF Loss                      100.81501
Policy Loss                  -820.82733
Q Predictions Mean           811.5981
Q Predictions Std            338.28787
Q Predictions Max            1223.0144
Q Predictions Min            89.52324
V Predictions Mean           821.6017
V Predictions Std            331.02716
V Predictions Max            1217.3214
V Predictions Min            236.9435
Log Pis Mean                 -0.36658764
Log Pis Std                  3.2789197
Log Pis Max                  20.478273
Log Pis Min                  -7.2418337
Policy mu Mean               -0.037219778
Policy mu Std                0.5633698
Policy mu Max                2.3155446
Policy mu Min                -3.43215
Policy log std Mean          -1.0098674
Policy log std Std           0.23458035
Policy log std Max           -0.36171085
Policy log std Min           -2.0146773
Z mean eval                  1.1269295
Z variance eval              0.045056604
total_rewards                [ 418.12697821  569.61335828 3509.86384287 2047.39513922  389.88038805
 2241.3259082  2615.76492054 2626.71590306  201.17810891 1677.30143501]
total_rewards_mean           1629.7165982334432
total_rewards_std            1105.5189970260021
total_rewards_max            3509.8638428677136
total_rewards_min            201.178108910236
Number of train steps total  476000
Number of env steps total    381133
Number of rollouts total     0
Train Time (s)               148.08551617199555
(Previous) Eval Time (s)     15.43709101807326
Sample Time (s)              8.425990176387131
Epoch Time (s)               171.94859736645594
Total Train Time (s)         19679.233782000374
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:48:35.923816 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #118 | Epoch Duration: 172.04010939598083
2020-01-11 13:48:35.924004 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1255352
Z variance train             0.044527154
KL Divergence                19.97147
KL Loss                      1.997147
QF Loss                      961.1246
VF Loss                      140.99274
Policy Loss                  -824.7287
Q Predictions Mean           816.0887
Q Predictions Std            323.89294
Q Predictions Max            1228.2504
Q Predictions Min            -9.066875
V Predictions Mean           830.28564
V Predictions Std            315.58185
V Predictions Max            1236.063
V Predictions Min            36.513317
Log Pis Mean                 -0.082919054
Log Pis Std                  2.9893496
Log Pis Max                  13.495417
Log Pis Min                  -8.093379
Policy mu Mean               -0.05219421
Policy mu Std                0.5883811
Policy mu Max                3.2934983
Policy mu Min                -2.9620202
Policy log std Mean          -1.0108323
Policy log std Std           0.23395935
Policy log std Max           -0.3945098
Policy log std Min           -2.0635436
Z mean eval                  1.1407721
Z variance eval              0.03402751
total_rewards                [3022.44133035 3315.6875213  1063.75965077 2841.36549823 3466.56074803
  225.52488901 3307.25621277 2780.87100139  720.65114016 3461.96743468]
total_rewards_mean           2420.6085426688114
total_rewards_std            1182.5425708307143
total_rewards_max            3466.5607480325634
total_rewards_min            225.52488901075733
Number of train steps total  480000
Number of env steps total    383581
Number of rollouts total     0
Train Time (s)               143.96217261906713
(Previous) Eval Time (s)     17.594236228149384
Sample Time (s)              7.128209902439266
Epoch Time (s)               168.68461874965578
Total Train Time (s)         19848.007953466382
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:51:24.700049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #119 | Epoch Duration: 168.7758994102478
2020-01-11 13:51:24.700238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1414484
Z variance train             0.033783328
KL Divergence                20.968521
KL Loss                      2.096852
QF Loss                      674.90845
VF Loss                      269.1487
Policy Loss                  -835.93414
Q Predictions Mean           827.09
Q Predictions Std            328.4201
Q Predictions Max            1223.7393
Q Predictions Min            -70.054184
V Predictions Mean           839.1009
V Predictions Std            316.07312
V Predictions Max            1213.3926
V Predictions Min            -9.112022
Log Pis Mean                 0.080501616
Log Pis Std                  3.5346432
Log Pis Max                  16.457699
Log Pis Min                  -9.18711
Policy mu Mean               -0.037563752
Policy mu Std                0.60551316
Policy mu Max                3.1944165
Policy mu Min                -3.0272055
Policy log std Mean          -1.0317193
Policy log std Std           0.23860542
Policy log std Max           -0.3922584
Policy log std Min           -2.154937
Z mean eval                  1.073251
Z variance eval              0.08129396
total_rewards                [ 948.75777529 1975.54616889 1159.23416239 1154.34027354  647.47727687
 1182.66854261   32.88483324  741.85757973 3154.61927747  908.25503491]
total_rewards_mean           1190.5640924917866
total_rewards_std            803.1647707301994
total_rewards_max            3154.6192774672254
total_rewards_min            32.884833240432414
Number of train steps total  484000
Number of env steps total    387606
Number of rollouts total     0
Train Time (s)               145.57640478527173
(Previous) Eval Time (s)     14.121134355664253
Sample Time (s)              7.623146479483694
Epoch Time (s)               167.32068562041968
Total Train Time (s)         20015.428012644872
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:54:12.123215 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #120 | Epoch Duration: 167.42281866073608
2020-01-11 13:54:12.123443 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0729069
Z variance train             0.08321177
KL Divergence                18.108816
KL Loss                      1.8108816
QF Loss                      622.85474
VF Loss                      125.369934
Policy Loss                  -813.2151
Q Predictions Mean           803.41187
Q Predictions Std            342.64877
Q Predictions Max            1248.558
Q Predictions Min            13.806763
V Predictions Mean           812.66315
V Predictions Std            336.6271
V Predictions Max            1233.1544
V Predictions Min            127.03731
Log Pis Mean                 -0.50808537
Log Pis Std                  2.9543962
Log Pis Max                  16.454388
Log Pis Min                  -6.6806297
Policy mu Mean               -0.02732036
Policy mu Std                0.55815727
Policy mu Max                2.9628725
Policy mu Min                -3.5620418
Policy log std Mean          -0.9801627
Policy log std Std           0.24365301
Policy log std Max           -0.361912
Policy log std Min           -2.057205
Z mean eval                  1.1151317
Z variance eval              0.07894797
total_rewards                [  95.05907767  304.36376553 1004.34782865  408.00152174  122.83969639
  324.18712049  552.55924388  237.70898025 1425.28607119  122.64061242]
total_rewards_mean           459.6993918204582
total_rewards_std            411.35304620137873
total_rewards_max            1425.2860711857527
total_rewards_min            95.05907766633435
Number of train steps total  488000
Number of env steps total    390362
Number of rollouts total     0
Train Time (s)               146.9989463458769
(Previous) Eval Time (s)     5.262980828993022
Sample Time (s)              7.287724058609456
Epoch Time (s)               159.54965123347938
Total Train Time (s)         20175.060307309963
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:56:51.755923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #121 | Epoch Duration: 159.63232851028442
2020-01-11 13:56:51.756039 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1164219
Z variance train             0.07937355
KL Divergence                19.895033
KL Loss                      1.9895033
QF Loss                      1739.0184
VF Loss                      817.15173
Policy Loss                  -867.585
Q Predictions Mean           855.7332
Q Predictions Std            307.49927
Q Predictions Max            1195.5583
Q Predictions Min            -46.832607
V Predictions Mean           871.5763
V Predictions Std            290.7815
V Predictions Max            1208.6183
V Predictions Min            230.05244
Log Pis Mean                 0.22975066
Log Pis Std                  3.5394566
Log Pis Max                  26.38594
Log Pis Min                  -6.684619
Policy mu Mean               -0.01918881
Policy mu Std                0.63364106
Policy mu Max                5.2851453
Policy mu Min                -3.029637
Policy log std Mean          -1.0065385
Policy log std Std           0.2314687
Policy log std Max           -0.27995956
Policy log std Min           -2.029803
Z mean eval                  1.0668194
Z variance eval              0.06783622
total_rewards                [1062.4289356  3110.21477301 2843.24413694  479.11089403 2609.98981695
 2415.3548893  3435.23203237 1709.81343258 2333.79040645 1597.98224855]
total_rewards_mean           2159.716156577548
total_rewards_std            885.5748970484575
total_rewards_max            3435.2320323683516
total_rewards_min            479.1108940342131
Number of train steps total  492000
Number of env steps total    394833
Number of rollouts total     0
Train Time (s)               142.38532737083733
(Previous) Eval Time (s)     15.179499710910022
Sample Time (s)              7.757077507209033
Epoch Time (s)               165.3219045889564
Total Train Time (s)         20340.472923115827
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:59:37.170297 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #122 | Epoch Duration: 165.4141561985016
2020-01-11 13:59:37.170443 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0687381
Z variance train             0.06789068
KL Divergence                19.962328
KL Loss                      1.9962329
QF Loss                      780.50134
VF Loss                      151.10512
Policy Loss                  -838.8378
Q Predictions Mean           832.03564
Q Predictions Std            299.65268
Q Predictions Max            1255.4753
Q Predictions Min            192.06326
V Predictions Mean           837.8924
V Predictions Std            296.25873
V Predictions Max            1254.7958
V Predictions Min            210.14857
Log Pis Mean                 -0.33246604
Log Pis Std                  2.8451211
Log Pis Max                  8.859657
Log Pis Min                  -9.632336
Policy mu Mean               -0.027677616
Policy mu Std                0.5703828
Policy mu Max                3.069685
Policy mu Min                -2.2959135
Policy log std Mean          -1.0018702
Policy log std Std           0.22564302
Policy log std Max           -0.37963527
Policy log std Min           -2.0936427
Z mean eval                  1.0758301
Z variance eval              0.013690069
total_rewards                [ 745.06422212  562.1530725   396.6985867  1676.47923939  723.64487368
  917.87486913  292.97391306  674.25227049 3139.11434179 1382.39964682]
total_rewards_mean           1051.065503566854
total_rewards_std            803.9512363226831
total_rewards_max            3139.114341790775
total_rewards_min            292.97391305509984
Number of train steps total  496000
Number of env steps total    397812
Number of rollouts total     0
Train Time (s)               141.68216640595347
(Previous) Eval Time (s)     13.908801851328462
Sample Time (s)              6.272847313899547
Epoch Time (s)               161.86381557118148
Total Train Time (s)         20502.4324790556
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:02:19.134277 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #123 | Epoch Duration: 161.96368312835693
2020-01-11 14:02:19.134549 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0776877
Z variance train             0.013558948
KL Divergence                21.948557
KL Loss                      2.1948557
QF Loss                      526.6697
VF Loss                      181.41837
Policy Loss                  -870.15265
Q Predictions Mean           860.02844
Q Predictions Std            314.50595
Q Predictions Max            1249.628
Q Predictions Min            54.064102
V Predictions Mean           861.9092
V Predictions Std            305.2905
V Predictions Max            1242.7592
V Predictions Min            140.40706
Log Pis Mean                 0.1633041
Log Pis Std                  3.2445288
Log Pis Max                  20.158995
Log Pis Min                  -6.945198
Policy mu Mean               -0.052530028
Policy mu Std                0.59556067
Policy mu Max                3.304717
Policy mu Min                -5.0930104
Policy log std Mean          -1.0092196
Policy log std Std           0.23429951
Policy log std Max           0.17273712
Policy log std Min           -2.1596394
Z mean eval                  1.1172683
Z variance eval              0.005452371
total_rewards                [ 199.23687495 2044.4564507  1030.8642635   400.50180825 2345.48077404
 1937.4339349   470.46960153   93.15398055  448.53792064 3368.1313813 ]
total_rewards_mean           1233.8266990371849
total_rewards_std            1060.6480093922505
total_rewards_max            3368.131381302079
total_rewards_min            93.153980552311
Number of train steps total  500000
Number of env steps total    401576
Number of rollouts total     0
Train Time (s)               141.56611986504868
(Previous) Eval Time (s)     10.903188199736178
Sample Time (s)              8.790943944826722
Epoch Time (s)               161.26025200961158
Total Train Time (s)         20663.78482319927
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:05:00.487284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #124 | Epoch Duration: 161.3525276184082
2020-01-11 14:05:00.487445 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1234288
Z variance train             0.0054776818
KL Divergence                23.82344
KL Loss                      2.382344
QF Loss                      592.87335
VF Loss                      185.36624
Policy Loss                  -815.0253
Q Predictions Mean           807.81744
Q Predictions Std            339.89758
Q Predictions Max            1226.7172
Q Predictions Min            141.98631
V Predictions Mean           811.1035
V Predictions Std            332.39633
V Predictions Max            1240.802
V Predictions Min            223.99103
Log Pis Mean                 -0.29569286
Log Pis Std                  3.5434873
Log Pis Max                  15.566323
Log Pis Min                  -11.048065
Policy mu Mean               -0.019165408
Policy mu Std                0.58340156
Policy mu Max                3.642837
Policy mu Min                -3.1660674
Policy log std Mean          -0.98768014
Policy log std Std           0.23030724
Policy log std Max           -0.39219725
Policy log std Min           -1.9991261
Z mean eval                  1.1286275
Z variance eval              0.03337378
total_rewards                [3389.50803439 3223.08325221 3251.76315809 3255.6466846  1579.38466108
 1116.04242847  100.22307189 3442.62974125 3385.95453816 1324.2836272 ]
total_rewards_mean           2406.8519197353803
total_rewards_std            1180.7215493444228
total_rewards_max            3442.6297412525537
total_rewards_min            100.22307189448901
Number of train steps total  504000
Number of env steps total    406760
Number of rollouts total     0
Train Time (s)               141.57846467290074
(Previous) Eval Time (s)     20.53754178620875
Sample Time (s)              7.892120137810707
Epoch Time (s)               170.0081265969202
Total Train Time (s)         20833.88947608741
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:07:50.593683 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #125 | Epoch Duration: 170.1061224937439
2020-01-11 14:07:50.593818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1343482
Z variance train             0.03309967
KL Divergence                20.82796
KL Loss                      2.0827959
QF Loss                      1293.2831
VF Loss                      315.43384
Policy Loss                  -794.3268
Q Predictions Mean           777.11505
Q Predictions Std            344.44034
Q Predictions Max            1243.9003
Q Predictions Min            -73.12148
V Predictions Mean           787.2961
V Predictions Std            331.43433
V Predictions Max            1237.9344
V Predictions Min            195.86707
Log Pis Mean                 0.091752306
Log Pis Std                  4.0602145
Log Pis Max                  24.249468
Log Pis Min                  -8.326549
Policy mu Mean               -0.030843586
Policy mu Std                0.62442404
Policy mu Max                4.030943
Policy mu Min                -3.6184187
Policy log std Mean          -1.017266
Policy log std Std           0.24892078
Policy log std Max           -0.25348228
Policy log std Min           -2.041908
Z mean eval                  1.0908227
Z variance eval              0.026469136
total_rewards                [2881.82594563  367.23496856  437.7637035  1113.76701859 2686.06139704
 1080.50095047  831.77489446  484.55502193  937.41036091  844.84128005]
total_rewards_mean           1166.5735541137647
total_rewards_std            846.4339261526014
total_rewards_max            2881.8259456258693
total_rewards_min            367.2349685635653
Number of train steps total  508000
Number of env steps total    410369
Number of rollouts total     0
Train Time (s)               146.25517910905182
(Previous) Eval Time (s)     11.88207471370697
Sample Time (s)              7.805329885799438
Epoch Time (s)               165.94258370855823
Total Train Time (s)         20999.92428031098
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:10:36.632901 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #126 | Epoch Duration: 166.0389473438263
2020-01-11 14:10:36.633176 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0813372
Z variance train             0.026165292
KL Divergence                19.6892
KL Loss                      1.96892
QF Loss                      1157.0641
VF Loss                      173.28865
Policy Loss                  -789.77264
Q Predictions Mean           783.16516
Q Predictions Std            328.70947
Q Predictions Max            1179.7234
Q Predictions Min            -38.91089
V Predictions Mean           790.4538
V Predictions Std            318.53275
V Predictions Max            1159.3179
V Predictions Min            -37.14457
Log Pis Mean                 -0.06526449
Log Pis Std                  3.5771663
Log Pis Max                  20.494984
Log Pis Min                  -7.79768
Policy mu Mean               0.013158861
Policy mu Std                0.59883004
Policy mu Max                4.5700884
Policy mu Min                -3.1050038
Policy log std Mean          -0.9998583
Policy log std Std           0.24548647
Policy log std Max           0.34089857
Policy log std Min           -2.6329975
Z mean eval                  1.1001133
Z variance eval              0.016725104
total_rewards                [2064.22298533  898.05903052 2811.0237179  2730.2760605   981.11036125
 3471.4722609  1392.4444691  1796.36980155  730.50913557  908.73957448]
total_rewards_mean           1778.4227397106292
total_rewards_std            912.9571910751017
total_rewards_max            3471.4722608963207
total_rewards_min            730.5091355706089
Number of train steps total  512000
Number of env steps total    413375
Number of rollouts total     0
Train Time (s)               145.3437726777047
(Previous) Eval Time (s)     14.281360452994704
Sample Time (s)              7.498569758143276
Epoch Time (s)               167.12370288884267
Total Train Time (s)         21167.1366983708
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:13:23.849153 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #127 | Epoch Duration: 167.21573114395142
2020-01-11 14:13:23.849458 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1040696
Z variance train             0.016855802
KL Divergence                21.470917
KL Loss                      2.1470916
QF Loss                      597.85693
VF Loss                      153.17017
Policy Loss                  -858.3332
Q Predictions Mean           848.6322
Q Predictions Std            347.30148
Q Predictions Max            1282.9957
Q Predictions Min            141.9191
V Predictions Mean           855.1798
V Predictions Std            340.4017
V Predictions Max            1278.3547
V Predictions Min            219.75023
Log Pis Mean                 -0.45116556
Log Pis Std                  3.7103148
Log Pis Max                  25.217896
Log Pis Min                  -10.852577
Policy mu Mean               -0.023640484
Policy mu Std                0.58197767
Policy mu Max                3.2036648
Policy mu Min                -4.715603
Policy log std Mean          -0.9739098
Policy log std Std           0.21859767
Policy log std Max           0.31138772
Policy log std Min           -2.225585
Z mean eval                  1.0820506
Z variance eval              0.025259316
total_rewards                [1245.69273832 1087.04855869  396.41342996  369.3050671   887.52492361
 1599.27448504 2414.90008269 1203.78380222  666.94594754 1576.7190237 ]
total_rewards_mean           1144.7608058870908
total_rewards_std            589.8524203038211
total_rewards_max            2414.900082692143
total_rewards_min            369.30506709680475
Number of train steps total  516000
Number of env steps total    416318
Number of rollouts total     0
Train Time (s)               146.88669124199077
(Previous) Eval Time (s)     10.444965403992683
Sample Time (s)              7.636857091449201
Epoch Time (s)               164.96851373743266
Total Train Time (s)         21332.236562591046
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:16:08.949937 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #128 | Epoch Duration: 165.10025215148926
2020-01-11 14:16:08.950142 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0776064
Z variance train             0.024712436
KL Divergence                19.517609
KL Loss                      1.9517609
QF Loss                      678.0153
VF Loss                      193.41063
Policy Loss                  -900.3369
Q Predictions Mean           891.86255
Q Predictions Std            319.9502
Q Predictions Max            1286.3334
Q Predictions Min            7.05492
V Predictions Mean           904.7825
V Predictions Std            313.1095
V Predictions Max            1292.741
V Predictions Min            49.306725
Log Pis Mean                 0.17039037
Log Pis Std                  3.5723462
Log Pis Max                  23.16174
Log Pis Min                  -7.651815
Policy mu Mean               -0.05691508
Policy mu Std                0.6162176
Policy mu Max                2.931805
Policy mu Min                -4.672957
Policy log std Mean          -1.009324
Policy log std Std           0.23739582
Policy log std Max           -0.4240585
Policy log std Min           -1.910285
Z mean eval                  1.0714653
Z variance eval              0.14678575
total_rewards                [2375.98563386 3756.06986483 3504.96890307 3260.60717511  677.53386435
 3236.47640574 3502.09975195 3554.58429978  631.86677526 3411.76366214]
total_rewards_mean           2791.1956336098206
total_rewards_std            1124.054930151527
total_rewards_max            3756.0698648322173
total_rewards_min            631.8667752589856
Number of train steps total  520000
Number of env steps total    420568
Number of rollouts total     0
Train Time (s)               146.40001259371638
(Previous) Eval Time (s)     17.767003450077027
Sample Time (s)              7.867765381932259
Epoch Time (s)               172.03478142572567
Total Train Time (s)         21504.381118422374
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:19:01.096352 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #129 | Epoch Duration: 172.14608216285706
2020-01-11 14:19:01.096488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0666239
Z variance train             0.15018626
KL Divergence                16.946447
KL Loss                      1.6946448
QF Loss                      679.66455
VF Loss                      171.99585
Policy Loss                  -835.7912
Q Predictions Mean           826.294
Q Predictions Std            338.62723
Q Predictions Max            1296.3553
Q Predictions Min            21.108036
V Predictions Mean           842.82263
V Predictions Std            333.77036
V Predictions Max            1312.9705
V Predictions Min            61.202763
Log Pis Mean                 0.06381159
Log Pis Std                  3.4712336
Log Pis Max                  20.024662
Log Pis Min                  -9.646436
Policy mu Mean               -0.047872446
Policy mu Std                0.584355
Policy mu Max                2.972582
Policy mu Min                -2.9875093
Policy log std Mean          -1.0387838
Policy log std Std           0.24858528
Policy log std Max           0.2701428
Policy log std Min           -2.2064247
Z mean eval                  1.0743665
Z variance eval              0.012171233
total_rewards                [ 629.0461543   779.72071841 1995.64588918  958.55563393  188.25165941
  471.48056725 3410.13607095 1726.90563395 1579.03817247 1391.96226017]
total_rewards_mean           1313.0742760021462
total_rewards_std            892.3753989047267
total_rewards_max            3410.1360709505775
total_rewards_min            188.25165941399098
Number of train steps total  524000
Number of env steps total    425308
Number of rollouts total     0
Train Time (s)               146.02981862379238
(Previous) Eval Time (s)     14.004479744005948
Sample Time (s)              6.561221217736602
Epoch Time (s)               166.59551958553493
Total Train Time (s)         21671.067384866998
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:21:47.784174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #130 | Epoch Duration: 166.68756866455078
2020-01-11 14:21:47.784383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.077776
Z variance train             0.012172719
KL Divergence                21.336037
KL Loss                      2.1336038
QF Loss                      1052.099
VF Loss                      275.60248
Policy Loss                  -857.43054
Q Predictions Mean           842.61414
Q Predictions Std            350.59988
Q Predictions Max            1287.0796
Q Predictions Min            -15.393713
V Predictions Mean           854.20215
V Predictions Std            336.51498
V Predictions Max            1273.8948
V Predictions Min            204.07817
Log Pis Mean                 -0.19452944
Log Pis Std                  3.6349907
Log Pis Max                  25.832031
Log Pis Min                  -7.9219065
Policy mu Mean               -0.061457943
Policy mu Std                0.6147943
Policy mu Max                3.9347124
Policy mu Min                -3.4646914
Policy log std Mean          -0.9988153
Policy log std Std           0.247062
Policy log std Max           -0.2500009
Policy log std Min           -2.3071997
Z mean eval                  1.013226
Z variance eval              0.025445823
total_rewards                [1223.05977836  256.74310707  453.84454223 3417.07628056 1815.81469069
  740.61606546 2760.21590017 3503.90980042 3106.43722673 3301.94035859]
total_rewards_mean           2057.9657750301267
total_rewards_std            1240.4265127743836
total_rewards_max            3503.909800416233
total_rewards_min            256.74310707293046
Number of train steps total  528000
Number of env steps total    428125
Number of rollouts total     0
Train Time (s)               145.46365906577557
(Previous) Eval Time (s)     14.382851014845073
Sample Time (s)              7.29324755910784
Epoch Time (s)               167.1397576397285
Total Train Time (s)         21838.30066230707
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:24:35.018819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #131 | Epoch Duration: 167.2342848777771
2020-01-11 14:24:35.018980 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0178199
Z variance train             0.025397757
KL Divergence                21.461376
KL Loss                      2.1461377
QF Loss                      1040.1155
VF Loss                      645.46173
Policy Loss                  -844.5999
Q Predictions Mean           828.7114
Q Predictions Std            360.9646
Q Predictions Max            1255.0575
Q Predictions Min            -117.84963
V Predictions Mean           844.8976
V Predictions Std            341.76526
V Predictions Max            1251.1912
V Predictions Min            40.148853
Log Pis Mean                 0.0019949228
Log Pis Std                  3.707959
Log Pis Max                  16.462597
Log Pis Min                  -7.5235815
Policy mu Mean               -0.030787708
Policy mu Std                0.59902877
Policy mu Max                3.6181064
Policy mu Min                -4.7618437
Policy log std Mean          -1.0059536
Policy log std Std           0.2497206
Policy log std Max           -0.104486644
Policy log std Min           -2.0820875
Z mean eval                  1.0702755
Z variance eval              0.030504659
total_rewards                [ 842.03888832 2987.81164528 1178.43959375 2098.85402494  347.90823359
  344.68871654 3548.14046372  326.60533887 1037.29713201 1261.6324185 ]
total_rewards_mean           1397.3416455514202
total_rewards_std            1072.7461589193335
total_rewards_max            3548.1404637207133
total_rewards_min            326.6053388688397
Number of train steps total  532000
Number of env steps total    432315
Number of rollouts total     0
Train Time (s)               145.03954164497554
(Previous) Eval Time (s)     13.731493039987981
Sample Time (s)              6.439945420715958
Epoch Time (s)               165.21098010567948
Total Train Time (s)         22003.727275791112
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:27:20.447448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #132 | Epoch Duration: 165.42831873893738
2020-01-11 14:27:20.447681 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0689325
Z variance train             0.030475568
KL Divergence                18.76462
KL Loss                      1.876462
QF Loss                      814.77747
VF Loss                      155.46883
Policy Loss                  -835.10895
Q Predictions Mean           825.67847
Q Predictions Std            356.61603
Q Predictions Max            1308.6227
Q Predictions Min            4.113279
V Predictions Mean           837.5078
V Predictions Std            349.8532
V Predictions Max            1312.135
V Predictions Min            182.50925
Log Pis Mean                 -0.1862099
Log Pis Std                  3.5536644
Log Pis Max                  20.385132
Log Pis Min                  -10.733339
Policy mu Mean               -0.019230228
Policy mu Std                0.61623514
Policy mu Max                4.956356
Policy mu Min                -2.8420334
Policy log std Mean          -0.9939436
Policy log std Std           0.24151841
Policy log std Max           -0.28712928
Policy log std Min           -1.956994
Z mean eval                  1.0531256
Z variance eval              0.022417242
total_rewards                [ 535.47862878 2959.65692523 3280.47845302 1834.03594634  107.49090697
 3699.4898894    54.34638754 2207.75670467 1409.97495164  923.14756278]
total_rewards_mean           1701.1856356371154
total_rewards_std            1250.8541586360154
total_rewards_max            3699.489889403752
total_rewards_min            54.34638753924109
Number of train steps total  536000
Number of env steps total    435307
Number of rollouts total     0
Train Time (s)               143.4565417780541
(Previous) Eval Time (s)     15.350889596156776
Sample Time (s)              7.741186283994466
Epoch Time (s)               166.54861765820533
Total Train Time (s)         22170.37530200137
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:30:07.097963 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #133 | Epoch Duration: 166.65011024475098
2020-01-11 14:30:07.098152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0528226
Z variance train             0.022428483
KL Divergence                19.708643
KL Loss                      1.9708643
QF Loss                      1045.9844
VF Loss                      116.39548
Policy Loss                  -899.7057
Q Predictions Mean           891.1309
Q Predictions Std            328.81146
Q Predictions Max            1280.3004
Q Predictions Min            -1.6600126
V Predictions Mean           895.4386
V Predictions Std            320.52908
V Predictions Max            1282.9127
V Predictions Min            20.396147
Log Pis Mean                 0.38298365
Log Pis Std                  2.8554902
Log Pis Max                  11.944549
Log Pis Min                  -6.701493
Policy mu Mean               -0.04820407
Policy mu Std                0.61723363
Policy mu Max                3.2609882
Policy mu Min                -2.4363813
Policy log std Mean          -1.01342
Policy log std Std           0.22432408
Policy log std Max           -0.3265152
Policy log std Min           -2.059103
Z mean eval                  1.0301087
Z variance eval              0.010641577
total_rewards                [1048.5770284  3682.84311209 2184.95965713  251.97046206  899.75629592
 1918.15022463  296.77080408 1099.34618073 3196.90616487 3399.59864459]
total_rewards_mean           1797.8878574503385
total_rewards_std            1214.0574159780083
total_rewards_max            3682.8431120873365
total_rewards_min            251.97046206227645
Number of train steps total  540000
Number of env steps total    439757
Number of rollouts total     0
Train Time (s)               145.47745918110013
(Previous) Eval Time (s)     14.86198346503079
Sample Time (s)              7.451023829635233
Epoch Time (s)               167.79046647576615
Total Train Time (s)         22338.2648482793
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:32:54.991829 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #134 | Epoch Duration: 167.89350986480713
2020-01-11 14:32:54.992086 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.030499
Z variance train             0.010638076
KL Divergence                21.582361
KL Loss                      2.1582363
QF Loss                      2003.5634
VF Loss                      669.4914
Policy Loss                  -845.4728
Q Predictions Mean           833.4863
Q Predictions Std            363.19656
Q Predictions Max            1282.897
Q Predictions Min            -74.66382
V Predictions Mean           840.946
V Predictions Std            352.69507
V Predictions Max            1270.3146
V Predictions Min            3.902381
Log Pis Mean                 -0.041905187
Log Pis Std                  3.714703
Log Pis Max                  19.30016
Log Pis Min                  -10.081629
Policy mu Mean               -0.009732099
Policy mu Std                0.62039685
Policy mu Max                4.4262223
Policy mu Min                -3.504319
Policy log std Mean          -1.0095801
Policy log std Std           0.23969087
Policy log std Max           -0.42648226
Policy log std Min           -2.0542717
Z mean eval                  1.045503
Z variance eval              0.036674023
total_rewards                [ 439.89261976  769.38130337 1182.81304503 1758.64410708 3555.66708862
 2196.93750831 3251.85559898 3455.20434256 3544.23395511 2072.58007925]
total_rewards_mean           2222.7209648073
total_rewards_std            1127.4720079576928
total_rewards_max            3555.667088623336
total_rewards_min            439.89261975980287
Number of train steps total  544000
Number of env steps total    444365
Number of rollouts total     0
Train Time (s)               143.71019597165287
(Previous) Eval Time (s)     14.271753340028226
Sample Time (s)              8.507700911257416
Epoch Time (s)               166.4896502229385
Total Train Time (s)         22504.842586792074
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:35:41.570680 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #135 | Epoch Duration: 166.5783941745758
2020-01-11 14:35:41.570874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #135 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0466923
Z variance train             0.03673465
KL Divergence                19.339718
KL Loss                      1.9339718
QF Loss                      761.0357
VF Loss                      115.14361
Policy Loss                  -846.7952
Q Predictions Mean           835.1369
Q Predictions Std            371.62543
Q Predictions Max            1289.7104
Q Predictions Min            -28.325817
V Predictions Mean           841.2892
V Predictions Std            360.29977
V Predictions Max            1261.0718
V Predictions Min            196.98982
Log Pis Mean                 0.031636655
Log Pis Std                  3.5761387
Log Pis Max                  22.015125
Log Pis Min                  -6.3432903
Policy mu Mean               -0.017054237
Policy mu Std                0.6066955
Policy mu Max                4.575958
Policy mu Min                -3.1104321
Policy log std Mean          -0.9918092
Policy log std Std           0.24000515
Policy log std Max           -0.043813884
Policy log std Min           -2.1424356
Z mean eval                  1.0396788
Z variance eval              0.020251231
total_rewards                [3226.09215629  406.35222666 2124.4871909  3280.48511378 3286.4341711
  639.08157124 3345.6098118  1934.49059371 1875.06493188 2651.06454399]
total_rewards_mean           2276.9162311352184
total_rewards_std            1034.059539086125
total_rewards_max            3345.60981180426
total_rewards_min            406.352226664304
Number of train steps total  548000
Number of env steps total    448103
Number of rollouts total     0
Train Time (s)               145.97623513592407
(Previous) Eval Time (s)     16.14906639698893
Sample Time (s)              6.975452768616378
Epoch Time (s)               169.10075430152938
Total Train Time (s)         22674.036431501154
Epoch                        136
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:38:30.766924 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #136 | Epoch Duration: 169.1959090232849
2020-01-11 14:38:30.767106 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0387517
Z variance train             0.020154072
KL Divergence                19.635569
KL Loss                      1.9635569
QF Loss                      1549.979
VF Loss                      117.59664
Policy Loss                  -857.42303
Q Predictions Mean           852.06995
Q Predictions Std            342.69305
Q Predictions Max            1296.696
Q Predictions Min            206.23958
V Predictions Mean           857.65125
V Predictions Std            339.97467
V Predictions Max            1290.546
V Predictions Min            224.94983
Log Pis Mean                 -0.35173613
Log Pis Std                  3.2960837
Log Pis Max                  15.696588
Log Pis Min                  -7.4327927
Policy mu Mean               -0.041336786
Policy mu Std                0.5768055
Policy mu Max                4.3824368
Policy mu Min                -2.8190923
Policy log std Mean          -1.0045812
Policy log std Std           0.23421967
Policy log std Max           -0.4603899
Policy log std Min           -1.9601157
Z mean eval                  1.1293623
Z variance eval              0.06525401
total_rewards                [1124.22398093 3546.78967018  533.31151912 3568.25233126    7.80417141
 2388.52006977  552.01823812 3441.93800541 3647.76881603 1016.8016046 ]
total_rewards_mean           1982.7428406841525
total_rewards_std            1405.1549349581405
total_rewards_max            3647.768816030575
total_rewards_min            7.804171414377607
Number of train steps total  552000
Number of env steps total    450815
Number of rollouts total     0
Train Time (s)               146.84205909911543
(Previous) Eval Time (s)     13.463275474961847
Sample Time (s)              7.509425484575331
Epoch Time (s)               167.8147600586526
Total Train Time (s)         22841.935249185655
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:41:18.667990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #137 | Epoch Duration: 167.90074706077576
2020-01-11 14:41:18.668174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1337483
Z variance train             0.06545262
KL Divergence                19.123844
KL Loss                      1.9123844
QF Loss                      950.26825
VF Loss                      169.93199
Policy Loss                  -845.72925
Q Predictions Mean           837.8624
Q Predictions Std            349.9945
Q Predictions Max            1273.5984
Q Predictions Min            35.546993
V Predictions Mean           842.40137
V Predictions Std            343.99197
V Predictions Max            1270.3846
V Predictions Min            167.76227
Log Pis Mean                 0.11469552
Log Pis Std                  3.8081312
Log Pis Max                  25.340189
Log Pis Min                  -6.635731
Policy mu Mean               -0.022262178
Policy mu Std                0.60143405
Policy mu Max                5.7914934
Policy mu Min                -5.3103747
Policy log std Mean          -1.0140114
Policy log std Std           0.2428866
Policy log std Max           -0.26888776
Policy log std Min           -2.3043423
Z mean eval                  1.1793628
Z variance eval              0.0076940632
total_rewards                [3406.98614955 1819.19996869 3467.48534817 1404.43144902 3598.07564974
 2138.07697109 3530.63803584 3472.60801556 3638.37602505  873.29363962]
total_rewards_mean           2734.9171252345905
total_rewards_std            1007.8473808666951
total_rewards_max            3638.3760250507476
total_rewards_min            873.2936396233317
Number of train steps total  556000
Number of env steps total    454141
Number of rollouts total     0
Train Time (s)               144.44478339422494
(Previous) Eval Time (s)     20.55428234813735
Sample Time (s)              7.569288549479097
Epoch Time (s)               172.5683542918414
Total Train Time (s)         23014.598311145324
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:44:11.335662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #138 | Epoch Duration: 172.66730093955994
2020-01-11 14:44:11.335986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1786995
Z variance train             0.0077058515
KL Divergence                22.32508
KL Loss                      2.2325082
QF Loss                      548.3234
VF Loss                      163.52454
Policy Loss                  -844.7735
Q Predictions Mean           839.4769
Q Predictions Std            363.40192
Q Predictions Max            1305.862
Q Predictions Min            -17.110037
V Predictions Mean           850.4796
V Predictions Std            358.91223
V Predictions Max            1308.5754
V Predictions Min            118.9709
Log Pis Mean                 0.19564341
Log Pis Std                  3.3361557
Log Pis Max                  15.66604
Log Pis Min                  -7.0186396
Policy mu Mean               -0.045036845
Policy mu Std                0.59029955
Policy mu Max                2.8499224
Policy mu Min                -2.519345
Policy log std Mean          -1.0114663
Policy log std Std           0.25519297
Policy log std Max           -0.02518922
Policy log std Min           -2.164647
Z mean eval                  1.0949425
Z variance eval              0.0110892635
total_rewards                [3540.42281578 1409.25905414 1553.36969799 3364.64665053 3290.39426826
 1104.76116469 2403.52581075 3563.03681034 1134.1935802  3534.12489681]
total_rewards_mean           2489.773474947499
total_rewards_std            1027.6421021991173
total_rewards_max            3563.036810337732
total_rewards_min            1104.761164687356
Number of train steps total  560000
Number of env steps total    457065
Number of rollouts total     0
Train Time (s)               146.04261909564957
(Previous) Eval Time (s)     18.91904537891969
Sample Time (s)              7.388299082405865
Epoch Time (s)               172.34996355697513
Total Train Time (s)         23187.04237287212
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:47:03.781534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #139 | Epoch Duration: 172.44530582427979
2020-01-11 14:47:03.781731 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0915962
Z variance train             0.011086391
KL Divergence                21.532993
KL Loss                      2.1532993
QF Loss                      773.66235
VF Loss                      109.57628
Policy Loss                  -882.66125
Q Predictions Mean           871.17065
Q Predictions Std            354.17102
Q Predictions Max            1323.8813
Q Predictions Min            199.37633
V Predictions Mean           884.26825
V Predictions Std            348.74524
V Predictions Max            1331.6399
V Predictions Min            219.66676
Log Pis Mean                 -0.10682809
Log Pis Std                  3.0977142
Log Pis Max                  14.804731
Log Pis Min                  -8.497807
Policy mu Mean               -0.039557673
Policy mu Std                0.5915027
Policy mu Max                3.8208652
Policy mu Min                -2.3051085
Policy log std Mean          -0.99523294
Policy log std Std           0.23744753
Policy log std Max           -0.24658805
Policy log std Min           -2.0389025
Z mean eval                  1.0229295
Z variance eval              0.015300326
total_rewards                [ 623.70000321 3338.30735041 1162.88506956 1503.28254095 3253.82276372
 1892.17452199 2335.59223703 3277.93332311 3420.68067025  897.81179332]
total_rewards_mean           2170.619027354733
total_rewards_std            1044.2334679298478
total_rewards_max            3420.680670251362
total_rewards_min            623.7000032078491
Number of train steps total  564000
Number of env steps total    463285
Number of rollouts total     0
Train Time (s)               147.22620432591066
(Previous) Eval Time (s)     17.131430144887418
Sample Time (s)              7.206840645056218
Epoch Time (s)               171.5644751158543
Total Train Time (s)         23358.69574013725
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:49:55.437239 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #140 | Epoch Duration: 171.65535688400269
2020-01-11 14:49:55.437418 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.020416
Z variance train             0.015197118
KL Divergence                22.026173
KL Loss                      2.2026174
QF Loss                      942.2475
VF Loss                      255.50883
Policy Loss                  -918.55536
Q Predictions Mean           911.7191
Q Predictions Std            339.45096
Q Predictions Max            1293.9685
Q Predictions Min            22.371305
V Predictions Mean           926.9483
V Predictions Std            332.5457
V Predictions Max            1299.1873
V Predictions Min            227.90984
Log Pis Mean                 0.23393166
Log Pis Std                  3.1036127
Log Pis Max                  13.935437
Log Pis Min                  -8.155075
Policy mu Mean               -0.028493125
Policy mu Std                0.6018545
Policy mu Max                3.2468712
Policy mu Min                -2.6534007
Policy log std Mean          -1.0380328
Policy log std Std           0.2484879
Policy log std Max           -0.46225977
Policy log std Min           -2.1458182
Z mean eval                  1.0729876
Z variance eval              0.02330907
total_rewards                [3542.9610627    46.07100881 3442.38601837  539.31710333 1607.93533671
 2883.76388449 3771.12353071 1809.80828989  122.97023499  269.03743968]
total_rewards_mean           1803.5373909680761
total_rewards_std            1437.147890860637
total_rewards_max            3771.123530707464
total_rewards_min            46.07100881316654
Number of train steps total  568000
Number of env steps total    468865
Number of rollouts total     0
Train Time (s)               147.08519169455394
(Previous) Eval Time (s)     16.417268407996744
Sample Time (s)              7.471918334718794
Epoch Time (s)               170.97437843726948
Total Train Time (s)         23529.760884676594
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:52:46.505072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #141 | Epoch Duration: 171.06751346588135
2020-01-11 14:52:46.505276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0766213
Z variance train             0.02329649
KL Divergence                19.97171
KL Loss                      1.997171
QF Loss                      531.7191
VF Loss                      234.7017
Policy Loss                  -920.1173
Q Predictions Mean           905.4232
Q Predictions Std            376.57864
Q Predictions Max            1366.9839
Q Predictions Min            -29.718609
V Predictions Mean           916.1344
V Predictions Std            360.9229
V Predictions Max            1376.3794
V Predictions Min            17.807753
Log Pis Mean                 0.07356371
Log Pis Std                  4.140609
Log Pis Max                  30.234514
Log Pis Min                  -11.847918
Policy mu Mean               -0.027035631
Policy mu Std                0.6323318
Policy mu Max                4.3004665
Policy mu Min                -3.7011538
Policy log std Mean          -1.0113244
Policy log std Std           0.2492266
Policy log std Max           -0.3340072
Policy log std Min           -2.5228887
Z mean eval                  1.0645367
Z variance eval              0.021532368
total_rewards                [ 528.48561987  170.51972471 3582.812161   3533.14176619 1119.84929267
 3522.40486944 2438.90053535 2339.90592453 3716.85322656  109.56094645]
total_rewards_mean           2106.2434066777378
total_rewards_std            1420.4643759905823
total_rewards_max            3716.85322656477
total_rewards_min            109.56094644693383
Number of train steps total  572000
Number of env steps total    474594
Number of rollouts total     0
Train Time (s)               145.92203581286594
(Previous) Eval Time (s)     12.89055938506499
Sample Time (s)              7.606507691089064
Epoch Time (s)               166.41910288902
Total Train Time (s)         23696.26901618531
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:55:33.014968 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #142 | Epoch Duration: 166.50953793525696
2020-01-11 14:55:33.015150 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0673087
Z variance train             0.021616958
KL Divergence                20.872726
KL Loss                      2.0872726
QF Loss                      851.0774
VF Loss                      193.68082
Policy Loss                  -902.2844
Q Predictions Mean           898.33997
Q Predictions Std            354.7321
Q Predictions Max            1332.304
Q Predictions Min            212.9351
V Predictions Mean           903.4171
V Predictions Std            350.21072
V Predictions Max            1335.531
V Predictions Min            223.3012
Log Pis Mean                 0.21920037
Log Pis Std                  3.424659
Log Pis Max                  16.665821
Log Pis Min                  -9.987498
Policy mu Mean               -0.06348976
Policy mu Std                0.6141742
Policy mu Max                2.5657318
Policy mu Min                -3.734281
Policy log std Mean          -1.0220225
Policy log std Std           0.25726774
Policy log std Max           -0.3863293
Policy log std Min           -2.138818
Z mean eval                  1.0236701
Z variance eval              0.02859568
total_rewards                [  59.59927638 1411.16031819 1242.71485904 2375.48292211 3348.99825824
  635.8865683  3610.09670874 1978.84184638   81.45745149 3627.52508384]
total_rewards_mean           1837.1763292695352
total_rewards_std            1310.1276317324318
total_rewards_max            3627.525083835126
total_rewards_min            59.599276377047886
Number of train steps total  576000
Number of env steps total    477971
Number of rollouts total     0
Train Time (s)               147.35583726596087
(Previous) Eval Time (s)     14.299574497155845
Sample Time (s)              7.255684988107532
Epoch Time (s)               168.91109675122425
Total Train Time (s)         23865.265062215272
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 14:58:22.011793 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #143 | Epoch Duration: 168.99652314186096
2020-01-11 14:58:22.011925 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0223148
Z variance train             0.02841645
KL Divergence                19.424635
KL Loss                      1.9424635
QF Loss                      921.811
VF Loss                      170.48433
Policy Loss                  -866.2349
Q Predictions Mean           854.28436
Q Predictions Std            388.78653
Q Predictions Max            1334.0956
Q Predictions Min            -28.894886
V Predictions Mean           860.0853
V Predictions Std            378.65298
V Predictions Max            1325.7
V Predictions Min            -68.592224
Log Pis Mean                 0.014398254
Log Pis Std                  4.1017284
Log Pis Max                  22.636375
Log Pis Min                  -10.604227
Policy mu Mean               -0.039769858
Policy mu Std                0.6040338
Policy mu Max                3.7434342
Policy mu Min                -3.4755104
Policy log std Mean          -0.9958632
Policy log std Std           0.2558723
Policy log std Max           -0.25759363
Policy log std Min           -2.3097882
Z mean eval                  1.114846
Z variance eval              0.032235987
total_rewards                [3443.1775713   908.93425045 2696.30679473 1327.89253434 3325.76743524
 2446.95845851 3200.18995005 1400.33257112  942.64193131 3659.93504925]
total_rewards_mean           2335.213654630469
total_rewards_std            1035.2272300322572
total_rewards_max            3659.9350492490084
total_rewards_min            908.9342504519991
Number of train steps total  580000
Number of env steps total    482143
Number of rollouts total     0
Train Time (s)               145.59355967864394
(Previous) Eval Time (s)     16.29334145085886
Sample Time (s)              6.2330794907175004
Epoch Time (s)               168.1199806202203
Total Train Time (s)         24033.472576396074
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:01:10.221260 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #144 | Epoch Duration: 168.209223985672
2020-01-11 15:01:10.221379 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1163014
Z variance train             0.032209475
KL Divergence                18.854834
KL Loss                      1.8854834
QF Loss                      614.0218
VF Loss                      165.19974
Policy Loss                  -913.0286
Q Predictions Mean           907.8779
Q Predictions Std            333.33508
Q Predictions Max            1322.2578
Q Predictions Min            187.54161
V Predictions Mean           917.39514
V Predictions Std            329.3419
V Predictions Max            1318.7416
V Predictions Min            213.41771
Log Pis Mean                 -0.16911964
Log Pis Std                  2.8827767
Log Pis Max                  10.809265
Log Pis Min                  -9.817608
Policy mu Mean               0.01824072
Policy mu Std                0.5756827
Policy mu Max                2.8573537
Policy mu Min                -3.1634085
Policy log std Mean          -1.0059651
Policy log std Std           0.23122497
Policy log std Max           -0.16378051
Policy log std Min           -2.135631
Z mean eval                  1.1335471
Z variance eval              0.061374962
total_rewards                [1207.3225807   596.63397337   62.77522773 3329.26070032 1060.90609845
  157.10951847 2057.0781502   553.17338915   11.58393586 3917.93802143]
total_rewards_mean           1295.378159568469
total_rewards_std            1309.9473531971908
total_rewards_max            3917.9380214312423
total_rewards_min            11.583935859708259
Number of train steps total  584000
Number of env steps total    487508
Number of rollouts total     0
Train Time (s)               145.791696599219
(Previous) Eval Time (s)     12.805953160859644
Sample Time (s)              7.157274698838592
Epoch Time (s)               165.75492445891723
Total Train Time (s)         24199.31601434434
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:03:56.067988 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #145 | Epoch Duration: 165.84650468826294
2020-01-11 15:03:56.068163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1261622
Z variance train             0.06139929
KL Divergence                18.848808
KL Loss                      1.8848809
QF Loss                      948.1912
VF Loss                      81.424965
Policy Loss                  -885.4436
Q Predictions Mean           877.37305
Q Predictions Std            334.67123
Q Predictions Max            1284.8221
Q Predictions Min            182.61646
V Predictions Mean           886.927
V Predictions Std            326.39587
V Predictions Max            1271.8589
V Predictions Min            183.0543
Log Pis Mean                 0.37162316
Log Pis Std                  3.226595
Log Pis Max                  14.137708
Log Pis Min                  -7.0853524
Policy mu Mean               -0.041960247
Policy mu Std                0.59419614
Policy mu Max                2.3274992
Policy mu Min                -2.7791414
Policy log std Mean          -1.034875
Policy log std Std           0.24501291
Policy log std Max           -0.52664816
Policy log std Min           -2.17283
Z mean eval                  1.0243076
Z variance eval              0.059867233
total_rewards                [  91.56281817  776.1990163  1120.39330692  489.7072205  3420.78277055
 1762.32824882 1168.76236315    7.44317779 1264.68991838 1486.86363971]
total_rewards_mean           1158.8732480287997
total_rewards_std            930.586454428614
total_rewards_max            3420.782770553958
total_rewards_min            7.443177793458203
Number of train steps total  588000
Number of env steps total    493415
Number of rollouts total     0
Train Time (s)               146.73831298714504
(Previous) Eval Time (s)     17.30222067516297
Sample Time (s)              7.871552898082882
Epoch Time (s)               171.9120865603909
Total Train Time (s)         24371.34729385795
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:06:48.099611 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #146 | Epoch Duration: 172.03132486343384
2020-01-11 15:06:48.099741 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0266072
Z variance train             0.060331147
KL Divergence                16.593987
KL Loss                      1.6593987
QF Loss                      701.2877
VF Loss                      229.33794
Policy Loss                  -931.02765
Q Predictions Mean           925.3356
Q Predictions Std            359.12607
Q Predictions Max            1347.2742
Q Predictions Min            23.496582
V Predictions Mean           930.81555
V Predictions Std            356.25433
V Predictions Max            1336.1011
V Predictions Min            -28.190357
Log Pis Mean                 0.3259006
Log Pis Std                  4.099013
Log Pis Max                  38.114826
Log Pis Min                  -7.653473
Policy mu Mean               -0.019362053
Policy mu Std                0.648179
Policy mu Max                5.735602
Policy mu Min                -3.2861614
Policy log std Mean          -1.0321982
Policy log std Std           0.24108183
Policy log std Max           -0.4908539
Policy log std Min           -2.178009
Z mean eval                  1.0614374
Z variance eval              0.03115815
total_rewards                [ 741.68450713  971.93186893 2837.68746532  906.26940308 2823.33167123
 2056.32692463  816.88007649 1284.44269554  423.50094641 1876.23175963]
total_rewards_mean           1473.8287318389112
total_rewards_std            828.4441714135037
total_rewards_max            2837.6874653226814
total_rewards_min            423.5009464149108
Number of train steps total  592000
Number of env steps total    498523
Number of rollouts total     0
Train Time (s)               147.71934974798933
(Previous) Eval Time (s)     10.79808967281133
Sample Time (s)              8.283137963619083
Epoch Time (s)               166.80057738441974
Total Train Time (s)         24538.24481628323
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:09:34.999018 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #147 | Epoch Duration: 166.89918398857117
2020-01-11 15:09:34.999146 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609343
Z variance train             0.031179596
KL Divergence                19.945595
KL Loss                      1.9945595
QF Loss                      1040.3213
VF Loss                      156.81163
Policy Loss                  -903.41266
Q Predictions Mean           898.3314
Q Predictions Std            374.79593
Q Predictions Max            1333.6637
Q Predictions Min            119.05299
V Predictions Mean           905.51184
V Predictions Std            372.26843
V Predictions Max            1311.1111
V Predictions Min            166.11989
Log Pis Mean                 -0.2869323
Log Pis Std                  2.8389924
Log Pis Max                  15.827632
Log Pis Min                  -6.483878
Policy mu Mean               -0.0677232
Policy mu Std                0.56261575
Policy mu Max                2.6376057
Policy mu Min                -3.074016
Policy log std Mean          -0.9936234
Policy log std Std           0.2383247
Policy log std Max           -0.25464898
Policy log std Min           -2.127771
Z mean eval                  1.0688426
Z variance eval              0.025392164
total_rewards                [1091.38873245 1600.30552062 3610.0465056   536.0041427   360.44408532
 3561.1779549  1829.22973208 1445.78142584 3333.04974586 3492.46383317]
total_rewards_mean           2085.9891678547597
total_rewards_std            1229.3548388351894
total_rewards_max            3610.0465055980553
total_rewards_min            360.44408532288617
Number of train steps total  596000
Number of env steps total    503027
Number of rollouts total     0
Train Time (s)               146.8357804310508
(Previous) Eval Time (s)     16.20667563378811
Sample Time (s)              7.849516668356955
Epoch Time (s)               170.89197273319587
Total Train Time (s)         24709.221241590567
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:12:25.976913 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #148 | Epoch Duration: 170.9776737689972
2020-01-11 15:12:25.977043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0628035
Z variance train             0.024990777
KL Divergence                20.833675
KL Loss                      2.0833676
QF Loss                      664.7117
VF Loss                      658.1681
Policy Loss                  -904.7617
Q Predictions Mean           894.08105
Q Predictions Std            380.8881
Q Predictions Max            1380.8807
Q Predictions Min            -28.05972
V Predictions Mean           904.7949
V Predictions Std            370.3574
V Predictions Max            1384.4958
V Predictions Min            -6.8637953
Log Pis Mean                 0.33998352
Log Pis Std                  3.9021397
Log Pis Max                  18.319302
Log Pis Min                  -7.0374517
Policy mu Mean               -0.022792464
Policy mu Std                0.61053437
Policy mu Max                3.2719455
Policy mu Min                -2.6294837
Policy log std Mean          -1.0433834
Policy log std Std           0.26937628
Policy log std Max           -0.24249423
Policy log std Min           -2.6774783
Z mean eval                  1.0612476
Z variance eval              0.018575322
total_rewards                [3513.8625909  2907.33743385  404.79330319 2449.02871765 3518.11129672
 2390.80143839  696.11873385  979.66073749 1899.35381414  115.82103318]
total_rewards_mean           1887.4889099357988
total_rewards_std            1203.8941472559256
total_rewards_max            3518.1112967234053
total_rewards_min            115.8210331825433
Number of train steps total  600000
Number of env steps total    505753
Number of rollouts total     0
Train Time (s)               146.0458785877563
(Previous) Eval Time (s)     12.023624591063708
Sample Time (s)              7.162729162722826
Epoch Time (s)               165.23223234154284
Total Train Time (s)         24874.53467641212
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:15:11.291866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #149 | Epoch Duration: 165.3147304058075
2020-01-11 15:15:11.291990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0555604
Z variance train             0.018659702
KL Divergence                19.603466
KL Loss                      1.9603466
QF Loss                      679.1388
VF Loss                      151.7841
Policy Loss                  -920.84076
Q Predictions Mean           906.9329
Q Predictions Std            380.45358
Q Predictions Max            1371.3606
Q Predictions Min            -127.322685
V Predictions Mean           917.6101
V Predictions Std            361.07928
V Predictions Max            1355.1215
V Predictions Min            -26.444483
Log Pis Mean                 0.5037019
Log Pis Std                  4.131531
Log Pis Max                  25.713167
Log Pis Min                  -8.972452
Policy mu Mean               -0.032438375
Policy mu Std                0.6712042
Policy mu Max                3.4312274
Policy mu Min                -4.7990313
Policy log std Mean          -1.0410488
Policy log std Std           0.2605232
Policy log std Max           -0.389957
Policy log std Min           -2.5845802
Z mean eval                  1.1301167
Z variance eval              0.01581174
total_rewards                [3295.7819906  3665.62754907 2387.94943571 1879.91747487   21.02856414
 2693.00179724  140.76886489  336.78442293 3586.42456875 2961.50145213]
total_rewards_mean           2096.8786120316468
total_rewards_std            1363.2780303901036
total_rewards_max            3665.627549068111
total_rewards_min            21.028564140949403
Number of train steps total  604000
Number of env steps total    511639
Number of rollouts total     0
Train Time (s)               146.1863347250037
(Previous) Eval Time (s)     16.595068603754044
Sample Time (s)              6.8234041896648705
Epoch Time (s)               169.6048075184226
Total Train Time (s)         25044.237795569003
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:18:00.998970 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #150 | Epoch Duration: 169.7068748474121
2020-01-11 15:18:00.999152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1282122
Z variance train             0.015732486
KL Divergence                20.22991
KL Loss                      2.022991
QF Loss                      776.0686
VF Loss                      150.41016
Policy Loss                  -912.5224
Q Predictions Mean           901.62024
Q Predictions Std            381.6774
Q Predictions Max            1410.3457
Q Predictions Min            0.60588324
V Predictions Mean           914.79266
V Predictions Std            374.99405
V Predictions Max            1405.2126
V Predictions Min            43.96732
Log Pis Mean                 0.24088518
Log Pis Std                  3.7708716
Log Pis Max                  21.157673
Log Pis Min                  -7.088807
Policy mu Mean               -0.076988325
Policy mu Std                0.6552569
Policy mu Max                2.6761756
Policy mu Min                -3.1246753
Policy log std Mean          -1.0039825
Policy log std Std           0.2542333
Policy log std Max           -0.3150134
Policy log std Min           -2.3362846
Z mean eval                  1.0263187
Z variance eval              0.04770874
total_rewards                [ 708.02489424  308.4852806  2251.33086871 1354.68328092 1960.58753739
 1739.60619421 1918.54824189 3656.38132713  163.55779263 3496.98316292]
total_rewards_mean           1755.81885806527
total_rewards_std            1133.4393953658403
total_rewards_max            3656.3813271288545
total_rewards_min            163.55779263471476
Number of train steps total  608000
Number of env steps total    515974
Number of rollouts total     0
Train Time (s)               146.91996286669746
(Previous) Eval Time (s)     12.31358569394797
Sample Time (s)              7.391122595407069
Epoch Time (s)               166.6246711560525
Total Train Time (s)         25210.955933788326
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:20:47.718851 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #151 | Epoch Duration: 166.7195565700531
2020-01-11 15:20:47.719027 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.025243
Z variance train             0.047292747
KL Divergence                18.224102
KL Loss                      1.8224102
QF Loss                      905.9596
VF Loss                      133.23627
Policy Loss                  -911.1662
Q Predictions Mean           908.7308
Q Predictions Std            374.68304
Q Predictions Max            1335.2754
Q Predictions Min            187.46994
V Predictions Mean           909.8522
V Predictions Std            368.79526
V Predictions Max            1338.763
V Predictions Min            189.39249
Log Pis Mean                 -0.04085712
Log Pis Std                  2.941254
Log Pis Max                  11.558731
Log Pis Min                  -5.9815345
Policy mu Mean               0.0074925143
Policy mu Std                0.5801939
Policy mu Max                2.670017
Policy mu Min                -3.1413636
Policy log std Mean          -1.0328608
Policy log std Std           0.24214345
Policy log std Max           -0.37285322
Policy log std Min           -2.317067
Z mean eval                  1.0881417
Z variance eval              0.10354197
total_rewards                [ 968.7477648  3312.39123308  666.92584017  771.24832486  782.33522527
 2934.02078397  659.22748576 1126.45298425 3714.10115742 2736.21447945]
total_rewards_mean           1767.1665279019749
total_rewards_std            1180.1130135940716
total_rewards_max            3714.10115741747
total_rewards_min            659.2274857640001
Number of train steps total  612000
Number of env steps total    521313
Number of rollouts total     0
Train Time (s)               144.93315999303013
(Previous) Eval Time (s)     12.840869260951877
Sample Time (s)              7.813450502697378
Epoch Time (s)               165.5874797566794
Total Train Time (s)         25376.64417573763
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:23:33.409391 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #152 | Epoch Duration: 165.69022035598755
2020-01-11 15:23:33.409617 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0817795
Z variance train             0.10484211
KL Divergence                18.097912
KL Loss                      1.8097912
QF Loss                      1467.2305
VF Loss                      578.17615
Policy Loss                  -881.2153
Q Predictions Mean           867.755
Q Predictions Std            377.94583
Q Predictions Max            1333.9274
Q Predictions Min            -35.368557
V Predictions Mean           878.9774
V Predictions Std            367.61334
V Predictions Max            1330.8634
V Predictions Min            220.468
Log Pis Mean                 0.2464206
Log Pis Std                  4.1141357
Log Pis Max                  24.926495
Log Pis Min                  -9.02626
Policy mu Mean               -0.05133424
Policy mu Std                0.635257
Policy mu Max                3.514416
Policy mu Min                -4.0803876
Policy log std Mean          -1.0136096
Policy log std Std           0.24909711
Policy log std Max           -0.25481987
Policy log std Min           -2.6721237
Z mean eval                  1.0305752
Z variance eval              0.012257459
total_rewards                [1477.76032362 2841.32709783 2090.03792929  959.90530349  132.55694193
 1639.28724197  548.96290515 3717.5561164  3825.58971267 2484.95438185]
total_rewards_mean           1971.793795418304
total_rewards_std            1195.9697720191061
total_rewards_max            3825.5897126679974
total_rewards_min            132.5569419257641
Number of train steps total  616000
Number of env steps total    527397
Number of rollouts total     0
Train Time (s)               146.83771431306377
(Previous) Eval Time (s)     12.29606779711321
Sample Time (s)              6.9589950437657535
Epoch Time (s)               166.09277715394273
Total Train Time (s)         25543.028284310363
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:26:19.804861 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #153 | Epoch Duration: 166.3950538635254
2020-01-11 15:26:19.805137 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0335317
Z variance train             0.012161543
KL Divergence                20.489851
KL Loss                      2.0489852
QF Loss                      578.55914
VF Loss                      155.12062
Policy Loss                  -893.19946
Q Predictions Mean           886.976
Q Predictions Std            397.74396
Q Predictions Max            1372.1996
Q Predictions Min            47.60621
V Predictions Mean           888.5237
V Predictions Std            390.24466
V Predictions Max            1365.8293
V Predictions Min            70.75145
Log Pis Mean                 0.2623803
Log Pis Std                  3.46107
Log Pis Max                  16.93002
Log Pis Min                  -7.390601
Policy mu Mean               -0.05051541
Policy mu Std                0.5771342
Policy mu Max                2.7148461
Policy mu Min                -3.2174304
Policy log std Mean          -1.0211228
Policy log std Std           0.26275402
Policy log std Max           -0.33868724
Policy log std Min           -1.9904473
Z mean eval                  1.034129
Z variance eval              0.025830645
total_rewards                [3022.62837228 2798.37044017 2145.72987219 1697.37487169  645.95474697
 1108.64382669 1865.76190023 3411.09855639 2080.1595013   907.84497422]
total_rewards_mean           1968.3567062122233
total_rewards_std            873.0619597289876
total_rewards_max            3411.0985563937766
total_rewards_min            645.9547469656804
Number of train steps total  620000
Number of env steps total    533038
Number of rollouts total     0
Train Time (s)               146.52221130765975
(Previous) Eval Time (s)     12.967440960928798
Sample Time (s)              7.337071560323238
Epoch Time (s)               166.82672382891178
Total Train Time (s)         25709.953377510887
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:29:06.727448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #154 | Epoch Duration: 166.92207169532776
2020-01-11 15:29:06.727758 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0326259
Z variance train             0.026021514
KL Divergence                20.251183
KL Loss                      2.0251184
QF Loss                      754.8179
VF Loss                      271.0355
Policy Loss                  -895.7617
Q Predictions Mean           877.8683
Q Predictions Std            391.74634
Q Predictions Max            1362.3325
Q Predictions Min            -16.924818
V Predictions Mean           889.46185
V Predictions Std            374.40604
V Predictions Max            1344.7789
V Predictions Min            226.70827
Log Pis Mean                 0.2352476
Log Pis Std                  4.519034
Log Pis Max                  35.1979
Log Pis Min                  -6.9689813
Policy mu Mean               -0.03739734
Policy mu Std                0.6263109
Policy mu Max                4.483569
Policy mu Min                -4.884084
Policy log std Mean          -1.0143359
Policy log std Std           0.26244295
Policy log std Max           -0.3781402
Policy log std Min           -2.3731623
Z mean eval                  1.0150373
Z variance eval              0.010163054
total_rewards                [1543.06996007  415.86401894 3898.68079943  225.73510929  809.89482139
 3680.93160348 2033.74195017 2666.08709547 3839.76586524 3579.84007873]
total_rewards_mean           2269.361130220824
total_rewards_std            1389.7139060475106
total_rewards_max            3898.680799431705
total_rewards_min            225.73510928913421
Number of train steps total  624000
Number of env steps total    538634
Number of rollouts total     0
Train Time (s)               145.16820212593302
(Previous) Eval Time (s)     17.028345103375614
Sample Time (s)              7.338493536226451
Epoch Time (s)               169.5350407655351
Total Train Time (s)         25879.619922273327
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:31:56.394789 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #155 | Epoch Duration: 169.66680335998535
2020-01-11 15:31:56.394986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0162117
Z variance train             0.010165891
KL Divergence                22.878101
KL Loss                      2.28781
QF Loss                      881.2187
VF Loss                      139.88512
Policy Loss                  -902.542
Q Predictions Mean           895.9642
Q Predictions Std            389.0851
Q Predictions Max            1361.634
Q Predictions Min            173.23958
V Predictions Mean           897.8376
V Predictions Std            382.5287
V Predictions Max            1344.5769
V Predictions Min            197.9155
Log Pis Mean                 -0.43856508
Log Pis Std                  2.759823
Log Pis Max                  9.191346
Log Pis Min                  -6.734139
Policy mu Mean               -0.036004987
Policy mu Std                0.5455038
Policy mu Max                1.9679315
Policy mu Min                -2.520591
Policy log std Mean          -1.0024542
Policy log std Std           0.24114756
Policy log std Max           -0.32947528
Policy log std Min           -2.1297874
Z mean eval                  1.0757169
Z variance eval              0.016526531
total_rewards                [3583.18025604 3465.43959149 3564.3639691   702.4395862  3875.69057813
 3430.01385591  383.99265979 3790.99356401 3452.14255154 3193.91656976]
total_rewards_mean           2944.217318196687
total_rewards_std            1215.970984165738
total_rewards_max            3875.6905781306123
total_rewards_min            383.99265978904725
Number of train steps total  628000
Number of env steps total    543734
Number of rollouts total     0
Train Time (s)               145.7900544158183
(Previous) Eval Time (s)     20.440146374050528
Sample Time (s)              8.097559292800725
Epoch Time (s)               174.32776008266956
Total Train Time (s)         26054.034962103236
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:34:50.811198 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #156 | Epoch Duration: 174.41607213020325
2020-01-11 15:34:50.811336 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.072747
Z variance train             0.016281174
KL Divergence                22.521084
KL Loss                      2.2521083
QF Loss                      856.4519
VF Loss                      182.82384
Policy Loss                  -919.0549
Q Predictions Mean           915.1354
Q Predictions Std            367.9211
Q Predictions Max            1395.5065
Q Predictions Min            205.41898
V Predictions Mean           923.06726
V Predictions Std            363.19086
V Predictions Max            1384.6302
V Predictions Min            223.53812
Log Pis Mean                 -0.004836049
Log Pis Std                  3.1797566
Log Pis Max                  15.833256
Log Pis Min                  -9.97748
Policy mu Mean               -0.017603036
Policy mu Std                0.60050046
Policy mu Max                2.5263307
Policy mu Min                -3.0822022
Policy log std Mean          -1.006089
Policy log std Std           0.2355408
Policy log std Max           -0.40117365
Policy log std Min           -2.3724947
Z mean eval                  1.0225799
Z variance eval              0.27554846
total_rewards                [3620.24944804 2705.30812567 3719.01443353 3455.23796229 1818.07111291
 3611.69124656 1854.32848408 3809.42271983 3564.76307831 3969.68947307]
total_rewards_mean           3212.7776084285383
total_rewards_std            757.7030009099354
total_rewards_max            3969.6894730665063
total_rewards_min            1818.0711129083475
Number of train steps total  632000
Number of env steps total    549727
Number of rollouts total     0
Train Time (s)               147.71175320912153
(Previous) Eval Time (s)     19.062790622003376
Sample Time (s)              7.235427334439009
Epoch Time (s)               174.0099711655639
Total Train Time (s)         26228.132359633688
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:37:44.912685 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #157 | Epoch Duration: 174.1012146472931
2020-01-11 15:37:44.912940 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0207021
Z variance train             0.27448314
KL Divergence                17.798773
KL Loss                      1.7798773
QF Loss                      1074.2303
VF Loss                      284.49768
Policy Loss                  -1044.9373
Q Predictions Mean           1037.0371
Q Predictions Std            407.8799
Q Predictions Max            1541.3208
Q Predictions Min            100.949326
V Predictions Mean           1040.1062
V Predictions Std            400.7808
V Predictions Max            1527.4117
V Predictions Min            272.30276
Log Pis Mean                 0.076667
Log Pis Std                  3.3777175
Log Pis Max                  18.968374
Log Pis Min                  -7.63441
Policy mu Mean               -0.044245064
Policy mu Std                0.62360173
Policy mu Max                5.4495864
Policy mu Min                -2.7068458
Policy log std Mean          -1.0170336
Policy log std Std           0.23997095
Policy log std Max           0.008474231
Policy log std Min           -2.1786551
Z mean eval                  1.0213834
Z variance eval              0.018307667
total_rewards                [ 384.72293076  234.06648719  254.55411583  243.11563198  894.81976689
 1960.53083875  318.84544121 1044.04125915   10.96828909  258.12066405]
total_rewards_mean           560.3785424900175
total_rewards_std            555.8125120131714
total_rewards_max            1960.5308387466803
total_rewards_min            10.968289090294808
Number of train steps total  636000
Number of env steps total    552984
Number of rollouts total     0
Train Time (s)               144.76395819988102
(Previous) Eval Time (s)     7.03263327293098
Sample Time (s)              7.300448587629944
Epoch Time (s)               159.09704006044194
Total Train Time (s)         26387.321364850737
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:40:24.102379 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #158 | Epoch Duration: 159.18925738334656
2020-01-11 15:40:24.102517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0205466
Z variance train             0.018261962
KL Divergence                18.996925
KL Loss                      1.8996925
QF Loss                      655.3761
VF Loss                      250.26447
Policy Loss                  -869.8758
Q Predictions Mean           858.629
Q Predictions Std            386.98648
Q Predictions Max            1331.2859
Q Predictions Min            -13.295248
V Predictions Mean           874.0095
V Predictions Std            382.9715
V Predictions Max            1341.7653
V Predictions Min            10.203704
Log Pis Mean                 -0.028251305
Log Pis Std                  3.4981213
Log Pis Max                  18.28951
Log Pis Min                  -10.00412
Policy mu Mean               -0.026927287
Policy mu Std                0.59602195
Policy mu Max                2.982004
Policy mu Min                -2.6523576
Policy log std Mean          -1.0092821
Policy log std Std           0.23889574
Policy log std Max           -0.43175638
Policy log std Min           -2.3159237
Z mean eval                  1.2451787
Z variance eval              0.010476274
total_rewards                [2351.47349518 3870.12296597  647.58084306 1964.31958251  859.82255975
 1075.70011656  549.8560084  3834.17053085  854.66912684  360.3117772 ]
total_rewards_mean           1636.8027006321731
total_rewards_std            1255.1444415139595
total_rewards_max            3870.122965973569
total_rewards_min            360.3117771997879
Number of train steps total  640000
Number of env steps total    557325
Number of rollouts total     0
Train Time (s)               148.2654293589294
(Previous) Eval Time (s)     15.725560580845922
Sample Time (s)              7.159033984411508
Epoch Time (s)               171.15002392418683
Total Train Time (s)         26558.586657957174
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:43:15.368849 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #159 | Epoch Duration: 171.26623964309692
2020-01-11 15:43:15.368981 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2415801
Z variance train             0.010316421
KL Divergence                21.700638
KL Loss                      2.1700637
QF Loss                      818.328
VF Loss                      748.35693
Policy Loss                  -917.20416
Q Predictions Mean           908.71643
Q Predictions Std            392.60144
Q Predictions Max            1449.4968
Q Predictions Min            -80.318436
V Predictions Mean           907.5782
V Predictions Std            385.13058
V Predictions Max            1434.6682
V Predictions Min            189.97577
Log Pis Mean                 -0.102384076
Log Pis Std                  3.370509
Log Pis Max                  15.931143
Log Pis Min                  -9.852452
Policy mu Mean               -0.020372787
Policy mu Std                0.60854083
Policy mu Max                3.198028
Policy mu Min                -3.170894
Policy log std Mean          -0.98624974
Policy log std Std           0.2453851
Policy log std Max           -0.24143547
Policy log std Min           -2.1569724
Z mean eval                  1.1807494
Z variance eval              0.020896753
total_rewards                [1342.3395705   573.12432722 1473.46294474 2483.63925515 1066.40156697
  376.99817265 2608.02397018 3234.1060384  3574.85911205 1332.54605666]
total_rewards_mean           1806.5501014519018
total_rewards_std            1045.44434623141
total_rewards_max            3574.859112054888
total_rewards_min            376.99817264794603
Number of train steps total  644000
Number of env steps total    562295
Number of rollouts total     0
Train Time (s)               146.3050698977895
(Previous) Eval Time (s)     10.906312722712755
Sample Time (s)              7.8084933357313275
Epoch Time (s)               165.0198759562336
Total Train Time (s)         26723.687530863564
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:46:00.471350 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #160 | Epoch Duration: 165.1022744178772
2020-01-11 15:46:00.471480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.17746
Z variance train             0.020813847
KL Divergence                20.293633
KL Loss                      2.0293634
QF Loss                      1014.1958
VF Loss                      165.75987
Policy Loss                  -930.62695
Q Predictions Mean           921.0543
Q Predictions Std            393.38794
Q Predictions Max            1380.5564
Q Predictions Min            88.4962
V Predictions Mean           933.7384
V Predictions Std            388.70135
V Predictions Max            1383.5883
V Predictions Min            237.03706
Log Pis Mean                 0.09187248
Log Pis Std                  3.4586236
Log Pis Max                  25.115126
Log Pis Min                  -8.053253
Policy mu Mean               -0.052901104
Policy mu Std                0.59771955
Policy mu Max                2.6889617
Policy mu Min                -5.788378
Policy log std Mean          -1.0146894
Policy log std Std           0.2560321
Policy log std Max           -0.39014357
Policy log std Min           -2.0065153
Z mean eval                  1.0650456
Z variance eval              0.007897704
total_rewards                [  60.40433832  656.60356224 3414.02481773 1668.66213393   69.96017962
 1365.71881774 1040.04060131  711.75082876 3122.95552724 2016.97180259]
total_rewards_mean           1412.7092609473675
total_rewards_std            1104.3859662130817
total_rewards_max            3414.0248177337903
total_rewards_min            60.40433832455527
Number of train steps total  648000
Number of env steps total    568382
Number of rollouts total     0
Train Time (s)               146.87246039882302
(Previous) Eval Time (s)     8.66145056206733
Sample Time (s)              6.61017378885299
Epoch Time (s)               162.14408474974334
Total Train Time (s)         26885.923679097556
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:48:42.711519 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #161 | Epoch Duration: 162.2399251461029
2020-01-11 15:48:42.711710 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #161 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0675052
Z variance train             0.007910441
KL Divergence                21.377457
KL Loss                      2.1377456
QF Loss                      1086.4585
VF Loss                      206.08603
Policy Loss                  -889.2783
Q Predictions Mean           879.13434
Q Predictions Std            386.4773
Q Predictions Max            1394.8896
Q Predictions Min            -70.77731
V Predictions Mean           891.65173
V Predictions Std            381.13083
V Predictions Max            1389.2461
V Predictions Min            -7.787405
Log Pis Mean                 0.13126357
Log Pis Std                  3.6969168
Log Pis Max                  18.78806
Log Pis Min                  -8.266052
Policy mu Mean               -0.024146836
Policy mu Std                0.5979893
Policy mu Max                3.2261703
Policy mu Min                -2.6618614
Policy log std Mean          -1.0186884
Policy log std Std           0.25221285
Policy log std Max           -0.32862115
Policy log std Min           -2.2157733
Z mean eval                  1.011504
Z variance eval              0.05106209
total_rewards                [1.02833054e+03 3.88075164e+03 3.52465494e+03 2.47567690e+03
 3.55415721e+03 8.56714416e+02 1.06701824e+03 1.54665379e+03
 3.62808780e+03 3.19474857e+00]
total_rewards_mean           2156.5240224327868
total_rewards_std            1349.9480428934053
total_rewards_max            3880.7516448765036
total_rewards_min            3.1947485701845855
Number of train steps total  652000
Number of env steps total    575242
Number of rollouts total     0
Train Time (s)               146.29476325633004
(Previous) Eval Time (s)     15.31399170262739
Sample Time (s)              7.388039338868111
Epoch Time (s)               168.99679429782555
Total Train Time (s)         27055.004054404795
Epoch                        162
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:51:31.792108 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #162 | Epoch Duration: 169.08026885986328
2020-01-11 15:51:31.792227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0039468
Z variance train             0.052235283
KL Divergence                18.542982
KL Loss                      1.8542982
QF Loss                      1389.076
VF Loss                      373.6712
Policy Loss                  -895.82947
Q Predictions Mean           885.5868
Q Predictions Std            386.74188
Q Predictions Max            1340.3735
Q Predictions Min            -56.791367
V Predictions Mean           897.3336
V Predictions Std            374.07596
V Predictions Max            1323.8823
V Predictions Min            42.5532
Log Pis Mean                 0.8564706
Log Pis Std                  4.413121
Log Pis Max                  23.382425
Log Pis Min                  -7.452545
Policy mu Mean               -0.018434796
Policy mu Std                0.66184676
Policy mu Max                4.487566
Policy mu Min                -4.600228
Policy log std Mean          -1.0710766
Policy log std Std           0.2815993
Policy log std Max           -0.0986073
Policy log std Min           -2.5613475
Z mean eval                  0.97921383
Z variance eval              0.01718895
total_rewards                [ 278.56583452 3544.56309536 3555.13793756 3489.91944542  334.00811936
  177.66774895  726.37688125 1424.59152799 3527.6418119  2388.84166977]
total_rewards_mean           1944.7314072087581
total_rewards_std            1431.4782713791667
total_rewards_max            3555.1379375629635
total_rewards_min            177.66774894866737
Number of train steps total  656000
Number of env steps total    581609
Number of rollouts total     0
Train Time (s)               146.96101257996634
(Previous) Eval Time (s)     13.977749282959849
Sample Time (s)              6.19791702972725
Epoch Time (s)               167.13667889265344
Total Train Time (s)         27222.230934622232
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:54:19.024679 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #163 | Epoch Duration: 167.23234939575195
2020-01-11 15:54:19.024846 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97856253
Z variance train             0.017348927
KL Divergence                19.82147
KL Loss                      1.9821471
QF Loss                      744.87665
VF Loss                      194.91312
Policy Loss                  -862.72766
Q Predictions Mean           855.1814
Q Predictions Std            437.43115
Q Predictions Max            1382.8926
Q Predictions Min            -31.958694
V Predictions Mean           866.9739
V Predictions Std            430.8123
V Predictions Max            1392.1165
V Predictions Min            27.039894
Log Pis Mean                 0.008026306
Log Pis Std                  3.6814327
Log Pis Max                  21.384901
Log Pis Min                  -6.4326506
Policy mu Mean               -0.08002081
Policy mu Std                0.5959583
Policy mu Max                4.0297513
Policy mu Min                -2.707185
Policy log std Mean          -1.0070316
Policy log std Std           0.26590762
Policy log std Max           -0.30051267
Policy log std Min           -2.3678846
Z mean eval                  1.0872523
Z variance eval              0.020450128
total_rewards                [ 687.37624718 3548.32288387 3734.1360636  2733.18012669 3774.49298701
 1493.71565515 1040.16227936 3523.03045238 2775.00326671 3288.67352148]
total_rewards_mean           2659.8093483424127
total_rewards_std            1105.3936406929863
total_rewards_max            3774.4929870141887
total_rewards_min            687.3762471809791
Number of train steps total  660000
Number of env steps total    588663
Number of rollouts total     0
Train Time (s)               145.88213396118954
(Previous) Eval Time (s)     20.31838615424931
Sample Time (s)              7.802074397914112
Epoch Time (s)               174.00259451335296
Total Train Time (s)         27396.322958468925
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 15:57:13.115642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #164 | Epoch Duration: 174.09066152572632
2020-01-11 15:57:13.115811 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0981131
Z variance train             0.01949813
KL Divergence                19.322495
KL Loss                      1.9322494
QF Loss                      712.43427
VF Loss                      233.19695
Policy Loss                  -949.67755
Q Predictions Mean           942.2771
Q Predictions Std            387.02753
Q Predictions Max            1415.2144
Q Predictions Min            -3.1921413
V Predictions Mean           948.9724
V Predictions Std            382.25797
V Predictions Max            1404.9141
V Predictions Min            89.19729
Log Pis Mean                 0.26908636
Log Pis Std                  3.9962502
Log Pis Max                  27.548784
Log Pis Min                  -9.316134
Policy mu Mean               -0.042648036
Policy mu Std                0.62767106
Policy mu Max                3.3185656
Policy mu Min                -3.3527982
Policy log std Mean          -1.0187633
Policy log std Std           0.2489064
Policy log std Max           -0.30750448
Policy log std Min           -2.2095695
Z mean eval                  1.0401974
Z variance eval              0.010807996
total_rewards                [1578.04284186 3919.48210061 3715.89444154 2061.52814306  324.65855043
  786.6348297  1350.29163655 3838.89298232  110.75665972 3668.67863836]
total_rewards_mean           2135.4860824138686
total_rewards_std            1451.3226796081365
total_rewards_max            3919.482100608182
total_rewards_min            110.75665972116812
Number of train steps total  664000
Number of env steps total    594318
Number of rollouts total     0
Train Time (s)               146.02888339292258
(Previous) Eval Time (s)     13.758023425936699
Sample Time (s)              7.325979315210134
Epoch Time (s)               167.1128861340694
Total Train Time (s)         27563.52201675158
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:00:00.321339 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #165 | Epoch Duration: 167.20535588264465
2020-01-11 16:00:00.321665 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0444131
Z variance train             0.010770509
KL Divergence                20.466846
KL Loss                      2.0466847
QF Loss                      725.2663
VF Loss                      189.23865
Policy Loss                  -897.42316
Q Predictions Mean           891.1382
Q Predictions Std            398.96906
Q Predictions Max            1416.0942
Q Predictions Min            -9.518065
V Predictions Mean           900.4908
V Predictions Std            394.62643
V Predictions Max            1409.9294
V Predictions Min            28.079458
Log Pis Mean                 0.12399387
Log Pis Std                  3.4226036
Log Pis Max                  19.189423
Log Pis Min                  -7.432661
Policy mu Mean               -0.031485777
Policy mu Std                0.58605427
Policy mu Max                2.4567766
Policy mu Min                -3.4874601
Policy log std Mean          -1.0052139
Policy log std Std           0.26372254
Policy log std Max           -0.46325895
Policy log std Min           -2.4082246
Z mean eval                  1.0494113
Z variance eval              0.008640242
total_rewards                [2705.0892341  3885.10769831 3752.39511504 3616.18247437 3735.00713472
 1505.8710834   867.89981019 2887.41985177  236.74566419   61.4807555 ]
total_rewards_mean           2325.319882158394
total_rewards_std            1444.5029153841947
total_rewards_max            3885.107698307673
total_rewards_min            61.4807555049705
Number of train steps total  668000
Number of env steps total    599483
Number of rollouts total     0
Train Time (s)               147.3594272644259
(Previous) Eval Time (s)     15.091691732872277
Sample Time (s)              7.3167430106550455
Epoch Time (s)               169.76786200795323
Total Train Time (s)         27733.37846473558
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:02:50.177003 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #166 | Epoch Duration: 169.85512495040894
2020-01-11 16:02:50.177130 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #166 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0545168
Z variance train             0.008641476
KL Divergence                21.450691
KL Loss                      2.1450691
QF Loss                      1060.1661
VF Loss                      175.72388
Policy Loss                  -856.9078
Q Predictions Mean           850.2146
Q Predictions Std            426.79434
Q Predictions Max            1422.1353
Q Predictions Min            76.18966
V Predictions Mean           853.9656
V Predictions Std            420.91165
V Predictions Max            1400.925
V Predictions Min            232.92397
Log Pis Mean                 -8.291751e-05
Log Pis Std                  3.752019
Log Pis Max                  23.955425
Log Pis Min                  -7.5189147
Policy mu Mean               -0.04068973
Policy mu Std                0.5775633
Policy mu Max                4.6533318
Policy mu Min                -5.331272
Policy log std Mean          -1.009217
Policy log std Std           0.26985943
Policy log std Max           -0.4515264
Policy log std Min           -2.2992682
Z mean eval                  1.0952551
Z variance eval              0.006560459
total_rewards                [ 499.24195594  379.27899305  952.10673309 3713.32141586 3840.3376409
  379.8648501   716.86383999 1463.96048958  578.76352123 3534.3738131 ]
total_rewards_mean           1605.811325283082
total_rewards_std            1402.7967840901908
total_rewards_max            3840.3376408979607
total_rewards_min            379.27899304630546
Number of train steps total  672000
Number of env steps total    607576
Number of rollouts total     0
Train Time (s)               147.5881339898333
(Previous) Eval Time (s)     14.93535296805203
Sample Time (s)              6.442413163371384
Epoch Time (s)               168.9659001212567
Total Train Time (s)         27902.43296235893
Epoch                        167
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:05:39.233786 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #167 | Epoch Duration: 169.0565631389618
2020-01-11 16:05:39.233914 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0961616
Z variance train             0.006576507
KL Divergence                22.720278
KL Loss                      2.2720277
QF Loss                      940.95544
VF Loss                      115.264084
Policy Loss                  -902.7235
Q Predictions Mean           892.3324
Q Predictions Std            414.35382
Q Predictions Max            1442.8357
Q Predictions Min            -76.883
V Predictions Mean           901.35443
V Predictions Std            406.0282
V Predictions Max            1443.8044
V Predictions Min            117.64781
Log Pis Mean                 -0.25219402
Log Pis Std                  3.1324916
Log Pis Max                  19.576468
Log Pis Min                  -7.9276767
Policy mu Mean               -0.05748818
Policy mu Std                0.5605869
Policy mu Max                3.2707696
Policy mu Min                -2.738452
Policy log std Mean          -0.9949126
Policy log std Std           0.23804346
Policy log std Max           -0.27324492
Policy log std Min           -2.0929496
Z mean eval                  1.0530932
Z variance eval              0.0049571684
total_rewards                [3019.55517925  785.00942541  875.12187293 3708.33137788 2627.75825045
 3733.5908848   473.85659153   34.3346833   338.83468415 2127.43903827]
total_rewards_mean           1772.3831987949484
total_rewards_std            1361.9629292972904
total_rewards_max            3733.590884797442
total_rewards_min            34.33468329591827
Number of train steps total  676000
Number of env steps total    612567
Number of rollouts total     0
Train Time (s)               140.37053853506222
(Previous) Eval Time (s)     10.433592772111297
Sample Time (s)              7.717065311968327
Epoch Time (s)               158.52119661914185
Total Train Time (s)         28061.13019990083
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:08:17.935803 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #168 | Epoch Duration: 158.70175623893738
2020-01-11 16:08:17.936093 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0566355
Z variance train             0.0049720206
KL Divergence                22.867918
KL Loss                      2.2867918
QF Loss                      1329.29
VF Loss                      254.98616
Policy Loss                  -931.27466
Q Predictions Mean           927.41235
Q Predictions Std            382.3423
Q Predictions Max            1395.5898
Q Predictions Min            -14.001715
V Predictions Mean           938.0126
V Predictions Std            379.9568
V Predictions Max            1411.1932
V Predictions Min            -16.402298
Log Pis Mean                 0.10174037
Log Pis Std                  3.16448
Log Pis Max                  11.262628
Log Pis Min                  -6.9850745
Policy mu Mean               -0.070740655
Policy mu Std                0.58793384
Policy mu Max                2.55076
Policy mu Min                -2.851095
Policy log std Mean          -1.0120635
Policy log std Std           0.2572967
Policy log std Max           -0.089438975
Policy log std Min           -2.0337977
Z mean eval                  1.037844
Z variance eval              0.02331159
total_rewards                [2395.53022449 1414.71960344 3512.18751689 1480.86867635  742.61454078
 1377.56934985 2863.02521682  430.51120813  431.30331563 1036.92080192]
total_rewards_mean           1568.5250454296463
total_rewards_std            987.8449212103103
total_rewards_max            3512.1875168904535
total_rewards_min            430.5112081254691
Number of train steps total  680000
Number of env steps total    620575
Number of rollouts total     0
Train Time (s)               141.37924952199683
(Previous) Eval Time (s)     9.167286767158657
Sample Time (s)              7.689139644149691
Epoch Time (s)               158.23567593330517
Total Train Time (s)         28219.45036348654
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:10:56.256238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #169 | Epoch Duration: 158.31996417045593
2020-01-11 16:10:56.256353 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0326524
Z variance train             0.02372788
KL Divergence                18.57534
KL Loss                      1.857534
QF Loss                      1788.1694
VF Loss                      317.3422
Policy Loss                  -944.3318
Q Predictions Mean           933.1269
Q Predictions Std            375.45145
Q Predictions Max            1374.4194
Q Predictions Min            119.1539
V Predictions Mean           952.4855
V Predictions Std            367.94904
V Predictions Max            1389.2607
V Predictions Min            165.65681
Log Pis Mean                 0.4524203
Log Pis Std                  3.8473783
Log Pis Max                  22.827572
Log Pis Min                  -7.46233
Policy mu Mean               -0.03378184
Policy mu Std                0.6561189
Policy mu Max                4.5292587
Policy mu Min                -4.3155546
Policy log std Mean          -1.0276482
Policy log std Std           0.26684892
Policy log std Max           0.38626087
Policy log std Min           -2.3010616
Z mean eval                  1.1612172
Z variance eval              0.025389338
total_rewards                [2102.36064568   38.93869366  357.3759548   901.40410347 3502.91360852
 3722.46493786  275.35719474  805.96281836  680.13728821  423.76139266]
total_rewards_mean           1281.0676637968493
total_rewards_std            1282.3824275641068
total_rewards_max            3722.464937857948
total_rewards_min            38.93869366044213
Number of train steps total  684000
Number of env steps total    627572
Number of rollouts total     0
Train Time (s)               140.42691310029477
(Previous) Eval Time (s)     12.624649965204298
Sample Time (s)              6.565829759929329
Epoch Time (s)               159.6173928254284
Total Train Time (s)         28379.16231651092
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:13:35.974446 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #170 | Epoch Duration: 159.71795201301575
2020-01-11 16:13:35.974814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.153197
Z variance train             0.025139267
KL Divergence                18.805206
KL Loss                      1.8805207
QF Loss                      1188.9418
VF Loss                      272.2414
Policy Loss                  -933.1222
Q Predictions Mean           924.9
Q Predictions Std            410.7536
Q Predictions Max            1456.4398
Q Predictions Min            -28.200495
V Predictions Mean           928.5359
V Predictions Std            398.24234
V Predictions Max            1438.349
V Predictions Min            22.547794
Log Pis Mean                 0.21642967
Log Pis Std                  3.3406596
Log Pis Max                  16.576513
Log Pis Min                  -6.5897145
Policy mu Mean               0.005930921
Policy mu Std                0.6061332
Policy mu Max                3.589585
Policy mu Min                -3.0049825
Policy log std Mean          -1.0264678
Policy log std Std           0.25717193
Policy log std Max           -0.3459018
Policy log std Min           -2.2897315
Z mean eval                  1.0436785
Z variance eval              0.03964549
total_rewards                [3834.38357239 3038.84028301 3073.17308844 3705.99553626  296.70563185
 3734.08023268 3561.04894815 2634.48154776 3951.98455528 1389.0590922 ]
total_rewards_mean           2921.975248804521
total_rewards_std            1137.4123696143645
total_rewards_max            3951.984555282734
total_rewards_min            296.7056318509827
Number of train steps total  688000
Number of env steps total    632312
Number of rollouts total     0
Train Time (s)               141.5796744269319
(Previous) Eval Time (s)     19.307071352843195
Sample Time (s)              7.551475883927196
Epoch Time (s)               168.43822166370228
Total Train Time (s)         28547.68999965256
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:16:24.503585 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #171 | Epoch Duration: 168.52855038642883
2020-01-11 16:16:24.503762 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0497516
Z variance train             0.039555643
KL Divergence                17.875889
KL Loss                      1.787589
QF Loss                      968.32324
VF Loss                      323.34094
Policy Loss                  -938.5216
Q Predictions Mean           930.1937
Q Predictions Std            384.6976
Q Predictions Max            1412.2877
Q Predictions Min            -23.235376
V Predictions Mean           938.8545
V Predictions Std            372.73117
V Predictions Max            1406.5214
V Predictions Min            16.703321
Log Pis Mean                 0.27770454
Log Pis Std                  3.5621238
Log Pis Max                  16.448612
Log Pis Min                  -7.0503244
Policy mu Mean               -0.043982163
Policy mu Std                0.58958644
Policy mu Max                2.8242571
Policy mu Min                -4.268088
Policy log std Mean          -1.0470612
Policy log std Std           0.27483407
Policy log std Max           -0.2803654
Policy log std Min           -2.5047684
Z mean eval                  0.97198343
Z variance eval              0.0059545734
total_rewards                [4080.93625384   96.42988276 3437.5332962   865.28077023  203.46465176
  704.23846064  507.51478298 1029.70545085  395.4505724   255.76579654]
total_rewards_mean           1157.6319918202223
total_rewards_std            1338.079917698776
total_rewards_max            4080.9362538426917
total_rewards_min            96.42988276291644
Number of train steps total  692000
Number of env steps total    636804
Number of rollouts total     0
Train Time (s)               146.04565305821598
(Previous) Eval Time (s)     11.740731060039252
Sample Time (s)              7.243667897302657
Epoch Time (s)               165.03005201555789
Total Train Time (s)         28712.80683875736
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:19:09.621711 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #172 | Epoch Duration: 165.11782717704773
2020-01-11 16:19:09.621833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96308887
Z variance train             0.00597347
KL Divergence                21.58579
KL Loss                      2.158579
QF Loss                      797.24365
VF Loss                      309.74048
Policy Loss                  -928.852
Q Predictions Mean           921.069
Q Predictions Std            402.18597
Q Predictions Max            1440.9935
Q Predictions Min            -24.395638
V Predictions Mean           938.9133
V Predictions Std            394.23712
V Predictions Max            1439.5829
V Predictions Min            247.56442
Log Pis Mean                 -0.031899802
Log Pis Std                  3.463646
Log Pis Max                  26.813732
Log Pis Min                  -10.962921
Policy mu Mean               -0.0043022814
Policy mu Std                0.58488274
Policy mu Max                3.2152133
Policy mu Min                -3.3189168
Policy log std Mean          -1.0146182
Policy log std Std           0.24010904
Policy log std Max           -0.4223547
Policy log std Min           -2.0560558
Z mean eval                  1.045769
Z variance eval              0.016079886
total_rewards                [ 176.75408404 3887.79423371 3902.4113901  2996.79677571 3939.98850441
 2297.93734339 1214.37433946    4.73325925 1592.22229539 3913.1766643 ]
total_rewards_mean           2392.6188889767627
total_rewards_std            1491.1879974247167
total_rewards_max            3939.988504413094
total_rewards_min            4.733259251942876
Number of train steps total  696000
Number of env steps total    645202
Number of rollouts total     0
Train Time (s)               144.8548553059809
(Previous) Eval Time (s)     15.308349866885692
Sample Time (s)              7.2540686978027225
Epoch Time (s)               167.4172738706693
Total Train Time (s)         28880.31519569084
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:21:57.130770 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #173 | Epoch Duration: 167.5088415145874
2020-01-11 16:21:57.130895 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0425448
Z variance train             0.015926283
KL Divergence                20.654385
KL Loss                      2.0654385
QF Loss                      1148.3765
VF Loss                      235.7459
Policy Loss                  -911.4351
Q Predictions Mean           901.9332
Q Predictions Std            410.71277
Q Predictions Max            1416.499
Q Predictions Min            -17.854954
V Predictions Mean           908.58014
V Predictions Std            402.9025
V Predictions Max            1409.3799
V Predictions Min            -22.043224
Log Pis Mean                 0.1284919
Log Pis Std                  3.9991665
Log Pis Max                  23.379066
Log Pis Min                  -9.485185
Policy mu Mean               -0.02780201
Policy mu Std                0.6476701
Policy mu Max                4.6460776
Policy mu Min                -3.755172
Policy log std Mean          -1.0131772
Policy log std Std           0.26208702
Policy log std Max           -0.397762
Policy log std Min           -2.165179
Z mean eval                  1.0887935
Z variance eval              0.021708129
total_rewards                [3825.2516158  3673.34677878 3930.53546795 3750.57893519 3689.32838959
 2789.6782666  3783.64184534 3500.13889929 3885.46337364 3819.05578243]
total_rewards_mean           3664.7019354594922
total_rewards_std            313.68049991401307
total_rewards_max            3930.535467946812
total_rewards_min            2789.678266595298
Number of train steps total  700000
Number of env steps total    649979
Number of rollouts total     0
Train Time (s)               146.60503164771944
(Previous) Eval Time (s)     21.41675903275609
Sample Time (s)              7.086646975949407
Epoch Time (s)               175.10843765642494
Total Train Time (s)         29055.50881022541
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:24:52.328309 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #174 | Epoch Duration: 175.19732236862183
2020-01-11 16:24:52.328423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0821835
Z variance train             0.02206498
KL Divergence                19.160473
KL Loss                      1.9160473
QF Loss                      862.7891
VF Loss                      134.52246
Policy Loss                  -960.62787
Q Predictions Mean           954.4864
Q Predictions Std            416.2058
Q Predictions Max            1438.9879
Q Predictions Min            80.730804
V Predictions Mean           961.39
V Predictions Std            410.56186
V Predictions Max            1447.2378
V Predictions Min            135.11282
Log Pis Mean                 0.33286464
Log Pis Std                  3.3137987
Log Pis Max                  16.456316
Log Pis Min                  -8.342206
Policy mu Mean               -0.049520157
Policy mu Std                0.57108974
Policy mu Max                2.9674797
Policy mu Min                -2.982294
Policy log std Mean          -1.0668929
Policy log std Std           0.27564704
Policy log std Max           -0.2720297
Policy log std Min           -2.3353682
Z mean eval                  1.127845
Z variance eval              0.012438955
total_rewards                [1803.61127528 2856.52945582 3686.89418444  828.04024025 3925.15514773
 3972.62775675 3913.58096308 1994.11715302 3787.28006266 2158.05721906]
total_rewards_mean           2892.5893458103324
total_rewards_std            1072.5118615620554
total_rewards_max            3972.62775675016
total_rewards_min            828.0402402474235
Number of train steps total  704000
Number of env steps total    655549
Number of rollouts total     0
Train Time (s)               147.43143950309604
(Previous) Eval Time (s)     16.520492401905358
Sample Time (s)              6.536128900945187
Epoch Time (s)               170.4880608059466
Total Train Time (s)         29226.091201290023
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:27:42.909570 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #175 | Epoch Duration: 170.58105945587158
2020-01-11 16:27:42.909685 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #175 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1215285
Z variance train             0.012349424
KL Divergence                20.022236
KL Loss                      2.0022237
QF Loss                      841.1379
VF Loss                      313.25223
Policy Loss                  -929.9901
Q Predictions Mean           925.0065
Q Predictions Std            399.24628
Q Predictions Max            1449.3947
Q Predictions Min            -17.746557
V Predictions Mean           924.9938
V Predictions Std            393.53394
V Predictions Max            1440.0709
V Predictions Min            -42.67958
Log Pis Mean                 0.59359145
Log Pis Std                  3.462956
Log Pis Max                  21.814137
Log Pis Min                  -6.229167
Policy mu Mean               0.003412217
Policy mu Std                0.6213056
Policy mu Max                4.0936246
Policy mu Min                -3.604299
Policy log std Mean          -1.0395772
Policy log std Std           0.26438504
Policy log std Max           -0.035505116
Policy log std Min           -2.2928233
Z mean eval                  1.0326564
Z variance eval              0.17410183
total_rewards                [ 239.24431258 2669.42866424 1436.43764601  123.41906684 4188.8686073
 1458.66202704 1511.09331084  689.04114841 4055.27847361 3746.61376656]
total_rewards_mean           2011.8087023428386
total_rewards_std            1473.1878391498894
total_rewards_max            4188.868607300512
total_rewards_min            123.41906684232455
Number of train steps total  708000
Number of env steps total    660034
Number of rollouts total     0
Train Time (s)               145.97102109203115
(Previous) Eval Time (s)     12.217901322059333
Sample Time (s)              6.0176416472531855
Epoch Time (s)               164.20656406134367
Total Train Time (s)         29390.396917414386
Epoch                        176
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:30:27.218885 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #176 | Epoch Duration: 164.3091003894806
2020-01-11 16:30:27.219035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0366609
Z variance train             0.1728474
KL Divergence                18.314234
KL Loss                      1.8314234
QF Loss                      1002.7901
VF Loss                      336.906
Policy Loss                  -849.3077
Q Predictions Mean           843.1445
Q Predictions Std            374.07257
Q Predictions Max            1350.7921
Q Predictions Min            3.6790879
V Predictions Mean           849.83594
V Predictions Std            369.09793
V Predictions Max            1326.3549
V Predictions Min            131.13434
Log Pis Mean                 0.38858002
Log Pis Std                  3.6251945
Log Pis Max                  20.313564
Log Pis Min                  -8.855909
Policy mu Mean               -0.02037813
Policy mu Std                0.6260773
Policy mu Max                3.9823108
Policy mu Min                -3.7370064
Policy log std Mean          -1.0319916
Policy log std Std           0.25822473
Policy log std Max           -0.12756681
Policy log std Min           -2.4475892
Z mean eval                  1.0863974
Z variance eval              0.011915296
total_rewards                [3377.07191517 4073.24634784  796.77477609 3484.59863869 2783.38765377
 1098.72643664 3804.85518609 3853.70635819 3571.37387001   60.61390665]
total_rewards_mean           2690.435508913418
total_rewards_std            1393.9011310638887
total_rewards_max            4073.246347836382
total_rewards_min            60.6139066469637
Number of train steps total  712000
Number of env steps total    665782
Number of rollouts total     0
Train Time (s)               146.11748628411442
(Previous) Eval Time (s)     15.620050852186978
Sample Time (s)              6.3942778231576085
Epoch Time (s)               168.131814959459
Total Train Time (s)         29558.615296470933
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:33:15.437152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #177 | Epoch Duration: 168.217999458313
2020-01-11 16:33:15.437267 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0928411
Z variance train             0.011999942
KL Divergence                20.957636
KL Loss                      2.0957637
QF Loss                      840.2367
VF Loss                      202.91632
Policy Loss                  -939.3268
Q Predictions Mean           937.17834
Q Predictions Std            411.50522
Q Predictions Max            1437.835
Q Predictions Min            237.90097
V Predictions Mean           936.33167
V Predictions Std            408.51614
V Predictions Max            1431.1527
V Predictions Min            236.5803
Log Pis Mean                 -0.17742805
Log Pis Std                  3.2931128
Log Pis Max                  15.632788
Log Pis Min                  -8.381136
Policy mu Mean               -0.037050463
Policy mu Std                0.5664888
Policy mu Max                2.5863793
Policy mu Min                -2.6942813
Policy log std Mean          -1.0211589
Policy log std Std           0.27945223
Policy log std Max           -0.3829412
Policy log std Min           -2.320962
Z mean eval                  1.182355
Z variance eval              0.028874317
total_rewards                [1644.05209767  727.50320849 2284.8721183  3219.40736342 3759.20259334
 1109.10330957  228.54981874 3891.96727893 1854.77040238 2921.84811557]
total_rewards_mean           2164.12763064163
total_rewards_std            1205.057543637963
total_rewards_max            3891.9672789258484
total_rewards_min            228.54981873612118
Number of train steps total  716000
Number of env steps total    671741
Number of rollouts total     0
Train Time (s)               145.2770688580349
(Previous) Eval Time (s)     14.056225365959108
Sample Time (s)              6.87294396944344
Epoch Time (s)               166.20623819343746
Total Train Time (s)         29724.968650743365
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:36:01.791523 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #178 | Epoch Duration: 166.35416746139526
2020-01-11 16:36:01.791639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1765416
Z variance train             0.02934685
KL Divergence                19.633953
KL Loss                      1.9633954
QF Loss                      669.0961
VF Loss                      314.96246
Policy Loss                  -986.47186
Q Predictions Mean           981.76434
Q Predictions Std            415.02914
Q Predictions Max            1490.7592
Q Predictions Min            39.37907
V Predictions Mean           995.3113
V Predictions Std            412.12384
V Predictions Max            1497.3967
V Predictions Min            229.53162
Log Pis Mean                 0.10888404
Log Pis Std                  3.169324
Log Pis Max                  16.26733
Log Pis Min                  -8.824646
Policy mu Mean               -0.0823468
Policy mu Std                0.6073553
Policy mu Max                2.6606982
Policy mu Min                -2.437638
Policy log std Mean          -0.9903227
Policy log std Std           0.2443406
Policy log std Max           -0.26756006
Policy log std Min           -2.2065372
Z mean eval                  1.1395782
Z variance eval              0.016506335
total_rewards                [3809.78235089 2384.09851254 3999.82088338 3334.05544788 4075.73735568
 4134.27526156 4209.15786835 1974.80139738 3979.71550571 4012.77974126]
total_rewards_mean           3591.42243246475
total_rewards_std            747.7274524984346
total_rewards_max            4209.157868349629
total_rewards_min            1974.8013973829775
Number of train steps total  720000
Number of env steps total    678505
Number of rollouts total     0
Train Time (s)               146.1040901551023
(Previous) Eval Time (s)     20.42908703815192
Sample Time (s)              7.390756969340146
Epoch Time (s)               173.92393416259438
Total Train Time (s)         29899.00581888389
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:38:55.830042 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #179 | Epoch Duration: 174.03831481933594
2020-01-11 16:38:55.830165 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1345671
Z variance train             0.016285826
KL Divergence                21.380646
KL Loss                      2.1380646
QF Loss                      1203.9839
VF Loss                      650.31714
Policy Loss                  -958.142
Q Predictions Mean           949.3022
Q Predictions Std            419.4468
Q Predictions Max            1446.7035
Q Predictions Min            48.711216
V Predictions Mean           977.1466
V Predictions Std            412.0286
V Predictions Max            1445.6097
V Predictions Min            237.37793
Log Pis Mean                 0.23748542
Log Pis Std                  3.7064154
Log Pis Max                  18.95023
Log Pis Min                  -8.925896
Policy mu Mean               -0.0260934
Policy mu Std                0.6524264
Policy mu Max                3.900603
Policy mu Min                -4.4398656
Policy log std Mean          -1.0163116
Policy log std Std           0.26571813
Policy log std Max           -0.26268172
Policy log std Min           -2.1234262
Z mean eval                  0.9737461
Z variance eval              0.010422665
total_rewards                [3907.40590374 2470.78087065 2980.75630719 1622.78707531 2804.14335982
  558.92308394 4119.40467677 4029.98814078 3922.19723363 1300.76699877]
total_rewards_mean           2771.7153650602004
total_rewards_std            1205.3383192882845
total_rewards_max            4119.404676765751
total_rewards_min            558.9230839404669
Number of train steps total  724000
Number of env steps total    685525
Number of rollouts total     0
Train Time (s)               146.10189644386992
(Previous) Eval Time (s)     19.86610188893974
Sample Time (s)              6.417991494294256
Epoch Time (s)               172.3859898271039
Total Train Time (s)         30071.503635147586
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:41:48.330153 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #180 | Epoch Duration: 172.49989771842957
2020-01-11 16:41:48.330284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9780243
Z variance train             0.0103621185
KL Divergence                21.286535
KL Loss                      2.1286535
QF Loss                      1857.0121
VF Loss                      360.3691
Policy Loss                  -999.39966
Q Predictions Mean           991.53754
Q Predictions Std            364.25082
Q Predictions Max            1437.8455
Q Predictions Min            222.92053
V Predictions Mean           992.2909
V Predictions Std            358.0563
V Predictions Max            1424.6833
V Predictions Min            237.92487
Log Pis Mean                 0.3573315
Log Pis Std                  3.6017475
Log Pis Max                  27.544956
Log Pis Min                  -7.9460044
Policy mu Mean               0.0064782966
Policy mu Std                0.6398793
Policy mu Max                3.4255269
Policy mu Min                -3.1369576
Policy log std Mean          -1.0141066
Policy log std Std           0.24607025
Policy log std Max           -0.30907607
Policy log std Min           -2.1473846
Z mean eval                  1.0636911
Z variance eval              0.018732447
total_rewards                [  58.63120779  260.32706742 3111.57241929  864.77149339 3585.85740014
 1159.87167133 1800.34430004  903.38305351 3428.73871879 1059.83603795]
total_rewards_mean           1623.3333369639122
total_rewards_std            1236.5001813589938
total_rewards_max            3585.857400138214
total_rewards_min            58.63120778940441
Number of train steps total  728000
Number of env steps total    691998
Number of rollouts total     0
Train Time (s)               146.63236178085208
(Previous) Eval Time (s)     14.407768782228231
Sample Time (s)              7.797562898136675
Epoch Time (s)               168.837693461217
Total Train Time (s)         30240.435713221785
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:44:37.263456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #181 | Epoch Duration: 168.93307280540466
2020-01-11 16:44:37.263593 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0638494
Z variance train             0.018732036
KL Divergence                20.843021
KL Loss                      2.0843022
QF Loss                      1434.2302
VF Loss                      250.05836
Policy Loss                  -968.13794
Q Predictions Mean           958.87256
Q Predictions Std            406.7001
Q Predictions Max            1465.9592
Q Predictions Min            -21.299812
V Predictions Mean           969.69965
V Predictions Std            399.11215
V Predictions Max            1459.7417
V Predictions Min            205.18161
Log Pis Mean                 -0.16992034
Log Pis Std                  3.329415
Log Pis Max                  14.679911
Log Pis Min                  -8.763121
Policy mu Mean               -0.019578956
Policy mu Std                0.5812909
Policy mu Max                3.0845659
Policy mu Min                -2.4393456
Policy log std Mean          -0.99963534
Policy log std Std           0.26569653
Policy log std Max           -0.07305372
Policy log std Min           -2.5917847
Z mean eval                  1.093415
Z variance eval              0.004322523
total_rewards                [3172.40280193 3397.09708445  581.03186357 1761.91697149 2482.43087234
  827.9248712  3643.0568588   357.95810225 2049.71276534 1411.4274854 ]
total_rewards_mean           1968.4959676784515
total_rewards_std            1128.6258771983432
total_rewards_max            3643.0568587986927
total_rewards_min            357.9581022494642
Number of train steps total  732000
Number of env steps total    697694
Number of rollouts total     0
Train Time (s)               147.66074765194207
(Previous) Eval Time (s)     12.254348682705313
Sample Time (s)              7.597250023391098
Epoch Time (s)               167.51234635803849
Total Train Time (s)         30408.035196545068
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:47:24.864922 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #182 | Epoch Duration: 167.6012260913849
2020-01-11 16:47:24.865054 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0878704
Z variance train             0.004313278
KL Divergence                24.349026
KL Loss                      2.4349027
QF Loss                      927.31055
VF Loss                      131.36526
Policy Loss                  -933.39746
Q Predictions Mean           920.49133
Q Predictions Std            415.33893
Q Predictions Max            1437.0493
Q Predictions Min            14.845974
V Predictions Mean           934.52734
V Predictions Std            406.78525
V Predictions Max            1457.6278
V Predictions Min            221.1216
Log Pis Mean                 0.2470214
Log Pis Std                  4.0465136
Log Pis Max                  24.800274
Log Pis Min                  -9.688975
Policy mu Mean               -0.033680603
Policy mu Std                0.6104729
Policy mu Max                2.9424794
Policy mu Min                -3.533311
Policy log std Mean          -1.017217
Policy log std Std           0.27176183
Policy log std Max           -0.28458428
Policy log std Min           -2.230524
Z mean eval                  1.1184976
Z variance eval              0.011788107
total_rewards                [2959.63746146 2423.35214939 2680.6059431   470.53452328  850.39342139
 4172.57165949 1148.84154054 3663.71080045 3852.62048108   72.17656592]
total_rewards_mean           2229.4444546089517
total_rewards_std            1416.2960745656362
total_rewards_max            4172.571659486271
total_rewards_min            72.17656592039644
Number of train steps total  736000
Number of env steps total    703891
Number of rollouts total     0
Train Time (s)               145.96652264520526
(Previous) Eval Time (s)     14.108174736145884
Sample Time (s)              6.543248918838799
Epoch Time (s)               166.61794630018994
Total Train Time (s)         30574.736926055513
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:50:11.569327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #183 | Epoch Duration: 166.70416927337646
2020-01-11 16:50:11.569468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #183 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1203041
Z variance train             0.011761917
KL Divergence                20.060736
KL Loss                      2.0060737
QF Loss                      677.0234
VF Loss                      209.18732
Policy Loss                  -977.12103
Q Predictions Mean           971.194
Q Predictions Std            392.9107
Q Predictions Max            1476.579
Q Predictions Min            5.910309
V Predictions Mean           980.2692
V Predictions Std            388.17862
V Predictions Max            1473.8036
V Predictions Min            250.2231
Log Pis Mean                 0.20043896
Log Pis Std                  3.29221
Log Pis Max                  16.72836
Log Pis Min                  -10.660681
Policy mu Mean               -0.03010184
Policy mu Std                0.60815895
Policy mu Max                3.3220127
Policy mu Min                -3.0905602
Policy log std Mean          -1.0429487
Policy log std Std           0.25873953
Policy log std Max           -0.45466995
Policy log std Min           -2.0846472
Z mean eval                  1.0268651
Z variance eval              0.030869815
total_rewards                [3619.72140357 4067.15490885 3788.79182746 3281.31672667 2925.702225
 3741.26323126  898.63833779 3946.53802759 1410.05039958 1440.79649589]
total_rewards_mean           2911.9973583658384
total_rewards_std            1138.9672043357475
total_rewards_max            4067.154908850328
total_rewards_min            898.6383377899281
Number of train steps total  740000
Number of env steps total    711362
Number of rollouts total     0
Train Time (s)               146.55911250179633
(Previous) Eval Time (s)     16.869463956914842
Sample Time (s)              8.017341976985335
Epoch Time (s)               171.4459184356965
Total Train Time (s)         30746.285248456523
Epoch                        184
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:53:03.118642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #184 | Epoch Duration: 171.54905557632446
2020-01-11 16:53:03.118780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0267096
Z variance train             0.030835876
KL Divergence                18.674326
KL Loss                      1.8674326
QF Loss                      1832.1958
VF Loss                      262.92474
Policy Loss                  -914.7591
Q Predictions Mean           909.9861
Q Predictions Std            426.50836
Q Predictions Max            1462.6415
Q Predictions Min            3.4498134
V Predictions Mean           916.5116
V Predictions Std            421.71942
V Predictions Max            1453.3722
V Predictions Min            221.05183
Log Pis Mean                 -0.36129743
Log Pis Std                  3.4010913
Log Pis Max                  15.120653
Log Pis Min                  -9.355655
Policy mu Mean               -0.040669385
Policy mu Std                0.5356226
Policy mu Max                2.907089
Policy mu Min                -3.215506
Policy log std Mean          -1.0272706
Policy log std Std           0.26633948
Policy log std Max           -0.3778972
Policy log std Min           -2.1304698
Z mean eval                  1.0052081
Z variance eval              0.018388005
total_rewards                [1605.63405744 4116.61753742  645.24079457 1419.05894053 1324.80387454
  554.22686193 4162.95733037 2308.92380733  242.89865522  442.66422479]
total_rewards_mean           1682.302608414559
total_rewards_std            1364.9839174262124
total_rewards_max            4162.957330370555
total_rewards_min            242.8986552193923
Number of train steps total  744000
Number of env steps total    717530
Number of rollouts total     0
Train Time (s)               146.81988630304113
(Previous) Eval Time (s)     14.099216787144542
Sample Time (s)              6.923584480769932
Epoch Time (s)               167.8426875709556
Total Train Time (s)         30914.213376005646
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:55:51.049560 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #185 | Epoch Duration: 167.9306676387787
2020-01-11 16:55:51.049727 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0079492
Z variance train             0.018385068
KL Divergence                18.869785
KL Loss                      1.8869785
QF Loss                      706.34595
VF Loss                      152.61958
Policy Loss                  -998.67804
Q Predictions Mean           991.7105
Q Predictions Std            393.92267
Q Predictions Max            1456.0555
Q Predictions Min            23.420736
V Predictions Mean           997.22534
V Predictions Std            389.96082
V Predictions Max            1440.3551
V Predictions Min            242.49477
Log Pis Mean                 0.006469533
Log Pis Std                  3.1412642
Log Pis Max                  9.996935
Log Pis Min                  -8.957094
Policy mu Mean               -0.06735483
Policy mu Std                0.58458316
Policy mu Max                2.4498684
Policy mu Min                -2.7161927
Policy log std Mean          -1.0433834
Policy log std Std           0.26773533
Policy log std Max           -0.15441525
Policy log std Min           -2.1897154
Z mean eval                  1.1083317
Z variance eval              0.014008805
total_rewards                [3636.55278586 3939.09458907 3943.67013562 1365.70189209 4226.99867884
 4122.65751051 1018.79240172 4018.22221921 3968.50288046  966.60063552]
total_rewards_mean           3120.6793728884136
total_rewards_std            1323.0065419433358
total_rewards_max            4226.998678839935
total_rewards_min            966.600635517199
Number of train steps total  748000
Number of env steps total    721629
Number of rollouts total     0
Train Time (s)               147.7424487322569
(Previous) Eval Time (s)     21.642592302057892
Sample Time (s)              7.607963056303561
Epoch Time (s)               176.99300409061834
Total Train Time (s)         31091.30095162848
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 16:58:48.139265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #186 | Epoch Duration: 177.08940410614014
2020-01-11 16:58:48.139433 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.101896
Z variance train             0.013976763
KL Divergence                20.488739
KL Loss                      2.048874
QF Loss                      922.99927
VF Loss                      352.85995
Policy Loss                  -931.03
Q Predictions Mean           926.7663
Q Predictions Std            419.9715
Q Predictions Max            1498.4625
Q Predictions Min            3.7519164
V Predictions Mean           942.6742
V Predictions Std            422.8075
V Predictions Max            1520.4362
V Predictions Min            -63.28724
Log Pis Mean                 0.17105746
Log Pis Std                  3.328094
Log Pis Max                  14.299684
Log Pis Min                  -7.0381374
Policy mu Mean               -0.04137709
Policy mu Std                0.6166219
Policy mu Max                2.4432237
Policy mu Min                -3.9709206
Policy log std Mean          -1.011339
Policy log std Std           0.2579299
Policy log std Max           -0.33960956
Policy log std Min           -2.1977477
Z mean eval                  0.96466273
Z variance eval              0.011331388
total_rewards                [3764.94566272 1805.78294293 3867.98341009  320.54344279 3714.78749921
  103.52499488 2011.85880439 3697.066312   1670.94433866  443.79017797]
total_rewards_mean           2140.1227585638835
total_rewards_std            1456.4923920283306
total_rewards_max            3867.9834100856106
total_rewards_min            103.52499488188715
Number of train steps total  752000
Number of env steps total    726749
Number of rollouts total     0
Train Time (s)               146.07398964604363
(Previous) Eval Time (s)     13.761584427207708
Sample Time (s)              6.35015120357275
Epoch Time (s)               166.1857252768241
Total Train Time (s)         31257.588176565245
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:01:34.429458 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #187 | Epoch Duration: 166.28987431526184
2020-01-11 17:01:34.429696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96566087
Z variance train             0.01133103
KL Divergence                19.94632
KL Loss                      1.994632
QF Loss                      1126.9502
VF Loss                      228.03497
Policy Loss                  -967.91223
Q Predictions Mean           958.3718
Q Predictions Std            398.83115
Q Predictions Max            1523.0443
Q Predictions Min            -37.197006
V Predictions Mean           971.5521
V Predictions Std            388.92758
V Predictions Max            1528.7806
V Predictions Min            251.6441
Log Pis Mean                 0.690408
Log Pis Std                  4.2196136
Log Pis Max                  19.424011
Log Pis Min                  -9.175593
Policy mu Mean               -0.05828146
Policy mu Std                0.6581722
Policy mu Max                3.11894
Policy mu Min                -3.5609157
Policy log std Mean          -1.0497863
Policy log std Std           0.2806452
Policy log std Max           -0.18795264
Policy log std Min           -2.2930627
Z mean eval                  1.0836462
Z variance eval              0.020322114
total_rewards                [3973.05081309 3765.12299505 3017.86831482 2377.88259006  205.61715941
 3869.472106   3972.83970042 2551.88310428 4114.47834206  655.86714082]
total_rewards_mean           2850.4082265997404
total_rewards_std            1347.0195736664027
total_rewards_max            4114.478342055876
total_rewards_min            205.61715940834716
Number of train steps total  756000
Number of env steps total    734328
Number of rollouts total     0
Train Time (s)               145.35551790799946
(Previous) Eval Time (s)     15.84976252913475
Sample Time (s)              7.466439674142748
Epoch Time (s)               168.67172011127695
Total Train Time (s)         31426.388937205542
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:04:23.232075 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #188 | Epoch Duration: 168.80219650268555
2020-01-11 17:04:23.232255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0773983
Z variance train             0.020244721
KL Divergence                19.241018
KL Loss                      1.9241018
QF Loss                      968.2784
VF Loss                      153.89914
Policy Loss                  -897.70807
Q Predictions Mean           889.86035
Q Predictions Std            397.1716
Q Predictions Max            1417.234
Q Predictions Min            220.22862
V Predictions Mean           901.429
V Predictions Std            396.59296
V Predictions Max            1439.5269
V Predictions Min            239.74619
Log Pis Mean                 0.2321886
Log Pis Std                  3.4558337
Log Pis Max                  14.147514
Log Pis Min                  -7.5504436
Policy mu Mean               -0.028359152
Policy mu Std                0.6114945
Policy mu Max                2.6822453
Policy mu Min                -3.548996
Policy log std Mean          -1.0341537
Policy log std Std           0.27168187
Policy log std Max           -0.43618643
Policy log std Min           -2.2378774
Z mean eval                  1.0189764
Z variance eval              0.0099979
total_rewards                [2306.2119066  2917.21535532 3938.00921839  361.04891297  654.75300627
  916.83123257 3870.56287406  281.58083747 3812.7963876  2683.05644408]
total_rewards_mean           2174.2066175338086
total_rewards_std            1423.422687242945
total_rewards_max            3938.0092183918614
total_rewards_min            281.5808374743889
Number of train steps total  760000
Number of env steps total    739572
Number of rollouts total     0
Train Time (s)               146.64801422692835
(Previous) Eval Time (s)     16.3490223409608
Sample Time (s)              7.366635449696332
Epoch Time (s)               170.3636720175855
Total Train Time (s)         31596.84567185305
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:07:13.689254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #189 | Epoch Duration: 170.4568736553192
2020-01-11 17:07:13.689395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0095627
Z variance train             0.009995751
KL Divergence                20.775831
KL Loss                      2.077583
QF Loss                      861.33014
VF Loss                      295.53552
Policy Loss                  -950.5934
Q Predictions Mean           939.58374
Q Predictions Std            404.55777
Q Predictions Max            1467.1865
Q Predictions Min            28.791063
V Predictions Mean           952.31506
V Predictions Std            401.73288
V Predictions Max            1478.7079
V Predictions Min            216.00443
Log Pis Mean                 -0.20862114
Log Pis Std                  3.1605017
Log Pis Max                  12.030825
Log Pis Min                  -8.627219
Policy mu Mean               -0.0344094
Policy mu Std                0.5626647
Policy mu Max                2.3732119
Policy mu Min                -3.3749452
Policy log std Mean          -1.0251496
Policy log std Std           0.2578503
Policy log std Max           -0.47051072
Policy log std Min           -2.1193109
Z mean eval                  1.0944139
Z variance eval              0.018316392
total_rewards                [3797.0815918  1460.66359794 3785.95484162  336.24749936 3620.86553069
 4120.82868052 2129.98273193 3968.54468377 4177.40838573 4323.42238787]
total_rewards_mean           3172.0999931222477
total_rewards_std            1299.8650336504227
total_rewards_max            4323.422387871407
total_rewards_min            336.24749936285895
Number of train steps total  764000
Number of env steps total    749146
Number of rollouts total     0
Train Time (s)               148.34196539176628
(Previous) Eval Time (s)     19.535854670219123
Sample Time (s)              6.406825363170356
Epoch Time (s)               174.28464542515576
Total Train Time (s)         31771.241776032373
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:10:08.088248 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #190 | Epoch Duration: 174.39874958992004
2020-01-11 17:10:08.088400 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #190 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0970243
Z variance train             0.018394597
KL Divergence                18.16038
KL Loss                      1.816038
QF Loss                      682.9336
VF Loss                      310.04874
Policy Loss                  -913.47406
Q Predictions Mean           905.4927
Q Predictions Std            430.7485
Q Predictions Max            1494.6484
Q Predictions Min            7.354807
V Predictions Mean           906.3407
V Predictions Std            423.75082
V Predictions Max            1468.0415
V Predictions Min            -91.52197
Log Pis Mean                 0.15683404
Log Pis Std                  3.5692506
Log Pis Max                  22.997894
Log Pis Min                  -7.876313
Policy mu Mean               -0.027949331
Policy mu Std                0.6020087
Policy mu Max                3.6558008
Policy mu Min                -6.6989822
Policy log std Mean          -1.0321013
Policy log std Std           0.27426764
Policy log std Max           0.51896095
Policy log std Min           -2.195915
Z mean eval                  0.98097163
Z variance eval              0.0144723235
total_rewards                [3393.23182862 3631.44190049 4069.17881691  582.54567132 3311.1335783
 3865.56530574 4169.53557248 1256.73163733 1098.56653035 1552.48970013]
total_rewards_mean           2693.0420541676685
total_rewards_std            1325.212732462465
total_rewards_max            4169.535572480344
total_rewards_min            582.5456713201484
Number of train steps total  768000
Number of env steps total    754239
Number of rollouts total     0
Train Time (s)               146.28636868530884
(Previous) Eval Time (s)     16.670070738065988
Sample Time (s)              7.290587138850242
Epoch Time (s)               170.24702656222507
Total Train Time (s)         31941.596232076176
Epoch                        191
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:12:58.443221 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #191 | Epoch Duration: 170.35470461845398
2020-01-11 17:12:58.443345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9767516
Z variance train             0.014395962
KL Divergence                19.194796
KL Loss                      1.9194796
QF Loss                      1025.941
VF Loss                      177.5672
Policy Loss                  -943.02124
Q Predictions Mean           933.9285
Q Predictions Std            423.2407
Q Predictions Max            1497.639
Q Predictions Min            22.19976
V Predictions Mean           938.96716
V Predictions Std            419.37167
V Predictions Max            1501.3877
V Predictions Min            -51.447117
Log Pis Mean                 0.05232015
Log Pis Std                  3.7756188
Log Pis Max                  22.631763
Log Pis Min                  -9.80648
Policy mu Mean               0.015368539
Policy mu Std                0.5962881
Policy mu Max                3.0854425
Policy mu Min                -3.0494678
Policy log std Mean          -1.023535
Policy log std Std           0.26947495
Policy log std Max           -0.41885006
Policy log std Min           -2.2026968
Z mean eval                  0.99962217
Z variance eval              0.0076431953
total_rewards                [4164.60003877 4094.48443453 4021.64953832 2643.60715059 3742.39398364
  720.50613637 3915.61319517 3647.90974448  899.83213222  534.72494778]
total_rewards_mean           2838.532130187523
total_rewards_std            1447.6849159104606
total_rewards_max            4164.600038772851
total_rewards_min            534.7249477820494
Number of train steps total  772000
Number of env steps total    760651
Number of rollouts total     0
Train Time (s)               145.89011958194897
(Previous) Eval Time (s)     16.767739336006343
Sample Time (s)              6.153077217750251
Epoch Time (s)               168.81093613570556
Total Train Time (s)         32110.490391077008
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:15:47.340335 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #192 | Epoch Duration: 168.89689445495605
2020-01-11 17:15:47.340450 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #192 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9984132
Z variance train             0.00762529
KL Divergence                20.746666
KL Loss                      2.0746667
QF Loss                      1306.8315
VF Loss                      467.40408
Policy Loss                  -949.427
Q Predictions Mean           937.8403
Q Predictions Std            412.3887
Q Predictions Max            1469.5573
Q Predictions Min            32.514946
V Predictions Mean           944.20996
V Predictions Std            404.65518
V Predictions Max            1469.7632
V Predictions Min            19.653816
Log Pis Mean                 0.36725026
Log Pis Std                  4.189255
Log Pis Max                  22.188837
Log Pis Min                  -8.027514
Policy mu Mean               -0.028252197
Policy mu Std                0.61431116
Policy mu Max                3.6131928
Policy mu Min                -4.2241874
Policy log std Mean          -1.0350225
Policy log std Std           0.26778758
Policy log std Max           -0.2270065
Policy log std Min           -2.5724604
Z mean eval                  1.0673708
Z variance eval              0.07364611
total_rewards                [1.47310159e+03 5.18855255e+01 4.50479985e-01 1.08428418e+03
 9.43766148e+02 1.20511526e+03 2.93501267e+03 3.69424723e+02
 1.48859248e+02 3.96633189e+03]
total_rewards_mean           1217.8231719488972
total_rewards_std            1239.5635960201396
total_rewards_max            3966.3318921171654
total_rewards_min            0.4504799852164103
Number of train steps total  776000
Number of env steps total    765341
Number of rollouts total     0
Train Time (s)               146.82905020425096
(Previous) Eval Time (s)     7.213467315770686
Sample Time (s)              6.338642593007535
Epoch Time (s)               160.38116011302918
Total Train Time (s)         32271.189930165652
Epoch                        193
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:18:28.061091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #193 | Epoch Duration: 160.72048997879028
2020-01-11 17:18:28.061402 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.065923
Z variance train             0.07350131
KL Divergence                17.10475
KL Loss                      1.710475
QF Loss                      773.86206
VF Loss                      132.28006
Policy Loss                  -945.3285
Q Predictions Mean           935.25165
Q Predictions Std            415.5766
Q Predictions Max            1501.9779
Q Predictions Min            -2.2499056
V Predictions Mean           941.8185
V Predictions Std            409.94327
V Predictions Max            1488.7985
V Predictions Min            185.75456
Log Pis Mean                 -0.022709265
Log Pis Std                  3.3601851
Log Pis Max                  18.102911
Log Pis Min                  -6.3264027
Policy mu Mean               -0.010850308
Policy mu Std                0.5885818
Policy mu Max                4.508485
Policy mu Min                -2.7557597
Policy log std Mean          -1.0205272
Policy log std Std           0.23760498
Policy log std Max           -0.3544563
Policy log std Min           -2.0562518
Z mean eval                  0.96866035
Z variance eval              0.009717045
total_rewards                [1431.58580301 3374.73010633 3208.03113603  815.03505067  259.17220799
  244.52574456 2991.57716891  269.12610288 3922.32256221 1821.09644427]
total_rewards_mean           1833.7202326839774
total_rewards_std            1364.5006639502394
total_rewards_max            3922.322562205017
total_rewards_min            244.52574455542657
Number of train steps total  780000
Number of env steps total    771262
Number of rollouts total     0
Train Time (s)               146.3558091428131
(Previous) Eval Time (s)     10.084108541253954
Sample Time (s)              7.944081384688616
Epoch Time (s)               164.38399906875566
Total Train Time (s)         32435.724045522977
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:21:12.578906 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #194 | Epoch Duration: 164.5172781944275
2020-01-11 17:21:12.579071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9662136
Z variance train             0.009681569
KL Divergence                19.881096
KL Loss                      1.9881096
QF Loss                      691.33435
VF Loss                      224.0809
Policy Loss                  -943.25385
Q Predictions Mean           935.45575
Q Predictions Std            424.57294
Q Predictions Max            1482.7009
Q Predictions Min            8.934256
V Predictions Mean           946.0934
V Predictions Std            419.3464
V Predictions Max            1488.8472
V Predictions Min            -37.258698
Log Pis Mean                 0.2274198
Log Pis Std                  3.5405564
Log Pis Max                  18.948536
Log Pis Min                  -6.3601847
Policy mu Mean               -0.03768345
Policy mu Std                0.6083994
Policy mu Max                3.2338173
Policy mu Min                -3.7944565
Policy log std Mean          -1.033303
Policy log std Std           0.26410025
Policy log std Max           -0.30067486
Policy log std Min           -2.27455
Z mean eval                  0.9741621
Z variance eval              0.01791097
total_rewards                [ 132.75196432 3844.70567546  697.09079872 1717.48639072  728.49181257
 1049.97505958 3014.61229154 3853.33707769 3642.51262874 4105.88346315]
total_rewards_mean           2278.6847162497666
total_rewards_std            1483.457402524984
total_rewards_max            4105.88346315249
total_rewards_min            132.75196432133401
Number of train steps total  784000
Number of env steps total    776181
Number of rollouts total     0
Train Time (s)               146.2530287830159
(Previous) Eval Time (s)     13.601720039732754
Sample Time (s)              6.4984885305166245
Epoch Time (s)               166.35323735326529
Total Train Time (s)         32602.195011248812
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:23:59.051658 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #195 | Epoch Duration: 166.47245359420776
2020-01-11 17:23:59.051834 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9734227
Z variance train             0.017906498
KL Divergence                18.46921
KL Loss                      1.846921
QF Loss                      1599.7615
VF Loss                      286.5235
Policy Loss                  -974.7819
Q Predictions Mean           966.3819
Q Predictions Std            436.6548
Q Predictions Max            1488.0323
Q Predictions Min            39.372875
V Predictions Mean           973.14514
V Predictions Std            430.43753
V Predictions Max            1490.4087
V Predictions Min            233.76215
Log Pis Mean                 0.026423603
Log Pis Std                  3.3160796
Log Pis Max                  18.96537
Log Pis Min                  -6.276272
Policy mu Mean               -0.033420686
Policy mu Std                0.61105245
Policy mu Max                3.1153047
Policy mu Min                -4.195901
Policy log std Mean          -1.022346
Policy log std Std           0.2633428
Policy log std Max           -0.40392113
Policy log std Min           -2.1647992
Z mean eval                  0.9889854
Z variance eval              0.012003005
total_rewards                [1548.45825701   54.60689007 4213.97747636 2081.85057091  329.28603675
 4250.11609654 4222.74974257  751.90969087 2278.2953916  3804.13364685]
total_rewards_mean           2353.5383799535625
total_rewards_std            1591.601275195965
total_rewards_max            4250.116096543373
total_rewards_min            54.60689007144457
Number of train steps total  788000
Number of env steps total    783214
Number of rollouts total     0
Train Time (s)               146.7023762143217
(Previous) Eval Time (s)     15.346511128358543
Sample Time (s)              7.743813758715987
Epoch Time (s)               169.79270110139623
Total Train Time (s)         32772.07292625308
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:26:48.931111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #196 | Epoch Duration: 169.87915444374084
2020-01-11 17:26:48.931246 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9851629
Z variance train             0.012068039
KL Divergence                19.595224
KL Loss                      1.9595225
QF Loss                      901.95557
VF Loss                      264.7753
Policy Loss                  -985.32635
Q Predictions Mean           979.9925
Q Predictions Std            409.26508
Q Predictions Max            1474.6364
Q Predictions Min            194.96878
V Predictions Mean           990.42834
V Predictions Std            404.73483
V Predictions Max            1478.6836
V Predictions Min            253.29065
Log Pis Mean                 0.14786525
Log Pis Std                  3.387923
Log Pis Max                  11.799272
Log Pis Min                  -8.905331
Policy mu Mean               -0.029199779
Policy mu Std                0.59352154
Policy mu Max                2.7769978
Policy mu Min                -3.2147021
Policy log std Mean          -1.0373263
Policy log std Std           0.26887637
Policy log std Max           -0.08566189
Policy log std Min           -2.252294
Z mean eval                  0.99847126
Z variance eval              0.024567526
total_rewards                [1303.50685899 2123.17623756 3797.15707558 1525.71417584 1595.68495585
  122.55772227  584.04962393  486.20242788 2763.63110778  494.61274239]
total_rewards_mean           1479.6292928073642
total_rewards_std            1099.1460745215716
total_rewards_max            3797.157075584053
total_rewards_min            122.5577222726555
Number of train steps total  792000
Number of env steps total    792083
Number of rollouts total     0
Train Time (s)               146.50620553130284
(Previous) Eval Time (s)     12.000978169031441
Sample Time (s)              6.73223778558895
Epoch Time (s)               165.23942148592323
Total Train Time (s)         32937.4480982041
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:29:34.308041 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #197 | Epoch Duration: 165.37670063972473
2020-01-11 17:29:34.308163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99859
Z variance train             0.024456374
KL Divergence                17.804579
KL Loss                      1.7804579
QF Loss                      1130.4387
VF Loss                      192.93643
Policy Loss                  -958.4227
Q Predictions Mean           954.64557
Q Predictions Std            401.41663
Q Predictions Max            1466.6393
Q Predictions Min            -42.921795
V Predictions Mean           949.5812
V Predictions Std            398.63834
V Predictions Max            1446.3124
V Predictions Min            128.43236
Log Pis Mean                 -0.34201628
Log Pis Std                  3.0247014
Log Pis Max                  12.389925
Log Pis Min                  -9.421332
Policy mu Mean               -0.03243698
Policy mu Std                0.56018585
Policy mu Max                2.7570705
Policy mu Min                -3.0637217
Policy log std Mean          -1.004919
Policy log std Std           0.23879197
Policy log std Max           -0.3493793
Policy log std Min           -2.3247275
Z mean eval                  1.106484
Z variance eval              0.0042664623
total_rewards                [1702.9879382   546.46310871 2511.89993345  487.59535737 4133.33273894
 2515.86866827 1088.5874529  4169.28989614 3813.77485203 2362.03083949]
total_rewards_mean           2333.1830785508027
total_rewards_std            1319.6534185463195
total_rewards_max            4169.289896136439
total_rewards_min            487.59535737227606
Number of train steps total  796000
Number of env steps total    797688
Number of rollouts total     0
Train Time (s)               144.84327322803438
(Previous) Eval Time (s)     15.898155812174082
Sample Time (s)              8.522996463812888
Epoch Time (s)               169.26442550402135
Total Train Time (s)         33106.79933978198
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:32:23.661422 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #198 | Epoch Duration: 169.35315346717834
2020-01-11 17:32:23.661589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0970736
Z variance train             0.004280771
KL Divergence                22.117966
KL Loss                      2.2117965
QF Loss                      1250.5499
VF Loss                      114.133194
Policy Loss                  -996.34186
Q Predictions Mean           991.72095
Q Predictions Std            429.1361
Q Predictions Max            1493.7928
Q Predictions Min            237.39876
V Predictions Mean           999.5984
V Predictions Std            425.98962
V Predictions Max            1486.3169
V Predictions Min            259.76495
Log Pis Mean                 0.14760594
Log Pis Std                  3.221073
Log Pis Max                  12.8441105
Log Pis Min                  -6.804487
Policy mu Mean               -0.027325157
Policy mu Std                0.58101726
Policy mu Max                2.586657
Policy mu Min                -2.6721663
Policy log std Mean          -1.0289016
Policy log std Std           0.26801506
Policy log std Max           -0.3486399
Policy log std Min           -2.1160467
Z mean eval                  1.0263855
Z variance eval              0.008313155
total_rewards                [2714.74482388 3789.77384212 3927.12919428  730.79581045  540.71501485
 3653.53636491  484.92620051  928.67318741 4482.35806013 1885.26747898]
total_rewards_mean           2313.791997753079
total_rewards_std            1501.2112650199206
total_rewards_max            4482.358060134872
total_rewards_min            484.9262005077487
Number of train steps total  800000
Number of env steps total    803475
Number of rollouts total     0
Train Time (s)               145.64935637405142
(Previous) Eval Time (s)     16.999195764306933
Sample Time (s)              8.29861864214763
Epoch Time (s)               170.94717078050599
Total Train Time (s)         33277.84557091165
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:35:14.711060 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #199 | Epoch Duration: 171.04932522773743
2020-01-11 17:35:14.711269 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.027518
Z variance train             0.008278322
KL Divergence                21.701307
KL Loss                      2.1701307
QF Loss                      628.155
VF Loss                      91.088776
Policy Loss                  -1003.676
Q Predictions Mean           999.21216
Q Predictions Std            408.07874
Q Predictions Max            1486.3071
Q Predictions Min            242.90819
V Predictions Mean           1004.7733
V Predictions Std            405.19714
V Predictions Max            1476.8945
V Predictions Min            253.59343
Log Pis Mean                 0.34811854
Log Pis Std                  3.2659123
Log Pis Max                  17.92765
Log Pis Min                  -12.27006
Policy mu Mean               -0.029904459
Policy mu Std                0.59747887
Policy mu Max                2.4261546
Policy mu Min                -3.383633
Policy log std Mean          -1.0208929
Policy log std Std           0.25131088
Policy log std Max           -0.29177922
Policy log std Min           -2.676908
Z mean eval                  1.075541
Z variance eval              0.02535868
total_rewards                [4376.94799064 4118.60811812 4173.20959191 2823.14213658 1862.91715523
 4146.5826598  4160.27317422 1323.87933164 4242.47496115 4153.34660599]
total_rewards_mean           3538.1381725294355
total_rewards_std            1062.8366930947036
total_rewards_max            4376.947990639165
total_rewards_min            1323.8793316435356
Number of train steps total  804000
Number of env steps total    813751
Number of rollouts total     0
Train Time (s)               146.48526863800362
(Previous) Eval Time (s)     21.096965411212295
Sample Time (s)              7.481994323898107
Epoch Time (s)               175.06422837311402
Total Train Time (s)         33453.01263969857
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:38:09.882760 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #200 | Epoch Duration: 175.1712372303009
2020-01-11 17:38:09.883160 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0867828
Z variance train             0.02567625
KL Divergence                19.715958
KL Loss                      1.9715958
QF Loss                      810.87195
VF Loss                      258.0076
Policy Loss                  -937.3791
Q Predictions Mean           932.0427
Q Predictions Std            444.6237
Q Predictions Max            1555.6837
Q Predictions Min            28.497086
V Predictions Mean           939.20526
V Predictions Std            439.44434
V Predictions Max            1550.2166
V Predictions Min            36.19485
Log Pis Mean                 0.07044952
Log Pis Std                  3.4366534
Log Pis Max                  16.753685
Log Pis Min                  -6.955448
Policy mu Mean               -0.04147126
Policy mu Std                0.5734066
Policy mu Max                2.28936
Policy mu Min                -2.6614902
Policy log std Mean          -1.038644
Policy log std Std           0.26459637
Policy log std Max           -0.3602103
Policy log std Min           -2.1046581
Z mean eval                  1.1066185
Z variance eval              0.022489024
total_rewards                [1281.83212167 4298.69081477  693.05213414 1548.94541408 4204.98026517
 3920.77890008 3034.47182173 3931.30424764 4158.56566922 3008.40087887]
total_rewards_mean           3008.1022267366984
total_rewards_std            1287.4891149803543
total_rewards_max            4298.690814765933
total_rewards_min            693.0521341371286
Number of train steps total  808000
Number of env steps total    822645
Number of rollouts total     0
Train Time (s)               146.0255455323495
(Previous) Eval Time (s)     24.59489715890959
Sample Time (s)              7.835295269731432
Epoch Time (s)               178.45573796099052
Total Train Time (s)         33631.61185153853
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:41:08.489006 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #201 | Epoch Duration: 178.60560369491577
2020-01-11 17:41:08.489241 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1041176
Z variance train             0.022293357
KL Divergence                19.224743
KL Loss                      1.9224743
QF Loss                      1273.6146
VF Loss                      123.31108
Policy Loss                  -946.47485
Q Predictions Mean           939.51807
Q Predictions Std            426.44754
Q Predictions Max            1522.5878
Q Predictions Min            -16.459303
V Predictions Mean           945.0287
V Predictions Std            420.65576
V Predictions Max            1504.9531
V Predictions Min            242.22939
Log Pis Mean                 -0.1410791
Log Pis Std                  3.2449856
Log Pis Max                  16.323524
Log Pis Min                  -6.899194
Policy mu Mean               0.006915077
Policy mu Std                0.580693
Policy mu Max                2.8404431
Policy mu Min                -2.8152485
Policy log std Mean          -1.0148822
Policy log std Std           0.25423717
Policy log std Max           -0.39867634
Policy log std Min           -2.0813046
Z mean eval                  1.0454803
Z variance eval              0.020352583
total_rewards                [3809.27065046  321.33724029 2789.4413535   357.13689604 1134.66039789
 2633.7702657   849.94889888 3783.25636765 3888.59687673  563.01905759]
total_rewards_mean           2013.0438004720163
total_rewards_std            1438.6345938220545
total_rewards_max            3888.5968767315217
total_rewards_min            321.3372402853635
Number of train steps total  812000
Number of env steps total    830590
Number of rollouts total     0
Train Time (s)               146.68654620228335
(Previous) Eval Time (s)     15.061517607886344
Sample Time (s)              8.019050480797887
Epoch Time (s)               169.76711429096758
Total Train Time (s)         33801.477300354745
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:43:58.353443 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #202 | Epoch Duration: 169.8640275001526
2020-01-11 17:43:58.353619 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0453771
Z variance train             0.020308064
KL Divergence                18.300001
KL Loss                      1.8300002
QF Loss                      1424.4958
VF Loss                      746.1086
Policy Loss                  -945.57806
Q Predictions Mean           941.87384
Q Predictions Std            448.71017
Q Predictions Max            1542.5089
Q Predictions Min            230.37842
V Predictions Mean           949.8434
V Predictions Std            444.0083
V Predictions Max            1537.6882
V Predictions Min            252.26915
Log Pis Mean                 -0.46611315
Log Pis Std                  3.2724612
Log Pis Max                  16.281427
Log Pis Min                  -8.0167885
Policy mu Mean               -0.046498343
Policy mu Std                0.5428455
Policy mu Max                2.5035605
Policy mu Min                -2.4583673
Policy log std Mean          -1.0089105
Policy log std Std           0.27272835
Policy log std Max           -0.31869024
Policy log std Min           -2.4437163
Z mean eval                  0.9780658
Z variance eval              0.011205504
total_rewards                [4086.75360879 4313.1468201  4310.20447156 3778.70035402 1721.84295239
 4185.17999961 4010.79855324 1833.39540407 4085.39544703 4037.93248235]
total_rewards_mean           3636.335009316995
total_rewards_std            941.04089804083
total_rewards_max            4313.146820102701
total_rewards_min            1721.842952391397
Number of train steps total  816000
Number of env steps total    838775
Number of rollouts total     0
Train Time (s)               145.89744283584878
(Previous) Eval Time (s)     21.86755714705214
Sample Time (s)              7.662750998046249
Epoch Time (s)               175.42775098094717
Total Train Time (s)         33977.07098672306
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:46:53.948502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #203 | Epoch Duration: 175.59476041793823
2020-01-11 17:46:53.948638 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #203 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9799277
Z variance train             0.011154899
KL Divergence                18.766417
KL Loss                      1.8766416
QF Loss                      1088.7742
VF Loss                      139.35526
Policy Loss                  -958.74805
Q Predictions Mean           952.2605
Q Predictions Std            417.5192
Q Predictions Max            1517.7343
Q Predictions Min            -10.723867
V Predictions Mean           953.9889
V Predictions Std            415.47873
V Predictions Max            1503.8796
V Predictions Min            7.221628
Log Pis Mean                 -0.08957751
Log Pis Std                  3.0979927
Log Pis Max                  11.684072
Log Pis Min                  -8.420761
Policy mu Mean               0.004557793
Policy mu Std                0.60104746
Policy mu Max                2.694278
Policy mu Min                -2.2771592
Policy log std Mean          -1.0168535
Policy log std Std           0.26936466
Policy log std Max           -0.21294701
Policy log std Min           -2.3977795
Z mean eval                  0.9980453
Z variance eval              0.080431156
total_rewards                [3910.99702421 3954.79917678 3513.40833036 4016.54821205 3682.9316799
 4050.96328055  377.36276073 2479.29436868  413.51431712 3848.05170251]
total_rewards_mean           3024.787085288441
total_rewards_std            1384.2597750740108
total_rewards_max            4050.9632805499837
total_rewards_min            377.36276072685376
Number of train steps total  820000
Number of env steps total    844935
Number of rollouts total     0
Train Time (s)               146.13265453791246
(Previous) Eval Time (s)     16.30128585314378
Sample Time (s)              6.372339003253728
Epoch Time (s)               168.80627939430997
Total Train Time (s)         34145.996935153846
Epoch                        204
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:49:42.876661 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #204 | Epoch Duration: 168.92792510986328
2020-01-11 17:49:42.876788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.995704
Z variance train             0.081096336
KL Divergence                17.081089
KL Loss                      1.7081089
QF Loss                      899.79736
VF Loss                      195.47878
Policy Loss                  -962.31415
Q Predictions Mean           956.2511
Q Predictions Std            442.7918
Q Predictions Max            1522.8455
Q Predictions Min            -9.250956
V Predictions Mean           964.0538
V Predictions Std            435.0163
V Predictions Max            1518.8335
V Predictions Min            232.99577
Log Pis Mean                 -0.011836238
Log Pis Std                  3.482695
Log Pis Max                  24.833504
Log Pis Min                  -6.964245
Policy mu Mean               -0.028543834
Policy mu Std                0.62530756
Policy mu Max                3.2777116
Policy mu Min                -4.7068787
Policy log std Mean          -0.99544305
Policy log std Std           0.24649593
Policy log std Max           -0.25984502
Policy log std Min           -2.141951
Z mean eval                  1.0359024
Z variance eval              0.015746787
total_rewards                [4075.98492351  541.31230516 1502.30026407  112.26357208 1024.09356483
 3708.8862257  4063.72089548 2736.31663918 3969.61999225 1711.56752993]
total_rewards_mean           2344.606591217617
total_rewards_std            1473.0101102447138
total_rewards_max            4075.984923509743
total_rewards_min            112.26357208028135
Number of train steps total  824000
Number of env steps total    853282
Number of rollouts total     0
Train Time (s)               145.54116195905954
(Previous) Eval Time (s)     15.875627958681434
Sample Time (s)              6.528131159953773
Epoch Time (s)               167.94492107769474
Total Train Time (s)         34314.026555066
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:52:30.908574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #205 | Epoch Duration: 168.0316891670227
2020-01-11 17:52:30.908704 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.040638
Z variance train             0.01565608
KL Divergence                18.378765
KL Loss                      1.8378766
QF Loss                      768.3849
VF Loss                      345.0705
Policy Loss                  -962.5803
Q Predictions Mean           953.39874
Q Predictions Std            414.93826
Q Predictions Max            1500.7117
Q Predictions Min            -40.140682
V Predictions Mean           959.448
V Predictions Std            400.6816
V Predictions Max            1495.2566
V Predictions Min            249.68715
Log Pis Mean                 0.34243646
Log Pis Std                  4.515491
Log Pis Max                  48.00788
Log Pis Min                  -8.8026085
Policy mu Mean               -0.0059245154
Policy mu Std                0.657779
Policy mu Max                5.7245746
Policy mu Min                -6.163916
Policy log std Mean          -1.003534
Policy log std Std           0.26340622
Policy log std Max           -0.2306562
Policy log std Min           -2.1583846
Z mean eval                  1.0059198
Z variance eval              0.0066949725
total_rewards                [3931.93291956  401.47688526 3202.26177196 4015.25271532  181.06093872
 2921.51412261 2366.48224247 4012.68120217  755.65301201 2710.48402491]
total_rewards_mean           2449.879983498521
total_rewards_std            1420.088280779381
total_rewards_max            4015.2527153226497
total_rewards_min            181.060938715662
Number of train steps total  828000
Number of env steps total    862773
Number of rollouts total     0
Train Time (s)               146.639030165039
(Previous) Eval Time (s)     16.27844032505527
Sample Time (s)              6.789474962744862
Epoch Time (s)               169.70694545283914
Total Train Time (s)         34483.822135547176
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:55:20.706807 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #206 | Epoch Duration: 169.79799365997314
2020-01-11 17:55:20.706968 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0043907
Z variance train             0.006693515
KL Divergence                20.319082
KL Loss                      2.0319083
QF Loss                      773.3015
VF Loss                      173.11894
Policy Loss                  -979.2322
Q Predictions Mean           973.86304
Q Predictions Std            419.73102
Q Predictions Max            1508.2039
Q Predictions Min            148.55545
V Predictions Mean           972.8826
V Predictions Std            419.95264
V Predictions Max            1491.7131
V Predictions Min            230.35442
Log Pis Mean                 -0.10107297
Log Pis Std                  2.8787823
Log Pis Max                  9.710861
Log Pis Min                  -7.5364847
Policy mu Mean               0.016150726
Policy mu Std                0.56562483
Policy mu Max                2.499324
Policy mu Min                -3.3654377
Policy log std Mean          -1.0284669
Policy log std Std           0.255409
Policy log std Max           -0.23199046
Policy log std Min           -2.2083058
Z mean eval                  1.1637316
Z variance eval              0.007633727
total_rewards                [  37.34771869 2370.17035601 3084.51136216 4240.10298989 4094.97386058
 1251.67046104 2734.92715302 4328.28235895 4190.45986039 1003.92145062]
total_rewards_mean           2733.636757134423
total_rewards_std            1466.3302346584305
total_rewards_max            4328.2823589499985
total_rewards_min            37.34771868769158
Number of train steps total  832000
Number of env steps total    871228
Number of rollouts total     0
Train Time (s)               146.78137473296374
(Previous) Eval Time (s)     14.203047099057585
Sample Time (s)              6.386096029076725
Epoch Time (s)               167.37051786109805
Total Train Time (s)         34651.30522143422
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 17:58:08.190714 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #207 | Epoch Duration: 167.4836277961731
2020-01-11 17:58:08.190853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1742522
Z variance train             0.0076282383
KL Divergence                20.431442
KL Loss                      2.0431442
QF Loss                      806.45325
VF Loss                      318.45837
Policy Loss                  -950.83344
Q Predictions Mean           943.1322
Q Predictions Std            414.00897
Q Predictions Max            1499.8187
Q Predictions Min            247.02719
V Predictions Mean           955.1763
V Predictions Std            415.9025
V Predictions Max            1509.9717
V Predictions Min            248.59492
Log Pis Mean                 -0.04923574
Log Pis Std                  3.5895457
Log Pis Max                  23.542263
Log Pis Min                  -7.037791
Policy mu Mean               0.015211677
Policy mu Std                0.61887103
Policy mu Max                3.7216706
Policy mu Min                -3.231172
Policy log std Mean          -0.9940241
Policy log std Std           0.24438335
Policy log std Max           -0.35667104
Policy log std Min           -2.130005
Z mean eval                  1.0429016
Z variance eval              0.022797177
total_rewards                [4057.84986399 3872.17790399 4135.57264232 4286.6622705   609.4045052
 3384.61119537 4164.94459028  929.09770119 1028.86950937 4228.30267512]
total_rewards_mean           3069.7492857351726
total_rewards_std            1472.3723618859876
total_rewards_max            4286.662270501227
total_rewards_min            609.4045052017594
Number of train steps total  836000
Number of env steps total    880124
Number of rollouts total     0
Train Time (s)               144.7979057370685
(Previous) Eval Time (s)     18.401752497069538
Sample Time (s)              6.317520655691624
Epoch Time (s)               169.51717888982967
Total Train Time (s)         34820.95375069184
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:00:57.842020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #208 | Epoch Duration: 169.65105390548706
2020-01-11 18:00:57.842189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0437009
Z variance train             0.022690216
KL Divergence                18.223358
KL Loss                      1.8223358
QF Loss                      1051.579
VF Loss                      245.05478
Policy Loss                  -921.5919
Q Predictions Mean           918.8345
Q Predictions Std            417.1945
Q Predictions Max            1487.4188
Q Predictions Min            -5.5760245
V Predictions Mean           925.89575
V Predictions Std            415.5149
V Predictions Max            1479.8955
V Predictions Min            -52.907635
Log Pis Mean                 0.34232062
Log Pis Std                  3.8996964
Log Pis Max                  21.19361
Log Pis Min                  -7.884131
Policy mu Mean               -0.042218775
Policy mu Std                0.63120115
Policy mu Max                4.350564
Policy mu Min                -2.1933577
Policy log std Mean          -1.0360794
Policy log std Std           0.27526572
Policy log std Max           -0.410267
Policy log std Min           -2.5019758
Z mean eval                  1.051468
Z variance eval              0.016265903
total_rewards                [ 420.38707957 4148.62060315 1907.64473433 4395.71758329 2340.82813478
 3427.27228875 4111.07209908 2722.15902426 3988.56563665 4050.63512184]
total_rewards_mean           3151.2902305688754
total_rewards_std            1220.4898410201629
total_rewards_max            4395.717583288467
total_rewards_min            420.387079566941
Number of train steps total  840000
Number of env steps total    888919
Number of rollouts total     0
Train Time (s)               147.0929756858386
(Previous) Eval Time (s)     19.438848675228655
Sample Time (s)              7.327887495048344
Epoch Time (s)               173.8597118561156
Total Train Time (s)         34994.97991342284
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:03:51.875210 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #209 | Epoch Duration: 174.03288626670837
2020-01-11 18:03:51.875395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0349038
Z variance train             0.016174952
KL Divergence                21.315437
KL Loss                      2.1315439
QF Loss                      896.4804
VF Loss                      306.25653
Policy Loss                  -942.8086
Q Predictions Mean           938.2213
Q Predictions Std            440.40247
Q Predictions Max            1498.2913
Q Predictions Min            166.95935
V Predictions Mean           953.4903
V Predictions Std            439.04773
V Predictions Max            1503.3655
V Predictions Min            259.58722
Log Pis Mean                 -0.4549644
Log Pis Std                  3.2930562
Log Pis Max                  13.350702
Log Pis Min                  -11.158331
Policy mu Mean               0.013519681
Policy mu Std                0.57071036
Policy mu Max                3.0893512
Policy mu Min                -2.1267655
Policy log std Mean          -0.9795192
Policy log std Std           0.26064324
Policy log std Max           -0.28749907
Policy log std Min           -2.177227
Z mean eval                  1.0434912
Z variance eval              0.027630746
total_rewards                [3930.10400205 2260.37248    4185.2298025  3715.94113688 1575.07545012
 3963.05024039 3977.18328252 4181.66404773  802.30201667 4004.45740598]
total_rewards_mean           3259.5379864843067
total_rewards_std            1174.8952289026095
total_rewards_max            4185.229802497701
total_rewards_min            802.3020166704332
Number of train steps total  844000
Number of env steps total    894850
Number of rollouts total     0
Train Time (s)               145.49194320384413
(Previous) Eval Time (s)     17.754966165870428
Sample Time (s)              6.411332973279059
Epoch Time (s)               169.65824234299362
Total Train Time (s)         35164.796425328124
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:06:41.692932 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #210 | Epoch Duration: 169.81739163398743
2020-01-11 18:06:41.693126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.036883
Z variance train             0.027560538
KL Divergence                17.182095
KL Loss                      1.7182095
QF Loss                      1698.0054
VF Loss                      166.77667
Policy Loss                  -995.354
Q Predictions Mean           989.43677
Q Predictions Std            427.60095
Q Predictions Max            1520.2987
Q Predictions Min            -81.50049
V Predictions Mean           1001.15643
V Predictions Std            426.05408
V Predictions Max            1543.645
V Predictions Min            -56.9725
Log Pis Mean                 0.13736808
Log Pis Std                  3.225895
Log Pis Max                  17.78974
Log Pis Min                  -7.1771994
Policy mu Mean               -0.05207052
Policy mu Std                0.58144915
Policy mu Max                2.6039937
Policy mu Min                -2.3664572
Policy log std Mean          -1.0359129
Policy log std Std           0.27492467
Policy log std Max           -0.42732793
Policy log std Min           -2.333511
Z mean eval                  0.9434077
Z variance eval              0.035214305
total_rewards                [2824.05367502 3751.58212208 3697.78619529 3840.5992414   644.96411312
 2631.11180629 3560.6945424  1740.08518777 3993.75309564 3848.00456902]
total_rewards_mean           3053.263454802271
total_rewards_std            1051.2691707809836
total_rewards_max            3993.7530956378946
total_rewards_min            644.9641131228382
Number of train steps total  848000
Number of env steps total    900787
Number of rollouts total     0
Train Time (s)               145.80650324886665
(Previous) Eval Time (s)     22.397196656093
Sample Time (s)              6.416696360334754
Epoch Time (s)               174.6203962652944
Total Train Time (s)         35339.532818677835
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:09:36.431466 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #211 | Epoch Duration: 174.7382037639618
2020-01-11 18:09:36.431602 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9384774
Z variance train             0.03521506
KL Divergence                16.476719
KL Loss                      1.6476719
QF Loss                      747.20386
VF Loss                      182.75137
Policy Loss                  -982.6666
Q Predictions Mean           975.09467
Q Predictions Std            431.5608
Q Predictions Max            1542.8503
Q Predictions Min            -52.983715
V Predictions Mean           987.4769
V Predictions Std            424.82526
V Predictions Max            1548.7185
V Predictions Min            260.52777
Log Pis Mean                 -0.13841912
Log Pis Std                  3.1027045
Log Pis Max                  15.722841
Log Pis Min                  -7.538236
Policy mu Mean               -0.020329654
Policy mu Std                0.56877667
Policy mu Max                3.6308506
Policy mu Min                -2.5234232
Policy log std Mean          -1.0176331
Policy log std Std           0.25559324
Policy log std Max           -0.32128865
Policy log std Min           -2.353703
Z mean eval                  0.9658333
Z variance eval              0.020687604
total_rewards                [1314.27368662  159.88671997 3382.58891845 2662.93547639 4255.68298052
 2642.29492193 3913.28583201  661.63566607 4105.78047219 3983.14127457]
total_rewards_mean           2708.1505948720796
total_rewards_std            1432.207782616856
total_rewards_max            4255.682980519644
total_rewards_min            159.88671997092504
Number of train steps total  852000
Number of env steps total    909281
Number of rollouts total     0
Train Time (s)               147.0706221330911
(Previous) Eval Time (s)     14.69600892579183
Sample Time (s)              7.712284055072814
Epoch Time (s)               169.47891511395574
Total Train Time (s)         35509.09424235765
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:12:25.994034 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #212 | Epoch Duration: 169.56231570243835
2020-01-11 18:12:25.994161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9675107
Z variance train             0.020514984
KL Divergence                18.00218
KL Loss                      1.800218
QF Loss                      1302.7214
VF Loss                      664.6907
Policy Loss                  -953.5173
Q Predictions Mean           947.6349
Q Predictions Std            435.16748
Q Predictions Max            1521.335
Q Predictions Min            -61.047375
V Predictions Mean           949.31067
V Predictions Std            433.55374
V Predictions Max            1487.5153
V Predictions Min            -51.22029
Log Pis Mean                 0.3676266
Log Pis Std                  4.0069036
Log Pis Max                  28.245457
Log Pis Min                  -9.583534
Policy mu Mean               -0.011084471
Policy mu Std                0.62447006
Policy mu Max                3.582476
Policy mu Min                -3.9265468
Policy log std Mean          -1.0192642
Policy log std Std           0.29067758
Policy log std Max           -0.32760358
Policy log std Min           -2.3700223
Z mean eval                  0.99005044
Z variance eval              0.009035448
total_rewards                [ 370.04605566 3423.40172356 1113.17893002 2626.1134043   323.04246051
  428.19634195 2179.49628187 1774.65451636 3958.53842785 2252.49534083]
total_rewards_mean           1844.916348290693
total_rewards_std            1220.088605128949
total_rewards_max            3958.5384278542224
total_rewards_min            323.0424605118817
Number of train steps total  856000
Number of env steps total    916208
Number of rollouts total     0
Train Time (s)               145.57289107702672
(Previous) Eval Time (s)     9.943542048335075
Sample Time (s)              6.242811040021479
Epoch Time (s)               161.75924416538328
Total Train Time (s)         35670.940750499256
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:15:07.843539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #213 | Epoch Duration: 161.84927082061768
2020-01-11 18:15:07.843702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9936268
Z variance train             0.009078755
KL Divergence                19.941801
KL Loss                      1.9941801
QF Loss                      565.26605
VF Loss                      183.22928
Policy Loss                  -942.8337
Q Predictions Mean           940.7252
Q Predictions Std            427.49207
Q Predictions Max            1524.3745
Q Predictions Min            207.2673
V Predictions Mean           939.7539
V Predictions Std            423.10202
V Predictions Max            1502.0105
V Predictions Min            169.79126
Log Pis Mean                 0.22770837
Log Pis Std                  3.971504
Log Pis Max                  30.877357
Log Pis Min                  -8.668598
Policy mu Mean               0.024126492
Policy mu Std                0.6175695
Policy mu Max                3.2272522
Policy mu Min                -4.999099
Policy log std Mean          -1.0410038
Policy log std Std           0.2667131
Policy log std Max           -0.28299993
Policy log std Min           -2.2914612
Z mean eval                  1.045465
Z variance eval              0.028712207
total_rewards                [1590.24623649 3455.37199265  795.73604114  680.41209694  950.76591799
 3505.82330652 2518.59578013 4217.89174265 2278.00370748  820.00937431]
total_rewards_mean           2081.285619629203
total_rewards_std            1242.4790329541872
total_rewards_max            4217.891742651848
total_rewards_min            680.4120969377257
Number of train steps total  860000
Number of env steps total    924283
Number of rollouts total     0
Train Time (s)               147.71462779073045
(Previous) Eval Time (s)     13.17174109024927
Sample Time (s)              7.217906290665269
Epoch Time (s)               168.10427517164499
Total Train Time (s)         35839.182670232374
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:17:56.087286 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #214 | Epoch Duration: 168.24345755577087
2020-01-11 18:17:56.087423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0412071
Z variance train             0.02859537
KL Divergence                16.53992
KL Loss                      1.653992
QF Loss                      1161.2158
VF Loss                      143.73083
Policy Loss                  -1038.7361
Q Predictions Mean           1031.1174
Q Predictions Std            420.1276
Q Predictions Max            1551.6716
Q Predictions Min            223.89914
V Predictions Mean           1039.1328
V Predictions Std            416.09253
V Predictions Max            1539.2631
V Predictions Min            203.08722
Log Pis Mean                 0.21327817
Log Pis Std                  3.1481328
Log Pis Max                  14.526326
Log Pis Min                  -8.311165
Policy mu Mean               -0.019676268
Policy mu Std                0.6030243
Policy mu Max                3.2903688
Policy mu Min                -4.0555487
Policy log std Mean          -1.0372233
Policy log std Std           0.2559656
Policy log std Max           -0.07814801
Policy log std Min           -2.3874123
Z mean eval                  0.97874326
Z variance eval              0.020125892
total_rewards                [3317.76595763 4372.06845786  514.67671256 4195.30752089 3974.66268567
 1540.05657345 4044.48200348 2242.31174475 3896.1239568  4172.71396962]
total_rewards_mean           3227.0169582685708
total_rewards_std            1264.8519472199612
total_rewards_max            4372.068457855923
total_rewards_min            514.6767125558914
Number of train steps total  864000
Number of env steps total    930536
Number of rollouts total     0
Train Time (s)               146.1511814976111
(Previous) Eval Time (s)     17.00041664671153
Sample Time (s)              7.689599138684571
Epoch Time (s)               170.8411972830072
Total Train Time (s)         36010.12835665513
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:20:47.034665 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #215 | Epoch Duration: 170.9470932483673
2020-01-11 18:20:47.034860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9802598
Z variance train             0.020478735
KL Divergence                18.620573
KL Loss                      1.8620573
QF Loss                      705.64166
VF Loss                      228.57272
Policy Loss                  -1047.4675
Q Predictions Mean           1043.1929
Q Predictions Std            403.61258
Q Predictions Max            1541.6919
Q Predictions Min            230.68262
V Predictions Mean           1041.8447
V Predictions Std            399.1272
V Predictions Max            1534.3998
V Predictions Min            248.94852
Log Pis Mean                 0.23482168
Log Pis Std                  3.2821171
Log Pis Max                  16.42352
Log Pis Min                  -8.161525
Policy mu Mean               -0.01398657
Policy mu Std                0.60323584
Policy mu Max                3.368413
Policy mu Min                -2.3818657
Policy log std Mean          -1.0281594
Policy log std Std           0.27333885
Policy log std Max           -0.104195
Policy log std Min           -2.4677644
Z mean eval                  0.94358647
Z variance eval              0.026429478
total_rewards                [4018.25161482 4062.71286023 4155.02173433 4532.853581   2699.46772887
 4406.23007057 4178.05742591 4145.87076847 4078.05658506 4000.87800996]
total_rewards_mean           4027.740037921058
total_rewards_std            471.1707749864926
total_rewards_max            4532.853580996483
total_rewards_min            2699.4677288686735
Number of train steps total  868000
Number of env steps total    938156
Number of rollouts total     0
Train Time (s)               145.36685317009687
(Previous) Eval Time (s)     20.28902764711529
Sample Time (s)              6.744877751916647
Epoch Time (s)               172.4007585691288
Total Train Time (s)         36182.671335670166
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:23:39.578540 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #216 | Epoch Duration: 172.5435733795166
2020-01-11 18:23:39.578662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9404192
Z variance train             0.026306856
KL Divergence                17.524797
KL Loss                      1.7524798
QF Loss                      904.2906
VF Loss                      156.1912
Policy Loss                  -999.8888
Q Predictions Mean           994.39954
Q Predictions Std            431.21356
Q Predictions Max            1544.3438
Q Predictions Min            -71.894356
V Predictions Mean           998.5069
V Predictions Std            428.92603
V Predictions Max            1542.3171
V Predictions Min            -37.74499
Log Pis Mean                 0.020344064
Log Pis Std                  3.1012943
Log Pis Max                  12.032406
Log Pis Min                  -7.57497
Policy mu Mean               -0.010150786
Policy mu Std                0.58528894
Policy mu Max                2.5832
Policy mu Min                -2.3672392
Policy log std Mean          -1.0179431
Policy log std Std           0.2575423
Policy log std Max           -0.31515104
Policy log std Min           -2.119761
Z mean eval                  0.9656919
Z variance eval              0.05048991
total_rewards                [4360.12903429 4339.05527808 1882.42626627  569.94650587 4185.15917405
 4119.23688746 4160.26101985 4010.9805693  4172.24491037 4462.14183202]
total_rewards_mean           3626.158147755931
total_rewards_std            1241.53165456881
total_rewards_max            4462.141832022984
total_rewards_min            569.9465058650374
Number of train steps total  872000
Number of env steps total    946651
Number of rollouts total     0
Train Time (s)               145.05600431608036
(Previous) Eval Time (s)     19.940419589169323
Sample Time (s)              6.636303638108075
Epoch Time (s)               171.63272754335776
Total Train Time (s)         36354.41619565943
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:26:31.325306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #217 | Epoch Duration: 171.74655437469482
2020-01-11 18:26:31.325423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97318536
Z variance train             0.050321013
KL Divergence                19.031242
KL Loss                      1.9031242
QF Loss                      774.0387
VF Loss                      292.4483
Policy Loss                  -1041.9705
Q Predictions Mean           1036.044
Q Predictions Std            393.45416
Q Predictions Max            1525.9089
Q Predictions Min            189.48254
V Predictions Mean           1037.0768
V Predictions Std            386.72345
V Predictions Max            1500.8827
V Predictions Min            249.60423
Log Pis Mean                 0.5914022
Log Pis Std                  3.729329
Log Pis Max                  20.378807
Log Pis Min                  -6.7565517
Policy mu Mean               -0.013457594
Policy mu Std                0.62525237
Policy mu Max                4.330369
Policy mu Min                -3.1950297
Policy log std Mean          -1.0575389
Policy log std Std           0.27736467
Policy log std Max           -0.07076669
Policy log std Min           -2.807071
Z mean eval                  1.0487732
Z variance eval              0.021177717
total_rewards                [4304.316247   2516.67867028 4318.61783142 2491.87520476 3718.32467215
 1721.20567338 2272.19654875 1119.06899027  558.47526794   98.32226826]
total_rewards_mean           2311.9081374210155
total_rewards_std            1407.009642003661
total_rewards_max            4318.6178314214085
total_rewards_min            98.32226825923085
Number of train steps total  876000
Number of env steps total    952968
Number of rollouts total     0
Train Time (s)               145.23225642414764
(Previous) Eval Time (s)     13.572239725384861
Sample Time (s)              6.712953218724579
Epoch Time (s)               165.51744936825708
Total Train Time (s)         36520.04682575073
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:29:16.957817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #218 | Epoch Duration: 165.6323037147522
2020-01-11 18:29:16.957942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.042908
Z variance train             0.021302875
KL Divergence                20.64931
KL Loss                      2.064931
QF Loss                      681.78326
VF Loss                      249.13904
Policy Loss                  -980.66644
Q Predictions Mean           974.72754
Q Predictions Std            424.03424
Q Predictions Max            1521.0164
Q Predictions Min            1.8547649
V Predictions Mean           976.19775
V Predictions Std            418.36722
V Predictions Max            1508.36
V Predictions Min            215.69499
Log Pis Mean                 0.31302404
Log Pis Std                  3.561931
Log Pis Max                  27.815178
Log Pis Min                  -6.7865963
Policy mu Mean               -0.028906882
Policy mu Std                0.60589576
Policy mu Max                3.1882758
Policy mu Min                -5.1057873
Policy log std Mean          -1.0206947
Policy log std Std           0.26130077
Policy log std Max           -0.32004857
Policy log std Min           -2.2005904
Z mean eval                  1.0653306
Z variance eval              0.027257267
total_rewards                [1475.68341424  106.36119717  942.25310361 1963.31054288 4128.14432683
 4506.17093514 4127.80436441 1719.8559402  2920.04080854 4372.91332563]
total_rewards_mean           2626.253795864321
total_rewards_std            1514.9959776233943
total_rewards_max            4506.170935142542
total_rewards_min            106.3611971683377
Number of train steps total  880000
Number of env steps total    959400
Number of rollouts total     0
Train Time (s)               145.7226967108436
(Previous) Eval Time (s)     13.510605907998979
Sample Time (s)              7.643644418567419
Epoch Time (s)               166.87694703741
Total Train Time (s)         36687.036886256654
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:32:03.949979 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #219 | Epoch Duration: 166.99194478988647
2020-01-11 18:32:03.950094 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609596
Z variance train             0.027536362
KL Divergence                19.480434
KL Loss                      1.9480435
QF Loss                      692.3845
VF Loss                      216.72993
Policy Loss                  -959.6687
Q Predictions Mean           948.8458
Q Predictions Std            437.89444
Q Predictions Max            1540.4224
Q Predictions Min            -52.494812
V Predictions Mean           953.2883
V Predictions Std            430.17572
V Predictions Max            1548.3374
V Predictions Min            143.25229
Log Pis Mean                 -0.05853346
Log Pis Std                  3.1551557
Log Pis Max                  12.866266
Log Pis Min                  -8.90514
Policy mu Mean               0.012704821
Policy mu Std                0.59962046
Policy mu Max                2.902674
Policy mu Min                -2.9532528
Policy log std Mean          -0.9962898
Policy log std Std           0.24822684
Policy log std Max           -0.2324934
Policy log std Min           -2.180708
Z mean eval                  0.9203687
Z variance eval              0.017361213
total_rewards                [ 740.35108087 1942.81932565 3858.10468069 4111.83295467 1682.91274213
 4337.18971994 4238.45440367 4264.95079139 4342.34225854 4217.06002208]
total_rewards_mean           3373.6017979653743
total_rewards_std            1293.8377095518022
total_rewards_max            4342.3422585410635
total_rewards_min            740.3510808742108
Number of train steps total  884000
Number of env steps total    968458
Number of rollouts total     0
Train Time (s)               146.71224843384698
(Previous) Eval Time (s)     18.849456725176424
Sample Time (s)              6.892036355566233
Epoch Time (s)               172.45374151458964
Total Train Time (s)         36859.573893857654
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:34:56.488885 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #220 | Epoch Duration: 172.53870153427124
2020-01-11 18:34:56.489006 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9200531
Z variance train             0.017250273
KL Divergence                19.571552
KL Loss                      1.9571552
QF Loss                      726.3562
VF Loss                      127.21504
Policy Loss                  -998.71625
Q Predictions Mean           995.30646
Q Predictions Std            425.3295
Q Predictions Max            1565.8484
Q Predictions Min            244.4209
V Predictions Mean           992.93445
V Predictions Std            422.66058
V Predictions Max            1552.9567
V Predictions Min            230.5265
Log Pis Mean                 -0.011498123
Log Pis Std                  3.0623045
Log Pis Max                  9.094202
Log Pis Min                  -8.886045
Policy mu Mean               -0.025707187
Policy mu Std                0.5852109
Policy mu Max                2.5309849
Policy mu Min                -2.3694334
Policy log std Mean          -1.0104702
Policy log std Std           0.25985768
Policy log std Max           -0.36323208
Policy log std Min           -2.2972279
Z mean eval                  0.9893174
Z variance eval              0.005913437
total_rewards                [4020.73730559 4500.4720801  4021.75571494 4051.99713514   72.72086245
 1498.02607763   54.97639563 4127.08041997 4269.99633071 4362.21739107]
total_rewards_mean           3097.997971323868
total_rewards_std            1720.0249363367677
total_rewards_max            4500.472080104182
total_rewards_min            54.976395631711824
Number of train steps total  888000
Number of env steps total    976769
Number of rollouts total     0
Train Time (s)               145.79731831979007
(Previous) Eval Time (s)     15.796530615072697
Sample Time (s)              6.423625402152538
Epoch Time (s)               168.0174743370153
Total Train Time (s)         37027.74818301294
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:37:44.665472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #221 | Epoch Duration: 168.17635464668274
2020-01-11 18:37:44.665644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9877798
Z variance train             0.005923488
KL Divergence                19.983727
KL Loss                      1.9983727
QF Loss                      874.78766
VF Loss                      131.74072
Policy Loss                  -1025.0067
Q Predictions Mean           1019.18665
Q Predictions Std            416.07877
Q Predictions Max            1538.8539
Q Predictions Min            223.05281
V Predictions Mean           1023.14
V Predictions Std            414.15457
V Predictions Max            1526.8693
V Predictions Min            245.02327
Log Pis Mean                 -0.163708
Log Pis Std                  3.2950122
Log Pis Max                  17.749004
Log Pis Min                  -7.04422
Policy mu Mean               -0.0131352255
Policy mu Std                0.6179491
Policy mu Max                3.3218174
Policy mu Min                -3.923326
Policy log std Mean          -1.0115243
Policy log std Std           0.2692675
Policy log std Max           -0.2378279
Policy log std Min           -2.3547914
Z mean eval                  1.0034292
Z variance eval              0.023378983
total_rewards                [3726.29786156 4212.19093032 4231.84382093 3982.78234457 3967.75230067
 2931.08987758 3984.88805098 3059.98781747 4004.81813872 3847.9950814 ]
total_rewards_mean           3794.9646224190483
total_rewards_std            424.75634707927395
total_rewards_max            4231.843820930333
total_rewards_min            2931.0898775798782
Number of train steps total  892000
Number of env steps total    986437
Number of rollouts total     0
Train Time (s)               147.02670027175918
(Previous) Eval Time (s)     20.940541465301067
Sample Time (s)              7.590916075743735
Epoch Time (s)               175.55815781280398
Total Train Time (s)         37203.45205981238
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:40:40.386035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #222 | Epoch Duration: 175.7202308177948
2020-01-11 18:40:40.386268 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9994386
Z variance train             0.02339465
KL Divergence                16.936197
KL Loss                      1.6936197
QF Loss                      674.5934
VF Loss                      113.265434
Policy Loss                  -981.37463
Q Predictions Mean           975.6465
Q Predictions Std            436.09506
Q Predictions Max            1566.4167
Q Predictions Min            -4.0685954
V Predictions Mean           984.25684
V Predictions Std            433.03217
V Predictions Max            1555.4972
V Predictions Min            -28.567371
Log Pis Mean                 0.16438583
Log Pis Std                  3.5017529
Log Pis Max                  17.700256
Log Pis Min                  -7.159913
Policy mu Mean               -0.003843802
Policy mu Std                0.6326299
Policy mu Max                2.788123
Policy mu Min                -3.4669542
Policy log std Mean          -1.0002841
Policy log std Std           0.26307765
Policy log std Max           -0.11640173
Policy log std Min           -2.3598876
Z mean eval                  0.9433527
Z variance eval              0.013235283
total_rewards                [3922.67551213 4042.64264108 4095.53902959 4188.57608125 4101.01699724
 4135.61406836 3983.84707205 3853.5722831  4228.68614753 4016.75040614]
total_rewards_mean           4056.892023848458
total_rewards_std            110.90294174959605
total_rewards_max            4228.6861475347
total_rewards_min            3853.5722831045578
Number of train steps total  896000
Number of env steps total    996413
Number of rollouts total     0
Train Time (s)               146.1544323391281
(Previous) Eval Time (s)     21.47079561976716
Sample Time (s)              8.223286824766546
Epoch Time (s)               175.8485147836618
Total Train Time (s)         37379.43737808615
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:43:36.362800 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #223 | Epoch Duration: 175.97635984420776
2020-01-11 18:43:36.362960 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94375646
Z variance train             0.01336021
KL Divergence                18.298489
KL Loss                      1.8298489
QF Loss                      1044.343
VF Loss                      759.0602
Policy Loss                  -1014.9642
Q Predictions Mean           1005.5956
Q Predictions Std            408.46753
Q Predictions Max            1530.3186
Q Predictions Min            167.50739
V Predictions Mean           1018.9532
V Predictions Std            406.5332
V Predictions Max            1549.0768
V Predictions Min            243.9079
Log Pis Mean                 0.68168116
Log Pis Std                  4.205332
Log Pis Max                  26.516987
Log Pis Min                  -7.427782
Policy mu Mean               0.058169626
Policy mu Std                0.65170574
Policy mu Max                3.6832376
Policy mu Min                -4.622685
Policy log std Mean          -1.0589261
Policy log std Std           0.28075504
Policy log std Max           -0.3507496
Policy log std Min           -2.3577676
Z mean eval                  0.86112154
Z variance eval              0.01055309
total_rewards                [2901.87755598 1265.55698814 4254.36406472 1593.37831254 2227.72771853
 4261.135814   3860.27141396 4342.23731502 2703.03847933 4146.53149552]
total_rewards_mean           3155.6119157743933
total_rewards_std            1116.20070861554
total_rewards_max            4342.237315023032
total_rewards_min            1265.5569881432284
Number of train steps total  900000
Number of env steps total    1006414
Number of rollouts total     0
Train Time (s)               146.6570232301019
(Previous) Eval Time (s)     18.62599729280919
Sample Time (s)              7.186676332727075
Epoch Time (s)               172.46969685563818
Total Train Time (s)         37551.99910792755
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:46:28.927316 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #224 | Epoch Duration: 172.56422066688538
2020-01-11 18:46:28.927508 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8592707
Z variance train             0.010570109
KL Divergence                18.990711
KL Loss                      1.8990711
QF Loss                      1407.1886
VF Loss                      559.13617
Policy Loss                  -968.2463
Q Predictions Mean           960.608
Q Predictions Std            442.01544
Q Predictions Max            1541.2609
Q Predictions Min            -25.993124
V Predictions Mean           973.5119
V Predictions Std            435.64523
V Predictions Max            1529.1666
V Predictions Min            163.11787
Log Pis Mean                 0.18863732
Log Pis Std                  4.2359576
Log Pis Max                  34.29308
Log Pis Min                  -7.3294334
Policy mu Mean               -0.006156447
Policy mu Std                0.63208103
Policy mu Max                4.51846
Policy mu Min                -4.47037
Policy log std Mean          -1.0008116
Policy log std Std           0.26712778
Policy log std Max           0.00018167496
Policy log std Min           -2.5393317
Z mean eval                  1.0655733
Z variance eval              0.00434268
total_rewards                [4242.20733808 4203.44931587 4102.2706282   274.13210895 4104.26851203
 4106.63554173 3739.37744436 4199.80695227 3636.93236943 4033.66137579]
total_rewards_mean           3664.274158669996
total_rewards_std            1145.7979588476524
total_rewards_max            4242.2073380783295
total_rewards_min            274.13210894523684
Number of train steps total  904000
Number of env steps total    1015311
Number of rollouts total     0
Train Time (s)               146.44884935580194
(Previous) Eval Time (s)     22.398210754152387
Sample Time (s)              7.320179509930313
Epoch Time (s)               176.16723961988464
Total Train Time (s)         37728.24969656626
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:49:25.179581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #225 | Epoch Duration: 176.25191068649292
2020-01-11 18:49:25.179719 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #225 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0598456
Z variance train             0.0043149064
KL Divergence                20.89642
KL Loss                      2.089642
QF Loss                      1212.5676
VF Loss                      233.10704
Policy Loss                  -992.4518
Q Predictions Mean           989.1029
Q Predictions Std            433.02277
Q Predictions Max            1546.9824
Q Predictions Min            -29.554432
V Predictions Mean           998.5112
V Predictions Std            427.4828
V Predictions Max            1550.5962
V Predictions Min            75.98149
Log Pis Mean                 -0.099717885
Log Pis Std                  3.3832448
Log Pis Max                  14.744799
Log Pis Min                  -7.5507817
Policy mu Mean               0.02630828
Policy mu Std                0.6148988
Policy mu Max                3.1204498
Policy mu Min                -3.6405149
Policy log std Mean          -1.0150365
Policy log std Std           0.28798744
Policy log std Max           -0.036203623
Policy log std Min           -2.7577748
Z mean eval                  0.961041
Z variance eval              0.020847285
total_rewards                [1975.53698736 4016.11439398 4159.34263745 2790.44596107 4340.0069264
 3581.40658795 4257.81740963 4269.09586874 3994.71665792  657.7146655 ]
total_rewards_mean           3404.219809600558
total_rewards_std            1167.8265105969115
total_rewards_max            4340.006926400145
total_rewards_min            657.7146654978844
Number of train steps total  908000
Number of env steps total    1025416
Number of rollouts total     0
Train Time (s)               146.0303494790569
(Previous) Eval Time (s)     19.266332970932126
Sample Time (s)              7.824429979082197
Epoch Time (s)               173.12111242907122
Total Train Time (s)         37901.46217547823
Epoch                        226
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:52:18.395190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #226 | Epoch Duration: 173.21534657478333
2020-01-11 18:52:18.395363 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9560245
Z variance train             0.021025252
KL Divergence                16.796597
KL Loss                      1.6796597
QF Loss                      1016.25543
VF Loss                      111.10003
Policy Loss                  -1024.9664
Q Predictions Mean           1018.49713
Q Predictions Std            417.21426
Q Predictions Max            1590.4711
Q Predictions Min            0.38982105
V Predictions Mean           1021.7682
V Predictions Std            412.1974
V Predictions Max            1576.2708
V Predictions Min            240.85207
Log Pis Mean                 0.21255374
Log Pis Std                  3.2559865
Log Pis Max                  18.761333
Log Pis Min                  -7.383958
Policy mu Mean               -0.023081891
Policy mu Std                0.58147436
Policy mu Max                2.3783994
Policy mu Min                -2.9339144
Policy log std Mean          -1.0271668
Policy log std Std           0.2765489
Policy log std Max           -0.18844104
Policy log std Min           -2.4859362
Z mean eval                  1.024226
Z variance eval              0.012876813
total_rewards                [ 417.46622397   61.3619408  3075.71446245 1925.80286765 2398.48424583
 4174.74577287   12.52647552 3665.63271399 1234.43564988 4332.59775769]
total_rewards_mean           2129.8768110650153
total_rewards_std            1577.8628244573827
total_rewards_max            4332.597757690288
total_rewards_min            12.526475521186532
Number of train steps total  912000
Number of env steps total    1035266
Number of rollouts total     0
Train Time (s)               147.0208061109297
(Previous) Eval Time (s)     15.168227126821876
Sample Time (s)              7.378477691672742
Epoch Time (s)               169.56751092942432
Total Train Time (s)         38071.127774500754
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:55:08.062400 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #227 | Epoch Duration: 169.6669201850891
2020-01-11 18:55:08.062522 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.01669
Z variance train             0.012700451
KL Divergence                19.30486
KL Loss                      1.930486
QF Loss                      864.16455
VF Loss                      184.97568
Policy Loss                  -992.3169
Q Predictions Mean           990.45264
Q Predictions Std            436.80347
Q Predictions Max            1643.7538
Q Predictions Min            213.23773
V Predictions Mean           997.0929
V Predictions Std            435.48584
V Predictions Max            1642.8173
V Predictions Min            224.01828
Log Pis Mean                 -0.21939814
Log Pis Std                  3.5422385
Log Pis Max                  13.600241
Log Pis Min                  -11.660021
Policy mu Mean               -0.018702406
Policy mu Std                0.58722574
Policy mu Max                3.2195015
Policy mu Min                -2.7128713
Policy log std Mean          -1.0155389
Policy log std Std           0.27281046
Policy log std Max           0.095128775
Policy log std Min           -2.3032808
Z mean eval                  0.9384969
Z variance eval              0.015895793
total_rewards                [1600.25739691 4102.24700383 2055.23415045 4270.74312601  585.11828925
 4288.24946841 1355.41549864 2389.30005318 4089.0953187  2903.7880507 ]
total_rewards_mean           2763.944835607576
total_rewards_std            1299.562093096283
total_rewards_max            4288.249468413739
total_rewards_min            585.1182892457191
Number of train steps total  916000
Number of env steps total    1042553
Number of rollouts total     0
Train Time (s)               145.64291860489175
(Previous) Eval Time (s)     16.390521810390055
Sample Time (s)              8.253365764394403
Epoch Time (s)               170.2868061796762
Total Train Time (s)         38241.50081086205
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 18:57:58.436801 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #228 | Epoch Duration: 170.37418675422668
2020-01-11 18:57:58.436939 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9428023
Z variance train             0.015919061
KL Divergence                19.54689
KL Loss                      1.954689
QF Loss                      2133.9146
VF Loss                      666.6009
Policy Loss                  -972.0207
Q Predictions Mean           967.76965
Q Predictions Std            450.3118
Q Predictions Max            1518.0835
Q Predictions Min            203.2717
V Predictions Mean           976.94586
V Predictions Std            450.946
V Predictions Max            1527.9647
V Predictions Min            210.63585
Log Pis Mean                 0.21353726
Log Pis Std                  4.1637697
Log Pis Max                  37.75535
Log Pis Min                  -7.278336
Policy mu Mean               -0.021620821
Policy mu Std                0.6001742
Policy mu Max                3.2957973
Policy mu Min                -5.445593
Policy log std Mean          -1.0296531
Policy log std Std           0.3063799
Policy log std Max           -0.32416582
Policy log std Min           -2.6088643
Z mean eval                  0.95263016
Z variance eval              0.01280502
total_rewards                [1509.30436476 1881.31238164 4487.88685072 4216.9157565   827.04620137
  917.44025713 3886.40777047  319.22283008 2268.88870961  903.58220429]
total_rewards_mean           2121.8007326567576
total_rewards_std            1463.439330098804
total_rewards_max            4487.8868507185525
total_rewards_min            319.2228300750763
Number of train steps total  920000
Number of env steps total    1053753
Number of rollouts total     0
Train Time (s)               146.21178304310888
(Previous) Eval Time (s)     12.254462011158466
Sample Time (s)              7.374903226736933
Epoch Time (s)               165.84114828100428
Total Train Time (s)         38407.4296298977
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:00:44.367540 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #229 | Epoch Duration: 165.930499792099
2020-01-11 19:00:44.367668 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9566673
Z variance train             0.0128573375
KL Divergence                18.021976
KL Loss                      1.8021977
QF Loss                      853.52563
VF Loss                      182.66855
Policy Loss                  -1026.6119
Q Predictions Mean           1016.8342
Q Predictions Std            435.9372
Q Predictions Max            1553.5588
Q Predictions Min            182.38628
V Predictions Mean           1028.227
V Predictions Std            431.6909
V Predictions Max            1545.2329
V Predictions Min            248.2841
Log Pis Mean                 0.15275638
Log Pis Std                  3.3964937
Log Pis Max                  15.705734
Log Pis Min                  -8.100323
Policy mu Mean               -0.019300718
Policy mu Std                0.60516244
Policy mu Max                4.336897
Policy mu Min                -2.5439148
Policy log std Mean          -1.0257668
Policy log std Std           0.2791975
Policy log std Max           -0.233899
Policy log std Min           -2.3462248
Z mean eval                  0.92738676
Z variance eval              0.0060947374
total_rewards                [1980.09292912 4263.44706427 1994.33745668 4278.06495754 2950.72649921
 4361.54183822 1101.62052002 1615.34866835  183.01467575 3386.71281277]
total_rewards_mean           2611.490742192567
total_rewards_std            1386.8742842136141
total_rewards_max            4361.541838224137
total_rewards_min            183.01467574908207
Number of train steps total  924000
Number of env steps total    1061081
Number of rollouts total     0
Train Time (s)               147.67494226107374
(Previous) Eval Time (s)     15.683920393232256
Sample Time (s)              7.728173624258488
Epoch Time (s)               171.08703627856448
Total Train Time (s)         38578.66467411909
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:03:35.612407 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #230 | Epoch Duration: 171.24462485313416
2020-01-11 19:03:35.612588 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92790735
Z variance train             0.006099493
KL Divergence                19.624634
KL Loss                      1.9624634
QF Loss                      1249.1793
VF Loss                      191.33328
Policy Loss                  -1084.024
Q Predictions Mean           1079.2167
Q Predictions Std            440.68756
Q Predictions Max            1625.3124
Q Predictions Min            42.435577
V Predictions Mean           1082.001
V Predictions Std            437.18143
V Predictions Max            1612.6267
V Predictions Min            201.56508
Log Pis Mean                 0.23717996
Log Pis Std                  3.25887
Log Pis Max                  13.548338
Log Pis Min                  -8.691757
Policy mu Mean               -0.049261834
Policy mu Std                0.59346753
Policy mu Max                2.2978683
Policy mu Min                -2.6810813
Policy log std Mean          -1.0362489
Policy log std Std           0.27724302
Policy log std Max           -0.2722901
Policy log std Min           -2.1860821
Z mean eval                  0.9558304
Z variance eval              0.032225437
total_rewards                [2035.42754304 4438.08905634 4493.76284223 4031.69205868 4183.12992768
 4295.00341032 4306.18043368   36.18863061 4089.31253103 4010.83246951]
total_rewards_mean           3591.961890310835
total_rewards_std            1362.5537341496768
total_rewards_max            4493.7628422268845
total_rewards_min            36.1886306136212
Number of train steps total  928000
Number of env steps total    1071091
Number of rollouts total     0
Train Time (s)               146.2061426579021
(Previous) Eval Time (s)     21.168507820926607
Sample Time (s)              8.387079305946827
Epoch Time (s)               175.76172978477553
Total Train Time (s)         38754.51622752426
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:06:31.458212 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #231 | Epoch Duration: 175.84550166130066
2020-01-11 19:06:31.458346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #231 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9494006
Z variance train             0.032194413
KL Divergence                16.157932
KL Loss                      1.6157932
QF Loss                      1179.5305
VF Loss                      201.71725
Policy Loss                  -1035.066
Q Predictions Mean           1027.8826
Q Predictions Std            426.81796
Q Predictions Max            1595.735
Q Predictions Min            -17.87179
V Predictions Mean           1035.4437
V Predictions Std            421.53622
V Predictions Max            1584.8267
V Predictions Min            250.60419
Log Pis Mean                 0.29274073
Log Pis Std                  4.075251
Log Pis Max                  40.199287
Log Pis Min                  -7.9406295
Policy mu Mean               -0.02925453
Policy mu Std                0.6219718
Policy mu Max                4.101901
Policy mu Min                -5.2407875
Policy log std Mean          -1.0358078
Policy log std Std           0.2784422
Policy log std Max           -0.2159822
Policy log std Min           -2.5156524
Z mean eval                  1.0228332
Z variance eval              0.012172385
total_rewards                [4362.78361192 1138.78268002 4400.02117074 4390.57555119  581.2925577
 4360.35950664 2662.28882274 4331.01175114 4597.40304996 4375.19928584]
total_rewards_mean           3519.9717987883278
total_rewards_std            1433.1990926347787
total_rewards_max            4597.4030499567525
total_rewards_min            581.2925577020033
Number of train steps total  932000
Number of env steps total    1079511
Number of rollouts total     0
Train Time (s)               144.84732535574585
(Previous) Eval Time (s)     17.486390025820583
Sample Time (s)              7.336270637344569
Epoch Time (s)               169.669986018911
Total Train Time (s)         38924.2927803481
Epoch                        232
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:09:21.236944 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #232 | Epoch Duration: 169.77849984169006
2020-01-11 19:09:21.237060 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0222915
Z variance train             0.012145944
KL Divergence                18.214252
KL Loss                      1.8214253
QF Loss                      1924.1965
VF Loss                      316.5085
Policy Loss                  -1003.565
Q Predictions Mean           997.28204
Q Predictions Std            447.8558
Q Predictions Max            1578.7854
Q Predictions Min            -21.07232
V Predictions Mean           1002.86194
V Predictions Std            445.62628
V Predictions Max            1565.0381
V Predictions Min            -45.203285
Log Pis Mean                 0.34606355
Log Pis Std                  3.636918
Log Pis Max                  20.552113
Log Pis Min                  -7.9634094
Policy mu Mean               -0.06326703
Policy mu Std                0.6076115
Policy mu Max                3.238687
Policy mu Min                -3.4687011
Policy log std Mean          -1.0513575
Policy log std Std           0.29997554
Policy log std Max           -0.0627383
Policy log std Min           -2.3404846
Z mean eval                  0.9988059
Z variance eval              0.005696186
total_rewards                [4160.7423743  4312.64442587 4241.62832463 2319.66246364 4393.12794301
  744.63354272 4383.32076595 1225.96631747 4411.37509578   11.10937938]
total_rewards_mean           3020.4210632758222
total_rewards_std            1675.8397919679899
total_rewards_max            4411.3750957813045
total_rewards_min            11.109379376706153
Number of train steps total  936000
Number of env steps total    1088080
Number of rollouts total     0
Train Time (s)               146.62404253007844
(Previous) Eval Time (s)     14.887587196193635
Sample Time (s)              6.277398359961808
Epoch Time (s)               167.78902808623388
Total Train Time (s)         39092.168021572754
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:12:09.114677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #233 | Epoch Duration: 167.87750840187073
2020-01-11 19:12:09.114850 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9941158
Z variance train             0.0056935
KL Divergence                20.33674
KL Loss                      2.033674
QF Loss                      840.7285
VF Loss                      178.54762
Policy Loss                  -1061.4512
Q Predictions Mean           1060.3088
Q Predictions Std            434.27225
Q Predictions Max            1622.407
Q Predictions Min            8.961076
V Predictions Mean           1062.7844
V Predictions Std            435.9841
V Predictions Max            1629.4827
V Predictions Min            -52.456936
Log Pis Mean                 0.4191382
Log Pis Std                  3.7510698
Log Pis Max                  29.755596
Log Pis Min                  -10.149435
Policy mu Mean               -0.015838912
Policy mu Std                0.65671754
Policy mu Max                4.6308303
Policy mu Min                -3.6173759
Policy log std Mean          -1.0021788
Policy log std Std           0.28130436
Policy log std Max           0.5295236
Policy log std Min           -2.2873015
Z mean eval                  0.95793164
Z variance eval              0.06339449
total_rewards                [1418.92272932 4264.4778064  2526.63517493 4255.55449485 3434.64144167
 4152.46461151  870.70012913 4151.38738301 4563.86188131 4159.02220497]
total_rewards_mean           3379.766785710184
total_rewards_std            1249.906710738533
total_rewards_max            4563.861881314311
total_rewards_min            870.7001291282197
Number of train steps total  940000
Number of env steps total    1098402
Number of rollouts total     0
Train Time (s)               147.5479020131752
(Previous) Eval Time (s)     19.491029446013272
Sample Time (s)              7.095338326878846
Epoch Time (s)               174.1342697860673
Total Train Time (s)         39266.407928356435
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:15:03.357159 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #234 | Epoch Duration: 174.24217534065247
2020-01-11 19:15:03.357303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9675128
Z variance train             0.06371976
KL Divergence                16.20248
KL Loss                      1.6202481
QF Loss                      6013.922
VF Loss                      1502.4508
Policy Loss                  -1064.0043
Q Predictions Mean           1055.6232
Q Predictions Std            441.1628
Q Predictions Max            1593.9857
Q Predictions Min            -51.127678
V Predictions Mean           1060.6787
V Predictions Std            434.20224
V Predictions Max            1587.0856
V Predictions Min            -24.833595
Log Pis Mean                 0.60260737
Log Pis Std                  3.9974759
Log Pis Max                  24.586246
Log Pis Min                  -7.576546
Policy mu Mean               -0.03068135
Policy mu Std                0.6444872
Policy mu Max                5.341866
Policy mu Min                -4.1754847
Policy log std Mean          -1.041817
Policy log std Std           0.29442427
Policy log std Max           -0.15777242
Policy log std Min           -2.534193
Z mean eval                  1.0273389
Z variance eval              0.017785195
total_rewards                [4499.57716413 2906.24941118 1611.46405474 1301.73677824  319.04605217
 1419.96298604 4213.73477824 2866.91271023  391.53290357  671.81785142]
total_rewards_mean           2020.2034689960237
total_rewards_std            1444.612977536498
total_rewards_max            4499.577164129229
total_rewards_min            319.04605217300684
Number of train steps total  944000
Number of env steps total    1106771
Number of rollouts total     0
Train Time (s)               147.1422084113583
(Previous) Eval Time (s)     13.407091628294438
Sample Time (s)              8.461460317019373
Epoch Time (s)               169.0107603566721
Total Train Time (s)         39435.53994714795
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:17:52.491165 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #235 | Epoch Duration: 169.13375163078308
2020-01-11 19:17:52.491349 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0295998
Z variance train             0.017707746
KL Divergence                17.385757
KL Loss                      1.7385758
QF Loss                      710.4623
VF Loss                      98.55083
Policy Loss                  -1078.8696
Q Predictions Mean           1075.7048
Q Predictions Std            415.34375
Q Predictions Max            1573.0167
Q Predictions Min            245.73494
V Predictions Mean           1079.0713
V Predictions Std            413.42212
V Predictions Max            1573.655
V Predictions Min            247.97192
Log Pis Mean                 0.62270695
Log Pis Std                  3.2335784
Log Pis Max                  14.302135
Log Pis Min                  -7.9242344
Policy mu Mean               -0.0018615762
Policy mu Std                0.6112214
Policy mu Max                2.9538953
Policy mu Min                -3.1244016
Policy log std Mean          -1.0718799
Policy log std Std           0.27954683
Policy log std Max           -0.35312635
Policy log std Min           -2.3990808
Z mean eval                  0.97599506
Z variance eval              0.010352868
total_rewards                [2840.73097998   38.86493999  289.07441391 3847.61699027  693.08693467
 1110.0751403  3857.01471111 4133.59105733 4131.59231326 4330.44293774]
total_rewards_mean           2527.209041855815
total_rewards_std            1690.8486922078864
total_rewards_max            4330.44293774103
total_rewards_min            38.86493999463288
Number of train steps total  948000
Number of env steps total    1114153
Number of rollouts total     0
Train Time (s)               146.41531192697585
(Previous) Eval Time (s)     19.230950470082462
Sample Time (s)              7.379418820608407
Epoch Time (s)               173.02568121766672
Total Train Time (s)         39608.6535111703
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:20:45.606726 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #236 | Epoch Duration: 173.11524510383606
2020-01-11 19:20:45.606893 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9733863
Z variance train             0.010328321
KL Divergence                18.273209
KL Loss                      1.8273209
QF Loss                      702.07214
VF Loss                      222.26018
Policy Loss                  -1085.5615
Q Predictions Mean           1077.8735
Q Predictions Std            407.35205
Q Predictions Max            1600.7599
Q Predictions Min            43.630245
V Predictions Mean           1091.1653
V Predictions Std            404.11493
V Predictions Max            1620.3085
V Predictions Min            55.035656
Log Pis Mean                 -0.022976182
Log Pis Std                  3.0902581
Log Pis Max                  11.169921
Log Pis Min                  -11.828419
Policy mu Mean               -0.025473427
Policy mu Std                0.5659599
Policy mu Max                2.3271875
Policy mu Min                -2.6697671
Policy log std Mean          -1.0302286
Policy log std Std           0.2709124
Policy log std Max           0.08503747
Policy log std Min           -2.115259
Z mean eval                  0.94122016
Z variance eval              0.010318808
total_rewards                [4103.41982797 2524.05946724 1203.96350688 4434.39478577  996.60523755
 1475.59702338  141.92926023 4169.93268116 1057.00816094  884.58878606]
total_rewards_mean           2099.1498737167726
total_rewards_std            1507.8749426062604
total_rewards_max            4434.394785766808
total_rewards_min            141.92926023067156
Number of train steps total  952000
Number of env steps total    1122254
Number of rollouts total     0
Train Time (s)               146.07024861965328
(Previous) Eval Time (s)     17.6442453074269
Sample Time (s)              8.841035245917737
Epoch Time (s)               172.55552917299792
Total Train Time (s)         39781.29946530098
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:23:38.253866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #237 | Epoch Duration: 172.64685678482056
2020-01-11 19:23:38.253994 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94458437
Z variance train             0.010396622
KL Divergence                18.074844
KL Loss                      1.8074845
QF Loss                      593.9321
VF Loss                      111.65049
Policy Loss                  -1051.604
Q Predictions Mean           1048.0048
Q Predictions Std            430.36768
Q Predictions Max            1601.8586
Q Predictions Min            266.4575
V Predictions Mean           1047.246
V Predictions Std            429.61093
V Predictions Max            1607.0498
V Predictions Min            270.26297
Log Pis Mean                 -0.11118509
Log Pis Std                  3.249723
Log Pis Max                  11.926748
Log Pis Min                  -8.372932
Policy mu Mean               -0.0037895795
Policy mu Std                0.5795754
Policy mu Max                2.5977416
Policy mu Min                -2.3566613
Policy log std Mean          -1.0378914
Policy log std Std           0.28521776
Policy log std Max           -0.15766472
Policy log std Min           -2.4407892
Z mean eval                  0.9627821
Z variance eval              0.025124049
total_rewards                [1605.08452764 3017.53882036 4299.3432254  4403.68078167 2117.28218913
 3215.72761902  337.88471538 4512.23096995  455.45275098 4083.02597952]
total_rewards_mean           2804.7251579047215
total_rewards_std            1518.8970376237053
total_rewards_max            4512.230969946475
total_rewards_min            337.88471537933526
Number of train steps total  956000
Number of env steps total    1129760
Number of rollouts total     0
Train Time (s)               146.61005096510053
(Previous) Eval Time (s)     18.332943473942578
Sample Time (s)              7.51411343831569
Epoch Time (s)               172.4571078773588
Total Train Time (s)         39953.83976902999
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:26:30.796522 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #238 | Epoch Duration: 172.54243779182434
2020-01-11 19:26:30.796652 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9620439
Z variance train             0.025043866
KL Divergence                16.810455
KL Loss                      1.6810455
QF Loss                      805.34155
VF Loss                      325.60178
Policy Loss                  -1053.1648
Q Predictions Mean           1045.8145
Q Predictions Std            423.5106
Q Predictions Max            1594.0771
Q Predictions Min            -22.682783
V Predictions Mean           1043.7382
V Predictions Std            417.4322
V Predictions Max            1582.6427
V Predictions Min            10.107955
Log Pis Mean                 0.39533108
Log Pis Std                  3.4199023
Log Pis Max                  17.918905
Log Pis Min                  -7.270591
Policy mu Mean               -0.025082616
Policy mu Std                0.6147836
Policy mu Max                3.216931
Policy mu Min                -3.7638423
Policy log std Mean          -1.0269643
Policy log std Std           0.28694725
Policy log std Max           0.70535314
Policy log std Min           -2.1811032
Z mean eval                  1.0341903
Z variance eval              0.0069256267
total_rewards                [3910.57792033 1814.37121896 4558.01514598 4071.16925799 4410.01171779
 4276.34542732 1698.5121666  3550.75212443 4548.88149058 4347.68417056]
total_rewards_mean           3718.6320640547065
total_rewards_std            1023.4763195872378
total_rewards_max            4558.015145982903
total_rewards_min            1698.5121666024802
Number of train steps total  960000
Number of env steps total    1140722
Number of rollouts total     0
Train Time (s)               145.83049253188074
(Previous) Eval Time (s)     21.45102809043601
Sample Time (s)              7.446843537501991
Epoch Time (s)               174.72836415981874
Total Train Time (s)         40128.65094364341
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:29:25.609170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #239 | Epoch Duration: 174.81241106987
2020-01-11 19:29:25.609301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0309461
Z variance train             0.0068198843
KL Divergence                19.981012
KL Loss                      1.9981012
QF Loss                      1745.8491
VF Loss                      276.22275
Policy Loss                  -1083.1139
Q Predictions Mean           1074.8359
Q Predictions Std            414.81683
Q Predictions Max            1639.5245
Q Predictions Min            -28.778143
V Predictions Mean           1082.0864
V Predictions Std            408.75418
V Predictions Max            1605.372
V Predictions Min            -54.70713
Log Pis Mean                 0.7386112
Log Pis Std                  3.3609364
Log Pis Max                  13.601027
Log Pis Min                  -7.657585
Policy mu Mean               -0.027632846
Policy mu Std                0.60482836
Policy mu Max                2.119181
Policy mu Min                -3.09482
Policy log std Mean          -1.0815287
Policy log std Std           0.2946858
Policy log std Max           -0.44515526
Policy log std Min           -2.459537
Z mean eval                  1.0232996
Z variance eval              0.015958577
total_rewards                [4018.38868216  132.16684438  528.75078959 4386.78057462  410.14878714
 4242.50831292 2724.03157123 4387.22407458 4285.19704488 4245.46847573]
total_rewards_mean           2936.066515722791
total_rewards_std            1752.3004657257245
total_rewards_max            4387.224074581949
total_rewards_min            132.16684437890967
Number of train steps total  964000
Number of env steps total    1150334
Number of rollouts total     0
Train Time (s)               146.05250133620575
(Previous) Eval Time (s)     17.021254133898765
Sample Time (s)              7.26451266836375
Epoch Time (s)               170.33826813846827
Total Train Time (s)         40299.08207578724
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:32:16.043335 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #240 | Epoch Duration: 170.43392634391785
2020-01-11 19:32:16.043499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #240 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.013287
Z variance train             0.015965452
KL Divergence                17.378561
KL Loss                      1.7378561
QF Loss                      1048.762
VF Loss                      290.4463
Policy Loss                  -1028.1228
Q Predictions Mean           1022.5767
Q Predictions Std            448.7762
Q Predictions Max            1620.868
Q Predictions Min            28.03347
V Predictions Mean           1038.2509
V Predictions Std            444.10416
V Predictions Max            1619.8964
V Predictions Min            71.03135
Log Pis Mean                 0.2804451
Log Pis Std                  3.7035344
Log Pis Max                  20.850582
Log Pis Min                  -8.637246
Policy mu Mean               -0.037146732
Policy mu Std                0.60327
Policy mu Max                3.0951738
Policy mu Min                -2.8046894
Policy log std Mean          -1.017071
Policy log std Std           0.28624356
Policy log std Max           -0.31221652
Policy log std Min           -2.6038618
Z mean eval                  0.91866046
Z variance eval              0.017004179
total_rewards                [4268.0926122  4533.95479926 2203.58606371  408.08371681 3515.0431381
 3719.40635647 1467.05785174    7.96618192 4299.33382923 4183.14404034]
total_rewards_mean           2860.5668589780116
total_rewards_std            1621.4825477456632
total_rewards_max            4533.954799261426
total_rewards_min            7.9661819162654055
Number of train steps total  968000
Number of env steps total    1160344
Number of rollouts total     0
Train Time (s)               145.15123662305996
(Previous) Eval Time (s)     18.64895747601986
Sample Time (s)              8.143983935471624
Epoch Time (s)               171.94417803455144
Total Train Time (s)         40471.11925569503
Epoch                        241
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:35:08.083586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #241 | Epoch Duration: 172.03995513916016
2020-01-11 19:35:08.083773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9202651
Z variance train             0.01699869
KL Divergence                18.015251
KL Loss                      1.8015251
QF Loss                      813.40027
VF Loss                      225.32971
Policy Loss                  -1084.8441
Q Predictions Mean           1082.5267
Q Predictions Std            430.12683
Q Predictions Max            1679.8333
Q Predictions Min            204.00905
V Predictions Mean           1085.0153
V Predictions Std            427.99017
V Predictions Max            1674.887
V Predictions Min            200.70541
Log Pis Mean                 -0.15367618
Log Pis Std                  2.9342158
Log Pis Max                  9.87318
Log Pis Min                  -6.6910925
Policy mu Mean               -0.011250598
Policy mu Std                0.58204937
Policy mu Max                1.997952
Policy mu Min                -3.00778
Policy log std Mean          -1.0017282
Policy log std Std           0.26973227
Policy log std Max           -0.23294032
Policy log std Min           -2.4441814
Z mean eval                  0.86652595
Z variance eval              0.00811728
total_rewards                [4248.30306152 4284.49117217 4451.38146835 2605.82131405 4247.84979499
 4483.73711289  635.91103044 3825.58074412 4247.93506656 4388.22481936]
total_rewards_mean           3741.9235584450616
total_rewards_std            1160.9983924906533
total_rewards_max            4483.737112890195
total_rewards_min            635.9110304402047
Number of train steps total  972000
Number of env steps total    1170156
Number of rollouts total     0
Train Time (s)               145.97285675583407
(Previous) Eval Time (s)     17.9671049551107
Sample Time (s)              7.949752319604158
Epoch Time (s)               171.88971403054893
Total Train Time (s)         40643.09501308529
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:38:00.061659 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #242 | Epoch Duration: 171.9777636528015
2020-01-11 19:38:00.061782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86651546
Z variance train             0.008142455
KL Divergence                18.81514
KL Loss                      1.881514
QF Loss                      609.089
VF Loss                      188.749
Policy Loss                  -1085.7247
Q Predictions Mean           1083.2278
Q Predictions Std            426.66324
Q Predictions Max            1617.18
Q Predictions Min            146.57422
V Predictions Mean           1079.5293
V Predictions Std            426.45728
V Predictions Max            1596.6516
V Predictions Min            -40.41646
Log Pis Mean                 -0.02831782
Log Pis Std                  3.1827426
Log Pis Max                  10.732838
Log Pis Min                  -7.58939
Policy mu Mean               0.054121837
Policy mu Std                0.5875688
Policy mu Max                2.989885
Policy mu Min                -2.8208785
Policy log std Mean          -1.0279546
Policy log std Std           0.27366218
Policy log std Max           -0.3498034
Policy log std Min           -2.3404634
Z mean eval                  1.0132954
Z variance eval              0.0149414195
total_rewards                [4034.0494946  4426.74852851 2984.49480599 4488.24766395 2513.27871366
 4259.86126722 3540.4035306  3999.21614142 3865.03821512 4341.55457654]
total_rewards_mean           3845.289293760645
total_rewards_std            619.477847186261
total_rewards_max            4488.2476639513925
total_rewards_min            2513.2787136589445
Number of train steps total  976000
Number of env steps total    1178557
Number of rollouts total     0
Train Time (s)               147.43829506915063
(Previous) Eval Time (s)     20.395654409192502
Sample Time (s)              6.2288283058442175
Epoch Time (s)               174.06277778418735
Total Train Time (s)         40817.562358905096
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:40:54.532000 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #243 | Epoch Duration: 174.4701042175293
2020-01-11 19:40:54.532191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0139118
Z variance train             0.015017335
KL Divergence                18.40437
KL Loss                      1.8404369
QF Loss                      1090.948
VF Loss                      205.27509
Policy Loss                  -1035.8911
Q Predictions Mean           1028.7194
Q Predictions Std            401.55154
Q Predictions Max            1535.6595
Q Predictions Min            247.86949
V Predictions Mean           1035.593
V Predictions Std            400.02573
V Predictions Max            1534.872
V Predictions Min            261.28714
Log Pis Mean                 0.43372446
Log Pis Std                  3.2343986
Log Pis Max                  11.61652
Log Pis Min                  -8.07897
Policy mu Mean               -0.010974047
Policy mu Std                0.6242647
Policy mu Max                2.5215485
Policy mu Min                -3.185829
Policy log std Mean          -1.0422649
Policy log std Std           0.30838123
Policy log std Max           -0.39361453
Policy log std Min           -2.6011078
Z mean eval                  1.0625545
Z variance eval              0.01778194
total_rewards                [4229.83684007 4141.67776461 4009.49117636 4104.7010454  4497.31099554
 4184.04697437 4387.71316563 4109.82755842 4231.39800259 4007.7221623 ]
total_rewards_mean           4190.372568528173
total_rewards_std            147.8893433390775
total_rewards_max            4497.310995536893
total_rewards_min            4007.7221622993093
Number of train steps total  980000
Number of env steps total    1187804
Number of rollouts total     0
Train Time (s)               147.26454979507253
(Previous) Eval Time (s)     21.04808470699936
Sample Time (s)              7.644937968812883
Epoch Time (s)               175.95757247088477
Total Train Time (s)         40993.60806085123
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:43:50.580454 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #244 | Epoch Duration: 176.04810166358948
2020-01-11 19:43:50.580655 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0593954
Z variance train             0.017563183
KL Divergence                17.819427
KL Loss                      1.7819427
QF Loss                      797.7419
VF Loss                      404.57275
Policy Loss                  -1079.4124
Q Predictions Mean           1075.3345
Q Predictions Std            442.31567
Q Predictions Max            1686.8809
Q Predictions Min            46.25234
V Predictions Mean           1069.0625
V Predictions Std            435.31387
V Predictions Max            1663.6411
V Predictions Min            259.98468
Log Pis Mean                 0.18097803
Log Pis Std                  2.9370754
Log Pis Max                  15.413373
Log Pis Min                  -6.9233155
Policy mu Mean               -0.07197998
Policy mu Std                0.6138178
Policy mu Max                2.3417923
Policy mu Min                -2.7733867
Policy log std Mean          -1.0014834
Policy log std Std           0.27433306
Policy log std Max           -0.2853912
Policy log std Min           -2.4870539
Z mean eval                  0.9293969
Z variance eval              0.014581877
total_rewards                [2472.95543027 4482.20018999 2791.43295764 4601.38512737 4465.89070675
 2229.35765099 4154.55172058 2732.02903665 3477.72308243 2375.07972823]
total_rewards_mean           3378.2605630911467
total_rewards_std            917.5012468426385
total_rewards_max            4601.385127365161
total_rewards_min            2229.357650994879
Number of train steps total  984000
Number of env steps total    1197802
Number of rollouts total     0
Train Time (s)               148.64688286278397
(Previous) Eval Time (s)     19.06496981717646
Sample Time (s)              7.286512971390039
Epoch Time (s)               174.99836565135047
Total Train Time (s)         41168.69361128984
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:46:45.667357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #245 | Epoch Duration: 175.08657002449036
2020-01-11 19:46:45.667491 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92914695
Z variance train             0.014606488
KL Divergence                17.642445
KL Loss                      1.7642444
QF Loss                      793.71985
VF Loss                      130.14348
Policy Loss                  -1091.7622
Q Predictions Mean           1088.9094
Q Predictions Std            437.44403
Q Predictions Max            1651.0687
Q Predictions Min            276.5016
V Predictions Mean           1096.4618
V Predictions Std            435.45316
V Predictions Max            1658.7385
V Predictions Min            291.78528
Log Pis Mean                 0.33919707
Log Pis Std                  3.231005
Log Pis Max                  11.602787
Log Pis Min                  -6.6461954
Policy mu Mean               -0.00079825753
Policy mu Std                0.6078011
Policy mu Max                2.541887
Policy mu Min                -2.4981968
Policy log std Mean          -1.0287838
Policy log std Std           0.30387154
Policy log std Max           -0.16015822
Policy log std Min           -2.3360624
Z mean eval                  1.0179769
Z variance eval              0.019913003
total_rewards                [4228.43733767 3420.01242158 4110.80435724 3856.61957188 4119.62014074
 3996.07407118 3671.61363582 4456.38625272 3508.07039046 4192.4402971 ]
total_rewards_mean           3956.0078476386057
total_rewards_std            318.0456070985986
total_rewards_max            4456.386252718356
total_rewards_min            3420.012421581481
Number of train steps total  988000
Number of env steps total    1208504
Number of rollouts total     0
Train Time (s)               146.53206134401262
(Previous) Eval Time (s)     23.98126071691513
Sample Time (s)              7.270837540272623
Epoch Time (s)               177.78415960120037
Total Train Time (s)         41346.58071847586
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:49:43.559313 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #246 | Epoch Duration: 177.89170742034912
2020-01-11 19:49:43.559509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0261652
Z variance train             0.019564012
KL Divergence                15.989075
KL Loss                      1.5989075
QF Loss                      1502.7212
VF Loss                      327.36554
Policy Loss                  -1020.6663
Q Predictions Mean           1014.298
Q Predictions Std            412.9972
Q Predictions Max            1605.0183
Q Predictions Min            260.04834
V Predictions Mean           1023.54987
V Predictions Std            412.60925
V Predictions Max            1605.5525
V Predictions Min            278.26624
Log Pis Mean                 0.4766187
Log Pis Std                  3.4106631
Log Pis Max                  18.942196
Log Pis Min                  -6.652478
Policy mu Mean               -0.08954369
Policy mu Std                0.61776054
Policy mu Max                2.6827006
Policy mu Min                -2.955787
Policy log std Mean          -1.04257
Policy log std Std           0.3081608
Policy log std Max           -0.24649101
Policy log std Min           -2.3729746
Z mean eval                  0.91435397
Z variance eval              0.056240357
total_rewards                [4512.67448183 4260.01166078 4468.75917007 2246.89624464 4230.20301145
 1664.11956551 4545.27900163 4308.51395768 1371.25113044 4158.20237668]
total_rewards_mean           3576.5910600690395
total_rewards_std            1211.114664851031
total_rewards_max            4545.279001627012
total_rewards_min            1371.2511304359575
Number of train steps total  992000
Number of env steps total    1218718
Number of rollouts total     0
Train Time (s)               147.2243572738953
(Previous) Eval Time (s)     21.35556802712381
Sample Time (s)              7.497987689450383
Epoch Time (s)               176.07791299046949
Total Train Time (s)         41522.76627980871
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:52:39.746323 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #247 | Epoch Duration: 176.1866888999939
2020-01-11 19:52:39.746461 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90533257
Z variance train             0.056747325
KL Divergence                15.350549
KL Loss                      1.5350549
QF Loss                      835.79016
VF Loss                      126.58269
Policy Loss                  -1120.425
Q Predictions Mean           1117.5168
Q Predictions Std            440.33005
Q Predictions Max            1679.6375
Q Predictions Min            290.24472
V Predictions Mean           1123.6907
V Predictions Std            436.99942
V Predictions Max            1685.9689
V Predictions Min            299.87616
Log Pis Mean                 0.19202426
Log Pis Std                  3.3651092
Log Pis Max                  11.762138
Log Pis Min                  -7.283245
Policy mu Mean               -0.008985084
Policy mu Std                0.62372005
Policy mu Max                2.285076
Policy mu Min                -2.8096368
Policy log std Mean          -1.0385087
Policy log std Std           0.32338214
Policy log std Max           -0.2869581
Policy log std Min           -2.5728998
Z mean eval                  1.100898
Z variance eval              0.039867256
total_rewards                [3985.35928997 2738.50144722 3524.68769235  411.43393053 3880.31784861
 3913.12399328 4010.29442199 4155.8428048  4276.0309342  1436.57941896]
total_rewards_mean           3233.2171781920206
total_rewards_std            1245.3651906307916
total_rewards_max            4276.030934203834
total_rewards_min            411.43393053280795
Number of train steps total  996000
Number of env steps total    1228335
Number of rollouts total     0
Train Time (s)               145.74972484493628
(Previous) Eval Time (s)     21.48528989776969
Sample Time (s)              7.218408292159438
Epoch Time (s)               174.4534230348654
Total Train Time (s)         41697.312095772475
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:55:34.293757 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #248 | Epoch Duration: 174.5472002029419
2020-01-11 19:55:34.293886 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1033568
Z variance train             0.040050767
KL Divergence                17.991192
KL Loss                      1.7991192
QF Loss                      898.0348
VF Loss                      209.35579
Policy Loss                  -1131.1276
Q Predictions Mean           1126.5759
Q Predictions Std            432.71606
Q Predictions Max            1679.9542
Q Predictions Min            290.3745
V Predictions Mean           1124.2477
V Predictions Std            429.26056
V Predictions Max            1680.1964
V Predictions Min            282.71097
Log Pis Mean                 0.23347111
Log Pis Std                  3.2816443
Log Pis Max                  10.236598
Log Pis Min                  -7.829558
Policy mu Mean               0.0132647175
Policy mu Std                0.6415854
Policy mu Max                2.734565
Policy mu Min                -2.9233751
Policy log std Mean          -0.98964983
Policy log std Std           0.31094348
Policy log std Max           -0.15930963
Policy log std Min           -2.6903193
Z mean eval                  0.93672454
Z variance eval              0.023198634
total_rewards                [1450.00376544 4475.32232404 3002.59547457 4010.19063131 2058.78667139
 3364.13685685 1669.49991219 4448.0515459     9.60114315 4247.04212969]
total_rewards_mean           2873.523045453209
total_rewards_std            1443.0091224488376
total_rewards_max            4475.322324041925
total_rewards_min            9.601143151293625
Number of train steps total  1000000
Number of env steps total    1238375
Number of rollouts total     0
Train Time (s)               146.81984106916934
(Previous) Eval Time (s)     19.465709306765348
Sample Time (s)              7.7242831834591925
Epoch Time (s)               174.00983355939388
Total Train Time (s)         41871.48201493174
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 19:58:28.470140 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #249 | Epoch Duration: 174.176123380661
2020-01-11 19:58:28.470414 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94127923
Z variance train             0.02317489
KL Divergence                18.633175
KL Loss                      1.8633175
QF Loss                      1177.4875
VF Loss                      443.55054
Policy Loss                  -1115.9393
Q Predictions Mean           1109.4062
Q Predictions Std            437.04623
Q Predictions Max            1668.5916
Q Predictions Min            -15.254794
V Predictions Mean           1106.764
V Predictions Std            431.19083
V Predictions Max            1658.9905
V Predictions Min            261.12546
Log Pis Mean                 0.48031124
Log Pis Std                  3.3822827
Log Pis Max                  15.293879
Log Pis Min                  -6.8280396
Policy mu Mean               -0.021881498
Policy mu Std                0.62485504
Policy mu Max                4.142482
Policy mu Min                -2.5434213
Policy log std Mean          -1.0294762
Policy log std Std           0.30609238
Policy log std Max           0.029337764
Policy log std Min           -2.2511153
Z mean eval                  0.97074556
Z variance eval              0.013057654
total_rewards                [4528.54452671 4228.62345394 4186.85051198   46.82407801 4598.25203609
 4398.89608458 4426.45739743 4632.76419963 4410.07397939 4374.32780996]
total_rewards_mean           3983.161407770787
total_rewards_std            1319.047671981071
total_rewards_max            4632.76419962732
total_rewards_min            46.82407800682871
Number of train steps total  1004000
Number of env steps total    1247818
Number of rollouts total     0
Train Time (s)               146.48079588031396
(Previous) Eval Time (s)     19.099742677994072
Sample Time (s)              7.19110423931852
Epoch Time (s)               172.77164279762655
Total Train Time (s)         42044.348155037966
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:01:21.339683 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #250 | Epoch Duration: 172.8690629005432
2020-01-11 20:01:21.339899 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9691205
Z variance train             0.013067807
KL Divergence                19.163073
KL Loss                      1.9163073
QF Loss                      1778.814
VF Loss                      167.08963
Policy Loss                  -1115.7184
Q Predictions Mean           1112.929
Q Predictions Std            419.6323
Q Predictions Max            1634.1139
Q Predictions Min            39.92983
V Predictions Mean           1120.8274
V Predictions Std            418.87387
V Predictions Max            1629.9501
V Predictions Min            33.499413
Log Pis Mean                 0.21818577
Log Pis Std                  3.6680205
Log Pis Max                  15.486919
Log Pis Min                  -9.367874
Policy mu Mean               -0.009119308
Policy mu Std                0.62826675
Policy mu Max                2.5271566
Policy mu Min                -3.5467157
Policy log std Mean          -1.039386
Policy log std Std           0.31556103
Policy log std Max           -0.2240771
Policy log std Min           -2.5088105
Z mean eval                  0.8573019
Z variance eval              0.042831298
total_rewards                [ 774.32964976 3841.68038926 2621.65534481 4312.69701354 4755.97740129
 4510.42304306 4356.30233057 1136.67483916 3952.03825122 4249.2921773 ]
total_rewards_mean           3451.1070439967625
total_rewards_std            1365.168696809845
total_rewards_max            4755.977401293763
total_rewards_min            774.3296497588053
Number of train steps total  1008000
Number of env steps total    1256725
Number of rollouts total     0
Train Time (s)               147.45018149679527
(Previous) Eval Time (s)     19.552846777718514
Sample Time (s)              7.339808419812471
Epoch Time (s)               174.34283669432625
Total Train Time (s)         42218.79587793443
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:04:15.792463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #251 | Epoch Duration: 174.45240998268127
2020-01-11 20:04:15.792629 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8592002
Z variance train             0.042893596
KL Divergence                18.563404
KL Loss                      1.8563404
QF Loss                      853.5449
VF Loss                      116.51091
Policy Loss                  -1123.5487
Q Predictions Mean           1116.6765
Q Predictions Std            427.0953
Q Predictions Max            1708.7864
Q Predictions Min            93.54506
V Predictions Mean           1125.2947
V Predictions Std            420.76804
V Predictions Max            1701.8102
V Predictions Min            268.90463
Log Pis Mean                 0.19383426
Log Pis Std                  3.3412945
Log Pis Max                  15.584903
Log Pis Min                  -8.080096
Policy mu Mean               -0.05581699
Policy mu Std                0.6342359
Policy mu Max                2.5300424
Policy mu Min                -4.318058
Policy log std Mean          -1.0327736
Policy log std Std           0.29640225
Policy log std Max           -0.31723744
Policy log std Min           -2.3486009
Z mean eval                  0.94762355
Z variance eval              0.022436421
total_rewards                [4446.06875375 4374.88038622 4493.08869478 4275.26805594 4212.4786033
 4246.05703237 4353.02896302 4079.40515798 4374.5862238  4318.30103012]
total_rewards_mean           4317.316290128301
total_rewards_std            113.92170710510139
total_rewards_max            4493.088694777314
total_rewards_min            4079.4051579805723
Number of train steps total  1012000
Number of env steps total    1266426
Number of rollouts total     0
Train Time (s)               147.50997381005436
(Previous) Eval Time (s)     21.36624225322157
Sample Time (s)              7.0913719376549125
Epoch Time (s)               175.96758800093085
Total Train Time (s)         42394.85327819083
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:07:11.852205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #252 | Epoch Duration: 176.0594446659088
2020-01-11 20:07:11.852380 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9470359
Z variance train             0.022579536
KL Divergence                17.372972
KL Loss                      1.7372973
QF Loss                      763.8219
VF Loss                      200.3288
Policy Loss                  -1137.3307
Q Predictions Mean           1133.5803
Q Predictions Std            413.665
Q Predictions Max            1665.4664
Q Predictions Min            307.13608
V Predictions Mean           1146.3306
V Predictions Std            412.29962
V Predictions Max            1681.3022
V Predictions Min            315.90997
Log Pis Mean                 0.50852525
Log Pis Std                  3.2479546
Log Pis Max                  13.331638
Log Pis Min                  -9.138624
Policy mu Mean               0.0050601256
Policy mu Std                0.66593575
Policy mu Max                3.564655
Policy mu Min                -2.8676784
Policy log std Mean          -1.0019801
Policy log std Std           0.30380166
Policy log std Max           -0.2307018
Policy log std Min           -2.3763907
Z mean eval                  0.9971959
Z variance eval              0.021251108
total_rewards                [ 438.05100603 3647.40861085 1634.6377949  4180.05935112 2497.71912036
 4532.11474834  149.60789529 4429.75478262 4367.33699026 4485.09199571]
total_rewards_mean           3036.17822954879
total_rewards_std            1645.299066772955
total_rewards_max            4532.114748341041
total_rewards_min            149.6078952944051
Number of train steps total  1016000
Number of env steps total    1273640
Number of rollouts total     0
Train Time (s)               146.3016569148749
(Previous) Eval Time (s)     17.99060367932543
Sample Time (s)              6.26476133055985
Epoch Time (s)               170.5570219247602
Total Train Time (s)         42565.5018360191
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:10:02.503619 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #253 | Epoch Duration: 170.65109419822693
2020-01-11 20:10:02.503814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0037895
Z variance train             0.021340525
KL Divergence                17.218513
KL Loss                      1.7218513
QF Loss                      704.4727
VF Loss                      524.2762
Policy Loss                  -1151.3225
Q Predictions Mean           1145.0879
Q Predictions Std            434.04483
Q Predictions Max            1718.0822
Q Predictions Min            4.490333
V Predictions Mean           1139.5605
V Predictions Std            425.94235
V Predictions Max            1703.1023
V Predictions Min            198.33945
Log Pis Mean                 0.39734748
Log Pis Std                  3.503488
Log Pis Max                  15.63241
Log Pis Min                  -5.8304586
Policy mu Mean               -0.0145085715
Policy mu Std                0.64235663
Policy mu Max                3.2596831
Policy mu Min                -2.720138
Policy log std Mean          -0.99742323
Policy log std Std           0.30719855
Policy log std Max           -0.22557563
Policy log std Min           -2.6816368
Z mean eval                  1.0270063
Z variance eval              0.06744175
total_rewards                [4452.90637249 4157.07680945 4331.49036714 4003.8235707  4383.66368894
 3468.68246394 4487.67651263 2626.62301001 4379.25206073 4212.645744  ]
total_rewards_mean           4050.384060003556
total_rewards_std            552.8880067835343
total_rewards_max            4487.676512633479
total_rewards_min            2626.623010006086
Number of train steps total  1020000
Number of env steps total    1283148
Number of rollouts total     0
Train Time (s)               147.54227703204378
(Previous) Eval Time (s)     22.983533864840865
Sample Time (s)              7.146630925126374
Epoch Time (s)               177.67244182201102
Total Train Time (s)         42743.2702697115
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:13:00.273586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #254 | Epoch Duration: 177.7696464061737
2020-01-11 20:13:00.273721 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0279866
Z variance train             0.067596644
KL Divergence                14.438133
KL Loss                      1.4438133
QF Loss                      1348.3362
VF Loss                      251.4993
Policy Loss                  -1141.7559
Q Predictions Mean           1131.8129
Q Predictions Std            407.04077
Q Predictions Max            1658.98
Q Predictions Min            -127.43465
V Predictions Mean           1148.1307
V Predictions Std            393.38132
V Predictions Max            1655.0269
V Predictions Min            314.98343
Log Pis Mean                 0.34548885
Log Pis Std                  3.2159317
Log Pis Max                  10.343415
Log Pis Min                  -7.0897675
Policy mu Mean               0.0020529283
Policy mu Std                0.60239565
Policy mu Max                2.3435147
Policy mu Min                -2.4025385
Policy log std Mean          -1.0555253
Policy log std Std           0.306878
Policy log std Max           -0.2993058
Policy log std Min           -2.3424277
Z mean eval                  1.2960942
Z variance eval              0.04282055
total_rewards                [4048.58630616 4181.55134748 3332.26353518 4088.4807113  4518.46344474
 4021.49803022 4232.16491846 4334.20689638 4318.71216665 4427.41463364]
total_rewards_mean           4150.334199021217
total_rewards_std            313.3912333961228
total_rewards_max            4518.463444743996
total_rewards_min            3332.263535180362
Number of train steps total  1024000
Number of env steps total    1290474
Number of rollouts total     0
Train Time (s)               146.26396775292233
(Previous) Eval Time (s)     23.40992822498083
Sample Time (s)              7.28491714829579
Epoch Time (s)               176.95881312619895
Total Train Time (s)         42920.31344360253
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:15:57.318511 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #255 | Epoch Duration: 177.044695854187
2020-01-11 20:15:57.318663 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2929863
Z variance train             0.04319607
KL Divergence                15.346523
KL Loss                      1.5346524
QF Loss                      1584.2355
VF Loss                      221.89978
Policy Loss                  -1071.1216
Q Predictions Mean           1069.9791
Q Predictions Std            446.4245
Q Predictions Max            1680.2035
Q Predictions Min            44.187607
V Predictions Mean           1067.7559
V Predictions Std            447.06735
V Predictions Max            1676.7153
V Predictions Min            -46.725864
Log Pis Mean                 0.22994272
Log Pis Std                  3.2666073
Log Pis Max                  14.50222
Log Pis Min                  -7.969261
Policy mu Mean               -0.05209135
Policy mu Std                0.61995345
Policy mu Max                2.4483922
Policy mu Min                -3.3787751
Policy log std Mean          -0.98048836
Policy log std Std           0.32510883
Policy log std Max           1.3500888
Policy log std Min           -2.563734
Z mean eval                  1.018167
Z variance eval              0.009569755
total_rewards                [4379.28457146 4078.27324676 1004.49979896 4170.88719553 4580.03041116
 4356.97915883 4317.37257979 4325.68700334 4164.92967019 4292.45147162]
total_rewards_mean           3967.0395107633717
total_rewards_std            996.2298867451351
total_rewards_max            4580.030411159158
total_rewards_min            1004.4997989596882
Number of train steps total  1028000
Number of env steps total    1301312
Number of rollouts total     0
Train Time (s)               146.7376505723223
(Previous) Eval Time (s)     22.5881544072181
Sample Time (s)              7.689836053177714
Epoch Time (s)               177.01564103271812
Total Train Time (s)         43097.42858724808
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:18:54.436900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #256 | Epoch Duration: 177.11813235282898
2020-01-11 20:18:54.437073 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0219178
Z variance train             0.009619473
KL Divergence                19.785685
KL Loss                      1.9785684
QF Loss                      3371.6538
VF Loss                      251.25902
Policy Loss                  -1165.2856
Q Predictions Mean           1160.3109
Q Predictions Std            423.3956
Q Predictions Max            1705.0002
Q Predictions Min            316.92062
V Predictions Mean           1159.5723
V Predictions Std            421.39917
V Predictions Max            1699.4365
V Predictions Min            312.383
Log Pis Mean                 0.37744647
Log Pis Std                  3.3212285
Log Pis Max                  10.687199
Log Pis Min                  -7.066723
Policy mu Mean               -0.003321642
Policy mu Std                0.6275904
Policy mu Max                2.6110582
Policy mu Min                -2.7537615
Policy log std Mean          -1.0376563
Policy log std Std           0.32187802
Policy log std Max           -0.3124156
Policy log std Min           -2.8807156
Z mean eval                  1.0102334
Z variance eval              0.0073967925
total_rewards                [1481.16164444  975.94169234  218.43640422 4328.48465407 4507.83037437
 4193.93366654 1047.31322279 4109.50828198 4420.11893955 4157.33451226]
total_rewards_mean           2944.0063392560855
total_rewards_std            1672.5274852024402
total_rewards_max            4507.8303743699635
total_rewards_min            218.4364042223415
Number of train steps total  1032000
Number of env steps total    1310724
Number of rollouts total     0
Train Time (s)               147.15652562864125
(Previous) Eval Time (s)     14.766544472891837
Sample Time (s)              7.728897288907319
Epoch Time (s)               169.6519673904404
Total Train Time (s)         43267.16612913646
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:21:44.176127 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #257 | Epoch Duration: 169.73893690109253
2020-01-11 20:21:44.176248 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0100113
Z variance train             0.007402307
KL Divergence                19.19442
KL Loss                      1.919442
QF Loss                      4884.5986
VF Loss                      187.91927
Policy Loss                  -1127.4374
Q Predictions Mean           1121.5948
Q Predictions Std            426.59177
Q Predictions Max            1722.4338
Q Predictions Min            326.66382
V Predictions Mean           1123.3616
V Predictions Std            426.29733
V Predictions Max            1704.5193
V Predictions Min            322.02353
Log Pis Mean                 0.031171829
Log Pis Std                  3.5989046
Log Pis Max                  21.317953
Log Pis Min                  -7.545041
Policy mu Mean               0.005151487
Policy mu Std                0.6276264
Policy mu Max                3.2822797
Policy mu Min                -3.3084316
Policy log std Mean          -1.002588
Policy log std Std           0.33855635
Policy log std Max           -0.33620638
Policy log std Min           -2.681993
Z mean eval                  0.9859125
Z variance eval              0.016806953
total_rewards                [4459.16779485 4411.43512521 3231.5787441  4207.06417487 4068.04979338
 4142.6370034   618.78146818 2078.06162719   22.04962209 4337.19029109]
total_rewards_mean           3157.601564436244
total_rewards_std            1581.3398730877736
total_rewards_max            4459.167794854027
total_rewards_min            22.049622090380282
Number of train steps total  1036000
Number of env steps total    1319508
Number of rollouts total     0
Train Time (s)               146.56487093539909
(Previous) Eval Time (s)     18.196633127052337
Sample Time (s)              6.486884186044335
Epoch Time (s)               171.24838824849576
Total Train Time (s)         43438.50256376015
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:24:35.514326 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #258 | Epoch Duration: 171.3379831314087
2020-01-11 20:24:35.514459 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #258 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.986677
Z variance train             0.0168983
KL Divergence                19.124317
KL Loss                      1.9124317
QF Loss                      852.0931
VF Loss                      119.929016
Policy Loss                  -1110.7959
Q Predictions Mean           1109.3545
Q Predictions Std            458.40945
Q Predictions Max            1739.598
Q Predictions Min            317.6572
V Predictions Mean           1115.7808
V Predictions Std            456.06815
V Predictions Max            1745.8883
V Predictions Min            320.6856
Log Pis Mean                 0.35704118
Log Pis Std                  3.715355
Log Pis Max                  13.387763
Log Pis Min                  -6.3125362
Policy mu Mean               0.020841891
Policy mu Std                0.62449545
Policy mu Max                2.5945132
Policy mu Min                -2.4068003
Policy log std Mean          -0.99227434
Policy log std Std           0.33707392
Policy log std Max           -0.3742658
Policy log std Min           -2.6402123
Z mean eval                  0.94171417
Z variance eval              0.009236179
total_rewards                [4339.12937344 4362.0658885  3057.34575262 4586.13820698 4374.3773682
 4627.7162367  4588.0856022  4351.71186718 4409.30795754 4242.94746795]
total_rewards_mean           4293.882572130916
total_rewards_std            429.51999746992857
total_rewards_max            4627.716236704336
total_rewards_min            3057.345752620726
Number of train steps total  1040000
Number of env steps total    1330262
Number of rollouts total     0
Train Time (s)               148.270577641204
(Previous) Eval Time (s)     23.535495267715305
Sample Time (s)              7.740566095337272
Epoch Time (s)               179.54663900425658
Total Train Time (s)         43618.137316721026
Epoch                        259
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:27:35.150852 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #259 | Epoch Duration: 179.6363022327423
2020-01-11 20:27:35.150983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9433359
Z variance train             0.009206794
KL Divergence                18.779007
KL Loss                      1.8779007
QF Loss                      858.5246
VF Loss                      167.47978
Policy Loss                  -1146.8309
Q Predictions Mean           1142.1843
Q Predictions Std            420.73972
Q Predictions Max            1732.139
Q Predictions Min            136.91258
V Predictions Mean           1142.5938
V Predictions Std            412.7966
V Predictions Max            1708.9252
V Predictions Min            313.77292
Log Pis Mean                 0.29545128
Log Pis Std                  3.2125852
Log Pis Max                  15.087541
Log Pis Min                  -6.5465217
Policy mu Mean               -0.020437974
Policy mu Std                0.6186801
Policy mu Max                2.3346488
Policy mu Min                -2.689066
Policy log std Mean          -1.0161712
Policy log std Std           0.30725574
Policy log std Max           -0.09345025
Policy log std Min           -2.2703063
Z mean eval                  1.1209414
Z variance eval              0.113998935
total_rewards                [ 802.00421455 4077.22003404 4068.28413706  596.18152485 4080.96515606
 3937.42248944 1316.68342638 1495.55981614 3100.76462604 3882.17995835]
total_rewards_mean           2735.72653829016
total_rewards_std            1419.3412078451545
total_rewards_max            4080.9651560563634
total_rewards_min            596.181524846306
Number of train steps total  1044000
Number of env steps total    1339096
Number of rollouts total     0
Train Time (s)               148.38101520994678
(Previous) Eval Time (s)     18.45090964017436
Sample Time (s)              7.10623259562999
Epoch Time (s)               173.93815744575113
Total Train Time (s)         43792.16483684257
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:30:29.182091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #260 | Epoch Duration: 174.03101468086243
2020-01-11 20:30:29.182224 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #260 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.128196
Z variance train             0.11377736
KL Divergence                18.15481
KL Loss                      1.8154811
QF Loss                      1255.1829
VF Loss                      491.5666
Policy Loss                  -1135.0283
Q Predictions Mean           1129.8325
Q Predictions Std            413.30453
Q Predictions Max            1685.0956
Q Predictions Min            116.43638
V Predictions Mean           1134.2512
V Predictions Std            414.5101
V Predictions Max            1680.1493
V Predictions Min            -14.179445
Log Pis Mean                 0.3754841
Log Pis Std                  3.905049
Log Pis Max                  25.359497
Log Pis Min                  -8.034541
Policy mu Mean               -0.0383934
Policy mu Std                0.65924644
Policy mu Max                3.315299
Policy mu Min                -5.3310647
Policy log std Mean          -1.0184097
Policy log std Std           0.3347244
Policy log std Max           -0.1413393
Policy log std Min           -2.803409
Z mean eval                  0.89686763
Z variance eval              0.030058226
total_rewards                [4475.96544411 4710.3423894  4530.28846068 2463.95462952  798.6022118
 4322.24592894 2135.79123027 4556.95747734 4492.60150642 4379.49351213]
total_rewards_mean           3686.6242790616934
total_rewards_std            1300.563916026686
total_rewards_max            4710.342389396306
total_rewards_min            798.6022118049916
Number of train steps total  1048000
Number of env steps total    1346500
Number of rollouts total     0
Train Time (s)               146.71242997981608
(Previous) Eval Time (s)     21.305976774077863
Sample Time (s)              7.111092755105346
Epoch Time (s)               175.1294995089993
Total Train Time (s)         43967.3827996715
Epoch                        261
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:33:24.401358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #261 | Epoch Duration: 175.21904373168945
2020-01-11 20:33:24.401489 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8961288
Z variance train             0.030088132
KL Divergence                16.514505
KL Loss                      1.6514505
QF Loss                      656.5442
VF Loss                      145.4957
Policy Loss                  -1115.6351
Q Predictions Mean           1115.1085
Q Predictions Std            429.09473
Q Predictions Max            1721.2126
Q Predictions Min            -42.9246
V Predictions Mean           1113.6073
V Predictions Std            427.74097
V Predictions Max            1707.8604
V Predictions Min            34.522877
Log Pis Mean                 0.3480028
Log Pis Std                  3.2320657
Log Pis Max                  11.734987
Log Pis Min                  -7.3293524
Policy mu Mean               -0.060075745
Policy mu Std                0.63784665
Policy mu Max                2.7057407
Policy mu Min                -2.7363198
Policy log std Mean          -0.9713747
Policy log std Std           0.3106738
Policy log std Max           -0.22701722
Policy log std Min           -2.2358599
Z mean eval                  1.0149002
Z variance eval              0.01040545
total_rewards                [1924.43315211 2658.23015373    9.94633324  667.1044197   477.68759754
 2359.99473457 3268.85032124 1881.26389968  852.8374887  1775.86109079]
total_rewards_mean           1587.6209191324126
total_rewards_std            995.6237834512247
total_rewards_max            3268.850321240693
total_rewards_min            9.946333243638316
Number of train steps total  1052000
Number of env steps total    1353740
Number of rollouts total     0
Train Time (s)               146.73345384001732
(Previous) Eval Time (s)     10.329560341779143
Sample Time (s)              7.083407093305141
Epoch Time (s)               164.1464212751016
Total Train Time (s)         44131.628434270155
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:36:08.649343 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #262 | Epoch Duration: 164.24775910377502
2020-01-11 20:36:08.649479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0141652
Z variance train             0.010385767
KL Divergence                18.45645
KL Loss                      1.845645
QF Loss                      556.9972
VF Loss                      198.45592
Policy Loss                  -1110.815
Q Predictions Mean           1105.1619
Q Predictions Std            453.32257
Q Predictions Max            1718.3137
Q Predictions Min            325.30853
V Predictions Mean           1112.4336
V Predictions Std            451.09204
V Predictions Max            1724.2728
V Predictions Min            347.91385
Log Pis Mean                 0.044137046
Log Pis Std                  3.3782635
Log Pis Max                  18.326237
Log Pis Min                  -7.284975
Policy mu Mean               -0.029220888
Policy mu Std                0.6590816
Policy mu Max                3.8651662
Policy mu Min                -2.474481
Policy log std Mean          -0.9468399
Policy log std Std           0.29570788
Policy log std Max           -0.28425592
Policy log std Min           -2.1748457
Z mean eval                  0.9428541
Z variance eval              0.06651505
total_rewards                [4237.4221331  2938.94440036 3202.46249436 1840.31139788 2623.04879053
 2069.0902497  1263.07301663 2429.9579375  1104.87391055  887.79254859]
total_rewards_mean           2259.697687919281
total_rewards_std            992.159593681203
total_rewards_max            4237.422133101038
total_rewards_min            887.7925485875161
Number of train steps total  1056000
Number of env steps total    1362430
Number of rollouts total     0
Train Time (s)               146.42877370817587
(Previous) Eval Time (s)     14.378263796214014
Sample Time (s)              8.314320221543312
Epoch Time (s)               169.1213577259332
Total Train Time (s)         44300.833723211195
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:38:57.856294 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #263 | Epoch Duration: 169.20672178268433
2020-01-11 20:38:57.856422 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9404007
Z variance train             0.0670267
KL Divergence                15.714238
KL Loss                      1.5714239
QF Loss                      1173.0531
VF Loss                      137.63773
Policy Loss                  -1123.2875
Q Predictions Mean           1117.6155
Q Predictions Std            429.1225
Q Predictions Max            1701.3795
Q Predictions Min            307.05338
V Predictions Mean           1122.7883
V Predictions Std            426.9914
V Predictions Max            1698.7855
V Predictions Min            323.6064
Log Pis Mean                 0.506147
Log Pis Std                  3.749727
Log Pis Max                  18.072224
Log Pis Min                  -7.097206
Policy mu Mean               -0.038235225
Policy mu Std                0.6565168
Policy mu Max                3.575375
Policy mu Min                -2.642206
Policy log std Mean          -1.020422
Policy log std Std           0.32813695
Policy log std Max           -0.33027363
Policy log std Min           -2.5096562
Z mean eval                  0.95016825
Z variance eval              0.014505103
total_rewards                [1250.55030804 3914.41086018 3312.80019506 1602.91906519 4172.78903361
  832.51020524  944.18514104 4333.71956265 1529.77352713   32.0504729 ]
total_rewards_mean           2192.570837104472
total_rewards_std            1499.1964856618465
total_rewards_max            4333.719562646661
total_rewards_min            32.05047290044072
Number of train steps total  1060000
Number of env steps total    1372387
Number of rollouts total     0
Train Time (s)               146.35894423909485
(Previous) Eval Time (s)     12.791376804932952
Sample Time (s)              7.074752783402801
Epoch Time (s)               166.2250738274306
Total Train Time (s)         44467.14862900507
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:41:44.174124 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #264 | Epoch Duration: 166.31759333610535
2020-01-11 20:41:44.174294 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9473232
Z variance train             0.014480854
KL Divergence                17.647182
KL Loss                      1.7647183
QF Loss                      4433.6113
VF Loss                      144.52019
Policy Loss                  -1158.9492
Q Predictions Mean           1155.1057
Q Predictions Std            449.2296
Q Predictions Max            1771.96
Q Predictions Min            -86.93773
V Predictions Mean           1162.2019
V Predictions Std            444.5176
V Predictions Max            1759.5994
V Predictions Min            221.57582
Log Pis Mean                 0.6435192
Log Pis Std                  4.1244855
Log Pis Max                  34.67414
Log Pis Min                  -6.671764
Policy mu Mean               -0.07853302
Policy mu Std                0.6803481
Policy mu Max                4.805861
Policy mu Min                -3.5569074
Policy log std Mean          -0.98774827
Policy log std Std           0.3116123
Policy log std Max           -0.3772503
Policy log std Min           -2.271185
Z mean eval                  1.0968996
Z variance eval              0.031094069
total_rewards                [4349.64684983 4307.95832685 4411.32831888 4094.10131735 3093.42298545
 4234.4626267  4436.44723504 4310.27021825 4264.35167891 4711.75858338]
total_rewards_mean           4221.3748140647585
total_rewards_std            405.60568371090517
total_rewards_max            4711.758583379301
total_rewards_min            3093.422985450584
Number of train steps total  1064000
Number of env steps total    1381394
Number of rollouts total     0
Train Time (s)               146.96019587200135
(Previous) Eval Time (s)     20.323211524635553
Sample Time (s)              7.891727025154978
Epoch Time (s)               175.17513442179188
Total Train Time (s)         44642.42370063299
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:44:39.453418 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #265 | Epoch Duration: 175.27893352508545
2020-01-11 20:44:39.453699 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1022826
Z variance train             0.03178001
KL Divergence                16.295086
KL Loss                      1.6295086
QF Loss                      900.4951
VF Loss                      225.74036
Policy Loss                  -1179.8679
Q Predictions Mean           1178.4576
Q Predictions Std            408.44437
Q Predictions Max            1707.6599
Q Predictions Min            94.26474
V Predictions Mean           1189.4314
V Predictions Std            407.34113
V Predictions Max            1707.8981
V Predictions Min            259.2364
Log Pis Mean                 0.33639395
Log Pis Std                  3.284208
Log Pis Max                  15.646261
Log Pis Min                  -7.8306146
Policy mu Mean               -0.017997038
Policy mu Std                0.6494714
Policy mu Max                4.0563903
Policy mu Min                -2.4056742
Policy log std Mean          -1.0047563
Policy log std Std           0.3131669
Policy log std Max           -0.33029294
Policy log std Min           -2.4844766
Z mean eval                  0.9263061
Z variance eval              0.011754667
total_rewards                [2019.78381858 2031.54996877 4192.03604468 4368.23340725 1964.66565678
 1967.08706917  421.17264286  774.71400528 2047.33006565 4377.57399996]
total_rewards_mean           2416.4146678980464
total_rewards_std            1353.9711284114933
total_rewards_max            4377.573999961158
total_rewards_min            421.17264285751594
Number of train steps total  1068000
Number of env steps total    1389923
Number of rollouts total     0
Train Time (s)               146.1001144940965
(Previous) Eval Time (s)     15.826924783177674
Sample Time (s)              7.196328193880618
Epoch Time (s)               169.12336747115478
Total Train Time (s)         44811.631549803074
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:47:28.661630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #266 | Epoch Duration: 169.20778059959412
2020-01-11 20:47:28.661767 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92560273
Z variance train             0.011784827
KL Divergence                17.78503
KL Loss                      1.7785031
QF Loss                      565.50964
VF Loss                      177.73929
Policy Loss                  -1142.7854
Q Predictions Mean           1137.4473
Q Predictions Std            443.95837
Q Predictions Max            1779.0409
Q Predictions Min            348.71844
V Predictions Mean           1133.9215
V Predictions Std            440.8478
V Predictions Max            1751.4801
V Predictions Min            344.73373
Log Pis Mean                 0.1555936
Log Pis Std                  3.9202907
Log Pis Max                  14.420998
Log Pis Min                  -11.114471
Policy mu Mean               -0.012200167
Policy mu Std                0.6611486
Policy mu Max                3.257173
Policy mu Min                -2.4357615
Policy log std Mean          -0.9866599
Policy log std Std           0.33799714
Policy log std Max           -0.33970082
Policy log std Min           -2.271665
Z mean eval                  0.9741597
Z variance eval              0.013943994
total_rewards                [4220.37251957  322.11860992 1034.02804359 3318.69902271 4122.08392424
 4287.55923252 4045.97037974 4296.2481519  4139.33477302  662.58984677]
total_rewards_mean           3044.9004503980304
total_rewards_std            1583.021682990914
total_rewards_max            4296.248151904822
total_rewards_min            322.1186099195971
Number of train steps total  1072000
Number of env steps total    1398490
Number of rollouts total     0
Train Time (s)               148.10178962396458
(Previous) Eval Time (s)     17.16161915520206
Sample Time (s)              6.888672499917448
Epoch Time (s)               172.1520812790841
Total Train Time (s)         44983.88793778373
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:50:20.923281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #267 | Epoch Duration: 172.2613866329193
2020-01-11 20:50:20.923502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9744317
Z variance train             0.013959968
KL Divergence                18.282578
KL Loss                      1.8282578
QF Loss                      887.6925
VF Loss                      153.13823
Policy Loss                  -1142.0348
Q Predictions Mean           1135.3306
Q Predictions Std            447.4254
Q Predictions Max            1731.1276
Q Predictions Min            278.55887
V Predictions Mean           1139.6395
V Predictions Std            442.98846
V Predictions Max            1728.5602
V Predictions Min            326.18375
Log Pis Mean                 0.0739103
Log Pis Std                  3.158101
Log Pis Max                  12.768229
Log Pis Min                  -6.6887865
Policy mu Mean               -0.013030654
Policy mu Std                0.6635215
Policy mu Max                3.5497868
Policy mu Min                -2.7954724
Policy log std Mean          -0.94886243
Policy log std Std           0.3031791
Policy log std Max           -0.2460559
Policy log std Min           -2.2727726
Z mean eval                  1.0581477
Z variance eval              0.028678874
total_rewards                [4262.10842672 4557.77556195 4165.11352476 4150.81485791 4337.57936996
 4072.56127447 4556.97910718 4366.98712579 2738.79215507 4249.54290583]
total_rewards_mean           4145.825430962251
total_rewards_std            493.37800670634084
total_rewards_max            4557.775561952345
total_rewards_min            2738.7921550650244
Number of train steps total  1076000
Number of env steps total    1408001
Number of rollouts total     0
Train Time (s)               144.96030478691682
(Previous) Eval Time (s)     20.19533340772614
Sample Time (s)              7.414458393584937
Epoch Time (s)               172.5700965882279
Total Train Time (s)         45156.568349016365
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:53:13.605411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #268 | Epoch Duration: 172.6817409992218
2020-01-11 20:53:13.605586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0591815
Z variance train             0.028675128
KL Divergence                16.982267
KL Loss                      1.6982268
QF Loss                      1770.044
VF Loss                      599.49634
Policy Loss                  -1149.4468
Q Predictions Mean           1139.7043
Q Predictions Std            445.04245
Q Predictions Max            1803.4467
Q Predictions Min            -9.526175
V Predictions Mean           1150.2798
V Predictions Std            432.5167
V Predictions Max            1793.3346
V Predictions Min            346.65933
Log Pis Mean                 0.58656824
Log Pis Std                  3.5090275
Log Pis Max                  13.404198
Log Pis Min                  -8.2099
Policy mu Mean               -0.08429426
Policy mu Std                0.6610568
Policy mu Max                3.4715316
Policy mu Min                -2.8687613
Policy log std Mean          -0.98110133
Policy log std Std           0.33798745
Policy log std Max           -0.13806939
Policy log std Min           -2.7002826
Z mean eval                  1.1286669
Z variance eval              0.07005249
total_rewards                [4092.03052758  416.87981173 1360.12027964  922.67273212 1108.81364007
 4367.57923958 2349.09917043 4011.96617028 3965.43012578 4249.7408535 ]
total_rewards_mean           2684.4332550709687
total_rewards_std            1525.1958799827642
total_rewards_max            4367.579239579516
total_rewards_min            416.8798117338823
Number of train steps total  1080000
Number of env steps total    1417280
Number of rollouts total     0
Train Time (s)               147.5775320008397
(Previous) Eval Time (s)     16.64904216118157
Sample Time (s)              7.0274433312006295
Epoch Time (s)               171.2540174932219
Total Train Time (s)         45327.91236397484
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:56:04.953296 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #269 | Epoch Duration: 171.34757781028748
2020-01-11 20:56:04.953474 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1285583
Z variance train             0.07015107
KL Divergence                17.831491
KL Loss                      1.7831491
QF Loss                      1769.3744
VF Loss                      150.4033
Policy Loss                  -1130.3785
Q Predictions Mean           1121.2108
Q Predictions Std            445.48032
Q Predictions Max            1719.9297
Q Predictions Min            242.54335
V Predictions Mean           1135.021
V Predictions Std            441.7517
V Predictions Max            1719.3229
V Predictions Min            347.75876
Log Pis Mean                 0.22224465
Log Pis Std                  3.5284643
Log Pis Max                  26.965668
Log Pis Min                  -6.109211
Policy mu Mean               -0.004096137
Policy mu Std                0.6605712
Policy mu Max                4.8647118
Policy mu Min                -2.5478058
Policy log std Mean          -0.9774147
Policy log std Std           0.32067636
Policy log std Max           -0.12111068
Policy log std Min           -2.3250813
Z mean eval                  0.9775585
Z variance eval              0.018024711
total_rewards                [4280.82749394 2468.70487266 2905.82036655  954.56406539  312.75287656
  551.97540839 1581.99905682 4055.37532514 3129.64669576 4445.76649446]
total_rewards_mean           2468.7432655669445
total_rewards_std            1474.4100056067543
total_rewards_max            4445.766494462931
total_rewards_min            312.75287655580894
Number of train steps total  1084000
Number of env steps total    1427005
Number of rollouts total     0
Train Time (s)               145.9544948930852
(Previous) Eval Time (s)     15.00322597194463
Sample Time (s)              7.942456430755556
Epoch Time (s)               168.9001772957854
Total Train Time (s)         45496.9026970882
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 20:58:53.944238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #270 | Epoch Duration: 168.9906361103058
2020-01-11 20:58:53.944376 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98269635
Z variance train             0.01790497
KL Divergence                19.063803
KL Loss                      1.9063803
QF Loss                      1063.343
VF Loss                      136.46136
Policy Loss                  -1140.8613
Q Predictions Mean           1133.9075
Q Predictions Std            417.04337
Q Predictions Max            1745.381
Q Predictions Min            348.44266
V Predictions Mean           1135.1334
V Predictions Std            417.1756
V Predictions Max            1745.2552
V Predictions Min            346.85962
Log Pis Mean                 0.2630294
Log Pis Std                  3.2204607
Log Pis Max                  13.331836
Log Pis Min                  -7.2170415
Policy mu Mean               -0.020193536
Policy mu Std                0.65858775
Policy mu Max                3.0385575
Policy mu Min                -2.5636652
Policy log std Mean          -0.9519787
Policy log std Std           0.3081624
Policy log std Max           -0.33268565
Policy log std Min           -2.457098
Z mean eval                  0.94071734
Z variance eval              0.0273203
total_rewards                [4634.41426153 4312.449955   3827.28702782 2028.96263169 4678.58329724
  309.11295683 2645.80266451 4415.57639942 4699.35050597  208.96935514]
total_rewards_mean           3176.050905514492
total_rewards_std            1690.4639750369793
total_rewards_max            4699.3505059671825
total_rewards_min            208.96935514124468
Number of train steps total  1088000
Number of env steps total    1437755
Number of rollouts total     0
Train Time (s)               147.72090937197208
(Previous) Eval Time (s)     18.573327265214175
Sample Time (s)              7.3824713178910315
Epoch Time (s)               173.6767079550773
Total Train Time (s)         45670.667294098996
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:01:47.711527 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #271 | Epoch Duration: 173.76703691482544
2020-01-11 21:01:47.711712 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94318753
Z variance train             0.027548825
KL Divergence                15.664148
KL Loss                      1.5664148
QF Loss                      757.6127
VF Loss                      122.32384
Policy Loss                  -1187.5764
Q Predictions Mean           1182.6006
Q Predictions Std            424.52725
Q Predictions Max            1723.0847
Q Predictions Min            103.25302
V Predictions Mean           1187.1274
V Predictions Std            418.9898
V Predictions Max            1711.5181
V Predictions Min            331.67422
Log Pis Mean                 0.7689548
Log Pis Std                  3.6959164
Log Pis Max                  23.279388
Log Pis Min                  -6.131775
Policy mu Mean               -0.03642066
Policy mu Std                0.68257177
Policy mu Max                4.1228704
Policy mu Min                -4.335272
Policy log std Mean          -0.9964815
Policy log std Std           0.34108716
Policy log std Max           0.0625329
Policy log std Min           -2.3681421
Z mean eval                  1.08131
Z variance eval              0.046757378
total_rewards                [ 707.95131715 4229.39917566 2276.68450045 1535.22920286  505.18201397
 4282.73451311 4238.33807227 4024.47454488 4230.13857299 4210.22209253]
total_rewards_mean           3024.035400586293
total_rewards_std            1511.8962796365158
total_rewards_max            4282.734513110182
total_rewards_min            505.182013968621
Number of train steps total  1092000
Number of env steps total    1448684
Number of rollouts total     0
Train Time (s)               148.6182382311672
(Previous) Eval Time (s)     20.864127542357892
Sample Time (s)              7.220027382019907
Epoch Time (s)               176.702393155545
Total Train Time (s)         45847.45952413604
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:04:44.505105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #272 | Epoch Duration: 176.7932629585266
2020-01-11 21:04:44.505255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #272 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084923
Z variance train             0.046691723
KL Divergence                16.77632
KL Loss                      1.677632
QF Loss                      672.6117
VF Loss                      253.04082
Policy Loss                  -1173.9298
Q Predictions Mean           1166.937
Q Predictions Std            403.20044
Q Predictions Max            1706.3263
Q Predictions Min            366.75262
V Predictions Mean           1162.374
V Predictions Std            403.69348
V Predictions Max            1685.2992
V Predictions Min            364.41934
Log Pis Mean                 0.191989
Log Pis Std                  3.3346345
Log Pis Max                  18.17884
Log Pis Min                  -10.589483
Policy mu Mean               -0.08686644
Policy mu Std                0.67118627
Policy mu Max                3.0725784
Policy mu Min                -2.5293732
Policy log std Mean          -0.96955097
Policy log std Std           0.2954006
Policy log std Max           -0.06163299
Policy log std Min           -2.1959596
Z mean eval                  0.88982487
Z variance eval              0.091698326
total_rewards                [4494.88554482 1893.98195062 4224.69738926  331.25239109  256.8718931
 1352.77489602 4311.62421479 4543.47038522 4243.22646702 3707.31947009]
total_rewards_mean           2936.010460203345
total_rewards_std            1685.9947730331196
total_rewards_max            4543.470385222956
total_rewards_min            256.8718931040406
Number of train steps total  1096000
Number of env steps total    1458618
Number of rollouts total     0
Train Time (s)               145.23074169130996
(Previous) Eval Time (s)     17.54971670312807
Sample Time (s)              7.1905355378985405
Epoch Time (s)               169.97099393233657
Total Train Time (s)         46017.523163932376
Epoch                        273
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:07:34.571998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #273 | Epoch Duration: 170.0666275024414
2020-01-11 21:07:34.572180 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88869333
Z variance train             0.09146588
KL Divergence                15.193004
KL Loss                      1.5193003
QF Loss                      1423.4294
VF Loss                      391.70273
Policy Loss                  -1213.6799
Q Predictions Mean           1207.8809
Q Predictions Std            433.61777
Q Predictions Max            1822.0225
Q Predictions Min            378.4889
V Predictions Mean           1225.8695
V Predictions Std            433.25262
V Predictions Max            1822.9874
V Predictions Min            386.14923
Log Pis Mean                 0.3764603
Log Pis Std                  3.1012714
Log Pis Max                  9.131445
Log Pis Min                  -6.5792847
Policy mu Mean               0.0345107
Policy mu Std                0.6619528
Policy mu Max                2.0564408
Policy mu Min                -2.0549836
Policy log std Mean          -0.9643013
Policy log std Std           0.30717143
Policy log std Max           -0.22974896
Policy log std Min           -2.335571
Z mean eval                  0.93254423
Z variance eval              0.026656892
total_rewards                [4614.24486243 3728.08473229 4330.20970549  611.27416558 2471.81658153
 4401.58459125 4252.38635915 1914.55080617 2773.90688251 1948.00536955]
total_rewards_mean           3104.606405595904
total_rewards_std            1290.342484001343
total_rewards_max            4614.244862432828
total_rewards_min            611.2741655795862
Number of train steps total  1100000
Number of env steps total    1467382
Number of rollouts total     0
Train Time (s)               146.86795000219718
(Previous) Eval Time (s)     15.462015244178474
Sample Time (s)              8.1062379674986
Epoch Time (s)               170.43620321387425
Total Train Time (s)         46188.05287295021
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:10:25.106844 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #274 | Epoch Duration: 170.53452491760254
2020-01-11 21:10:25.107018 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92612964
Z variance train             0.026767096
KL Divergence                16.898443
KL Loss                      1.6898444
QF Loss                      733.6765
VF Loss                      107.75291
Policy Loss                  -1209.0922
Q Predictions Mean           1205.2308
Q Predictions Std            365.14484
Q Predictions Max            1763.3422
Q Predictions Min            360.27374
V Predictions Mean           1206.7548
V Predictions Std            364.00735
V Predictions Max            1765.532
V Predictions Min            357.9936
Log Pis Mean                 0.64186364
Log Pis Std                  3.3831387
Log Pis Max                  11.199612
Log Pis Min                  -9.661334
Policy mu Mean               -0.064541265
Policy mu Std                0.66997004
Policy mu Max                2.5595143
Policy mu Min                -2.8112855
Policy log std Mean          -1.0424216
Policy log std Std           0.3391062
Policy log std Max           -0.31282115
Policy log std Min           -2.5060024
Z mean eval                  1.0963145
Z variance eval              0.031902798
total_rewards                [1440.98074847 1739.79560628  156.29296187  938.73000229 3455.87346471
   53.77309964   79.76536303 2419.95029822 1631.61878524 2509.71104551]
total_rewards_mean           1442.6491375251258
total_rewards_std            1093.887322250876
total_rewards_max            3455.8734647078845
total_rewards_min            53.773099638542746
Number of train steps total  1104000
Number of env steps total    1474771
Number of rollouts total     0
Train Time (s)               145.20890124002472
(Previous) Eval Time (s)     7.967034950852394
Sample Time (s)              7.290004758164287
Epoch Time (s)               160.4659409490414
Total Train Time (s)         46348.61026244424
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:13:05.666329 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #275 | Epoch Duration: 160.55917930603027
2020-01-11 21:13:05.666470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0976098
Z variance train             0.031931624
KL Divergence                16.550276
KL Loss                      1.6550276
QF Loss                      2372.5918
VF Loss                      246.2145
Policy Loss                  -1264.8466
Q Predictions Mean           1256.928
Q Predictions Std            385.97754
Q Predictions Max            1816.0344
Q Predictions Min            373.5944
V Predictions Mean           1268.0581
V Predictions Std            383.91223
V Predictions Max            1813.1102
V Predictions Min            378.7427
Log Pis Mean                 0.9298934
Log Pis Std                  3.1629553
Log Pis Max                  14.373794
Log Pis Min                  -6.052595
Policy mu Mean               -0.046419054
Policy mu Std                0.70043784
Policy mu Max                2.9213667
Policy mu Min                -2.5949
Policy log std Mean          -1.0126033
Policy log std Std           0.3126029
Policy log std Max           -0.25413376
Policy log std Min           -2.7954702
Z mean eval                  1.0101526
Z variance eval              0.038192164
total_rewards                [4052.07018994 4436.76740966 4622.55306333 4416.67542494 4611.89950185
 4747.01897816 4648.49287388 1295.66329053 2202.48061269 2643.14746236]
total_rewards_mean           3767.676880734957
total_rewards_std            1181.2489424410642
total_rewards_max            4747.018978163746
total_rewards_min            1295.6632905285767
Number of train steps total  1108000
Number of env steps total    1482876
Number of rollouts total     0
Train Time (s)               146.63740848563612
(Previous) Eval Time (s)     20.581478687003255
Sample Time (s)              7.818465983495116
Epoch Time (s)               175.0373531561345
Total Train Time (s)         46523.73084392818
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:16:00.788280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #276 | Epoch Duration: 175.12170600891113
2020-01-11 21:16:00.788424 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #276 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9955395
Z variance train             0.03829254
KL Divergence                16.368355
KL Loss                      1.6368355
QF Loss                      451.40665
VF Loss                      144.3924
Policy Loss                  -1219.409
Q Predictions Mean           1214.4849
Q Predictions Std            374.51105
Q Predictions Max            1768.5447
Q Predictions Min            369.47815
V Predictions Mean           1217.7816
V Predictions Std            371.0828
V Predictions Max            1766.9049
V Predictions Min            375.44424
Log Pis Mean                 0.7767528
Log Pis Std                  3.4040108
Log Pis Max                  13.658365
Log Pis Min                  -7.2354465
Policy mu Mean               -0.051056013
Policy mu Std                0.6880907
Policy mu Max                2.3941293
Policy mu Min                -3.1121275
Policy log std Mean          -1.0179574
Policy log std Std           0.3195513
Policy log std Max           -0.37805462
Policy log std Min           -2.6460905
Z mean eval                  0.8806367
Z variance eval              0.10436282
total_rewards                [2740.07980016 4117.18760617 4700.28467879 2273.13986124 4552.1883183
 4707.24994084 4097.33979025 3080.38717092   55.61400502 1148.67040755]
total_rewards_mean           3147.2141579239697
total_rewards_std            1521.5018245390959
total_rewards_max            4707.249940839705
total_rewards_min            55.61400502441656
Number of train steps total  1112000
Number of env steps total    1493651
Number of rollouts total     0
Train Time (s)               146.5680402610451
(Previous) Eval Time (s)     14.763072116766125
Sample Time (s)              7.980215663090348
Epoch Time (s)               169.31132804090157
Total Train Time (s)         46693.13343126234
Epoch                        277
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:18:50.193276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #277 | Epoch Duration: 169.4047474861145
2020-01-11 21:18:50.193416 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8775045
Z variance train             0.10520079
KL Divergence                14.345541
KL Loss                      1.4345541
QF Loss                      1024.2255
VF Loss                      111.063736
Policy Loss                  -1273.5486
Q Predictions Mean           1270.5432
Q Predictions Std            351.6302
Q Predictions Max            1776.0792
Q Predictions Min            410.62552
V Predictions Mean           1270.5286
V Predictions Std            346.96176
V Predictions Max            1766.694
V Predictions Min            411.246
Log Pis Mean                 0.53300184
Log Pis Std                  2.7407146
Log Pis Max                  9.683456
Log Pis Min                  -7.516048
Policy mu Mean               -0.053839944
Policy mu Std                0.6595485
Policy mu Max                2.91558
Policy mu Min                -3.4325163
Policy log std Mean          -1.010909
Policy log std Std           0.29836503
Policy log std Max           -0.08324635
Policy log std Min           -2.386089
Z mean eval                  1.0322889
Z variance eval              0.025119081
total_rewards                [ 860.40413092  479.27799965 2750.12506931  553.65028329  854.20754209
  489.38318053  717.24156839 1359.30538571 2284.6084946    17.61561216]
total_rewards_mean           1036.581926665025
total_rewards_std            815.2151618071492
total_rewards_max            2750.12506931285
total_rewards_min            17.615612155994647
Number of train steps total  1116000
Number of env steps total    1501941
Number of rollouts total     0
Train Time (s)               148.0414316416718
(Previous) Eval Time (s)     12.48893048800528
Sample Time (s)              7.55954808415845
Epoch Time (s)               168.08991021383554
Total Train Time (s)         46861.30616657343
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:21:38.367748 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #278 | Epoch Duration: 168.17422556877136
2020-01-11 21:21:38.367908 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0277702
Z variance train             0.025104245
KL Divergence                16.719086
KL Loss                      1.6719086
QF Loss                      796.9271
VF Loss                      268.3891
Policy Loss                  -1263.8694
Q Predictions Mean           1256.9426
Q Predictions Std            370.15494
Q Predictions Max            1813.9977
Q Predictions Min            418.06476
V Predictions Mean           1273.6865
V Predictions Std            370.00528
V Predictions Max            1833.0492
V Predictions Min            430.1274
Log Pis Mean                 0.6181531
Log Pis Std                  3.3336165
Log Pis Max                  14.364885
Log Pis Min                  -7.262858
Policy mu Mean               -0.07333669
Policy mu Std                0.6859316
Policy mu Max                3.131158
Policy mu Min                -3.14339
Policy log std Mean          -1.0360769
Policy log std Std           0.308776
Policy log std Max           -0.36930937
Policy log std Min           -2.567837
Z mean eval                  0.9770354
Z variance eval              0.043801356
total_rewards                [3724.98508876 4570.07443919 3558.81224641 4051.6282748  4445.45015938
   74.10237137 1761.05367017 2175.56964421 2228.41467513 1199.39164466]
total_rewards_mean           2778.9482214083773
total_rewards_std            1436.0606626981032
total_rewards_max            4570.074439186541
total_rewards_min            74.10237137289275
Number of train steps total  1120000
Number of env steps total    1511531
Number of rollouts total     0
Train Time (s)               145.7694364078343
(Previous) Eval Time (s)     16.665472181979567
Sample Time (s)              7.53368469607085
Epoch Time (s)               169.9685932858847
Total Train Time (s)         47031.36852926621
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:24:28.434983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #279 | Epoch Duration: 170.06695413589478
2020-01-11 21:24:28.435184 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97758454
Z variance train             0.04393481
KL Divergence                16.059486
KL Loss                      1.6059487
QF Loss                      2124.6113
VF Loss                      1088.2827
Policy Loss                  -1231.3158
Q Predictions Mean           1214.0013
Q Predictions Std            382.0637
Q Predictions Max            1761.7324
Q Predictions Min            -31.581083
V Predictions Mean           1225.3721
V Predictions Std            364.488
V Predictions Max            1739.3939
V Predictions Min            422.21475
Log Pis Mean                 0.8598805
Log Pis Std                  3.480936
Log Pis Max                  14.87495
Log Pis Min                  -9.173561
Policy mu Mean               -0.0520688
Policy mu Std                0.7345334
Policy mu Max                2.490214
Policy mu Min                -2.5656745
Policy log std Mean          -0.9887862
Policy log std Std           0.35093817
Policy log std Max           -0.25643367
Policy log std Min           -3.0869303
Z mean eval                  1.1258335
Z variance eval              0.032236997
total_rewards                [3506.65786096 3081.12485807 4183.01061615 4120.37433549 4756.06773947
  556.40756815 3335.41030772 2172.13295274 2633.81833943 4232.24842012]
total_rewards_mean           3257.725299831263
total_rewards_std            1172.9927483555693
total_rewards_max            4756.067739471862
total_rewards_min            556.407568154477
Number of train steps total  1124000
Number of env steps total    1519573
Number of rollouts total     0
Train Time (s)               147.2042684671469
(Previous) Eval Time (s)     16.89814347261563
Sample Time (s)              7.9101687567308545
Epoch Time (s)               172.0125806964934
Total Train Time (s)         47203.47901192028
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:27:20.548985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #280 | Epoch Duration: 172.11364555358887
2020-01-11 21:27:20.549169 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #280 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.128101
Z variance train             0.032471407
KL Divergence                17.315884
KL Loss                      1.7315884
QF Loss                      686.48535
VF Loss                      203.08109
Policy Loss                  -1278.9642
Q Predictions Mean           1270.9198
Q Predictions Std            357.86374
Q Predictions Max            1849.5055
Q Predictions Min            371.3961
V Predictions Mean           1273.2346
V Predictions Std            348.11172
V Predictions Max            1824.4324
V Predictions Min            442.3211
Log Pis Mean                 0.63479185
Log Pis Std                  3.0305896
Log Pis Max                  10.802414
Log Pis Min                  -7.9321384
Policy mu Mean               -0.09647989
Policy mu Std                0.71684974
Policy mu Max                3.0641484
Policy mu Min                -3.0637593
Policy log std Mean          -0.9652214
Policy log std Std           0.3013801
Policy log std Max           -0.2329821
Policy log std Min           -2.403359
Z mean eval                  1.0506774
Z variance eval              0.03785058
total_rewards                [2524.78113917 4679.13505493  749.87307183 1876.79025107 3914.3037107
  204.403454   1075.63683455 1586.95124418 4724.88711166  526.90845597]
total_rewards_mean           2186.367032805987
total_rewards_std            1618.4134766387301
total_rewards_max            4724.88711165661
total_rewards_min            204.40345400308394
Number of train steps total  1128000
Number of env steps total    1526975
Number of rollouts total     0
Train Time (s)               146.52337898314
(Previous) Eval Time (s)     13.055217769928277
Sample Time (s)              7.774307522922754
Epoch Time (s)               167.35290427599102
Total Train Time (s)         47370.92160793254
Epoch                        281
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:30:07.993224 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #281 | Epoch Duration: 167.44392895698547
2020-01-11 21:30:07.993368 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0425439
Z variance train             0.037682775
KL Divergence                15.281745
KL Loss                      1.5281745
QF Loss                      17257.602
VF Loss                      355.27707
Policy Loss                  -1238.4761
Q Predictions Mean           1234.6265
Q Predictions Std            337.23593
Q Predictions Max            1798.9377
Q Predictions Min            316.53015
V Predictions Mean           1252.2509
V Predictions Std            335.34384
V Predictions Max            1805.4666
V Predictions Min            457.0152
Log Pis Mean                 0.765005
Log Pis Std                  3.1587932
Log Pis Max                  18.192286
Log Pis Min                  -6.694874
Policy mu Mean               -0.055852216
Policy mu Std                0.72772837
Policy mu Max                2.7704148
Policy mu Min                -3.1429696
Policy log std Mean          -0.94403243
Policy log std Std           0.2936014
Policy log std Max           -0.30825162
Policy log std Min           -2.519052
Z mean eval                  0.9240494
Z variance eval              0.034794938
total_rewards                [ 807.47462709 4739.65935219  821.13783132 4365.78081237  279.12200855
 4102.22758726 2387.99193231 1695.92097061  880.48034643  520.08262288]
total_rewards_mean           2059.9878090999578
total_rewards_std            1641.5164637363293
total_rewards_max            4739.659352191017
total_rewards_min            279.1220085522588
Number of train steps total  1132000
Number of env steps total    1538078
Number of rollouts total     0
Train Time (s)               147.3251128909178
(Previous) Eval Time (s)     18.65664907824248
Sample Time (s)              7.351099050138146
Epoch Time (s)               173.33286101929843
Total Train Time (s)         47544.34824939119
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:33:01.422325 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #282 | Epoch Duration: 173.42885279655457
2020-01-11 21:33:01.422470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9239976
Z variance train             0.034872655
KL Divergence                17.87719
KL Loss                      1.787719
QF Loss                      600.08453
VF Loss                      132.25883
Policy Loss                  -1295.377
Q Predictions Mean           1290.7642
Q Predictions Std            344.68692
Q Predictions Max            1808.6904
Q Predictions Min            482.81686
V Predictions Mean           1292.6584
V Predictions Std            340.17175
V Predictions Max            1790.1953
V Predictions Min            468.45853
Log Pis Mean                 0.75145346
Log Pis Std                  3.2181656
Log Pis Max                  12.598814
Log Pis Min                  -9.317303
Policy mu Mean               -0.044638958
Policy mu Std                0.7336563
Policy mu Max                2.4999213
Policy mu Min                -3.2882085
Policy log std Mean          -0.9741525
Policy log std Std           0.31850654
Policy log std Max           -0.23205036
Policy log std Min           -2.4349625
Z mean eval                  0.99787724
Z variance eval              0.06389628
total_rewards                [ 583.61785438 1393.05003603 4419.79736946 1084.17283622 4594.49062178
 1859.81940438  356.34615525 1738.71710266 1954.79403808 2188.75322223]
total_rewards_mean           2017.3558640451552
total_rewards_std            1364.7066843015573
total_rewards_max            4594.490621778346
total_rewards_min            356.34615524992313
Number of train steps total  1136000
Number of env steps total    1547617
Number of rollouts total     0
Train Time (s)               146.57607553014532
(Previous) Eval Time (s)     13.179027860052884
Sample Time (s)              8.175880417227745
Epoch Time (s)               167.93098380742595
Total Train Time (s)         47712.37358769821
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:35:49.449401 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #283 | Epoch Duration: 168.0268268585205
2020-01-11 21:35:49.449545 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99865615
Z variance train             0.06394179
KL Divergence                13.949895
KL Loss                      1.3949895
QF Loss                      763.52594
VF Loss                      222.78818
Policy Loss                  -1223.6401
Q Predictions Mean           1218.2527
Q Predictions Std            358.39307
Q Predictions Max            1831.6936
Q Predictions Min            486.12448
V Predictions Mean           1222.1721
V Predictions Std            353.10114
V Predictions Max            1821.3197
V Predictions Min            493.8457
Log Pis Mean                 0.9025279
Log Pis Std                  3.456265
Log Pis Max                  15.860298
Log Pis Min                  -8.472961
Policy mu Mean               -0.0037215792
Policy mu Std                0.7268796
Policy mu Max                3.2918873
Policy mu Min                -2.6750853
Policy log std Mean          -0.97819656
Policy log std Std           0.33007598
Policy log std Max           -0.11472094
Policy log std Min           -2.5059252
Z mean eval                  0.9743775
Z variance eval              0.050813884
total_rewards                [4778.11860142 3629.18412899 3312.0754057  4729.82047745 4882.58901019
 4811.16509742 3916.40946133 4385.14649952 4827.07621863 1482.30981385]
total_rewards_mean           4075.3894714502176
total_rewards_std            1015.2394666316644
total_rewards_max            4882.589010186801
total_rewards_min            1482.3098138469895
Number of train steps total  1140000
Number of env steps total    1557672
Number of rollouts total     0
Train Time (s)               145.76147775910795
(Previous) Eval Time (s)     19.74851156398654
Sample Time (s)              7.451717985793948
Epoch Time (s)               172.96170730888844
Total Train Time (s)         47885.42450973578
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:38:42.505321 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #284 | Epoch Duration: 173.05566358566284
2020-01-11 21:38:42.505490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97810125
Z variance train             0.05065454
KL Divergence                15.548472
KL Loss                      1.5548472
QF Loss                      1086.0105
VF Loss                      272.3382
Policy Loss                  -1328.6017
Q Predictions Mean           1322.6892
Q Predictions Std            330.34335
Q Predictions Max            1831.4264
Q Predictions Min            513.8395
V Predictions Mean           1315.3513
V Predictions Std            329.1992
V Predictions Max            1796.0342
V Predictions Min            499.3964
Log Pis Mean                 0.8935463
Log Pis Std                  2.9306948
Log Pis Max                  12.405571
Log Pis Min                  -6.851465
Policy mu Mean               -0.03375514
Policy mu Std                0.7022397
Policy mu Max                2.6817508
Policy mu Min                -2.915538
Policy log std Mean          -1.0049185
Policy log std Std           0.29927033
Policy log std Max           -0.17607152
Policy log std Min           -2.4006646
Z mean eval                  0.9239848
Z variance eval              0.13948569
total_rewards                [2481.41017411    5.91060148 1517.38757617  709.98276503 1363.63892046
 2399.69687345 1681.93217726  943.93052417 4943.60361354 4515.05076529]
total_rewards_mean           2056.2543990974937
total_rewards_std            1511.4564964451476
total_rewards_max            4943.603613539975
total_rewards_min            5.910601482637778
Number of train steps total  1144000
Number of env steps total    1568424
Number of rollouts total     0
Train Time (s)               145.99299418041483
(Previous) Eval Time (s)     11.076981991995126
Sample Time (s)              7.167903167195618
Epoch Time (s)               164.23787933960557
Total Train Time (s)         48049.75348283304
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:41:26.837799 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #285 | Epoch Duration: 164.33218145370483
2020-01-11 21:41:26.837941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92564696
Z variance train             0.13836086
KL Divergence                13.164676
KL Loss                      1.3164676
QF Loss                      631.4576
VF Loss                      134.8497
Policy Loss                  -1247.1287
Q Predictions Mean           1235.8137
Q Predictions Std            347.6415
Q Predictions Max            1794.9312
Q Predictions Min            521.30817
V Predictions Mean           1243.6833
V Predictions Std            345.0569
V Predictions Max            1790.4412
V Predictions Min            518.55884
Log Pis Mean                 0.33694202
Log Pis Std                  3.0357287
Log Pis Max                  9.172141
Log Pis Min                  -8.508741
Policy mu Mean               -0.0312373
Policy mu Std                0.71139455
Policy mu Max                2.379537
Policy mu Min                -2.467075
Policy log std Mean          -0.93515
Policy log std Std           0.2975628
Policy log std Max           -0.23446858
Policy log std Min           -2.4215536
Z mean eval                  0.93564254
Z variance eval              0.13464984
total_rewards                [2237.93623704 2770.53351996 1425.64906137   59.39521047 3387.24466304
 4516.43288655 4668.41903958 4739.60909174 4468.19135071 4420.72812938]
total_rewards_mean           3269.413918984239
total_rewards_std            1531.8857047796116
total_rewards_max            4739.609091741345
total_rewards_min            59.395210474816096
Number of train steps total  1148000
Number of env steps total    1579011
Number of rollouts total     0
Train Time (s)               145.28708236431703
(Previous) Eval Time (s)     15.052160209044814
Sample Time (s)              8.015410169027746
Epoch Time (s)               168.3546527423896
Total Train Time (s)         48218.196142129134
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:44:15.283941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #286 | Epoch Duration: 168.4458830356598
2020-01-11 21:44:15.284127 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9382143
Z variance train             0.13651244
KL Divergence                13.954954
KL Loss                      1.3954954
QF Loss                      894.09656
VF Loss                      147.591
Policy Loss                  -1320.3932
Q Predictions Mean           1314.1274
Q Predictions Std            321.4939
Q Predictions Max            1815.102
Q Predictions Min            513.4399
V Predictions Mean           1315.1365
V Predictions Std            317.87405
V Predictions Max            1821.9281
V Predictions Min            513.80035
Log Pis Mean                 0.79907906
Log Pis Std                  3.2583475
Log Pis Max                  11.013003
Log Pis Min                  -11.136676
Policy mu Mean               -0.07215124
Policy mu Std                0.7125048
Policy mu Max                2.8725014
Policy mu Min                -2.4367743
Policy log std Mean          -1.01135
Policy log std Std           0.32540432
Policy log std Max           -0.077153385
Policy log std Min           -2.333698
Z mean eval                  1.1089679
Z variance eval              0.045928583
total_rewards                [4777.3453363  4338.49035085 4433.18523723 1596.82713348  307.19609223
 4218.45045639 3275.81581408 2739.34238349 4326.22804223 4679.58935296]
total_rewards_mean           3469.2470199239806
total_rewards_std            1422.36533969236
total_rewards_max            4777.34533629946
total_rewards_min            307.1960922281471
Number of train steps total  1152000
Number of env steps total    1587261
Number of rollouts total     0
Train Time (s)               148.4136372790672
(Previous) Eval Time (s)     21.05340237636119
Sample Time (s)              7.554789314512163
Epoch Time (s)               177.02182896994054
Total Train Time (s)         48395.30428005336
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:47:12.394266 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #287 | Epoch Duration: 177.11000037193298
2020-01-11 21:47:12.394448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1028721
Z variance train             0.046023123
KL Divergence                19.602936
KL Loss                      1.9602937
QF Loss                      3814.1592
VF Loss                      652.4685
Policy Loss                  -1429.9473
Q Predictions Mean           1421.3511
Q Predictions Std            320.4668
Q Predictions Max            1898.7877
Q Predictions Min            548.8375
V Predictions Mean           1432.822
V Predictions Std            322.9548
V Predictions Max            1894.0709
V Predictions Min            547.7222
Log Pis Mean                 1.9042876
Log Pis Std                  4.5400667
Log Pis Max                  21.933918
Log Pis Min                  -8.440806
Policy mu Mean               -0.04590103
Policy mu Std                0.90525687
Policy mu Max                3.5910769
Policy mu Min                -3.5224319
Policy log std Mean          -0.9399719
Policy log std Std           0.31820694
Policy log std Max           -0.11543536
Policy log std Min           -2.5315742
Z mean eval                  1.4474126
Z variance eval              0.031921107
total_rewards                [-1535.32497057 -1486.26086635 -1472.89484457 -1644.07160797
 -1455.789664   -1736.79389399 -1462.26572922 -1399.68365941
 -1636.80796649 -1331.38981872]
total_rewards_mean           -1516.1283021300137
total_rewards_std            117.04087835629323
total_rewards_max            -1331.389818722455
total_rewards_min            -1736.793893992721
Number of train steps total  1156000
Number of env steps total    1598507
Number of rollouts total     0
Train Time (s)               148.85470127128065
(Previous) Eval Time (s)     21.788122777361423
Sample Time (s)              6.348791559226811
Epoch Time (s)               176.99161560786888
Total Train Time (s)         48572.37964604888
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:50:09.471830 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #288 | Epoch Duration: 177.07725954055786
2020-01-11 21:50:09.471967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #288 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4372994
Z variance train             0.0319615
KL Divergence                26.977486
KL Loss                      2.6977487
QF Loss                      7076.667
VF Loss                      1504.2931
Policy Loss                  -1670.3481
Q Predictions Mean           1643.633
Q Predictions Std            411.12036
Q Predictions Max            3102.335
Q Predictions Min            1.3296599
V Predictions Mean           1672.0459
V Predictions Std            416.5203
V Predictions Max            3210.5215
V Predictions Min            101.87795
Log Pis Mean                 5.9629173
Log Pis Std                  5.1506658
Log Pis Max                  22.391712
Log Pis Min                  -8.766833
Policy mu Mean               0.022586903
Policy mu Std                1.2899424
Policy mu Max                3.9411077
Policy mu Min                -4.0068994
Policy log std Mean          -0.91594815
Policy log std Std           0.3672049
Policy log std Max           -0.011440635
Policy log std Min           -2.9280276
Z mean eval                  1.5681753
Z variance eval              0.19111936
total_rewards                [-1114.07205567 -1203.10780063 -1296.59737548 -1213.61903712
 -1241.25191378 -1162.22690752 -1170.47352242 -1260.23857363
 -1136.88410326 -1153.77349228]
total_rewards_mean           -1195.2244781792422
total_rewards_std            55.16455116237726
total_rewards_max            -1114.0720556669935
total_rewards_min            -1296.5973754760403
Number of train steps total  1160000
Number of env steps total    1607749
Number of rollouts total     0
Train Time (s)               146.97784119611606
(Previous) Eval Time (s)     22.071965645998716
Sample Time (s)              6.314002501778305
Epoch Time (s)               175.36380934389308
Total Train Time (s)         48747.82645272277
Epoch                        289
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:53:04.920962 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #289 | Epoch Duration: 175.44888997077942
2020-01-11 21:53:04.921106 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #289 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5834609
Z variance train             0.19279785
KL Divergence                31.493559
KL Loss                      3.149356
QF Loss                      4469.7617
VF Loss                      1995.85
Policy Loss                  -2482.317
Q Predictions Mean           2438.5234
Q Predictions Std            612.47473
Q Predictions Max            4333.6943
Q Predictions Min            -14.199838
V Predictions Mean           2454.568
V Predictions Std            629.6601
V Predictions Max            4401.0737
V Predictions Min            103.126785
Log Pis Mean                 5.925164
Log Pis Std                  4.992517
Log Pis Max                  21.436659
Log Pis Min                  -7.326764
Policy mu Mean               0.14324266
Policy mu Std                1.2805895
Policy mu Max                3.4314854
Policy mu Min                -3.7894733
Policy log std Mean          -0.9362962
Policy log std Std           0.32650626
Policy log std Max           -0.12187278
Policy log std Min           -3.0489762
Z mean eval                  1.4652681
Z variance eval              2.3237207
total_rewards                [ -554.34087125  -852.76423305 -1310.34803872  -710.60856366
  -569.36779579  -844.38293302 -1146.16408356  -768.02980664
 -1258.2248066   -558.95483592]
total_rewards_mean           -857.3185968207159
total_rewards_std            272.5453494044112
total_rewards_max            -554.3408712486508
total_rewards_min            -1310.3480387245418
Number of train steps total  1164000
Number of env steps total    1617393
Number of rollouts total     0
Train Time (s)               148.0759176230058
(Previous) Eval Time (s)     21.363641135860234
Sample Time (s)              7.101829651277512
Epoch Time (s)               176.54138841014355
Total Train Time (s)         48924.45999995433
Epoch                        290
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:56:01.556589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #290 | Epoch Duration: 176.63537979125977
2020-01-11 21:56:01.556718 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4677285
Z variance train             2.3234887
KL Divergence                24.373768
KL Loss                      2.4373767
QF Loss                      10382.73
VF Loss                      2588.1316
Policy Loss                  -2195.4922
Q Predictions Mean           2161.3306
Q Predictions Std            498.8016
Q Predictions Max            3698.3423
Q Predictions Min            937.3373
V Predictions Mean           2198.7678
V Predictions Std            508.5437
V Predictions Max            3714.4712
V Predictions Min            679.08417
Log Pis Mean                 7.112216
Log Pis Std                  4.527546
Log Pis Max                  20.060766
Log Pis Min                  -4.940266
Policy mu Mean               0.26884487
Policy mu Std                1.3809208
Policy mu Max                3.8427994
Policy mu Min                -3.8149383
Policy log std Mean          -0.88918227
Policy log std Std           0.37644082
Policy log std Max           0.20297956
Policy log std Min           -2.7834063
Z mean eval                  1.3705697
Z variance eval              0.3049125
total_rewards                [-1327.00754715  -806.49842061  -712.71007613 -1422.08563938
  -749.97580457  -807.9346726   -659.68399135  -969.39160843
  -588.13545259  -684.00971563]
total_rewards_mean           -872.74329284474
total_rewards_std            269.9557745583445
total_rewards_max            -588.135452594238
total_rewards_min            -1422.085639378371
Number of train steps total  1168000
Number of env steps total    1626965
Number of rollouts total     0
Train Time (s)               147.94645152287558
(Previous) Eval Time (s)     25.215393932070583
Sample Time (s)              6.131930119823664
Epoch Time (s)               179.29377557476982
Total Train Time (s)         49103.844886641484
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 21:59:00.943659 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #291 | Epoch Duration: 179.38683772087097
2020-01-11 21:59:00.943806 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #291 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3748269
Z variance train             0.29954323
KL Divergence                23.335796
KL Loss                      2.3335798
QF Loss                      4174.333
VF Loss                      935.7433
Policy Loss                  -2846.0557
Q Predictions Mean           2815.2642
Q Predictions Std            587.0243
Q Predictions Max            4593.0854
Q Predictions Min            20.266645
V Predictions Mean           2852.3872
V Predictions Std            587.60614
V Predictions Max            4675.4346
V Predictions Min            1674.3516
Log Pis Mean                 5.195445
Log Pis Std                  3.8198056
Log Pis Max                  18.971266
Log Pis Min                  -3.8585544
Policy mu Mean               0.011324417
Policy mu Std                1.2283967
Policy mu Max                6.0798545
Policy mu Min                -4.741788
Policy log std Mean          -0.8905854
Policy log std Std           0.2913815
Policy log std Max           1.0767236
Policy log std Min           -2.1977715
Z mean eval                  1.4691288
Z variance eval              0.37213054
total_rewards                [ -823.34271024 -1059.1860443   -916.47675961 -1461.96184341
 -1013.30127141   -40.78857995  -829.56975513 -1018.98948927
  -969.43173857  -599.82254026]
total_rewards_mean           -873.2870732141491
total_rewards_std            347.17156613346214
total_rewards_max            -40.788579947661766
total_rewards_min            -1461.9618434125823
Number of train steps total  1172000
Number of env steps total    1636630
Number of rollouts total     0
Train Time (s)               145.98842718731612
(Previous) Eval Time (s)     19.63837729487568
Sample Time (s)              7.321823233738542
Epoch Time (s)               172.94862771593034
Total Train Time (s)         49276.876635574736
Epoch                        292
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:01:53.980163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #292 | Epoch Duration: 173.0362536907196
2020-01-11 22:01:53.980301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4705343
Z variance train             0.3656986
KL Divergence                23.376616
KL Loss                      2.3376615
QF Loss                      9437.897
VF Loss                      2175.3228
Policy Loss                  -2622.178
Q Predictions Mean           2593.9104
Q Predictions Std            782.5557
Q Predictions Max            5189.893
Q Predictions Min            -128.80507
V Predictions Mean           2618.041
V Predictions Std            794.3922
V Predictions Max            5295.633
V Predictions Min            70.342255
Log Pis Mean                 5.0731406
Log Pis Std                  4.638546
Log Pis Max                  26.957993
Log Pis Min                  -5.9676156
Policy mu Mean               0.035334162
Policy mu Std                1.2165282
Policy mu Max                5.3413854
Policy mu Min                -3.3482006
Policy log std Mean          -0.892297
Policy log std Std           0.343081
Policy log std Max           -0.09678888
Policy log std Min           -2.8179595
Z mean eval                  1.47295
Z variance eval              0.27322912
total_rewards                [-1436.24924097 -1453.64083133 -1440.5112689  -1397.62293987
 -1460.75330575 -1355.36934137 -1488.00070875 -1443.39722799
   -22.37850512 -1448.80983729]
total_rewards_mean           -1294.6733207346763
total_rewards_std            425.4920390886097
total_rewards_max            -22.378505124111364
total_rewards_min            -1488.0007087547306
Number of train steps total  1176000
Number of env steps total    1645923
Number of rollouts total     0
Train Time (s)               145.66189459897578
(Previous) Eval Time (s)     22.53112614573911
Sample Time (s)              6.128050295636058
Epoch Time (s)               174.32107104035094
Total Train Time (s)         49451.28438588558
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:04:48.391273 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #293 | Epoch Duration: 174.41085600852966
2020-01-11 22:04:48.391461 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4703493
Z variance train             0.2727143
KL Divergence                25.102695
KL Loss                      2.5102696
QF Loss                      5195.939
VF Loss                      1415.503
Policy Loss                  -3233.016
Q Predictions Mean           3196.2092
Q Predictions Std            1024.8037
Q Predictions Max            6309.906
Q Predictions Min            2530.2734
V Predictions Mean           3247.9824
V Predictions Std            1046.4147
V Predictions Max            6439.1064
V Predictions Min            2561.8552
Log Pis Mean                 6.4528656
Log Pis Std                  5.4689016
Log Pis Max                  34.624687
Log Pis Min                  -7.188274
Policy mu Mean               0.066150635
Policy mu Std                1.413343
Policy mu Max                5.852337
Policy mu Min                -3.9203355
Policy log std Mean          -0.78034186
Policy log std Std           0.34466195
Policy log std Max           0.020953298
Policy log std Min           -2.264494
Z mean eval                  1.8376122
Z variance eval              0.054943837
total_rewards                [-1447.10654761 -1513.21882939 -1844.8600162  -1975.43322047
  -364.35929333 -1589.87687862 -1670.05028264 -1707.49752189
 -1505.83812507  -759.61146766]
total_rewards_mean           -1437.7852182883485
total_rewards_std            471.9290299103957
total_rewards_max            -364.35929332657093
total_rewards_min            -1975.4332204714121
Number of train steps total  1180000
Number of env steps total    1656370
Number of rollouts total     0
Train Time (s)               145.87996910512447
(Previous) Eval Time (s)     18.438940646126866
Sample Time (s)              6.831290741451085
Epoch Time (s)               171.15020049270242
Total Train Time (s)         49622.63439352531
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:07:39.744979 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #294 | Epoch Duration: 171.35337352752686
2020-01-11 22:07:39.745181 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #294 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8282124
Z variance train             0.05516833
KL Divergence                39.272186
KL Loss                      3.9272187
QF Loss                      167251.25
VF Loss                      1483.7528
Policy Loss                  -4319.4062
Q Predictions Mean           4231.576
Q Predictions Std            1031.5785
Q Predictions Max            7760.5127
Q Predictions Min            3430.5703
V Predictions Mean           4332.001
V Predictions Std            1030.9373
V Predictions Max            7954.756
V Predictions Min            3387.2974
Log Pis Mean                 11.602487
Log Pis Std                  4.8549056
Log Pis Max                  27.968838
Log Pis Min                  0.2793876
Policy mu Mean               0.50747395
Policy mu Std                1.6807781
Policy mu Max                3.743859
Policy mu Min                -3.8106494
Policy log std Mean          -0.88314855
Policy log std Std           0.32355475
Policy log std Max           0.027792692
Policy log std Min           -2.131713
Z mean eval                  1.8060287
Z variance eval              0.13243847
total_rewards                [-1274.57803842 -1203.61280747 -1095.13242763 -1134.3638991
 -1141.36985004 -1198.13525335 -1181.82260157 -1241.35533919
 -1281.50444986 -1103.28888944]
total_rewards_mean           -1185.5163556064058
total_rewards_std            63.45088654237649
total_rewards_max            -1095.1324276252476
total_rewards_min            -1281.5044498557386
Number of train steps total  1184000
Number of env steps total    1666063
Number of rollouts total     0
Train Time (s)               147.312837630976
(Previous) Eval Time (s)     25.361640891060233
Sample Time (s)              7.7323966678231955
Epoch Time (s)               180.40687518985942
Total Train Time (s)         49803.12929731794
Epoch                        295
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:10:40.241797 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #295 | Epoch Duration: 180.49647450447083
2020-01-11 22:10:40.241942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #295 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8001859
Z variance train             0.13126925
KL Divergence                34.246376
KL Loss                      3.4246376
QF Loss                      8644.882
VF Loss                      1734.8226
Policy Loss                  -4481.6934
Q Predictions Mean           4435.1377
Q Predictions Std            1341.3667
Q Predictions Max            9531.867
Q Predictions Min            3661.3286
V Predictions Mean           4500.2524
V Predictions Std            1402.4724
V Predictions Max            9780.72
V Predictions Min            3657.2637
Log Pis Mean                 5.9290304
Log Pis Std                  5.22035
Log Pis Max                  31.689037
Log Pis Min                  -4.9085593
Policy mu Mean               -0.22972777
Policy mu Std                1.2784195
Policy mu Max                4.3050356
Policy mu Min                -4.469911
Policy log std Mean          -0.9230219
Policy log std Std           0.32303342
Policy log std Max           -0.07920349
Policy log std Min           -2.426426
Z mean eval                  1.7707589
Z variance eval              0.08733277
total_rewards                [-1380.72690672 -1317.3619163  -1287.36380452 -1252.42020347
 -1325.61393874 -1347.72555838 -1331.04720801 -1393.00685398
 -1754.25718204 -1320.76575217]
total_rewards_mean           -1371.0289324330104
total_rewards_std            133.46141702585408
total_rewards_max            -1252.420203468123
total_rewards_min            -1754.257182039447
Number of train steps total  1188000
Number of env steps total    1674530
Number of rollouts total     0
Train Time (s)               146.10446573700756
(Previous) Eval Time (s)     21.97185482410714
Sample Time (s)              7.267474823165685
Epoch Time (s)               175.34379538428038
Total Train Time (s)         49978.56348946644
Epoch                        296
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:13:35.679061 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #296 | Epoch Duration: 175.43700432777405
2020-01-11 22:13:35.679247 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #296 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7749516
Z variance train             0.0873004
KL Divergence                36.8548
KL Loss                      3.68548
QF Loss                      168759.22
VF Loss                      6124.65
Policy Loss                  -4746.076
Q Predictions Mean           4662.05
Q Predictions Std            1949.8497
Q Predictions Max            11863.786
Q Predictions Min            3037.4834
V Predictions Mean           4741.006
V Predictions Std            1993.0494
V Predictions Max            11960.178
V Predictions Min            3657.4487
Log Pis Mean                 9.325398
Log Pis Std                  5.1120625
Log Pis Max                  49.542503
Log Pis Min                  -1.6411572
Policy mu Mean               -0.1866849
Policy mu Std                1.5788121
Policy mu Max                5.454931
Policy mu Min                -5.189317
Policy log std Mean          -0.87040216
Policy log std Std           0.39715374
Policy log std Max           1.8131903
Policy log std Min           -2.7001216
Z mean eval                  1.8015779
Z variance eval              0.0886098
total_rewards                [ -189.21374721  -772.08886719   -22.45176973 -2140.39729455
 -2208.1040177    -37.03182622  -202.13368598 -1894.4536349
 -1773.4998047  -1679.40547032]
total_rewards_mean           -1091.8780118508366
total_rewards_std            881.1562515110511
total_rewards_max            -22.451769730061404
total_rewards_min            -2208.104017702929
Number of train steps total  1192000
Number of env steps total    1684012
Number of rollouts total     0
Train Time (s)               145.77445944398642
(Previous) Eval Time (s)     12.348823888227344
Sample Time (s)              7.226844496559352
Epoch Time (s)               165.3501278287731
Total Train Time (s)         50144.00635154825
Epoch                        297
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:16:21.130360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #297 | Epoch Duration: 165.4509415626526
2020-01-11 22:16:21.130714 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #297 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8037369
Z variance train             0.08763436
KL Divergence                40.79087
KL Loss                      4.0790873
QF Loss                      20117.371
VF Loss                      4162.272
Policy Loss                  -5882.899
Q Predictions Mean           5770.125
Q Predictions Std            2694.8342
Q Predictions Max            13504.87
Q Predictions Min            1273.9305
V Predictions Mean           5893.6016
V Predictions Std            2727.1265
V Predictions Max            13715.232
V Predictions Min            4211.744
Log Pis Mean                 11.416975
Log Pis Std                  6.754746
Log Pis Max                  88.24317
Log Pis Min                  -0.35089672
Policy mu Mean               -0.6088247
Policy mu Std                1.7268494
Policy mu Max                6.5340614
Policy mu Min                -11.998314
Policy log std Mean          -0.8075667
Policy log std Std           0.4406755
Policy log std Max           0.17160296
Policy log std Min           -2.488113
Z mean eval                  1.9159473
Z variance eval              0.13862526
total_rewards                [  -65.50630567 -1842.67101958  -956.11833126 -1562.0743823
  -847.79531416 -1837.26012676  -592.13000389 -1866.94246438
   -44.4948878  -1593.31348702]
total_rewards_mean           -1120.8306322831563
total_rewards_std            682.8143654715116
total_rewards_max            -44.49488780092185
total_rewards_min            -1866.9424643802317
Number of train steps total  1196000
Number of env steps total    1692216
Number of rollouts total     0
Train Time (s)               149.3781035770662
(Previous) Eval Time (s)     20.630559459794313
Sample Time (s)              7.074871667660773
Epoch Time (s)               177.0835347045213
Total Train Time (s)         50321.17785491748
Epoch                        298
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:19:18.302549 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #298 | Epoch Duration: 177.17161417007446
2020-01-11 22:19:18.302702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #298 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9179633
Z variance train             0.13783698
KL Divergence                46.3808
KL Loss                      4.63808
QF Loss                      26691.566
VF Loss                      4810.63
Policy Loss                  -6493.1987
Q Predictions Mean           6400.619
Q Predictions Std            1970.345
Q Predictions Max            13842.249
Q Predictions Min            1528.6555
V Predictions Mean           6499.765
V Predictions Std            1963.3602
V Predictions Max            13962.963
V Predictions Min            2768.969
Log Pis Mean                 12.191017
Log Pis Std                  5.195045
Log Pis Max                  26.703358
Log Pis Min                  0.7238295
Policy mu Mean               -0.5111244
Policy mu Std                1.7114322
Policy mu Max                4.6054664
Policy mu Min                -5.0510273
Policy log std Mean          -0.92567
Policy log std Std           0.42340797
Policy log std Max           0.08606827
Policy log std Min           -3.956058
Z mean eval                  1.9446176
Z variance eval              0.16745134
total_rewards                [  -13.43115979 -2142.80205873 -1801.24150022   -73.36153442
   -64.73554138  -159.91682721  -126.46676038   -39.7563706
 -1984.9594697    -38.86573603]
total_rewards_mean           -644.5536958469671
total_rewards_std            876.1308339342444
total_rewards_max            -13.431159793559917
total_rewards_min            -2142.802058726201
Number of train steps total  1200000
Number of env steps total    1702263
Number of rollouts total     0
Train Time (s)               147.71863425988704
(Previous) Eval Time (s)     8.61633661808446
Sample Time (s)              6.683053941465914
Epoch Time (s)               163.01802481943741
Total Train Time (s)         50484.28215849493
Epoch                        299
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:22:01.409306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #299 | Epoch Duration: 163.10649728775024
2020-01-11 22:22:01.409452 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9468362
Z variance train             0.1660969
KL Divergence                41.891994
KL Loss                      4.1891994
QF Loss                      14592.258
VF Loss                      4586.804
Policy Loss                  -6718.3975
Q Predictions Mean           6652.2188
Q Predictions Std            1942.9297
Q Predictions Max            12780.8545
Q Predictions Min            5385.829
V Predictions Mean           6756.868
V Predictions Std            1962.099
V Predictions Max            13191.1045
V Predictions Min            5446.4985
Log Pis Mean                 10.032294
Log Pis Std                  4.3471007
Log Pis Max                  23.762165
Log Pis Min                  -3.9015303
Policy mu Mean               -0.32103515
Policy mu Std                1.5607295
Policy mu Max                4.5680466
Policy mu Min                -4.068689
Policy log std Mean          -0.9915967
Policy log std Std           0.40246376
Policy log std Max           0.028214216
Policy log std Min           -2.372683
Z mean eval                  1.9456857
Z variance eval              0.07168164
total_rewards                [  -45.07979303 -1177.71403269  -831.32361437   -66.49622817
 -1298.07292923  -951.54270778  -908.28830495    -4.03423705
 -1076.19801356  -200.96933918]
total_rewards_mean           -655.9719200009386
total_rewards_std            489.4479795025284
total_rewards_max            -4.034237048974907
total_rewards_min            -1298.072929229784
Number of train steps total  1204000
Number of env steps total    1713354
Number of rollouts total     0
Train Time (s)               146.8543333192356
(Previous) Eval Time (s)     13.765488039236516
Sample Time (s)              8.16590332891792
Epoch Time (s)               168.78572468739003
Total Train Time (s)         50653.16112051206
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:24:50.292276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #300 | Epoch Duration: 168.88270783424377
2020-01-11 22:24:50.292462 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9270773
Z variance train             0.071876705
KL Divergence                43.214664
KL Loss                      4.3214664
QF Loss                      17220.824
VF Loss                      2594.4902
Policy Loss                  -6498.175
Q Predictions Mean           6443.7124
Q Predictions Std            1900.8823
Q Predictions Max            11978.812
Q Predictions Min            5185.9116
V Predictions Mean           6515.8164
V Predictions Std            1927.474
V Predictions Max            12126.815
V Predictions Min            5219.3945
Log Pis Mean                 8.349392
Log Pis Std                  4.3194003
Log Pis Max                  20.54311
Log Pis Min                  -3.0115483
Policy mu Mean               -0.19331649
Policy mu Std                1.3999476
Policy mu Max                3.5065217
Policy mu Min                -3.5453544
Policy log std Mean          -1.1108749
Policy log std Std           0.4046388
Policy log std Max           -0.17945588
Policy log std Min           -2.815064
Z mean eval                  1.7388579
Z variance eval              0.13935098
total_rewards                [  -30.1908181  -1731.52410461   -38.74699892 -1244.26096549
 -1876.66684129   -38.41970861  -855.765004     -10.04442324
 -1695.61332343   -16.70163532]
total_rewards_mean           -753.7933822986558
total_rewards_std            774.4612246875176
total_rewards_max            -10.044423235338348
total_rewards_min            -1876.6668412866957
Number of train steps total  1208000
Number of env steps total    1722181
Number of rollouts total     0
Train Time (s)               149.2702007777989
(Previous) Eval Time (s)     11.367855042684823
Sample Time (s)              7.267506462987512
Epoch Time (s)               167.90556228347123
Total Train Time (s)         50821.61365345586
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:27:38.749252 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #301 | Epoch Duration: 168.45663046836853
2020-01-11 22:27:38.749504 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #301 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7375953
Z variance train             0.13938165
KL Divergence                39.14741
KL Loss                      3.9147413
QF Loss                      31489.99
VF Loss                      4569.7295
Policy Loss                  -6093.928
Q Predictions Mean           6036.678
Q Predictions Std            1765.3285
Q Predictions Max            12482.012
Q Predictions Min            -1130.5518
V Predictions Mean           6129.755
V Predictions Std            1799.11
V Predictions Max            12618.258
V Predictions Min            -1215.7433
Log Pis Mean                 8.491453
Log Pis Std                  4.8583837
Log Pis Max                  47.764954
Log Pis Min                  -4.4505954
Policy mu Mean               -0.34185082
Policy mu Std                1.3808324
Policy mu Max                8.173066
Policy mu Min                -3.7729495
Policy log std Mean          -1.0902814
Policy log std Std           0.4084714
Policy log std Max           2.0
Policy log std Min           -2.842235
Z mean eval                  1.7829126
Z variance eval              0.029655516
total_rewards                [-1291.52459199   -51.54222605 -1138.62114104 -1159.07688174
   -20.03665623 -1333.20981387   -64.57609527  -721.26844925
  -647.00524714  -173.35688179]
total_rewards_mean           -660.02179843731
total_rewards_std            520.1190701089032
total_rewards_max            -20.0366562306336
total_rewards_min            -1333.2098138727295
Number of train steps total  1212000
Number of env steps total    1731906
Number of rollouts total     0
Train Time (s)               146.6409672871232
(Previous) Eval Time (s)     13.785419372841716
Sample Time (s)              7.358621511142701
Epoch Time (s)               167.78500817110762
Total Train Time (s)         50989.496354174335
Epoch                        302
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:30:26.636955 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #302 | Epoch Duration: 167.88724994659424
2020-01-11 22:30:26.637212 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.783777
Z variance train             0.029662732
KL Divergence                42.512203
KL Loss                      4.25122
QF Loss                      55979.316
VF Loss                      3703.2166
Policy Loss                  -6447.5713
Q Predictions Mean           6335.3115
Q Predictions Std            1788.531
Q Predictions Max            12326.102
Q Predictions Min            1845.621
V Predictions Mean           6457.575
V Predictions Std            1802.3582
V Predictions Max            12475.985
V Predictions Min            4883.4697
Log Pis Mean                 10.11697
Log Pis Std                  4.7860847
Log Pis Max                  23.890268
Log Pis Min                  -0.7724893
Policy mu Mean               -0.48587537
Policy mu Std                1.54565
Policy mu Max                3.807965
Policy mu Min                -5.341216
Policy log std Mean          -1.0263463
Policy log std Std           0.45147306
Policy log std Max           0.24949217
Policy log std Min           -3.0806403
Z mean eval                  1.8449663
Z variance eval              0.032244395
total_rewards                [-665.0891743  -471.00043375 -595.31278049   -3.49188095  -12.05868624
 -548.95640548 -669.26468962  -47.0096525  -810.91811244 -830.17967854]
total_rewards_mean           -465.3281494322151
total_rewards_std            308.4966474139683
total_rewards_max            -3.4918809515594855
total_rewards_min            -830.1796785409971
Number of train steps total  1216000
Number of env steps total    1741943
Number of rollouts total     0
Train Time (s)               146.30859878705814
(Previous) Eval Time (s)     17.434488971717656
Sample Time (s)              7.4936567642726
Epoch Time (s)               171.2367445230484
Total Train Time (s)         51160.82391157979
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:33:17.966513 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #303 | Epoch Duration: 171.32912397384644
2020-01-11 22:33:17.966696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #303 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8529679
Z variance train             0.032461975
KL Divergence                45.385567
KL Loss                      4.5385566
QF Loss                      61953.473
VF Loss                      6593.84
Policy Loss                  -6613.0127
Q Predictions Mean           6547.315
Q Predictions Std            1398.9225
Q Predictions Max            11257.584
Q Predictions Min            2865.6548
V Predictions Mean           6586.8765
V Predictions Std            1371.5537
V Predictions Max            11310.298
V Predictions Min            4059.5845
Log Pis Mean                 9.200558
Log Pis Std                  4.5772524
Log Pis Max                  21.987827
Log Pis Min                  -1.5004852
Policy mu Mean               -0.02171776
Policy mu Std                1.4444871
Policy mu Max                3.8819659
Policy mu Min                -4.379889
Policy log std Mean          -1.170323
Policy log std Std           0.45912287
Policy log std Max           -0.13386619
Policy log std Min           -3.3125162
Z mean eval                  1.7934376
Z variance eval              0.0019835366
total_rewards                [ -817.67416136  -629.93192757    -4.72424128  -339.71751911
  -690.16191369  -629.20493263  -824.47199251  -732.45511908
  -749.19487171 -1790.86569394]
total_rewards_mean           -720.840237287786
total_rewards_std            429.1490269840196
total_rewards_max            -4.724241279160923
total_rewards_min            -1790.8656939366876
Number of train steps total  1220000
Number of env steps total    1751698
Number of rollouts total     0
Train Time (s)               147.9800033532083
(Previous) Eval Time (s)     22.174818924162537
Sample Time (s)              7.939627035986632
Epoch Time (s)               178.09444931335747
Total Train Time (s)         51339.01005285885
Epoch                        304
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:36:16.154171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #304 | Epoch Duration: 178.1873619556427
2020-01-11 22:36:16.154317 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #304 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7917324
Z variance train             0.0019838489
KL Divergence                50.120224
KL Loss                      5.0120225
QF Loss                      17355.691
VF Loss                      2969.8542
Policy Loss                  -6482.211
Q Predictions Mean           6431.715
Q Predictions Std            1074.3088
Q Predictions Max            10047.117
Q Predictions Min            4503.3193
V Predictions Mean           6476.1943
V Predictions Std            1074.4916
V Predictions Max            10084.5
V Predictions Min            4552.9463
Log Pis Mean                 8.427306
Log Pis Std                  3.9229057
Log Pis Max                  22.005919
Log Pis Min                  -1.6019808
Policy mu Mean               0.033011787
Policy mu Std                1.2821436
Policy mu Max                3.949666
Policy mu Min                -3.5991104
Policy log std Mean          -1.3010708
Policy log std Std           0.44552675
Policy log std Max           -0.13558614
Policy log std Min           -3.6457782
Z mean eval                  1.8043363
Z variance eval              0.0024508976
total_rewards                [   47.48535661    27.92430233   -17.95925516   -96.23545432
 -1146.0878455   -801.65306241  -510.30474312    96.67155897
  -143.94106112    70.02970442]
total_rewards_mean           -247.40704993130976
total_rewards_std            406.4554626930612
total_rewards_max            96.67155896561124
total_rewards_min            -1146.0878454997526
Number of train steps total  1224000
Number of env steps total    1760772
Number of rollouts total     0
Train Time (s)               147.50814508507028
(Previous) Eval Time (s)     13.477028962690383
Sample Time (s)              7.451967275701463
Epoch Time (s)               168.43714132346213
Total Train Time (s)         51507.54740552837
Epoch                        305
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:39:04.694635 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #305 | Epoch Duration: 168.54020190238953
2020-01-11 22:39:04.694786 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8049663
Z variance train             0.0024292655
KL Divergence                48.812943
KL Loss                      4.8812943
QF Loss                      267088.3
VF Loss                      4582.8037
Policy Loss                  -5959.773
Q Predictions Mean           5924.0537
Q Predictions Std            925.5464
Q Predictions Max            8513.357
Q Predictions Min            3167.7634
V Predictions Mean           5991.465
V Predictions Std            919.04083
V Predictions Max            8585.467
V Predictions Min            3972.6948
Log Pis Mean                 7.269739
Log Pis Std                  4.1852274
Log Pis Max                  25.603554
Log Pis Min                  -5.847557
Policy mu Mean               0.17593843
Policy mu Std                1.224836
Policy mu Max                3.9922793
Policy mu Min                -3.4149024
Policy log std Mean          -1.24285
Policy log std Std           0.41316816
Policy log std Max           0.120312095
Policy log std Min           -2.8200765
Z mean eval                  1.7309244
Z variance eval              0.0005906224
total_rewards                [-421.59621099  198.82584801 -375.11223083   34.72474704  -89.0396673
 -463.5148933  -270.60444046  376.81666774 -173.64012237   59.41651758]
total_rewards_mean           -112.37237848766866
total_rewards_std            265.4406637765849
total_rewards_max            376.8166677350313
total_rewards_min            -463.51489329774716
Number of train steps total  1228000
Number of env steps total    1769514
Number of rollouts total     0
Train Time (s)               147.3799429940991
(Previous) Eval Time (s)     15.396379912737757
Sample Time (s)              7.519636561628431
Epoch Time (s)               170.2959594684653
Total Train Time (s)         51677.94855779363
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:41:55.099238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #306 | Epoch Duration: 170.40433835983276
2020-01-11 22:41:55.099417 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7325588
Z variance train             0.0005846906
KL Divergence                48.271088
KL Loss                      4.827109
QF Loss                      8252.471
VF Loss                      2050.8843
Policy Loss                  -5468.796
Q Predictions Mean           5442.4644
Q Predictions Std            786.91473
Q Predictions Max            7554.452
Q Predictions Min            3585.6848
V Predictions Mean           5454.9043
V Predictions Std            788.8425
V Predictions Max            7618.283
V Predictions Min            3592.783
Log Pis Mean                 5.5911026
Log Pis Std                  3.3691998
Log Pis Max                  14.611496
Log Pis Min                  -7.3833256
Policy mu Mean               0.08987868
Policy mu Std                1.0432847
Policy mu Max                4.151522
Policy mu Min                -3.5225449
Policy log std Mean          -1.2873824
Policy log std Std           0.37667415
Policy log std Max           0.1700263
Policy log std Min           -3.3156538
Z mean eval                  1.9525398
Z variance eval              0.043398883
total_rewards                [ -178.87344331    -6.0387004   -332.08107271  -160.41489669
  -136.75893249  -298.83687204  -499.925542   -1039.82933771
    69.37024934   244.07634423]
total_rewards_mean           -233.9312203786173
total_rewards_std            335.31587615292153
total_rewards_max            244.07634423044436
total_rewards_min            -1039.8293377129
Number of train steps total  1232000
Number of env steps total    1780043
Number of rollouts total     0
Train Time (s)               147.0838155504316
(Previous) Eval Time (s)     21.271355958189815
Sample Time (s)              7.391451851464808
Epoch Time (s)               175.74662336008623
Total Train Time (s)         51853.77743425919
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:44:50.930678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #307 | Epoch Duration: 175.83108830451965
2020-01-11 22:44:50.930825 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9514427
Z variance train             0.043244127
KL Divergence                39.615887
KL Loss                      3.9615886
QF Loss                      164762.38
VF Loss                      1408.8174
Policy Loss                  -4661.502
Q Predictions Mean           4635.5146
Q Predictions Std            592.53033
Q Predictions Max            6213.236
Q Predictions Min            2962.2717
V Predictions Mean           4640.4653
V Predictions Std            592.9201
V Predictions Max            6171.443
V Predictions Min            2990.31
Log Pis Mean                 5.413865
Log Pis Std                  3.3411517
Log Pis Max                  18.738571
Log Pis Min                  -1.5117756
Policy mu Mean               0.0191763
Policy mu Std                1.0844342
Policy mu Max                3.321663
Policy mu Min                -3.083198
Policy log std Mean          -1.1544338
Policy log std Std           0.34792674
Policy log std Max           -0.08712149
Policy log std Min           -2.441941
Z mean eval                  1.5780848
Z variance eval              0.16829112
total_rewards                [ 189.85200312 -156.75123444 -285.11979092 -100.34057222  165.59431516
 -400.29543925   28.13370775  -80.86524867 -138.66129918   31.48538497]
total_rewards_mean           -74.69681736638117
total_rewards_std            176.46161286732664
total_rewards_max            189.85200312454393
total_rewards_min            -400.2954392453049
Number of train steps total  1236000
Number of env steps total    1790894
Number of rollouts total     0
Train Time (s)               146.0516262408346
(Previous) Eval Time (s)     15.623306553810835
Sample Time (s)              7.408313598483801
Epoch Time (s)               169.08324639312923
Total Train Time (s)         52022.957472418435
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:47:40.113482 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #308 | Epoch Duration: 169.18253779411316
2020-01-11 22:47:40.113660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5881584
Z variance train             0.16649857
KL Divergence                30.01832
KL Loss                      3.001832
QF Loss                      7518.1475
VF Loss                      1573.7915
Policy Loss                  -4165.2085
Q Predictions Mean           4146.155
Q Predictions Std            488.23602
Q Predictions Max            5403.65
Q Predictions Min            2605.1365
V Predictions Mean           4173.355
V Predictions Std            499.96545
V Predictions Max            5486.8906
V Predictions Min            2623.727
Log Pis Mean                 4.2530055
Log Pis Std                  3.3455126
Log Pis Max                  21.350538
Log Pis Min                  -4.3252873
Policy mu Mean               -0.02428137
Policy mu Std                0.99071884
Policy mu Max                3.4839709
Policy mu Min                -3.1511445
Policy log std Mean          -1.1760696
Policy log std Std           0.33719885
Policy log std Max           -0.22517896
Policy log std Min           -3.1612854
Z mean eval                  1.2648399
Z variance eval              0.04958586
total_rewards                [-110.69389643 -619.69779696 -454.40629169  144.47295123  -39.88304853
 -535.7204165  -337.77576487 -269.8833931  -347.69286493 -347.47543602]
total_rewards_mean           -291.87559577881956
total_rewards_std            221.10369017567447
total_rewards_max            144.47295123471196
total_rewards_min            -619.6977969582176
Number of train steps total  1240000
Number of env steps total    1801091
Number of rollouts total     0
Train Time (s)               145.71941566793248
(Previous) Eval Time (s)     19.836949784774333
Sample Time (s)              7.7338505373336375
Epoch Time (s)               173.29021599004045
Total Train Time (s)         52196.340033627115
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:50:33.501640 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #309 | Epoch Duration: 173.38781309127808
2020-01-11 22:50:33.501946 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2672219
Z variance train             0.049493887
KL Divergence                29.351826
KL Loss                      2.9351826
QF Loss                      2902.1445
VF Loss                      1195.4296
Policy Loss                  -3621.0396
Q Predictions Mean           3610.9163
Q Predictions Std            399.43402
Q Predictions Max            4518.9014
Q Predictions Min            2186.2568
V Predictions Mean           3640.783
V Predictions Std            395.2529
V Predictions Max            4524.8936
V Predictions Min            2241.2808
Log Pis Mean                 3.8637714
Log Pis Std                  3.8490953
Log Pis Max                  22.96457
Log Pis Min                  -5.5393095
Policy mu Mean               0.07831739
Policy mu Std                0.98513615
Policy mu Max                3.4913783
Policy mu Min                -3.2436435
Policy log std Mean          -1.0901656
Policy log std Std           0.31488612
Policy log std Max           -0.26166856
Policy log std Min           -3.2017136
Z mean eval                  1.3074256
Z variance eval              0.047720205
total_rewards                [ 433.94747755 -461.76908216 -618.75932459   12.44241198 -546.23305124
  105.41997317   74.75420208  706.00184169 -394.75144713 -475.88245146]
total_rewards_mean           -116.48294501224109
total_rewards_std            429.49735388460783
total_rewards_max            706.0018416920032
total_rewards_min            -618.7593245868597
Number of train steps total  1244000
Number of env steps total    1811330
Number of rollouts total     0
Train Time (s)               146.55285779992118
(Previous) Eval Time (s)     18.055747935082763
Sample Time (s)              7.367747941054404
Epoch Time (s)               171.97635367605835
Total Train Time (s)         52368.409453118686
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:53:25.572223 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #310 | Epoch Duration: 172.07008481025696
2020-01-11 22:53:25.572367 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3095644
Z variance train             0.04772564
KL Divergence                27.473534
KL Loss                      2.7473533
QF Loss                      8015.201
VF Loss                      1070.3129
Policy Loss                  -3162.9128
Q Predictions Mean           3152.152
Q Predictions Std            382.21915
Q Predictions Max            3860.3557
Q Predictions Min            -82.64643
V Predictions Mean           3142.0452
V Predictions Std            375.3397
V Predictions Max            3934.2424
V Predictions Min            124.64289
Log Pis Mean                 2.547193
Log Pis Std                  4.084989
Log Pis Max                  46.017582
Log Pis Min                  -8.802771
Policy mu Mean               0.102047786
Policy mu Std                0.9184503
Policy mu Max                6.626835
Policy mu Min                -3.007111
Policy log std Mean          -1.0076087
Policy log std Std           0.3218537
Policy log std Max           1.7699908
Policy log std Min           -2.7610388
Z mean eval                  1.2039325
Z variance eval              0.20600334
total_rewards                [ 151.1498175    42.23808736  352.71322415  712.06567797  -10.78344636
 -498.47956096  119.75135245 -347.85881553  410.96598574  292.01932295]
total_rewards_mean           122.37816452561847
total_rewards_std            338.2932077113404
total_rewards_max            712.0656779673034
total_rewards_min            -498.4795609612061
Number of train steps total  1248000
Number of env steps total    1822704
Number of rollouts total     0
Train Time (s)               147.26664629392326
(Previous) Eval Time (s)     13.900149689987302
Sample Time (s)              7.167522139847279
Epoch Time (s)               168.33431812375784
Total Train Time (s)         52536.82961558178
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:56:14.005099 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #311 | Epoch Duration: 168.4325726032257
2020-01-11 22:56:14.005442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2112627
Z variance train             0.20595463
KL Divergence                24.644442
KL Loss                      2.4644442
QF Loss                      5713.248
VF Loss                      1007.6089
Policy Loss                  -2782.1294
Q Predictions Mean           2769.9587
Q Predictions Std            347.8097
Q Predictions Max            3286.281
Q Predictions Min            -355.11316
V Predictions Mean           2791.064
V Predictions Std            316.16168
V Predictions Max            3322.854
V Predictions Min            861.62756
Log Pis Mean                 2.0052056
Log Pis Std                  3.245419
Log Pis Max                  29.867401
Log Pis Min                  -8.446955
Policy mu Mean               0.095979646
Policy mu Std                0.794008
Policy mu Max                4.935875
Policy mu Min                -4.619303
Policy log std Mean          -1.0621445
Policy log std Std           0.26800504
Policy log std Max           -0.25086737
Policy log std Min           -2.4581785
Z mean eval                  1.1646271
Z variance eval              0.2218494
total_rewards                [-207.19655314   90.05555352  108.66990748  397.63803114  360.72859069
  462.06771606  158.75081741  408.66109763  273.2091683   827.85331961]
total_rewards_mean           288.04376487071534
total_rewards_std            262.1250151536881
total_rewards_max            827.8533196090376
total_rewards_min            -207.1965531442708
Number of train steps total  1252000
Number of env steps total    1832228
Number of rollouts total     0
Train Time (s)               147.22047175234184
(Previous) Eval Time (s)     14.23296682536602
Sample Time (s)              7.56058840546757
Epoch Time (s)               169.01402698317543
Total Train Time (s)         52705.93466326175
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 22:59:03.111659 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #312 | Epoch Duration: 169.1059765815735
2020-01-11 22:59:03.111841 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1628256
Z variance train             0.22236972
KL Divergence                21.58506
KL Loss                      2.1585062
QF Loss                      33697.42
VF Loss                      564.22125
Policy Loss                  -2471.8
Q Predictions Mean           2466.1838
Q Predictions Std            215.02577
Q Predictions Max            2968.6226
Q Predictions Min            1589.807
V Predictions Mean           2466.4248
V Predictions Std            209.96187
V Predictions Max            2952.5132
V Predictions Min            1592.907
Log Pis Mean                 1.8870476
Log Pis Std                  2.8314574
Log Pis Max                  12.012062
Log Pis Min                  -6.6775184
Policy mu Mean               -0.06476596
Policy mu Std                0.8049144
Policy mu Max                2.3842943
Policy mu Min                -2.914473
Policy log std Mean          -1.0289633
Policy log std Std           0.28634942
Policy log std Max           -0.14401805
Policy log std Min           -2.5400343
Z mean eval                  1.0511076
Z variance eval              0.40147248
total_rewards                [ 585.38809957   79.5873803   464.59164987 -103.58692817 -364.98851935
 -290.1288404    40.67141998  304.65532022  190.42952411 -423.8905096 ]
total_rewards_mean           48.272859653200065
total_rewards_std            328.6477294692536
total_rewards_max            585.388099573987
total_rewards_min            -423.89050959624024
Number of train steps total  1256000
Number of env steps total    1841284
Number of rollouts total     0
Train Time (s)               146.572114800103
(Previous) Eval Time (s)     16.327398115303367
Sample Time (s)              7.641575900837779
Epoch Time (s)               170.54108881624416
Total Train Time (s)         52876.623283020686
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:01:53.803938 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #313 | Epoch Duration: 170.69195222854614
2020-01-11 23:01:53.804122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.053671
Z variance train             0.4034068
KL Divergence                20.991322
KL Loss                      2.0991323
QF Loss                      1490.1758
VF Loss                      258.6008
Policy Loss                  -2179.5508
Q Predictions Mean           2170.1553
Q Predictions Std            229.13217
Q Predictions Max            2687.8516
Q Predictions Min            1399.6719
V Predictions Mean           2179.9155
V Predictions Std            222.24622
V Predictions Max            2679.1404
V Predictions Min            1389.9471
Log Pis Mean                 2.1104827
Log Pis Std                  2.8036683
Log Pis Max                  10.099522
Log Pis Min                  -5.7854843
Policy mu Mean               -0.010004459
Policy mu Std                0.82338804
Policy mu Max                2.6963906
Policy mu Min                -2.5945466
Policy log std Mean          -1.0202792
Policy log std Std           0.28262693
Policy log std Max           -0.2548337
Policy log std Min           -2.270737
Z mean eval                  1.0442302
Z variance eval              0.08231369
total_rewards                [ 146.00853719  712.70300702  467.96924912 1968.77813313  147.36566007
  420.32761794 1372.65579787   59.88789508  495.28331576  333.69114154]
total_rewards_mean           612.4670354715477
total_rewards_std            575.8476980712506
total_rewards_max            1968.778133125684
total_rewards_min            59.88789508103847
Number of train steps total  1260000
Number of env steps total    1850592
Number of rollouts total     0
Train Time (s)               148.20588567573577
(Previous) Eval Time (s)     17.034307185094804
Sample Time (s)              7.725020913872868
Epoch Time (s)               172.96521377470344
Total Train Time (s)         53049.75728629809
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:04:46.939404 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #314 | Epoch Duration: 173.13515329360962
2020-01-11 23:04:46.939543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0435195
Z variance train             0.08224428
KL Divergence                19.866901
KL Loss                      1.9866902
QF Loss                      889.6085
VF Loss                      155.33226
Policy Loss                  -1979.5051
Q Predictions Mean           1974.833
Q Predictions Std            213.81346
Q Predictions Max            2497.5818
Q Predictions Min            1309.5892
V Predictions Mean           1977.6375
V Predictions Std            209.70863
V Predictions Max            2466.711
V Predictions Min            1309.3052
Log Pis Mean                 1.0540221
Log Pis Std                  2.6655354
Log Pis Max                  10.34655
Log Pis Min                  -6.065371
Policy mu Mean               -0.015462375
Policy mu Std                0.78972214
Policy mu Max                2.8451061
Policy mu Min                -2.429911
Policy log std Mean          -0.982617
Policy log std Std           0.26460844
Policy log std Max           -0.112072945
Policy log std Min           -2.404418
Z mean eval                  1.0352814
Z variance eval              0.16017422
total_rewards                [ 502.31254492  344.61260341 3005.35330255  -17.49563051 1304.36714444
   43.97545894  756.02540312  417.17353876 2092.86308366 1506.83078266]
total_rewards_mean           995.6018231963078
total_rewards_std            926.8673562362479
total_rewards_max            3005.353302547954
total_rewards_min            -17.49563050859021
Number of train steps total  1264000
Number of env steps total    1862063
Number of rollouts total     0
Train Time (s)               147.1542550851591
(Previous) Eval Time (s)     10.908383755013347
Sample Time (s)              7.8609797223471105
Epoch Time (s)               165.92361856251955
Total Train Time (s)         53215.76887389133
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:07:32.954598 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #315 | Epoch Duration: 166.01493859291077
2020-01-11 23:07:32.954790 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0323981
Z variance train             0.15916112
KL Divergence                19.701149
KL Loss                      1.970115
QF Loss                      876.3711
VF Loss                      252.21461
Policy Loss                  -1829.4469
Q Predictions Mean           1822.131
Q Predictions Std            211.72272
Q Predictions Max            2343.445
Q Predictions Min            1197.5708
V Predictions Mean           1829.6718
V Predictions Std            213.37854
V Predictions Max            2351.0566
V Predictions Min            1208.2986
Log Pis Mean                 0.9388865
Log Pis Std                  2.7088597
Log Pis Max                  10.274335
Log Pis Min                  -9.155021
Policy mu Mean               0.026115403
Policy mu Std                0.73340285
Policy mu Max                2.1419954
Policy mu Min                -2.271729
Policy log std Mean          -1.0138057
Policy log std Std           0.24629793
Policy log std Max           -0.34988415
Policy log std Min           -2.4135416
Z mean eval                  1.0202343
Z variance eval              0.13141298
total_rewards                [ 140.15222398 1457.80519564  215.47390087   93.33307932  198.47329136
 1283.44253249  -15.27158058  312.93766194   66.74455141 -505.53173442]
total_rewards_mean           324.75591220233144
total_rewards_std            564.8107140939245
total_rewards_max            1457.8051956418055
total_rewards_min            -505.53173441841386
Number of train steps total  1268000
Number of env steps total    1872653
Number of rollouts total     0
Train Time (s)               146.94891093997285
(Previous) Eval Time (s)     12.404849644750357
Sample Time (s)              7.4229874005541205
Epoch Time (s)               166.77674798527732
Total Train Time (s)         53382.79987205472
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:10:19.997357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #316 | Epoch Duration: 167.04243755340576
2020-01-11 23:10:19.997499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.017922
Z variance train             0.1304279
KL Divergence                20.02987
KL Loss                      2.002987
QF Loss                      20317.293
VF Loss                      163.55203
Policy Loss                  -1718.2338
Q Predictions Mean           1713.2212
Q Predictions Std            214.76422
Q Predictions Max            2300.586
Q Predictions Min            1152.6152
V Predictions Mean           1716.9121
V Predictions Std            212.87253
V Predictions Max            2248.291
V Predictions Min            1140.6493
Log Pis Mean                 1.5883901
Log Pis Std                  3.1169362
Log Pis Max                  28.580187
Log Pis Min                  -5.8840456
Policy mu Mean               -0.018971909
Policy mu Std                0.7643543
Policy mu Max                3.1948957
Policy mu Min                -3.299154
Policy log std Mean          -1.0149907
Policy log std Std           0.2472709
Policy log std Max           -0.17066228
Policy log std Min           -2.2744308
Z mean eval                  0.878201
Z variance eval              0.2538444
total_rewards                [  50.15277308   92.19379445  268.44614707  135.27056034   85.07105908
  304.26240533   42.43072143  507.08342193 1031.84398177  852.56204065]
total_rewards_mean           336.9316905140281
total_rewards_std            334.13433065324915
total_rewards_max            1031.8439817709543
total_rewards_min            42.43072143137276
Number of train steps total  1272000
Number of env steps total    1882674
Number of rollouts total     0
Train Time (s)               148.12561930622905
(Previous) Eval Time (s)     13.819327123928815
Sample Time (s)              7.743436414282769
Epoch Time (s)               169.68838284444064
Total Train Time (s)         53552.59140594071
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:13:09.781678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #317 | Epoch Duration: 169.7840723991394
2020-01-11 23:13:09.781821 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8812494
Z variance train             0.25433102
KL Divergence                16.740318
KL Loss                      1.6740319
QF Loss                      1450.9243
VF Loss                      174.02794
Policy Loss                  -1599.5304
Q Predictions Mean           1590.4445
Q Predictions Std            232.9651
Q Predictions Max            2134.5735
Q Predictions Min            696.444
V Predictions Mean           1597.1714
V Predictions Std            221.5737
V Predictions Max            2131.5532
V Predictions Min            1045.3723
Log Pis Mean                 0.98942083
Log Pis Std                  2.6492057
Log Pis Max                  10.349371
Log Pis Min                  -6.721818
Policy mu Mean               0.0048799813
Policy mu Std                0.7539199
Policy mu Max                2.5554936
Policy mu Min                -2.4000168
Policy log std Mean          -0.97839177
Policy log std Std           0.26277006
Policy log std Max           -0.18199646
Policy log std Min           -2.2876973
Z mean eval                  0.91171753
Z variance eval              0.078388676
total_rewards                [1603.02502961 1795.40162731   50.10568534 1128.32780497 2456.21517745
   46.8687975   116.0945134  2382.48330683  982.42375826  841.523003  ]
total_rewards_mean           1140.246870367491
total_rewards_std            864.0238967252103
total_rewards_max            2456.215177453519
total_rewards_min            46.86879750096613
Number of train steps total  1276000
Number of env steps total    1892756
Number of rollouts total     0
Train Time (s)               146.90646971669048
(Previous) Eval Time (s)     15.977511621080339
Sample Time (s)              7.371195117011666
Epoch Time (s)               170.2551764547825
Total Train Time (s)         53722.95009424398
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:16:00.143922 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #318 | Epoch Duration: 170.36196851730347
2020-01-11 23:16:00.144151 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9136504
Z variance train             0.07815689
KL Divergence                18.444841
KL Loss                      1.8444842
QF Loss                      4002.9143
VF Loss                      312.8582
Policy Loss                  -1507.7645
Q Predictions Mean           1496.7312
Q Predictions Std            274.05072
Q Predictions Max            2077.3857
Q Predictions Min            447.07718
V Predictions Mean           1497.3757
V Predictions Std            266.01968
V Predictions Max            2067.3323
V Predictions Min            809.5095
Log Pis Mean                 1.0289931
Log Pis Std                  2.6442711
Log Pis Max                  11.302591
Log Pis Min                  -6.707478
Policy mu Mean               0.017272262
Policy mu Std                0.75315875
Policy mu Max                2.699137
Policy mu Min                -2.7416193
Policy log std Mean          -0.97023755
Policy log std Std           0.2594325
Policy log std Max           -0.1972605
Policy log std Min           -2.2214923
Z mean eval                  0.959638
Z variance eval              0.08548773
total_rewards                [ 324.04449229 1599.85959752  978.6409846   112.1677908  3628.59805897
 1134.28157127   23.31400846 3087.53518787 3963.19881676 2047.86965072]
total_rewards_mean           1689.9510159251506
total_rewards_std            1377.061421862588
total_rewards_max            3963.1988167561585
total_rewards_min            23.314008462612247
Number of train steps total  1280000
Number of env steps total    1904095
Number of rollouts total     0
Train Time (s)               147.99234098521993
(Previous) Eval Time (s)     16.05110703688115
Sample Time (s)              7.858181536663324
Epoch Time (s)               171.9016295587644
Total Train Time (s)         53894.9597605099
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:18:52.155557 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #319 | Epoch Duration: 172.01124596595764
2020-01-11 23:18:52.155707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96301067
Z variance train             0.08545898
KL Divergence                18.344814
KL Loss                      1.8344815
QF Loss                      1021.7194
VF Loss                      366.21136
Policy Loss                  -1438.3759
Q Predictions Mean           1429.4719
Q Predictions Std            277.83408
Q Predictions Max            1978.5875
Q Predictions Min            687.4882
V Predictions Mean           1423.9839
V Predictions Std            275.82977
V Predictions Max            1973.169
V Predictions Min            663.39154
Log Pis Mean                 0.64417946
Log Pis Std                  2.9964445
Log Pis Max                  18.07029
Log Pis Min                  -6.5048285
Policy mu Mean               0.03235081
Policy mu Std                0.72175556
Policy mu Max                3.2700794
Policy mu Min                -2.5592027
Policy log std Mean          -0.9748167
Policy log std Std           0.27036703
Policy log std Max           -0.056922674
Policy log std Min           -2.366851
Z mean eval                  1.0848806
Z variance eval              0.04426209
total_rewards                [ 835.59717283 1983.25605488  535.30677971   79.43248129  769.27814604
 2898.42577841  253.94844573    4.23283838 1778.90730306 2021.10834517]
total_rewards_mean           1115.949334550437
total_rewards_std            936.8841782105765
total_rewards_max            2898.4257784066353
total_rewards_min            4.232838379481967
Number of train steps total  1284000
Number of env steps total    1914593
Number of rollouts total     0
Train Time (s)               147.60735634202138
(Previous) Eval Time (s)     13.815360829234123
Sample Time (s)              7.79811128647998
Epoch Time (s)               169.22082845773548
Total Train Time (s)         54064.287124222144
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:21:41.488157 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #320 | Epoch Duration: 169.3322970867157
2020-01-11 23:21:41.488409 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #320 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0850571
Z variance train             0.04421246
KL Divergence                19.566544
KL Loss                      1.9566544
QF Loss                      544.88257
VF Loss                      83.047134
Policy Loss                  -1369.6443
Q Predictions Mean           1363.8042
Q Predictions Std            287.47684
Q Predictions Max            1942.7955
Q Predictions Min            676.89966
V Predictions Mean           1370.0814
V Predictions Std            285.81754
V Predictions Max            1933.6606
V Predictions Min            681.04364
Log Pis Mean                 0.32137793
Log Pis Std                  2.764617
Log Pis Max                  8.382547
Log Pis Min                  -7.3767366
Policy mu Mean               -0.0056893197
Policy mu Std                0.7163101
Policy mu Max                2.71974
Policy mu Min                -2.5959241
Policy log std Mean          -0.93886644
Policy log std Std           0.26221922
Policy log std Max           -0.14944363
Policy log std Min           -1.9820838
Z mean eval                  0.97741354
Z variance eval              0.06345091
total_rewards                [3426.3612099  1478.46677644 4087.75988039 1902.12466782 3528.712638
  271.04896503 3982.41812311 3794.97635843 4113.44354532 2943.70708167]
total_rewards_mean           2952.9019246106404
total_rewards_std            1242.1749374475564
total_rewards_max            4113.443545322668
total_rewards_min            271.04896503098263
Number of train steps total  1288000
Number of env steps total    1924753
Number of rollouts total     0
Train Time (s)               148.04920337582007
(Previous) Eval Time (s)     21.592609444167465
Sample Time (s)              8.28820772934705
Epoch Time (s)               177.93002054933459
Total Train Time (s)         54242.30848222412
Epoch                        321
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:24:39.511076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #321 | Epoch Duration: 178.0224974155426
2020-01-11 23:24:39.511222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9772949
Z variance train             0.0625888
KL Divergence                19.152435
KL Loss                      1.9152435
QF Loss                      1161.6145
VF Loss                      137.89627
Policy Loss                  -1332.3201
Q Predictions Mean           1323.0054
Q Predictions Std            306.85168
Q Predictions Max            1909.099
Q Predictions Min            497.55624
V Predictions Mean           1331.5103
V Predictions Std            297.24368
V Predictions Max            1925.5121
V Predictions Min            569.3144
Log Pis Mean                 1.2966082
Log Pis Std                  3.3581455
Log Pis Max                  16.179428
Log Pis Min                  -6.348009
Policy mu Mean               0.074395046
Policy mu Std                0.769191
Policy mu Max                3.289919
Policy mu Min                -3.4364138
Policy log std Mean          -0.9901093
Policy log std Std           0.28612408
Policy log std Max           -0.04681456
Policy log std Min           -2.2943113
Z mean eval                  0.8910154
Z variance eval              0.072200075
total_rewards                [4088.87239304 1883.70716899 2974.1080965  -178.76043738  372.28904127
  944.70837838 3993.62495866 3036.70184878   37.29661504  159.61565633]
total_rewards_mean           1731.2163719598673
total_rewards_std            1593.7986954990324
total_rewards_max            4088.8723930355786
total_rewards_min            -178.76043737778556
Number of train steps total  1292000
Number of env steps total    1935273
Number of rollouts total     0
Train Time (s)               146.90641234675422
(Previous) Eval Time (s)     13.84284047409892
Sample Time (s)              7.316383676137775
Epoch Time (s)               168.06563649699092
Total Train Time (s)         54410.46505069686
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:27:27.671780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #322 | Epoch Duration: 168.1604359149933
2020-01-11 23:27:27.671973 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89375037
Z variance train             0.072145976
KL Divergence                19.239727
KL Loss                      1.9239727
QF Loss                      1692.5864
VF Loss                      124.37163
Policy Loss                  -1296.6472
Q Predictions Mean           1289.8246
Q Predictions Std            293.46463
Q Predictions Max            1861.6499
Q Predictions Min            570.255
V Predictions Mean           1292.0549
V Predictions Std            289.32715
V Predictions Max            1839.9963
V Predictions Min            577.9767
Log Pis Mean                 0.35833868
Log Pis Std                  2.9348125
Log Pis Max                  12.970873
Log Pis Min                  -9.636341
Policy mu Mean               0.021240419
Policy mu Std                0.69738
Policy mu Max                2.1527154
Policy mu Min                -3.4842005
Policy log std Mean          -0.9525012
Policy log std Std           0.27409607
Policy log std Max           -0.15000486
Policy log std Min           -2.4802382
Z mean eval                  0.8369177
Z variance eval              0.0699278
total_rewards                [1838.11778111  309.4891879   551.66931074 4475.21600666 3930.26441283
 3833.51231416 3321.58464388 4284.78133453 2469.77885517  503.95891719]
total_rewards_mean           2551.8372764161913
total_rewards_std            1567.688612216386
total_rewards_max            4475.216006660529
total_rewards_min            309.48918789508986
Number of train steps total  1296000
Number of env steps total    1946711
Number of rollouts total     0
Train Time (s)               146.5247127711773
(Previous) Eval Time (s)     16.12750907614827
Sample Time (s)              7.597140606492758
Epoch Time (s)               170.24936245381832
Total Train Time (s)         54580.83546741633
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:30:18.045660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #323 | Epoch Duration: 170.3735375404358
2020-01-11 23:30:18.045840 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8472818
Z variance train             0.06793254
KL Divergence                18.573635
KL Loss                      1.8573636
QF Loss                      484.47247
VF Loss                      116.61221
Policy Loss                  -1240.444
Q Predictions Mean           1233.315
Q Predictions Std            300.89246
Q Predictions Max            1799.9622
Q Predictions Min            520.8384
V Predictions Mean           1239.8579
V Predictions Std            301.7578
V Predictions Max            1786.351
V Predictions Min            516.3882
Log Pis Mean                 0.2535359
Log Pis Std                  2.704838
Log Pis Max                  7.5391083
Log Pis Min                  -8.189453
Policy mu Mean               0.029113282
Policy mu Std                0.6702684
Policy mu Max                2.3648937
Policy mu Min                -2.629012
Policy log std Mean          -0.96953905
Policy log std Std           0.27256104
Policy log std Max           -0.21493196
Policy log std Min           -2.094601
Z mean eval                  0.9534513
Z variance eval              0.051078808
total_rewards                [ 331.13710898 3601.69497315 2746.35755948   48.71791312 4294.04139972
  523.42537638 4027.23366617  957.81873673 3471.02872225 3758.32016222]
total_rewards_mean           2375.977561820058
total_rewards_std            1618.5123488974261
total_rewards_max            4294.041399720729
total_rewards_min            48.717913117932355
Number of train steps total  1300000
Number of env steps total    1957251
Number of rollouts total     0
Train Time (s)               148.14928887225688
(Previous) Eval Time (s)     15.282562816981226
Sample Time (s)              7.271054292563349
Epoch Time (s)               170.70290598180145
Total Train Time (s)         54751.63307580957
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:33:08.844717 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #324 | Epoch Duration: 170.79875373840332
2020-01-11 23:33:08.844849 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94727707
Z variance train             0.05087892
KL Divergence                18.887669
KL Loss                      1.8887669
QF Loss                      549.0199
VF Loss                      113.80948
Policy Loss                  -1223.4694
Q Predictions Mean           1221.1931
Q Predictions Std            306.85526
Q Predictions Max            1777.9941
Q Predictions Min            468.5901
V Predictions Mean           1222.5039
V Predictions Std            305.20105
V Predictions Max            1755.256
V Predictions Min            475.46445
Log Pis Mean                 0.25571674
Log Pis Std                  2.8710084
Log Pis Max                  10.944456
Log Pis Min                  -10.345185
Policy mu Mean               -0.014348394
Policy mu Std                0.6608209
Policy mu Max                2.5520506
Policy mu Min                -2.4397764
Policy log std Mean          -0.9707607
Policy log std Std           0.27370617
Policy log std Max           -0.051133037
Policy log std Min           -2.3906202
Z mean eval                  0.81371385
Z variance eval              0.0153417485
total_rewards                [ 927.54294056  188.13244342 1637.39717718 3966.74545217 3820.62346073
 4070.35825209  386.60342806 3655.35981702 1367.65735514 3434.55880883]
total_rewards_mean           2345.497913520264
total_rewards_std            1504.694071286276
total_rewards_max            4070.3582520920204
total_rewards_min            188.13244342326982
Number of train steps total  1304000
Number of env steps total    1969251
Number of rollouts total     0
Train Time (s)               145.7871784348972
(Previous) Eval Time (s)     16.668000624980778
Sample Time (s)              6.018572765402496
Epoch Time (s)               168.4737518252805
Total Train Time (s)         54920.19519368
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:35:57.410238 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #325 | Epoch Duration: 168.56528306007385
2020-01-11 23:35:57.410389 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.814226
Z variance train             0.015242465
KL Divergence                19.53102
KL Loss                      1.953102
QF Loss                      1482.4375
VF Loss                      161.05815
Policy Loss                  -1202.0215
Q Predictions Mean           1199.168
Q Predictions Std            331.66245
Q Predictions Max            1815.3534
Q Predictions Min            429.128
V Predictions Mean           1203.7769
V Predictions Std            328.77182
V Predictions Max            1810.0471
V Predictions Min            402.74426
Log Pis Mean                 0.6190971
Log Pis Std                  3.220203
Log Pis Max                  20.117947
Log Pis Min                  -10.133417
Policy mu Mean               0.010414464
Policy mu Std                0.7084001
Policy mu Max                3.2575126
Policy mu Min                -2.9308639
Policy log std Mean          -0.9610095
Policy log std Std           0.2864014
Policy log std Max           -0.2748655
Policy log std Min           -2.2885425
Z mean eval                  0.8698932
Z variance eval              0.03086916
total_rewards                [2060.86183187 4160.71814864 1314.86649448 4292.6519572  4142.85409991
 3713.32253017 4186.32062851 1116.5640425  1248.38940521  543.16105278]
total_rewards_mean           2677.9710191294853
total_rewards_std            1468.9000626936818
total_rewards_max            4292.651957200419
total_rewards_min            543.1610527800159
Number of train steps total  1308000
Number of env steps total    1981026
Number of rollouts total     0
Train Time (s)               147.7304720338434
(Previous) Eval Time (s)     18.473284938838333
Sample Time (s)              7.241693580988795
Epoch Time (s)               173.44545055367053
Total Train Time (s)         55093.73308283882
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:38:50.949887 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #326 | Epoch Duration: 173.53939199447632
2020-01-11 23:38:50.950032 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86947024
Z variance train             0.030825373
KL Divergence                19.076862
KL Loss                      1.9076862
QF Loss                      5039.883
VF Loss                      149.59706
Policy Loss                  -1208.6388
Q Predictions Mean           1202.4495
Q Predictions Std            317.3281
Q Predictions Max            1786.6345
Q Predictions Min            437.2012
V Predictions Mean           1204.5146
V Predictions Std            314.87735
V Predictions Max            1788.74
V Predictions Min            451.63364
Log Pis Mean                 0.34310052
Log Pis Std                  3.0067606
Log Pis Max                  12.294863
Log Pis Min                  -9.8151455
Policy mu Mean               0.051348574
Policy mu Std                0.67048615
Policy mu Max                2.8439386
Policy mu Min                -2.6503289
Policy log std Mean          -1.0072913
Policy log std Std           0.28393474
Policy log std Max           -0.18743336
Policy log std Min           -2.4673562
Z mean eval                  0.8646758
Z variance eval              0.022909204
total_rewards                [ 503.83896828 1415.92036393 -144.78725872 4395.91658528 2080.49928309
   81.3423754  2942.63187399 1321.18360472 1244.86718904  481.00650992]
total_rewards_mean           1432.2419494936562
total_rewards_std            1327.0766380375935
total_rewards_max            4395.916585284314
total_rewards_min            -144.787258716343
Number of train steps total  1312000
Number of env steps total    1988655
Number of rollouts total     0
Train Time (s)               145.25094787729904
(Previous) Eval Time (s)     10.994665694888681
Sample Time (s)              7.060962551739067
Epoch Time (s)               163.3065761239268
Total Train Time (s)         55257.27790492214
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:41:34.515572 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #327 | Epoch Duration: 163.56542825698853
2020-01-11 23:41:34.515725 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8570148
Z variance train             0.023053631
KL Divergence                19.811228
KL Loss                      1.9811229
QF Loss                      526.2406
VF Loss                      163.47797
Policy Loss                  -1219.5792
Q Predictions Mean           1215.6948
Q Predictions Std            325.31488
Q Predictions Max            1755.4333
Q Predictions Min            400.66818
V Predictions Mean           1228.1108
V Predictions Std            322.90088
V Predictions Max            1776.0735
V Predictions Min            410.61496
Log Pis Mean                 0.45188898
Log Pis Std                  2.7309878
Log Pis Max                  9.504321
Log Pis Min                  -7.2507386
Policy mu Mean               0.017024979
Policy mu Std                0.6613792
Policy mu Max                2.396735
Policy mu Min                -2.6138258
Policy log std Mean          -0.9969796
Policy log std Std           0.28674847
Policy log std Max           0.008518338
Policy log std Min           -2.1452122
Z mean eval                  0.81593466
Z variance eval              0.018288944
total_rewards                [ 481.90636022 3450.55642089   46.4617137  4243.30373546 4090.48548158
 4463.5646454  2934.55340048  284.88219466 4144.01207688 3023.78586534]
total_rewards_mean           2716.3511894619214
total_rewards_std            1674.0692992715458
total_rewards_max            4463.564645404922
total_rewards_min            46.461713703668266
Number of train steps total  1316000
Number of env steps total    2000442
Number of rollouts total     0
Train Time (s)               145.71286549558863
(Previous) Eval Time (s)     18.224572575185448
Sample Time (s)              7.9497071034274995
Epoch Time (s)               171.88714517420158
Total Train Time (s)         55429.27641887823
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:44:26.498474 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #328 | Epoch Duration: 171.9826455116272
2020-01-11 23:44:26.498628 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81508625
Z variance train             0.018355884
KL Divergence                20.837357
KL Loss                      2.0837357
QF Loss                      913.1086
VF Loss                      695.7258
Policy Loss                  -1167.4119
Q Predictions Mean           1158.8223
Q Predictions Std            364.78284
Q Predictions Max            1771.871
Q Predictions Min            -36.418266
V Predictions Mean           1168.0334
V Predictions Std            358.1898
V Predictions Max            1764.087
V Predictions Min            -22.089987
Log Pis Mean                 0.5503401
Log Pis Std                  3.4887693
Log Pis Max                  28.785498
Log Pis Min                  -7.1708403
Policy mu Mean               -0.0016491197
Policy mu Std                0.71469384
Policy mu Max                3.695374
Policy mu Min                -4.373354
Policy log std Mean          -0.948784
Policy log std Std           0.30448756
Policy log std Max           0.0111095905
Policy log std Min           -2.6702127
Z mean eval                  0.86595917
Z variance eval              0.10026487
total_rewards                [ 455.3396815  4072.0703742  3486.02953788 4670.086764    792.16273318
  927.76778999 4432.73098535   40.42802395 1670.05201057  134.55435711]
total_rewards_mean           2068.1222257727113
total_rewards_std            1786.7876244090069
total_rewards_max            4670.086763997537
total_rewards_min            40.42802394909534
Number of train steps total  1320000
Number of env steps total    2012442
Number of rollouts total     0
Train Time (s)               146.85378240188584
(Previous) Eval Time (s)     12.535754450131208
Sample Time (s)              7.290455584879965
Epoch Time (s)               166.679992436897
Total Train Time (s)         55596.04669505637
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:47:13.272005 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #329 | Epoch Duration: 166.7732572555542
2020-01-11 23:47:13.272189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86693925
Z variance train             0.09948023
KL Divergence                19.278397
KL Loss                      1.9278396
QF Loss                      412.886
VF Loss                      85.35206
Policy Loss                  -1194.8667
Q Predictions Mean           1190.9868
Q Predictions Std            332.6518
Q Predictions Max            1792.0802
Q Predictions Min            405.80096
V Predictions Mean           1196.2598
V Predictions Std            331.28476
V Predictions Max            1739.5742
V Predictions Min            418.39777
Log Pis Mean                 0.6332325
Log Pis Std                  2.7845309
Log Pis Max                  11.431604
Log Pis Min                  -8.631292
Policy mu Mean               0.011179162
Policy mu Std                0.67918605
Policy mu Max                2.4620097
Policy mu Min                -2.4093904
Policy log std Mean          -0.98651034
Policy log std Std           0.27547035
Policy log std Max           -0.25743973
Policy log std Min           -2.41427
Z mean eval                  0.9567236
Z variance eval              0.015301602
total_rewards                [ 782.03819804 4358.15516194 4288.83328801  480.62278412  698.94624388
 1505.26424013 3976.19611893 4254.85647262 2439.84884493 4066.93967577]
total_rewards_mean           2685.1701028370944
total_rewards_std            1590.2814453941628
total_rewards_max            4358.155161941941
total_rewards_min            480.62278412442186
Number of train steps total  1324000
Number of env steps total    2023017
Number of rollouts total     0
Train Time (s)               145.70889100292698
(Previous) Eval Time (s)     16.747438713908195
Sample Time (s)              6.171395462937653
Epoch Time (s)               168.62772517977282
Total Train Time (s)         55764.81092862971
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:50:02.044767 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #330 | Epoch Duration: 168.77244400978088
2020-01-11 23:50:02.044933 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96514714
Z variance train             0.01544403
KL Divergence                20.829334
KL Loss                      2.0829334
QF Loss                      421.62137
VF Loss                      97.66629
Policy Loss                  -1156.3907
Q Predictions Mean           1148.631
Q Predictions Std            344.96503
Q Predictions Max            1776.8281
Q Predictions Min            402.47772
V Predictions Mean           1155.7771
V Predictions Std            344.0329
V Predictions Max            1762.874
V Predictions Min            367.37045
Log Pis Mean                 0.3683898
Log Pis Std                  3.256419
Log Pis Max                  14.100241
Log Pis Min                  -8.912943
Policy mu Mean               0.044665754
Policy mu Std                0.68518126
Policy mu Max                2.7214592
Policy mu Min                -2.7323842
Policy log std Mean          -0.9718415
Policy log std Std           0.2923876
Policy log std Max           -0.20922816
Policy log std Min           -2.5786405
Z mean eval                  0.856949
Z variance eval              0.019588456
total_rewards                [4456.1757452  3942.29517847 2646.60015816 1284.25305759 1576.48373241
 4447.75317863 4571.12158155 2509.65827318 4523.49638972  648.53872091]
total_rewards_mean           3060.637601580698
total_rewards_std            1439.5115524209061
total_rewards_max            4571.1215815454125
total_rewards_min            648.5387209093562
Number of train steps total  1328000
Number of env steps total    2031318
Number of rollouts total     0
Train Time (s)               146.53207987267524
(Previous) Eval Time (s)     17.616217301692814
Sample Time (s)              6.266449803020805
Epoch Time (s)               170.41474697738886
Total Train Time (s)         55935.319089399185
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:52:52.549985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #331 | Epoch Duration: 170.50492668151855
2020-01-11 23:52:52.550130 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8577673
Z variance train             0.01955318
KL Divergence                19.93611
KL Loss                      1.993611
QF Loss                      520.63055
VF Loss                      116.79106
Policy Loss                  -1151.6063
Q Predictions Mean           1146.1804
Q Predictions Std            358.01895
Q Predictions Max            1767.9456
Q Predictions Min            376.42807
V Predictions Mean           1156.9023
V Predictions Std            359.1485
V Predictions Max            1770.489
V Predictions Min            369.7459
Log Pis Mean                 0.33833566
Log Pis Std                  2.710297
Log Pis Max                  10.116886
Log Pis Min                  -5.9194565
Policy mu Mean               0.047619164
Policy mu Std                0.6534418
Policy mu Max                1.8335816
Policy mu Min                -2.3690352
Policy log std Mean          -0.96727663
Policy log std Std           0.26097357
Policy log std Max           -0.29627478
Policy log std Min           -2.6295748
Z mean eval                  0.8853494
Z variance eval              0.04844123
total_rewards                [3722.72263465 1631.43920979  376.07480341  571.84638732  363.84669569
  494.56193641 3373.68780699 1823.22136518  389.31478169   41.54250918]
total_rewards_mean           1278.8258130312113
total_rewards_std            1259.79827469183
total_rewards_max            3722.7226346462944
total_rewards_min            41.5425091845373
Number of train steps total  1332000
Number of env steps total    2042954
Number of rollouts total     0
Train Time (s)               147.04136352567002
(Previous) Eval Time (s)     11.013989276252687
Sample Time (s)              8.01367171946913
Epoch Time (s)               166.06902452139184
Total Train Time (s)         56101.48277036473
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:55:38.716065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #332 | Epoch Duration: 166.16582441329956
2020-01-11 23:55:38.716225 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8830358
Z variance train             0.048213933
KL Divergence                19.038166
KL Loss                      1.9038166
QF Loss                      847.5651
VF Loss                      70.62959
Policy Loss                  -1176.0958
Q Predictions Mean           1171.1548
Q Predictions Std            373.82956
Q Predictions Max            1816.466
Q Predictions Min            374.8177
V Predictions Mean           1177.3835
V Predictions Std            374.13998
V Predictions Max            1814.7799
V Predictions Min            370.8343
Log Pis Mean                 0.042937703
Log Pis Std                  2.86467
Log Pis Max                  9.353043
Log Pis Min                  -8.490092
Policy mu Mean               -0.045687966
Policy mu Std                0.6313777
Policy mu Max                2.0543284
Policy mu Min                -2.6131077
Policy log std Mean          -0.9724909
Policy log std Std           0.28641465
Policy log std Max           -0.09150946
Policy log std Min           -2.469812
Z mean eval                  0.88689727
Z variance eval              0.028703058
total_rewards                [ 259.47590289 1104.61534327  594.96225723 2313.71705325 4270.48994033
  193.19938059  544.55704675  260.50118178  491.3761652   308.60999242]
total_rewards_mean           1034.150426370516
total_rewards_std            1235.9450911886865
total_rewards_max            4270.489940334315
total_rewards_min            193.19938058655308
Number of train steps total  1336000
Number of env steps total    2052926
Number of rollouts total     0
Train Time (s)               146.24039129912853
(Previous) Eval Time (s)     9.348403637763113
Sample Time (s)              6.9878098466433585
Epoch Time (s)               162.576604783535
Total Train Time (s)         56264.15022847988
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 23:58:21.387518 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #333 | Epoch Duration: 162.67118287086487
2020-01-11 23:58:21.387671 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8781045
Z variance train             0.027311895
KL Divergence                19.931253
KL Loss                      1.9931253
QF Loss                      690.6566
VF Loss                      163.70374
Policy Loss                  -1163.2562
Q Predictions Mean           1154.5695
Q Predictions Std            350.28
Q Predictions Max            1775.8998
Q Predictions Min            380.8173
V Predictions Mean           1157.9858
V Predictions Std            349.60855
V Predictions Max            1771.3251
V Predictions Min            392.5477
Log Pis Mean                 0.60312486
Log Pis Std                  3.2147062
Log Pis Max                  12.4890585
Log Pis Min                  -6.521179
Policy mu Mean               -0.021401266
Policy mu Std                0.6966776
Policy mu Max                2.4817746
Policy mu Min                -3.5243871
Policy log std Mean          -0.9773704
Policy log std Std           0.30267584
Policy log std Max           -0.1979444
Policy log std Min           -2.3632288
Z mean eval                  0.8832741
Z variance eval              0.011963798
total_rewards                [3773.16854547  647.42646997 2093.84815989 3488.35258775 2079.14769426
 4438.90140929  173.2950934  1375.12276667  276.78866008 4599.37441295]
total_rewards_mean           2294.5425799730774
total_rewards_std            1604.3086021152894
total_rewards_max            4599.374412947117
total_rewards_min            173.29509340208278
Number of train steps total  1340000
Number of env steps total    2063472
Number of rollouts total     0
Train Time (s)               146.93631789414212
(Previous) Eval Time (s)     15.524911739863455
Sample Time (s)              7.182041538413614
Epoch Time (s)               169.6432711724192
Total Train Time (s)         56433.8809567811
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:01:11.120684 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #334 | Epoch Duration: 169.73289465904236
2020-01-12 00:01:11.120869 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88501275
Z variance train             0.011992437
KL Divergence                21.350977
KL Loss                      2.1350977
QF Loss                      421.91785
VF Loss                      162.32248
Policy Loss                  -1217.8923
Q Predictions Mean           1209.26
Q Predictions Std            347.44785
Q Predictions Max            1807.0702
Q Predictions Min            371.6218
V Predictions Mean           1208.2251
V Predictions Std            344.91937
V Predictions Max            1778.6526
V Predictions Min            366.17145
Log Pis Mean                 0.5435771
Log Pis Std                  2.755996
Log Pis Max                  11.609392
Log Pis Min                  -6.31339
Policy mu Mean               -0.013037108
Policy mu Std                0.66888994
Policy mu Max                2.4184961
Policy mu Min                -2.2450724
Policy log std Mean          -0.9706821
Policy log std Std           0.27033326
Policy log std Max           -0.24424231
Policy log std Min           -2.1765437
Z mean eval                  0.878026
Z variance eval              0.030809289
total_rewards                [3737.80100248  858.80057602 1326.78360576 3249.07670731    7.02429273
 4632.42417641 4658.93632599 2955.13063746 1466.53973747 3754.56212336]
total_rewards_mean           2664.7079184988806
total_rewards_std            1554.4847842799318
total_rewards_max            4658.936325987293
total_rewards_min            7.024292730351411
Number of train steps total  1344000
Number of env steps total    2075344
Number of rollouts total     0
Train Time (s)               145.76593072433025
(Previous) Eval Time (s)     20.9531925288029
Sample Time (s)              8.45602976018563
Epoch Time (s)               175.17515301331878
Total Train Time (s)         56609.14342043409
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:04:06.385281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #335 | Epoch Duration: 175.26428890228271
2020-01-12 00:04:06.385417 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8852866
Z variance train             0.030800337
KL Divergence                18.934666
KL Loss                      1.8934666
QF Loss                      3102.005
VF Loss                      106.21297
Policy Loss                  -1133.0221
Q Predictions Mean           1124.1702
Q Predictions Std            379.49826
Q Predictions Max            1776.6082
Q Predictions Min            314.35367
V Predictions Mean           1129.543
V Predictions Std            373.33423
V Predictions Max            1760.8755
V Predictions Min            384.02713
Log Pis Mean                 0.110610165
Log Pis Std                  3.0609756
Log Pis Max                  10.596675
Log Pis Min                  -7.0507708
Policy mu Mean               0.050190702
Policy mu Std                0.63607115
Policy mu Max                2.6599298
Policy mu Min                -3.5411494
Policy log std Mean          -0.9358233
Policy log std Std           0.28111917
Policy log std Max           0.10281432
Policy log std Min           -2.2617574
Z mean eval                  1.2030725
Z variance eval              0.0300376
total_rewards                [1691.70013592 1056.58557315 2651.00531211  963.14230743 1577.00386466
 2650.44990935  739.05655107 1223.24699622 2215.08919775   57.23924681]
total_rewards_mean           1482.4519094468446
total_rewards_std            801.3312829380579
total_rewards_max            2651.0053121091446
total_rewards_min            57.23924681380505
Number of train steps total  1348000
Number of env steps total    2086516
Number of rollouts total     0
Train Time (s)               145.58664253586903
(Previous) Eval Time (s)     12.12291733827442
Sample Time (s)              6.924528729636222
Epoch Time (s)               164.63408860377967
Total Train Time (s)         56773.865404771175
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:06:51.111819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #336 | Epoch Duration: 164.72628712654114
2020-01-12 00:06:51.111993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.201483
Z variance train             0.029940521
KL Divergence                19.653204
KL Loss                      1.9653205
QF Loss                      763.17847
VF Loss                      265.4216
Policy Loss                  -1132.8431
Q Predictions Mean           1127.7393
Q Predictions Std            388.826
Q Predictions Max            1754.924
Q Predictions Min            -53.5899
V Predictions Mean           1125.1499
V Predictions Std            386.84583
V Predictions Max            1756.9028
V Predictions Min            23.07779
Log Pis Mean                 0.4364574
Log Pis Std                  3.4328578
Log Pis Max                  19.663292
Log Pis Min                  -7.779198
Policy mu Mean               0.026880832
Policy mu Std                0.63447756
Policy mu Max                2.576042
Policy mu Min                -3.3860486
Policy log std Mean          -0.9837197
Policy log std Std           0.34845805
Policy log std Max           -0.26544523
Policy log std Min           -4.3668838
Z mean eval                  0.8579667
Z variance eval              0.06074942
total_rewards                [2260.23050656 4717.50134784 2698.38885251 4682.63898251 4860.12232719
 1889.14094649 1546.86879935 4024.47294946 4182.5205827  4415.94304602]
total_rewards_mean           3527.78283406253
total_rewards_std            1220.3365712435884
total_rewards_max            4860.122327188052
total_rewards_min            1546.8687993455706
Number of train steps total  1352000
Number of env steps total    2097444
Number of rollouts total     0
Train Time (s)               146.0694644539617
(Previous) Eval Time (s)     17.516963745933026
Sample Time (s)              7.289663682691753
Epoch Time (s)               170.87609188258648
Total Train Time (s)         56944.82501091994
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:09:42.073399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #337 | Epoch Duration: 170.96128034591675
2020-01-12 00:09:42.073534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85700977
Z variance train             0.060599536
KL Divergence                17.453232
KL Loss                      1.7453232
QF Loss                      779.14417
VF Loss                      109.4717
Policy Loss                  -1184.4596
Q Predictions Mean           1177.1138
Q Predictions Std            335.57782
Q Predictions Max            1736.1039
Q Predictions Min            364.97214
V Predictions Mean           1184.2051
V Predictions Std            335.79562
V Predictions Max            1735.8866
V Predictions Min            371.2045
Log Pis Mean                 0.35938263
Log Pis Std                  3.1021826
Log Pis Max                  10.536713
Log Pis Min                  -9.612883
Policy mu Mean               -8.389191e-05
Policy mu Std                0.63096887
Policy mu Max                2.0327194
Policy mu Min                -2.3753705
Policy log std Mean          -1.0139048
Policy log std Std           0.29533502
Policy log std Max           -0.25331837
Policy log std Min           -2.2448573
Z mean eval                  0.7745789
Z variance eval              0.015214831
total_rewards                [4327.46192504 1680.05035599 4202.37408695 2169.6072025  4310.59131147
  948.37069556 4562.65645752   29.9475791  2320.91688821 4361.12581252]
total_rewards_mean           2891.3102314854345
total_rewards_std            1581.938669365955
total_rewards_max            4562.656457517129
total_rewards_min            29.947579101889534
Number of train steps total  1356000
Number of env steps total    2107805
Number of rollouts total     0
Train Time (s)               147.31582065066323
(Previous) Eval Time (s)     16.91281518433243
Sample Time (s)              6.409549590200186
Epoch Time (s)               170.63818542519584
Total Train Time (s)         57115.56227524951
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:12:32.816382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #338 | Epoch Duration: 170.74271965026855
2020-01-12 00:12:32.816609 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77412385
Z variance train             0.015261541
KL Divergence                19.340652
KL Loss                      1.9340652
QF Loss                      1079.5549
VF Loss                      263.2934
Policy Loss                  -1164.5032
Q Predictions Mean           1157.943
Q Predictions Std            379.12726
Q Predictions Max            1800.9005
Q Predictions Min            362.74484
V Predictions Mean           1156.3025
V Predictions Std            375.9773
V Predictions Max            1791.8578
V Predictions Min            356.71487
Log Pis Mean                 0.3356163
Log Pis Std                  3.347885
Log Pis Max                  14.155209
Log Pis Min                  -6.6674914
Policy mu Mean               0.05192075
Policy mu Std                0.65422046
Policy mu Max                2.8664513
Policy mu Min                -3.0258143
Policy log std Mean          -0.9841486
Policy log std Std           0.30385107
Policy log std Max           -0.16019201
Policy log std Min           -2.516805
Z mean eval                  0.8275207
Z variance eval              0.015241469
total_rewards                [4183.35129434 2080.56714646 4544.57338056 4027.07720688 1506.28322315
 4508.3967107  4359.67343217  638.23869805 4526.68632395 4826.32451513]
total_rewards_mean           3520.1171931391027
total_rewards_std            1434.5857845014236
total_rewards_max            4826.324515131429
total_rewards_min            638.2386980494177
Number of train steps total  1360000
Number of env steps total    2118367
Number of rollouts total     0
Train Time (s)               147.14156302902848
(Previous) Eval Time (s)     19.33837390411645
Sample Time (s)              6.763312291819602
Epoch Time (s)               173.24324922496453
Total Train Time (s)         57288.89289236022
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:15:26.150073 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #339 | Epoch Duration: 173.33330297470093
2020-01-12 00:15:26.150215 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8296939
Z variance train             0.015245144
KL Divergence                19.69871
KL Loss                      1.9698709
QF Loss                      761.8573
VF Loss                      77.483315
Policy Loss                  -1152.9342
Q Predictions Mean           1147.2207
Q Predictions Std            377.91006
Q Predictions Max            1754.643
Q Predictions Min            365.98734
V Predictions Mean           1149.0826
V Predictions Std            378.29105
V Predictions Max            1737.3022
V Predictions Min            372.2701
Log Pis Mean                 0.35326508
Log Pis Std                  3.2061584
Log Pis Max                  11.161019
Log Pis Min                  -9.869419
Policy mu Mean               0.037992835
Policy mu Std                0.64773285
Policy mu Max                2.2199464
Policy mu Min                -2.5918574
Policy log std Mean          -0.9927501
Policy log std Std           0.3004231
Policy log std Max           -0.24593729
Policy log std Min           -2.3898423
Z mean eval                  1.0518869
Z variance eval              0.014451268
total_rewards                [ 799.38577218 2263.06813216  431.42941649 4162.2359842  2117.87013691
  841.69954067 3626.39435113 3553.07584293 3798.71747829 4395.23781795]
total_rewards_mean           2598.9114472907995
total_rewards_std            1429.8501155674269
total_rewards_max            4395.237817953042
total_rewards_min            431.4294164898539
Number of train steps total  1364000
Number of env steps total    2129154
Number of rollouts total     0
Train Time (s)               148.73900257702917
(Previous) Eval Time (s)     16.19365428108722
Sample Time (s)              7.233699174597859
Epoch Time (s)               172.16635603271425
Total Train Time (s)         57461.14436163055
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:18:18.405241 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #340 | Epoch Duration: 172.25491166114807
2020-01-12 00:18:18.405420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0486189
Z variance train             0.014387804
KL Divergence                20.706299
KL Loss                      2.0706298
QF Loss                      876.34326
VF Loss                      636.973
Policy Loss                  -1197.0018
Q Predictions Mean           1186.7812
Q Predictions Std            375.29572
Q Predictions Max            1763.5209
Q Predictions Min            -1.4505906
V Predictions Mean           1190.418
V Predictions Std            372.7187
V Predictions Max            1756.5496
V Predictions Min            218.62743
Log Pis Mean                 0.9240529
Log Pis Std                  3.6681082
Log Pis Max                  25.206884
Log Pis Min                  -8.781702
Policy mu Mean               -0.09620677
Policy mu Std                0.7132138
Policy mu Max                2.944569
Policy mu Min                -4.169911
Policy log std Mean          -1.0158788
Policy log std Std           0.30525672
Policy log std Max           -0.22207999
Policy log std Min           -2.7541375
Z mean eval                  0.8605564
Z variance eval              0.009854101
total_rewards                [4220.14374882 1808.72573467 4870.32364044   98.01070964 4737.90831408
 1795.66037325 4884.09643377 2431.33581567   38.82753795 2923.88171736]
total_rewards_mean           2780.891402563811
total_rewards_std            1773.8586652720805
total_rewards_max            4884.096433769937
total_rewards_min            38.82753794816068
Number of train steps total  1368000
Number of env steps total    2138881
Number of rollouts total     0
Train Time (s)               146.54965856065974
(Previous) Eval Time (s)     14.757382126990706
Sample Time (s)              7.035609394777566
Epoch Time (s)               168.342650082428
Total Train Time (s)         57629.571093541104
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:21:06.834173 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #341 | Epoch Duration: 168.42862749099731
2020-01-12 00:21:06.834316 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8656378
Z variance train             0.009841555
KL Divergence                20.622484
KL Loss                      2.0622485
QF Loss                      575.19714
VF Loss                      103.50422
Policy Loss                  -1188.9308
Q Predictions Mean           1183.5732
Q Predictions Std            366.90344
Q Predictions Max            1785.4689
Q Predictions Min            353.11368
V Predictions Mean           1188.6643
V Predictions Std            363.38196
V Predictions Max            1782.3552
V Predictions Min            356.74194
Log Pis Mean                 0.41610828
Log Pis Std                  3.0185797
Log Pis Max                  17.980957
Log Pis Min                  -14.089735
Policy mu Mean               -0.0021124794
Policy mu Std                0.6485228
Policy mu Max                2.2621634
Policy mu Min                -2.466523
Policy log std Mean          -1.0148894
Policy log std Std           0.2840742
Policy log std Max           -0.2550658
Policy log std Min           -2.4856758
Z mean eval                  0.7947877
Z variance eval              0.0070349225
total_rewards                [3089.90103926 4831.69034208 2614.707769   4654.87981096 4726.24243289
 4448.71672918 4907.38199707 5066.93253301 4850.68447164  350.75543376]
total_rewards_mean           3954.1892558850695
total_rewards_std            1434.5039804833714
total_rewards_max            5066.932533005276
total_rewards_min            350.7554337597216
Number of train steps total  1372000
Number of env steps total    2150418
Number of rollouts total     0
Train Time (s)               150.09449787205085
(Previous) Eval Time (s)     19.20082108490169
Sample Time (s)              7.162753284908831
Epoch Time (s)               176.45807224186137
Total Train Time (s)         57806.122397014406
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:24:03.392236 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #342 | Epoch Duration: 176.55775928497314
2020-01-12 00:24:03.392525 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79314935
Z variance train             0.0070457743
KL Divergence                20.350035
KL Loss                      2.0350034
QF Loss                      589.59973
VF Loss                      132.80554
Policy Loss                  -1155.6733
Q Predictions Mean           1150.0659
Q Predictions Std            378.87802
Q Predictions Max            1801.3458
Q Predictions Min            356.10345
V Predictions Mean           1162.374
V Predictions Std            378.28564
V Predictions Max            1790.1526
V Predictions Min            357.92667
Log Pis Mean                 0.22964352
Log Pis Std                  3.0244186
Log Pis Max                  13.731737
Log Pis Min                  -8.45373
Policy mu Mean               -0.008949212
Policy mu Std                0.6361093
Policy mu Max                2.8256927
Policy mu Min                -2.4776924
Policy log std Mean          -0.9910944
Policy log std Std           0.270682
Policy log std Max           -0.27829236
Policy log std Min           -2.331399
Z mean eval                  0.781846
Z variance eval              0.007819963
total_rewards                [ 189.35841771 4634.72803826 1472.92081255 4594.0048505  4833.70505852
 4455.02421155 4723.4458513  4456.2620288  1920.00533984 3323.08415444]
total_rewards_mean           3460.2538763474477
total_rewards_std            1586.4373324512144
total_rewards_max            4833.705058520491
total_rewards_min            189.35841770839417
Number of train steps total  1376000
Number of env steps total    2160822
Number of rollouts total     0
Train Time (s)               145.38466403400525
(Previous) Eval Time (s)     17.86054772976786
Sample Time (s)              6.641034216154367
Epoch Time (s)               169.88624597992748
Total Train Time (s)         57976.09285411937
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:26:53.365055 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #343 | Epoch Duration: 169.9723358154297
2020-01-12 00:26:53.365201 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.785807
Z variance train             0.007867673
KL Divergence                20.617998
KL Loss                      2.0617998
QF Loss                      10087.098
VF Loss                      95.08764
Policy Loss                  -1205.049
Q Predictions Mean           1201.4524
Q Predictions Std            370.55536
Q Predictions Max            1784.6522
Q Predictions Min            343.7836
V Predictions Mean           1206.1855
V Predictions Std            371.41318
V Predictions Max            1784.7098
V Predictions Min            332.85468
Log Pis Mean                 0.36736166
Log Pis Std                  3.1035948
Log Pis Max                  11.22212
Log Pis Min                  -8.969408
Policy mu Mean               -0.0055273334
Policy mu Std                0.657621
Policy mu Max                2.1029916
Policy mu Min                -2.167325
Policy log std Mean          -0.9939595
Policy log std Std           0.3056148
Policy log std Max           -0.29287267
Policy log std Min           -2.4609356
Z mean eval                  1.1104783
Z variance eval              0.0044197687
total_rewards                [4784.71216666 3848.09008224 3583.64267729 3447.63220455 4607.30525645
 4715.71469157 1544.95939488 2011.68548825  642.01842618  653.58944529]
total_rewards_mean           2983.934983336613
total_rewards_std            1553.3712448677034
total_rewards_max            4784.712166663672
total_rewards_min            642.0184261848646
Number of train steps total  1380000
Number of env steps total    2171732
Number of rollouts total     0
Train Time (s)               145.80378750804812
(Previous) Eval Time (s)     15.365430916193873
Sample Time (s)              6.805514784064144
Epoch Time (s)               167.97473320830613
Total Train Time (s)         58144.157686454244
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:29:41.435104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #344 | Epoch Duration: 168.0697886943817
2020-01-12 00:29:41.435291 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1051219
Z variance train             0.0044188453
KL Divergence                22.432163
KL Loss                      2.2432163
QF Loss                      493.0785
VF Loss                      87.25375
Policy Loss                  -1213.6759
Q Predictions Mean           1207.2296
Q Predictions Std            365.83936
Q Predictions Max            1776.547
Q Predictions Min            316.22455
V Predictions Mean           1208.7297
V Predictions Std            366.21213
V Predictions Max            1759.1311
V Predictions Min            314.50134
Log Pis Mean                 0.73971313
Log Pis Std                  2.7799184
Log Pis Max                  9.733143
Log Pis Min                  -6.179607
Policy mu Mean               0.055143423
Policy mu Std                0.6581439
Policy mu Max                2.9831538
Policy mu Min                -2.4524066
Policy log std Mean          -1.0132117
Policy log std Std           0.26747602
Policy log std Max           -0.17965972
Policy log std Min           -2.1541843
Z mean eval                  0.69227487
Z variance eval              0.006309843
total_rewards                [ 484.50435959 2906.19417637   42.85565825  107.90067425 2472.10970069
 3512.60631556  205.63957849 2660.75339499   96.19761369  341.86856604]
total_rewards_mean           1283.063003790454
total_rewards_std            1339.0084157339522
total_rewards_max            3512.6063155553466
total_rewards_min            42.85565824535088
Number of train steps total  1384000
Number of env steps total    2183732
Number of rollouts total     0
Train Time (s)               146.71021055569872
(Previous) Eval Time (s)     6.289163914043456
Sample Time (s)              7.136965253856033
Epoch Time (s)               160.1363397235982
Total Train Time (s)         58304.383126396686
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:32:21.669119 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #345 | Epoch Duration: 160.23365807533264
2020-01-12 00:32:21.669420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6904358
Z variance train             0.006327614
KL Divergence                21.043703
KL Loss                      2.1043704
QF Loss                      1415.3394
VF Loss                      157.84447
Policy Loss                  -1215.8768
Q Predictions Mean           1211.812
Q Predictions Std            398.89673
Q Predictions Max            1819.6683
Q Predictions Min            351.7279
V Predictions Mean           1223.8666
V Predictions Std            398.47968
V Predictions Max            1840.5402
V Predictions Min            370.35968
Log Pis Mean                 0.31118238
Log Pis Std                  3.3414762
Log Pis Max                  11.354091
Log Pis Min                  -7.2862225
Policy mu Mean               -0.025794066
Policy mu Std                0.6656714
Policy mu Max                2.631468
Policy mu Min                -2.7998095
Policy log std Mean          -1.0069661
Policy log std Std           0.3284527
Policy log std Max           -0.24941039
Policy log std Min           -2.487647
Z mean eval                  0.7189653
Z variance eval              0.0096107265
total_rewards                [4641.28727314 4735.70554857 1279.32650773 4952.50079113 4757.98096222
 4782.35700276 4808.85970463 4763.9151435   788.04195684 4797.61733091]
total_rewards_mean           4030.7592221447267
total_rewards_std            1504.3164094288675
total_rewards_max            4952.50079113356
total_rewards_min            788.0419568415092
Number of train steps total  1388000
Number of env steps total    2193364
Number of rollouts total     0
Train Time (s)               148.66670306911692
(Previous) Eval Time (s)     20.487687902059406
Sample Time (s)              7.534273363184184
Epoch Time (s)               176.6886643343605
Total Train Time (s)         58481.16358675202
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:35:18.450503 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #346 | Epoch Duration: 176.7808701992035
2020-01-12 00:35:18.450656 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7121069
Z variance train             0.009623617
KL Divergence                20.151142
KL Loss                      2.0151143
QF Loss                      1933.2607
VF Loss                      204.86838
Policy Loss                  -1188.9576
Q Predictions Mean           1184.4056
Q Predictions Std            366.7068
Q Predictions Max            1737.1343
Q Predictions Min            357.00055
V Predictions Mean           1195.5942
V Predictions Std            367.17795
V Predictions Max            1739.7577
V Predictions Min            361.75443
Log Pis Mean                 0.4805575
Log Pis Std                  3.0485437
Log Pis Max                  11.724588
Log Pis Min                  -6.554317
Policy mu Mean               0.007321927
Policy mu Std                0.6546408
Policy mu Max                2.071593
Policy mu Min                -2.2961068
Policy log std Mean          -1.0110993
Policy log std Std           0.28994384
Policy log std Max           -0.2958355
Policy log std Min           -2.472105
Z mean eval                  0.7961201
Z variance eval              0.008659029
total_rewards                [4372.2501412  3086.7713451  1932.34203869 4478.24886217 3964.09306714
  983.13740781  183.1856367  4862.91413621 4829.02701225 2248.78470586]
total_rewards_mean           3094.0754353134607
total_rewards_std            1594.9601150386538
total_rewards_max            4862.91413620645
total_rewards_min            183.18563670298795
Number of train steps total  1392000
Number of env steps total    2205364
Number of rollouts total     0
Train Time (s)               146.64613626059145
(Previous) Eval Time (s)     16.028877512086183
Sample Time (s)              7.13362842798233
Epoch Time (s)               169.80864220065996
Total Train Time (s)         58651.06167791411
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:38:08.352539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #347 | Epoch Duration: 169.90176010131836
2020-01-12 00:38:08.352734 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7964935
Z variance train             0.008678497
KL Divergence                21.104599
KL Loss                      2.11046
QF Loss                      561.8111
VF Loss                      148.69293
Policy Loss                  -1193.8558
Q Predictions Mean           1184.158
Q Predictions Std            404.14114
Q Predictions Max            1800.7644
Q Predictions Min            -85.8404
V Predictions Mean           1194.804
V Predictions Std            396.67166
V Predictions Max            1799.6917
V Predictions Min            366.78723
Log Pis Mean                 0.43943754
Log Pis Std                  3.1982646
Log Pis Max                  10.919508
Log Pis Min                  -7.3434954
Policy mu Mean               0.068600126
Policy mu Std                0.6294259
Policy mu Max                2.600304
Policy mu Min                -2.7282374
Policy log std Mean          -1.0293331
Policy log std Std           0.31100893
Policy log std Max           -0.2532581
Policy log std Min           -2.372453
Z mean eval                  0.868752
Z variance eval              0.0043228865
total_rewards                [3518.51476455 4447.93022566 4564.16953    1034.2696875  4546.74136819
 1087.91976223  224.44738737 1707.01912501 4138.92537714  890.39358786]
total_rewards_mean           2616.033081549613
total_rewards_std            1684.4381053646032
total_rewards_max            4564.169529998683
total_rewards_min            224.44738736528257
Number of train steps total  1396000
Number of env steps total    2217447
Number of rollouts total     0
Train Time (s)               147.31049879593775
(Previous) Eval Time (s)     12.105296682100743
Sample Time (s)              7.471280115190893
Epoch Time (s)               166.88707559322938
Total Train Time (s)         58818.0374295013
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:40:55.333348 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #348 | Epoch Duration: 166.9804708957672
2020-01-12 00:40:55.333529 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8624355
Z variance train             0.0043186815
KL Divergence                22.08338
KL Loss                      2.208338
QF Loss                      434.78036
VF Loss                      102.517235
Policy Loss                  -1197.413
Q Predictions Mean           1194.7711
Q Predictions Std            402.96674
Q Predictions Max            1810.693
Q Predictions Min            345.16046
V Predictions Mean           1196.7153
V Predictions Std            402.16656
V Predictions Max            1801.3431
V Predictions Min            346.20435
Log Pis Mean                 0.051344126
Log Pis Std                  3.2243738
Log Pis Max                  12.044588
Log Pis Min                  -10.086383
Policy mu Mean               -0.007220291
Policy mu Std                0.62020874
Policy mu Max                2.0744908
Policy mu Min                -2.765799
Policy log std Mean          -0.99139947
Policy log std Std           0.28202432
Policy log std Max           -0.26075816
Policy log std Min           -2.4407074
Z mean eval                  0.81437606
Z variance eval              0.015987385
total_rewards                [4728.85240322 4845.26982652 2925.47619037 4616.03354489 4718.06781673
 5042.3642378  4966.89178222  -31.30274761 4557.05139097 4627.19016063]
total_rewards_mean           4099.589460573863
total_rewards_std            1489.0508705022016
total_rewards_max            5042.36423779506
total_rewards_min            -31.30274760683555
Number of train steps total  1400000
Number of env steps total    2229052
Number of rollouts total     0
Train Time (s)               147.15054362500086
(Previous) Eval Time (s)     20.550031268037856
Sample Time (s)              7.534005630761385
Epoch Time (s)               175.2345805238001
Total Train Time (s)         58993.36074822908
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:43:50.660560 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #349 | Epoch Duration: 175.32689499855042
2020-01-12 00:43:50.660743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81151164
Z variance train             0.016316589
KL Divergence                18.681093
KL Loss                      1.8681093
QF Loss                      690.22754
VF Loss                      229.49907
Policy Loss                  -1204.9528
Q Predictions Mean           1199.1675
Q Predictions Std            377.5673
Q Predictions Max            1777.367
Q Predictions Min            262.6304
V Predictions Mean           1209.7583
V Predictions Std            376.2929
V Predictions Max            1786.8989
V Predictions Min            292.88516
Log Pis Mean                 0.6651711
Log Pis Std                  3.1540534
Log Pis Max                  13.108055
Log Pis Min                  -6.9948215
Policy mu Mean               0.036536068
Policy mu Std                0.65290093
Policy mu Max                2.9268847
Policy mu Min                -2.259869
Policy log std Mean          -1.0293585
Policy log std Std           0.32057568
Policy log std Max           -0.083207846
Policy log std Min           -3.0154605
Z mean eval                  0.84709835
Z variance eval              0.011538526
total_rewards                [4903.37626528 4236.7380827  3558.94266929 4708.14148318 4680.54281521
 4847.10300883  398.0006179  4665.10356342 2196.01640795  726.51580437]
total_rewards_mean           3492.0480718140534
total_rewards_std            1659.9854764790098
total_rewards_max            4903.376265276403
total_rewards_min            398.0006178960972
Number of train steps total  1404000
Number of env steps total    2238068
Number of rollouts total     0
Train Time (s)               145.61300478409976
(Previous) Eval Time (s)     15.997023827861995
Sample Time (s)              7.576132407411933
Epoch Time (s)               169.18616101937369
Total Train Time (s)         59162.643802545965
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:46:39.948301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #350 | Epoch Duration: 169.28741979599
2020-01-12 00:46:39.948488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84804994
Z variance train             0.011586519
KL Divergence                19.845524
KL Loss                      1.9845524
QF Loss                      1427.1172
VF Loss                      85.515045
Policy Loss                  -1265.4885
Q Predictions Mean           1256.7897
Q Predictions Std            396.22824
Q Predictions Max            1831.0911
Q Predictions Min            70.225746
V Predictions Mean           1265.1879
V Predictions Std            390.8123
V Predictions Max            1822.6115
V Predictions Min            370.54147
Log Pis Mean                 0.49639344
Log Pis Std                  3.1375537
Log Pis Max                  13.169416
Log Pis Min                  -9.400563
Policy mu Mean               0.029333469
Policy mu Std                0.65214574
Policy mu Max                2.1068017
Policy mu Min                -2.9683683
Policy log std Mean          -1.0418382
Policy log std Std           0.3029545
Policy log std Max           -0.28248358
Policy log std Min           -2.3246841
Z mean eval                  0.72915363
Z variance eval              0.016176125
total_rewards                [ 880.61153653  668.83625397 2447.98273775  378.17053714 1912.89218757
 1512.27705839  397.9510443  2081.71393118  637.11920262   94.53328165]
total_rewards_mean           1101.2087771102854
total_rewards_std            780.0472493238664
total_rewards_max            2447.982737752602
total_rewards_min            94.53328164825862
Number of train steps total  1408000
Number of env steps total    2248329
Number of rollouts total     0
Train Time (s)               148.50059083569795
(Previous) Eval Time (s)     8.088789233006537
Sample Time (s)              8.259154424536973
Epoch Time (s)               164.84853449324146
Total Train Time (s)         59327.58715402987
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:49:24.894858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #351 | Epoch Duration: 164.9461648464203
2020-01-12 00:49:24.895209 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #351 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72741413
Z variance train             0.016185503
KL Divergence                20.975178
KL Loss                      2.0975177
QF Loss                      12783.348
VF Loss                      265.26224
Policy Loss                  -1214.0287
Q Predictions Mean           1207.5698
Q Predictions Std            403.08374
Q Predictions Max            1819.5194
Q Predictions Min            170.26314
V Predictions Mean           1217.6853
V Predictions Std            398.85703
V Predictions Max            1813.5264
V Predictions Min            333.30188
Log Pis Mean                 0.56937927
Log Pis Std                  3.0086777
Log Pis Max                  10.473054
Log Pis Min                  -7.904763
Policy mu Mean               -0.004578448
Policy mu Std                0.6713352
Policy mu Max                3.2698448
Policy mu Min                -2.4029582
Policy log std Mean          -0.99915516
Policy log std Std           0.28222597
Policy log std Max           -0.18379259
Policy log std Min           -2.2346587
Z mean eval                  0.7104204
Z variance eval              0.009724943
total_rewards                [ 952.98561475 4640.12912874 4683.69090314 2045.06199721 4781.9655727
 2466.73938985 4394.89273141  560.74371953 3391.18015914 1340.49922118]
total_rewards_mean           2925.7888437640363
total_rewards_std            1575.8924458260246
total_rewards_max            4781.96557270133
total_rewards_min            560.7437195296076
Number of train steps total  1412000
Number of env steps total    2260217
Number of rollouts total     0
Train Time (s)               144.75988972187042
(Previous) Eval Time (s)     15.083329332061112
Sample Time (s)              7.662995295599103
Epoch Time (s)               167.50621434953064
Total Train Time (s)         59495.47169443406
Epoch                        352
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:52:12.782725 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #352 | Epoch Duration: 167.88730430603027
2020-01-12 00:52:12.782917 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7155746
Z variance train             0.0097011095
KL Divergence                19.913094
KL Loss                      1.9913094
QF Loss                      2623.8628
VF Loss                      91.43964
Policy Loss                  -1260.1654
Q Predictions Mean           1251.0718
Q Predictions Std            399.88263
Q Predictions Max            1842.284
Q Predictions Min            108.82054
V Predictions Mean           1256.1254
V Predictions Std            397.28937
V Predictions Max            1809.869
V Predictions Min            209.15915
Log Pis Mean                 0.8976985
Log Pis Std                  3.4542985
Log Pis Max                  13.899317
Log Pis Min                  -8.24123
Policy mu Mean               0.023877852
Policy mu Std                0.6557392
Policy mu Max                2.7437944
Policy mu Min                -4.3778224
Policy log std Mean          -1.0662171
Policy log std Std           0.32776922
Policy log std Max           -0.18527901
Policy log std Min           -2.4231353
Z mean eval                  0.8380555
Z variance eval              0.0075451345
total_rewards                [4977.04799529  540.74871218 2618.79352994 5056.08969687 4800.41918606
 3944.53883669 4894.69087609 1368.55687083  663.10867481 4527.64120527]
total_rewards_mean           3339.163558403468
total_rewards_std            1770.8475787079935
total_rewards_max            5056.089696869296
total_rewards_min            540.7487121835685
Number of train steps total  1416000
Number of env steps total    2271492
Number of rollouts total     0
Train Time (s)               147.8868845421821
(Previous) Eval Time (s)     18.28835282707587
Sample Time (s)              7.601177999284118
Epoch Time (s)               173.77641536854208
Total Train Time (s)         59669.41332519753
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:55:06.730719 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #353 | Epoch Duration: 173.94760751724243
2020-01-12 00:55:06.730986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8353798
Z variance train             0.007539963
KL Divergence                19.85494
KL Loss                      1.985494
QF Loss                      419.6316
VF Loss                      99.72792
Policy Loss                  -1174.8425
Q Predictions Mean           1170.8562
Q Predictions Std            416.39566
Q Predictions Max            1795.3467
Q Predictions Min            320.17804
V Predictions Mean           1179.5474
V Predictions Std            416.7333
V Predictions Max            1785.7561
V Predictions Min            314.98663
Log Pis Mean                 0.33344492
Log Pis Std                  2.8200796
Log Pis Max                  10.096947
Log Pis Min                  -7.334688
Policy mu Mean               0.02696227
Policy mu Std                0.60690475
Policy mu Max                2.3485126
Policy mu Min                -2.242031
Policy log std Mean          -1.0192578
Policy log std Std           0.27908292
Policy log std Max           -0.35403562
Policy log std Min           -2.130613
Z mean eval                  1.0628748
Z variance eval              0.026267573
total_rewards                [3161.77611085 1201.60529    1796.36920688 4701.8361606    29.90542162
 4749.66156038  418.17823332 2995.18069618 4760.49773279 4628.36271683]
total_rewards_mean           2844.3373129445536
total_rewards_std            1779.3982514032775
total_rewards_max            4760.497732788144
total_rewards_min            29.905421617520556
Number of train steps total  1420000
Number of env steps total    2282376
Number of rollouts total     0
Train Time (s)               147.34125082427636
(Previous) Eval Time (s)     14.491617104969919
Sample Time (s)              6.637808640487492
Epoch Time (s)               168.47067656973377
Total Train Time (s)         59837.99421269167
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 00:57:55.313780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #354 | Epoch Duration: 168.58264756202698
2020-01-12 00:57:55.313967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0601591
Z variance train             0.026688779
KL Divergence                21.086824
KL Loss                      2.1086824
QF Loss                      444.78336
VF Loss                      103.27963
Policy Loss                  -1260.2672
Q Predictions Mean           1255.485
Q Predictions Std            413.1634
Q Predictions Max            1852.4792
Q Predictions Min            344.0437
V Predictions Mean           1265.475
V Predictions Std            409.66083
V Predictions Max            1851.6788
V Predictions Min            370.33997
Log Pis Mean                 0.44180232
Log Pis Std                  3.1002672
Log Pis Max                  11.782956
Log Pis Min                  -6.31938
Policy mu Mean               0.011864728
Policy mu Std                0.6329826
Policy mu Max                2.2430658
Policy mu Min                -2.5524306
Policy log std Mean          -1.0265965
Policy log std Std           0.290979
Policy log std Max           -0.31844968
Policy log std Min           -2.435605
Z mean eval                  0.8176945
Z variance eval              0.010254879
total_rewards                [4769.90896421 2159.41724334 2243.27011756  514.41780108 4927.55994194
 4550.83630228 3435.36884393 4779.53853071  430.79444977 4658.50761373]
total_rewards_mean           3246.9619808538905
total_rewards_std            1697.3026406024148
total_rewards_max            4927.559941942083
total_rewards_min            430.7944497724775
Number of train steps total  1424000
Number of env steps total    2292575
Number of rollouts total     0
Train Time (s)               146.57912730798125
(Previous) Eval Time (s)     16.749800668098032
Sample Time (s)              7.011990837752819
Epoch Time (s)               170.3409188138321
Total Train Time (s)         60008.42266753223
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:00:45.745702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #355 | Epoch Duration: 170.4315960407257
2020-01-12 01:00:45.745856 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #355 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8173169
Z variance train             0.01026914
KL Divergence                20.7769
KL Loss                      2.07769
QF Loss                      726.81384
VF Loss                      79.56623
Policy Loss                  -1280.4231
Q Predictions Mean           1274.2985
Q Predictions Std            391.8367
Q Predictions Max            1874.639
Q Predictions Min            353.134
V Predictions Mean           1279.3823
V Predictions Std            391.23984
V Predictions Max            1887.7836
V Predictions Min            354.22366
Log Pis Mean                 0.4676776
Log Pis Std                  3.0215554
Log Pis Max                  15.077216
Log Pis Min                  -6.151383
Policy mu Mean               -0.012491744
Policy mu Std                0.6546099
Policy mu Max                3.4298859
Policy mu Min                -2.9539366
Policy log std Mean          -1.0201483
Policy log std Std           0.30234545
Policy log std Max           -0.2370807
Policy log std Min           -2.5772648
Z mean eval                  0.81978875
Z variance eval              0.025946358
total_rewards                [5129.4901497  1567.99987607 4994.23299415 4901.25098315 4979.7432718
 5091.13166911 5039.05565898 4805.40349245 1951.17584176 4740.06620274]
total_rewards_mean           4319.955013991937
total_rewards_std            1288.08261126749
total_rewards_max            5129.490149698948
total_rewards_min            1567.9998760698397
Number of train steps total  1428000
Number of env steps total    2302996
Number of rollouts total     0
Train Time (s)               146.75400393409654
(Previous) Eval Time (s)     21.35971216019243
Sample Time (s)              7.810678380075842
Epoch Time (s)               175.92439447436482
Total Train Time (s)         60184.44745798828
Epoch                        356
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:03:41.773198 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #356 | Epoch Duration: 176.02722811698914
2020-01-12 01:03:41.773345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8119354
Z variance train             0.026208043
KL Divergence                18.995491
KL Loss                      1.8995491
QF Loss                      1442.3534
VF Loss                      2059.4893
Policy Loss                  -1228.6837
Q Predictions Mean           1223.3344
Q Predictions Std            382.12988
Q Predictions Max            1852.8292
Q Predictions Min            339.94928
V Predictions Mean           1235.9939
V Predictions Std            380.88364
V Predictions Max            1864.118
V Predictions Min            354.4592
Log Pis Mean                 0.44947296
Log Pis Std                  3.245839
Log Pis Max                  10.986495
Log Pis Min                  -7.017172
Policy mu Mean               0.006341461
Policy mu Std                0.67443204
Policy mu Max                2.9840438
Policy mu Min                -2.5111606
Policy log std Mean          -1.0190961
Policy log std Std           0.29541114
Policy log std Max           -0.29431462
Policy log std Min           -2.3048816
Z mean eval                  0.94102114
Z variance eval              0.015682044
total_rewards                [4336.63049572 4188.55565859 2046.71412061 3959.07998707 4471.94566251
   29.81025916 4548.56766745 1072.89935685 2995.36034442 4159.43487124]
total_rewards_mean           3180.8998423619296
total_rewards_std            1521.358836106271
total_rewards_max            4548.567667446387
total_rewards_min            29.810259159296454
Number of train steps total  1432000
Number of env steps total    2311192
Number of rollouts total     0
Train Time (s)               146.55415153875947
(Previous) Eval Time (s)     19.938137784134597
Sample Time (s)              7.0150096118450165
Epoch Time (s)               173.50729893473908
Total Train Time (s)         60358.04343648534
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:06:35.371983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #357 | Epoch Duration: 173.5985312461853
2020-01-12 01:06:35.372126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9368477
Z variance train             0.015717108
KL Divergence                21.092924
KL Loss                      2.1092925
QF Loss                      702.8002
VF Loss                      93.465355
Policy Loss                  -1252.4467
Q Predictions Mean           1246.0167
Q Predictions Std            414.50684
Q Predictions Max            1840.7517
Q Predictions Min            347.67874
V Predictions Mean           1253.5522
V Predictions Std            414.60535
V Predictions Max            1840.7855
V Predictions Min            362.30673
Log Pis Mean                 0.6432882
Log Pis Std                  3.2054937
Log Pis Max                  11.848946
Log Pis Min                  -6.895895
Policy mu Mean               -0.036071494
Policy mu Std                0.6647908
Policy mu Max                2.5512981
Policy mu Min                -2.8661914
Policy log std Mean          -1.0224402
Policy log std Std           0.31878945
Policy log std Max           -0.157009
Policy log std Min           -2.3953643
Z mean eval                  0.82123244
Z variance eval              0.009617038
total_rewards                [4846.29400207 4607.98363374  511.15357595 4830.63086595 4877.35243846
 4749.42658559 5131.90751393 2044.10582387 4802.20245152 4767.0101721 ]
total_rewards_mean           4116.806706316272
total_rewards_std            1465.652554686146
total_rewards_max            5131.907513927825
total_rewards_min            511.15357595186435
Number of train steps total  1436000
Number of env steps total    2322428
Number of rollouts total     0
Train Time (s)               147.87216954864562
(Previous) Eval Time (s)     17.64730933587998
Sample Time (s)              7.957919913344085
Epoch Time (s)               173.47739879786968
Total Train Time (s)         60531.61665474996
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:09:28.950936 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #358 | Epoch Duration: 173.57869720458984
2020-01-12 01:09:28.951110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82054394
Z variance train             0.009612043
KL Divergence                19.97781
KL Loss                      1.997781
QF Loss                      490.8568
VF Loss                      88.5172
Policy Loss                  -1248.7632
Q Predictions Mean           1240.1793
Q Predictions Std            353.81512
Q Predictions Max            1815.9141
Q Predictions Min            334.72223
V Predictions Mean           1250.1921
V Predictions Std            354.41052
V Predictions Max            1805.9225
V Predictions Min            342.39957
Log Pis Mean                 0.91833407
Log Pis Std                  3.3590505
Log Pis Max                  12.250242
Log Pis Min                  -6.5835996
Policy mu Mean               0.061195917
Policy mu Std                0.69842774
Policy mu Max                2.6128833
Policy mu Min                -2.520661
Policy log std Mean          -1.0041671
Policy log std Std           0.30609426
Policy log std Max           -0.29528773
Policy log std Min           -2.2961302
Z mean eval                  0.8682722
Z variance eval              0.03305182
total_rewards                [4842.0219325  1047.99707157 3471.09253497 4520.088445   4818.49473338
 4743.81864551 4699.0882074  4762.74553517 1531.84007391 5121.12618961]
total_rewards_mean           3955.8313369014772
total_rewards_std            1399.8746674760623
total_rewards_max            5121.1261896147535
total_rewards_min            1047.9970715652732
Number of train steps total  1440000
Number of env steps total    2332842
Number of rollouts total     0
Train Time (s)               148.0082333148457
(Previous) Eval Time (s)     20.310661736875772
Sample Time (s)              7.199247779324651
Epoch Time (s)               175.51814283104613
Total Train Time (s)         60707.234896736685
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:12:24.575420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #359 | Epoch Duration: 175.62417483329773
2020-01-12 01:12:24.575568 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86727065
Z variance train             0.03308148
KL Divergence                17.672613
KL Loss                      1.7672614
QF Loss                      663.0005
VF Loss                      100.6379
Policy Loss                  -1242.2074
Q Predictions Mean           1233.9143
Q Predictions Std            389.36917
Q Predictions Max            1825.2069
Q Predictions Min            334.01913
V Predictions Mean           1239.5437
V Predictions Std            387.08038
V Predictions Max            1813.3877
V Predictions Min            343.2258
Log Pis Mean                 0.60622317
Log Pis Std                  3.2718656
Log Pis Max                  13.150175
Log Pis Min                  -8.1399555
Policy mu Mean               -0.004418103
Policy mu Std                0.6456485
Policy mu Max                2.5652912
Policy mu Min                -2.6671445
Policy log std Mean          -1.0384904
Policy log std Std           0.29975432
Policy log std Max           -0.2991352
Policy log std Min           -2.4019706
Z mean eval                  1.05607
Z variance eval              0.018468266
total_rewards                [4630.65692352 4700.67651051 4725.54101278  119.44404205 1458.13497834
 4764.77281213 2917.17966516 4572.39578999 4817.3660624  1789.55176094]
total_rewards_mean           3449.5719557816165
total_rewards_std            1659.649073477119
total_rewards_max            4817.366062403568
total_rewards_min            119.44404205035394
Number of train steps total  1444000
Number of env steps total    2342877
Number of rollouts total     0
Train Time (s)               147.51963291224092
(Previous) Eval Time (s)     18.084133984986693
Sample Time (s)              7.106908892747015
Epoch Time (s)               172.71067578997463
Total Train Time (s)         60880.03143783659
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:15:17.375823 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #360 | Epoch Duration: 172.80013799667358
2020-01-12 01:15:17.376017 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0525295
Z variance train             0.018513272
KL Divergence                18.736595
KL Loss                      1.8736595
QF Loss                      605.3694
VF Loss                      167.54184
Policy Loss                  -1201.5698
Q Predictions Mean           1195.834
Q Predictions Std            416.35135
Q Predictions Max            1794.4305
Q Predictions Min            295.5183
V Predictions Mean           1208.5995
V Predictions Std            415.79446
V Predictions Max            1808.0701
V Predictions Min            309.4735
Log Pis Mean                 0.5087544
Log Pis Std                  3.0233643
Log Pis Max                  9.781357
Log Pis Min                  -8.322241
Policy mu Mean               0.013991604
Policy mu Std                0.645799
Policy mu Max                1.8936138
Policy mu Min                -2.5430589
Policy log std Mean          -1.0061129
Policy log std Std           0.30590484
Policy log std Max           -0.27350318
Policy log std Min           -2.1364057
Z mean eval                  0.8741587
Z variance eval              0.0117382
total_rewards                [3848.47908782  935.92387032   28.48793941 1582.44630335 1335.18518164
 4674.28423963 1367.2368116  1329.85775055 4843.08130102 4645.2109579 ]
total_rewards_mean           2459.0193443240723
total_rewards_std            1732.826112973665
total_rewards_max            4843.081301023471
total_rewards_min            28.48793940837515
Number of train steps total  1448000
Number of env steps total    2352849
Number of rollouts total     0
Train Time (s)               147.63158975867555
(Previous) Eval Time (s)     14.46956318616867
Sample Time (s)              6.8624456617981195
Epoch Time (s)               168.96359860664234
Total Train Time (s)         61049.107815413736
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:18:06.455374 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #361 | Epoch Duration: 169.07920670509338
2020-01-12 01:18:06.455603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8734924
Z variance train             0.011820272
KL Divergence                20.823248
KL Loss                      2.0823247
QF Loss                      454.4291
VF Loss                      165.0368
Policy Loss                  -1247.9054
Q Predictions Mean           1238.4274
Q Predictions Std            406.7087
Q Predictions Max            1842.3197
Q Predictions Min            -120.030235
V Predictions Mean           1240.3485
V Predictions Std            407.7818
V Predictions Max            1848.8081
V Predictions Min            -21.138584
Log Pis Mean                 0.2792078
Log Pis Std                  3.6045198
Log Pis Max                  27.879375
Log Pis Min                  -7.730074
Policy mu Mean               0.01623575
Policy mu Std                0.66103524
Policy mu Max                2.750353
Policy mu Min                -4.6996245
Policy log std Mean          -1.0015057
Policy log std Std           0.29918775
Policy log std Max           -0.06940687
Policy log std Min           -2.7336516
Z mean eval                  0.7493123
Z variance eval              0.009734927
total_rewards                [1998.12686049 1439.91773867  570.58723112 1937.72464973 4997.87261734
  290.89459339 4685.78431244 4910.05444826 4039.88223738 1279.56869554]
total_rewards_mean           2615.0413384339954
total_rewards_std            1756.3687780097923
total_rewards_max            4997.872617339474
total_rewards_min            290.8945933863141
Number of train steps total  1452000
Number of env steps total    2362032
Number of rollouts total     0
Train Time (s)               146.17989639705047
(Previous) Eval Time (s)     13.412928679957986
Sample Time (s)              7.439627469982952
Epoch Time (s)               167.0324525469914
Total Train Time (s)         61216.23382338602
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:20:53.585626 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #362 | Epoch Duration: 167.1298544406891
2020-01-12 01:20:53.585808 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7515138
Z variance train             0.009756066
KL Divergence                21.225883
KL Loss                      2.1225884
QF Loss                      677.59454
VF Loss                      106.80152
Policy Loss                  -1246.539
Q Predictions Mean           1239.8732
Q Predictions Std            403.3569
Q Predictions Max            1843.4325
Q Predictions Min            319.52707
V Predictions Mean           1248.6555
V Predictions Std            400.8034
V Predictions Max            1852.3508
V Predictions Min            324.22293
Log Pis Mean                 0.5726246
Log Pis Std                  3.4054117
Log Pis Max                  21.560738
Log Pis Min                  -8.517424
Policy mu Mean               0.01085331
Policy mu Std                0.64329785
Policy mu Max                2.7616076
Policy mu Min                -3.0708277
Policy log std Mean          -1.0349512
Policy log std Std           0.2856676
Policy log std Max           0.0781399
Policy log std Min           -2.3200545
Z mean eval                  1.0754273
Z variance eval              0.0052718455
total_rewards                [  32.93742335 1325.43432257  626.54985195 4728.2621889   441.19755684
 4045.83079215 3049.59306797 4757.80883077 4548.96921547 3503.25605241]
total_rewards_mean           2705.9839302371097
total_rewards_std            1809.681946626812
total_rewards_max            4757.80883076654
total_rewards_min            32.93742334955412
Number of train steps total  1456000
Number of env steps total    2371033
Number of rollouts total     0
Train Time (s)               145.66188507713377
(Previous) Eval Time (s)     17.609649267047644
Sample Time (s)              6.390405961312354
Epoch Time (s)               169.66194030549377
Total Train Time (s)         61385.98437411059
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:23:43.338079 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #363 | Epoch Duration: 169.75214385986328
2020-01-12 01:23:43.338222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0741556
Z variance train             0.0052922545
KL Divergence                23.028053
KL Loss                      2.3028054
QF Loss                      2292.3584
VF Loss                      113.814674
Policy Loss                  -1314.259
Q Predictions Mean           1307.6711
Q Predictions Std            379.19626
Q Predictions Max            1917.5327
Q Predictions Min            348.90668
V Predictions Mean           1313.6844
V Predictions Std            378.00336
V Predictions Max            1899.6096
V Predictions Min            350.85406
Log Pis Mean                 0.5273882
Log Pis Std                  3.1144488
Log Pis Max                  10.706358
Log Pis Min                  -7.7299976
Policy mu Mean               -0.018264253
Policy mu Std                0.67595315
Policy mu Max                3.64414
Policy mu Min                -2.7970555
Policy log std Mean          -0.98738223
Policy log std Std           0.27433684
Policy log std Max           -0.35303771
Policy log std Min           -2.2288275
Z mean eval                  0.98156035
Z variance eval              0.0032866027
total_rewards                [ 840.01735531  842.29597318 4603.53070948  343.86870394  158.81551665
 2463.76044462 4471.95774951 4674.63515897 1996.89712909 4328.13641536]
total_rewards_mean           2472.391515610143
total_rewards_std            1796.244836637729
total_rewards_max            4674.635158970684
total_rewards_min            158.81551664863852
Number of train steps total  1460000
Number of env steps total    2381587
Number of rollouts total     0
Train Time (s)               145.88371850317344
(Previous) Eval Time (s)     21.077565680257976
Sample Time (s)              7.188151601701975
Epoch Time (s)               174.1494357851334
Total Train Time (s)         61560.23367656488
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:26:37.589358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #364 | Epoch Duration: 174.25103163719177
2020-01-12 01:26:37.589501 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9832331
Z variance train             0.0032863363
KL Divergence                20.494698
KL Loss                      2.0494697
QF Loss                      712.4331
VF Loss                      118.82176
Policy Loss                  -1174.8744
Q Predictions Mean           1167.8649
Q Predictions Std            360.4236
Q Predictions Max            1739.9755
Q Predictions Min            323.52377
V Predictions Mean           1169.6913
V Predictions Std            363.04385
V Predictions Max            1744.5472
V Predictions Min            317.20993
Log Pis Mean                 0.3414628
Log Pis Std                  3.0071352
Log Pis Max                  10.197086
Log Pis Min                  -6.4008894
Policy mu Mean               0.023761082
Policy mu Std                0.5926702
Policy mu Max                2.3355248
Policy mu Min                -2.3401697
Policy log std Mean          -1.0629143
Policy log std Std           0.31048298
Policy log std Max           -0.26022375
Policy log std Min           -2.5414987
Z mean eval                  0.7885691
Z variance eval              0.003914159
total_rewards                [2029.82800105 4597.88976964 4633.18009416 4821.93915998 3405.81917742
 4295.54044138 4392.50058352 4860.79917274 4830.45115851 4325.51548153]
total_rewards_mean           4219.3463039921435
total_rewards_std            834.5932702437399
total_rewards_max            4860.799172738715
total_rewards_min            2029.8280010451138
Number of train steps total  1464000
Number of env steps total    2392340
Number of rollouts total     0
Train Time (s)               144.55025326972827
(Previous) Eval Time (s)     20.015367562882602
Sample Time (s)              7.227496782783419
Epoch Time (s)               171.7931176153943
Total Train Time (s)         61732.11100794235
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:29:29.469507 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #365 | Epoch Duration: 171.87990045547485
2020-01-12 01:29:29.469649 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7915006
Z variance train             0.0039008749
KL Divergence                22.215391
KL Loss                      2.2215393
QF Loss                      668.9231
VF Loss                      170.71503
Policy Loss                  -1288.7445
Q Predictions Mean           1281.511
Q Predictions Std            391.8876
Q Predictions Max            1874.6964
Q Predictions Min            311.66824
V Predictions Mean           1293.5408
V Predictions Std            390.0541
V Predictions Max            1867.4893
V Predictions Min            320.51486
Log Pis Mean                 0.66438276
Log Pis Std                  3.033164
Log Pis Max                  11.422869
Log Pis Min                  -7.252203
Policy mu Mean               0.0013969154
Policy mu Std                0.670887
Policy mu Max                2.3131022
Policy mu Min                -2.611953
Policy log std Mean          -1.0279169
Policy log std Std           0.30817863
Policy log std Max           -0.31258094
Policy log std Min           -2.8175302
Z mean eval                  0.6999781
Z variance eval              0.013297481
total_rewards                [  92.22615871 2437.44498939 1012.77570304 3123.51530475 4980.45933071
 4707.46415936 4951.12113711 4855.01932579 4380.17850081 4770.36323712]
total_rewards_mean           3531.0567846782787
total_rewards_std            1704.1250627737418
total_rewards_max            4980.4593307064015
total_rewards_min            92.22615870949122
Number of train steps total  1468000
Number of env steps total    2402211
Number of rollouts total     0
Train Time (s)               144.0057005425915
(Previous) Eval Time (s)     17.205030767712742
Sample Time (s)              6.3359408136457205
Epoch Time (s)               167.54667212394997
Total Train Time (s)         61899.74870817503
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:32:17.110497 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #366 | Epoch Duration: 167.64073514938354
2020-01-12 01:32:17.110687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.69611394
Z variance train             0.012948659
KL Divergence                19.711884
KL Loss                      1.9711884
QF Loss                      567.9243
VF Loss                      101.960266
Policy Loss                  -1234.4869
Q Predictions Mean           1229.0085
Q Predictions Std            388.95425
Q Predictions Max            1838.2123
Q Predictions Min            332.53137
V Predictions Mean           1237.8162
V Predictions Std            389.98627
V Predictions Max            1848.77
V Predictions Min            329.35626
Log Pis Mean                 0.74822843
Log Pis Std                  2.8503084
Log Pis Max                  8.94998
Log Pis Min                  -7.459894
Policy mu Mean               0.009103371
Policy mu Std                0.68702215
Policy mu Max                2.145847
Policy mu Min                -2.3780217
Policy log std Mean          -1.0190077
Policy log std Std           0.28675213
Policy log std Max           -0.1600318
Policy log std Min           -2.4031053
Z mean eval                  1.0333391
Z variance eval              0.017658437
total_rewards                [ 127.61104818 4954.62485724 4779.5829316  2351.2108417  4945.59488135
 1052.87178211 4745.07107743 3386.51489168 1875.86321539 2248.52957553]
total_rewards_mean           3046.7475102203143
total_rewards_std            1680.3830510851537
total_rewards_max            4954.624857243355
total_rewards_min            127.61104817981332
Number of train steps total  1472000
Number of env steps total    2410813
Number of rollouts total     0
Train Time (s)               145.5438879681751
(Previous) Eval Time (s)     19.125644634943455
Sample Time (s)              6.4438608437776566
Epoch Time (s)               171.11339344689623
Total Train Time (s)         62070.956669100095
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:35:08.320976 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #367 | Epoch Duration: 171.21016025543213
2020-01-12 01:35:08.321126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0314426
Z variance train             0.017715184
KL Divergence                21.091793
KL Loss                      2.1091793
QF Loss                      394.97034
VF Loss                      91.21582
Policy Loss                  -1264.209
Q Predictions Mean           1258.6729
Q Predictions Std            403.60706
Q Predictions Max            1859.3179
Q Predictions Min            332.79993
V Predictions Mean           1265.7351
V Predictions Std            405.46094
V Predictions Max            1867.7101
V Predictions Min            335.4713
Log Pis Mean                 0.44833267
Log Pis Std                  2.9052262
Log Pis Max                  9.696117
Log Pis Min                  -7.2374496
Policy mu Mean               0.012163539
Policy mu Std                0.63274056
Policy mu Max                2.6189892
Policy mu Min                -2.6908972
Policy log std Mean          -1.034296
Policy log std Std           0.30007368
Policy log std Max           -0.28384173
Policy log std Min           -2.156721
Z mean eval                  0.7612752
Z variance eval              0.019519988
total_rewards                [3655.85620906 1659.33193195 4958.25568276  982.80128419 2572.12831506
 3914.32502375 1306.60235757 1857.7450288  4948.99072221 4932.75973243]
total_rewards_mean           3078.87962877811
total_rewards_std            1509.7915649647482
total_rewards_max            4958.255682755098
total_rewards_min            982.801284194986
Number of train steps total  1476000
Number of env steps total    2423032
Number of rollouts total     0
Train Time (s)               144.66416506515816
(Previous) Eval Time (s)     17.426686168648303
Sample Time (s)              7.820175892673433
Epoch Time (s)               169.9110271264799
Total Train Time (s)         62240.95906572975
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:37:58.325948 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #368 | Epoch Duration: 170.0047197341919
2020-01-12 01:37:58.326089 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75923175
Z variance train             0.019401522
KL Divergence                20.597078
KL Loss                      2.0597079
QF Loss                      476.7411
VF Loss                      90.8852
Policy Loss                  -1302.8676
Q Predictions Mean           1294.9336
Q Predictions Std            342.74448
Q Predictions Max            1889.8755
Q Predictions Min            326.66907
V Predictions Mean           1303.2881
V Predictions Std            341.29556
V Predictions Max            1880.2202
V Predictions Min            328.2769
Log Pis Mean                 0.7477976
Log Pis Std                  2.8467207
Log Pis Max                  9.561072
Log Pis Min                  -5.958342
Policy mu Mean               0.038304016
Policy mu Std                0.6611287
Policy mu Max                2.15474
Policy mu Min                -2.4804428
Policy log std Mean          -1.0365831
Policy log std Std           0.2846414
Policy log std Max           -0.2886994
Policy log std Min           -2.572917
Z mean eval                  0.74418324
Z variance eval              0.0118476255
total_rewards                [4938.95627022  363.40777067 5094.18158796 5168.87417539  125.96239217
 4915.40571874 4812.48881199 4740.12089759 5107.98354684 4630.11732466]
total_rewards_mean           3989.749849623274
total_rewards_std            1880.0962438562688
total_rewards_max            5168.874175393914
total_rewards_min            125.96239217266228
Number of train steps total  1480000
Number of env steps total    2434854
Number of rollouts total     0
Train Time (s)               144.55714851943776
(Previous) Eval Time (s)     19.604538405314088
Sample Time (s)              6.661934916395694
Epoch Time (s)               170.82362184114754
Total Train Time (s)         62411.87435544282
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:40:49.245101 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #369 | Epoch Duration: 170.91889834403992
2020-01-12 01:40:49.245287 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7473689
Z variance train             0.011854308
KL Divergence                18.706589
KL Loss                      1.8706589
QF Loss                      610.04724
VF Loss                      97.406204
Policy Loss                  -1288.3306
Q Predictions Mean           1278.6772
Q Predictions Std            326.31903
Q Predictions Max            1837.4556
Q Predictions Min            338.99106
V Predictions Mean           1285.8291
V Predictions Std            322.74374
V Predictions Max            1830.1074
V Predictions Min            344.2451
Log Pis Mean                 1.0907784
Log Pis Std                  3.045084
Log Pis Max                  9.224752
Log Pis Min                  -8.36199
Policy mu Mean               0.026222294
Policy mu Std                0.69147176
Policy mu Max                2.5071156
Policy mu Min                -2.360757
Policy log std Mean          -1.0754362
Policy log std Std           0.2878993
Policy log std Max           -0.044682145
Policy log std Min           -2.760048
Z mean eval                  1.1021739
Z variance eval              0.0066022747
total_rewards                [4613.93969684 3238.52210524 4513.43306546 2828.91979784 4653.76397218
 4650.73461016 4770.55343037 4773.73905541 4812.05959617 4793.28205732]
total_rewards_mean           4364.894738698113
total_rewards_std            677.6692389472493
total_rewards_max            4812.059596169401
total_rewards_min            2828.919797842618
Number of train steps total  1484000
Number of env steps total    2445868
Number of rollouts total     0
Train Time (s)               145.77456622291356
(Previous) Eval Time (s)     23.650099745951593
Sample Time (s)              7.305976883973926
Epoch Time (s)               176.73064285283908
Total Train Time (s)         62588.694853557274
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:43:46.066950 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #370 | Epoch Duration: 176.82153820991516
2020-01-12 01:43:46.067097 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1091951
Z variance train             0.006639219
KL Divergence                21.371965
KL Loss                      2.1371965
QF Loss                      8477.633
VF Loss                      115.751396
Policy Loss                  -1363.4594
Q Predictions Mean           1353.013
Q Predictions Std            349.71948
Q Predictions Max            1915.8153
Q Predictions Min            14.209589
V Predictions Mean           1366.9324
V Predictions Std            341.41138
V Predictions Max            1917.4268
V Predictions Min            375.7009
Log Pis Mean                 1.087031
Log Pis Std                  2.7643209
Log Pis Max                  10.088692
Log Pis Min                  -7.773112
Policy mu Mean               0.015549336
Policy mu Std                0.6856392
Policy mu Max                2.456172
Policy mu Min                -2.6368887
Policy log std Mean          -1.0650191
Policy log std Std           0.28909874
Policy log std Max           -0.29367244
Policy log std Min           -2.599098
Z mean eval                  0.88134336
Z variance eval              0.004762362
total_rewards                [4698.96124501 5038.79456333 1830.03985771 2024.37144871 4987.45108267
 5271.96707985 4949.62321719 4979.83300349 4800.02910422  510.54192957]
total_rewards_mean           3909.16125317482
total_rewards_std            1654.3319024461637
total_rewards_max            5271.967079847705
total_rewards_min            510.54192957069074
Number of train steps total  1488000
Number of env steps total    2457617
Number of rollouts total     0
Train Time (s)               146.20432912698016
(Previous) Eval Time (s)     20.900712608825415
Sample Time (s)              7.592525147367269
Epoch Time (s)               174.69756688317284
Total Train Time (s)         62763.6003376157
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:46:40.974967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #371 | Epoch Duration: 174.9077663421631
2020-01-12 01:46:40.975161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8761438
Z variance train             0.0047534117
KL Divergence                21.504612
KL Loss                      2.1504612
QF Loss                      563.2135
VF Loss                      205.87997
Policy Loss                  -1364.7158
Q Predictions Mean           1358.029
Q Predictions Std            340.74283
Q Predictions Max            1883.0756
Q Predictions Min            373.56934
V Predictions Mean           1367.8787
V Predictions Std            341.38718
V Predictions Max            1879.3583
V Predictions Min            372.5618
Log Pis Mean                 0.935929
Log Pis Std                  3.2111669
Log Pis Max                  12.930843
Log Pis Min                  -8.627723
Policy mu Mean               -0.014367593
Policy mu Std                0.6783569
Policy mu Max                2.6589603
Policy mu Min                -3.3120763
Policy log std Mean          -1.0752691
Policy log std Std           0.30439484
Policy log std Max           -0.27791357
Policy log std Min           -2.7156491
Z mean eval                  0.7073299
Z variance eval              0.0073301555
total_rewards                [5127.86111761 4961.15943564 4962.97029793 3037.66119465 5000.8807027
 4868.76256719 5062.09972301 5038.11730742 4783.9054444  5170.38657823]
total_rewards_mean           4801.380436879286
total_rewards_std            597.8098626841207
total_rewards_max            5170.386578228245
total_rewards_min            3037.6611946543626
Number of train steps total  1492000
Number of env steps total    2466852
Number of rollouts total     0
Train Time (s)               148.01739215292037
(Previous) Eval Time (s)     20.5864213174209
Sample Time (s)              6.973716826643795
Epoch Time (s)               175.57753029698506
Total Train Time (s)         62939.26834280556
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:49:36.647913 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #372 | Epoch Duration: 175.6725459098816
2020-01-12 01:49:36.648282 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.70596236
Z variance train             0.0073274323
KL Divergence                19.35779
KL Loss                      1.935779
QF Loss                      511.83044
VF Loss                      118.00159
Policy Loss                  -1318.19
Q Predictions Mean           1310.2069
Q Predictions Std            318.85327
Q Predictions Max            1852.2081
Q Predictions Min            232.33655
V Predictions Mean           1312.9226
V Predictions Std            313.29364
V Predictions Max            1837.7604
V Predictions Min            370.5992
Log Pis Mean                 0.84778816
Log Pis Std                  2.9458208
Log Pis Max                  17.573986
Log Pis Min                  -9.453226
Policy mu Mean               0.011620384
Policy mu Std                0.66214424
Policy mu Max                2.9963245
Policy mu Min                -2.5718002
Policy log std Mean          -1.0627996
Policy log std Std           0.28424388
Policy log std Max           -0.19584036
Policy log std Min           -2.2770832
Z mean eval                  0.8233635
Z variance eval              0.007504523
total_rewards                [ 671.52611241 4019.2105371  5081.33415698 5102.50972811 4949.67253454
 4938.62781179 4866.71232233 5012.06314429  741.86979231 3314.1445378 ]
total_rewards_mean           3869.7670677669644
total_rewards_std            1671.4809264035034
total_rewards_max            5102.509728108227
total_rewards_min            671.5261124104594
Number of train steps total  1496000
Number of env steps total    2475898
Number of rollouts total     0
Train Time (s)               146.09084956999868
(Previous) Eval Time (s)     21.297854518983513
Sample Time (s)              7.263164343312383
Epoch Time (s)               174.65186843229458
Total Train Time (s)         63114.00972626731
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:52:31.390178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #373 | Epoch Duration: 174.74166250228882
2020-01-12 01:52:31.390318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8241603
Z variance train             0.00754394
KL Divergence                20.195063
KL Loss                      2.0195062
QF Loss                      2315.9924
VF Loss                      170.77232
Policy Loss                  -1360.8455
Q Predictions Mean           1349.7241
Q Predictions Std            344.5723
Q Predictions Max            1898.428
Q Predictions Min            388.63098
V Predictions Mean           1356.3044
V Predictions Std            341.73724
V Predictions Max            1890.7753
V Predictions Min            394.6768
Log Pis Mean                 1.2502661
Log Pis Std                  3.0759346
Log Pis Max                  11.954191
Log Pis Min                  -8.157226
Policy mu Mean               -0.013544799
Policy mu Std                0.6771997
Policy mu Max                2.2843604
Policy mu Min                -2.232836
Policy log std Mean          -1.1065539
Policy log std Std           0.31113705
Policy log std Max           -0.20006025
Policy log std Min           -2.7625825
Z mean eval                  0.7689575
Z variance eval              0.0067520454
total_rewards                [5176.19665306 3076.72677166 1972.99060151 4267.26488895 5232.18667189
 4533.35706929 4747.10494744 4977.1957823  4699.80570669 4926.42284917]
total_rewards_mean           4360.9251941948
total_rewards_std            988.7981677262269
total_rewards_max            5232.186671890914
total_rewards_min            1972.990601508076
Number of train steps total  1500000
Number of env steps total    2485638
Number of rollouts total     0
Train Time (s)               147.06661586323753
(Previous) Eval Time (s)     19.36895801499486
Sample Time (s)              7.141583304386586
Epoch Time (s)               173.57715718261898
Total Train Time (s)         63287.674859651364
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:55:25.059129 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #374 | Epoch Duration: 173.668696641922
2020-01-12 01:55:25.059304 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.76924527
Z variance train             0.0067378515
KL Divergence                19.924446
KL Loss                      1.9924446
QF Loss                      454.49103
VF Loss                      77.178825
Policy Loss                  -1309.7571
Q Predictions Mean           1298.9429
Q Predictions Std            346.20892
Q Predictions Max            1928.9899
Q Predictions Min            -82.094086
V Predictions Mean           1310.4546
V Predictions Std            338.74847
V Predictions Max            1944.2258
V Predictions Min            373.76218
Log Pis Mean                 1.259598
Log Pis Std                  3.092232
Log Pis Max                  17.459509
Log Pis Min                  -5.8103065
Policy mu Mean               -0.011853274
Policy mu Std                0.6890797
Policy mu Max                4.047874
Policy mu Min                -2.7460167
Policy log std Mean          -1.090495
Policy log std Std           0.2786505
Policy log std Max           -0.3412361
Policy log std Min           -2.5169716
Z mean eval                  0.79143834
Z variance eval              0.035245508
total_rewards                [ 705.8479172  3250.81129344  473.91797217 4460.40790175 2534.20743875
 5013.5805854  5208.15719283 5313.83090225  711.19190557 5062.27012795]
total_rewards_mean           3273.4223237310885
total_rewards_std            1925.7509120826855
total_rewards_max            5313.830902252645
total_rewards_min            473.91797216686496
Number of train steps total  1504000
Number of env steps total    2495843
Number of rollouts total     0
Train Time (s)               146.23585331067443
(Previous) Eval Time (s)     15.596790416631848
Sample Time (s)              7.079811271745712
Epoch Time (s)               168.912454999052
Total Train Time (s)         63456.67508039996
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 01:58:14.061835 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #375 | Epoch Duration: 169.0024058818817
2020-01-12 01:58:14.061974 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #375 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79256403
Z variance train             0.035863835
KL Divergence                19.930336
KL Loss                      1.9930336
QF Loss                      1518.76
VF Loss                      193.15872
Policy Loss                  -1326.0881
Q Predictions Mean           1319.875
Q Predictions Std            367.08438
Q Predictions Max            1925.8602
Q Predictions Min            373.62973
V Predictions Mean           1321.0857
V Predictions Std            369.74268
V Predictions Max            1918.4161
V Predictions Min            306.71964
Log Pis Mean                 0.85131645
Log Pis Std                  3.1887193
Log Pis Max                  23.284739
Log Pis Min                  -7.447454
Policy mu Mean               0.022292085
Policy mu Std                0.7101104
Policy mu Max                3.043583
Policy mu Min                -5.297733
Policy log std Mean          -1.0419364
Policy log std Std           0.30783266
Policy log std Max           0.348418
Policy log std Min           -2.5779738
Z mean eval                  0.98058164
Z variance eval              0.0015765165
total_rewards                [5002.94982116 4793.83952498 4959.43752596 4934.06755379 5188.4776674
 4826.15025968 4692.44901102 4888.91451442 3911.89639174 4952.69003294]
total_rewards_mean           4815.087230308915
total_rewards_std            326.41366014097906
total_rewards_max            5188.4776673981105
total_rewards_min            3911.8963917363894
Number of train steps total  1508000
Number of env steps total    2507738
Number of rollouts total     0
Train Time (s)               146.14692103210837
(Previous) Eval Time (s)     20.914437311235815
Sample Time (s)              6.177472996525466
Epoch Time (s)               173.23883133986965
Total Train Time (s)         63630.006743000355
Epoch                        376
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:01:07.397004 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #376 | Epoch Duration: 173.33491706848145
2020-01-12 02:01:07.397180 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.974723
Z variance train             0.0015731457
KL Divergence                22.853401
KL Loss                      2.28534
QF Loss                      746.0452
VF Loss                      362.48743
Policy Loss                  -1296.4127
Q Predictions Mean           1288.7698
Q Predictions Std            356.68173
Q Predictions Max            1886.3992
Q Predictions Min            380.89706
V Predictions Mean           1296.8427
V Predictions Std            357.2188
V Predictions Max            1885.9595
V Predictions Min            383.77606
Log Pis Mean                 0.9812993
Log Pis Std                  2.8460965
Log Pis Max                  13.7738905
Log Pis Min                  -7.1113586
Policy mu Mean               0.03630564
Policy mu Std                0.6697497
Policy mu Max                2.3324792
Policy mu Min                -2.257752
Policy log std Mean          -1.0525994
Policy log std Std           0.28126296
Policy log std Max           -0.0681963
Policy log std Min           -2.2865012
Z mean eval                  0.7537792
Z variance eval              0.0064333477
total_rewards                [3852.90925396 3120.87175639 4556.53213185 4767.94466383 4848.57945957
 4925.72669861 4894.89834344 4872.43671576 4771.42231053 4748.06170994]
total_rewards_mean           4535.938304388526
total_rewards_std            558.1581412605997
total_rewards_max            4925.72669860779
total_rewards_min            3120.8717563904565
Number of train steps total  1512000
Number of env steps total    2518841
Number of rollouts total     0
Train Time (s)               145.9913209839724
(Previous) Eval Time (s)     23.15682313265279
Sample Time (s)              7.390402570366859
Epoch Time (s)               176.53854668699205
Total Train Time (s)         63806.64255538676
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:04:04.035480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #377 | Epoch Duration: 176.63817143440247
2020-01-12 02:04:04.035637 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7545326
Z variance train             0.0064288303
KL Divergence                20.262524
KL Loss                      2.0262525
QF Loss                      516.4385
VF Loss                      133.08777
Policy Loss                  -1365.9769
Q Predictions Mean           1359.8489
Q Predictions Std            339.26825
Q Predictions Max            1908.9349
Q Predictions Min            393.2228
V Predictions Mean           1369.3918
V Predictions Std            337.0015
V Predictions Max            1904.1687
V Predictions Min            398.16702
Log Pis Mean                 1.1673816
Log Pis Std                  2.673228
Log Pis Max                  11.845209
Log Pis Min                  -5.1881094
Policy mu Mean               -0.016316012
Policy mu Std                0.6653296
Policy mu Max                2.6920872
Policy mu Min                -2.3503363
Policy log std Mean          -1.1065754
Policy log std Std           0.28779456
Policy log std Max           -0.31202412
Policy log std Min           -2.484353
Z mean eval                  0.7599846
Z variance eval              0.008071923
total_rewards                [5201.33094872   93.66204697 -375.60347646 2840.58825564 4953.01928816
 3984.11381072 5048.46179048  957.48537045 5075.37648693 1572.59996906]
total_rewards_mean           2935.1034490673937
total_rewards_std            2101.574124709779
total_rewards_max            5201.330948715695
total_rewards_min            -375.6034764591159
Number of train steps total  1516000
Number of env steps total    2528490
Number of rollouts total     0
Train Time (s)               148.32555911317468
(Previous) Eval Time (s)     16.78034031484276
Sample Time (s)              7.23319932911545
Epoch Time (s)               172.3390987571329
Total Train Time (s)         63979.07230887702
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:06:56.467104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #378 | Epoch Duration: 172.43135952949524
2020-01-12 02:06:56.467247 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7599183
Z variance train             0.007998211
KL Divergence                20.046814
KL Loss                      2.0046813
QF Loss                      621.8684
VF Loss                      114.07994
Policy Loss                  -1346.0957
Q Predictions Mean           1340.2292
Q Predictions Std            339.6772
Q Predictions Max            1935.3914
Q Predictions Min            391.40158
V Predictions Mean           1348.6481
V Predictions Std            340.18204
V Predictions Max            1915.0121
V Predictions Min            394.96704
Log Pis Mean                 1.6596993
Log Pis Std                  3.347984
Log Pis Max                  22.188665
Log Pis Min                  -6.294301
Policy mu Mean               0.08826348
Policy mu Std                0.7350475
Policy mu Max                3.400574
Policy mu Min                -5.515213
Policy log std Mean          -1.075126
Policy log std Std           0.3062119
Policy log std Max           1.0755727
Policy log std Min           -2.2274988
Z mean eval                  0.74666053
Z variance eval              0.011997945
total_rewards                [4869.57129537 1601.60483235 4776.94678456 5163.22793243 5127.87353368
 4928.88903417 5293.02544203 1185.620217   4962.68571677 2853.52635243]
total_rewards_mean           4076.2971140785994
total_rewards_std            1495.8520704558905
total_rewards_max            5293.025442025633
total_rewards_min            1185.6202170002848
Number of train steps total  1520000
Number of env steps total    2538561
Number of rollouts total     0
Train Time (s)               145.55372556392103
(Previous) Eval Time (s)     20.31787985190749
Sample Time (s)              6.11322166910395
Epoch Time (s)               171.98482708493248
Total Train Time (s)         64151.15260756202
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:09:48.549951 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #379 | Epoch Duration: 172.08259987831116
2020-01-12 02:09:48.550102 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74868476
Z variance train             0.012022452
KL Divergence                19.007517
KL Loss                      1.9007517
QF Loss                      613.6813
VF Loss                      238.86674
Policy Loss                  -1299.4485
Q Predictions Mean           1288.545
Q Predictions Std            367.65588
Q Predictions Max            1852.6919
Q Predictions Min            351.5601
V Predictions Mean           1287.1868
V Predictions Std            364.8024
V Predictions Max            1844.3474
V Predictions Min            367.6342
Log Pis Mean                 0.8590969
Log Pis Std                  2.868417
Log Pis Max                  12.77152
Log Pis Min                  -9.201452
Policy mu Mean               -0.034052666
Policy mu Std                0.635462
Policy mu Max                1.8901132
Policy mu Min                -3.5016832
Policy log std Mean          -1.0905095
Policy log std Std           0.2889898
Policy log std Max           -0.16789007
Policy log std Min           -2.3243878
Z mean eval                  0.6840142
Z variance eval              0.003160121
total_rewards                [2287.69498702 5202.61669549 5279.0158525  5360.46181823 5413.03272416
 4968.83514168 5100.6107882  5151.48819923 4943.85645887 5340.13881838]
total_rewards_mean           4904.7751483753445
total_rewards_std            885.3384579471905
total_rewards_max            5413.032724158657
total_rewards_min            2287.6949870214025
Number of train steps total  1524000
Number of env steps total    2551009
Number of rollouts total     0
Train Time (s)               143.33714977884665
(Previous) Eval Time (s)     23.428322554565966
Sample Time (s)              8.578353198710829
Epoch Time (s)               175.34382553212345
Total Train Time (s)         64326.59199747816
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:12:43.996811 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #380 | Epoch Duration: 175.4465765953064
2020-01-12 02:12:43.997063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67857325
Z variance train             0.003162269
KL Divergence                21.274082
KL Loss                      2.1274083
QF Loss                      680.6668
VF Loss                      199.93199
Policy Loss                  -1321.3396
Q Predictions Mean           1312.7712
Q Predictions Std            328.24936
Q Predictions Max            1910.8943
Q Predictions Min            387.2707
V Predictions Mean           1324.9336
V Predictions Std            331.34973
V Predictions Max            1886.5977
V Predictions Min            382.2311
Log Pis Mean                 1.033503
Log Pis Std                  3.2709177
Log Pis Max                  15.213512
Log Pis Min                  -7.329135
Policy mu Mean               0.023459315
Policy mu Std                0.67998964
Policy mu Max                2.585738
Policy mu Min                -2.505069
Policy log std Mean          -1.1023406
Policy log std Std           0.29992503
Policy log std Max           -0.28367043
Policy log std Min           -2.7505658
Z mean eval                  0.9146017
Z variance eval              0.011220587
total_rewards                [4881.48211375 4924.5251469  5162.17654017 4879.76662077 4915.99006413
 4963.65119942 5094.97198301 1498.41853211 1535.53469532   29.12864501]
total_rewards_mean           3788.5645540602795
total_rewards_std            1854.0575793455396
total_rewards_max            5162.176540174952
total_rewards_min            29.12864501061992
Number of train steps total  1528000
Number of env steps total    2561694
Number of rollouts total     0
Train Time (s)               145.17412716615945
(Previous) Eval Time (s)     18.86483663180843
Sample Time (s)              7.047614839859307
Epoch Time (s)               171.0865786378272
Total Train Time (s)         64497.776958542876
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:15:35.185613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #381 | Epoch Duration: 171.18836736679077
2020-01-12 02:15:35.185817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.916893
Z variance train             0.011139457
KL Divergence                19.674215
KL Loss                      1.9674215
QF Loss                      15629.807
VF Loss                      148.24406
Policy Loss                  -1347.2234
Q Predictions Mean           1343.3235
Q Predictions Std            327.68796
Q Predictions Max            1902.9819
Q Predictions Min            386.40024
V Predictions Mean           1349.843
V Predictions Std            326.4153
V Predictions Max            1921.5026
V Predictions Min            393.07565
Log Pis Mean                 1.110074
Log Pis Std                  2.8054519
Log Pis Max                  11.312769
Log Pis Min                  -5.6033177
Policy mu Mean               -0.027219502
Policy mu Std                0.70866424
Policy mu Max                2.3497505
Policy mu Min                -2.5438032
Policy log std Mean          -1.0683924
Policy log std Std           0.30099756
Policy log std Max           -0.22439921
Policy log std Min           -2.6994562
Z mean eval                  0.9934617
Z variance eval              0.0048946464
total_rewards                [  62.29624585 1296.87177463  198.52582621 4732.48808439  802.12117651
 2171.82245865 2962.28357549 1993.74415668 4864.67623177 4922.08722542]
total_rewards_mean           2400.691675560344
total_rewards_std            1802.5198028267487
total_rewards_max            4922.087225420301
total_rewards_min            62.29624585134559
Number of train steps total  1532000
Number of env steps total    2573330
Number of rollouts total     0
Train Time (s)               144.75332352984697
(Previous) Eval Time (s)     10.585104211233556
Sample Time (s)              8.431138406973332
Epoch Time (s)               163.76956614805385
Total Train Time (s)         64661.63712349953
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:18:19.054948 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #382 | Epoch Duration: 163.86893892288208
2020-01-12 02:18:19.055219 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99696314
Z variance train             0.004908249
KL Divergence                22.75034
KL Loss                      2.275034
QF Loss                      525.668
VF Loss                      95.425186
Policy Loss                  -1390.6334
Q Predictions Mean           1384.212
Q Predictions Std            322.64374
Q Predictions Max            1924.7273
Q Predictions Min            377.99246
V Predictions Mean           1387.6163
V Predictions Std            318.97263
V Predictions Max            1902.6455
V Predictions Min            396.40604
Log Pis Mean                 1.239989
Log Pis Std                  2.9963753
Log Pis Max                  13.580122
Log Pis Min                  -8.227466
Policy mu Mean               0.06741379
Policy mu Std                0.6721918
Policy mu Max                2.538734
Policy mu Min                -2.809733
Policy log std Mean          -1.1061666
Policy log std Std           0.3075305
Policy log std Max           -0.15533328
Policy log std Min           -2.4734352
Z mean eval                  0.7328458
Z variance eval              0.018192522
total_rewards                [5242.88164438 5156.35324806 5163.14948108 4918.86318186 5074.74402914
 5081.88691073 5151.9007268  5191.75533598 5127.1900212  5174.61453251]
total_rewards_mean           5128.3339111723935
total_rewards_std            84.11091034605644
total_rewards_max            5242.88164437805
total_rewards_min            4918.863181860494
Number of train steps total  1536000
Number of env steps total    2585370
Number of rollouts total     0
Train Time (s)               146.43903620122
(Previous) Eval Time (s)     21.21510009514168
Sample Time (s)              7.171048602554947
Epoch Time (s)               174.82518489891663
Total Train Time (s)         64836.5568094952
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:21:13.977687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #383 | Epoch Duration: 174.92233061790466
2020-01-12 02:21:13.977875 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7415156
Z variance train             0.018387636
KL Divergence                17.170359
KL Loss                      1.7170359
QF Loss                      747.30115
VF Loss                      176.6693
Policy Loss                  -1322.4465
Q Predictions Mean           1316.2352
Q Predictions Std            289.9676
Q Predictions Max            1830.9727
Q Predictions Min            368.19763
V Predictions Mean           1327.2954
V Predictions Std            286.23395
V Predictions Max            1826.8871
V Predictions Min            380.9793
Log Pis Mean                 1.2643354
Log Pis Std                  2.9012704
Log Pis Max                  8.708987
Log Pis Min                  -7.663479
Policy mu Mean               0.037401885
Policy mu Std                0.6908161
Policy mu Max                2.9873977
Policy mu Min                -2.2239342
Policy log std Mean          -1.0885781
Policy log std Std           0.2867281
Policy log std Max           -0.22801125
Policy log std Min           -2.2183251
Z mean eval                  0.8064724
Z variance eval              0.028298184
total_rewards                [4895.9553783  4854.38912205 2158.13302059 4775.34474263  681.04315303
 4691.73172359 5002.66528344 1014.57377668 4712.02693646 4717.79699551]
total_rewards_mean           3750.3660132284376
total_rewards_std            1653.4046267636713
total_rewards_max            5002.665283438539
total_rewards_min            681.0431530306806
Number of train steps total  1540000
Number of env steps total    2594041
Number of rollouts total     0
Train Time (s)               144.8728587110527
(Previous) Eval Time (s)     19.066420681774616
Sample Time (s)              7.049888646695763
Epoch Time (s)               170.98916803952307
Total Train Time (s)         65007.641030048486
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:24:05.066032 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #384 | Epoch Duration: 171.08802795410156
2020-01-12 02:24:05.066178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8021649
Z variance train             0.028214354
KL Divergence                20.582172
KL Loss                      2.0582173
QF Loss                      673.6754
VF Loss                      105.7528
Policy Loss                  -1412.1749
Q Predictions Mean           1405.551
Q Predictions Std            305.0404
Q Predictions Max            1954.9095
Q Predictions Min            389.2151
V Predictions Mean           1414.2021
V Predictions Std            304.0874
V Predictions Max            1939.6626
V Predictions Min            392.29422
Log Pis Mean                 1.4071367
Log Pis Std                  3.139805
Log Pis Max                  11.715664
Log Pis Min                  -11.550369
Policy mu Mean               0.00052641914
Policy mu Std                0.7084108
Policy mu Max                2.519195
Policy mu Min                -2.5382507
Policy log std Mean          -1.0910244
Policy log std Std           0.3044257
Policy log std Max           -0.16467035
Policy log std Min           -2.5563142
Z mean eval                  0.7820159
Z variance eval              0.0045304275
total_rewards                [4900.77681285 1925.65526263 4710.93209922 5000.77486842  681.31566103
 4817.2444753  4726.37401168 4982.68110889 4915.03218002 4920.85694489]
total_rewards_mean           4158.164342493391
total_rewards_std            1457.093586383227
total_rewards_max            5000.774868421028
total_rewards_min            681.3156610337911
Number of train steps total  1544000
Number of env steps total    2605603
Number of rollouts total     0
Train Time (s)               147.1550318012014
(Previous) Eval Time (s)     18.169641037937254
Sample Time (s)              7.2240771246142685
Epoch Time (s)               172.54874996375293
Total Train Time (s)         65180.39455628162
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:26:57.843368 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #385 | Epoch Duration: 172.7769422531128
2020-01-12 02:26:57.843844 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78823066
Z variance train             0.0045419834
KL Divergence                21.035345
KL Loss                      2.1035345
QF Loss                      436.4382
VF Loss                      99.27544
Policy Loss                  -1413.84
Q Predictions Mean           1405.2561
Q Predictions Std            324.7887
Q Predictions Max            1979.1001
Q Predictions Min            387.51147
V Predictions Mean           1414.6995
V Predictions Std            329.44556
V Predictions Max            1971.3534
V Predictions Min            378.17932
Log Pis Mean                 1.2844224
Log Pis Std                  3.0634005
Log Pis Max                  13.369812
Log Pis Min                  -8.598906
Policy mu Mean               0.017353507
Policy mu Std                0.68340266
Policy mu Max                2.5164795
Policy mu Min                -2.4760842
Policy log std Mean          -1.1000214
Policy log std Std           0.28410622
Policy log std Max           -0.4255544
Policy log std Min           -2.7346354
Z mean eval                  1.0342205
Z variance eval              0.0036778215
total_rewards                [4862.84397963 4839.53093693 4854.22443273 2518.69764092 4805.43829033
 3714.32484535 4688.06654741 3554.40918736 4929.46924485 5013.12721632]
total_rewards_mean           4378.013232183075
total_rewards_std            789.7465203299913
total_rewards_max            5013.127216315686
total_rewards_min            2518.6976409200925
Number of train steps total  1548000
Number of env steps total    2614144
Number of rollouts total     0
Train Time (s)               147.56508763413876
(Previous) Eval Time (s)     22.117426068987697
Sample Time (s)              6.385454374365509
Epoch Time (s)               176.06796807749197
Total Train Time (s)         65356.56316134846
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:29:53.997146 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #386 | Epoch Duration: 176.15306067466736
2020-01-12 02:29:53.997277 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0322235
Z variance train             0.0036991711
KL Divergence                22.306479
KL Loss                      2.2306478
QF Loss                      791.69324
VF Loss                      78.63958
Policy Loss                  -1370.3439
Q Predictions Mean           1359.4412
Q Predictions Std            334.32736
Q Predictions Max            1884.3896
Q Predictions Min            400.7314
V Predictions Mean           1368.8823
V Predictions Std            332.08963
V Predictions Max            1872.8468
V Predictions Min            401.68408
Log Pis Mean                 1.2275244
Log Pis Std                  2.9902625
Log Pis Max                  17.01796
Log Pis Min                  -8.310878
Policy mu Mean               0.03780952
Policy mu Std                0.69161797
Policy mu Max                2.5113401
Policy mu Min                -3.6525946
Policy log std Mean          -1.0944521
Policy log std Std           0.29902875
Policy log std Max           -0.08020961
Policy log std Min           -2.6181178
Z mean eval                  0.8682294
Z variance eval              0.0082515795
total_rewards                [5173.5022337  5131.43942871 5141.17555378 5177.1407587  5196.76608216
 1804.3712357  5089.8003938  5289.429092   5224.53366098 5153.8758943 ]
total_rewards_mean           4838.203433383868
total_rewards_std            1012.6003160328821
total_rewards_max            5289.429092003107
total_rewards_min            1804.371235700867
Number of train steps total  1552000
Number of env steps total    2623775
Number of rollouts total     0
Train Time (s)               145.48044216493145
(Previous) Eval Time (s)     24.6339092371054
Sample Time (s)              7.061593112070113
Epoch Time (s)               177.17594451410696
Total Train Time (s)         65533.82569946442
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:32:51.262298 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #387 | Epoch Duration: 177.26493072509766
2020-01-12 02:32:51.262429 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.865466
Z variance train             0.008314975
KL Divergence                19.543606
KL Loss                      1.9543606
QF Loss                      5077.959
VF Loss                      142.48885
Policy Loss                  -1355.0065
Q Predictions Mean           1351.6436
Q Predictions Std            307.22775
Q Predictions Max            1893.7692
Q Predictions Min            382.32596
V Predictions Mean           1358.9761
V Predictions Std            305.52405
V Predictions Max            1904.9589
V Predictions Min            389.461
Log Pis Mean                 1.165601
Log Pis Std                  3.1696193
Log Pis Max                  18.159332
Log Pis Min                  -6.6491194
Policy mu Mean               0.059024133
Policy mu Std                0.6449818
Policy mu Max                2.2581263
Policy mu Min                -3.4205508
Policy log std Mean          -1.1499299
Policy log std Std           0.29760808
Policy log std Max           -0.31140316
Policy log std Min           -2.6048343
Z mean eval                  1.0696143
Z variance eval              0.012701613
total_rewards                [4221.8542742  4606.22575895 4875.7250542  5014.55757169 5099.29645719
 4397.92716052 4264.76665591 1109.48033025 4859.55536747 4771.12224016]
total_rewards_mean           4322.051087054143
total_rewards_std            1109.1100219572681
total_rewards_max            5099.296457193187
total_rewards_min            1109.480330253011
Number of train steps total  1556000
Number of env steps total    2634386
Number of rollouts total     0
Train Time (s)               146.09365746704862
(Previous) Eval Time (s)     18.771953872404993
Sample Time (s)              7.201709533110261
Epoch Time (s)               172.06732087256387
Total Train Time (s)         65705.99277922185
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:35:43.433628 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #388 | Epoch Duration: 172.17108583450317
2020-01-12 02:35:43.433837 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0608925
Z variance train             0.012710996
KL Divergence                20.849533
KL Loss                      2.0849533
QF Loss                      570.3154
VF Loss                      231.24132
Policy Loss                  -1418.8951
Q Predictions Mean           1414.4515
Q Predictions Std            351.97534
Q Predictions Max            1972.0363
Q Predictions Min            408.64877
V Predictions Mean           1430.3561
V Predictions Std            350.96603
V Predictions Max            1986.1401
V Predictions Min            419.08002
Log Pis Mean                 1.1443399
Log Pis Std                  2.9613535
Log Pis Max                  13.468388
Log Pis Min                  -6.9352503
Policy mu Mean               0.0078241695
Policy mu Std                0.6511874
Policy mu Max                2.6185791
Policy mu Min                -2.507619
Policy log std Mean          -1.0874327
Policy log std Std           0.31241184
Policy log std Max           -0.19178224
Policy log std Min           -2.3626146
Z mean eval                  0.6219728
Z variance eval              0.013268545
total_rewards                [4451.12706354 4895.4817971  5018.23811657 5213.34941141 4982.58773983
 4956.81218309 4960.76451137 4923.88398078 4966.09245782 1659.44992746]
total_rewards_mean           4602.77871889722
total_rewards_std            997.502613962269
total_rewards_max            5213.34941141013
total_rewards_min            1659.449927456986
Number of train steps total  1560000
Number of env steps total    2646539
Number of rollouts total     0
Train Time (s)               146.6369881699793
(Previous) Eval Time (s)     22.852989279665053
Sample Time (s)              7.5761809181421995
Epoch Time (s)               177.06615836778656
Total Train Time (s)         65883.35707950965
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:38:40.806681 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #389 | Epoch Duration: 177.37269616127014
2020-01-12 02:38:40.806828 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6203886
Z variance train             0.013285038
KL Divergence                18.584
KL Loss                      1.8584
QF Loss                      557.47253
VF Loss                      133.18361
Policy Loss                  -1394.1184
Q Predictions Mean           1388.1367
Q Predictions Std            314.64124
Q Predictions Max            1906.8851
Q Predictions Min            322.22446
V Predictions Mean           1400.0515
V Predictions Std            314.1824
V Predictions Max            1916.3479
V Predictions Min            338.24698
Log Pis Mean                 1.2933978
Log Pis Std                  3.2144094
Log Pis Max                  10.827578
Log Pis Min                  -7.557035
Policy mu Mean               0.016448975
Policy mu Std                0.6813783
Policy mu Max                2.471297
Policy mu Min                -2.4118783
Policy log std Mean          -1.1189902
Policy log std Std           0.32189056
Policy log std Max           -0.19662833
Policy log std Min           -2.7375884
Z mean eval                  0.7942023
Z variance eval              0.015781542
total_rewards                [2263.15091146  195.15296191   57.77946117 4804.50660517 4896.49479279
  277.64352572 4391.59221268  134.31853437  612.20227198 4880.8326616 ]
total_rewards_mean           2251.3673938860875
total_rewards_std            2124.0102964920984
total_rewards_max            4896.494792794802
total_rewards_min            57.77946117492823
Number of train steps total  1564000
Number of env steps total    2658725
Number of rollouts total     0
Train Time (s)               145.35066037997603
(Previous) Eval Time (s)     11.957744940184057
Sample Time (s)              7.811469622887671
Epoch Time (s)               165.11987494304776
Total Train Time (s)         66048.58984371647
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:41:26.039837 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #390 | Epoch Duration: 165.232896566391
2020-01-12 02:41:26.040023 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7869297
Z variance train             0.015761962
KL Divergence                20.22962
KL Loss                      2.022962
QF Loss                      599.9821
VF Loss                      93.34365
Policy Loss                  -1452.2661
Q Predictions Mean           1445.0662
Q Predictions Std            332.7692
Q Predictions Max            1961.7917
Q Predictions Min            419.0251
V Predictions Mean           1453.8579
V Predictions Std            331.23575
V Predictions Max            1991.3064
V Predictions Min            415.57703
Log Pis Mean                 1.0114799
Log Pis Std                  2.9957974
Log Pis Max                  11.779205
Log Pis Min                  -9.300364
Policy mu Mean               -0.0018803165
Policy mu Std                0.6885948
Policy mu Max                3.0947144
Policy mu Min                -3.0441315
Policy log std Mean          -1.0616369
Policy log std Std           0.28709716
Policy log std Max           0.017912626
Policy log std Min           -2.4534879
Z mean eval                  0.77650654
Z variance eval              0.011170566
total_rewards                [1403.79007724 4869.13435784 4924.30789004 5070.47241175 5215.17287697
 5008.4196088  5107.24917485 4900.95426037  538.78376552 4782.95052026]
total_rewards_mean           4182.123494365232
total_rewards_std            1621.375063479944
total_rewards_max            5215.172876974664
total_rewards_min            538.7837655235628
Number of train steps total  1568000
Number of env steps total    2670932
Number of rollouts total     0
Train Time (s)               146.3053671871312
(Previous) Eval Time (s)     17.7742008282803
Sample Time (s)              7.781457832548767
Epoch Time (s)               171.86102584796026
Total Train Time (s)         66220.53479151335
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:44:17.987615 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #391 | Epoch Duration: 171.94746947288513
2020-01-12 02:44:17.987755 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.78236544
Z variance train             0.011196155
KL Divergence                20.49557
KL Loss                      2.049557
QF Loss                      4403.857
VF Loss                      151.8154
Policy Loss                  -1455.5564
Q Predictions Mean           1449.426
Q Predictions Std            354.6884
Q Predictions Max            1996.3584
Q Predictions Min            428.95276
V Predictions Mean           1446.969
V Predictions Std            353.74054
V Predictions Max            1977.2421
V Predictions Min            423.50217
Log Pis Mean                 1.2095286
Log Pis Std                  2.9628935
Log Pis Max                  15.1513
Log Pis Min                  -8.494425
Policy mu Mean               0.03911607
Policy mu Std                0.69622475
Policy mu Max                3.7149327
Policy mu Min                -2.5318305
Policy log std Mean          -1.0851316
Policy log std Std           0.3136049
Policy log std Max           -0.0027526617
Policy log std Min           -2.4124885
Z mean eval                  0.81023467
Z variance eval              0.009764462
total_rewards                [-463.79278235 2024.49310213 2134.04112575 5003.58672777  210.92986826
  924.4051747  2242.69554669 2063.82260994 2947.17606472 3113.46413336]
total_rewards_mean           2020.082157096521
total_rewards_std            1471.8674397863529
total_rewards_max            5003.586727774875
total_rewards_min            -463.7927823547527
Number of train steps total  1572000
Number of env steps total    2681570
Number of rollouts total     0
Train Time (s)               146.4287578132935
(Previous) Eval Time (s)     12.3540272382088
Sample Time (s)              6.589574210811406
Epoch Time (s)               165.3723592623137
Total Train Time (s)         66385.99350465275
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:47:03.450348 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #392 | Epoch Duration: 165.4624810218811
2020-01-12 02:47:03.450533 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82142943
Z variance train             0.010073864
KL Divergence                20.134394
KL Loss                      2.0134394
QF Loss                      18847.941
VF Loss                      140.26323
Policy Loss                  -1408.6492
Q Predictions Mean           1401.9255
Q Predictions Std            347.81955
Q Predictions Max            1965.9313
Q Predictions Min            380.72726
V Predictions Mean           1404.8501
V Predictions Std            343.75287
V Predictions Max            1943.8496
V Predictions Min            379.2811
Log Pis Mean                 1.3414991
Log Pis Std                  2.9342477
Log Pis Max                  9.828578
Log Pis Min                  -6.1047187
Policy mu Mean               0.020790637
Policy mu Std                0.69208807
Policy mu Max                2.5673904
Policy mu Min                -2.1850786
Policy log std Mean          -1.0888664
Policy log std Std           0.31210142
Policy log std Max           -0.1349119
Policy log std Min           -2.6892917
Z mean eval                  0.6656255
Z variance eval              0.0041668555
total_rewards                [2221.46525192 5179.44703767 4977.88756447 5350.18175691 5429.60945236
 5291.52344725 5253.36634678 5359.08486153 4846.31768679 1042.74793217]
total_rewards_mean           4495.163133784659
total_rewards_std            1465.370909375456
total_rewards_max            5429.609452360422
total_rewards_min            1042.7479321729293
Number of train steps total  1576000
Number of env steps total    2691499
Number of rollouts total     0
Train Time (s)               145.43125837715343
(Previous) Eval Time (s)     19.456647179089487
Sample Time (s)              7.112905432935804
Epoch Time (s)               172.00081098917872
Total Train Time (s)         66558.12146960013
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:49:55.583566 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #393 | Epoch Duration: 172.1328902244568
2020-01-12 02:49:55.583749 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.66499126
Z variance train             0.004159567
KL Divergence                21.468048
KL Loss                      2.1468048
QF Loss                      763.98096
VF Loss                      336.1373
Policy Loss                  -1430.6495
Q Predictions Mean           1420.3374
Q Predictions Std            343.88947
Q Predictions Max            1953.7341
Q Predictions Min            390.66034
V Predictions Mean           1427.0671
V Predictions Std            340.68652
V Predictions Max            1943.7751
V Predictions Min            402.88107
Log Pis Mean                 1.2214408
Log Pis Std                  2.7800977
Log Pis Max                  9.217782
Log Pis Min                  -7.39006
Policy mu Mean               -0.0062081874
Policy mu Std                0.6319298
Policy mu Max                2.1595619
Policy mu Min                -2.4861026
Policy log std Mean          -1.1429206
Policy log std Std           0.27679765
Policy log std Max           -0.34372652
Policy log std Min           -2.4536932
Z mean eval                  0.76452637
Z variance eval              0.005629602
total_rewards                [ 822.86203675 4852.41730244 4916.95953117 1217.01724802 4454.17583588
  827.78200405 4562.37323872 4736.84061843 4893.64428278 4371.61253317]
total_rewards_mean           3565.568463139768
total_rewards_std            1720.0132997081173
total_rewards_max            4916.9595311688345
total_rewards_min            822.8620367485089
Number of train steps total  1580000
Number of env steps total    2703499
Number of rollouts total     0
Train Time (s)               146.51483275694773
(Previous) Eval Time (s)     15.698599773924798
Sample Time (s)              7.032410653773695
Epoch Time (s)               169.24584318464622
Total Train Time (s)         66727.45722890086
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:52:44.923722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #394 | Epoch Duration: 169.33984065055847
2020-01-12 02:52:44.923888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7665829
Z variance train             0.005623917
KL Divergence                20.576624
KL Loss                      2.0576625
QF Loss                      510.38034
VF Loss                      88.74224
Policy Loss                  -1462.7921
Q Predictions Mean           1455.0345
Q Predictions Std            331.60867
Q Predictions Max            1978.2659
Q Predictions Min            409.18793
V Predictions Mean           1464.8462
V Predictions Std            331.74835
V Predictions Max            1983.9314
V Predictions Min            409.92447
Log Pis Mean                 1.5112479
Log Pis Std                  2.990692
Log Pis Max                  14.185801
Log Pis Min                  -6.8548813
Policy mu Mean               -0.052537005
Policy mu Std                0.6912971
Policy mu Max                2.465443
Policy mu Min                -2.5246139
Policy log std Mean          -1.1384103
Policy log std Std           0.29669496
Policy log std Max           -0.250278
Policy log std Min           -2.6389127
Z mean eval                  0.70837414
Z variance eval              0.0018839777
total_rewards                [1928.73330449 3677.19644361 3188.29969515 5136.29203631 2954.24533902
 4877.34885818 5200.15559915 5007.0067027  4799.27609106 5290.73825768]
total_rewards_mean           4205.929232734091
total_rewards_std            1119.9519480161782
total_rewards_max            5290.73825768393
total_rewards_min            1928.7333044853435
Number of train steps total  1584000
Number of env steps total    2713950
Number of rollouts total     0
Train Time (s)               146.75949004199356
(Previous) Eval Time (s)     17.818572842981666
Sample Time (s)              7.942671089433134
Epoch Time (s)               172.52073397440836
Total Train Time (s)         66900.05919144163
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:55:37.527993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #395 | Epoch Duration: 172.60399103164673
2020-01-12 02:55:37.528116 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.71555114
Z variance train             0.0018857915
KL Divergence                23.207434
KL Loss                      2.3207433
QF Loss                      677.37866
VF Loss                      131.64514
Policy Loss                  -1489.2717
Q Predictions Mean           1480.4474
Q Predictions Std            337.35406
Q Predictions Max            1973.7896
Q Predictions Min            391.39935
V Predictions Mean           1487.9885
V Predictions Std            334.52734
V Predictions Max            1962.9789
V Predictions Min            386.02145
Log Pis Mean                 1.637589
Log Pis Std                  3.1717398
Log Pis Max                  15.5233965
Log Pis Min                  -5.059027
Policy mu Mean               -0.06041562
Policy mu Std                0.7230229
Policy mu Max                2.47314
Policy mu Min                -2.3699722
Policy log std Mean          -1.1191592
Policy log std Std           0.30978137
Policy log std Max           -0.18995333
Policy log std Min           -2.616829
Z mean eval                  0.8133764
Z variance eval              0.005648868
total_rewards                [5189.97388824 4978.70874444 5014.29895522 5203.22088125 5013.75058719
 1459.83445875 5017.60797266 2409.8314902   777.35787699 5143.94534901]
total_rewards_mean           4020.8530203953865
total_rewards_std            1660.8560851640977
total_rewards_max            5203.220881253851
total_rewards_min            777.3578769947796
Number of train steps total  1588000
Number of env steps total    2725307
Number of rollouts total     0
Train Time (s)               148.3620524443686
(Previous) Eval Time (s)     19.69620075682178
Sample Time (s)              6.247810335829854
Epoch Time (s)               174.30606353702024
Total Train Time (s)         67074.45536735049
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 02:58:31.926497 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #396 | Epoch Duration: 174.3982720375061
2020-01-12 02:58:31.926631 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8126377
Z variance train             0.005643573
KL Divergence                22.57146
KL Loss                      2.2571461
QF Loss                      457.05396
VF Loss                      135.9136
Policy Loss                  -1461.4846
Q Predictions Mean           1454.4973
Q Predictions Std            370.29025
Q Predictions Max            1979.769
Q Predictions Min            401.32275
V Predictions Mean           1464.7146
V Predictions Std            371.14734
V Predictions Max            1975.3882
V Predictions Min            410.06592
Log Pis Mean                 1.4818687
Log Pis Std                  3.0446546
Log Pis Max                  11.837296
Log Pis Min                  -5.9625864
Policy mu Mean               0.0002398286
Policy mu Std                0.72164416
Policy mu Max                2.439536
Policy mu Min                -3.3988566
Policy log std Mean          -1.0731837
Policy log std Std           0.30817616
Policy log std Max           -0.11557984
Policy log std Min           -2.7704158
Z mean eval                  0.74008524
Z variance eval              0.005097526
total_rewards                [5096.76114961 1347.70628799 5047.84713948 4090.57978281 3699.96222863
 5002.22668169 5127.81802596 5102.42371009 1070.86437663 4871.55139939]
total_rewards_mean           4045.7740782266046
total_rewards_std            1491.442673397451
total_rewards_max            5127.818025962005
total_rewards_min            1070.8643766312027
Number of train steps total  1592000
Number of env steps total    2736555
Number of rollouts total     0
Train Time (s)               146.28058337699622
(Previous) Eval Time (s)     17.051648961845785
Sample Time (s)              7.37910999218002
Epoch Time (s)               170.71134233102202
Total Train Time (s)         67245.25618702685
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:01:22.732091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #397 | Epoch Duration: 170.80534839630127
2020-01-12 03:01:22.732280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.743568
Z variance train             0.005093875
KL Divergence                20.850895
KL Loss                      2.0850894
QF Loss                      662.1229
VF Loss                      220.1666
Policy Loss                  -1417.0077
Q Predictions Mean           1408.2081
Q Predictions Std            333.54147
Q Predictions Max            1979.2705
Q Predictions Min            181.61569
V Predictions Mean           1409.9331
V Predictions Std            334.84564
V Predictions Max            1922.1802
V Predictions Min            338.79
Log Pis Mean                 1.3696141
Log Pis Std                  3.0990934
Log Pis Max                  14.623285
Log Pis Min                  -6.2549663
Policy mu Mean               0.040769484
Policy mu Std                0.6869657
Policy mu Max                2.430766
Policy mu Min                -2.4681678
Policy log std Mean          -1.1115707
Policy log std Std           0.3015694
Policy log std Max           -0.15113711
Policy log std Min           -2.6663842
Z mean eval                  0.73047966
Z variance eval              0.0038166787
total_rewards                [5138.94714739 5048.24463472 5000.27142192 5084.23420026 5019.43580263
 4752.25726574 5099.0138889  5027.77217641 5161.39458176 5134.5218163 ]
total_rewards_mean           5046.6092936019795
total_rewards_std            111.12094900244031
total_rewards_max            5161.394581764131
total_rewards_min            4752.257265737951
Number of train steps total  1596000
Number of env steps total    2748579
Number of rollouts total     0
Train Time (s)               145.94727589190006
(Previous) Eval Time (s)     21.2755510751158
Sample Time (s)              6.334518387448043
Epoch Time (s)               173.5573453544639
Total Train Time (s)         67418.90174405696
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:04:16.384497 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #398 | Epoch Duration: 173.65201210975647
2020-01-12 03:04:16.384785 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #398 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73346347
Z variance train             0.0038138952
KL Divergence                21.515509
KL Loss                      2.151551
QF Loss                      384.32773
VF Loss                      82.02098
Policy Loss                  -1456.6674
Q Predictions Mean           1448.5095
Q Predictions Std            310.39017
Q Predictions Max            1949.7749
Q Predictions Min            378.0573
V Predictions Mean           1458.118
V Predictions Std            311.5511
V Predictions Max            1933.3667
V Predictions Min            380.82977
Log Pis Mean                 1.7290857
Log Pis Std                  3.023264
Log Pis Max                  11.515589
Log Pis Min                  -8.024206
Policy mu Mean               -0.039336544
Policy mu Std                0.69747937
Policy mu Max                2.1204267
Policy mu Min                -2.5819616
Policy log std Mean          -1.1391015
Policy log std Std           0.31149155
Policy log std Max           -0.2546749
Policy log std Min           -2.722652
Z mean eval                  0.66682005
Z variance eval              0.0028726268
total_rewards                [4930.57970036  105.38716225 4997.85041513 2013.11088824 1400.1991825
 4958.70321437 5128.55287255 3518.99346867 4784.73963858 4834.54164097]
total_rewards_mean           3667.265818362662
total_rewards_std            1742.5743093445046
total_rewards_max            5128.552872547844
total_rewards_min            105.38716225486635
Number of train steps total  1600000
Number of env steps total    2758216
Number of rollouts total     0
Train Time (s)               147.99738539382815
(Previous) Eval Time (s)     15.42835337901488
Sample Time (s)              7.308953108731657
Epoch Time (s)               170.7346918815747
Total Train Time (s)         67589.72699274216
Epoch                        399
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:07:07.213418 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #399 | Epoch Duration: 170.82845497131348
2020-01-12 03:07:07.213599 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.67170113
Z variance train             0.0028692812
KL Divergence                21.819887
KL Loss                      2.1819887
QF Loss                      502.2466
VF Loss                      87.95842
Policy Loss                  -1440.2034
Q Predictions Mean           1432.8313
Q Predictions Std            334.93112
Q Predictions Max            1954.7767
Q Predictions Min            -69.33951
V Predictions Mean           1435.7339
V Predictions Std            334.80865
V Predictions Max            1946.4587
V Predictions Min            3.3822138
Log Pis Mean                 1.3463216
Log Pis Std                  3.0110984
Log Pis Max                  21.21548
Log Pis Min                  -6.5403514
Policy mu Mean               -0.038091213
Policy mu Std                0.69465846
Policy mu Max                2.6796412
Policy mu Min                -2.735403
Policy log std Mean          -1.0999515
Policy log std Std           0.31606436
Policy log std Max           -0.071917534
Policy log std Min           -3.7375307
Z mean eval                  0.71438277
Z variance eval              0.021146294
total_rewards                [3606.20444464 4913.34349805 5046.71189354 4930.56963021 5075.7402218
 5098.94946987 5023.69281279  737.50979367 5060.88547558 5140.6419392 ]
total_rewards_mean           4463.424917934626
total_rewards_std            1314.779398728278
total_rewards_max            5140.641939203874
total_rewards_min            737.5097936718588
Number of train steps total  1604000
Number of env steps total    2768905
Number of rollouts total     0
Train Time (s)               147.11370355589315
(Previous) Eval Time (s)     20.343438003212214
Sample Time (s)              7.523493902757764
Epoch Time (s)               174.98063546186313
Total Train Time (s)         67764.80296825059
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:10:02.291932 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #400 | Epoch Duration: 175.07820415496826
2020-01-12 03:10:02.292075 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7177113
Z variance train             0.020536436
KL Divergence                17.660406
KL Loss                      1.7660407
QF Loss                      34896.9
VF Loss                      134.17026
Policy Loss                  -1447.8492
Q Predictions Mean           1441.1213
Q Predictions Std            300.1311
Q Predictions Max            1980.616
Q Predictions Min            400.29865
V Predictions Mean           1454.8301
V Predictions Std            301.69135
V Predictions Max            1981.1309
V Predictions Min            398.5491
Log Pis Mean                 1.8858241
Log Pis Std                  3.099018
Log Pis Max                  11.512299
Log Pis Min                  -6.4845085
Policy mu Mean               -0.090477385
Policy mu Std                0.72512656
Policy mu Max                2.4788496
Policy mu Min                -2.671973
Policy log std Mean          -1.1185715
Policy log std Std           0.30034798
Policy log std Max           -0.17981517
Policy log std Min           -2.5034842
Z mean eval                  0.91745174
Z variance eval              0.020620113
total_rewards                [4623.99093742 2967.74801124  954.10007673  775.53670797 2030.04294728
 2111.18742897  614.17224833 4561.45676506 2460.93935132 1526.22459583]
total_rewards_mean           2262.5399070154886
total_rewards_std            1365.9276110761746
total_rewards_max            4623.99093742028
total_rewards_min            614.1722483313564
Number of train steps total  1608000
Number of env steps total    2778818
Number of rollouts total     0
Train Time (s)               150.71942071663216
(Previous) Eval Time (s)     12.127068034373224
Sample Time (s)              7.2549362746067345
Epoch Time (s)               170.10142502561212
Total Train Time (s)         67934.99341393448
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:12:52.485351 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #401 | Epoch Duration: 170.19312357902527
2020-01-12 03:12:52.485566 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91849643
Z variance train             0.020624837
KL Divergence                22.09441
KL Loss                      2.209441
QF Loss                      22129.285
VF Loss                      137.79228
Policy Loss                  -1581.3137
Q Predictions Mean           1568.3201
Q Predictions Std            334.07376
Q Predictions Max            2028.35
Q Predictions Min            -65.46024
V Predictions Mean           1578.7528
V Predictions Std            312.43436
V Predictions Max            2041.5111
V Predictions Min            430.8729
Log Pis Mean                 1.4953024
Log Pis Std                  3.2774942
Log Pis Max                  15.657244
Log Pis Min                  -8.410081
Policy mu Mean               0.07243295
Policy mu Std                0.7291982
Policy mu Max                3.0521436
Policy mu Min                -2.9643693
Policy log std Mean          -1.1031976
Policy log std Std           0.30086094
Policy log std Max           -0.17348099
Policy log std Min           -2.490458
Z mean eval                  0.7176725
Z variance eval              0.026901778
total_rewards                [ 118.07206478 3319.64883853 5060.35220908  420.94135331 3761.68638904
  222.0232439  4994.4685417  5120.11015955 4865.20362887 5093.63966633]
total_rewards_mean           3297.614609508684
total_rewards_std            2074.8720121770384
total_rewards_max            5120.110159553675
total_rewards_min            118.07206477597045
Number of train steps total  1612000
Number of env steps total    2789229
Number of rollouts total     0
Train Time (s)               146.6551733831875
(Previous) Eval Time (s)     13.925467865075916
Sample Time (s)              7.5184118817560375
Epoch Time (s)               168.09905313001946
Total Train Time (s)         68103.18379193358
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:15:40.678956 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #402 | Epoch Duration: 168.1932601928711
2020-01-12 03:15:40.679161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.71689606
Z variance train             0.02670208
KL Divergence                18.983326
KL Loss                      1.8983326
QF Loss                      940.1367
VF Loss                      142.81642
Policy Loss                  -1453.0892
Q Predictions Mean           1445.032
Q Predictions Std            313.86966
Q Predictions Max            1976.3899
Q Predictions Min            378.74213
V Predictions Mean           1457.6896
V Predictions Std            309.3136
V Predictions Max            1966.641
V Predictions Min            382.0165
Log Pis Mean                 1.5674272
Log Pis Std                  3.1787558
Log Pis Max                  12.184686
Log Pis Min                  -6.858984
Policy mu Mean               -0.02190898
Policy mu Std                0.7396747
Policy mu Max                2.653219
Policy mu Min                -3.099168
Policy log std Mean          -1.1133704
Policy log std Std           0.3032084
Policy log std Max           -0.30189168
Policy log std Min           -2.787762
Z mean eval                  0.87966603
Z variance eval              0.024657533
total_rewards                [4586.2548442  2952.80882022   39.95782505 4455.10216723  639.4879753
 1641.29174915 3394.78842488 4334.89158309 4763.75831313 2142.06710605]
total_rewards_mean           2895.040880829911
total_rewards_std            1627.5819509981873
total_rewards_max            4763.758313128728
total_rewards_min            39.9578250482586
Number of train steps total  1616000
Number of env steps total    2799244
Number of rollouts total     0
Train Time (s)               144.3509547119029
(Previous) Eval Time (s)     13.435003852006048
Sample Time (s)              7.372791329398751
Epoch Time (s)               165.1587498933077
Total Train Time (s)         68268.43049683655
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:18:25.935259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #403 | Epoch Duration: 165.2559597492218
2020-01-12 03:18:25.935448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.879024
Z variance train             0.024638347
KL Divergence                19.295897
KL Loss                      1.9295896
QF Loss                      719.0486
VF Loss                      102.33582
Policy Loss                  -1561.4048
Q Predictions Mean           1554.0337
Q Predictions Std            349.8584
Q Predictions Max            2056.7144
Q Predictions Min            433.40787
V Predictions Mean           1559.7921
V Predictions Std            347.8161
V Predictions Max            2039.8096
V Predictions Min            429.8111
Log Pis Mean                 1.307968
Log Pis Std                  3.1781838
Log Pis Max                  13.221403
Log Pis Min                  -9.150104
Policy mu Mean               -0.0017917659
Policy mu Std                0.71588004
Policy mu Max                2.6039872
Policy mu Min                -2.6549895
Policy log std Mean          -1.07139
Policy log std Std           0.31144896
Policy log std Max           -0.23697233
Policy log std Min           -2.7273917
Z mean eval                  0.72308946
Z variance eval              0.002538824
total_rewards                [5028.75845471 5019.59114665 1767.03625173 1974.64013763 2243.20531231
 5195.13144051 5079.65109354 5287.93339017   38.01649096 5166.13871077]
total_rewards_mean           3680.010242899078
total_rewards_std            1858.990687064592
total_rewards_max            5287.933390168082
total_rewards_min            38.016490957191415
Number of train steps total  1620000
Number of env steps total    2810800
Number of rollouts total     0
Train Time (s)               146.575421505142
(Previous) Eval Time (s)     17.79077014606446
Sample Time (s)              8.287510800175369
Epoch Time (s)               172.65370245138183
Total Train Time (s)         68441.17512616795
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:21:18.686259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #404 | Epoch Duration: 172.75067973136902
2020-01-12 03:21:18.686424 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7204145
Z variance train             0.00253561
KL Divergence                22.480145
KL Loss                      2.2480145
QF Loss                      453.112
VF Loss                      157.15369
Policy Loss                  -1520.6312
Q Predictions Mean           1513.6467
Q Predictions Std            318.5298
Q Predictions Max            1973.5372
Q Predictions Min            420.99033
V Predictions Mean           1513.106
V Predictions Std            314.2319
V Predictions Max            1947.16
V Predictions Min            407.07956
Log Pis Mean                 1.7744161
Log Pis Std                  3.1302211
Log Pis Max                  16.212934
Log Pis Min                  -7.8706656
Policy mu Mean               -0.04392327
Policy mu Std                0.7123841
Policy mu Max                2.4971523
Policy mu Min                -2.7787843
Policy log std Mean          -1.1301999
Policy log std Std           0.2972784
Policy log std Max           -0.21149337
Policy log std Min           -2.719478
Z mean eval                  0.83889645
Z variance eval              0.0020976537
total_rewards                [5212.88381515 5120.83494982 5272.53766668 1951.50366677 5247.32908583
 5087.13525653 5238.60332303 5030.5703986  5098.83099933 3490.54993631]
total_rewards_mean           4675.077909806752
total_rewards_std            1038.5865884080085
total_rewards_max            5272.537666682183
total_rewards_min            1951.503666774286
Number of train steps total  1624000
Number of env steps total    2821105
Number of rollouts total     0
Train Time (s)               144.84953891811892
(Previous) Eval Time (s)     22.17181507591158
Sample Time (s)              6.402410811278969
Epoch Time (s)               173.42376480530947
Total Train Time (s)         68614.68194012204
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:24:12.196975 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #405 | Epoch Duration: 173.5104365348816
2020-01-12 03:24:12.197104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84058523
Z variance train             0.0020593237
KL Divergence                22.144573
KL Loss                      2.2144573
QF Loss                      6442.4824
VF Loss                      214.59134
Policy Loss                  -1487.1816
Q Predictions Mean           1477.0875
Q Predictions Std            300.76135
Q Predictions Max            1971.4149
Q Predictions Min            23.311666
V Predictions Mean           1481.72
V Predictions Std            286.53418
V Predictions Max            1948.777
V Predictions Min            364.9577
Log Pis Mean                 1.8584789
Log Pis Std                  3.007438
Log Pis Max                  16.237732
Log Pis Min                  -6.7261252
Policy mu Mean               -0.059479598
Policy mu Std                0.7253486
Policy mu Max                2.636671
Policy mu Min                -3.900075
Policy log std Mean          -1.1407237
Policy log std Std           0.3246822
Policy log std Max           0.49943805
Policy log std Min           -2.8738458
Z mean eval                  0.56018794
Z variance eval              0.0059634396
total_rewards                [4707.5274545  4722.14316278 5002.89796503 4909.59847686 4928.07234866
 4231.33950641 5010.51037403 4963.91695538 4912.70883442 4905.59060763]
total_rewards_mean           4829.430568570662
total_rewards_std            222.24851237479055
total_rewards_max            5010.5103740324685
total_rewards_min            4231.339506409353
Number of train steps total  1628000
Number of env steps total    2832180
Number of rollouts total     0
Train Time (s)               145.26609877543524
(Previous) Eval Time (s)     22.789640955161303
Sample Time (s)              7.701411138288677
Epoch Time (s)               175.75715086888522
Total Train Time (s)         68790.5249032965
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:27:08.043947 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #406 | Epoch Duration: 175.8467252254486
2020-01-12 03:27:08.044193 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.55712664
Z variance train             0.0059891827
KL Divergence                18.388342
KL Loss                      1.8388342
QF Loss                      443.03113
VF Loss                      133.08653
Policy Loss                  -1364.8772
Q Predictions Mean           1360.9786
Q Predictions Std            330.21774
Q Predictions Max            1888.131
Q Predictions Min            331.69006
V Predictions Mean           1367.3958
V Predictions Std            330.47687
V Predictions Max            1888.3372
V Predictions Min            332.86816
Log Pis Mean                 1.8714064
Log Pis Std                  2.7457044
Log Pis Max                  10.732697
Log Pis Min                  -5.7682776
Policy mu Mean               -0.0855383
Policy mu Std                0.67603874
Policy mu Max                1.9501613
Policy mu Min                -2.451242
Policy log std Mean          -1.1557789
Policy log std Std           0.31437847
Policy log std Max           -0.19639337
Policy log std Min           -2.6679373
Z mean eval                  0.8054611
Z variance eval              0.0022740695
total_rewards                [5308.20290416 3705.27183886 4959.50714358 3013.11869155  198.17268876
 4935.80346952 5406.32797856 1033.27619391 3189.88982462 5322.91638164]
total_rewards_mean           3707.248711515507
total_rewards_std            1770.622174431701
total_rewards_max            5406.327978560865
total_rewards_min            198.17268876006094
Number of train steps total  1632000
Number of env steps total    2841428
Number of rollouts total     0
Train Time (s)               148.17863484006375
(Previous) Eval Time (s)     17.7250909130089
Sample Time (s)              7.198150406591594
Epoch Time (s)               173.10187615966424
Total Train Time (s)         68963.71787828393
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:30:01.241346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #407 | Epoch Duration: 173.19701099395752
2020-01-12 03:30:01.241532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8109811
Z variance train             0.002274802
KL Divergence                23.191704
KL Loss                      2.3191705
QF Loss                      439.901
VF Loss                      204.94989
Policy Loss                  -1560.5245
Q Predictions Mean           1556.9961
Q Predictions Std            300.05792
Q Predictions Max            2037.8192
Q Predictions Min            432.74902
V Predictions Mean           1570.0193
V Predictions Std            296.89203
V Predictions Max            2035.0565
V Predictions Min            448.1795
Log Pis Mean                 1.5733973
Log Pis Std                  2.8645184
Log Pis Max                  12.9334755
Log Pis Min                  -8.2367115
Policy mu Mean               -0.01685827
Policy mu Std                0.69476134
Policy mu Max                3.6784575
Policy mu Min                -2.6184924
Policy log std Mean          -1.1148494
Policy log std Std           0.2936313
Policy log std Max           -0.27872908
Policy log std Min           -2.557632
Z mean eval                  0.79611015
Z variance eval              0.0009710025
total_rewards                [4754.21178808 5083.86728979   91.14653304 4959.9040745    38.10329101
 5328.68402035 1830.28178506 5075.04473222 4794.51106627 2940.78354074]
total_rewards_mean           3489.6538121058547
total_rewards_std            2010.4286875137134
total_rewards_max            5328.684020352491
total_rewards_min            38.10329100783704
Number of train steps total  1636000
Number of env steps total    2851826
Number of rollouts total     0
Train Time (s)               145.5702260080725
(Previous) Eval Time (s)     19.249406876042485
Sample Time (s)              7.140501058660448
Epoch Time (s)               171.96013394277543
Total Train Time (s)         69135.76754698856
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:32:53.293730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #408 | Epoch Duration: 172.05207443237305
2020-01-12 03:32:53.293916 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7967931
Z variance train             0.0009707602
KL Divergence                24.63247
KL Loss                      2.463247
QF Loss                      467.8899
VF Loss                      185.51262
Policy Loss                  -1590.2113
Q Predictions Mean           1581.3126
Q Predictions Std            295.88965
Q Predictions Max            2034.1354
Q Predictions Min            421.68225
V Predictions Mean           1597.9819
V Predictions Std            295.80246
V Predictions Max            2047.3743
V Predictions Min            428.46936
Log Pis Mean                 1.6264764
Log Pis Std                  3.1658864
Log Pis Max                  14.388968
Log Pis Min                  -8.72247
Policy mu Mean               -0.033090435
Policy mu Std                0.71285576
Policy mu Max                2.263373
Policy mu Min                -2.5300274
Policy log std Mean          -1.1305561
Policy log std Std           0.3096807
Policy log std Max           -0.14727318
Policy log std Min           -2.4809427
Z mean eval                  0.8361312
Z variance eval              0.0009345895
total_rewards                [ 458.74975792  130.53328778 5106.87608501   41.63628226 3108.15495246
 -219.54253589 4834.77832405 5266.10138492 1986.3483592   636.83834917]
total_rewards_mean           2135.047424687661
total_rewards_std            2142.241966029483
total_rewards_max            5266.101384924528
total_rewards_min            -219.54253589224766
Number of train steps total  1640000
Number of env steps total    2863963
Number of rollouts total     0
Train Time (s)               144.6834209128283
(Previous) Eval Time (s)     13.23227471113205
Sample Time (s)              7.721024237573147
Epoch Time (s)               165.6367198615335
Total Train Time (s)         69301.49142276682
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:35:39.020646 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #409 | Epoch Duration: 165.72663378715515
2020-01-12 03:35:39.020778 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8367103
Z variance train             0.0009357518
KL Divergence                23.819702
KL Loss                      2.3819702
QF Loss                      2446.8938
VF Loss                      143.24178
Policy Loss                  -1545.0258
Q Predictions Mean           1538.8894
Q Predictions Std            307.68515
Q Predictions Max            2015.0759
Q Predictions Min            403.24182
V Predictions Mean           1552.321
V Predictions Std            307.64505
V Predictions Max            2012.4075
V Predictions Min            407.5663
Log Pis Mean                 1.6404982
Log Pis Std                  2.9125462
Log Pis Max                  12.572451
Log Pis Min                  -7.032861
Policy mu Mean               0.020629298
Policy mu Std                0.7202593
Policy mu Max                2.4605598
Policy mu Min                -2.8771782
Policy log std Mean          -1.107391
Policy log std Std           0.29068506
Policy log std Max           -0.16032362
Policy log std Min           -2.7209063
Z mean eval                  0.9469188
Z variance eval              0.0033660694
total_rewards                [ 555.21497154 4478.265852   4935.05518886 2099.8069535  4801.77802304
  619.65265461  712.74715873 1158.70839751 4699.23163933  798.64149456]
total_rewards_mean           2485.91023336849
total_rewards_std            1879.942878807526
total_rewards_max            4935.055188859709
total_rewards_min            555.2149715412861
Number of train steps total  1644000
Number of env steps total    2874971
Number of rollouts total     0
Train Time (s)               144.9728096537292
(Previous) Eval Time (s)     13.089803349226713
Sample Time (s)              7.1973643116652966
Epoch Time (s)               165.2599773146212
Total Train Time (s)         69466.84410400223
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:38:24.379269 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #410 | Epoch Duration: 165.35836124420166
2020-01-12 03:38:24.379537 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9477048
Z variance train             0.0033555713
KL Divergence                22.977476
KL Loss                      2.2977476
QF Loss                      21423.229
VF Loss                      253.1627
Policy Loss                  -1563.0986
Q Predictions Mean           1557.3826
Q Predictions Std            349.31323
Q Predictions Max            2084.678
Q Predictions Min            232.91882
V Predictions Mean           1563.5527
V Predictions Std            343.41507
V Predictions Max            2071.7454
V Predictions Min            430.7131
Log Pis Mean                 1.9809996
Log Pis Std                  3.4999788
Log Pis Max                  22.355545
Log Pis Min                  -6.162012
Policy mu Mean               -0.009021029
Policy mu Std                0.77782834
Policy mu Max                3.2654
Policy mu Min                -3.2972353
Policy log std Mean          -1.0956068
Policy log std Std           0.3410672
Policy log std Max           0.28687382
Policy log std Min           -3.0265546
Z mean eval                  0.7571994
Z variance eval              0.014816704
total_rewards                [ 878.90887228  294.99995828 2330.02533383  149.18450538 4115.32527563
 1556.78890436 -115.89142205   80.31405267    7.54768428 1274.58493396]
total_rewards_mean           1057.1788098636637
total_rewards_std            1270.3742834701366
total_rewards_max            4115.3252756315005
total_rewards_min            -115.89142204620902
Number of train steps total  1648000
Number of env steps total    2883746
Number of rollouts total     0
Train Time (s)               146.35093718674034
(Previous) Eval Time (s)     10.226900428999215
Sample Time (s)              8.038410728797317
Epoch Time (s)               164.61624834453687
Total Train Time (s)         69631.55012261588
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:41:09.087342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #411 | Epoch Duration: 164.70762729644775
2020-01-12 03:41:09.087469 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74419934
Z variance train             0.014885962
KL Divergence                21.69435
KL Loss                      2.169435
QF Loss                      37252.195
VF Loss                      114.98615
Policy Loss                  -1539.4126
Q Predictions Mean           1536.2699
Q Predictions Std            309.55026
Q Predictions Max            2025.0361
Q Predictions Min            430.77985
V Predictions Mean           1545.5278
V Predictions Std            308.49414
V Predictions Max            2018.5308
V Predictions Min            438.96768
Log Pis Mean                 2.0261557
Log Pis Std                  3.198274
Log Pis Max                  13.613819
Log Pis Min                  -4.9688196
Policy mu Mean               -0.049113676
Policy mu Std                0.71129614
Policy mu Max                2.4523268
Policy mu Min                -2.5289955
Policy log std Mean          -1.1521688
Policy log std Std           0.31868175
Policy log std Max           -0.14024496
Policy log std Min           -2.5947804
Z mean eval                  1.1542828
Z variance eval              0.012072579
total_rewards                [1159.20104595  878.40085287 5076.90918945 3853.14950849 2111.57729636
 1268.03318109  976.22358964  855.70895868 3473.67307292   22.36818211]
total_rewards_mean           1967.5244877564182
total_rewards_std            1544.1631771168793
total_rewards_max            5076.909189451334
total_rewards_min            22.368182113957843
Number of train steps total  1652000
Number of env steps total    2894347
Number of rollouts total     0
Train Time (s)               145.91106817917898
(Previous) Eval Time (s)     12.537192672025412
Sample Time (s)              6.960133398417383
Epoch Time (s)               165.40839424962178
Total Train Time (s)         69797.04571133805
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:43:54.587024 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #412 | Epoch Duration: 165.49944138526917
2020-01-12 03:43:54.587211 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1385765
Z variance train             0.010924558
KL Divergence                23.721521
KL Loss                      2.372152
QF Loss                      575.83154
VF Loss                      159.9451
Policy Loss                  -1644.465
Q Predictions Mean           1633.4839
Q Predictions Std            321.4805
Q Predictions Max            2106.3975
Q Predictions Min            374.69406
V Predictions Mean           1639.0237
V Predictions Std            313.05048
V Predictions Max            2078.268
V Predictions Min            390.35
Log Pis Mean                 1.8068756
Log Pis Std                  3.5623553
Log Pis Max                  30.197454
Log Pis Min                  -8.851902
Policy mu Mean               0.0042422432
Policy mu Std                0.7767693
Policy mu Max                6.19961
Policy mu Min                -2.9501593
Policy log std Mean          -1.0940449
Policy log std Std           0.34941706
Policy log std Max           0.6158017
Policy log std Min           -2.794778
Z mean eval                  1.2338499
Z variance eval              0.004646658
total_rewards                [2643.75290384 1572.21779604 3165.26841095 4735.05146555 4749.54193397
 4773.92404331 4731.8769972  3913.18749844 4883.06351701 4703.20281816]
total_rewards_mean           3987.1087384468724
total_rewards_std            1093.0322738049406
total_rewards_max            4883.063517005675
total_rewards_min            1572.2177960438084
Number of train steps total  1656000
Number of env steps total    2905346
Number of rollouts total     0
Train Time (s)               145.98363327980042
(Previous) Eval Time (s)     21.526000387966633
Sample Time (s)              7.131125876214355
Epoch Time (s)               174.6407595439814
Total Train Time (s)         69971.84721312346
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:46:49.396819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #413 | Epoch Duration: 174.80946254730225
2020-01-12 03:46:49.397003 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2320383
Z variance train             0.004642927
KL Divergence                22.947863
KL Loss                      2.2947862
QF Loss                      528.5543
VF Loss                      139.95471
Policy Loss                  -1578.3444
Q Predictions Mean           1567.4282
Q Predictions Std            327.95804
Q Predictions Max            2038.8256
Q Predictions Min            400.11633
V Predictions Mean           1570.4304
V Predictions Std            328.17126
V Predictions Max            2025.9736
V Predictions Min            386.0583
Log Pis Mean                 1.886134
Log Pis Std                  2.9622195
Log Pis Max                  13.427475
Log Pis Min                  -7.002635
Policy mu Mean               -0.14815854
Policy mu Std                0.75389796
Policy mu Max                2.788493
Policy mu Min                -2.3579924
Policy log std Mean          -1.0861225
Policy log std Std           0.31721935
Policy log std Max           -0.09631348
Policy log std Min           -2.713345
Z mean eval                  0.70260435
Z variance eval              0.0072122514
total_rewards                [4954.39637372 5103.93353972  673.84529889 5153.62904841 4991.98145491
 1922.94411195 4997.71824288 4956.49289764 1482.04765272 1219.0684029 ]
total_rewards_mean           3545.605702375108
total_rewards_std            1836.8761061528207
total_rewards_max            5153.62904841442
total_rewards_min            673.8452988879856
Number of train steps total  1660000
Number of env steps total    2915625
Number of rollouts total     0
Train Time (s)               144.91871770936996
(Previous) Eval Time (s)     16.90781654184684
Sample Time (s)              7.276261904742569
Epoch Time (s)               169.10279615595937
Total Train Time (s)         70141.0395877217
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:49:38.593915 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #414 | Epoch Duration: 169.19677567481995
2020-01-12 03:49:38.594098 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6978456
Z variance train             0.007171914
KL Divergence                19.97446
KL Loss                      1.9974461
QF Loss                      6556.0303
VF Loss                      124.65078
Policy Loss                  -1581.6227
Q Predictions Mean           1574.5433
Q Predictions Std            328.42285
Q Predictions Max            2074.0984
Q Predictions Min            439.5237
V Predictions Mean           1580.0294
V Predictions Std            324.02853
V Predictions Max            2056.8506
V Predictions Min            452.59036
Log Pis Mean                 1.4374309
Log Pis Std                  2.5242841
Log Pis Max                  8.2096615
Log Pis Min                  -6.600837
Policy mu Mean               -0.0065326868
Policy mu Std                0.68471014
Policy mu Max                2.1148295
Policy mu Min                -2.6078548
Policy log std Mean          -1.1068778
Policy log std Std           0.28277782
Policy log std Max           -0.27180505
Policy log std Min           -2.5482316
Z mean eval                  0.75428313
Z variance eval              0.0018059714
total_rewards                [5320.00047972 2746.40700141 4932.30399068 2620.06159801 5144.47040375
 2258.22635049 4883.32327179 4540.26711582 4921.23855992 5061.14821667]
total_rewards_mean           4242.744698827185
total_rewards_std            1135.276179656244
total_rewards_max            5320.000479723347
total_rewards_min            2258.2263504911393
Number of train steps total  1664000
Number of env steps total    2925681
Number of rollouts total     0
Train Time (s)               145.60921049304307
(Previous) Eval Time (s)     18.44629265507683
Sample Time (s)              8.207994858268648
Epoch Time (s)               172.26349800638855
Total Train Time (s)         70313.39074959466
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:52:30.953749 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #415 | Epoch Duration: 172.35949730873108
2020-01-12 03:52:30.953996 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74223703
Z variance train             0.0018188494
KL Divergence                22.50549
KL Loss                      2.250549
QF Loss                      482.741
VF Loss                      83.747505
Policy Loss                  -1582.3625
Q Predictions Mean           1577.0046
Q Predictions Std            322.07193
Q Predictions Max            2075.9878
Q Predictions Min            438.03482
V Predictions Mean           1585.1029
V Predictions Std            322.87982
V Predictions Max            2072.0847
V Predictions Min            436.6774
Log Pis Mean                 1.870609
Log Pis Std                  3.2432125
Log Pis Max                  14.753156
Log Pis Min                  -5.1867256
Policy mu Mean               -0.029164173
Policy mu Std                0.723862
Policy mu Max                2.79405
Policy mu Min                -2.97456
Policy log std Mean          -1.1395876
Policy log std Std           0.3336326
Policy log std Max           -0.1891582
Policy log std Min           -2.710427
Z mean eval                  0.8977364
Z variance eval              0.011171386
total_rewards                [4849.58719567 5218.56671907 4842.69979921  574.02431532 1171.73005515
 4958.22249628 5155.75373763 4939.8611909  3063.71944056 4925.91628824]
total_rewards_mean           3970.0081238035737
total_rewards_std            1658.7799649566286
total_rewards_max            5218.56671907433
total_rewards_min            574.02431532371
Number of train steps total  1668000
Number of env steps total    2934943
Number of rollouts total     0
Train Time (s)               146.0237389788963
(Previous) Eval Time (s)     19.471093044616282
Sample Time (s)              7.216885422356427
Epoch Time (s)               172.711717445869
Total Train Time (s)         70486.19075849699
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:55:23.756281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #416 | Epoch Duration: 172.80211901664734
2020-01-12 03:55:23.756418 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8876691
Z variance train             0.011269845
KL Divergence                18.899502
KL Loss                      1.8899502
QF Loss                      18267.164
VF Loss                      101.335495
Policy Loss                  -1504.8052
Q Predictions Mean           1497.8798
Q Predictions Std            303.95416
Q Predictions Max            1965.047
Q Predictions Min            401.64325
V Predictions Mean           1509.5474
V Predictions Std            302.6574
V Predictions Max            1972.8575
V Predictions Min            401.27628
Log Pis Mean                 1.519271
Log Pis Std                  2.8410313
Log Pis Max                  10.827694
Log Pis Min                  -6.9420433
Policy mu Mean               -0.05061402
Policy mu Std                0.68136424
Policy mu Max                2.4863715
Policy mu Min                -2.5633616
Policy log std Mean          -1.1436596
Policy log std Std           0.31463125
Policy log std Max           0.2539884
Policy log std Min           -2.6451387
Z mean eval                  0.6520039
Z variance eval              0.054286398
total_rewards                [1932.99773851 2086.00970709 2989.68682352 4920.30648084 5240.65875782
 4682.54676918 1597.89722035 4780.98541065 5138.44670943 5097.98006363]
total_rewards_mean           3846.751568102841
total_rewards_std            1430.226012079891
total_rewards_max            5240.658757820878
total_rewards_min            1597.8972203494232
Number of train steps total  1672000
Number of env steps total    2946125
Number of rollouts total     0
Train Time (s)               145.07525118999183
(Previous) Eval Time (s)     17.465798298828304
Sample Time (s)              7.154764585196972
Epoch Time (s)               169.6958140740171
Total Train Time (s)         70655.99779767031
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 03:58:13.568730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #417 | Epoch Duration: 169.81218957901
2020-01-12 03:58:13.568962 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.64225394
Z variance train             0.054449856
KL Divergence                17.631552
KL Loss                      1.7631552
QF Loss                      38007.28
VF Loss                      199.65028
Policy Loss                  -1532.6261
Q Predictions Mean           1526.394
Q Predictions Std            327.50928
Q Predictions Max            2014.5016
Q Predictions Min            399.532
V Predictions Mean           1524.0303
V Predictions Std            325.06793
V Predictions Max            2002.1306
V Predictions Min            387.30386
Log Pis Mean                 1.3022639
Log Pis Std                  2.9717152
Log Pis Max                  11.153976
Log Pis Min                  -7.1033335
Policy mu Mean               -0.050320536
Policy mu Std                0.64025897
Policy mu Max                2.4114416
Policy mu Min                -2.8184373
Policy log std Mean          -1.1743121
Policy log std Std           0.30587506
Policy log std Max           -0.19670594
Policy log std Min           -2.669764
Z mean eval                  0.87316036
Z variance eval              0.001428975
total_rewards                [4823.18297099 4978.67585731 4176.07930561 2345.47349465 4981.00900277
 5247.84224318   56.06769751 4631.79640019 5216.77777608  919.33624821]
total_rewards_mean           3737.62409964869
total_rewards_std            1820.9827653920868
total_rewards_max            5247.842243180339
total_rewards_min            56.06769751190819
Number of train steps total  1676000
Number of env steps total    2958125
Number of rollouts total     0
Train Time (s)               145.79775725817308
(Previous) Eval Time (s)     21.16659086709842
Sample Time (s)              7.170896745286882
Epoch Time (s)               174.13524487055838
Total Train Time (s)         70830.21868547704
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:01:07.791671 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #418 | Epoch Duration: 174.22255110740662
2020-01-12 04:01:07.791800 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8697649
Z variance train             0.0014303534
KL Divergence                23.890364
KL Loss                      2.3890364
QF Loss                      825.71747
VF Loss                      118.86955
Policy Loss                  -1577.2601
Q Predictions Mean           1569.853
Q Predictions Std            339.77637
Q Predictions Max            2070.5928
Q Predictions Min            398.61548
V Predictions Mean           1581.3579
V Predictions Std            338.46527
V Predictions Max            2076.295
V Predictions Min            420.63647
Log Pis Mean                 1.5590284
Log Pis Std                  3.316954
Log Pis Max                  17.54594
Log Pis Min                  -7.233261
Policy mu Mean               -0.098209545
Policy mu Std                0.6934965
Policy mu Max                2.6808906
Policy mu Min                -4.3422666
Policy log std Mean          -1.1498156
Policy log std Std           0.31770518
Policy log std Max           0.09974587
Policy log std Min           -2.5661762
Z mean eval                  0.6354225
Z variance eval              0.048039716
total_rewards                [1355.46955165  202.79720718 5169.18911377 3090.02206147 5213.83483793
 4919.85217168 5069.39455118 5118.46765667 5108.74351668 1147.22445658]
total_rewards_mean           3639.499512478961
total_rewards_std            1907.6028277118153
total_rewards_max            5213.834837930777
total_rewards_min            202.79720718326757
Number of train steps total  1680000
Number of env steps total    2968538
Number of rollouts total     0
Train Time (s)               145.04600468603894
(Previous) Eval Time (s)     17.35518134990707
Sample Time (s)              7.212138489354402
Epoch Time (s)               169.6133245253004
Total Train Time (s)         70999.91851822473
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:03:57.497480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #419 | Epoch Duration: 169.70556235313416
2020-01-12 04:03:57.497672 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6339642
Z variance train             0.047712438
KL Divergence                20.429035
KL Loss                      2.0429037
QF Loss                      17564.498
VF Loss                      107.50444
Policy Loss                  -1558.9647
Q Predictions Mean           1549.5509
Q Predictions Std            324.57455
Q Predictions Max            2049.8774
Q Predictions Min            410.82635
V Predictions Mean           1556.6089
V Predictions Std            323.55112
V Predictions Max            2046.9004
V Predictions Min            409.0888
Log Pis Mean                 1.7201046
Log Pis Std                  2.876433
Log Pis Max                  10.243247
Log Pis Min                  -6.6860332
Policy mu Mean               -0.11538939
Policy mu Std                0.70913
Policy mu Max                2.2146637
Policy mu Min                -2.6208336
Policy log std Mean          -1.1541989
Policy log std Std           0.30322602
Policy log std Max           -0.3388847
Policy log std Min           -2.6007013
Z mean eval                  0.79189855
Z variance eval              0.00041442233
total_rewards                [ 235.25924411 1374.95094489  297.35047318  898.44570082 5253.38958778
 2011.75593953 5001.58226743  -10.03205451 4237.61054509 3016.67990399]
total_rewards_mean           2231.6992552300217
total_rewards_std            1917.1732851308768
total_rewards_max            5253.389587776081
total_rewards_min            -10.032054512906214
Number of train steps total  1684000
Number of env steps total    2980262
Number of rollouts total     0
Train Time (s)               146.7145840441808
(Previous) Eval Time (s)     16.287910589948297
Sample Time (s)              7.368622147012502
Epoch Time (s)               170.3711167811416
Total Train Time (s)         71170.38059911132
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:06:47.961833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #420 | Epoch Duration: 170.46401810646057
2020-01-12 04:06:47.961978 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7931878
Z variance train             0.00041478747
KL Divergence                25.078358
KL Loss                      2.5078359
QF Loss                      430.39474
VF Loss                      85.98187
Policy Loss                  -1591.6055
Q Predictions Mean           1583.2864
Q Predictions Std            368.5857
Q Predictions Max            2093.936
Q Predictions Min            394.0773
V Predictions Mean           1591.3049
V Predictions Std            367.6957
V Predictions Max            2092.9314
V Predictions Min            393.3464
Log Pis Mean                 1.6275828
Log Pis Std                  2.9286437
Log Pis Max                  11.733465
Log Pis Min                  -10.318203
Policy mu Mean               -0.07845767
Policy mu Std                0.727349
Policy mu Max                2.764383
Policy mu Min                -2.572224
Policy log std Mean          -1.1057099
Policy log std Std           0.3020643
Policy log std Max           -0.12978578
Policy log std Min           -2.229281
Z mean eval                  0.6890775
Z variance eval              0.00399763
total_rewards                [1028.63977926 2216.35710507 2888.0201555  4846.69153864  547.22273294
  335.69134924 5187.5655491  1694.92094748 1149.44806918 4865.47866929]
total_rewards_mean           2476.003589569522
total_rewards_std            1780.0373152612428
total_rewards_max            5187.565549102041
total_rewards_min            335.69134923709913
Number of train steps total  1688000
Number of env steps total    2990707
Number of rollouts total     0
Train Time (s)               146.980985165108
(Previous) Eval Time (s)     15.598799663130194
Sample Time (s)              7.203854168299586
Epoch Time (s)               169.78363899653777
Total Train Time (s)         71340.2736970447
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:09:37.857867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #421 | Epoch Duration: 169.89579057693481
2020-01-12 04:09:37.858001 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6836119
Z variance train             0.0039955555
KL Divergence                22.70946
KL Loss                      2.270946
QF Loss                      464.46875
VF Loss                      73.35926
Policy Loss                  -1575.6176
Q Predictions Mean           1572.262
Q Predictions Std            399.04953
Q Predictions Max            2058.7478
Q Predictions Min            386.77258
V Predictions Mean           1575.4277
V Predictions Std            397.00378
V Predictions Max            2048.1858
V Predictions Min            393.77124
Log Pis Mean                 1.5683085
Log Pis Std                  3.1866932
Log Pis Max                  14.469618
Log Pis Min                  -7.001284
Policy mu Mean               -0.03815359
Policy mu Std                0.7139933
Policy mu Max                2.536083
Policy mu Min                -2.6951005
Policy log std Mean          -1.1131254
Policy log std Std           0.31747535
Policy log std Max           -0.093024254
Policy log std Min           -2.359977
Z mean eval                  0.7307411
Z variance eval              0.00056531216
total_rewards                [2254.07257621 2387.00877993 4964.171241   5063.98355704 5156.95008785
  842.66129353 5028.53469709 5205.18435709 5078.13875443 5134.46147144]
total_rewards_mean           4111.516681560215
total_rewards_std            1544.4866755311502
total_rewards_max            5205.184357085793
total_rewards_min            842.6612935280629
Number of train steps total  1692000
Number of env steps total    3000161
Number of rollouts total     0
Train Time (s)               145.5743971033953
(Previous) Eval Time (s)     17.02493701176718
Sample Time (s)              7.265382143203169
Epoch Time (s)               169.86471625836566
Total Train Time (s)         71510.22627286799
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:12:27.814268 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #422 | Epoch Duration: 169.95615530014038
2020-01-12 04:12:27.814453 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.71577233
Z variance train             0.00056768965
KL Divergence                22.20165
KL Loss                      2.220165
QF Loss                      449.14685
VF Loss                      100.2287
Policy Loss                  -1444.3438
Q Predictions Mean           1435.0322
Q Predictions Std            303.76495
Q Predictions Max            1913.7474
Q Predictions Min            322.89362
V Predictions Mean           1446.4131
V Predictions Std            303.06012
V Predictions Max            1932.1866
V Predictions Min            324.3943
Log Pis Mean                 1.7746701
Log Pis Std                  3.0394475
Log Pis Max                  12.831759
Log Pis Min                  -7.4054337
Policy mu Mean               -0.098647654
Policy mu Std                0.71170205
Policy mu Max                2.6767766
Policy mu Min                -2.5247736
Policy log std Mean          -1.1626713
Policy log std Std           0.32470176
Policy log std Max           -0.22660983
Policy log std Min           -2.698326
Z mean eval                  0.9457814
Z variance eval              0.005990573
total_rewards                [1655.83892037 4779.8938614  1977.27173927 3056.01563842 4813.35185862
 4774.63628797 2766.41075053 4307.99927936 4632.02472867 1853.30312991]
total_rewards_mean           3461.6746194523525
total_rewards_std            1267.8284926308677
total_rewards_max            4813.351858622081
total_rewards_min            1655.83892037483
Number of train steps total  1696000
Number of env steps total    3012036
Number of rollouts total     0
Train Time (s)               148.2645442900248
(Previous) Eval Time (s)     16.847666489891708
Sample Time (s)              7.454730371478945
Epoch Time (s)               172.56694115139544
Total Train Time (s)         71682.89430586156
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:15:20.487481 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #423 | Epoch Duration: 172.67287755012512
2020-01-12 04:15:20.487701 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95321447
Z variance train             0.0059454623
KL Divergence                23.925722
KL Loss                      2.3925722
QF Loss                      439.46567
VF Loss                      132.87512
Policy Loss                  -1731.3461
Q Predictions Mean           1722.4626
Q Predictions Std            332.21945
Q Predictions Max            2214.8608
Q Predictions Min            486.95648
V Predictions Mean           1738.3892
V Predictions Std            330.69223
V Predictions Max            2218.0881
V Predictions Min            496.32632
Log Pis Mean                 2.2058935
Log Pis Std                  2.9311795
Log Pis Max                  11.7554
Log Pis Min                  -5.125422
Policy mu Mean               0.028682558
Policy mu Std                0.8036944
Policy mu Max                2.736034
Policy mu Min                -2.5991788
Policy log std Mean          -1.0766944
Policy log std Std           0.3179384
Policy log std Max           -0.16566265
Policy log std Min           -2.4956894
Z mean eval                  0.78971815
Z variance eval              0.011560693
total_rewards                [4985.85153508 4797.33071678 4913.92103307 3422.30626463 5167.37203544
 4892.6001252  5076.43120681 5241.47481268 4772.4469356  4810.67904296]
total_rewards_mean           4808.041370824578
total_rewards_std            485.864563765774
total_rewards_max            5241.474812677274
total_rewards_min            3422.3062646268368
Number of train steps total  1700000
Number of env steps total    3023227
Number of rollouts total     0
Train Time (s)               145.7851431760937
(Previous) Eval Time (s)     21.189988129772246
Sample Time (s)              7.395105344243348
Epoch Time (s)               174.3702366501093
Total Train Time (s)         71857.63173481775
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:18:15.244285 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #424 | Epoch Duration: 174.75642132759094
2020-01-12 04:18:15.244457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79352206
Z variance train             0.011522347
KL Divergence                18.954899
KL Loss                      1.8954899
QF Loss                      30970.697
VF Loss                      270.89703
Policy Loss                  -1366.9275
Q Predictions Mean           1363.8706
Q Predictions Std            318.90436
Q Predictions Max            1880.6343
Q Predictions Min            327.66333
V Predictions Mean           1378.0505
V Predictions Std            318.24097
V Predictions Max            1894.8656
V Predictions Min            330.91098
Log Pis Mean                 1.7424884
Log Pis Std                  2.5095263
Log Pis Max                  8.94629
Log Pis Min                  -6.497115
Policy mu Mean               -0.18932107
Policy mu Std                0.6297611
Policy mu Max                1.8513918
Policy mu Min                -2.3556418
Policy log std Mean          -1.1762357
Policy log std Std           0.29227167
Policy log std Max           -0.25309217
Policy log std Min           -2.496706
Z mean eval                  2.2920344
Z variance eval              0.0006349455
total_rewards                [3452.06909975 4620.48179237 4536.53707576 3192.39086748  435.36302078
   33.52519157 4217.8786076  1746.72836456 4461.35572175 3578.71260755]
total_rewards_mean           3027.5042349182822
total_rewards_std            1616.243974742307
total_rewards_max            4620.481792369004
total_rewards_min            33.52519157151889
Number of train steps total  1704000
Number of env steps total    3033445
Number of rollouts total     0
Train Time (s)               146.2397422818467
(Previous) Eval Time (s)     19.312967439182103
Sample Time (s)              7.062718774192035
Epoch Time (s)               172.61542849522084
Total Train Time (s)         72030.37536812946
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:21:07.976255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #425 | Epoch Duration: 172.73166871070862
2020-01-12 04:21:07.976424 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.299745
Z variance train             0.0006315218
KL Divergence                33.70497
KL Loss                      3.3704972
QF Loss                      747.4696
VF Loss                      176.50607
Policy Loss                  -1625.445
Q Predictions Mean           1617.7483
Q Predictions Std            280.1688
Q Predictions Max            2068.2776
Q Predictions Min            418.54984
V Predictions Mean           1617.2075
V Predictions Std            275.11603
V Predictions Max            2045.575
V Predictions Min            415.25235
Log Pis Mean                 2.2363558
Log Pis Std                  2.891068
Log Pis Max                  12.479318
Log Pis Min                  -6.8505898
Policy mu Mean               -0.08048675
Policy mu Std                0.72442544
Policy mu Max                2.6955283
Policy mu Min                -2.8463712
Policy log std Mean          -1.2023633
Policy log std Std           0.30022597
Policy log std Max           -0.29873908
Policy log std Min           -2.5570388
Z mean eval                  1.2220528
Z variance eval              0.00015674111
total_rewards                [4404.17672485 3391.27493861 4819.34104099 4438.07882097 3009.34328214
 4538.82417077   48.84799512 4766.97831775 4646.2831383   226.63617005]
total_rewards_mean           3428.9784599552013
total_rewards_std            1739.6559556818313
total_rewards_max            4819.34104099149
total_rewards_min            48.847995122960405
Number of train steps total  1708000
Number of env steps total    3045445
Number of rollouts total     0
Train Time (s)               146.2040701857768
(Previous) Eval Time (s)     14.850963093806058
Sample Time (s)              7.166495017707348
Epoch Time (s)               168.2215282972902
Total Train Time (s)         72198.68723578006
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:23:56.294889 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #426 | Epoch Duration: 168.3183298110962
2020-01-12 04:23:56.295065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2305998
Z variance train             0.00015776901
KL Divergence                30.028635
KL Loss                      3.0028636
QF Loss                      832.6028
VF Loss                      165.89531
Policy Loss                  -1707.6672
Q Predictions Mean           1697.7544
Q Predictions Std            246.19264
Q Predictions Max            2398.19
Q Predictions Min            476.9846
V Predictions Mean           1713.1824
V Predictions Std            245.76105
V Predictions Max            2471.566
V Predictions Min            501.10248
Log Pis Mean                 1.8891647
Log Pis Std                  3.1029963
Log Pis Max                  11.539145
Log Pis Min                  -8.745475
Policy mu Mean               -0.123076685
Policy mu Std                0.7305985
Policy mu Max                2.2868745
Policy mu Min                -2.957632
Policy log std Mean          -1.1493759
Policy log std Std           0.29118782
Policy log std Max           -0.0982641
Policy log std Min           -2.604617
Z mean eval                  1.3829663
Z variance eval              0.0009162318
total_rewards                [4735.38145926  386.61876172 4909.31680559 1000.47581193 -256.89722578
 4610.23034621 1374.19875545 4784.96240059 1376.46963231 4033.5840266 ]
total_rewards_mean           2695.4340773894505
total_rewards_std            1982.1953106759343
total_rewards_max            4909.316805585676
total_rewards_min            -256.8972257793997
Number of train steps total  1712000
Number of env steps total    3057203
Number of rollouts total     0
Train Time (s)               147.06489003868774
(Previous) Eval Time (s)     15.914757262915373
Sample Time (s)              7.532650416251272
Epoch Time (s)               170.51229771785438
Total Train Time (s)         72369.28797266167
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:26:46.900131 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #427 | Epoch Duration: 170.6049325466156
2020-01-12 04:26:46.900308 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3652494
Z variance train             0.0009122662
KL Divergence                28.944656
KL Loss                      2.8944657
QF Loss                      481.46402
VF Loss                      257.24515
Policy Loss                  -1789.6669
Q Predictions Mean           1783.8684
Q Predictions Std            214.68279
Q Predictions Max            2922.404
Q Predictions Min            604.4234
V Predictions Mean           1801.1101
V Predictions Std            215.97075
V Predictions Max            3007.6155
V Predictions Min            604.60803
Log Pis Mean                 2.1397247
Log Pis Std                  3.2882884
Log Pis Max                  13.113173
Log Pis Min                  -7.463291
Policy mu Mean               0.012728716
Policy mu Std                0.76598686
Policy mu Max                2.622921
Policy mu Min                -2.8935075
Policy log std Mean          -1.1339576
Policy log std Std           0.2947419
Policy log std Max           -0.2624601
Policy log std Min           -2.5979028
Z mean eval                  0.66613823
Z variance eval              0.0004798597
total_rewards                [2920.20271304 5078.4896748   764.86360317  285.8209467  5089.60060544
 5170.5880266  1083.26626559  820.31128166 2435.07464265 5069.1610313 ]
total_rewards_mean           2871.7378790963894
total_rewards_std            1965.3991982849416
total_rewards_max            5170.588026596277
total_rewards_min            285.820946704708
Number of train steps total  1716000
Number of env steps total    3068065
Number of rollouts total     0
Train Time (s)               147.61962771601975
(Previous) Eval Time (s)     14.857337021268904
Sample Time (s)              7.742148268036544
Epoch Time (s)               170.2191130053252
Total Train Time (s)         72539.60155873792
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:29:37.220484 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #428 | Epoch Duration: 170.3200237751007
2020-01-12 04:29:37.220723 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6743254
Z variance train             0.00047910315
KL Divergence                24.634382
KL Loss                      2.4634383
QF Loss                      883.95654
VF Loss                      214.98317
Policy Loss                  -1771.9501
Q Predictions Mean           1757.7534
Q Predictions Std            309.55402
Q Predictions Max            3583.625
Q Predictions Min            1075.8406
V Predictions Mean           1774.1023
V Predictions Std            311.7523
V Predictions Max            3680.3374
V Predictions Min            1095.3458
Log Pis Mean                 2.5247219
Log Pis Std                  3.175313
Log Pis Max                  12.527702
Log Pis Min                  -7.3874893
Policy mu Mean               -0.06641866
Policy mu Std                0.7736442
Policy mu Max                2.697403
Policy mu Min                -2.5428033
Policy log std Mean          -1.1769588
Policy log std Std           0.2985675
Policy log std Max           -0.19280922
Policy log std Min           -2.5949895
Z mean eval                  0.8126408
Z variance eval              0.9573016
total_rewards                [4654.42623069 4823.70618304 4786.70520033 -815.58845609 5027.16997241
  241.44851214 2881.22472679 4975.79632673 5208.37381764 4487.47400282]
total_rewards_mean           3627.073651650051
total_rewards_std            2064.1764559747567
total_rewards_max            5208.37381763724
total_rewards_min            -815.588456088375
Number of train steps total  1720000
Number of env steps total    3079365
Number of rollouts total     0
Train Time (s)               145.11895228084177
(Previous) Eval Time (s)     20.8350589168258
Sample Time (s)              7.421326611191034
Epoch Time (s)               173.3753378088586
Total Train Time (s)         72713.08004327863
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:32:30.705907 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #429 | Epoch Duration: 173.48498439788818
2020-01-12 04:32:30.706155 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80428445
Z variance train             0.9442587
KL Divergence                19.33506
KL Loss                      1.933506
QF Loss                      4090.7646
VF Loss                      858.9716
Policy Loss                  -1713.2004
Q Predictions Mean           1702.6805
Q Predictions Std            492.99448
Q Predictions Max            4469.3545
Q Predictions Min            1020.3621
V Predictions Mean           1715.1707
V Predictions Std            532.5364
V Predictions Max            4707.5664
V Predictions Min            1036.1628
Log Pis Mean                 2.0682786
Log Pis Std                  3.3234189
Log Pis Max                  14.389982
Log Pis Min                  -6.1929474
Policy mu Mean               -0.11685049
Policy mu Std                0.7796704
Policy mu Max                2.197881
Policy mu Min                -2.792061
Policy log std Mean          -1.1377363
Policy log std Std           0.2674063
Policy log std Max           -0.30442452
Policy log std Min           -2.584589
Z mean eval                  1.7540951
Z variance eval              0.0024623272
total_rewards                [-1995.54100875  -979.36013674 -2099.4975522  -2013.86090279
 -2068.93646748 -1916.57362077 -1919.78770893 -2171.24768466
 -1937.25677519 -1953.35918193]
total_rewards_mean           -1905.5421039436562
total_rewards_std            318.77556618170297
total_rewards_max            -979.3601367352207
total_rewards_min            -2171.247684663364
Number of train steps total  1724000
Number of env steps total    3090778
Number of rollouts total     0
Train Time (s)               145.02663035411388
(Previous) Eval Time (s)     24.52430673222989
Sample Time (s)              7.0456146015785635
Epoch Time (s)               176.59655168792233
Total Train Time (s)         72889.79957074765
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:35:27.433205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #430 | Epoch Duration: 176.72686433792114
2020-01-12 04:35:27.433385 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #430 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7550373
Z variance train             0.002450968
KL Divergence                35.041794
KL Loss                      3.5041795
QF Loss                      531101.2
VF Loss                      3596.5425
Policy Loss                  -3883.7776
Q Predictions Mean           3515.726
Q Predictions Std            635.5844
Q Predictions Max            8599.8545
Q Predictions Min            2244.5627
V Predictions Mean           3871.178
V Predictions Std            657.4535
V Predictions Max            8882.267
V Predictions Min            2435.9495
Log Pis Mean                 20.948547
Log Pis Std                  5.064551
Log Pis Max                  37.180473
Log Pis Min                  7.94468
Policy mu Mean               0.7144475
Policy mu Std                2.3025243
Policy mu Max                4.80477
Policy mu Min                -5.021761
Policy log std Mean          -0.87813777
Policy log std Std           0.39054176
Policy log std Max           0.250165
Policy log std Min           -2.535801
Z mean eval                  3.471377
Z variance eval              0.00018478485
total_rewards                [-2177.07027471 -1909.63609781  -977.31345489 -1758.39938462
 -2007.31525892 -1898.68428989  -777.93214615 -1686.50676071
  -966.34839327 -2117.68505677]
total_rewards_mean           -1627.6891117733562
total_rewards_std            494.1614940773749
total_rewards_max            -777.9321461516541
total_rewards_min            -2177.070274707926
Number of train steps total  1728000
Number of env steps total    3101989
Number of rollouts total     0
Train Time (s)               145.58745687128976
(Previous) Eval Time (s)     23.45302583090961
Sample Time (s)              8.21802874142304
Epoch Time (s)               177.2585114436224
Total Train Time (s)         73067.21574440645
Epoch                        431
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:38:24.855275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #431 | Epoch Duration: 177.42175793647766
2020-01-12 04:38:24.855439 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #431 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4781146
Z variance train             0.0001858965
KL Divergence                78.40022
KL Loss                      7.8400226
QF Loss                      11687.418
VF Loss                      2284.6824
Policy Loss                  -6904.556
Q Predictions Mean           6784.0522
Q Predictions Std            890.7818
Q Predictions Max            11759.768
Q Predictions Min            3864.103
V Predictions Mean           6887.207
V Predictions Std            930.1692
V Predictions Max            12068.618
V Predictions Min            3864.6094
Log Pis Mean                 10.742569
Log Pis Std                  4.8900604
Log Pis Max                  26.24218
Log Pis Min                  -2.6092582
Policy mu Mean               0.2613918
Policy mu Std                1.5649059
Policy mu Max                5.0321555
Policy mu Min                -4.717443
Policy log std Mean          -1.1160878
Policy log std Std           0.42385516
Policy log std Max           0.17147005
Policy log std Min           -2.3038583
Z mean eval                  4.1335683
Z variance eval              0.009696908
total_rewards                [-2612.69264894 -2541.58521907 -2622.09759396 -2527.02273773
 -2643.81983876 -2688.71211694 -2606.63643768 -2635.47253929
 -2683.05788786 -2546.06624535]
total_rewards_mean           -2610.7163265570402
total_rewards_std            53.98036848954277
total_rewards_max            -2527.022737726956
total_rewards_min            -2688.7121169368993
Number of train steps total  1732000
Number of env steps total    3113322
Number of rollouts total     0
Train Time (s)               144.48542744200677
(Previous) Eval Time (s)     22.907133212778717
Sample Time (s)              7.308692616876215
Epoch Time (s)               174.7012532716617
Total Train Time (s)         73242.00837512128
Epoch                        432
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:41:19.651915 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #432 | Epoch Duration: 174.79634642601013
2020-01-12 04:41:19.652083 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.129953
Z variance train             0.009639475
KL Divergence                94.82266
KL Loss                      9.482266
QF Loss                      59434.57
VF Loss                      4303.7236
Policy Loss                  -9463.307
Q Predictions Mean           9178.258
Q Predictions Std            1781.7865
Q Predictions Max            19026.34
Q Predictions Min            5677.2183
V Predictions Mean           9488.273
V Predictions Std            1849.4775
V Predictions Max            19697.63
V Predictions Min            5798.0093
Log Pis Mean                 18.841719
Log Pis Std                  5.296691
Log Pis Max                  33.50625
Log Pis Min                  6.980826
Policy mu Mean               1.0390592
Policy mu Std                1.9810315
Policy mu Max                4.870183
Policy mu Min                -4.713033
Policy log std Mean          -0.9287987
Policy log std Std           0.41758853
Policy log std Max           0.09936392
Policy log std Min           -2.4759483
Z mean eval                  5.6726456
Z variance eval              0.04975379
total_rewards                [  -35.41410289 -1668.52216918   -42.83990879   -26.56134252
 -1906.41748603 -1913.26373716   -16.63740851 -2349.54570678
 -2799.58272177   -14.55839982]
total_rewards_mean           -1077.3342983441119
total_rewards_std            1087.8783112178842
total_rewards_max            -14.558399815654424
total_rewards_min            -2799.582721769659
Number of train steps total  1736000
Number of env steps total    3124114
Number of rollouts total     0
Train Time (s)               146.13274789694697
(Previous) Eval Time (s)     12.458496208302677
Sample Time (s)              7.696730681695044
Epoch Time (s)               166.2879747869447
Total Train Time (s)         73408.39015727304
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:44:06.039025 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #433 | Epoch Duration: 166.3867495059967
2020-01-12 04:44:06.039305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.6756177
Z variance train             0.04993195
KL Divergence                156.54851
KL Loss                      15.654851
QF Loss                      104318.75
VF Loss                      12549.678
Policy Loss                  -15332.486
Q Predictions Mean           14961.838
Q Predictions Std            2537.6594
Q Predictions Max            29761.451
Q Predictions Min            10835.898
V Predictions Mean           15289.343
V Predictions Std            2684.246
V Predictions Max            30655.76
V Predictions Min            11229.861
Log Pis Mean                 19.453457
Log Pis Std                  6.2629857
Log Pis Max                  41.020195
Log Pis Min                  4.6606655
Policy mu Mean               0.23101369
Policy mu Std                2.292625
Policy mu Max                5.3194666
Policy mu Min                -9.002875
Policy log std Mean          -1.1249485
Policy log std Std           0.54980916
Policy log std Max           0.3992287
Policy log std Min           -2.947424
Z mean eval                  6.5944796
Z variance eval              0.005723192
total_rewards                [-1952.63880273 -1676.29567918   -80.45247058 -1856.94007598
 -2005.2200322    -50.99487438   -15.57648186 -1936.81343277
 -1623.13131234   -32.38908414]
total_rewards_mean           -1123.045224618452
total_rewards_std            887.4547787475071
total_rewards_max            -15.576481857551949
total_rewards_min            -2005.2200322010588
Number of train steps total  1740000
Number of env steps total    3133439
Number of rollouts total     0
Train Time (s)               146.15135749895126
(Previous) Eval Time (s)     15.002347789239138
Sample Time (s)              7.3792273425497115
Epoch Time (s)               168.5329326307401
Total Train Time (s)         73577.02281209733
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:46:54.677172 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #434 | Epoch Duration: 168.63768982887268
2020-01-12 04:46:54.677346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #434 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.5942736
Z variance train             0.00570998
KL Divergence                205.76437
KL Loss                      20.576437
QF Loss                      89030.45
VF Loss                      15145.445
Policy Loss                  -21853.326
Q Predictions Mean           21495.424
Q Predictions Std            2631.3975
Q Predictions Max            36547.215
Q Predictions Min            15064.201
V Predictions Mean           21889.703
V Predictions Std            2665.1125
V Predictions Max            37444.227
V Predictions Min            15633.442
Log Pis Mean                 19.797628
Log Pis Std                  6.8690658
Log Pis Max                  40.69568
Log Pis Min                  1.3120418
Policy mu Mean               0.0706637
Policy mu Std                2.2725885
Policy mu Max                6.219165
Policy mu Min                -6.78705
Policy log std Mean          -1.2177066
Policy log std Std           0.57817227
Policy log std Max           0.5328969
Policy log std Min           -3.05928
Z mean eval                  6.4069147
Z variance eval              0.009940053
total_rewards                [  -17.07018488   -19.31750581 -2159.77618237 -1894.10719697
 -1961.59329322 -1571.58760717 -1917.75377628   -35.4738485
   -32.36677943   -18.07429547]
total_rewards_mean           -962.7120670083286
total_rewards_std            947.7838695106354
total_rewards_max            -17.07018487578929
total_rewards_min            -2159.776182366435
Number of train steps total  1744000
Number of env steps total    3143446
Number of rollouts total     0
Train Time (s)               146.05217060865834
(Previous) Eval Time (s)     11.128413479309529
Sample Time (s)              7.6327703963033855
Epoch Time (s)               164.81335448427126
Total Train Time (s)         73741.92306153523
Epoch                        435
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:49:39.579318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #435 | Epoch Duration: 164.90185022354126
2020-01-12 04:49:39.579451 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 6.408212
Z variance train             0.009949248
KL Divergence                197.63837
KL Loss                      19.763838
QF Loss                      141647.9
VF Loss                      16014.122
Policy Loss                  -23338.242
Q Predictions Mean           22984.52
Q Predictions Std            1445.6964
Q Predictions Max            32451.527
Q Predictions Min            17154.232
V Predictions Mean           23323.531
V Predictions Std            1436.8428
V Predictions Max            32471.79
V Predictions Min            17466.479
Log Pis Mean                 17.047968
Log Pis Std                  4.937743
Log Pis Max                  33.75503
Log Pis Min                  4.840475
Policy mu Mean               -0.055574566
Policy mu Std                2.0502555
Policy mu Max                6.3854733
Policy mu Min                -6.0630054
Policy log std Mean          -1.3416897
Policy log std Std           0.6296386
Policy log std Max           0.70649123
Policy log std Min           -3.5736613
Z mean eval                  5.704064
Z variance eval              0.035582382
total_rewards                [-1175.10060851  -702.45860941 -1688.28505793  -901.80420159
   -42.06130202 -1672.41510981   -28.72359578 -1579.87275837
  -669.82375612  -702.95033428]
total_rewards_mean           -916.3495333821465
total_rewards_std            581.314853290411
total_rewards_max            -28.723595784827047
total_rewards_min            -1688.2850579316132
Number of train steps total  1748000
Number of env steps total    3155351
Number of rollouts total     0
Train Time (s)               146.04611129127443
(Previous) Eval Time (s)     18.271445041988045
Sample Time (s)              6.396338503807783
Epoch Time (s)               170.71389483707026
Total Train Time (s)         73912.73101319466
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:52:30.395337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #436 | Epoch Duration: 170.81572031974792
2020-01-12 04:52:30.395603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 5.695534
Z variance train             0.03607651
KL Divergence                163.81552
KL Loss                      16.381552
QF Loss                      49645.023
VF Loss                      15914.999
Policy Loss                  -21658.592
Q Predictions Mean           21520.492
Q Predictions Std            2168.1921
Q Predictions Max            31840.781
Q Predictions Min            15775.78
V Predictions Mean           21731.629
V Predictions Std            2209.244
V Predictions Max            32867.098
V Predictions Min            16174.719
Log Pis Mean                 12.144533
Log Pis Std                  4.651496
Log Pis Max                  28.563679
Log Pis Min                  1.9501543
Policy mu Mean               0.23563093
Policy mu Std                1.4369409
Policy mu Max                5.0063233
Policy mu Min                -4.199363
Policy log std Mean          -1.6280864
Policy log std Std           0.5156766
Policy log std Max           -0.021588802
Policy log std Min           -3.564745
Z mean eval                  4.830753
Z variance eval              0.017717663
total_rewards                [ -774.50475587   -43.2891728  -1449.26988657  -175.12374072
 -1553.18329967 -1516.38828783  -118.98595785   -18.93630638
 -1464.14903433 -1129.82827846]
total_rewards_mean           -824.3658720488824
total_rewards_std            639.0277431622733
total_rewards_max            -18.936306378551016
total_rewards_min            -1553.183299669537
Number of train steps total  1752000
Number of env steps total    3165152
Number of rollouts total     0
Train Time (s)               146.80822027707472
(Previous) Eval Time (s)     14.126766034867615
Sample Time (s)              7.975065133534372
Epoch Time (s)               168.9100514454767
Total Train Time (s)         74081.73484264081
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:55:19.404325 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #437 | Epoch Duration: 169.00856590270996
2020-01-12 04:55:19.404494 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #437 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.8338785
Z variance train             0.017701812
KL Divergence                131.16486
KL Loss                      13.116486
QF Loss                      106729.14
VF Loss                      15493.879
Policy Loss                  -18627.842
Q Predictions Mean           18510.168
Q Predictions Std            2521.4658
Q Predictions Max            33833.934
Q Predictions Min            14917.626
V Predictions Mean           18608.693
V Predictions Std            2597.535
V Predictions Max            34198.027
V Predictions Min            14018.253
Log Pis Mean                 11.63492
Log Pis Std                  4.8742127
Log Pis Max                  24.955196
Log Pis Min                  0.63839984
Policy mu Mean               -0.3851117
Policy mu Std                1.509134
Policy mu Max                4.5077276
Policy mu Min                -5.066772
Policy log std Mean          -1.3784444
Policy log std Std           0.52490413
Policy log std Max           0.14204156
Policy log std Min           -3.485415
Z mean eval                  4.181504
Z variance eval              0.003880451
total_rewards                [-6.99361973e+02 -1.04923338e+00 -9.39549405e+02 -1.09964271e+03
 -1.23560968e+03 -1.35858197e+03 -1.51064028e+03 -5.44666569e+02
 -3.49223414e+00 -1.58483688e+03]
total_rewards_mean           -897.7430940019749
total_rewards_std            546.30952202514
total_rewards_max            -1.0492333836238528
total_rewards_min            -1584.8368801428057
Number of train steps total  1756000
Number of env steps total    3176763
Number of rollouts total     0
Train Time (s)               146.20783561002463
(Previous) Eval Time (s)     17.58585170377046
Sample Time (s)              8.39365133875981
Epoch Time (s)               172.1873386525549
Total Train Time (s)         74254.02731567249
Epoch                        438
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 04:58:11.701311 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #438 | Epoch Duration: 172.2966752052307
2020-01-12 04:58:11.701530 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.183284
Z variance train             0.0039010223
KL Divergence                108.44554
KL Loss                      10.844554
QF Loss                      52708.953
VF Loss                      10252.897
Policy Loss                  -16385.965
Q Predictions Mean           16247.611
Q Predictions Std            2520.4202
Q Predictions Max            33109.906
Q Predictions Min            15050.413
V Predictions Mean           16356.311
V Predictions Std            2579.2495
V Predictions Max            33745.477
V Predictions Min            15129.651
Log Pis Mean                 10.895493
Log Pis Std                  5.3816366
Log Pis Max                  36.031734
Log Pis Min                  -3.6799955
Policy mu Mean               -0.109772384
Policy mu Std                1.4694654
Policy mu Max                5.271853
Policy mu Min                -4.835328
Policy log std Mean          -1.4327644
Policy log std Std           0.5194802
Policy log std Max           0.05260575
Policy log std Min           -2.9368668
Z mean eval                  3.9588878
Z variance eval              0.00070502557
total_rewards                [-2106.74796288 -2036.06314116 -2055.75357476 -2069.29588069
 -1845.93202885 -1921.47728967 -1523.88281699 -2008.54928076
 -1996.31191101 -1922.34981145]
total_rewards_mean           -1948.636369823469
total_rewards_std            160.29048773125226
total_rewards_max            -1523.8828169909223
total_rewards_min            -2106.747962882509
Number of train steps total  1760000
Number of env steps total    3188326
Number of rollouts total     0
Train Time (s)               146.63115145405754
(Previous) Eval Time (s)     21.486421186011285
Sample Time (s)              7.258388078771532
Epoch Time (s)               175.37596071884036
Total Train Time (s)         74429.49374551652
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:01:07.173047 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #439 | Epoch Duration: 175.47133994102478
2020-01-12 05:01:07.173284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.9599411
Z variance train             0.00070296694
KL Divergence                101.98286
KL Loss                      10.198286
QF Loss                      5487153.5
VF Loss                      17748.682
Policy Loss                  -15744.579
Q Predictions Mean           15498.181
Q Predictions Std            2868.4937
Q Predictions Max            34180.945
Q Predictions Min            13087.716
V Predictions Mean           15792.473
V Predictions Std            2926.8027
V Predictions Max            34580.125
V Predictions Min            13149.689
Log Pis Mean                 16.609505
Log Pis Std                  6.139339
Log Pis Max                  37.01304
Log Pis Min                  2.697989
Policy mu Mean               -0.07878831
Policy mu Std                2.0332046
Policy mu Max                6.697605
Policy mu Min                -6.7494683
Policy log std Mean          -1.2433422
Policy log std Std           0.5590462
Policy log std Max           0.81623936
Policy log std Min           -3.043282
Z mean eval                  3.7116764
Z variance eval              0.014078736
total_rewards                [ -115.56080194 -1731.60876995   -36.57023971 -1663.22503721
 -1331.66891009    -4.40118326  -766.56691862  -903.71747587
 -1770.23321299   -15.33628918]
total_rewards_mean           -833.888883882689
total_rewards_std            716.7582461954227
total_rewards_max            -4.401183261930522
total_rewards_min            -1770.2332129944043
Number of train steps total  1764000
Number of env steps total    3198490
Number of rollouts total     0
Train Time (s)               146.25396741786972
(Previous) Eval Time (s)     15.313383894972503
Sample Time (s)              6.743091267067939
Epoch Time (s)               168.31044257991016
Total Train Time (s)         74597.89227709034
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:03:55.574708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #440 | Epoch Duration: 168.4012587070465
2020-01-12 05:03:55.574848 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #440 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7128265
Z variance train             0.014048512
KL Divergence                101.97301
KL Loss                      10.197301
QF Loss                      71917.875
VF Loss                      10889.714
Policy Loss                  -17095.549
Q Predictions Mean           16890.227
Q Predictions Std            3538.5986
Q Predictions Max            35763.523
Q Predictions Min            11792.311
V Predictions Mean           17063.504
V Predictions Std            3597.476
V Predictions Max            35856.19
V Predictions Min            11020.823
Log Pis Mean                 13.857359
Log Pis Std                  4.764735
Log Pis Max                  30.85064
Log Pis Min                  3.573462
Policy mu Mean               0.15905496
Policy mu Std                1.6448426
Policy mu Max                5.750464
Policy mu Min                -5.2052207
Policy log std Mean          -1.5226454
Policy log std Std           0.5944913
Policy log std Max           0.3505485
Policy log std Min           -3.4854684
Z mean eval                  3.498506
Z variance eval              0.0039988165
total_rewards                [-1257.47896777 -1234.05262526 -1108.6801336    -21.37966899
  -492.95760629  -742.11522514    -1.95724857  -627.14130717
 -1175.14499787 -1277.67956094]
total_rewards_mean           -793.8587341602936
total_rewards_std            472.4546700574425
total_rewards_max            -1.9572485670220807
total_rewards_min            -1277.6795609441847
Number of train steps total  1768000
Number of env steps total    3209921
Number of rollouts total     0
Train Time (s)               146.39874137286097
(Previous) Eval Time (s)     20.557727883104235
Sample Time (s)              7.888922833837569
Epoch Time (s)               174.84539208980277
Total Train Time (s)         74772.83247647015
Epoch                        441
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:06:50.517337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #441 | Epoch Duration: 174.94238996505737
2020-01-12 05:06:50.517476 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.4992485
Z variance train             0.0040383125
KL Divergence                98.66675
KL Loss                      9.866675
QF Loss                      47530.297
VF Loss                      9768.822
Policy Loss                  -16730.121
Q Predictions Mean           16520.447
Q Predictions Std            3116.8582
Q Predictions Max            34753.34
Q Predictions Min            8171.8896
V Predictions Mean           16767.73
V Predictions Std            3133.1873
V Predictions Max            35037.01
V Predictions Min            12970.608
Log Pis Mean                 12.536368
Log Pis Std                  4.3789263
Log Pis Max                  24.738354
Log Pis Min                  0.21317673
Policy mu Mean               0.16723834
Policy mu Std                1.5619
Policy mu Max                4.4043055
Policy mu Min                -5.1317005
Policy log std Mean          -1.4494131
Policy log std Std           0.5277626
Policy log std Max           0.05635929
Policy log std Min           -3.3885307
Z mean eval                  3.1461701
Z variance eval              0.0030822377
total_rewards                [-1201.85439656  -848.62104419   -60.902981    -889.09114685
 -1031.72352506 -1090.05866346 -1022.03098918  -899.70813305
  -851.26891458  -894.80385495]
total_rewards_mean           -879.0063648881217
total_rewards_std            293.99287504321086
total_rewards_max            -60.902981002733874
total_rewards_min            -1201.8543965594602
Number of train steps total  1772000
Number of env steps total    3220377
Number of rollouts total     0
Train Time (s)               146.1420074547641
(Previous) Eval Time (s)     23.2620105240494
Sample Time (s)              7.273829255718738
Epoch Time (s)               176.67784723453224
Total Train Time (s)         74949.6016744203
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:09:47.289978 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #442 | Epoch Duration: 176.77240681648254
2020-01-12 05:09:47.290115 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.1498966
Z variance train             0.0031042497
KL Divergence                91.5237
KL Loss                      9.1523695
QF Loss                      34914.93
VF Loss                      6382.571
Policy Loss                  -15462.459
Q Predictions Mean           15317.637
Q Predictions Std            2188.7131
Q Predictions Max            32593.48
Q Predictions Min            11548.524
V Predictions Mean           15480.327
V Predictions Std            2206.06
V Predictions Max            32857.496
V Predictions Min            11278.038
Log Pis Mean                 11.430877
Log Pis Std                  3.7699313
Log Pis Max                  22.478724
Log Pis Min                  2.6989324
Policy mu Mean               0.021657798
Policy mu Std                1.4201154
Policy mu Max                4.1847787
Policy mu Min                -4.6408463
Policy log std Mean          -1.5849261
Policy log std Std           0.5202785
Policy log std Max           0.48430932
Policy log std Min           -3.4560518
Z mean eval                  2.744637
Z variance eval              0.0062919543
total_rewards                [-926.7462529  -343.24663617 -639.73393029 -391.83042217 -733.80820967
 -125.75564308 -772.24081914 -986.46171045 -675.93375466 -716.34209944]
total_rewards_mean           -631.2099477974762
total_rewards_std            254.75311052574318
total_rewards_max            -125.75564308181232
total_rewards_min            -986.4617104486946
Number of train steps total  1776000
Number of env steps total    3230934
Number of rollouts total     0
Train Time (s)               146.17595764109865
(Previous) Eval Time (s)     21.58991393027827
Sample Time (s)              7.61448587756604
Epoch Time (s)               175.38035744894296
Total Train Time (s)         75125.06550750742
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:12:42.757051 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #443 | Epoch Duration: 175.46683621406555
2020-01-12 05:12:42.757173 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.750032
Z variance train             0.0064071333
KL Divergence                77.667244
KL Loss                      7.7667246
QF Loss                      38698.14
VF Loss                      9804.894
Policy Loss                  -14066.432
Q Predictions Mean           13947.085
Q Predictions Std            2771.287
Q Predictions Max            30709.986
Q Predictions Min            -197.16055
V Predictions Mean           14041.064
V Predictions Std            2822.972
V Predictions Max            31191.033
V Predictions Min            -409.8197
Log Pis Mean                 10.037181
Log Pis Std                  4.1448355
Log Pis Max                  35.303947
Log Pis Min                  -0.23568368
Policy mu Mean               -0.24921075
Policy mu Std                1.2936836
Policy mu Max                4.937652
Policy mu Min                -4.3390627
Policy log std Mean          -1.540437
Policy log std Std           0.5343765
Policy log std Max           -0.06211996
Policy log std Min           -5.213005
Z mean eval                  2.5240855
Z variance eval              0.0020491586
total_rewards                [ -750.48518736 -1728.93880615 -1138.16572388   -44.63296329
   -11.65783802 -1747.12393906 -1785.71036013  -801.84624339
    -4.19626505 -1562.55067979]
total_rewards_mean           -957.5308006112639
total_rewards_std            707.6084704535012
total_rewards_max            -4.196265051579463
total_rewards_min            -1785.71036013405
Number of train steps total  1780000
Number of env steps total    3242333
Number of rollouts total     0
Train Time (s)               146.03167852014303
(Previous) Eval Time (s)     17.811282538808882
Sample Time (s)              6.233801917172968
Epoch Time (s)               170.07676297612488
Total Train Time (s)         75295.23301257752
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:15:32.929493 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #444 | Epoch Duration: 170.17221665382385
2020-01-12 05:15:32.929664 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5239875
Z variance train             0.002055422
KL Divergence                72.33089
KL Loss                      7.233089
QF Loss                      61926.086
VF Loss                      6485.6924
Policy Loss                  -13005.107
Q Predictions Mean           12892.124
Q Predictions Std            2771.93
Q Predictions Max            28876.705
Q Predictions Min            10061.565
V Predictions Mean           13036.995
V Predictions Std            2813.2295
V Predictions Max            29387.238
V Predictions Min            10402.891
Log Pis Mean                 11.583679
Log Pis Std                  4.9700365
Log Pis Max                  28.70847
Log Pis Min                  -1.6484032
Policy mu Mean               -0.17878067
Policy mu Std                1.6050091
Policy mu Max                6.121757
Policy mu Min                -4.315014
Policy log std Mean          -1.2711775
Policy log std Std           0.5241708
Policy log std Max           0.539639
Policy log std Min           -3.4207773
Z mean eval                  2.5024116
Z variance eval              0.000110567504
total_rewards                [-2576.8497597  -2621.55340408 -2574.31595288 -2583.98545268
 -2599.39775919 -2579.13769385 -2580.77406849 -2580.25061714
 -2553.55148126 -2565.4102924 ]
total_rewards_mean           -2581.5226481681325
total_rewards_std            17.46905661566207
total_rewards_max            -2553.551481261864
total_rewards_min            -2621.553404076362
Number of train steps total  1784000
Number of env steps total    3254105
Number of rollouts total     0
Train Time (s)               146.51367920124903
(Previous) Eval Time (s)     24.954811876174062
Sample Time (s)              6.383232038002461
Epoch Time (s)               177.85172311542556
Total Train Time (s)         75473.16570045473
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:18:30.866100 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #445 | Epoch Duration: 177.9363191127777
2020-01-12 05:18:30.866228 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5145075
Z variance train             0.00011123928
KL Divergence                77.109024
KL Loss                      7.7109027
QF Loss                      74366.56
VF Loss                      29222.23
Policy Loss                  -13806.3
Q Predictions Mean           13576.277
Q Predictions Std            3054.5713
Q Predictions Max            30282.055
Q Predictions Min            -768.863
V Predictions Mean           13866.576
V Predictions Std            2961.8376
V Predictions Max            30810.807
V Predictions Min            11627.619
Log Pis Mean                 16.303083
Log Pis Std                  5.2006025
Log Pis Max                  36.93043
Log Pis Min                  2.7129729
Policy mu Mean               -0.8359095
Policy mu Std                1.8730669
Policy mu Max                5.17195
Policy mu Min                -5.2665095
Policy log std Mean          -1.0571315
Policy log std Std           0.5472672
Policy log std Max           0.34870636
Policy log std Min           -4.614561
Z mean eval                  2.8167706
Z variance eval              4.547991e-05
total_rewards                [  -28.53176666  -579.352255   -1973.83169379  -789.25853375
 -1647.12345519 -1696.88857178  -506.92899052 -2391.13196055
   -64.95318111   -22.91042799]
total_rewards_mean           -970.0910836344107
total_rewards_std            837.6345228929764
total_rewards_max            -22.910427992587792
total_rewards_min            -2391.131960547497
Number of train steps total  1788000
Number of env steps total    3266105
Number of rollouts total     0
Train Time (s)               147.42211386794224
(Previous) Eval Time (s)     14.91639585280791
Sample Time (s)              7.335120516829193
Epoch Time (s)               169.67363023757935
Total Train Time (s)         75643.07434324734
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:21:20.785305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #446 | Epoch Duration: 169.91896200180054
2020-01-12 05:21:20.785507 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #446 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.8123312
Z variance train             4.530639e-05
KL Divergence                81.94016
KL Loss                      8.194016
QF Loss                      288629.75
VF Loss                      23183.996
Policy Loss                  -15911.197
Q Predictions Mean           15644.469
Q Predictions Std            3635.8845
Q Predictions Max            31498.955
Q Predictions Min            12109.769
V Predictions Mean           15972.396
V Predictions Std            3707.9949
V Predictions Max            32044.215
V Predictions Min            12296.827
Log Pis Mean                 18.294172
Log Pis Std                  7.186336
Log Pis Max                  40.545578
Log Pis Min                  2.417825
Policy mu Mean               -0.19822964
Policy mu Std                2.1564424
Policy mu Max                5.051123
Policy mu Min                -5.101853
Policy log std Mean          -1.108131
Policy log std Std           0.62227017
Policy log std Max           0.23397207
Policy log std Min           -4.0603924
Z mean eval                  3.177539
Z variance eval              4.1674775e-06
total_rewards                [-1607.61401791 -2145.94891354  -282.92578314   -58.98495954
 -1248.97554234  -279.55611324 -2436.8120883    -19.3716748
  -436.32083133   -43.58665188]
total_rewards_mean           -856.0096576013768
total_rewards_std            878.3117931933225
total_rewards_max            -19.371674798229066
total_rewards_min            -2436.812088302189
Number of train steps total  1792000
Number of env steps total    3277083
Number of rollouts total     0
Train Time (s)               147.17941076867282
(Previous) Eval Time (s)     18.057910887058824
Sample Time (s)              7.7339125336147845
Epoch Time (s)               172.97123418934643
Total Train Time (s)         75816.1411503707
Epoch                        447
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:24:13.850575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #447 | Epoch Duration: 173.06493163108826
2020-01-12 05:24:13.850713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #447 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.169096
Z variance train             4.1752264e-06
KL Divergence                94.47655
KL Loss                      9.447655
QF Loss                      135426.9
VF Loss                      36055.81
Policy Loss                  -18798.98
Q Predictions Mean           18532.871
Q Predictions Std            2610.8613
Q Predictions Max            33249.57
Q Predictions Min            12222.873
V Predictions Mean           18806.436
V Predictions Std            2607.4373
V Predictions Max            33328.67
V Predictions Min            13728.453
Log Pis Mean                 16.07774
Log Pis Std                  5.473627
Log Pis Max                  36.190434
Log Pis Min                  4.7707143
Policy mu Mean               -0.45545468
Policy mu Std                1.9455062
Policy mu Max                6.6590266
Policy mu Min                -5.1433506
Policy log std Mean          -1.2832937
Policy log std Std           0.64408416
Policy log std Max           0.8660445
Policy log std Min           -3.8213143
Z mean eval                  2.6204126
Z variance eval              2.1718301e-06
total_rewards                [    9.73966394  -287.38415648 -1269.30850119  -858.90320832
  -109.12168961  -256.70031413 -1211.93418008 -1706.90957224
   -10.93320761  -461.6907485 ]
total_rewards_mean           -616.3145914235688
total_rewards_std            575.0227623537594
total_rewards_max            9.739663935353907
total_rewards_min            -1706.9095722378654
Number of train steps total  1796000
Number of env steps total    3288080
Number of rollouts total     0
Train Time (s)               146.3765486162156
(Previous) Eval Time (s)     17.15408883197233
Sample Time (s)              8.162907546386123
Epoch Time (s)               171.69354499457404
Total Train Time (s)         75987.93744861986
Epoch                        448
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:27:05.650275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #448 | Epoch Duration: 171.79944849014282
2020-01-12 05:27:05.650470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.6226938
Z variance train             2.1859069e-06
KL Divergence                86.255264
KL Loss                      8.625526
QF Loss                      115668.69
VF Loss                      12059.089
Policy Loss                  -18177.072
Q Predictions Mean           18011.352
Q Predictions Std            2109.2737
Q Predictions Max            28686.516
Q Predictions Min            14186.135
V Predictions Mean           18137.496
V Predictions Std            2149.418
V Predictions Max            29130.064
V Predictions Min            14284.079
Log Pis Mean                 13.040653
Log Pis Std                  4.723013
Log Pis Max                  51.77312
Log Pis Min                  0.47716177
Policy mu Mean               -0.37666327
Policy mu Std                1.5279837
Policy mu Max                8.29914
Policy mu Min                -5.1006184
Policy log std Mean          -1.5654783
Policy log std Std           0.61325115
Policy log std Max           0.25869906
Policy log std Min           -5.7164516
Z mean eval                  2.9118333
Z variance eval              0.14080402
total_rewards                [    4.03173936  -430.57118328 -1467.27989712 -1099.37135242
    44.2721646    -57.67521794   -26.18248132  -966.65610906
   -64.12624854   -16.9108486 ]
total_rewards_mean           -408.0469434323357
total_rewards_std            531.667805001038
total_rewards_max            44.272164601286825
total_rewards_min            -1467.2798971162483
Number of train steps total  1800000
Number of env steps total    3299466
Number of rollouts total     0
Train Time (s)               146.3088096487336
(Previous) Eval Time (s)     13.721461206674576
Sample Time (s)              8.426753422245383
Epoch Time (s)               168.45702427765355
Total Train Time (s)         76156.48099002708
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:29:54.202532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #449 | Epoch Duration: 168.55189538002014
2020-01-12 05:29:54.202820 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #449 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.9246013
Z variance train             0.14032002
KL Divergence                72.21074
KL Loss                      7.221074
QF Loss                      40033.863
VF Loss                      7894.2944
Policy Loss                  -16195.8
Q Predictions Mean           16095.319
Q Predictions Std            2136.0015
Q Predictions Max            26088.506
Q Predictions Min            12895.813
V Predictions Mean           16191.322
V Predictions Std            2129.0203
V Predictions Max            26033.307
V Predictions Min            12953.095
Log Pis Mean                 11.619814
Log Pis Std                  4.2492476
Log Pis Max                  28.98731
Log Pis Min                  2.3970046
Policy mu Mean               -0.17983578
Policy mu Std                1.3984631
Policy mu Max                4.5653963
Policy mu Min                -4.6634355
Policy log std Mean          -1.6228683
Policy log std Std           0.5795719
Policy log std Max           -0.01262331
Policy log std Min           -4.587324
Z mean eval                  2.4543614
Z variance eval              0.008449772
total_rewards                [-1013.19510896  -607.28395308    -9.24096525  -801.07345444
  -884.48318125  -813.03216149  -962.38108058  -100.5143934
 -1494.17847972 -1168.23499915]
total_rewards_mean           -785.3617777327336
total_rewards_std            429.6726204531113
total_rewards_max            -9.24096525161631
total_rewards_min            -1494.1784797178925
Number of train steps total  1804000
Number of env steps total    3310599
Number of rollouts total     0
Train Time (s)               146.90830183494836
(Previous) Eval Time (s)     21.623331416398287
Sample Time (s)              7.934999136719853
Epoch Time (s)               176.4666323880665
Total Train Time (s)         76333.03172734892
Epoch                        450
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:32:50.756036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #450 | Epoch Duration: 176.55302000045776
2020-01-12 05:32:50.756170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4298728
Z variance train             0.008409331
KL Divergence                67.307785
KL Loss                      6.7307787
QF Loss                      96696.484
VF Loss                      101983.6
Policy Loss                  -15029.347
Q Predictions Mean           14931.639
Q Predictions Std            1831.0798
Q Predictions Max            23669.732
Q Predictions Min            2401.5054
V Predictions Mean           15094.238
V Predictions Std            1739.7596
V Predictions Max            23745.531
V Predictions Min            6638.25
Log Pis Mean                 11.121911
Log Pis Std                  4.3145514
Log Pis Max                  32.952343
Log Pis Min                  0.46673965
Policy mu Mean               -0.33489537
Policy mu Std                1.3017316
Policy mu Max                4.5237403
Policy mu Min                -5.3972497
Policy log std Mean          -1.6881117
Policy log std Std           0.5432375
Policy log std Max           0.16043484
Policy log std Min           -3.527259
Z mean eval                  1.794108
Z variance eval              0.0009912222
total_rewards                [  46.22542966    4.25415006   12.76973632 -560.53234271   94.11637811
   72.70796315  181.9195166    -5.28100741 -751.9004691   -14.64968182]
total_rewards_mean           -92.0370327133999
total_rewards_std            290.6272830152391
total_rewards_max            181.91951660268293
total_rewards_min            -751.9004691006419
Number of train steps total  1808000
Number of env steps total    3321317
Number of rollouts total     0
Train Time (s)               147.43919320683926
(Previous) Eval Time (s)     9.880653691943735
Sample Time (s)              8.055355079006404
Epoch Time (s)               165.3752019777894
Total Train Time (s)         76498.49048432661
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:35:36.218318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #451 | Epoch Duration: 165.46205592155457
2020-01-12 05:35:36.218434 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7890213
Z variance train             0.0009844888
KL Divergence                64.62528
KL Loss                      6.462528
QF Loss                      29216.717
VF Loss                      40409.594
Policy Loss                  -13652.304
Q Predictions Mean           13569.321
Q Predictions Std            1573.3043
Q Predictions Max            20978.492
Q Predictions Min            6319.6514
V Predictions Mean           13735.918
V Predictions Std            1564.593
V Predictions Max            21104.51
V Predictions Min            7445.0093
Log Pis Mean                 10.465073
Log Pis Std                  4.626096
Log Pis Max                  27.929724
Log Pis Min                  0.3451984
Policy mu Mean               -0.22690597
Policy mu Std                1.2771848
Policy mu Max                5.0597425
Policy mu Min                -4.153219
Policy log std Mean          -1.6409681
Policy log std Std           0.5408365
Policy log std Max           0.056263685
Policy log std Min           -3.899415
Z mean eval                  1.7360255
Z variance eval              3.5078767e-05
total_rewards                [ -476.17112454  -671.54706848  -455.40235917  -464.84073864
  -512.11656475 -1541.92895313  -506.23370711  -540.64398084
  -536.1002359   -313.52561526]
total_rewards_mean           -601.8510347814963
total_rewards_std            324.5018447358936
total_rewards_max            -313.52561525888257
total_rewards_min            -1541.9289531305626
Number of train steps total  1812000
Number of env steps total    3332880
Number of rollouts total     0
Train Time (s)               147.01227779174224
(Previous) Eval Time (s)     21.72341394983232
Sample Time (s)              6.8405166463926435
Epoch Time (s)               175.5762083879672
Total Train Time (s)         76674.1983273644
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:38:31.933868 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #452 | Epoch Duration: 175.71532654762268
2020-01-12 05:38:31.934042 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7292362
Z variance train             3.46924e-05
KL Divergence                58.227554
KL Loss                      5.8227553
QF Loss                      25024.824
VF Loss                      7626.9634
Policy Loss                  -12088.788
Q Predictions Mean           11995.692
Q Predictions Std            1561.3035
Q Predictions Max            18045.857
Q Predictions Min            8159.9316
V Predictions Mean           12109.349
V Predictions Std            1594.7563
V Predictions Max            18419.756
V Predictions Min            8554.337
Log Pis Mean                 10.242242
Log Pis Std                  3.9133856
Log Pis Max                  36.35959
Log Pis Min                  -0.13569117
Policy mu Mean               -0.2973951
Policy mu Std                1.3015682
Policy mu Max                4.959135
Policy mu Min                -4.5047746
Policy log std Mean          -1.530805
Policy log std Std           0.5265787
Policy log std Max           0.11584973
Policy log std Min           -2.981544
Z mean eval                  1.6029915
Z variance eval              1.6233354e-05
total_rewards                [-620.11609423 -259.83976286 -457.41179454 -647.31916306  176.60608897
 -977.27535724 -341.87094077 -605.27297248  151.86555419 -459.9369468 ]
total_rewards_mean           -404.0571388813939
total_rewards_std            339.3787992784334
total_rewards_max            176.60608897460884
total_rewards_min            -977.2753572417247
Number of train steps total  1816000
Number of env steps total    3342877
Number of rollouts total     0
Train Time (s)               145.92712062317878
(Previous) Eval Time (s)     25.128967294935137
Sample Time (s)              7.676974641624838
Epoch Time (s)               178.73306255973876
Total Train Time (s)         76853.14351782482
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:41:30.882998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #453 | Epoch Duration: 178.9488341808319
2020-01-12 05:41:30.883134 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5868251
Z variance train             1.6007782e-05
KL Divergence                57.47695
KL Loss                      5.7476954
QF Loss                      19306.059
VF Loss                      6251.462
Policy Loss                  -11282.833
Q Predictions Mean           11176.244
Q Predictions Std            1182.7104
Q Predictions Max            16966.848
Q Predictions Min            8427.915
V Predictions Mean           11306.018
V Predictions Std            1157.9906
V Predictions Max            16775.805
V Predictions Min            8469.179
Log Pis Mean                 10.361773
Log Pis Std                  3.7954512
Log Pis Max                  23.792835
Log Pis Min                  -2.9418762
Policy mu Mean               -0.27821594
Policy mu Std                1.2887793
Policy mu Max                4.3008275
Policy mu Min                -4.5640497
Policy log std Mean          -1.5511725
Policy log std Std           0.52315587
Policy log std Max           0.16681242
Policy log std Min           -3.0562432
Z mean eval                  2.061781
Z variance eval              2.9425963e-05
total_rewards                [  -19.43209992  -217.38441959    -3.44993789  -306.71082321
  -216.79163976 -1180.76139104  -619.43154908   -65.23232503
   227.44930094   -62.22003054]
total_rewards_mean           -246.39649151140162
total_rewards_std            376.74341504412433
total_rewards_max            227.44930093635546
total_rewards_min            -1180.761391035908
Number of train steps total  1820000
Number of env steps total    3352131
Number of rollouts total     0
Train Time (s)               145.78925307607278
(Previous) Eval Time (s)     20.047460792120546
Sample Time (s)              7.246700704563409
Epoch Time (s)               173.08341457275674
Total Train Time (s)         77026.31634276127
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:44:24.060393 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #454 | Epoch Duration: 173.17715287208557
2020-01-12 05:44:24.060560 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0530872
Z variance train             2.939298e-05
KL Divergence                52.992966
KL Loss                      5.299297
QF Loss                      193186.83
VF Loss                      5397.0186
Policy Loss                  -9568.955
Q Predictions Mean           9494.264
Q Predictions Std            1033.8013
Q Predictions Max            14290.559
Q Predictions Min            -388.57944
V Predictions Mean           9588.315
V Predictions Std            886.1786
V Predictions Max            14622.286
V Predictions Min            4934.4067
Log Pis Mean                 8.186817
Log Pis Std                  3.681702
Log Pis Max                  20.380922
Log Pis Min                  -4.957546
Policy mu Mean               -0.086449556
Policy mu Std                1.0767112
Policy mu Max                3.7904594
Policy mu Min                -3.8989463
Policy log std Mean          -1.597639
Policy log std Std           0.44611943
Policy log std Max           -0.31057537
Policy log std Min           -3.4104724
Z mean eval                  1.6948588
Z variance eval              6.676519e-05
total_rewards                [-198.38549473  331.13246009 -134.11434825 -748.53         58.61012913
 -891.06337319 -268.81386521   57.37153729 -281.49078275  207.33968505]
total_rewards_mean           -186.7944052577759
total_rewards_std            370.61787694026555
total_rewards_max            331.1324600914199
total_rewards_min            -891.0633731935433
Number of train steps total  1824000
Number of env steps total    3363168
Number of rollouts total     0
Train Time (s)               146.05887089390308
(Previous) Eval Time (s)     19.719667359255254
Sample Time (s)              7.795685305260122
Epoch Time (s)               173.57422355841845
Total Train Time (s)         77199.97899722587
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:47:17.726778 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #455 | Epoch Duration: 173.66609358787537
2020-01-12 05:47:17.726925 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6914593
Z variance train             6.679787e-05
KL Divergence                49.680565
KL Loss                      4.9680567
QF Loss                      13253.221
VF Loss                      8500.084
Policy Loss                  -8963.512
Q Predictions Mean           8900.557
Q Predictions Std            1052.7482
Q Predictions Max            12958.75
Q Predictions Min            7270.321
V Predictions Mean           9008.532
V Predictions Std            1060.1085
V Predictions Max            13054.311
V Predictions Min            7369.385
Log Pis Mean                 7.948876
Log Pis Std                  3.8565063
Log Pis Max                  34.978676
Log Pis Min                  -0.22804058
Policy mu Mean               0.061341878
Policy mu Std                1.0998744
Policy mu Max                5.357719
Policy mu Min                -4.0932245
Policy log std Mean          -1.5422435
Policy log std Std           0.43174136
Policy log std Max           0.15872097
Policy log std Min           -3.048265
Z mean eval                  1.3175683
Z variance eval              1.2797976e-05
total_rewards                [ -353.15543397 -1060.72874339  -113.22489447    44.96489384
  -155.51289877   102.37367357  -441.43335339    -9.60585948
  -157.16543333  -590.19238311]
total_rewards_mean           -273.36804325081715
total_rewards_std            334.6719896501662
total_rewards_max            102.37367356877786
total_rewards_min            -1060.7287433939553
Number of train steps total  1828000
Number of env steps total    3374956
Number of rollouts total     0
Train Time (s)               146.29200620297343
(Previous) Eval Time (s)     22.754002775996923
Sample Time (s)              7.671928936615586
Epoch Time (s)               176.71793791558594
Total Train Time (s)         77376.79108318314
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:50:14.541191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #456 | Epoch Duration: 176.81416153907776
2020-01-12 05:50:14.541334 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3170848
Z variance train             1.2820639e-05
KL Divergence                48.26046
KL Loss                      4.826046
QF Loss                      14721.473
VF Loss                      9463.82
Policy Loss                  -8004.7393
Q Predictions Mean           7958.622
Q Predictions Std            1117.4237
Q Predictions Max            12538.038
Q Predictions Min            888.0793
V Predictions Mean           8026.4463
V Predictions Std            1080.2533
V Predictions Max            12637.199
V Predictions Min            3758.3691
Log Pis Mean                 7.2042193
Log Pis Std                  4.2617836
Log Pis Max                  27.451197
Log Pis Min                  -3.895843
Policy mu Mean               0.10188183
Policy mu Std                1.0790746
Policy mu Max                4.419904
Policy mu Min                -3.515598
Policy log std Mean          -1.4606872
Policy log std Std           0.43783656
Policy log std Max           0.19650364
Policy log std Min           -3.0148416
Z mean eval                  1.4034693
Z variance eval              3.221829e-05
total_rewards                [-1264.29149752    43.69248283    48.06726012  -119.59634702
     4.73503127  -329.06146567    23.04690522   -26.68917677
    53.13777462 -1235.56420278]
total_rewards_mean           -280.2523235692039
total_rewards_std            497.04446338335936
total_rewards_max            53.137774616594115
total_rewards_min            -1264.2914975248757
Number of train steps total  1832000
Number of env steps total    3385244
Number of rollouts total     0
Train Time (s)               146.09103992208838
(Previous) Eval Time (s)     13.560337670147419
Sample Time (s)              7.386509743053466
Epoch Time (s)               167.03788733528927
Total Train Time (s)         77543.93565673754
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:53:01.692113 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #457 | Epoch Duration: 167.15068364143372
2020-01-12 05:53:01.692243 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4005997
Z variance train             3.2197124e-05
KL Divergence                47.651302
KL Loss                      4.7651305
QF Loss                      374555.12
VF Loss                      1912.5496
Policy Loss                  -7450.8296
Q Predictions Mean           7420.302
Q Predictions Std            942.6638
Q Predictions Max            12382.502
Q Predictions Min            6630.718
V Predictions Mean           7472.214
V Predictions Std            963.10345
V Predictions Max            12523.312
V Predictions Min            6567.529
Log Pis Mean                 6.5249743
Log Pis Std                  3.9554632
Log Pis Max                  20.283068
Log Pis Min                  -3.7443883
Policy mu Mean               0.09905371
Policy mu Std                1.0550758
Policy mu Max                4.059328
Policy mu Min                -4.020302
Policy log std Mean          -1.3913436
Policy log std Std           0.3951242
Policy log std Max           -0.014699459
Policy log std Min           -2.9664788
Z mean eval                  1.7151556
Z variance eval              2.1028041e-05
total_rewards                [   9.08114733 -382.14207551 -631.48239719 -200.73074227 -214.28919449
 -290.13618401 -297.5494116  -258.66574792   30.70975535  -38.20680021]
total_rewards_mean           -227.34116505098854
total_rewards_std            188.7546457667827
total_rewards_max            30.70975534603627
total_rewards_min            -631.4823971882541
Number of train steps total  1836000
Number of env steps total    3397148
Number of rollouts total     0
Train Time (s)               146.52086417982355
(Previous) Eval Time (s)     16.091428239364177
Sample Time (s)              7.107653570361435
Epoch Time (s)               169.71994598954916
Total Train Time (s)         77713.74379717559
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:55:51.507063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #458 | Epoch Duration: 169.81471252441406
2020-01-12 05:55:51.507239 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7281606
Z variance train             2.036372e-05
KL Divergence                49.33898
KL Loss                      4.9338984
QF Loss                      9900.723
VF Loss                      5009.6006
Policy Loss                  -6669.5967
Q Predictions Mean           6614.151
Q Predictions Std            823.26416
Q Predictions Max            11976.901
Q Predictions Min            5917.614
V Predictions Mean           6613.8335
V Predictions Std            823.7718
V Predictions Max            12105.953
V Predictions Min            5931.428
Log Pis Mean                 5.462008
Log Pis Std                  3.9669225
Log Pis Max                  25.14159
Log Pis Min                  -2.941768
Policy mu Mean               0.16660544
Policy mu Std                1.0484205
Policy mu Max                3.8428762
Policy mu Min                -3.3055444
Policy log std Mean          -1.2613108
Policy log std Std           0.37791604
Policy log std Max           -0.08272004
Policy log std Min           -2.8863864
Z mean eval                  1.1354798
Z variance eval              9.6497184e-05
total_rewards                [-1122.72978416  -318.5255489   -690.60329431  -802.84712192
  -392.7348654   -211.11623376  -785.03398251  -862.33632261
  -111.44213297  -943.30117199]
total_rewards_mean           -624.0670458531083
total_rewards_std            324.0107719440093
total_rewards_max            -111.44213296883053
total_rewards_min            -1122.7297841581694
Number of train steps total  1840000
Number of env steps total    3408357
Number of rollouts total     0
Train Time (s)               147.3369079111144
(Previous) Eval Time (s)     25.679945884738117
Sample Time (s)              7.484742459375411
Epoch Time (s)               180.50159625522792
Total Train Time (s)         77894.33199971588
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 05:58:52.100024 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #459 | Epoch Duration: 180.59264969825745
2020-01-12 05:58:52.100215 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1327207
Z variance train             9.855106e-05
KL Divergence                43.100006
KL Loss                      4.310001
QF Loss                      7695.8345
VF Loss                      3087.828
Policy Loss                  -5811.592
Q Predictions Mean           5796.9863
Q Predictions Std            1083.3958
Q Predictions Max            10913.339
Q Predictions Min            4747.3687
V Predictions Mean           5792.9536
V Predictions Std            1116.4513
V Predictions Max            11106.774
V Predictions Min            4736.735
Log Pis Mean                 5.0451717
Log Pis Std                  3.930085
Log Pis Max                  20.928652
Log Pis Min                  -3.1727087
Policy mu Mean               0.06292183
Policy mu Std                0.9455979
Policy mu Max                3.7121198
Policy mu Min                -3.794617
Policy log std Mean          -1.3509965
Policy log std Std           0.36512655
Policy log std Max           -0.2872311
Policy log std Min           -2.8928356
Z mean eval                  1.1472846
Z variance eval              3.3984456e-05
total_rewards                [-761.56884696 -794.17440682 -749.60733006  102.46628555 -623.1770524
 -836.46570008 -772.13170784  -20.4893438  -705.6036648  -686.1385419 ]
total_rewards_mean           -584.6890309124226
total_rewards_std            319.0285694655475
total_rewards_max            102.46628554718617
total_rewards_min            -836.465700082257
Number of train steps total  1844000
Number of env steps total    3419690
Number of rollouts total     0
Train Time (s)               147.88033078797162
(Previous) Eval Time (s)     20.300722646992654
Sample Time (s)              7.074214982334524
Epoch Time (s)               175.2552684172988
Total Train Time (s)         78069.67629746674
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:01:47.448660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #460 | Epoch Duration: 175.34825110435486
2020-01-12 06:01:47.448937 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1574014
Z variance train             3.419119e-05
KL Divergence                42.39788
KL Loss                      4.239788
QF Loss                      14846.684
VF Loss                      2142.1958
Policy Loss                  -5200.585
Q Predictions Mean           5171.8877
Q Predictions Std            1201.1398
Q Predictions Max            10750.772
Q Predictions Min            1175.2297
V Predictions Mean           5210.0146
V Predictions Std            1228.4471
V Predictions Max            10784.753
V Predictions Min            1004.5196
Log Pis Mean                 5.0492516
Log Pis Std                  4.19934
Log Pis Max                  33.8483
Log Pis Min                  -4.6032085
Policy mu Mean               0.10513145
Policy mu Std                0.9850745
Policy mu Max                3.9554517
Policy mu Min                -4.457886
Policy log std Mean          -1.2859433
Policy log std Std           0.34704494
Policy log std Max           -0.12815595
Policy log std Min           -2.5572848
Z mean eval                  1.1576014
Z variance eval              2.1908434e-05
total_rewards                [   37.52189556  -814.23386532    23.6082852     14.49294861
 -1079.68519715  -640.88626148  -311.32783911  -540.50395523
  -743.43319988   226.33285185]
total_rewards_mean           -382.8114336947735
total_rewards_std            420.61270733717845
total_rewards_max            226.33285185343559
total_rewards_min            -1079.6851971484773
Number of train steps total  1848000
Number of env steps total    3431920
Number of rollouts total     0
Train Time (s)               149.59490084694698
(Previous) Eval Time (s)     15.938684701919556
Sample Time (s)              7.9460911033675075
Epoch Time (s)               173.47967665223405
Total Train Time (s)         78243.24795878027
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:04:41.022689 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #461 | Epoch Duration: 173.57360243797302
2020-01-12 06:04:41.022854 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1547865
Z variance train             2.192722e-05
KL Divergence                41.030304
KL Loss                      4.1030307
QF Loss                      2541.3975
VF Loss                      1016.4119
Policy Loss                  -4304.47
Q Predictions Mean           4278.4883
Q Predictions Std            689.2874
Q Predictions Max            9156.021
Q Predictions Min            3123.9824
V Predictions Mean           4319.6523
V Predictions Std            701.5471
V Predictions Max            9228.539
V Predictions Min            3495.8074
Log Pis Mean                 4.5611057
Log Pis Std                  3.865164
Log Pis Max                  19.694267
Log Pis Min                  -5.991001
Policy mu Mean               -0.035196792
Policy mu Std                0.9674481
Policy mu Max                4.2804704
Policy mu Min                -3.5264714
Policy log std Mean          -1.2396631
Policy log std Std           0.32900515
Policy log std Max           -0.15724456
Policy log std Min           -2.7067096
Z mean eval                  0.92981815
Z variance eval              1.9091789e-05
total_rewards                [ -607.48736272  -860.04338699    15.32875814  -137.22204508
 -1181.23047615  -928.93958173  -456.97963293  -278.56095595
 -1014.17855701  -953.63801777]
total_rewards_mean           -640.2951258195346
total_rewards_std            388.6703348840695
total_rewards_max            15.328758135397806
total_rewards_min            -1181.2304761549963
Number of train steps total  1852000
Number of env steps total    3441995
Number of rollouts total     0
Train Time (s)               147.96116839908063
(Previous) Eval Time (s)     23.064367739018053
Sample Time (s)              7.402572041377425
Epoch Time (s)               178.4281081794761
Total Train Time (s)         78421.76760578854
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:07:39.545983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #462 | Epoch Duration: 178.52296257019043
2020-01-12 06:07:39.546206 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9258952
Z variance train             1.9362193e-05
KL Divergence                40.283863
KL Loss                      4.0283866
QF Loss                      3243.7522
VF Loss                      1243.317
Policy Loss                  -4209.087
Q Predictions Mean           4196.4756
Q Predictions Std            979.08954
Q Predictions Max            9672.684
Q Predictions Min            3260.3972
V Predictions Mean           4201.9727
V Predictions Std            983.8823
V Predictions Max            9743.548
V Predictions Min            3324.26
Log Pis Mean                 5.1130905
Log Pis Std                  4.022194
Log Pis Max                  20.997517
Log Pis Min                  -5.657748
Policy mu Mean               -0.05548782
Policy mu Std                1.0081506
Policy mu Max                3.1292713
Policy mu Min                -3.728882
Policy log std Mean          -1.258951
Policy log std Std           0.3721746
Policy log std Max           -0.09613621
Policy log std Min           -2.8686378
Z mean eval                  1.5090271
Z variance eval              1.5809333e-05
total_rewards                [ 202.57884397    7.91787699 -881.9902462  -402.29003377 -613.34638689
 -559.53880455 -561.89526834 -467.48362741   63.70792901 -750.29582953]
total_rewards_mean           -396.26355467201995
total_rewards_std            346.57526303268236
total_rewards_max            202.5788439682106
total_rewards_min            -881.9902462030275
Number of train steps total  1856000
Number of env steps total    3451684
Number of rollouts total     0
Train Time (s)               147.74874881887808
(Previous) Eval Time (s)     18.239955348894
Sample Time (s)              7.548594252672046
Epoch Time (s)               173.53729842044413
Total Train Time (s)         78595.39672843413
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:10:33.177724 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #463 | Epoch Duration: 173.63140058517456
2020-01-12 06:10:33.177851 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4994686
Z variance train             1.5746857e-05
KL Divergence                38.377583
KL Loss                      3.8377583
QF Loss                      4214.973
VF Loss                      4125.9023
Policy Loss                  -3353.6804
Q Predictions Mean           3329.7395
Q Predictions Std            803.21985
Q Predictions Max            7286.461
Q Predictions Min            893.28864
V Predictions Mean           3366.0107
V Predictions Std            801.8903
V Predictions Max            7408.3833
V Predictions Min            1875.2008
Log Pis Mean                 5.1767054
Log Pis Std                  3.76785
Log Pis Max                  21.9856
Log Pis Min                  -6.1795816
Policy mu Mean               -0.17194065
Policy mu Std                1.001279
Policy mu Max                3.691813
Policy mu Min                -3.5993419
Policy log std Mean          -1.2809994
Policy log std Std           0.38625908
Policy log std Max           -0.03670454
Policy log std Min           -2.7010503
Z mean eval                  0.96549445
Z variance eval              9.125089e-06
total_rewards                [ 132.84059192  -34.42391129 -489.54787605 -163.04889242  158.77434823
 -504.75368673  254.16799528 -453.78197036 -412.4764091   138.54505265]
total_rewards_mean           -137.37047578921369
total_rewards_std            289.17187979886637
total_rewards_max            254.1679952761551
total_rewards_min            -504.75368673446883
Number of train steps total  1860000
Number of env steps total    3462087
Number of rollouts total     0
Train Time (s)               147.94108371483162
(Previous) Eval Time (s)     20.08233520993963
Sample Time (s)              7.203730748500675
Epoch Time (s)               175.22714967327192
Total Train Time (s)         78770.71365261683
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:13:28.501600 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #464 | Epoch Duration: 175.3236482143402
2020-01-12 06:13:28.501757 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9551504
Z variance train             9.318214e-06
KL Divergence                39.60658
KL Loss                      3.9606578
QF Loss                      12148.119
VF Loss                      1051.9581
Policy Loss                  -3764.4045
Q Predictions Mean           3748.8787
Q Predictions Std            849.8222
Q Predictions Max            7840.539
Q Predictions Min            3193.2156
V Predictions Mean           3775.6555
V Predictions Std            853.0434
V Predictions Max            7857.2544
V Predictions Min            3224.1377
Log Pis Mean                 5.0653524
Log Pis Std                  3.368479
Log Pis Max                  14.476103
Log Pis Min                  -3.5609164
Policy mu Mean               -0.107543156
Policy mu Std                0.9599206
Policy mu Max                3.4613993
Policy mu Min                -3.317113
Policy log std Mean          -1.3172626
Policy log std Std           0.35825303
Policy log std Max           -0.15791035
Policy log std Min           -2.481338
Z mean eval                  1.0569147
Z variance eval              0.000105465515
total_rewards                [-1299.52920038    34.24982653  -636.03294494  -824.46849858
  -563.53103828  -742.01064919  -260.83359251  -422.30944916
   220.62056535    15.10898449]
total_rewards_mean           -447.87359966846634
total_rewards_std            439.5174599946144
total_rewards_max            220.6205653539569
total_rewards_min            -1299.5292003832105
Number of train steps total  1864000
Number of env steps total    3472840
Number of rollouts total     0
Train Time (s)               148.25935381278396
(Previous) Eval Time (s)     25.225129560101777
Sample Time (s)              7.602202809881419
Epoch Time (s)               181.08668618276715
Total Train Time (s)         78951.89425248234
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:16:29.686075 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #465 | Epoch Duration: 181.1842017173767
2020-01-12 06:16:29.686204 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0539323
Z variance train             0.00010523584
KL Divergence                36.098812
KL Loss                      3.6098812
QF Loss                      4981.9316
VF Loss                      1348.3865
Policy Loss                  -3298.2686
Q Predictions Mean           3276.1504
Q Predictions Std            582.7932
Q Predictions Max            6237.283
Q Predictions Min            2336.5322
V Predictions Mean           3298.624
V Predictions Std            591.2781
V Predictions Max            6257.392
V Predictions Min            2395.7898
Log Pis Mean                 5.2309866
Log Pis Std                  3.8362017
Log Pis Max                  26.001112
Log Pis Min                  -2.790714
Policy mu Mean               -0.10872041
Policy mu Std                0.9446148
Policy mu Max                4.106602
Policy mu Min                -3.8281949
Policy log std Mean          -1.3859906
Policy log std Std           0.37649116
Policy log std Max           -0.010946274
Policy log std Min           -3.289177
Z mean eval                  1.2305691
Z variance eval              2.3314875e-05
total_rewards                [-322.28767892  492.73153365 1550.73511705 1463.08740562 -128.66302961
  678.28998156 -182.14519729  189.23724705  436.03764751  -22.33954277]
total_rewards_mean           415.4683483862138
total_rewards_std            624.6731429254168
total_rewards_max            1550.7351170489583
total_rewards_min            -322.28767891709504
Number of train steps total  1868000
Number of env steps total    3483560
Number of rollouts total     0
Train Time (s)               148.37941644480452
(Previous) Eval Time (s)     24.335750740021467
Sample Time (s)              8.036660219542682
Epoch Time (s)               180.75182740436867
Total Train Time (s)         79132.73753037583
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:19:30.533022 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #466 | Epoch Duration: 180.84672164916992
2020-01-12 06:19:30.533154 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2279422
Z variance train             2.3268725e-05
KL Divergence                40.190323
KL Loss                      4.0190325
QF Loss                      2715.5747
VF Loss                      2001.3383
Policy Loss                  -3373.5725
Q Predictions Mean           3357.6685
Q Predictions Std            556.1645
Q Predictions Max            6185.07
Q Predictions Min            2348.686
V Predictions Mean           3372.3494
V Predictions Std            575.632
V Predictions Max            6296.702
V Predictions Min            2339.7039
Log Pis Mean                 4.394955
Log Pis Std                  3.1805375
Log Pis Max                  14.775993
Log Pis Min                  -4.6789703
Policy mu Mean               0.040857304
Policy mu Std                0.85894054
Policy mu Max                3.6340773
Policy mu Min                -2.9677343
Policy log std Mean          -1.343392
Policy log std Std           0.33896926
Policy log std Max           -0.22128332
Policy log std Min           -2.421115
Z mean eval                  1.0943086
Z variance eval              1.2356977e-05
total_rewards                [-737.50673027 1250.69387254  912.54718606 1579.94953372 -280.43479193
 1331.17018342  135.31019959 -493.77863171  -38.95233124  224.51931642]
total_rewards_mean           388.3517806608657
total_rewards_std            780.6198373734544
total_rewards_max            1579.9495337208339
total_rewards_min            -737.5067302694127
Number of train steps total  1872000
Number of env steps total    3492749
Number of rollouts total     0
Train Time (s)               148.5564217949286
(Previous) Eval Time (s)     21.680115068797022
Sample Time (s)              7.325391119346023
Epoch Time (s)               177.56192798307166
Total Train Time (s)         79310.38192781108
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:22:28.179687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #467 | Epoch Duration: 177.64644026756287
2020-01-12 06:22:28.179809 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0784762
Z variance train             1.2407478e-05
KL Divergence                39.40237
KL Loss                      3.940237
QF Loss                      5016.715
VF Loss                      949.90216
Policy Loss                  -3092.9502
Q Predictions Mean           3084.7666
Q Predictions Std            268.71045
Q Predictions Max            5098.5176
Q Predictions Min            1926.8027
V Predictions Mean           3099.1116
V Predictions Std            260.92377
V Predictions Max            5101.6533
V Predictions Min            2131.5063
Log Pis Mean                 4.209127
Log Pis Std                  2.9792848
Log Pis Max                  26.261244
Log Pis Min                  -2.751596
Policy mu Mean               -0.015820354
Policy mu Std                0.8582002
Policy mu Max                3.8742726
Policy mu Min                -2.2604735
Policy log std Mean          -1.3310077
Policy log std Std           0.30308282
Policy log std Max           -0.2577517
Policy log std Min           -2.583698
Z mean eval                  1.0023615
Z variance eval              0.054663103
total_rewards                [ -88.88664673  639.86836902 2392.84612285  251.13748257 -357.07548354
  131.90880189 2415.61128116   74.15089031  -80.26346922 1784.52822496]
total_rewards_mean           716.3825573264322
total_rewards_std            1012.4543220977065
total_rewards_max            2415.611281160659
total_rewards_min            -357.0754835448942
Number of train steps total  1876000
Number of env steps total    3503278
Number of rollouts total     0
Train Time (s)               147.37645858665928
(Previous) Eval Time (s)     22.63912422209978
Sample Time (s)              6.730565048754215
Epoch Time (s)               176.74614785751328
Total Train Time (s)         79487.21542976052
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:25:25.018330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #468 | Epoch Duration: 176.83842706680298
2020-01-12 06:25:25.018464 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9967818
Z variance train             0.06525721
KL Divergence                31.416542
KL Loss                      3.1416543
QF Loss                      145429.4
VF Loss                      719.0478
Policy Loss                  -2852.6611
Q Predictions Mean           2834.5422
Q Predictions Std            438.0053
Q Predictions Max            4822.3604
Q Predictions Min            1861.226
V Predictions Mean           2846.1787
V Predictions Std            417.65533
V Predictions Max            4755.096
V Predictions Min            1980.6215
Log Pis Mean                 3.9660702
Log Pis Std                  3.1616852
Log Pis Max                  13.215675
Log Pis Min                  -5.879257
Policy mu Mean               0.042169616
Policy mu Std                0.8310432
Policy mu Max                2.8404677
Policy mu Min                -3.2024853
Policy log std Mean          -1.3161659
Policy log std Std           0.3080628
Policy log std Max           0.11121917
Policy log std Min           -2.2790267
Z mean eval                  4.3726573
Z variance eval              0.033479948
total_rewards                [   53.35163098  -480.3486464    269.96295214   139.87270756
   294.03881174    11.1793596   -482.71896603   458.19613323
   109.64278957 -1887.01881561]
total_rewards_mean           -151.38420432249544
total_rewards_std            648.0170109350369
total_rewards_max            458.19613322513453
total_rewards_min            -1887.0188156092875
Number of train steps total  1880000
Number of env steps total    3513499
Number of rollouts total     0
Train Time (s)               148.69299873430282
(Previous) Eval Time (s)     8.755449851974845
Sample Time (s)              7.134631438180804
Epoch Time (s)               164.58308002445847
Total Train Time (s)         79651.94008287974
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:28:09.747917 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #469 | Epoch Duration: 164.72934460639954
2020-01-12 06:28:09.748108 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.352763
Z variance train             0.033467196
KL Divergence                80.96639
KL Loss                      8.09664
QF Loss                      2279.2183
VF Loss                      486.78687
Policy Loss                  -1097.6683
Q Predictions Mean           1072.3721
Q Predictions Std            229.13681
Q Predictions Max            1824.2246
Q Predictions Min            746.92474
V Predictions Mean           1093.6838
V Predictions Std            219.44992
V Predictions Max            1738.6879
V Predictions Min            719.26447
Log Pis Mean                 4.753346
Log Pis Std                  3.4652436
Log Pis Max                  19.319237
Log Pis Min                  -4.339289
Policy mu Mean               -0.1484845
Policy mu Std                1.140071
Policy mu Max                3.0796206
Policy mu Min                -3.5822253
Policy log std Mean          -0.97626984
Policy log std Std           0.29687476
Policy log std Max           -0.061787367
Policy log std Min           -2.1852715
Z mean eval                  1.6314484
Z variance eval              0.016657451
total_rewards                [  -26.66652577   484.83598436    93.49426726   835.92166878
   402.03948279  1411.97709421  1213.12088704   100.39154233
 -1568.9045929    995.378037  ]
total_rewards_mean           394.15878451033404
total_rewards_std            804.9202844016546
total_rewards_max            1411.977094213046
total_rewards_min            -1568.904592902341
Number of train steps total  1884000
Number of env steps total    3523514
Number of rollouts total     0
Train Time (s)               148.00580214103684
(Previous) Eval Time (s)     20.01201645284891
Sample Time (s)              8.188794095534831
Epoch Time (s)               176.20661268942058
Total Train Time (s)         79828.24390609143
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:31:06.054871 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #470 | Epoch Duration: 176.30663418769836
2020-01-12 06:31:06.055003 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6306814
Z variance train             0.016467448
KL Divergence                34.005615
KL Loss                      3.4005616
QF Loss                      2950.9585
VF Loss                      197.84042
Policy Loss                  -2344.9434
Q Predictions Mean           2335.1084
Q Predictions Std            241.28413
Q Predictions Max            3273.1865
Q Predictions Min            1746.0428
V Predictions Mean           2343.9465
V Predictions Std            239.04588
V Predictions Max            3297.701
V Predictions Min            1775.909
Log Pis Mean                 3.2666926
Log Pis Std                  3.2386642
Log Pis Max                  17.917362
Log Pis Min                  -4.1171694
Policy mu Mean               0.008279169
Policy mu Std                0.78749657
Policy mu Max                4.144146
Policy mu Min                -3.6668134
Policy log std Mean          -1.2762353
Policy log std Std           0.3238139
Policy log std Max           0.03944397
Policy log std Min           -2.4430203
Z mean eval                  0.9293734
Z variance eval              0.026882296
total_rewards                [1902.60667557  268.81134388  139.76560193 2411.01114904  273.89677449
  333.26267176  364.70864226 1038.58077465 -284.86284235   78.32248709]
total_rewards_mean           652.6103278307373
total_rewards_std            821.6267769800756
total_rewards_max            2411.0111490403096
total_rewards_min            -284.8628423542582
Number of train steps total  1888000
Number of env steps total    3535373
Number of rollouts total     0
Train Time (s)               147.34190712310374
(Previous) Eval Time (s)     12.74972628382966
Sample Time (s)              7.208061465993524
Epoch Time (s)               167.29969487292692
Total Train Time (s)         79995.63554300042
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:33:53.450182 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #471 | Epoch Duration: 167.39508628845215
2020-01-12 06:33:53.450324 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9083227
Z variance train             0.026760513
KL Divergence                31.51176
KL Loss                      3.1511762
QF Loss                      46625.53
VF Loss                      392.1058
Policy Loss                  -2407.3115
Q Predictions Mean           2395.0195
Q Predictions Std            249.65828
Q Predictions Max            3492.727
Q Predictions Min            1517.3749
V Predictions Mean           2410.3784
V Predictions Std            247.30292
V Predictions Max            3488.4456
V Predictions Min            1611.9113
Log Pis Mean                 2.6479366
Log Pis Std                  2.9909267
Log Pis Max                  12.265888
Log Pis Min                  -6.665866
Policy mu Mean               -0.0007388771
Policy mu Std                0.7207685
Policy mu Max                2.82962
Policy mu Min                -2.5394475
Policy log std Mean          -1.2723607
Policy log std Std           0.29238427
Policy log std Max           -0.31548524
Policy log std Min           -2.4171224
Z mean eval                  1.0737073
Z variance eval              0.0074240416
total_rewards                [ 186.26533952 -165.38053772 -177.71759509  151.7749352   630.85367299
 -325.91988184  295.76176163 1102.40165845  675.79512105  105.28418756]
total_rewards_mean           247.91186617516004
total_rewards_std            421.52225418243677
total_rewards_max            1102.4016584527058
total_rewards_min            -325.9198818420859
Number of train steps total  1892000
Number of env steps total    3545232
Number of rollouts total     0
Train Time (s)               148.18306762399152
(Previous) Eval Time (s)     10.056848865002394
Sample Time (s)              7.464128938969225
Epoch Time (s)               165.70404542796314
Total Train Time (s)         80161.42807221832
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:36:39.245504 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #472 | Epoch Duration: 165.79508113861084
2020-01-12 06:36:39.245634 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0759951
Z variance train             0.007401912
KL Divergence                33.45966
KL Loss                      3.345966
QF Loss                      2026.6256
VF Loss                      793.011
Policy Loss                  -2283.5405
Q Predictions Mean           2277.9944
Q Predictions Std            271.85495
Q Predictions Max            3461.3577
Q Predictions Min            1472.5406
V Predictions Mean           2272.0293
V Predictions Std            273.1846
V Predictions Max            3438.6763
V Predictions Min            1477.1775
Log Pis Mean                 2.8064208
Log Pis Std                  3.0497808
Log Pis Max                  14.59741
Log Pis Min                  -5.683853
Policy mu Mean               0.0043203947
Policy mu Std                0.76620173
Policy mu Max                3.2244473
Policy mu Min                -2.742072
Policy log std Mean          -1.2311889
Policy log std Std           0.2934198
Policy log std Max           0.23904967
Policy log std Min           -2.3915927
Z mean eval                  0.7250615
Z variance eval              0.0017858429
total_rewards                [ 1567.73889406   801.17276252  1507.66872396  1419.39992544
   805.47936668 -1131.56364305  -203.08008236  3190.93346563
  1932.36445864  3000.35295145]
total_rewards_mean           1289.0466822965102
total_rewards_std            1251.3877136252408
total_rewards_max            3190.933465625347
total_rewards_min            -1131.5636430508039
Number of train steps total  1896000
Number of env steps total    3556031
Number of rollouts total     0
Train Time (s)               148.0598990637809
(Previous) Eval Time (s)     17.75516542000696
Sample Time (s)              8.492174487560987
Epoch Time (s)               174.30723897134885
Total Train Time (s)         80335.86148270546
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:39:33.683490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #473 | Epoch Duration: 174.43774151802063
2020-01-12 06:39:33.683679 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72177136
Z variance train             0.0017787669
KL Divergence                30.614096
KL Loss                      3.0614097
QF Loss                      4744.1797
VF Loss                      324.89352
Policy Loss                  -1999.3098
Q Predictions Mean           1981.769
Q Predictions Std            253.34741
Q Predictions Max            2968.3328
Q Predictions Min            1092.359
V Predictions Mean           1988.6
V Predictions Std            254.04167
V Predictions Max            3007.21
V Predictions Min            1112.7642
Log Pis Mean                 2.8246558
Log Pis Std                  2.7499878
Log Pis Max                  14.556831
Log Pis Min                  -7.037307
Policy mu Mean               0.012996391
Policy mu Std                0.78874195
Policy mu Max                2.810055
Policy mu Min                -2.6626244
Policy log std Mean          -1.2065735
Policy log std Std           0.28828874
Policy log std Max           -0.3933034
Policy log std Min           -2.3986626
Z mean eval                  0.7807868
Z variance eval              0.0013069129
total_rewards                [2620.38599555  738.0556222  3510.63284715 1243.1319328  3983.37492127
 1195.85381495  224.80631784 2181.50440476  337.45649925 1725.37180321]
total_rewards_mean           1776.0574158989034
total_rewards_std            1222.0841058693366
total_rewards_max            3983.3749212697317
total_rewards_min            224.80631783866914
Number of train steps total  1900000
Number of env steps total    3566729
Number of rollouts total     0
Train Time (s)               147.87957631098107
(Previous) Eval Time (s)     19.754882929380983
Sample Time (s)              7.485087345354259
Epoch Time (s)               175.1195465857163
Total Train Time (s)         80511.06927484553
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:42:28.897579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #474 | Epoch Duration: 175.2137634754181
2020-01-12 06:42:28.897720 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77016014
Z variance train             0.0013092465
KL Divergence                30.715298
KL Loss                      3.0715299
QF Loss                      1184.5117
VF Loss                      614.28076
Policy Loss                  -1824.6278
Q Predictions Mean           1822.4198
Q Predictions Std            266.44592
Q Predictions Max            2454.1724
Q Predictions Min            919.93176
V Predictions Mean           1838.176
V Predictions Std            260.95572
V Predictions Max            2486.6052
V Predictions Min            930.20856
Log Pis Mean                 2.2418122
Log Pis Std                  3.091918
Log Pis Max                  15.062527
Log Pis Min                  -7.1998997
Policy mu Mean               0.0093769375
Policy mu Std                0.7573174
Policy mu Max                3.1426742
Policy mu Min                -3.150075
Policy log std Mean          -1.1672088
Policy log std Std           0.28319004
Policy log std Max           0.08154464
Policy log std Min           -2.157644
Z mean eval                  3.7560525
Z variance eval              0.000104471306
total_rewards                [ 254.56742838  725.7187769   919.53661666   69.31660474  964.33795823
 3215.15551981 -446.38284     387.24478308  995.36505043  487.82230259]
total_rewards_mean           757.2682200822109
total_rewards_std            924.7910135267713
total_rewards_max            3215.155519811881
total_rewards_min            -446.3828399998052
Number of train steps total  1904000
Number of env steps total    3577367
Number of rollouts total     0
Train Time (s)               147.76922325091437
(Previous) Eval Time (s)     9.39796139812097
Sample Time (s)              7.745114170946181
Epoch Time (s)               164.91229881998152
Total Train Time (s)         80676.07030671462
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:45:13.902749 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #475 | Epoch Duration: 165.00492930412292
2020-01-12 06:45:13.902880 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.7432067
Z variance train             0.00010404787
KL Divergence                73.51783
KL Loss                      7.3517833
QF Loss                      1143.5797
VF Loss                      292.3486
Policy Loss                  -762.49915
Q Predictions Mean           753.40564
Q Predictions Std            162.53308
Q Predictions Max            1262.8206
Q Predictions Min            342.90094
V Predictions Mean           758.5608
V Predictions Std            161.12038
V Predictions Max            1267.8557
V Predictions Min            353.55807
Log Pis Mean                 2.6541603
Log Pis Std                  2.8581727
Log Pis Max                  13.175014
Log Pis Min                  -6.9284825
Policy mu Mean               -0.1371724
Policy mu Std                0.88565075
Policy mu Max                3.4231815
Policy mu Min                -3.4328964
Policy log std Mean          -1.033627
Policy log std Std           0.29605305
Policy log std Max           0.15848732
Policy log std Min           -2.5004168
Z mean eval                  2.0469708
Z variance eval              0.00011012895
total_rewards                [ 218.14691016 1220.57878533  751.94948988 1764.00949388 -671.10043501
 1213.30249924 2339.77116256  862.08406905 1072.53376366 -571.4569651 ]
total_rewards_mean           819.9818773644723
total_rewards_std            900.4412198648915
total_rewards_max            2339.7711625583306
total_rewards_min            -671.1004350143589
Number of train steps total  1908000
Number of env steps total    3586622
Number of rollouts total     0
Train Time (s)               145.43824985018
(Previous) Eval Time (s)     21.424984036944807
Sample Time (s)              6.422847305890173
Epoch Time (s)               173.28608119301498
Total Train Time (s)         80849.44187368872
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:48:07.277317 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #476 | Epoch Duration: 173.37434077262878
2020-01-12 06:48:07.277448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.041883
Z variance train             0.000110955225
KL Divergence                43.52166
KL Loss                      4.352166
QF Loss                      1007.87866
VF Loss                      431.36966
Policy Loss                  -2233.109
Q Predictions Mean           2228.6262
Q Predictions Std            261.53937
Q Predictions Max            2721.5044
Q Predictions Min            921.7295
V Predictions Mean           2242.5393
V Predictions Std            261.4387
V Predictions Max            2700.1614
V Predictions Min            976.18634
Log Pis Mean                 2.03581
Log Pis Std                  2.899427
Log Pis Max                  13.671572
Log Pis Min                  -5.776041
Policy mu Mean               0.02242396
Policy mu Std                0.7411155
Policy mu Max                2.5568094
Policy mu Min                -3.297153
Policy log std Mean          -1.1377571
Policy log std Std           0.27544606
Policy log std Max           0.16444623
Policy log std Min           -2.341895
Z mean eval                  4.276595
Z variance eval              1.8196619e-05
total_rewards                [  -11.139314    -314.15600987  -350.15942436  -296.25200662
  -439.93441316  -270.31738184 -1277.39219394     1.52483582
     1.9512256    -22.99234174]
total_rewards_mean           -297.88670241058315
total_rewards_std            363.4156647883195
total_rewards_max            1.9512255958822973
total_rewards_min            -1277.3921939374527
Number of train steps total  1912000
Number of env steps total    3598677
Number of rollouts total     0
Train Time (s)               147.12546565989032
(Previous) Eval Time (s)     12.471411161124706
Sample Time (s)              7.471262346487492
Epoch Time (s)               167.06813916750252
Total Train Time (s)         81016.59344373085
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:50:54.433898 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #477 | Epoch Duration: 167.15633940696716
2020-01-12 06:50:54.434071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 4.2765174
Z variance train             1.8225715e-05
KL Divergence                90.067566
KL Loss                      9.006757
QF Loss                      710.65717
VF Loss                      188.68486
Policy Loss                  -594.6512
Q Predictions Mean           588.29626
Q Predictions Std            116.0164
Q Predictions Max            1004.65985
Q Predictions Min            227.66417
V Predictions Mean           594.5247
V Predictions Std            116.492836
V Predictions Max            1051.9854
V Predictions Min            231.57603
Log Pis Mean                 1.2965288
Log Pis Std                  2.703315
Log Pis Max                  15.923839
Log Pis Min                  -7.174333
Policy mu Mean               -0.013288058
Policy mu Std                0.76411396
Policy mu Max                3.029242
Policy mu Min                -2.4143348
Policy log std Mean          -1.0110337
Policy log std Std           0.25971153
Policy log std Max           0.18275666
Policy log std Min           -1.7793123
Z mean eval                  3.1301136
Z variance eval              4.364759e-05
total_rewards                [  95.47938779  -53.48653415  185.8194328   544.00401473 1249.0264813
  187.92644614 1198.63845053  -46.87657729   30.8311574    41.74675508]
total_rewards_mean           343.3109014332203
total_rewards_std            469.13015279539877
total_rewards_max            1249.0264813045324
total_rewards_min            -53.486534154216486
Number of train steps total  1916000
Number of env steps total    3609722
Number of rollouts total     0
Train Time (s)               148.1644321968779
(Previous) Eval Time (s)     13.099777644965798
Sample Time (s)              7.455973946023732
Epoch Time (s)               168.72018378786743
Total Train Time (s)         81185.40628422657
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:53:43.250485 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #478 | Epoch Duration: 168.8162841796875
2020-01-12 06:53:43.250647 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.13111
Z variance train             4.4186563e-05
KL Divergence                62.83021
KL Loss                      6.2830215
QF Loss                      575.8749
VF Loss                      149.67357
Policy Loss                  -767.12494
Q Predictions Mean           761.13763
Q Predictions Std            136.32983
Q Predictions Max            1343.6929
Q Predictions Min            347.4822
V Predictions Mean           768.02234
V Predictions Std            135.09897
V Predictions Max            1345.1726
V Predictions Min            346.19867
Log Pis Mean                 1.526191
Log Pis Std                  2.4258063
Log Pis Max                  8.457172
Log Pis Min                  -8.532937
Policy mu Mean               -0.028038785
Policy mu Std                0.7323719
Policy mu Max                2.4611783
Policy mu Min                -2.596137
Policy log std Mean          -1.0775986
Policy log std Std           0.25648832
Policy log std Max           -0.09913957
Policy log std Min           -1.865125
Z mean eval                  1.1484871
Z variance eval              0.00023350058
total_rewards                [  64.70596076  474.67150267  496.27394366   39.94361243 -134.75418009
   58.05653707 1615.95888556  -57.49992448  919.96887211  175.42343157]
total_rewards_mean           365.27486412632004
total_rewards_std            515.4028201500986
total_rewards_max            1615.9588855599818
total_rewards_min            -134.75418008732336
Number of train steps total  1920000
Number of env steps total    3618603
Number of rollouts total     0
Train Time (s)               147.56905968906358
(Previous) Eval Time (s)     12.935387190897018
Sample Time (s)              7.931770177092403
Epoch Time (s)               168.436217057053
Total Train Time (s)         81353.93990368396
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:56:31.788561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #479 | Epoch Duration: 168.53779435157776
2020-01-12 06:56:31.788743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1523349
Z variance train             0.00023349149
KL Divergence                35.04637
KL Loss                      3.5046372
QF Loss                      943.7732
VF Loss                      278.89392
Policy Loss                  -1397.843
Q Predictions Mean           1387.0132
Q Predictions Std            232.46278
Q Predictions Max            2026.8099
Q Predictions Min            584.7229
V Predictions Mean           1401.9569
V Predictions Std            232.20575
V Predictions Max            2017.0903
V Predictions Min            597.7649
Log Pis Mean                 2.962514
Log Pis Std                  2.7312894
Log Pis Max                  17.004028
Log Pis Min                  -6.547989
Policy mu Mean               0.0065829693
Policy mu Std                0.811399
Policy mu Max                2.6741061
Policy mu Min                -2.918825
Policy log std Mean          -1.1891177
Policy log std Std           0.31084508
Policy log std Max           -0.03864324
Policy log std Min           -2.5626302
Z mean eval                  0.7470652
Z variance eval              0.00047368027
total_rewards                [2503.29474589  845.92053506 2074.63868072  445.76361764 4050.91634562
 1483.86739578 4161.27858646 4363.53887155 3839.62602434 4075.04852369]
total_rewards_mean           2784.3893326760162
total_rewards_std            1423.8645496673646
total_rewards_max            4363.538871553705
total_rewards_min            445.7636176371449
Number of train steps total  1924000
Number of env steps total    3627879
Number of rollouts total     0
Train Time (s)               150.912281868048
(Previous) Eval Time (s)     20.05512822372839
Sample Time (s)              7.923218499403447
Epoch Time (s)               178.89062859117985
Total Train Time (s)         81532.93747878866
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 06:59:30.793502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #480 | Epoch Duration: 179.00462293624878
2020-01-12 06:59:30.793678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7447759
Z variance train             0.00046936033
KL Divergence                31.357918
KL Loss                      3.1357918
QF Loss                      866.93994
VF Loss                      235.91064
Policy Loss                  -1714.0767
Q Predictions Mean           1705.1559
Q Predictions Std            334.99237
Q Predictions Max            2345.0806
Q Predictions Min            673.29614
V Predictions Mean           1708.0537
V Predictions Std            333.88647
V Predictions Max            2329.2292
V Predictions Min            665.0971
Log Pis Mean                 2.1858706
Log Pis Std                  2.4921672
Log Pis Max                  11.157324
Log Pis Min                  -8.776588
Policy mu Mean               0.029982854
Policy mu Std                0.71071154
Policy mu Max                3.8488703
Policy mu Min                -2.5493598
Policy log std Mean          -1.1818678
Policy log std Std           0.27880347
Policy log std Max           0.096624136
Policy log std Min           -2.080783
Z mean eval                  0.87781334
Z variance eval              0.0008011276
total_rewards                [3875.83539304 1210.25751198 1545.71697299 2435.59244522  997.53279549
  765.14490773 3693.98155356 3007.3188194   931.77176607  145.2962176 ]
total_rewards_mean           1860.8448383073824
total_rewards_std            1238.5489033069841
total_rewards_max            3875.8353930356893
total_rewards_min            145.29621759728656
Number of train steps total  1928000
Number of env steps total    3639586
Number of rollouts total     0
Train Time (s)               148.44545076508075
(Previous) Eval Time (s)     14.969400434289128
Sample Time (s)              7.319969943724573
Epoch Time (s)               170.73482114309445
Total Train Time (s)         81703.76266089687
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:02:21.628087 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #481 | Epoch Duration: 170.8342764377594
2020-01-12 07:02:21.628264 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88254166
Z variance train             0.0008066627
KL Divergence                31.676344
KL Loss                      3.1676345
QF Loss                      842.8109
VF Loss                      768.60925
Policy Loss                  -1741.992
Q Predictions Mean           1736.8402
Q Predictions Std            360.48676
Q Predictions Max            2314.2126
Q Predictions Min            163.80457
V Predictions Mean           1756.2056
V Predictions Std            361.46115
V Predictions Max            2317.0593
V Predictions Min            220.02525
Log Pis Mean                 2.163561
Log Pis Std                  3.304251
Log Pis Max                  27.403683
Log Pis Min                  -8.431429
Policy mu Mean               0.07786353
Policy mu Std                0.75352055
Policy mu Max                3.5522356
Policy mu Min                -4.2575274
Policy log std Mean          -1.1571522
Policy log std Std           0.31010526
Policy log std Max           0.1562475
Policy log std Min           -2.596126
Z mean eval                  1.0390561
Z variance eval              0.0061808093
total_rewards                [3956.05102917  744.13267026  536.87567758  109.39620075 4294.40410632
   50.04665731  105.74909994 3105.61932949 1910.57628479   85.98983487]
total_rewards_mean           1489.8840890476442
total_rewards_std            1614.4625046785557
total_rewards_max            4294.404106321908
total_rewards_min            50.04665730814504
Number of train steps total  1932000
Number of env steps total    3650140
Number of rollouts total     0
Train Time (s)               147.19460494909436
(Previous) Eval Time (s)     11.56326539022848
Sample Time (s)              7.355616648681462
Epoch Time (s)               166.1134869880043
Total Train Time (s)         81869.97229603399
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:05:07.843265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #482 | Epoch Duration: 166.21486163139343
2020-01-12 07:05:07.843478 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0335186
Z variance train             0.0061742575
KL Divergence                30.395512
KL Loss                      3.0395513
QF Loss                      752.3572
VF Loss                      228.6752
Policy Loss                  -1695.6562
Q Predictions Mean           1691.027
Q Predictions Std            369.30737
Q Predictions Max            2232.3374
Q Predictions Min            194.14897
V Predictions Mean           1701.3983
V Predictions Std            370.37134
V Predictions Max            2258.2954
V Predictions Min            229.04828
Log Pis Mean                 1.6569676
Log Pis Std                  2.7750838
Log Pis Max                  13.04154
Log Pis Min                  -4.9883757
Policy mu Mean               0.017659161
Policy mu Std                0.72016126
Policy mu Max                2.891527
Policy mu Min                -2.6098416
Policy log std Mean          -1.1116905
Policy log std Std           0.29587635
Policy log std Max           -0.05945921
Policy log std Min           -2.3153398
Z mean eval                  1.2678344
Z variance eval              0.0005871254
total_rewards                [4313.59436812 4383.15773809  822.52214235  132.34204084 2131.93233313
 4290.9115444  2124.20370856  226.81093107 1761.31327941 2230.41383964]
total_rewards_mean           2241.720192560461
total_rewards_std            1544.598436999867
total_rewards_max            4383.1577380882245
total_rewards_min            132.34204084167288
Number of train steps total  1936000
Number of env steps total    3661948
Number of rollouts total     0
Train Time (s)               147.9894919139333
(Previous) Eval Time (s)     16.09445940889418
Sample Time (s)              7.744697603397071
Epoch Time (s)               171.82864892622456
Total Train Time (s)         82041.97669424582
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:07:59.852692 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #483 | Epoch Duration: 172.00904846191406
2020-01-12 07:07:59.852879 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2090839
Z variance train             0.0005839865
KL Divergence                33.706856
KL Loss                      3.3706856
QF Loss                      931.8572
VF Loss                      898.4773
Policy Loss                  -1826.4126
Q Predictions Mean           1831.1147
Q Predictions Std            350.5873
Q Predictions Max            2396.1382
Q Predictions Min            516.37213
V Predictions Mean           1852.2332
V Predictions Std            352.53198
V Predictions Max            2406.1436
V Predictions Min            533.5156
Log Pis Mean                 1.8057795
Log Pis Std                  2.995319
Log Pis Max                  13.018604
Log Pis Min                  -6.814311
Policy mu Mean               -0.02694207
Policy mu Std                0.67580605
Policy mu Max                2.815382
Policy mu Min                -2.7232077
Policy log std Mean          -1.2005147
Policy log std Std           0.2839719
Policy log std Max           -0.4343784
Policy log std Min           -2.3314278
Z mean eval                  1.1778948
Z variance eval              0.0021689497
total_rewards                [1474.3654776  3492.88993239  174.67515718 2053.08056164  874.61993329
 2198.1402436    19.65749301  389.61728932 4489.35193148 2687.5848855 ]
total_rewards_mean           1785.3982905021435
total_rewards_std            1409.594841650258
total_rewards_max            4489.351931483272
total_rewards_min            19.65749301347842
Number of train steps total  1940000
Number of env steps total    3674232
Number of rollouts total     0
Train Time (s)               148.59835044387728
(Previous) Eval Time (s)     14.604545267298818
Sample Time (s)              8.685066388454288
Epoch Time (s)               171.88796209963039
Total Train Time (s)         82213.95579956844
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:10:51.834591 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #484 | Epoch Duration: 171.9815878868103
2020-01-12 07:10:51.834735 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1852463
Z variance train             0.002170634
KL Divergence                33.570854
KL Loss                      3.3570855
QF Loss                      30971.719
VF Loss                      212.37012
Policy Loss                  -1818.9877
Q Predictions Mean           1812.9434
Q Predictions Std            403.72964
Q Predictions Max            2410.7126
Q Predictions Min            505.34897
V Predictions Mean           1820.7864
V Predictions Std            403.08698
V Predictions Max            2409.9158
V Predictions Min            514.165
Log Pis Mean                 1.5815868
Log Pis Std                  3.114634
Log Pis Max                  12.980673
Log Pis Min                  -7.4958863
Policy mu Mean               0.13938433
Policy mu Std                0.6936424
Policy mu Max                3.2079983
Policy mu Min                -2.9079006
Policy log std Mean          -1.1406002
Policy log std Std           0.29251626
Policy log std Max           -0.14528227
Policy log std Min           -2.467614
Z mean eval                  3.5461006
Z variance eval              0.2614442
total_rewards                [ 252.03740693  273.66773478  317.84258744  346.32450446  714.94760191
 1442.2299172   838.31550615  293.09273536 4146.87344278 1108.45145772]
total_rewards_mean           973.378289473542
total_rewards_std            1126.4903880465395
total_rewards_max            4146.8734427774025
total_rewards_min            252.03740692732595
Number of train steps total  1944000
Number of env steps total    3686531
Number of rollouts total     0
Train Time (s)               145.81285720178857
(Previous) Eval Time (s)     11.916416425723583
Sample Time (s)              8.219166533090174
Epoch Time (s)               165.94844016060233
Total Train Time (s)         82380.01275336603
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:13:37.899498 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #485 | Epoch Duration: 166.06465554237366
2020-01-12 07:13:37.899685 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 3.5532928
Z variance train             0.26123995
KL Divergence                62.326057
KL Loss                      6.232606
QF Loss                      774.3185
VF Loss                      149.54071
Policy Loss                  -754.26984
Q Predictions Mean           744.22485
Q Predictions Std            193.81529
Q Predictions Max            1356.1444
Q Predictions Min            258.1305
V Predictions Mean           752.8896
V Predictions Std            193.46252
V Predictions Max            1304.7366
V Predictions Min            220.46204
Log Pis Mean                 1.9933733
Log Pis Std                  3.5366213
Log Pis Max                  13.050797
Log Pis Min                  -7.6824155
Policy mu Mean               -0.020621983
Policy mu Std                0.7589687
Policy mu Max                3.1527832
Policy mu Min                -2.8876565
Policy log std Mean          -1.1635702
Policy log std Std           0.3018236
Policy log std Max           -0.29313374
Policy log std Min           -2.1334562
Z mean eval                  1.010023
Z variance eval              0.0032056808
total_rewards                [ 511.33056493 2237.40689941 3676.24795018 4188.82023985  713.16737978
 4228.59319518 4330.12189947  950.00933565  177.08317648 2345.31280011]
total_rewards_mean           2335.809344103221
total_rewards_std            1591.9278174233289
total_rewards_max            4330.121899466346
total_rewards_min            177.08317648091463
Number of train steps total  1948000
Number of env steps total    3698080
Number of rollouts total     0
Train Time (s)               145.1800966169685
(Previous) Eval Time (s)     20.964144784025848
Sample Time (s)              7.379982060287148
Epoch Time (s)               173.5242234612815
Total Train Time (s)         82553.63752280362
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:16:31.527088 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #486 | Epoch Duration: 173.6272623538971
2020-01-12 07:16:31.527302 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9990159
Z variance train             0.003214125
KL Divergence                29.784126
KL Loss                      2.9784126
QF Loss                      1008.01624
VF Loss                      128.21083
Policy Loss                  -1743.462
Q Predictions Mean           1741.9373
Q Predictions Std            394.40363
Q Predictions Max            2291.6167
Q Predictions Min            -194.57936
V Predictions Mean           1745.7861
V Predictions Std            392.7489
V Predictions Max            2294.4663
V Predictions Min            -195.35919
Log Pis Mean                 1.6579638
Log Pis Std                  2.9153285
Log Pis Max                  20.637623
Log Pis Min                  -5.757896
Policy mu Mean               0.053509377
Policy mu Std                0.68322974
Policy mu Max                2.7734656
Policy mu Min                -2.543579
Policy log std Mean          -1.1292312
Policy log std Std           0.28780398
Policy log std Max           -0.14728642
Policy log std Min           -3.8495703
Z mean eval                  1.4514439
Z variance eval              0.19534752
total_rewards                [2200.03509521 1949.63708718  622.22373271  271.56422213   35.98932062
  685.00101932 1439.77860152 3803.08609571 4587.28013723 4235.76199491]
total_rewards_mean           1983.0357306542817
total_rewards_std            1605.2915073905203
total_rewards_max            4587.280137228105
total_rewards_min            35.989320623590295
Number of train steps total  1952000
Number of env steps total    3708221
Number of rollouts total     0
Train Time (s)               147.93314632680267
(Previous) Eval Time (s)     14.411400654353201
Sample Time (s)              7.625954094808549
Epoch Time (s)               169.97050107596442
Total Train Time (s)         82723.70414316375
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:19:21.600780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #487 | Epoch Duration: 170.07331705093384
2020-01-12 07:19:21.600952 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.464046
Z variance train             0.19579275
KL Divergence                31.810072
KL Loss                      3.1810071
QF Loss                      724.48706
VF Loss                      129.60905
Policy Loss                  -1194.7191
Q Predictions Mean           1189.8246
Q Predictions Std            348.1931
Q Predictions Max            1808.5208
Q Predictions Min            266.4425
V Predictions Mean           1199.527
V Predictions Std            349.25406
V Predictions Max            1812.09
V Predictions Min            289.28625
Log Pis Mean                 1.640445
Log Pis Std                  3.0119839
Log Pis Max                  9.580215
Log Pis Min                  -9.203449
Policy mu Mean               0.018839886
Policy mu Std                0.7171907
Policy mu Max                2.6967702
Policy mu Min                -2.6225286
Policy log std Mean          -1.0950708
Policy log std Std           0.2866935
Policy log std Max           -0.2671939
Policy log std Min           -2.2073963
Z mean eval                  1.4156498
Z variance eval              0.017092502
total_rewards                [2317.3212445   190.26911136  950.08832695  374.66913638 2043.55556462
  282.07786654 2416.73665904  370.20415998 4362.99991232 1930.44570595]
total_rewards_mean           1523.836768763022
total_rewards_std            1273.7418586016706
total_rewards_max            4362.99991231706
total_rewards_min            190.2691113562581
Number of train steps total  1956000
Number of env steps total    3718661
Number of rollouts total     0
Train Time (s)               148.08507724432275
(Previous) Eval Time (s)     11.63279083603993
Sample Time (s)              8.052288131788373
Epoch Time (s)               167.77015621215105
Total Train Time (s)         82891.55837963521
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:22:09.459356 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #488 | Epoch Duration: 167.85828375816345
2020-01-12 07:22:09.459492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4131119
Z variance train             0.017141007
KL Divergence                31.610252
KL Loss                      3.1610253
QF Loss                      598.3048
VF Loss                      125.571236
Policy Loss                  -1263.7819
Q Predictions Mean           1258.5188
Q Predictions Std            379.96854
Q Predictions Max            1941.6661
Q Predictions Min            273.53137
V Predictions Mean           1262.0903
V Predictions Std            379.774
V Predictions Max            1937.7208
V Predictions Min            278.61404
Log Pis Mean                 1.3741374
Log Pis Std                  3.262221
Log Pis Max                  11.483229
Log Pis Min                  -8.585823
Policy mu Mean               -0.012794446
Policy mu Std                0.68105763
Policy mu Max                2.8508832
Policy mu Min                -2.9166825
Policy log std Mean          -1.1269408
Policy log std Std           0.30768296
Policy log std Max           -0.19283366
Policy log std Min           -2.1393175
Z mean eval                  0.8679975
Z variance eval              0.4953869
total_rewards                [4071.29632402 4515.18718798 2509.6279215   877.90395325 4792.62004836
 4659.35664986 3587.69379507 4149.89241148 4513.35468928  962.09101583]
total_rewards_mean           3463.9023996624264
total_rewards_std            1418.2056690983927
total_rewards_max            4792.6200483560915
total_rewards_min            877.9039532526297
Number of train steps total  1960000
Number of env steps total    3729421
Number of rollouts total     0
Train Time (s)               146.95435428526253
(Previous) Eval Time (s)     19.237291450146586
Sample Time (s)              6.600353478919715
Epoch Time (s)               172.79199921432883
Total Train Time (s)         83064.69567492837
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:25:02.604460 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #489 | Epoch Duration: 173.144868850708
2020-01-12 07:25:02.604601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8646577
Z variance train             0.5005713
KL Divergence                25.31678
KL Loss                      2.531678
QF Loss                      512.0836
VF Loss                      449.39786
Policy Loss                  -1565.422
Q Predictions Mean           1560.3062
Q Predictions Std            395.86136
Q Predictions Max            2145.902
Q Predictions Min            309.75006
V Predictions Mean           1568.5415
V Predictions Std            396.31793
V Predictions Max            2111.752
V Predictions Min            315.39255
Log Pis Mean                 1.8050379
Log Pis Std                  2.8014326
Log Pis Max                  13.614277
Log Pis Min                  -8.775051
Policy mu Mean               -0.05016654
Policy mu Std                0.70092416
Policy mu Max                2.7902944
Policy mu Min                -2.4415867
Policy log std Mean          -1.1124582
Policy log std Std           0.29138714
Policy log std Max           -0.30718017
Policy log std Min           -2.361404
Z mean eval                  0.4888385
Z variance eval              0.10167529
total_rewards                [4924.42690387 1530.45800615 5060.53753665 4901.71716655 1582.94593772
 1211.60897435 4512.94369156 4559.92767258 1947.27155934 5007.43897038]
total_rewards_mean           3523.9276419151865
total_rewards_std            1613.9120169636426
total_rewards_max            5060.5375366484905
total_rewards_min            1211.6089743540906
Number of train steps total  1964000
Number of env steps total    3740350
Number of rollouts total     0
Train Time (s)               147.10625339578837
(Previous) Eval Time (s)     15.976161134429276
Sample Time (s)              7.42403304297477
Epoch Time (s)               170.50644757319242
Total Train Time (s)         83235.28714502836
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:27:53.207697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #490 | Epoch Duration: 170.60298013687134
2020-01-12 07:27:53.207888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.49620676
Z variance train             0.10428455
KL Divergence                25.511757
KL Loss                      2.5511758
QF Loss                      1436.1199
VF Loss                      120.0926
Policy Loss                  -1354.4996
Q Predictions Mean           1347.9609
Q Predictions Std            369.89316
Q Predictions Max            1930.9016
Q Predictions Min            254.51685
V Predictions Mean           1358.4292
V Predictions Std            372.1489
V Predictions Max            1933.7333
V Predictions Min            266.631
Log Pis Mean                 1.6085682
Log Pis Std                  3.0204895
Log Pis Max                  13.758949
Log Pis Min                  -5.616496
Policy mu Mean               -0.02219968
Policy mu Std                0.6846234
Policy mu Max                2.8908534
Policy mu Min                -2.482982
Policy log std Mean          -1.1392503
Policy log std Std           0.3037102
Policy log std Max           -0.09597373
Policy log std Min           -2.1305988
Z mean eval                  1.4394076
Z variance eval              0.017965864
total_rewards                [3167.13347583 4871.60269745   11.91905326  751.21827949 1214.71381828
 1484.031952   4725.89247554 1425.67225203 1175.35466084   59.67416882]
total_rewards_mean           1888.7212833543658
total_rewards_std            1675.844221324993
total_rewards_max            4871.602697450991
total_rewards_min            11.919053259703208
Number of train steps total  1968000
Number of env steps total    3750595
Number of rollouts total     0
Train Time (s)               146.96826511621475
(Previous) Eval Time (s)     11.860376592725515
Sample Time (s)              7.310079728253186
Epoch Time (s)               166.13872143719345
Total Train Time (s)         83401.52573323296
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:30:39.455337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #491 | Epoch Duration: 166.2473042011261
2020-01-12 07:30:39.455517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4453449
Z variance train             0.017982112
KL Divergence                30.961546
KL Loss                      3.0961547
QF Loss                      12741.916
VF Loss                      137.21207
Policy Loss                  -1193.2203
Q Predictions Mean           1189.7903
Q Predictions Std            313.12158
Q Predictions Max            1750.4458
Q Predictions Min            263.00836
V Predictions Mean           1189.7415
V Predictions Std            313.2628
V Predictions Max            1740.6393
V Predictions Min            263.56528
Log Pis Mean                 1.3164126
Log Pis Std                  2.860289
Log Pis Max                  10.954117
Log Pis Min                  -6.1998453
Policy mu Mean               -0.036580548
Policy mu Std                0.6358658
Policy mu Max                3.193204
Policy mu Min                -2.2612188
Policy log std Mean          -1.1690855
Policy log std Std           0.29844263
Policy log std Max           -0.23241162
Policy log std Min           -2.4231486
Z mean eval                  0.33781177
Z variance eval              0.10966823
total_rewards                [3852.57720875 1995.4686826  4870.68855646  424.32825452 3536.71887065
 2957.33740342 4809.80997526 1375.10500475 4891.1949001  2643.65682192]
total_rewards_mean           3135.688567844264
total_rewards_std            1469.5101072103305
total_rewards_max            4891.19490010397
total_rewards_min            424.32825452366137
Number of train steps total  1972000
Number of env steps total    3761926
Number of rollouts total     0
Train Time (s)               149.56243213824928
(Previous) Eval Time (s)     19.645630285143852
Sample Time (s)              7.469434321857989
Epoch Time (s)               176.67749674525112
Total Train Time (s)         83578.29465367226
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:33:36.228158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #492 | Epoch Duration: 176.77250981330872
2020-01-12 07:33:36.228330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.34300265
Z variance train             0.11181966
KL Divergence                23.976063
KL Loss                      2.3976064
QF Loss                      4145.4355
VF Loss                      262.0165
Policy Loss                  -1401.0067
Q Predictions Mean           1392.1416
Q Predictions Std            398.15442
Q Predictions Max            2022.5564
Q Predictions Min            262.80148
V Predictions Mean           1397.6978
V Predictions Std            397.72647
V Predictions Max            2033.7867
V Predictions Min            284.45593
Log Pis Mean                 1.1640658
Log Pis Std                  3.0761955
Log Pis Max                  15.036184
Log Pis Min                  -7.047559
Policy mu Mean               -0.0008147614
Policy mu Std                0.65654933
Policy mu Max                3.191936
Policy mu Min                -2.8292804
Policy log std Mean          -1.147896
Policy log std Std           0.2906691
Policy log std Max           -0.28721583
Policy log std Min           -2.446361
Z mean eval                  1.0343907
Z variance eval              0.002695325
total_rewards                [1463.79421165  735.72864086 2814.57703273 1920.38643646 4228.23833574
  412.12453912  963.17149032  281.242703    590.95448869  421.57436007]
total_rewards_mean           1383.1792238647938
total_rewards_std            1214.2267250534533
total_rewards_max            4228.238335741614
total_rewards_min            281.2427030020437
Number of train steps total  1976000
Number of env steps total    3772357
Number of rollouts total     0
Train Time (s)               147.640893147327
(Previous) Eval Time (s)     9.782124819699675
Sample Time (s)              8.187155195046216
Epoch Time (s)               165.6101731620729
Total Train Time (s)         83743.99404935353
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:36:21.929123 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #493 | Epoch Duration: 165.70067358016968
2020-01-12 07:36:21.929254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0356895
Z variance train             0.0026972299
KL Divergence                30.243847
KL Loss                      3.0243847
QF Loss                      496.63678
VF Loss                      104.75297
Policy Loss                  -1666.2958
Q Predictions Mean           1660.0144
Q Predictions Std            350.5199
Q Predictions Max            2188.9844
Q Predictions Min            338.09195
V Predictions Mean           1664.5636
V Predictions Std            350.85898
V Predictions Max            2189.2961
V Predictions Min            341.45837
Log Pis Mean                 1.5997434
Log Pis Std                  2.952762
Log Pis Max                  11.958553
Log Pis Min                  -8.010288
Policy mu Mean               0.0025382824
Policy mu Std                0.63937336
Policy mu Max                3.0993586
Policy mu Min                -2.756807
Policy log std Mean          -1.1885933
Policy log std Std           0.28474742
Policy log std Max           -0.32511866
Policy log std Min           -2.3588343
Z mean eval                  0.33141202
Z variance eval              0.006238822
total_rewards                [ 663.63342567 1656.66405715  704.87594721 1741.05040997 4872.93405792
 2681.36275087 1539.42625087 4721.78479729 4821.10057198 4913.33023572]
total_rewards_mean           2831.6162504660942
total_rewards_std            1718.04097659761
total_rewards_max            4913.330235718235
total_rewards_min            663.6334256724186
Number of train steps total  1980000
Number of env steps total    3783082
Number of rollouts total     0
Train Time (s)               147.76219649706036
(Previous) Eval Time (s)     12.655892425216734
Sample Time (s)              7.5904675796628
Epoch Time (s)               168.0085565019399
Total Train Time (s)         83912.08532856731
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:39:10.023694 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #494 | Epoch Duration: 168.09434604644775
2020-01-12 07:39:10.023818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.33860102
Z variance train             0.0063318657
KL Divergence                26.982538
KL Loss                      2.6982539
QF Loss                      708.66736
VF Loss                      178.8175
Policy Loss                  -1331.2059
Q Predictions Mean           1327.2095
Q Predictions Std            401.0477
Q Predictions Max            1952.9856
Q Predictions Min            286.3334
V Predictions Mean           1330.0262
V Predictions Std            398.212
V Predictions Max            1922.3804
V Predictions Min            285.44437
Log Pis Mean                 1.2361981
Log Pis Std                  2.7481287
Log Pis Max                  10.855075
Log Pis Min                  -6.389551
Policy mu Mean               -0.05751233
Policy mu Std                0.62823117
Policy mu Max                2.6963363
Policy mu Min                -2.4726808
Policy log std Mean          -1.1642945
Policy log std Std           0.2931184
Policy log std Max           -0.23003232
Policy log std Min           -2.2272346
Z mean eval                  0.31114113
Z variance eval              0.028745184
total_rewards                [4428.82500134 4738.84179176 4725.13453435 4654.9810649  4984.65701339
 4558.55765219 4571.00042874 4933.85831251 5154.17031418 4464.04548047]
total_rewards_mean           4721.4071593820545
total_rewards_std            225.2624495115364
total_rewards_max            5154.170314180788
total_rewards_min            4428.825001340917
Number of train steps total  1984000
Number of env steps total    3795243
Number of rollouts total     0
Train Time (s)               145.69008072605357
(Previous) Eval Time (s)     24.708455719053745
Sample Time (s)              6.9280183208175
Epoch Time (s)               177.3265547659248
Total Train Time (s)         84089.50082438253
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:42:07.443562 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #495 | Epoch Duration: 177.4196422100067
2020-01-12 07:42:07.443730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.31629068
Z variance train             0.028682208
KL Divergence                25.017754
KL Loss                      2.5017755
QF Loss                      699.4601
VF Loss                      210.84119
Policy Loss                  -1357.3849
Q Predictions Mean           1351.2063
Q Predictions Std            370.3923
Q Predictions Max            1993.9916
Q Predictions Min            135.21536
V Predictions Mean           1367.5378
V Predictions Std            372.75793
V Predictions Max            1990.5847
V Predictions Min            -54.853706
Log Pis Mean                 1.6127293
Log Pis Std                  3.2420163
Log Pis Max                  12.22593
Log Pis Min                  -6.5194263
Policy mu Mean               -0.011756899
Policy mu Std                0.6697468
Policy mu Max                3.280729
Policy mu Min                -3.2254093
Policy log std Mean          -1.1567332
Policy log std Std           0.32936028
Policy log std Max           -0.18505788
Policy log std Min           -2.6278546
Z mean eval                  0.47955447
Z variance eval              0.07981412
total_rewards                [4731.50035406 4380.82214451 2570.3535663  4716.10582154 4642.10905651
 4599.3114846  1243.33936169 2510.26541835  366.41079566 2380.06732264]
total_rewards_mean           3214.028532587071
total_rewards_std            1532.2017148699151
total_rewards_max            4731.500354062693
total_rewards_min            366.4107956649272
Number of train steps total  1988000
Number of env steps total    3806012
Number of rollouts total     0
Train Time (s)               147.82051986223087
(Previous) Eval Time (s)     17.178379779215902
Sample Time (s)              7.138551706913859
Epoch Time (s)               172.13745134836063
Total Train Time (s)         84261.73052478768
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:44:59.678458 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #496 | Epoch Duration: 172.2345907688141
2020-01-12 07:44:59.678687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.4847427
Z variance train             0.07771575
KL Divergence                26.340864
KL Loss                      2.6340864
QF Loss                      16933.832
VF Loss                      119.20764
Policy Loss                  -1371.5347
Q Predictions Mean           1366.4329
Q Predictions Std            337.17322
Q Predictions Max            1872.3079
Q Predictions Min            299.64746
V Predictions Mean           1365.128
V Predictions Std            336.49637
V Predictions Max            1865.4323
V Predictions Min            301.5001
Log Pis Mean                 1.5339147
Log Pis Std                  3.023833
Log Pis Max                  12.883462
Log Pis Min                  -9.019521
Policy mu Mean               0.029792266
Policy mu Std                0.66988385
Policy mu Max                2.6905794
Policy mu Min                -2.6240766
Policy log std Mean          -1.1247096
Policy log std Std           0.30469528
Policy log std Max           -0.045041203
Policy log std Min           -2.0350547
Z mean eval                  0.27896374
Z variance eval              0.5502301
total_rewards                [  40.50835394 2661.87721131 5145.19644898 3464.02151878  191.82392443
  656.69175541 2128.38327228 3967.04228309 4693.18276252 1031.9210648 ]
total_rewards_mean           2398.0648595533817
total_rewards_std            1785.465707462741
total_rewards_max            5145.196448976614
total_rewards_min            40.50835393907107
Number of train steps total  1992000
Number of env steps total    3816886
Number of rollouts total     0
Train Time (s)               146.91875397320837
(Previous) Eval Time (s)     14.600557076279074
Sample Time (s)              8.065306153148413
Epoch Time (s)               169.58461720263585
Total Train Time (s)         84431.40394073166
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:47:49.355405 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #497 | Epoch Duration: 169.67657327651978
2020-01-12 07:47:49.355586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.27957895
Z variance train             0.5438705
KL Divergence                23.367897
KL Loss                      2.3367898
QF Loss                      541.4241
VF Loss                      156.85388
Policy Loss                  -1365.4443
Q Predictions Mean           1358.7671
Q Predictions Std            339.27353
Q Predictions Max            1934.9692
Q Predictions Min            242.13803
V Predictions Mean           1366.8793
V Predictions Std            334.33
V Predictions Max            1941.2062
V Predictions Min            250.71121
Log Pis Mean                 1.5079403
Log Pis Std                  3.0633235
Log Pis Max                  9.615995
Log Pis Min                  -12.752978
Policy mu Mean               -0.02051493
Policy mu Std                0.6568341
Policy mu Max                2.846649
Policy mu Min                -2.7223325
Policy log std Mean          -1.1793082
Policy log std Std           0.30021957
Policy log std Max           -0.2733494
Policy log std Min           -2.1863093
Z mean eval                  0.552767
Z variance eval              0.06808157
total_rewards                [ 642.08334609  724.65482285 4271.73471802  279.08397444 3370.42205204
 4820.02506299 5105.02856349 5085.29019876 3305.86851317 4770.43636569]
total_rewards_mean           3237.462761753368
total_rewards_std            1861.4794886288605
total_rewards_max            5105.028563485324
total_rewards_min            279.08397444182754
Number of train steps total  1996000
Number of env steps total    3828029
Number of rollouts total     0
Train Time (s)               148.77000781800598
(Previous) Eval Time (s)     16.69438911601901
Sample Time (s)              7.6455993433482945
Epoch Time (s)               173.10999627737328
Total Train Time (s)         84604.71127361897
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:50:42.668693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #498 | Epoch Duration: 173.31296706199646
2020-01-12 07:50:42.668888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.55178154
Z variance train             0.0683264
KL Divergence                25.566435
KL Loss                      2.5566435
QF Loss                      807.694
VF Loss                      151.03351
Policy Loss                  -1413.6597
Q Predictions Mean           1409.6565
Q Predictions Std            361.69766
Q Predictions Max            1990.7399
Q Predictions Min            268.77762
V Predictions Mean           1411.0841
V Predictions Std            356.34442
V Predictions Max            1987.4231
V Predictions Min            271.4487
Log Pis Mean                 1.4153818
Log Pis Std                  3.0421119
Log Pis Max                  13.042715
Log Pis Min                  -7.260951
Policy mu Mean               -0.0031173602
Policy mu Std                0.6385447
Policy mu Max                2.7560406
Policy mu Min                -2.8285222
Policy log std Mean          -1.1654239
Policy log std Std           0.2984774
Policy log std Max           -0.29311252
Policy log std Min           -2.6187878
Z mean eval                  0.24908392
Z variance eval              0.3965269
total_rewards                [ 738.63578456 4857.51349558 5068.93967921 4899.76685139 2553.80842108
  134.31446177 4824.27246075 3328.35091987 4932.20732582  354.68571764]
total_rewards_mean           3169.2495117666595
total_rewards_std            1968.3859805390066
total_rewards_max            5068.939679209161
total_rewards_min            134.31446176682036
Number of train steps total  2000000
Number of env steps total    3838995
Number of rollouts total     0
Train Time (s)               147.29843754693866
(Previous) Eval Time (s)     20.102085867896676
Sample Time (s)              7.656092692166567
Epoch Time (s)               175.0566161070019
Total Train Time (s)         84779.85693617072
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:53:37.817630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #499 | Epoch Duration: 175.1486110687256
2020-01-12 07:53:37.817761 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Iteration #499 | Started Training: True
2020-01-12 07:53:38.385535 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] Variant:
2020-01-12 07:53:38.385828 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019175082
Z variance train             0.6939387
KL Divergence                0.14828885
KL Loss                      0.014828885
QF Loss                      46.709827
VF Loss                      16.167742
Policy Loss                  -3.9816623
Q Predictions Mean           -0.0026792148
Q Predictions Std            0.0026757657
Q Predictions Max            0.0040889876
Q Predictions Min            -0.010387832
V Predictions Mean           -0.001651519
V Predictions Std            0.001290455
V Predictions Max            0.0017824029
V Predictions Min            -0.0049177175
Log Pis Mean                 -4.0086207
Log Pis Std                  0.54835194
Log Pis Max                  -2.2180557
Log Pis Min                  -5.7349057
Policy mu Mean               -0.0001299685
Policy mu Std                0.0013389915
Policy mu Max                0.0041198926
Policy mu Min                -0.004545611
Policy log std Mean          -0.00054704404
Policy log std Std           0.0011561852
Policy log std Max           0.0023886173
Policy log std Min           -0.0044405647
Z mean eval                  0.8570304
Z variance eval              0.047355607
total_rewards                [-119.80486682 -136.9792466  -158.74689445 -140.93463933 -123.38789593
 -141.5424727  -149.58532802 -151.90958377 -119.03849759 -164.97905753]
total_rewards_mean           -140.6908482719261
total_rewards_std            15.296767846030868
total_rewards_max            -119.0384975864594
total_rewards_min            -164.97905752784447
Number of train steps total  4000
Number of env steps total    14000
Number of rollouts total     0
Train Time (s)               141.9527783249505
(Previous) Eval Time (s)     0
Sample Time (s)              10.93709594849497
Epoch Time (s)               152.88987427344546
Total Train Time (s)         170.62058700295165
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:56:29.084136 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #0 | Epoch Duration: 170.62382292747498
2020-01-12 07:56:29.084306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90167505
Z variance train             0.041856658
KL Divergence                9.360006
KL Loss                      0.93600065
QF Loss                      47.1469
VF Loss                      9.294404
Policy Loss                  -48.83809
Q Predictions Mean           44.240807
Q Predictions Std            17.82905
Q Predictions Max            99.00708
Q Predictions Min            -16.574621
V Predictions Mean           49.184624
V Predictions Std            17.31221
V Predictions Max            101.537
V Predictions Min            -8.512872
Log Pis Mean                 -3.2385275
Log Pis Std                  1.2206479
Log Pis Max                  -0.06476468
Log Pis Min                  -8.254299
Policy mu Mean               0.06723497
Policy mu Std                0.3628978
Policy mu Max                1.6284689
Policy mu Min                -1.2889998
Policy log std Mean          -0.31089845
Policy log std Std           0.06466471
Policy log std Max           -0.16806349
Policy log std Min           -0.5761995
Z mean eval                  1.0705801
Z variance eval              0.023435056
total_rewards                [-140.71860726  -66.55020744 -116.91921201 -100.35151368  -46.52522974
 -136.85984412 -110.46513159 -127.80643182 -129.03688426 -108.42813742]
total_rewards_mean           -108.36611993377657
total_rewards_std            28.945547516274093
total_rewards_max            -46.52522973505119
total_rewards_min            -140.7186072572156
Number of train steps total  8000
Number of env steps total    26000
Number of rollouts total     0
Train Time (s)               141.15574117889628
(Previous) Eval Time (s)     17.725766093004495
Sample Time (s)              5.554469279013574
Epoch Time (s)               164.43597655091435
Total Train Time (s)         335.1402840889059
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 07:59:13.605309 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #1 | Epoch Duration: 164.5208625793457
2020-01-12 07:59:13.605506 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #1 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0627549
Z variance train             0.023334749
KL Divergence                12.617655
KL Loss                      1.2617655
QF Loss                      77.44399
VF Loss                      28.448317
Policy Loss                  -88.40505
Q Predictions Mean           84.29179
Q Predictions Std            26.726316
Q Predictions Max            182.0234
Q Predictions Min            20.158403
V Predictions Mean           91.97092
V Predictions Std            27.315807
V Predictions Max            176.4221
V Predictions Min            32.280903
Log Pis Mean                 -3.2033463
Log Pis Std                  1.3965696
Log Pis Max                  1.9968648
Log Pis Min                  -6.9521055
Policy mu Mean               0.023217214
Policy mu Std                0.44225755
Policy mu Max                1.6368394
Policy mu Min                -1.8417437
Policy log std Mean          -0.3282062
Policy log std Std           0.076840825
Policy log std Max           -0.10830869
Policy log std Min           -0.680839
Z mean eval                  1.1768091
Z variance eval              0.03133611
total_rewards                [-52.09384411 -20.17585418 -70.50107003 -56.87156973  -4.5261226
 -86.1482204   -4.72648553 -38.32399383  41.84297799 -71.25432327]
total_rewards_mean           -36.27785056900022
total_rewards_std            37.31738041555544
total_rewards_max            41.8429779925883
total_rewards_min            -86.14822039934562
Number of train steps total  12000
Number of env steps total    38000
Number of rollouts total     0
Train Time (s)               142.3822284513153
(Previous) Eval Time (s)     20.99292907398194
Sample Time (s)              6.486303466837853
Epoch Time (s)               169.8614609921351
Total Train Time (s)         505.0999261382967
Epoch                        2
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:02:03.564764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #2 | Epoch Duration: 169.95912408828735
2020-01-12 08:02:03.564903 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.173344
Z variance train             0.031380285
KL Divergence                13.744539
KL Loss                      1.3744539
QF Loss                      53.716454
VF Loss                      28.074799
Policy Loss                  -128.45241
Q Predictions Mean           124.663605
Q Predictions Std            39.311035
Q Predictions Max            223.57649
Q Predictions Min            49.962246
V Predictions Mean           131.93298
V Predictions Std            39.126827
V Predictions Max            227.50276
V Predictions Min            64.5722
Log Pis Mean                 -3.0888681
Log Pis Std                  1.2659762
Log Pis Max                  1.723346
Log Pis Min                  -6.025714
Policy mu Mean               0.010516976
Policy mu Std                0.41898605
Policy mu Max                1.791188
Policy mu Min                -1.301242
Policy log std Mean          -0.33096814
Policy log std Std           0.0815935
Policy log std Max           -0.16474834
Policy log std Min           -0.69333816
Z mean eval                  1.2243838
Z variance eval              0.034015235
total_rewards                [215.12223097 116.96737152 175.28799707  94.11691416 221.12375198
  46.61422166  79.10989942  49.36864236  80.11590951  67.35587742]
total_rewards_mean           114.51828160639369
total_rewards_std            62.544431445440715
total_rewards_max            221.12375197785596
total_rewards_min            46.61422165789635
Number of train steps total  16000
Number of env steps total    50000
Number of rollouts total     0
Train Time (s)               143.11390058416873
(Previous) Eval Time (s)     20.959214230068028
Sample Time (s)              6.4461075672879815
Epoch Time (s)               170.51922238152474
Total Train Time (s)         675.7064033807255
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:04:54.172490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #3 | Epoch Duration: 170.60749053955078
2020-01-12 08:04:54.172618 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2231514
Z variance train             0.03410511
KL Divergence                14.648917
KL Loss                      1.4648918
QF Loss                      46.83977
VF Loss                      10.9094715
Policy Loss                  -149.63753
Q Predictions Mean           143.59972
Q Predictions Std            42.67657
Q Predictions Max            274.90213
Q Predictions Min            71.712555
V Predictions Mean           150.32635
V Predictions Std            41.4437
V Predictions Max            273.18155
V Predictions Min            81.26038
Log Pis Mean                 -3.2629328
Log Pis Std                  1.4189438
Log Pis Max                  2.3022041
Log Pis Min                  -7.2082367
Policy mu Mean               0.012199369
Policy mu Std                0.38947287
Policy mu Max                1.7695112
Policy mu Min                -1.4258059
Policy log std Mean          -0.32613477
Policy log std Std           0.085294366
Policy log std Max           -0.07732354
Policy log std Min           -0.7754878
Z mean eval                  1.27453
Z variance eval              0.036229327
total_rewards                [377.42888561 577.56733452 207.63355706 158.23362038 404.82230909
 246.98884586 410.91484624 323.08229238 157.35252815  62.43087185]
total_rewards_mean           292.6455091142385
total_rewards_std            146.47437471863918
total_rewards_max            577.5673345246104
total_rewards_min            62.43087185137737
Number of train steps total  20000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               140.82227462902665
(Previous) Eval Time (s)     21.069865269120783
Sample Time (s)              5.542368256952614
Epoch Time (s)               167.43450815510005
Total Train Time (s)         843.2300534984097
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:07:41.696785 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #4 | Epoch Duration: 167.52407312393188
2020-01-12 08:07:41.696921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2748578
Z variance train             0.03630378
KL Divergence                15.50745
KL Loss                      1.550745
QF Loss                      68.44155
VF Loss                      19.164122
Policy Loss                  -191.49336
Q Predictions Mean           186.28488
Q Predictions Std            52.588593
Q Predictions Max            334.50677
Q Predictions Min            100.755165
V Predictions Mean           190.23953
V Predictions Std            52.079636
V Predictions Max            327.00708
V Predictions Min            99.7673
Log Pis Mean                 -3.179522
Log Pis Std                  1.3542868
Log Pis Max                  2.3836563
Log Pis Min                  -7.610919
Policy mu Mean               -0.03514818
Policy mu Std                0.44905213
Policy mu Max                1.946063
Policy mu Min                -1.8796372
Policy log std Mean          -0.3404627
Policy log std Std           0.09354306
Policy log std Max           -0.032215998
Policy log std Min           -0.8408439
Z mean eval                  1.3176636
Z variance eval              0.03010225
total_rewards                [1359.03449963 1683.98054731  698.55417239 1282.31917818 1284.74318036
 1253.42464325 1276.47792498 1467.87376846 1610.50044553  717.21644516]
total_rewards_mean           1263.412480522977
total_rewards_std            310.92981283036073
total_rewards_max            1683.9805473055778
total_rewards_min            698.5541723887386
Number of train steps total  24000
Number of env steps total    74000
Number of rollouts total     0
Train Time (s)               141.90008722618222
(Previous) Eval Time (s)     17.662372660823166
Sample Time (s)              6.5747709991410375
Epoch Time (s)               166.13723088614643
Total Train Time (s)         1009.4530332400464
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:10:27.923233 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #5 | Epoch Duration: 166.22619891166687
2020-01-12 08:10:27.923441 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.315428
Z variance train             0.029934848
KL Divergence                16.201488
KL Loss                      1.6201489
QF Loss                      302.90747
VF Loss                      50.24353
Policy Loss                  -223.01384
Q Predictions Mean           216.83366
Q Predictions Std            72.6502
Q Predictions Max            432.32693
Q Predictions Min            111.42569
V Predictions Mean           228.04527
V Predictions Std            71.72269
V Predictions Max            427.9796
V Predictions Min            116.36963
Log Pis Mean                 -2.908556
Log Pis Std                  1.8381262
Log Pis Max                  5.4552507
Log Pis Min                  -8.615093
Policy mu Mean               -0.006876013
Policy mu Std                0.5119946
Policy mu Max                2.0630612
Policy mu Min                -1.704877
Policy log std Mean          -0.35600626
Policy log std Std           0.10570439
Policy log std Max           -0.124134116
Policy log std Min           -0.89694417
Z mean eval                  1.3300673
Z variance eval              0.050965853
total_rewards                [1717.4468697   957.23179952 2182.97970855 2026.76438238 2364.95295906
 1805.16370186 2174.37854872  556.20935944 1851.90103585  813.99279666]
total_rewards_mean           1645.102116173703
total_rewards_std            604.6910074424577
total_rewards_max            2364.9529590588845
total_rewards_min            556.209359444083
Number of train steps total  28000
Number of env steps total    86000
Number of rollouts total     0
Train Time (s)               141.37778852460906
(Previous) Eval Time (s)     19.815300669055432
Sample Time (s)              6.597711309790611
Epoch Time (s)               167.7908005034551
Total Train Time (s)         1177.3287200927734
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:13:15.797750 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #6 | Epoch Duration: 167.87416124343872
2020-01-12 08:13:15.797921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3293868
Z variance train             0.051017683
KL Divergence                14.408234
KL Loss                      1.4408234
QF Loss                      129.80072
VF Loss                      33.496193
Policy Loss                  -262.55328
Q Predictions Mean           254.32748
Q Predictions Std            104.98196
Q Predictions Max            570.5655
Q Predictions Min            135.75388
V Predictions Mean           263.52344
V Predictions Std            104.4851
V Predictions Max            579.60455
V Predictions Min            140.23055
Log Pis Mean                 -2.628164
Log Pis Std                  1.8245932
Log Pis Max                  4.3250685
Log Pis Min                  -6.169155
Policy mu Mean               -0.017206943
Policy mu Std                0.5317824
Policy mu Max                1.7189984
Policy mu Min                -2.1563804
Policy log std Mean          -0.36801186
Policy log std Std           0.13275558
Policy log std Max           -0.06561345
Policy log std Min           -1.3202304
Z mean eval                  1.4363272
Z variance eval              0.023656022
total_rewards                [2653.94428115 2711.7415817  2650.90073385 2677.82463629 2718.87350692
 2753.16561472 2621.09594926  844.33412152 2472.45300589 2696.02910001]
total_rewards_mean           2480.036253130594
total_rewards_std            550.0926172467537
total_rewards_max            2753.1656147219624
total_rewards_min            844.3341215245425
Number of train steps total  32000
Number of env steps total    98000
Number of rollouts total     0
Train Time (s)               142.3745892061852
(Previous) Eval Time (s)     17.83722969610244
Sample Time (s)              6.397122672293335
Epoch Time (s)               166.60894157458097
Total Train Time (s)         1344.0142849930562
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:16:02.486677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #7 | Epoch Duration: 166.6886112689972
2020-01-12 08:16:02.486818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4365635
Z variance train             0.023555791
KL Divergence                18.323
KL Loss                      1.8323001
QF Loss                      119.078415
VF Loss                      56.591427
Policy Loss                  -284.66232
Q Predictions Mean           275.00464
Q Predictions Std            114.12933
Q Predictions Max            679.53375
Q Predictions Min            142.85335
V Predictions Mean           279.9147
V Predictions Std            115.98067
V Predictions Max            685.7592
V Predictions Min            158.8588
Log Pis Mean                 -2.4140596
Log Pis Std                  2.1078944
Log Pis Max                  6.48071
Log Pis Min                  -7.6143284
Policy mu Mean               -0.010068208
Policy mu Std                0.5826307
Policy mu Max                2.2576063
Policy mu Min                -1.8932884
Policy log std Mean          -0.382583
Policy log std Std           0.1403378
Policy log std Max           -0.059430644
Policy log std Min           -1.187321
Z mean eval                  1.570262
Z variance eval              0.026734218
total_rewards                [2925.51027445 2980.84446605 2906.78806712 2941.08159982 2890.42442532
  682.37579128 2917.04663503 2833.37568792 3108.70423823 3084.19761975]
total_rewards_mean           2727.034880496346
total_rewards_std            686.2882399905322
total_rewards_max            3108.704238229665
total_rewards_min            682.3757912759372
Number of train steps total  36000
Number of env steps total    110000
Number of rollouts total     0
Train Time (s)               141.39585772203282
(Previous) Eval Time (s)     17.810863703954965
Sample Time (s)              5.681655390653759
Epoch Time (s)               164.88837681664154
Total Train Time (s)         1508.9887186517008
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:18:47.461094 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #8 | Epoch Duration: 164.97414755821228
2020-01-12 08:18:47.461321 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5714668
Z variance train             0.026570031
KL Divergence                18.710285
KL Loss                      1.8710285
QF Loss                      102.72793
VF Loss                      36.4113
Policy Loss                  -319.53604
Q Predictions Mean           312.20898
Q Predictions Std            157.32193
Q Predictions Max            809.073
Q Predictions Min            162.68185
V Predictions Mean           315.6676
V Predictions Std            157.63722
V Predictions Max            802.6678
V Predictions Min            178.22974
Log Pis Mean                 -2.2060304
Log Pis Std                  2.28106
Log Pis Max                  5.391802
Log Pis Min                  -6.3220606
Policy mu Mean               -0.043104004
Policy mu Std                0.58388966
Policy mu Max                1.9197209
Policy mu Min                -2.170544
Policy log std Mean          -0.39043918
Policy log std Std           0.16912653
Policy log std Max           -0.16119978
Policy log std Min           -1.5250498
Z mean eval                  1.6815469
Z variance eval              0.039277457
total_rewards                [3247.66095674 3338.15260218 3211.673153   3226.83353884 3144.61281778
  880.26929528 3360.72621857 3269.68389065 3201.73817106 3182.73076804]
total_rewards_mean           3006.408141213126
total_rewards_std            711.5226084700234
total_rewards_max            3360.7262185714835
total_rewards_min            880.2692952814242
Number of train steps total  40000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               142.4535206318833
(Previous) Eval Time (s)     17.709922744892538
Sample Time (s)              6.519831718411297
Epoch Time (s)               166.68327509518713
Total Train Time (s)         1675.75117145665
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:21:34.223158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #9 | Epoch Duration: 166.76168417930603
2020-01-12 08:21:34.223280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #9 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6836075
Z variance train             0.03931024
KL Divergence                18.877396
KL Loss                      1.8877395
QF Loss                      184.54936
VF Loss                      41.86239
Policy Loss                  -396.34106
Q Predictions Mean           390.6626
Q Predictions Std            204.74251
Q Predictions Max            951.7623
Q Predictions Min            178.26329
V Predictions Mean           396.48065
V Predictions Std            205.25139
V Predictions Max            935.0167
V Predictions Min            184.77711
Log Pis Mean                 -1.6992711
Log Pis Std                  2.6339643
Log Pis Max                  8.966895
Log Pis Min                  -6.1031294
Policy mu Mean               -0.037009757
Policy mu Std                0.66445965
Policy mu Max                2.1140459
Policy mu Min                -2.4695745
Policy log std Mean          -0.41836834
Policy log std Std           0.17262731
Policy log std Max           -0.1683233
Policy log std Min           -1.6283408
Z mean eval                  1.8004423
Z variance eval              0.025630694
total_rewards                [3197.58308723 3180.13771558 3200.83346392 3350.73068538 3225.9101789
 3194.85224419 3266.06561277 3119.33723773 3179.48128653 3221.9817852 ]
total_rewards_mean           3213.691329742958
total_rewards_std            58.06846005912471
total_rewards_max            3350.7306853787322
total_rewards_min            3119.337237726468
Number of train steps total  44000
Number of env steps total    134000
Number of rollouts total     0
Train Time (s)               142.48910357616842
(Previous) Eval Time (s)     20.946224097162485
Sample Time (s)              5.543400122784078
Epoch Time (s)               168.97872779611498
Total Train Time (s)         1844.8138136649504
Epoch                        10
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:24:23.286598 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #10 | Epoch Duration: 169.0632243156433
2020-01-12 08:24:23.286748 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7987705
Z variance train             0.025562212
KL Divergence                21.54616
KL Loss                      2.154616
QF Loss                      255.54514
VF Loss                      44.870293
Policy Loss                  -419.74313
Q Predictions Mean           409.26196
Q Predictions Std            239.83783
Q Predictions Max            999.7389
Q Predictions Min            179.36961
V Predictions Mean           417.6826
V Predictions Std            242.16188
V Predictions Max            989.6034
V Predictions Min            180.6841
Log Pis Mean                 -1.6384289
Log Pis Std                  2.9173105
Log Pis Max                  9.976688
Log Pis Min                  -6.883501
Policy mu Mean               0.0390093
Policy mu Std                0.7015887
Policy mu Max                2.232673
Policy mu Min                -2.88056
Policy log std Mean          -0.43228927
Policy log std Std           0.17674474
Policy log std Max           -0.15156235
Policy log std Min           -1.5816116
Z mean eval                  1.8647034
Z variance eval              0.041358586
total_rewards                [3496.06408563 3386.06200743 3396.06383101 3379.52744395 3429.18691467
 3183.10183791 3411.18558081 3361.47100881 3626.09294958 3570.80664561]
total_rewards_mean           3423.956230539804
total_rewards_std            115.72268855520052
total_rewards_max            3626.0929495760342
total_rewards_min            3183.1018379089323
Number of train steps total  48000
Number of env steps total    146000
Number of rollouts total     0
Train Time (s)               142.06342723593116
(Previous) Eval Time (s)     17.73807872692123
Sample Time (s)              6.663839919026941
Epoch Time (s)               166.46534588187933
Total Train Time (s)         2011.3705884623341
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:27:09.846437 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #11 | Epoch Duration: 166.55957293510437
2020-01-12 08:27:09.846654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8670645
Z variance train             0.041168876
KL Divergence                22.36293
KL Loss                      2.236293
QF Loss                      266.77255
VF Loss                      64.75019
Policy Loss                  -486.61905
Q Predictions Mean           482.40308
Q Predictions Std            303.24554
Q Predictions Max            1171.0256
Q Predictions Min            181.78835
V Predictions Mean           490.1347
V Predictions Std            303.90918
V Predictions Max            1179.5087
V Predictions Min            189.39278
Log Pis Mean                 -1.6668222
Log Pis Std                  2.8095558
Log Pis Max                  8.014477
Log Pis Min                  -6.818327
Policy mu Mean               -0.0012474066
Policy mu Std                0.69911116
Policy mu Max                2.413759
Policy mu Min                -2.1176836
Policy log std Mean          -0.4259226
Policy log std Std           0.18999746
Policy log std Max           -0.18290961
Policy log std Min           -1.7285247
Z mean eval                  1.9208361
Z variance eval              0.062533356
total_rewards                [3647.83754964 1986.71218261 3453.38915687 3731.92363645 3952.03275232
 3601.31676996 3894.62698816 3779.96119087 3853.15682137 3728.71648566]
total_rewards_mean           3562.9673533903215
total_rewards_std            543.5022192927119
total_rewards_max            3952.03275231869
total_rewards_min            1986.712182612499
Number of train steps total  52000
Number of env steps total    158000
Number of rollouts total     0
Train Time (s)               140.4986516800709
(Previous) Eval Time (s)     17.891712713986635
Sample Time (s)              6.539673796389252
Epoch Time (s)               164.9300381904468
Total Train Time (s)         2176.3850927725434
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:29:54.860620 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #12 | Epoch Duration: 165.0138087272644
2020-01-12 08:29:54.860793 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #12 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9238151
Z variance train             0.06255022
KL Divergence                21.104979
KL Loss                      2.110498
QF Loss                      192.47461
VF Loss                      53.167927
Policy Loss                  -499.34152
Q Predictions Mean           489.2808
Q Predictions Std            315.59253
Q Predictions Max            1245.9806
Q Predictions Min            180.39574
V Predictions Mean           497.90594
V Predictions Std            320.7221
V Predictions Max            1239.2789
V Predictions Min            192.77258
Log Pis Mean                 -1.6713185
Log Pis Std                  2.9008896
Log Pis Max                  7.919036
Log Pis Min                  -6.565384
Policy mu Mean               0.0073697814
Policy mu Std                0.69410866
Policy mu Max                2.2955432
Policy mu Min                -2.45524
Policy log std Mean          -0.42986774
Policy log std Std           0.19321421
Policy log std Max           -0.08899097
Policy log std Min           -1.7646841
Z mean eval                  1.9908984
Z variance eval              0.044801436
total_rewards                [3597.56510471 3754.33492186 3886.7450577  3917.08730919 1525.849065
 3699.59665719 3682.37350865 3618.87022995 3724.97316285  632.87361478]
total_rewards_mean           3204.0268631866247
total_rewards_std            1085.2310993010149
total_rewards_max            3917.087309185161
total_rewards_min            632.8736147781527
Number of train steps total  56000
Number of env steps total    170000
Number of rollouts total     0
Train Time (s)               142.7484659468755
(Previous) Eval Time (s)     17.47962373821065
Sample Time (s)              5.485343575943261
Epoch Time (s)               165.71343326102942
Total Train Time (s)         2342.293415383436
Epoch                        13
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:32:40.773009 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #13 | Epoch Duration: 165.91203117370605
2020-01-12 08:32:40.773346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9899276
Z variance train             0.044774417
KL Divergence                22.732903
KL Loss                      2.2732904
QF Loss                      213.39098
VF Loss                      78.78076
Policy Loss                  -572.7304
Q Predictions Mean           562.2091
Q Predictions Std            352.63538
Q Predictions Max            1348.5013
Q Predictions Min            166.63504
V Predictions Mean           576.347
V Predictions Std            356.1466
V Predictions Max            1359.0101
V Predictions Min            178.96198
Log Pis Mean                 -1.3015859
Log Pis Std                  3.0637565
Log Pis Max                  8.39757
Log Pis Min                  -7.7917633
Policy mu Mean               -0.0063744714
Policy mu Std                0.7601129
Policy mu Max                2.5440035
Policy mu Min                -2.5537932
Policy log std Mean          -0.44454932
Policy log std Std           0.19278629
Policy log std Max           -0.18689111
Policy log std Min           -1.6942906
Z mean eval                  1.9935968
Z variance eval              0.022119524
total_rewards                [3994.11953706 4009.57377319 3939.00621871 3846.97152189 4206.60503925
 3986.57180254 3913.63253053 4112.39257128 3591.71382445 4027.5646049 ]
total_rewards_mean           3962.8151423793547
total_rewards_std            156.15756602388578
total_rewards_max            4206.605039250798
total_rewards_min            3591.7138244491184
Number of train steps total  60000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               143.7748798429966
(Previous) Eval Time (s)     17.678873215802014
Sample Time (s)              6.872498502954841
Epoch Time (s)               168.32625156175345
Total Train Time (s)         2510.7047553318553
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:35:29.185577 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #14 | Epoch Duration: 168.41198301315308
2020-01-12 08:35:29.185810 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9973282
Z variance train             0.022061782
KL Divergence                25.375153
KL Loss                      2.5375154
QF Loss                      278.40143
VF Loss                      120.32531
Policy Loss                  -590.9313
Q Predictions Mean           580.3989
Q Predictions Std            387.98715
Q Predictions Max            1374.031
Q Predictions Min            197.42363
V Predictions Mean           582.9354
V Predictions Std            392.8555
V Predictions Max            1374.2429
V Predictions Min            182.33005
Log Pis Mean                 -1.8189039
Log Pis Std                  2.9065118
Log Pis Max                  9.886803
Log Pis Min                  -9.42384
Policy mu Mean               0.02803404
Policy mu Std                0.6917555
Policy mu Max                2.6575043
Policy mu Min                -2.3253694
Policy log std Mean          -0.4342667
Policy log std Std           0.20232873
Policy log std Max           -0.14432487
Policy log std Min           -1.814332
Z mean eval                  2.0189488
Z variance eval              0.020484768
total_rewards                [4089.35527728 3969.20606861 3892.96665691 3945.35581067 4154.40706829
 4091.61760454 4029.99428848 4089.70896751 3998.36152585 4052.11362906]
total_rewards_mean           4031.3086897186668
total_rewards_std            75.81135439617427
total_rewards_max            4154.407068286706
total_rewards_min            3892.9666569096507
Number of train steps total  64000
Number of env steps total    194000
Number of rollouts total     0
Train Time (s)               141.4555628071539
(Previous) Eval Time (s)     17.70490838587284
Sample Time (s)              6.405570060014725
Epoch Time (s)               165.56604125304148
Total Train Time (s)         2676.358530738391
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:38:14.839205 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #15 | Epoch Duration: 165.6531822681427
2020-01-12 08:38:14.839475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0222774
Z variance train             0.020504672
KL Divergence                26.754631
KL Loss                      2.6754632
QF Loss                      240.58748
VF Loss                      62.769855
Policy Loss                  -581.881
Q Predictions Mean           573.33453
Q Predictions Std            419.62024
Q Predictions Max            1431.6758
Q Predictions Min            180.37498
V Predictions Mean           577.6216
V Predictions Std            419.91595
V Predictions Max            1438.6364
V Predictions Min            193.83583
Log Pis Mean                 -1.6598133
Log Pis Std                  2.9547858
Log Pis Max                  7.375328
Log Pis Min                  -7.093722
Policy mu Mean               -0.012869437
Policy mu Std                0.7047756
Policy mu Max                3.1364698
Policy mu Min                -2.551782
Policy log std Mean          -0.4289706
Policy log std Std           0.20139201
Policy log std Max           0.0058861375
Policy log std Min           -1.7983794
Z mean eval                  2.015856
Z variance eval              0.024991319
total_rewards                [4114.56073325 4070.33360968 4153.26172274 4144.03621273 4028.69383079
 4259.75024172 4104.84860212 4150.12714683 4295.24025268 3953.23815284]
total_rewards_mean           4127.409050538331
total_rewards_std            95.47475772704307
total_rewards_max            4295.240252678438
total_rewards_min            3953.2381528432056
Number of train steps total  68000
Number of env steps total    206000
Number of rollouts total     0
Train Time (s)               138.40331477764994
(Previous) Eval Time (s)     20.69219624903053
Sample Time (s)              6.5194888999685645
Epoch Time (s)               165.61499992664903
Total Train Time (s)         2842.0592373525724
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:41:00.541037 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #16 | Epoch Duration: 165.70138359069824
2020-01-12 08:41:00.541267 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0182343
Z variance train             0.025100445
KL Divergence                25.548069
KL Loss                      2.554807
QF Loss                      452.11264
VF Loss                      75.35474
Policy Loss                  -670.85315
Q Predictions Mean           659.8121
Q Predictions Std            445.31833
Q Predictions Max            1507.5543
Q Predictions Min            179.56554
V Predictions Mean           669.7782
V Predictions Std            444.68677
V Predictions Max            1508.9167
V Predictions Min            182.09344
Log Pis Mean                 -1.2252969
Log Pis Std                  3.0463333
Log Pis Max                  9.89942
Log Pis Min                  -6.402498
Policy mu Mean               0.015006158
Policy mu Std                0.75904214
Policy mu Max                2.5791357
Policy mu Min                -2.4907227
Policy log std Mean          -0.4502164
Policy log std Std           0.21949393
Policy log std Max           -0.1407725
Policy log std Min           -1.9273262
Z mean eval                  2.0372725
Z variance eval              0.036213472
total_rewards                [4170.19527401 4160.97827397 4436.13019125 4274.02923458 4346.11147862
 3048.00019551 4248.92151438 4117.69155094 4079.86585307 4188.52261099]
total_rewards_mean           4107.04461773277
total_rewards_std            367.34531893871576
total_rewards_max            4436.130191250258
total_rewards_min            3048.0001955116168
Number of train steps total  72000
Number of env steps total    218000
Number of rollouts total     0
Train Time (s)               141.87035724613816
(Previous) Eval Time (s)     17.881520632188767
Sample Time (s)              6.634430787991732
Epoch Time (s)               166.38630866631866
Total Train Time (s)         3008.5308165517636
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:43:47.014301 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #17 | Epoch Duration: 166.47281789779663
2020-01-12 08:43:47.014578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0378158
Z variance train             0.036215726
KL Divergence                24.724936
KL Loss                      2.4724936
QF Loss                      374.02994
VF Loss                      76.496376
Policy Loss                  -647.4341
Q Predictions Mean           642.9774
Q Predictions Std            468.45865
Q Predictions Max            1586.17
Q Predictions Min            171.4921
V Predictions Mean           645.7477
V Predictions Std            470.40665
V Predictions Max            1587.5881
V Predictions Min            184.52608
Log Pis Mean                 -1.4477639
Log Pis Std                  3.1816647
Log Pis Max                  12.205077
Log Pis Min                  -8.441115
Policy mu Mean               -0.028402278
Policy mu Std                0.72741604
Policy mu Max                2.8540606
Policy mu Min                -2.7232344
Policy log std Mean          -0.43199572
Policy log std Std           0.21164581
Policy log std Max           -0.06852865
Policy log std Min           -1.9186136
Z mean eval                  2.052632
Z variance eval              0.031677354
total_rewards                [4423.29883442 4639.7374459  4596.92142487 4585.55192501 4452.78936389
  357.0784464  4611.41226796 4639.93532078 4725.60387926 4694.20164616]
total_rewards_mean           4172.653055465287
total_rewards_std            1275.0371020760185
total_rewards_max            4725.603879259614
total_rewards_min            357.07844640025763
Number of train steps total  76000
Number of env steps total    230000
Number of rollouts total     0
Train Time (s)               143.2174494159408
(Previous) Eval Time (s)     20.94682462280616
Sample Time (s)              6.389730323571712
Epoch Time (s)               170.55400436231866
Total Train Time (s)         3179.1718197641894
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:46:37.657065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #18 | Epoch Duration: 170.64227199554443
2020-01-12 08:46:37.657384 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0513146
Z variance train             0.03166527
KL Divergence                25.73482
KL Loss                      2.573482
QF Loss                      713.3954
VF Loss                      104.504196
Policy Loss                  -735.2631
Q Predictions Mean           724.59595
Q Predictions Std            487.6482
Q Predictions Max            1631.7289
Q Predictions Min            156.41557
V Predictions Mean           736.07623
V Predictions Std            488.02353
V Predictions Max            1630.2549
V Predictions Min            165.74829
Log Pis Mean                 -1.0247283
Log Pis Std                  3.1998994
Log Pis Max                  11.451237
Log Pis Min                  -5.8777943
Policy mu Mean               -0.0056029856
Policy mu Std                0.8005643
Policy mu Max                2.5224411
Policy mu Min                -2.9216983
Policy log std Mean          -0.46340272
Policy log std Std           0.21830687
Policy log std Max           -0.18346441
Policy log std Min           -1.8705614
Z mean eval                  2.0377026
Z variance eval              0.029175634
total_rewards                [4494.37355246 4542.25351847 4710.45495347 4572.37737284 4437.07986685
 4583.15881631 4385.16812602 4538.85797426 1563.01554507 4645.52914923]
total_rewards_mean           4247.226887498035
total_rewards_std            899.1680254196839
total_rewards_max            4710.454953471471
total_rewards_min            1563.015545065152
Number of train steps total  80000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               144.04432352632284
(Previous) Eval Time (s)     17.662697550375015
Sample Time (s)              5.488814770244062
Epoch Time (s)               167.19583584694192
Total Train Time (s)         3346.4538402222097
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:49:24.937351 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #19 | Epoch Duration: 167.27975988388062
2020-01-12 08:49:24.937478 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.038317
Z variance train             0.029166698
KL Divergence                26.68172
KL Loss                      2.6681721
QF Loss                      641.4892
VF Loss                      146.53987
Policy Loss                  -671.963
Q Predictions Mean           665.6077
Q Predictions Std            481.8907
Q Predictions Max            1700.374
Q Predictions Min            156.67418
V Predictions Mean           674.1025
V Predictions Std            487.74765
V Predictions Max            1713.3905
V Predictions Min            162.89917
Log Pis Mean                 -1.2450749
Log Pis Std                  3.4889727
Log Pis Max                  17.339317
Log Pis Min                  -6.065465
Policy mu Mean               0.013075356
Policy mu Std                0.7786593
Policy mu Max                3.379003
Policy mu Min                -2.5032597
Policy log std Mean          -0.44531807
Policy log std Std           0.20463842
Policy log std Max           -0.12810335
Policy log std Min           -1.8942711
Z mean eval                  2.0361876
Z variance eval              0.013548319
total_rewards                [4760.88826166 4807.56384841 4764.86397556 4604.2524492  4596.94859848
 4850.72336513 4810.88148502 4660.62932514 4570.57482272 4758.09768673]
total_rewards_mean           4718.542381803219
total_rewards_std            96.18845413896143
total_rewards_max            4850.723365126467
total_rewards_min            4570.574822723481
Number of train steps total  84000
Number of env steps total    254000
Number of rollouts total     0
Train Time (s)               142.0042720111087
(Previous) Eval Time (s)     17.802587168756872
Sample Time (s)              5.6005626055411994
Epoch Time (s)               165.40742178540677
Total Train Time (s)         3511.9494775370695
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:52:10.434581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #20 | Epoch Duration: 165.4969961643219
2020-01-12 08:52:10.434788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0380793
Z variance train             0.013576733
KL Divergence                29.003494
KL Loss                      2.9003494
QF Loss                      434.9151
VF Loss                      56.841743
Policy Loss                  -610.7264
Q Predictions Mean           601.98413
Q Predictions Std            510.05133
Q Predictions Max            1693.618
Q Predictions Min            124.833755
V Predictions Mean           609.64
V Predictions Std            510.94025
V Predictions Max            1680.4326
V Predictions Min            135.87263
Log Pis Mean                 -1.9410557
Log Pis Std                  2.8054404
Log Pis Max                  8.169623
Log Pis Min                  -7.3368673
Policy mu Mean               -0.02429389
Policy mu Std                0.67474085
Policy mu Max                2.4181688
Policy mu Min                -2.2684376
Policy log std Mean          -0.4195682
Policy log std Std           0.20062496
Policy log std Max           -0.16138537
Policy log std Min           -1.7702808
Z mean eval                  2.025179
Z variance eval              0.015457749
total_rewards                [4642.04754859 4672.63591211 4704.63247448 4620.64115103 4752.66093323
 4602.03838834 5079.6816223  4497.61826388 4786.90901841 4648.51359052]
total_rewards_mean           4700.737890289772
total_rewards_std            147.68591752773307
total_rewards_max            5079.681622304998
total_rewards_min            4497.618263882255
Number of train steps total  88000
Number of env steps total    266000
Number of rollouts total     0
Train Time (s)               142.99548460543156
(Previous) Eval Time (s)     17.859015784226358
Sample Time (s)              6.667985321488231
Epoch Time (s)               167.52248571114615
Total Train Time (s)         3679.6615470452234
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:54:58.147837 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #21 | Epoch Duration: 167.71291279792786
2020-01-12 08:54:58.147998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.023418
Z variance train             0.015453505
KL Divergence                27.739176
KL Loss                      2.7739177
QF Loss                      547.84827
VF Loss                      152.75642
Policy Loss                  -651.7789
Q Predictions Mean           642.58344
Q Predictions Std            538.62616
Q Predictions Max            1812.4312
Q Predictions Min            96.81076
V Predictions Mean           657.5343
V Predictions Std            541.4896
V Predictions Max            1816.8794
V Predictions Min            128.5691
Log Pis Mean                 -1.495946
Log Pis Std                  3.176322
Log Pis Max                  10.926348
Log Pis Min                  -7.9325523
Policy mu Mean               0.018956264
Policy mu Std                0.7482804
Policy mu Max                2.8720756
Policy mu Min                -2.2401588
Policy log std Mean          -0.44692007
Policy log std Std           0.2161793
Policy log std Max           -0.14366439
Policy log std Min           -1.8633794
Z mean eval                  2.0281339
Z variance eval              0.01714147
total_rewards                [4597.09641947 4687.12053559 4561.88036722 4486.31165808 4745.18781628
 4584.36826656 4614.64885838 4638.46529576 4635.273062   4764.83699843]
total_rewards_mean           4631.518927775065
total_rewards_std            79.67156455104514
total_rewards_max            4764.836998426894
total_rewards_min            4486.31165808141
Number of train steps total  92000
Number of env steps total    278000
Number of rollouts total     0
Train Time (s)               143.04083065968007
(Previous) Eval Time (s)     20.841031291987747
Sample Time (s)              5.558446064591408
Epoch Time (s)               169.44030801625922
Total Train Time (s)         3849.189192353748
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 08:57:47.676545 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #22 | Epoch Duration: 169.52843403816223
2020-01-12 08:57:47.676697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0243769
Z variance train             0.01729947
KL Divergence                28.261993
KL Loss                      2.8261993
QF Loss                      409.73837
VF Loss                      193.96175
Policy Loss                  -746.556
Q Predictions Mean           740.37976
Q Predictions Std            556.5069
Q Predictions Max            1789.7455
Q Predictions Min            101.513115
V Predictions Mean           750.61646
V Predictions Std            560.095
V Predictions Max            1823.0089
V Predictions Min            119.21659
Log Pis Mean                 -1.3957946
Log Pis Std                  2.9787452
Log Pis Max                  8.2895355
Log Pis Min                  -5.977763
Policy mu Mean               -0.03283703
Policy mu Std                0.7476174
Policy mu Max                2.4543555
Policy mu Min                -2.4720156
Policy log std Mean          -0.466127
Policy log std Std           0.22201559
Policy log std Max           -0.1286805
Policy log std Min           -1.826636
Z mean eval                  2.0326412
Z variance eval              0.028896078
total_rewards                [4669.05711737 4852.18490254 4774.42824169 4946.57610971 4715.19232555
 4836.29778806 4619.8709596  4870.40027789 4814.16670865 4784.92612985]
total_rewards_mean           4788.310056091102
total_rewards_std            93.26397161865265
total_rewards_max            4946.576109708171
total_rewards_min            4619.870959600222
Number of train steps total  96000
Number of env steps total    290000
Number of rollouts total     0
Train Time (s)               141.10860030306503
(Previous) Eval Time (s)     20.56366327079013
Sample Time (s)              6.3761213487014174
Epoch Time (s)               168.04838492255658
Total Train Time (s)         4017.3202581135556
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:00:35.807636 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #23 | Epoch Duration: 168.13083934783936
2020-01-12 09:00:35.807768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0306573
Z variance train             0.029026305
KL Divergence                26.534168
KL Loss                      2.6534169
QF Loss                      337.837
VF Loss                      205.6247
Policy Loss                  -713.5992
Q Predictions Mean           708.9459
Q Predictions Std            557.4165
Q Predictions Max            1774.2218
Q Predictions Min            102.92879
V Predictions Mean           722.3935
V Predictions Std            560.33765
V Predictions Max            1766.4296
V Predictions Min            109.6126
Log Pis Mean                 -1.3685559
Log Pis Std                  3.2782125
Log Pis Max                  10.387593
Log Pis Min                  -6.2781324
Policy mu Mean               -0.011731562
Policy mu Std                0.7513631
Policy mu Max                3.3826246
Policy mu Min                -2.598694
Policy log std Mean          -0.4469289
Policy log std Std           0.20790525
Policy log std Max           -0.08461824
Policy log std Min           -1.7412851
Z mean eval                  2.047018
Z variance eval              0.013464752
total_rewards                [4493.17581748 4903.17742806 4902.48281753 4903.70523446 4824.49535493
 5015.17877966 4862.99264961 5055.62232655 4693.74234792 4912.4287529 ]
total_rewards_mean           4856.700150910781
total_rewards_std            152.9832616733558
total_rewards_max            5055.622326550684
total_rewards_min            4493.1758174775705
Number of train steps total  100000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               142.7698723897338
(Previous) Eval Time (s)     20.68376092100516
Sample Time (s)              6.422889966983348
Epoch Time (s)               169.8765232777223
Total Train Time (s)         4187.292667977046
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:03:25.781355 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #24 | Epoch Duration: 169.9734947681427
2020-01-12 09:03:25.781486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.049327
Z variance train             0.013461389
KL Divergence                29.153847
KL Loss                      2.9153848
QF Loss                      619.75793
VF Loss                      74.08905
Policy Loss                  -737.48126
Q Predictions Mean           732.8335
Q Predictions Std            595.222
Q Predictions Max            1905.4208
Q Predictions Min            97.762924
V Predictions Mean           734.8203
V Predictions Std            602.84515
V Predictions Max            1892.0446
V Predictions Min            89.38137
Log Pis Mean                 -1.4506104
Log Pis Std                  2.9830441
Log Pis Max                  9.500827
Log Pis Min                  -11.382517
Policy mu Mean               -0.025762184
Policy mu Std                0.7205925
Policy mu Max                2.56592
Policy mu Min                -2.437033
Policy log std Mean          -0.45581213
Policy log std Std           0.2215566
Policy log std Max           -0.10289693
Policy log std Min           -1.7334188
Z mean eval                  2.0222604
Z variance eval              0.013711552
total_rewards                [4981.23265904 4943.10141212 5007.24569139 5063.85853729 4656.56662369
 4819.71382857 5021.85060958 4961.23376933 4920.53993101 4880.39479163]
total_rewards_mean           4925.573785364833
total_rewards_std            111.97170480004746
total_rewards_max            5063.858537289605
total_rewards_min            4656.566623687077
Number of train steps total  104000
Number of env steps total    314000
Number of rollouts total     0
Train Time (s)               141.62008549598977
(Previous) Eval Time (s)     18.15337662398815
Sample Time (s)              6.579955822322518
Epoch Time (s)               166.35341794230044
Total Train Time (s)         4353.729885804933
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:06:12.220284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #25 | Epoch Duration: 166.43868494033813
2020-01-12 09:06:12.220463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0234795
Z variance train             0.013727216
KL Divergence                29.582672
KL Loss                      2.9582672
QF Loss                      472.3687
VF Loss                      152.70818
Policy Loss                  -657.65674
Q Predictions Mean           646.95654
Q Predictions Std            594.7751
Q Predictions Max            1871.282
Q Predictions Min            74.429436
V Predictions Mean           651.1465
V Predictions Std            594.6614
V Predictions Max            1871.5942
V Predictions Min            75.58759
Log Pis Mean                 -1.2451394
Log Pis Std                  3.6449473
Log Pis Max                  16.5498
Log Pis Min                  -6.4693623
Policy mu Mean               -0.052829474
Policy mu Std                0.7481135
Policy mu Max                3.615227
Policy mu Min                -2.6340947
Policy log std Mean          -0.44625163
Policy log std Std           0.21348017
Policy log std Max           -0.13894868
Policy log std Min           -2.0049624
Z mean eval                  2.0357692
Z variance eval              0.012407092
total_rewards                [4832.67316982 4854.17474441 4925.39359424 4775.88037532 4861.57829159
 4812.29789474 5009.44890185 4743.83523951 4775.74990292 4654.94663439]
total_rewards_mean           4824.597874878151
total_rewards_std            93.19452094767739
total_rewards_max            5009.448901854064
total_rewards_min            4654.9466343894865
Number of train steps total  108000
Number of env steps total    326000
Number of rollouts total     0
Train Time (s)               141.2612595348619
(Previous) Eval Time (s)     20.997426039073616
Sample Time (s)              6.409218803979456
Epoch Time (s)               168.66790437791497
Total Train Time (s)         4522.480996177066
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:09:00.971810 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #26 | Epoch Duration: 168.751207113266
2020-01-12 09:09:00.971994 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0352776
Z variance train             0.012401191
KL Divergence                30.053246
KL Loss                      3.0053246
QF Loss                      263.26642
VF Loss                      54.5548
Policy Loss                  -710.5604
Q Predictions Mean           699.81146
Q Predictions Std            621.94183
Q Predictions Max            1934.0841
Q Predictions Min            57.98015
V Predictions Mean           714.37573
V Predictions Std            622.8636
V Predictions Max            1925.218
V Predictions Min            61.315956
Log Pis Mean                 -1.4607358
Log Pis Std                  3.2791247
Log Pis Max                  9.323282
Log Pis Min                  -6.436953
Policy mu Mean               -0.03982942
Policy mu Std                0.6925763
Policy mu Max                2.63727
Policy mu Min                -2.20095
Policy log std Mean          -0.45009172
Policy log std Std           0.21778397
Policy log std Max           -0.16445899
Policy log std Min           -2.0487385
Z mean eval                  2.0214164
Z variance eval              0.010071065
total_rewards                [5182.63918377 5091.50331903 5103.22119622 5039.1372463  5151.28000896
 5128.72296529 5039.69001429 5098.48234197 5255.90866963 5008.14275095]
total_rewards_mean           5109.872769643438
total_rewards_std            70.34264464468178
total_rewards_max            5255.90866963438
total_rewards_min            5008.142750953293
Number of train steps total  112000
Number of env steps total    338000
Number of rollouts total     0
Train Time (s)               141.0411677430384
(Previous) Eval Time (s)     18.003767985850573
Sample Time (s)              6.6133713675662875
Epoch Time (s)               165.65830709645525
Total Train Time (s)         4688.2212854032405
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:11:46.712660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #27 | Epoch Duration: 165.74053406715393
2020-01-12 09:11:46.712831 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #27 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0188687
Z variance train             0.010054784
KL Divergence                30.087471
KL Loss                      3.008747
QF Loss                      266.87878
VF Loss                      121.0192
Policy Loss                  -702.7262
Q Predictions Mean           691.6536
Q Predictions Std            639.0264
Q Predictions Max            2008.6222
Q Predictions Min            50.822777
V Predictions Mean           699.0124
V Predictions Std            641.7784
V Predictions Max            2003.8915
V Predictions Min            52.57433
Log Pis Mean                 -1.7039969
Log Pis Std                  2.9844642
Log Pis Max                  12.922958
Log Pis Min                  -7.612914
Policy mu Mean               -0.059568897
Policy mu Std                0.70399445
Policy mu Max                2.367546
Policy mu Min                -2.6718206
Policy log std Mean          -0.42861238
Policy log std Std           0.2138189
Policy log std Max           -0.10575122
Policy log std Min           -2.140331
Z mean eval                  2.027985
Z variance eval              0.01118052
total_rewards                [4410.39408363 4657.48944395 4767.114662   4921.24410369 4892.8415199
 4743.08554605 4855.15624898 4897.55695556 4526.66983644 4369.1545255 ]
total_rewards_mean           4704.0706925700915
total_rewards_std            195.0935319340546
total_rewards_max            4921.244103687312
total_rewards_min            4369.154525503183
Number of train steps total  116000
Number of env steps total    350000
Number of rollouts total     0
Train Time (s)               140.86426348332316
(Previous) Eval Time (s)     17.746226230170578
Sample Time (s)              6.709316718857735
Epoch Time (s)               165.31980643235147
Total Train Time (s)         4853.639465515502
Epoch                        28
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:14:32.134787 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #28 | Epoch Duration: 165.4217963218689
2020-01-12 09:14:32.135095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0266674
Z variance train             0.011172461
KL Divergence                30.200075
KL Loss                      3.0200076
QF Loss                      419.12427
VF Loss                      124.63762
Policy Loss                  -685.0663
Q Predictions Mean           674.84155
Q Predictions Std            646.5492
Q Predictions Max            2002.5687
Q Predictions Min            31.501518
V Predictions Mean           681.33026
V Predictions Std            646.2774
V Predictions Max            1990.4631
V Predictions Min            46.71347
Log Pis Mean                 -1.341938
Log Pis Std                  3.5698185
Log Pis Max                  12.222639
Log Pis Min                  -6.309934
Policy mu Mean               -0.040434983
Policy mu Std                0.75269246
Policy mu Max                2.889136
Policy mu Min                -2.5509439
Policy log std Mean          -0.42825142
Policy log std Std           0.20375769
Policy log std Max           -0.14308858
Policy log std Min           -1.8292899
Z mean eval                  2.0582018
Z variance eval              0.010430889
total_rewards                [5008.13326421 4974.93899032 5062.57897545 4870.47741931 4796.37815565
 4859.92731145 4989.17966042 5047.78401663 4946.93882823 5034.46758714]
total_rewards_mean           4959.080420880951
total_rewards_std            84.9284521215626
total_rewards_max            5062.578975451279
total_rewards_min            4796.378155654111
Number of train steps total  120000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               140.1498629320413
(Previous) Eval Time (s)     17.633558608591557
Sample Time (s)              6.662011910695583
Epoch Time (s)               164.44543345132843
Total Train Time (s)         5018.166662522126
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:17:16.660337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #29 | Epoch Duration: 164.52508091926575
2020-01-12 09:17:16.660464 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0576825
Z variance train             0.010412558
KL Divergence                31.138704
KL Loss                      3.1138704
QF Loss                      285.7967
VF Loss                      116.991905
Policy Loss                  -746.8724
Q Predictions Mean           738.9391
Q Predictions Std            664.5203
Q Predictions Max            2037.9059
Q Predictions Min            30.50481
V Predictions Mean           740.34644
V Predictions Std            665.69196
V Predictions Max            2023.6799
V Predictions Min            31.49628
Log Pis Mean                 -1.5492251
Log Pis Std                  3.4208007
Log Pis Max                  13.254298
Log Pis Min                  -7.7265205
Policy mu Mean               -0.013829236
Policy mu Std                0.72250754
Policy mu Max                3.267513
Policy mu Min                -2.490012
Policy log std Mean          -0.4482905
Policy log std Std           0.22513644
Policy log std Max           -0.16336924
Policy log std Min           -2.0232937
Z mean eval                  2.0259438
Z variance eval              0.010483713
total_rewards                [5194.02909708 5278.40269842 4935.91400351 5203.3047555  5086.38994591
 5151.55745666 4928.47303166 5213.3157406  5184.3956227  5020.14055701]
total_rewards_mean           5119.592290905054
total_rewards_std            115.33950608277617
total_rewards_max            5278.402698422147
total_rewards_min            4928.473031656963
Number of train steps total  124000
Number of env steps total    374000
Number of rollouts total     0
Train Time (s)               141.5582011579536
(Previous) Eval Time (s)     17.912122840993106
Sample Time (s)              5.539829174987972
Epoch Time (s)               165.01015317393467
Total Train Time (s)         5183.252319649328
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:20:01.746949 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #30 | Epoch Duration: 165.08639454841614
2020-01-12 09:20:01.747072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.024499
Z variance train             0.010481054
KL Divergence                31.816204
KL Loss                      3.1816204
QF Loss                      320.4638
VF Loss                      120.12851
Policy Loss                  -730.2805
Q Predictions Mean           730.4114
Q Predictions Std            684.0302
Q Predictions Max            2035.8125
Q Predictions Min            28.300985
V Predictions Mean           731.5387
V Predictions Std            686.4791
V Predictions Max            2040.6293
V Predictions Min            28.085276
Log Pis Mean                 -1.7431116
Log Pis Std                  3.3617494
Log Pis Max                  10.267867
Log Pis Min                  -7.428671
Policy mu Mean               -0.093174584
Policy mu Std                0.71207017
Policy mu Max                2.730125
Policy mu Min                -2.4501557
Policy log std Mean          -0.44136313
Policy log std Std           0.21834816
Policy log std Max           -0.13053262
Policy log std Min           -1.9691508
Z mean eval                  2.0677016
Z variance eval              0.011395861
total_rewards                [4913.49948454 5029.09877209 4992.64858802 4943.18625227 5060.08056666
 4849.38693109 5159.94198972 5043.60289026 4833.75016385 4901.20610447]
total_rewards_mean           4972.64017429837
total_rewards_std            97.62232696584172
total_rewards_max            5159.94198972395
total_rewards_min            4833.750163852258
Number of train steps total  128000
Number of env steps total    386000
Number of rollouts total     0
Train Time (s)               141.90789236221462
(Previous) Eval Time (s)     20.776423908770084
Sample Time (s)              5.908073846716434
Epoch Time (s)               168.59239011770114
Total Train Time (s)         5351.927293284796
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:22:50.424460 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #31 | Epoch Duration: 168.67728209495544
2020-01-12 09:22:50.424633 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0681777
Z variance train             0.011424643
KL Divergence                31.909388
KL Loss                      3.1909387
QF Loss                      676.81323
VF Loss                      297.85492
Policy Loss                  -702.78284
Q Predictions Mean           699.1506
Q Predictions Std            674.1053
Q Predictions Max            2018.4272
Q Predictions Min            18.44637
V Predictions Mean           715.4896
V Predictions Std            679.4722
V Predictions Max            2048.6272
V Predictions Min            26.603224
Log Pis Mean                 -1.8288109
Log Pis Std                  2.8762844
Log Pis Max                  7.754303
Log Pis Min                  -6.397706
Policy mu Mean               -0.031804267
Policy mu Std                0.69080275
Policy mu Max                2.4755273
Policy mu Min                -2.460748
Policy log std Mean          -0.43325615
Policy log std Std           0.2059932
Policy log std Max           -0.17781869
Policy log std Min           -1.8117874
Z mean eval                  2.0115523
Z variance eval              0.009158669
total_rewards                [4930.71792118 4961.27760372 4962.53582958 4958.88330646 5123.64096342
 4917.26776985 4894.19879394 5066.61585105 5138.38355569 5131.77833401]
total_rewards_mean           5008.529992890032
total_rewards_std            91.07402678033239
total_rewards_max            5138.383555689717
total_rewards_min            4894.198793941758
Number of train steps total  132000
Number of env steps total    398000
Number of rollouts total     0
Train Time (s)               140.84066153736785
(Previous) Eval Time (s)     21.090258467011154
Sample Time (s)              6.336463165469468
Epoch Time (s)               168.26738316984847
Total Train Time (s)         5520.274471122306
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:25:38.771578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #32 | Epoch Duration: 168.346825838089
2020-01-12 09:25:38.771712 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0108795
Z variance train             0.009148742
KL Divergence                31.219786
KL Loss                      3.1219785
QF Loss                      462.36652
VF Loss                      98.95071
Policy Loss                  -799.978
Q Predictions Mean           792.73425
Q Predictions Std            697.7275
Q Predictions Max            2116.9197
Q Predictions Min            7.562318
V Predictions Mean           805.38354
V Predictions Std            697.1497
V Predictions Max            2120.521
V Predictions Min            18.913448
Log Pis Mean                 -1.3409331
Log Pis Std                  3.4899313
Log Pis Max                  15.142234
Log Pis Min                  -10.815371
Policy mu Mean               -0.007524267
Policy mu Std                0.7541136
Policy mu Max                2.6081161
Policy mu Min                -2.9091694
Policy log std Mean          -0.44662738
Policy log std Std           0.23447126
Policy log std Max           -0.10689992
Policy log std Min           -1.9322999
Z mean eval                  2.0111644
Z variance eval              0.007921029
total_rewards                [5129.58879806 5111.6687505  5297.14298844 5097.01310495 5127.74535869
 5013.73793278 5257.27606019 5063.39930136 5181.40848919 5325.89018935]
total_rewards_mean           5160.487097349945
total_rewards_std            97.5905148372823
total_rewards_max            5325.8901893526845
total_rewards_min            5013.737932775146
Number of train steps total  136000
Number of env steps total    410000
Number of rollouts total     0
Train Time (s)               142.93487990368158
(Previous) Eval Time (s)     17.54302972694859
Sample Time (s)              6.32580513227731
Epoch Time (s)               166.80371476290748
Total Train Time (s)         5687.161943530664
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:28:25.666689 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #33 | Epoch Duration: 166.89479684829712
2020-01-12 09:28:25.666888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.013196
Z variance train             0.007927309
KL Divergence                32.476612
KL Loss                      3.2476614
QF Loss                      298.3022
VF Loss                      70.395615
Policy Loss                  -746.57043
Q Predictions Mean           743.2012
Q Predictions Std            706.8649
Q Predictions Max            2111.5063
Q Predictions Min            9.975159
V Predictions Mean           748.12537
V Predictions Std            704.9973
V Predictions Max            2103.6926
V Predictions Min            5.57406
Log Pis Mean                 -1.724053
Log Pis Std                  3.1172962
Log Pis Max                  10.207581
Log Pis Min                  -9.23498
Policy mu Mean               -0.11991951
Policy mu Std                0.6812127
Policy mu Max                3.2648926
Policy mu Min                -2.3841546
Policy log std Mean          -0.4455271
Policy log std Std           0.23644611
Policy log std Max           -0.14020789
Policy log std Min           -2.1365905
Z mean eval                  1.9923277
Z variance eval              0.0065028593
total_rewards                [5197.35521313 5141.54552838 5251.19244734 5284.64058169 5181.27458809
 5284.98839445 5165.15116807 5169.73454645 5271.48448344 5131.62165571]
total_rewards_mean           5207.8988606746825
total_rewards_std            56.63429281935582
total_rewards_max            5284.988394448434
total_rewards_min            5131.62165571312
Number of train steps total  140000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               141.8314101928845
(Previous) Eval Time (s)     21.229320212733
Sample Time (s)              6.686043226160109
Epoch Time (s)               169.74677363177761
Total Train Time (s)         5856.989601863548
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:31:15.490472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #34 | Epoch Duration: 169.82345485687256
2020-01-12 09:31:15.490662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9908043
Z variance train             0.0065027988
KL Divergence                32.60604
KL Loss                      3.2606041
QF Loss                      463.14
VF Loss                      227.22041
Policy Loss                  -795.10925
Q Predictions Mean           785.98083
Q Predictions Std            677.6413
Q Predictions Max            2136.5193
Q Predictions Min            3.414191
V Predictions Mean           790.85913
V Predictions Std            679.9208
V Predictions Max            2105.9216
V Predictions Min            -4.4826446
Log Pis Mean                 -1.2362294
Log Pis Std                  3.76636
Log Pis Max                  18.776363
Log Pis Min                  -11.588324
Policy mu Mean               0.01176576
Policy mu Std                0.76745343
Policy mu Max                3.4863715
Policy mu Min                -2.9122043
Policy log std Mean          -0.46014056
Policy log std Std           0.2393165
Policy log std Max           -0.12928592
Policy log std Min           -2.080087
Z mean eval                  1.982322
Z variance eval              0.01019543
total_rewards                [5511.46937797 5275.52435592 5299.64951233 5623.86889705 5489.50535016
 5528.13720094 5434.59457079 5314.21975526 5166.55774969 5289.20242108]
total_rewards_mean           5393.272919119725
total_rewards_std            136.89826437036996
total_rewards_max            5623.86889705389
total_rewards_min            5166.557749693539
Number of train steps total  144000
Number of env steps total    434000
Number of rollouts total     0
Train Time (s)               142.30565339094028
(Previous) Eval Time (s)     17.496944373007864
Sample Time (s)              6.514322770293802
Epoch Time (s)               166.31692053424194
Total Train Time (s)         6023.396328133531
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:34:01.898952 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #35 | Epoch Duration: 166.4081506729126
2020-01-12 09:34:01.899142 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9842106
Z variance train             0.010114294
KL Divergence                31.774921
KL Loss                      3.1774921
QF Loss                      719.38043
VF Loss                      142.73395
Policy Loss                  -731.98566
Q Predictions Mean           728.1707
Q Predictions Std            687.2407
Q Predictions Max            2071.074
Q Predictions Min            -0.54025406
V Predictions Mean           730.228
V Predictions Std            691.8735
V Predictions Max            2086.4177
V Predictions Min            -3.9985905
Log Pis Mean                 -1.4094245
Log Pis Std                  3.4193897
Log Pis Max                  12.677217
Log Pis Min                  -7.1152325
Policy mu Mean               0.034444217
Policy mu Std                0.7468055
Policy mu Max                2.5352218
Policy mu Min                -2.57408
Policy log std Mean          -0.4505248
Policy log std Std           0.23987654
Policy log std Max           -0.13523254
Policy log std Min           -2.0475059
Z mean eval                  1.9508088
Z variance eval              0.016275797
total_rewards                [5003.12511508 5326.30028738 5190.58051303 5142.59032258 5331.63778743
 5310.00922322 5297.72064848 5135.7072647  5195.42553707 5284.08597899]
total_rewards_mean           5221.718267796825
total_rewards_std            101.7762467060514
total_rewards_max            5331.637787429987
total_rewards_min            5003.125115082092
Number of train steps total  148000
Number of env steps total    446000
Number of rollouts total     0
Train Time (s)               144.4348793583922
(Previous) Eval Time (s)     20.861664231866598
Sample Time (s)              6.419082653708756
Epoch Time (s)               171.71562624396756
Total Train Time (s)         6195.258109313436
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:36:53.772583 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #36 | Epoch Duration: 171.8732626438141
2020-01-12 09:36:53.772891 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9521799
Z variance train             0.0163229
KL Divergence                30.590855
KL Loss                      3.0590856
QF Loss                      715.11865
VF Loss                      172.6002
Policy Loss                  -858.7785
Q Predictions Mean           852.54987
Q Predictions Std            704.0104
Q Predictions Max            2119.3477
Q Predictions Min            172.0868
V Predictions Mean           851.788
V Predictions Std            707.78625
V Predictions Max            2117.8516
V Predictions Min            170.26138
Log Pis Mean                 -0.9219233
Log Pis Std                  3.811944
Log Pis Max                  19.309246
Log Pis Min                  -9.117815
Policy mu Mean               -0.01584625
Policy mu Std                0.82065904
Policy mu Max                2.7104678
Policy mu Min                -2.586577
Policy log std Mean          -0.45785967
Policy log std Std           0.22366466
Policy log std Max           -0.07210088
Policy log std Min           -1.7587082
Z mean eval                  1.9624538
Z variance eval              0.016997833
total_rewards                [5132.91055929 5157.18391045 5281.45662361 5146.77024401 5091.99859833
 5230.39312718 5209.76390769 5175.3328794  5100.81521801 5335.88686695]
total_rewards_mean           5186.251193492533
total_rewards_std            74.50316066494202
total_rewards_max            5335.886866950929
total_rewards_min            5091.998598326392
Number of train steps total  152000
Number of env steps total    458000
Number of rollouts total     0
Train Time (s)               145.45794845093042
(Previous) Eval Time (s)     20.677375125698745
Sample Time (s)              6.431504470761865
Epoch Time (s)               172.56682804739103
Total Train Time (s)         6367.9311778373085
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:39:46.434021 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #37 | Epoch Duration: 172.6609284877777
2020-01-12 09:39:46.434152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9644178
Z variance train             0.017000634
KL Divergence                30.903831
KL Loss                      3.0903833
QF Loss                      364.62387
VF Loss                      87.63764
Policy Loss                  -833.8527
Q Predictions Mean           825.0542
Q Predictions Std            742.15674
Q Predictions Max            2155.3752
Q Predictions Min            -25.079063
V Predictions Mean           836.38275
V Predictions Std            745.8499
V Predictions Max            2155.4973
V Predictions Min            -16.207958
Log Pis Mean                 -1.4076827
Log Pis Std                  3.2843692
Log Pis Max                  9.679754
Log Pis Min                  -6.10823
Policy mu Mean               0.041896883
Policy mu Std                0.7189112
Policy mu Max                2.3668315
Policy mu Min                -2.2783396
Policy log std Mean          -0.45866325
Policy log std Std           0.24457046
Policy log std Max           -0.16071695
Policy log std Min           -1.941442
Z mean eval                  1.9287876
Z variance eval              0.010005602
total_rewards                [5234.26838    5329.25251579 5315.78567077 5207.5551744  5415.67141014
 5449.64089351 5264.04659681 5284.43980118 5182.61279573 5300.13561691]
total_rewards_mean           5298.340885523703
total_rewards_std            80.64172329573218
total_rewards_max            5449.6408935102945
total_rewards_min            5182.612795726832
Number of train steps total  156000
Number of env steps total    470000
Number of rollouts total     0
Train Time (s)               144.1300858198665
(Previous) Eval Time (s)     19.676211544778198
Sample Time (s)              6.481772172264755
Epoch Time (s)               170.28806953690946
Total Train Time (s)         6538.415540090296
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:42:36.920236 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #38 | Epoch Duration: 170.48597359657288
2020-01-12 09:42:36.920432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9272105
Z variance train             0.010000967
KL Divergence                32.510223
KL Loss                      3.2510223
QF Loss                      577.2046
VF Loss                      84.348495
Policy Loss                  -664.87524
Q Predictions Mean           656.20935
Q Predictions Std            689.24524
Q Predictions Max            2182.8716
Q Predictions Min            -25.503555
V Predictions Mean           665.0832
V Predictions Std            691.6892
V Predictions Max            2192.0193
V Predictions Min            -19.707468
Log Pis Mean                 -1.5502934
Log Pis Std                  3.6842868
Log Pis Max                  16.854641
Log Pis Min                  -5.7363153
Policy mu Mean               -0.032096673
Policy mu Std                0.7010603
Policy mu Max                2.8819785
Policy mu Min                -2.8021574
Policy log std Mean          -0.43353677
Policy log std Std           0.22576028
Policy log std Max           -0.111487776
Policy log std Min           -2.1224132
Z mean eval                  1.9261463
Z variance eval              0.010553861
total_rewards                [4841.72023421 4727.1767504  4673.99357773 4695.26410871 4732.95423643
 4804.11740735 4877.10070315 4711.59387007 4943.79758326 4801.65676445]
total_rewards_mean           4780.937523576407
total_rewards_std            83.19254079580932
total_rewards_max            4943.7975832642405
total_rewards_min            4673.993577734056
Number of train steps total  160000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               144.26923241792247
(Previous) Eval Time (s)     21.0937678120099
Sample Time (s)              6.575462173204869
Epoch Time (s)               171.93846240313724
Total Train Time (s)         6710.44034270104
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:45:28.946509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #39 | Epoch Duration: 172.02594590187073
2020-01-12 09:45:28.946658 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9253658
Z variance train             0.010538174
KL Divergence                31.91695
KL Loss                      3.191695
QF Loss                      289.47015
VF Loss                      93.636505
Policy Loss                  -705.2595
Q Predictions Mean           698.34973
Q Predictions Std            704.986
Q Predictions Max            2164.7893
Q Predictions Min            -40.51577
V Predictions Mean           702.0286
V Predictions Std            708.7143
V Predictions Max            2157.868
V Predictions Min            -30.491829
Log Pis Mean                 -1.5988269
Log Pis Std                  3.524259
Log Pis Max                  15.619225
Log Pis Min                  -7.467081
Policy mu Mean               0.009076622
Policy mu Std                0.71365994
Policy mu Max                2.5810375
Policy mu Min                -3.640359
Policy log std Mean          -0.4447304
Policy log std Std           0.23135073
Policy log std Max           -0.20116125
Policy log std Min           -2.151151
Z mean eval                  1.9241874
Z variance eval              0.007018107
total_rewards                [5255.78238791 5357.09015168 5286.09799596 5145.63399025 5446.89738573
 5469.86368091 5470.00097291 5484.02568532 5471.74067345 5090.33573978]
total_rewards_mean           5347.7468663903
total_rewards_std            138.95727308234007
total_rewards_max            5484.0256853181645
total_rewards_min            5090.335739783655
Number of train steps total  164000
Number of env steps total    494000
Number of rollouts total     0
Train Time (s)               143.19572606729344
(Previous) Eval Time (s)     20.853195880074054
Sample Time (s)              6.616421832703054
Epoch Time (s)               170.66534378007054
Total Train Time (s)         6881.185848126188
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:48:19.693430 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #40 | Epoch Duration: 170.74665665626526
2020-01-12 09:48:19.693619 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9250212
Z variance train             0.0070357444
KL Divergence                33.920822
KL Loss                      3.3920822
QF Loss                      243.66617
VF Loss                      69.93758
Policy Loss                  -766.4918
Q Predictions Mean           757.9278
Q Predictions Std            732.8205
Q Predictions Max            2186.0105
Q Predictions Min            -49.129402
V Predictions Mean           764.6832
V Predictions Std            730.8566
V Predictions Max            2169.438
V Predictions Min            -33.23138
Log Pis Mean                 -1.6020355
Log Pis Std                  3.108923
Log Pis Max                  8.506835
Log Pis Min                  -8.212087
Policy mu Mean               -0.054869715
Policy mu Std                0.71235174
Policy mu Max                2.9054751
Policy mu Min                -2.399456
Policy log std Mean          -0.45114264
Policy log std Std           0.22765432
Policy log std Max           -0.1610497
Policy log std Min           -2.0342834
Z mean eval                  1.9190514
Z variance eval              0.011739949
total_rewards                [5375.27445305 5470.55176071 5318.34127574 5630.99344036 5334.14956611
 5481.03371384 5555.55744295 5505.58239179 5567.26934222 5502.63762853]
total_rewards_mean           5474.139101529052
total_rewards_std            97.67854122860655
total_rewards_max            5630.993440358563
total_rewards_min            5318.341275739586
Number of train steps total  168000
Number of env steps total    506000
Number of rollouts total     0
Train Time (s)               143.62412471883
(Previous) Eval Time (s)     21.018029063940048
Sample Time (s)              6.4341979143209755
Epoch Time (s)               171.076351697091
Total Train Time (s)         7052.3416511416435
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:51:10.850680 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #41 | Epoch Duration: 171.1569230556488
2020-01-12 09:51:10.850870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198879
Z variance train             0.011732917
KL Divergence                34.13242
KL Loss                      3.413242
QF Loss                      609.5105
VF Loss                      74.978035
Policy Loss                  -804.8811
Q Predictions Mean           797.6124
Q Predictions Std            753.85614
Q Predictions Max            2188.6362
Q Predictions Min            -75.26409
V Predictions Mean           805.4087
V Predictions Std            756.02185
V Predictions Max            2211.2659
V Predictions Min            -47.226604
Log Pis Mean                 -1.4342676
Log Pis Std                  3.0170403
Log Pis Max                  7.873294
Log Pis Min                  -5.6499586
Policy mu Mean               -0.012094073
Policy mu Std                0.7186303
Policy mu Max                2.4601004
Policy mu Min                -2.3178265
Policy log std Mean          -0.4514916
Policy log std Std           0.2352799
Policy log std Max           -0.102035195
Policy log std Min           -2.2101946
Z mean eval                  1.9269985
Z variance eval              0.013267791
total_rewards                [5316.75040639 5394.59284535 5624.51197886 5448.12631754 5410.69106145
 5397.81146692 5397.91677631 5468.97522051 5419.58793861 5400.23368368]
total_rewards_mean           5427.919769562427
total_rewards_std            75.59835924673186
total_rewards_max            5624.511978855735
total_rewards_min            5316.750406388005
Number of train steps total  172000
Number of env steps total    518000
Number of rollouts total     0
Train Time (s)               143.49168620212004
(Previous) Eval Time (s)     17.771745512727648
Sample Time (s)              6.452022929675877
Epoch Time (s)               167.71545464452356
Total Train Time (s)         7220.141392479185
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:53:58.651610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #42 | Epoch Duration: 167.80060124397278
2020-01-12 09:53:58.651782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9245384
Z variance train             0.013272281
KL Divergence                34.07424
KL Loss                      3.4074242
QF Loss                      357.13147
VF Loss                      52.87967
Policy Loss                  -819.3936
Q Predictions Mean           809.0873
Q Predictions Std            776.2733
Q Predictions Max            2288.3298
Q Predictions Min            -81.76934
V Predictions Mean           820.7569
V Predictions Std            779.14026
V Predictions Max            2284.8242
V Predictions Min            -53.971855
Log Pis Mean                 -1.3937776
Log Pis Std                  3.290599
Log Pis Max                  9.213146
Log Pis Min                  -6.105917
Policy mu Mean               -0.012945895
Policy mu Std                0.73307234
Policy mu Max                2.6098738
Policy mu Min                -2.747522
Policy log std Mean          -0.44627246
Policy log std Std           0.24057874
Policy log std Max           -0.107094675
Policy log std Min           -1.9801906
Z mean eval                  1.9023939
Z variance eval              0.015818728
total_rewards                [5469.7053899  5304.34691067 5318.87198343 5273.46485828 5475.76758404
 5335.37818025 5353.28994653 5586.96660554 5378.88940983 5557.66317237]
total_rewards_mean           5405.4344040848255
total_rewards_std            104.24217215954204
total_rewards_max            5586.966605542253
total_rewards_min            5273.464858280324
Number of train steps total  176000
Number of env steps total    530000
Number of rollouts total     0
Train Time (s)               143.06550880009308
(Previous) Eval Time (s)     17.937850577756763
Sample Time (s)              6.5041520041413605
Epoch Time (s)               167.5075113819912
Total Train Time (s)         7387.733203678392
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:56:46.243860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #43 | Epoch Duration: 167.59194827079773
2020-01-12 09:56:46.244029 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9012167
Z variance train             0.015815016
KL Divergence                33.998493
KL Loss                      3.3998494
QF Loss                      239.00424
VF Loss                      67.562
Policy Loss                  -843.2859
Q Predictions Mean           835.68353
Q Predictions Std            768.2106
Q Predictions Max            2215.9426
Q Predictions Min            -88.108795
V Predictions Mean           846.5725
V Predictions Std            770.4154
V Predictions Max            2201.6748
V Predictions Min            -65.46102
Log Pis Mean                 -1.4238472
Log Pis Std                  3.4480162
Log Pis Max                  12.307868
Log Pis Min                  -7.2456417
Policy mu Mean               -0.060283113
Policy mu Std                0.7465031
Policy mu Max                2.421081
Policy mu Min                -2.3180935
Policy log std Mean          -0.45589724
Policy log std Std           0.21825029
Policy log std Max           -0.09982677
Policy log std Min           -2.124179
Z mean eval                  1.9076974
Z variance eval              0.04037873
total_rewards                [5442.26682282 5653.77333504 5710.47590112 5433.29131856 5687.16211155
 5542.57404424 5823.81447824 5477.79926265 5558.08626691 5659.14061679]
total_rewards_mean           5598.838415792896
total_rewards_std            122.03681071785272
total_rewards_max            5823.814478235809
total_rewards_min            5433.291318557084
Number of train steps total  180000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               142.94119915133342
(Previous) Eval Time (s)     17.483790965750813
Sample Time (s)              6.430965636391193
Epoch Time (s)               166.85595575347543
Total Train Time (s)         7554.683714353014
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 09:59:33.196329 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #44 | Epoch Duration: 166.95216512680054
2020-01-12 09:59:33.196519 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9086632
Z variance train             0.04029987
KL Divergence                33.183628
KL Loss                      3.318363
QF Loss                      304.98355
VF Loss                      73.066986
Policy Loss                  -791.1003
Q Predictions Mean           780.9748
Q Predictions Std            736.90955
Q Predictions Max            2218.1575
Q Predictions Min            -55.744564
V Predictions Mean           789.50476
V Predictions Std            740.0092
V Predictions Max            2206.0757
V Predictions Min            -64.38012
Log Pis Mean                 -1.5340321
Log Pis Std                  3.1847403
Log Pis Max                  8.749015
Log Pis Min                  -7.5470295
Policy mu Mean               0.054742172
Policy mu Std                0.72062105
Policy mu Max                2.8809147
Policy mu Min                -2.7458968
Policy log std Mean          -0.44299898
Policy log std Std           0.23286764
Policy log std Max           0.025168508
Policy log std Min           -2.0386028
Z mean eval                  1.8513556
Z variance eval              0.012730596
total_rewards                [5397.40525502 5370.16353743 5364.22663627 5264.2891714  5653.57532821
 5398.2987839  5505.47656431 5374.14392836 5670.40702041 5507.41517989]
total_rewards_mean           5450.540140520181
total_rewards_std            124.82235879247052
total_rewards_max            5670.407020414031
total_rewards_min            5264.28917139838
Number of train steps total  184000
Number of env steps total    554000
Number of rollouts total     0
Train Time (s)               144.12949279602617
(Previous) Eval Time (s)     17.7068201857619
Sample Time (s)              6.705497145652771
Epoch Time (s)               168.54181012744084
Total Train Time (s)         7723.308288410772
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:02:21.822865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #45 | Epoch Duration: 168.62620306015015
2020-01-12 10:02:21.823058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8514168
Z variance train             0.01271406
KL Divergence                33.495567
KL Loss                      3.3495567
QF Loss                      798.3193
VF Loss                      116.25695
Policy Loss                  -747.9724
Q Predictions Mean           744.17285
Q Predictions Std            755.35126
Q Predictions Max            2231.7295
Q Predictions Min            -56.000004
V Predictions Mean           747.9063
V Predictions Std            757.167
V Predictions Max            2235.5469
V Predictions Min            -54.767166
Log Pis Mean                 -1.1282357
Log Pis Std                  4.2470374
Log Pis Max                  23.090826
Log Pis Min                  -6.331657
Policy mu Mean               -0.06748571
Policy mu Std                0.8153058
Policy mu Max                4.0017395
Policy mu Min                -3.435657
Policy log std Mean          -0.43858957
Policy log std Std           0.21946585
Policy log std Max           -0.10813171
Policy log std Min           -2.1583917
Z mean eval                  1.8712082
Z variance eval              0.011885815
total_rewards                [5748.18982476 5783.06332014 5801.04602692 5645.08982198 5912.64965793
 5446.26334313 5708.11983901 5468.15816221 5646.84801799 5877.33752092]
total_rewards_mean           5703.6765534995375
total_rewards_std            148.3254860848242
total_rewards_max            5912.649657928322
total_rewards_min            5446.263343130335
Number of train steps total  188000
Number of env steps total    566000
Number of rollouts total     0
Train Time (s)               143.74878730112687
(Previous) Eval Time (s)     20.993784388992935
Sample Time (s)              6.59814507747069
Epoch Time (s)               171.3407167675905
Total Train Time (s)         7894.73615465872
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:05:13.254833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #46 | Epoch Duration: 171.43160009384155
2020-01-12 10:05:13.255145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #46 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8703245
Z variance train             0.01186792
KL Divergence                34.213387
KL Loss                      3.4213388
QF Loss                      263.79547
VF Loss                      90.35279
Policy Loss                  -792.53284
Q Predictions Mean           786.1685
Q Predictions Std            775.6831
Q Predictions Max            2308.4768
Q Predictions Min            -65.19418
V Predictions Mean           792.46094
V Predictions Std            777.14966
V Predictions Max            2282.9478
V Predictions Min            -66.33347
Log Pis Mean                 -1.6301293
Log Pis Std                  3.3078823
Log Pis Max                  11.368031
Log Pis Min                  -6.164665
Policy mu Mean               -0.054120336
Policy mu Std                0.69927406
Policy mu Max                2.808352
Policy mu Min                -2.4019203
Policy log std Mean          -0.45429122
Policy log std Std           0.2128615
Policy log std Max           -0.102273166
Policy log std Min           -1.7564662
Z mean eval                  1.8721428
Z variance eval              0.014268237
total_rewards                [5837.07552907 5850.41816961 5685.3987722  5558.38789608 5695.0855481
 5829.82082335 5717.63035447 5645.28799124 5734.21405516 5902.26022629]
total_rewards_mean           5745.557936558669
total_rewards_std            101.58193069532491
total_rewards_max            5902.260226291442
total_rewards_min            5558.387896084663
Number of train steps total  192000
Number of env steps total    578000
Number of rollouts total     0
Train Time (s)               143.50604869890958
(Previous) Eval Time (s)     17.73321666009724
Sample Time (s)              6.572123273741454
Epoch Time (s)               167.81138863274828
Total Train Time (s)         8062.632033065893
Epoch                        47
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:08:01.153273 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #47 | Epoch Duration: 167.8978705406189
2020-01-12 10:08:01.153607 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8735416
Z variance train             0.014314108
KL Divergence                34.210564
KL Loss                      3.4210565
QF Loss                      250.75179
VF Loss                      230.21744
Policy Loss                  -805.6316
Q Predictions Mean           799.13165
Q Predictions Std            794.46466
Q Predictions Max            2305.2632
Q Predictions Min            -59.250427
V Predictions Mean           798.6417
V Predictions Std            790.8266
V Predictions Max            2299.6558
V Predictions Min            -62.800117
Log Pis Mean                 -1.2670431
Log Pis Std                  3.7135718
Log Pis Max                  17.32623
Log Pis Min                  -6.441077
Policy mu Mean               -0.04691881
Policy mu Std                0.77236515
Policy mu Max                3.768476
Policy mu Min                -3.090287
Policy log std Mean          -0.46376157
Policy log std Std           0.24075274
Policy log std Max           -0.093961075
Policy log std Min           -2.1406426
Z mean eval                  1.9214566
Z variance eval              0.011791075
total_rewards                [5758.43177881 5669.22291618 5656.82555825 5533.6128064  5626.79835746
 5670.77350392 5878.66056699 5648.72597391 5743.69573581 5940.92112123]
total_rewards_mean           5712.7668318967935
total_rewards_std            115.32298504122477
total_rewards_max            5940.921121234132
total_rewards_min            5533.612806399934
Number of train steps total  196000
Number of env steps total    590000
Number of rollouts total     0
Train Time (s)               143.26335357129574
(Previous) Eval Time (s)     17.49813678022474
Sample Time (s)              6.509714362677187
Epoch Time (s)               167.27120471419767
Total Train Time (s)         8230.244601687416
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:10:48.769858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #48 | Epoch Duration: 167.6159737110138
2020-01-12 10:10:48.770176 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9220638
Z variance train             0.0117493365
KL Divergence                35.493843
KL Loss                      3.5493844
QF Loss                      172.55757
VF Loss                      130.18073
Policy Loss                  -838.7869
Q Predictions Mean           827.76196
Q Predictions Std            800.6093
Q Predictions Max            2316.8987
Q Predictions Min            -76.63891
V Predictions Mean           834.1653
V Predictions Std            798.9641
V Predictions Max            2306.9578
V Predictions Min            -60.37817
Log Pis Mean                 -1.3084625
Log Pis Std                  3.254869
Log Pis Max                  14.246044
Log Pis Min                  -8.17382
Policy mu Mean               -0.006135013
Policy mu Std                0.763452
Policy mu Max                3.1488557
Policy mu Min                -2.7901874
Policy log std Mean          -0.4522685
Policy log std Std           0.23155563
Policy log std Max           -0.16862334
Policy log std Min           -1.8720639
Z mean eval                  1.8891805
Z variance eval              0.026165362
total_rewards                [5804.44341711 5732.65804189 5751.82011639 5854.74367568 5720.83650314
 5904.0218234  5779.60885161 5630.85105581 5485.92094092 5787.32155007]
total_rewards_mean           5745.22259760217
total_rewards_std            111.7086290452769
total_rewards_max            5904.021823400131
total_rewards_min            5485.920940919257
Number of train steps total  200000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               143.59499228699133
(Previous) Eval Time (s)     20.5200759540312
Sample Time (s)              6.3855237369425595
Epoch Time (s)               170.5005919779651
Total Train Time (s)         8400.834318274632
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:13:39.354457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #49 | Epoch Duration: 170.58405089378357
2020-01-12 10:13:39.354586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #49 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8877255
Z variance train             0.026143441
KL Divergence                34.261887
KL Loss                      3.4261887
QF Loss                      151.47
VF Loss                      74.689224
Policy Loss                  -777.18005
Q Predictions Mean           769.6283
Q Predictions Std            770.9103
Q Predictions Max            2333.2605
Q Predictions Min            -62.803467
V Predictions Mean           777.297
V Predictions Std            773.03485
V Predictions Max            2328.6194
V Predictions Min            -62.887608
Log Pis Mean                 -1.529425
Log Pis Std                  3.6031268
Log Pis Max                  17.604313
Log Pis Min                  -7.6806536
Policy mu Mean               -0.06453533
Policy mu Std                0.7351338
Policy mu Max                3.340883
Policy mu Min                -3.248255
Policy log std Mean          -0.4403194
Policy log std Std           0.219875
Policy log std Max           -0.12182957
Policy log std Min           -1.9094846
Z mean eval                  1.8983333
Z variance eval              0.03466819
total_rewards                [5956.75127262 1699.77521269 5811.72847505 5773.0327818  5821.3959483
 5721.56651624 5658.80711247 5837.42073997 6047.07290058 5953.67949323]
total_rewards_mean           5428.1230452949185
total_rewards_std            1247.6763245181592
total_rewards_max            6047.072900581278
total_rewards_min            1699.775212686662
Number of train steps total  204000
Number of env steps total    614000
Number of rollouts total     0
Train Time (s)               143.0922031570226
(Previous) Eval Time (s)     17.62692299997434
Sample Time (s)              6.368096839636564
Epoch Time (s)               167.0872229966335
Total Train Time (s)         8567.995984552428
Epoch                        50
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:16:26.516928 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #50 | Epoch Duration: 167.16224241256714
2020-01-12 10:16:26.517052 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8970093
Z variance train             0.03462486
KL Divergence                32.347282
KL Loss                      3.2347283
QF Loss                      238.3025
VF Loss                      70.43088
Policy Loss                  -772.3433
Q Predictions Mean           762.6304
Q Predictions Std            776.8947
Q Predictions Max            2348.6226
Q Predictions Min            -78.86066
V Predictions Mean           768.6371
V Predictions Std            777.508
V Predictions Max            2334.2148
V Predictions Min            -67.32561
Log Pis Mean                 -1.4217439
Log Pis Std                  3.4403946
Log Pis Max                  17.663092
Log Pis Min                  -6.4747696
Policy mu Mean               -0.006363314
Policy mu Std                0.7322028
Policy mu Max                2.9210782
Policy mu Min                -3.011281
Policy log std Mean          -0.4603014
Policy log std Std           0.23135853
Policy log std Max           -0.1317612
Policy log std Min           -2.0758135
Z mean eval                  1.8859174
Z variance eval              0.028622497
total_rewards                [5676.73303539 6136.70675763 5807.77601871 5843.73649974 5867.46245166
 5539.20326202 5775.14656404 5625.9146136  5841.53958546 5851.46430082]
total_rewards_mean           5796.5683089078075
total_rewards_std            154.36496215590952
total_rewards_max            6136.7067576262425
total_rewards_min            5539.203262022167
Number of train steps total  208000
Number of env steps total    626000
Number of rollouts total     0
Train Time (s)               140.98946531908587
(Previous) Eval Time (s)     20.95800048438832
Sample Time (s)              5.5577001688070595
Epoch Time (s)               167.50516597228125
Total Train Time (s)         8735.581801717635
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:19:14.104274 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #51 | Epoch Duration: 167.58712887763977
2020-01-12 10:19:14.104404 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8855245
Z variance train             0.02874494
KL Divergence                32.242107
KL Loss                      3.2242107
QF Loss                      415.83487
VF Loss                      130.15628
Policy Loss                  -863.2267
Q Predictions Mean           851.42523
Q Predictions Std            818.6352
Q Predictions Max            2347.273
Q Predictions Min            -71.14651
V Predictions Mean           862.005
V Predictions Std            818.00867
V Predictions Max            2336.8342
V Predictions Min            -59.318924
Log Pis Mean                 -1.0537436
Log Pis Std                  3.5502145
Log Pis Max                  16.264355
Log Pis Min                  -6.4583836
Policy mu Mean               -0.0024442847
Policy mu Std                0.7759726
Policy mu Max                2.6581337
Policy mu Min                -3.0068195
Policy log std Mean          -0.46276775
Policy log std Std           0.22981273
Policy log std Max           -0.11840966
Policy log std Min           -1.8850093
Z mean eval                  1.8791876
Z variance eval              0.05245585
total_rewards                [5647.46107092 5810.82622592 5733.83735299 5746.90792243 5470.40518885
 5541.54561808 5705.30807394 5811.23556752 5796.46995441 5680.22718485]
total_rewards_mean           5694.422415992133
total_rewards_std            108.62666732609759
total_rewards_max            5811.235567519679
total_rewards_min            5470.405188848102
Number of train steps total  212000
Number of env steps total    638000
Number of rollouts total     0
Train Time (s)               142.00966284796596
(Previous) Eval Time (s)     17.656149435788393
Sample Time (s)              6.600771842524409
Epoch Time (s)               166.26658412627876
Total Train Time (s)         8901.922805187758
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:22:00.445970 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #52 | Epoch Duration: 166.34147119522095
2020-01-12 10:22:00.446101 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8796126
Z variance train             0.05281351
KL Divergence                31.209103
KL Loss                      3.1209104
QF Loss                      385.22107
VF Loss                      154.79964
Policy Loss                  -882.1649
Q Predictions Mean           876.24396
Q Predictions Std            834.06836
Q Predictions Max            2412.9082
Q Predictions Min            -84.228714
V Predictions Mean           882.1519
V Predictions Std            831.72
V Predictions Max            2375.1313
V Predictions Min            -62.908863
Log Pis Mean                 -1.2079711
Log Pis Std                  3.4926126
Log Pis Max                  14.1277485
Log Pis Min                  -7.2336392
Policy mu Mean               -0.08577788
Policy mu Std                0.7572583
Policy mu Max                3.0300536
Policy mu Min                -2.4278972
Policy log std Mean          -0.45907047
Policy log std Std           0.22877806
Policy log std Max           -0.13666219
Policy log std Min           -2.0360932
Z mean eval                  1.8759577
Z variance eval              0.019643849
total_rewards                [6015.20083317 5955.70823263 6288.19307968 6084.16033687 6059.58445514
 6035.6238619  5759.36011688 6073.98305983 6069.37890615 6141.730862  ]
total_rewards_mean           6048.29237442458
total_rewards_std            127.32281349773167
total_rewards_max            6288.193079683072
total_rewards_min            5759.360116880512
Number of train steps total  216000
Number of env steps total    650000
Number of rollouts total     0
Train Time (s)               141.87324781576172
(Previous) Eval Time (s)     17.40392248891294
Sample Time (s)              5.383260604459792
Epoch Time (s)               164.66043090913445
Total Train Time (s)         9066.660925125703
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:24:45.188692 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #53 | Epoch Duration: 164.7424509525299
2020-01-12 10:24:45.188985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8752245
Z variance train             0.019695168
KL Divergence                32.45962
KL Loss                      3.2459621
QF Loss                      526.9427
VF Loss                      115.280945
Policy Loss                  -811.3098
Q Predictions Mean           811.2045
Q Predictions Std            791.34064
Q Predictions Max            2404.5454
Q Predictions Min            -61.525093
V Predictions Mean           804.0415
V Predictions Std            792.68384
V Predictions Max            2385.5576
V Predictions Min            -67.08904
Log Pis Mean                 -1.5077579
Log Pis Std                  3.3026364
Log Pis Max                  13.840845
Log Pis Min                  -7.509549
Policy mu Mean               -0.024167174
Policy mu Std                0.7159687
Policy mu Max                2.6582415
Policy mu Min                -2.9119568
Policy log std Mean          -0.4569099
Policy log std Std           0.249724
Policy log std Max           -0.0557594
Policy log std Min           -1.894979
Z mean eval                  1.8687963
Z variance eval              0.017156215
total_rewards                [6094.39871867 5967.25560032 6261.16660472 6233.36304866 6028.57398998
 6022.62935986 6103.81386295 6172.3787617  6170.77288427 5944.30641934]
total_rewards_mean           6099.865925047094
total_rewards_std            103.44228401755637
total_rewards_max            6261.166604715957
total_rewards_min            5944.306419342358
Number of train steps total  220000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               142.35266576800495
(Previous) Eval Time (s)     17.484444808214903
Sample Time (s)              5.55425452394411
Epoch Time (s)               165.39136510016397
Total Train Time (s)         9232.132719982881
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:27:30.659787 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #54 | Epoch Duration: 165.47057723999023
2020-01-12 10:27:30.659960 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8665617
Z variance train             0.017196361
KL Divergence                32.11814
KL Loss                      3.2118142
QF Loss                      869.615
VF Loss                      83.93859
Policy Loss                  -813.8923
Q Predictions Mean           803.3523
Q Predictions Std            800.8981
Q Predictions Max            2377.5645
Q Predictions Min            -71.04194
V Predictions Mean           811.28357
V Predictions Std            798.81366
V Predictions Max            2362.3835
V Predictions Min            -65.080826
Log Pis Mean                 -1.5664377
Log Pis Std                  3.0562074
Log Pis Max                  9.094181
Log Pis Min                  -6.759577
Policy mu Mean               0.015075472
Policy mu Std                0.71984273
Policy mu Max                2.4889178
Policy mu Min                -3.2864187
Policy log std Mean          -0.4525486
Policy log std Std           0.23027934
Policy log std Max           0.08763325
Policy log std Min           -2.2802095
Z mean eval                  1.9073509
Z variance eval              0.021411065
total_rewards                [5741.54867847 5813.77340642 5757.02317438 5874.51514773 6029.57331223
 5817.32682192 5908.44064017 5899.13547085 5813.33301009 5800.32795427]
total_rewards_mean           5845.499761652221
total_rewards_std            80.66765806150396
total_rewards_max            6029.573312234016
total_rewards_min            5741.5486784674285
Number of train steps total  224000
Number of env steps total    674000
Number of rollouts total     0
Train Time (s)               142.24116083234549
(Previous) Eval Time (s)     17.85305330483243
Sample Time (s)              5.736719515640289
Epoch Time (s)               165.8309336528182
Total Train Time (s)         9398.095145242289
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:30:16.627333 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #55 | Epoch Duration: 165.96720552444458
2020-01-12 10:30:16.627640 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9079523
Z variance train             0.021327242
KL Divergence                32.34118
KL Loss                      3.234118
QF Loss                      297.69354
VF Loss                      109.85297
Policy Loss                  -807.7722
Q Predictions Mean           798.99347
Q Predictions Std            800.4997
Q Predictions Max            2510.236
Q Predictions Min            -66.91797
V Predictions Mean           806.35175
V Predictions Std            800.03674
V Predictions Max            2516.539
V Predictions Min            -79.96045
Log Pis Mean                 -1.3187336
Log Pis Std                  3.8927338
Log Pis Max                  22.023584
Log Pis Min                  -7.100261
Policy mu Mean               -0.07080189
Policy mu Std                0.75371224
Policy mu Max                3.4942703
Policy mu Min                -3.4144812
Policy log std Mean          -0.44200215
Policy log std Std           0.22220433
Policy log std Max           -0.018855155
Policy log std Min           -2.0377605
Z mean eval                  1.9003198
Z variance eval              0.016185593
total_rewards                [5750.16359294 5929.24298895 6083.53535391 6139.56655124 5960.96412124
 6082.23952813 5974.01794056 6103.08198822 6121.9520657  6022.24441339]
total_rewards_mean           6016.700854428677
total_rewards_std            112.27101178876529
total_rewards_max            6139.566551243188
total_rewards_min            5750.16359293663
Number of train steps total  228000
Number of env steps total    686000
Number of rollouts total     0
Train Time (s)               143.50717155635357
(Previous) Eval Time (s)     18.054022955708206
Sample Time (s)              6.491305843926966
Epoch Time (s)               168.05250035598874
Total Train Time (s)         9566.24206357263
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:33:04.774475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #56 | Epoch Duration: 168.14661693572998
2020-01-12 10:33:04.774687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.899774
Z variance train             0.0162099
KL Divergence                34.23713
KL Loss                      3.423713
QF Loss                      760.7185
VF Loss                      149.54698
Policy Loss                  -861.9661
Q Predictions Mean           856.6144
Q Predictions Std            815.158
Q Predictions Max            2397.2427
Q Predictions Min            -80.41623
V Predictions Mean           870.09296
V Predictions Std            822.50336
V Predictions Max            2416.4675
V Predictions Min            -74.714424
Log Pis Mean                 -1.0770266
Log Pis Std                  3.4037735
Log Pis Max                  10.692542
Log Pis Min                  -7.0710588
Policy mu Mean               -0.023240903
Policy mu Std                0.77144516
Policy mu Max                2.6875458
Policy mu Min                -2.5628715
Policy log std Mean          -0.47222805
Policy log std Std           0.23849125
Policy log std Max           0.012934864
Policy log std Min           -2.3637486
Z mean eval                  1.8927075
Z variance eval              0.019894749
total_rewards                [6191.0840435  6433.2354981  6277.76043254 6195.72947268 6201.78595471
 6217.14165692 5986.72057399 6357.57680424 5997.79880047 6169.75077874]
total_rewards_mean           6202.858401589968
total_rewards_std            131.482865362053
total_rewards_max            6433.235498098495
total_rewards_min            5986.720573989353
Number of train steps total  232000
Number of env steps total    698000
Number of rollouts total     0
Train Time (s)               143.93344952864572
(Previous) Eval Time (s)     17.77554969023913
Sample Time (s)              6.518613598309457
Epoch Time (s)               168.2276128171943
Total Train Time (s)         9734.555853433907
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:35:53.088547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #57 | Epoch Duration: 168.31372570991516
2020-01-12 10:35:53.088678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8901827
Z variance train             0.019898092
KL Divergence                32.486
KL Loss                      3.2486
QF Loss                      201.25052
VF Loss                      170.5032
Policy Loss                  -729.086
Q Predictions Mean           722.7387
Q Predictions Std            750.1167
Q Predictions Max            2387.3716
Q Predictions Min            -77.74265
V Predictions Mean           729.80115
V Predictions Std            753.97125
V Predictions Max            2400.3093
V Predictions Min            -66.036446
Log Pis Mean                 -1.4717016
Log Pis Std                  3.694242
Log Pis Max                  19.116325
Log Pis Min                  -9.39739
Policy mu Mean               -0.07228136
Policy mu Std                0.73850834
Policy mu Max                2.7865067
Policy mu Min                -4.252967
Policy log std Mean          -0.44299603
Policy log std Std           0.227759
Policy log std Max           -0.08598387
Policy log std Min           -2.3459992
Z mean eval                  1.9252005
Z variance eval              0.017758148
total_rewards                [6232.47442118 6549.95927191 6500.69857661 6588.60745011 6357.09258942
 6555.11790968 6294.38454278 6280.46786495 6426.14816771 6524.62318688]
total_rewards_mean           6430.957398123196
total_rewards_std            124.19412411897807
total_rewards_max            6588.607450106943
total_rewards_min            6232.474421177899
Number of train steps total  236000
Number of env steps total    710000
Number of rollouts total     0
Train Time (s)               143.56845584418625
(Previous) Eval Time (s)     17.46554338792339
Sample Time (s)              6.655137183144689
Epoch Time (s)               167.68913641525432
Total Train Time (s)         9902.323139491957
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:38:40.857938 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #58 | Epoch Duration: 167.76915979385376
2020-01-12 10:38:40.858095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9256147
Z variance train             0.017781407
KL Divergence                33.81601
KL Loss                      3.381601
QF Loss                      525.77045
VF Loss                      149.92085
Policy Loss                  -814.11053
Q Predictions Mean           808.9618
Q Predictions Std            809.64166
Q Predictions Max            2519.901
Q Predictions Min            -87.74165
V Predictions Mean           820.72473
V Predictions Std            811.73755
V Predictions Max            2493.5474
V Predictions Min            -75.8555
Log Pis Mean                 -1.1665244
Log Pis Std                  3.6893735
Log Pis Max                  16.430046
Log Pis Min                  -6.7211456
Policy mu Mean               -0.019803995
Policy mu Std                0.79165024
Policy mu Max                2.987426
Policy mu Min                -3.812008
Policy log std Mean          -0.44716606
Policy log std Std           0.22465664
Policy log std Max           -0.1455696
Policy log std Min           -2.0556123
Z mean eval                  1.8994443
Z variance eval              0.018577283
total_rewards                [6179.69659985 5839.93603208 6391.65903948 5682.45034428 5821.75260873
 1956.58622205 2033.34338564 5768.90171347 6056.36358283 4626.18300337]
total_rewards_mean           5035.68725317783
total_rewards_std            1583.4280347477397
total_rewards_max            6391.659039478091
total_rewards_min            1956.5862220484519
Number of train steps total  240000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               145.5277861300856
(Previous) Eval Time (s)     20.940628021024168
Sample Time (s)              5.603038269560784
Epoch Time (s)               172.07145242067054
Total Train Time (s)         10074.489447663072
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:41:33.028203 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #59 | Epoch Duration: 172.16996479034424
2020-01-12 10:41:33.028406 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8970039
Z variance train             0.018603487
KL Divergence                33.86045
KL Loss                      3.3860452
QF Loss                      277.7254
VF Loss                      156.77536
Policy Loss                  -762.06647
Q Predictions Mean           757.0532
Q Predictions Std            789.22504
Q Predictions Max            2477.9065
Q Predictions Min            -87.934555
V Predictions Mean           764.00836
V Predictions Std            793.2942
V Predictions Max            2478.8623
V Predictions Min            -81.49993
Log Pis Mean                 -1.3691115
Log Pis Std                  3.4341438
Log Pis Max                  15.413858
Log Pis Min                  -6.8653936
Policy mu Mean               0.022725277
Policy mu Std                0.7350813
Policy mu Max                2.6911309
Policy mu Min                -2.8846364
Policy log std Mean          -0.45042458
Policy log std Std           0.25385845
Policy log std Max           -0.12046051
Policy log std Min           -2.128117
Z mean eval                  1.9029392
Z variance eval              0.017013725
total_rewards                [6235.91544582 6504.20496221 6375.14782225 6369.74126573 6166.15508737
 6293.38570539 6328.76199036 6102.2269525  6278.81708252 6292.63418005]
total_rewards_mean           6294.699049421808
total_rewards_std            106.97623403139809
total_rewards_max            6504.204962212936
total_rewards_min            6102.226952496244
Number of train steps total  244000
Number of env steps total    734000
Number of rollouts total     0
Train Time (s)               143.45485528977588
(Previous) Eval Time (s)     20.97137754689902
Sample Time (s)              6.665078236721456
Epoch Time (s)               171.09131107339635
Total Train Time (s)         10245.667335619219
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:44:24.205399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #60 | Epoch Duration: 171.1768479347229
2020-01-12 10:44:24.205541 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9049244
Z variance train             0.01703859
KL Divergence                34.448112
KL Loss                      3.4448113
QF Loss                      219.80353
VF Loss                      65.774864
Policy Loss                  -732.9619
Q Predictions Mean           726.8058
Q Predictions Std            778.2118
Q Predictions Max            2483.9985
Q Predictions Min            -86.07766
V Predictions Mean           737.10645
V Predictions Std            781.17474
V Predictions Max            2484.1135
V Predictions Min            -75.22249
Log Pis Mean                 -1.8051128
Log Pis Std                  3.3693051
Log Pis Max                  11.850742
Log Pis Min                  -7.1885705
Policy mu Mean               -0.08657376
Policy mu Std                0.6796428
Policy mu Max                2.5687294
Policy mu Min                -2.6017447
Policy log std Mean          -0.4360343
Policy log std Std           0.22039998
Policy log std Max           -0.1517443
Policy log std Min           -1.8560152
Z mean eval                  1.8915558
Z variance eval              0.00734269
total_rewards                [6068.06574159 6378.23425657 6509.98468874 6065.62202989 6396.45389856
 6312.56601133 6358.0875473  6079.8965333  6382.86058413 6461.07551483]
total_rewards_mean           6301.2846806235775
total_rewards_std            159.0648778764951
total_rewards_max            6509.984688743908
total_rewards_min            6065.622029885062
Number of train steps total  248000
Number of env steps total    746000
Number of rollouts total     0
Train Time (s)               142.75785920303315
(Previous) Eval Time (s)     18.127722821664065
Sample Time (s)              6.582495357375592
Epoch Time (s)               167.4680773820728
Total Train Time (s)         10413.215161677916
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:47:11.758573 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #61 | Epoch Duration: 167.55288290977478
2020-01-12 10:47:11.758931 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8889208
Z variance train             0.0073339297
KL Divergence                35.53086
KL Loss                      3.553086
QF Loss                      297.96295
VF Loss                      41.249165
Policy Loss                  -705.5631
Q Predictions Mean           701.0416
Q Predictions Std            779.5128
Q Predictions Max            2433.4177
Q Predictions Min            -101.09969
V Predictions Mean           707.49475
V Predictions Std            783.0013
V Predictions Max            2422.8987
V Predictions Min            -79.826675
Log Pis Mean                 -1.7390406
Log Pis Std                  3.130801
Log Pis Max                  9.510326
Log Pis Min                  -6.8319407
Policy mu Mean               -0.051184982
Policy mu Std                0.6825109
Policy mu Max                2.7602153
Policy mu Min                -2.834474
Policy log std Mean          -0.42968836
Policy log std Std           0.23661794
Policy log std Max           -0.10862002
Policy log std Min           -2.1391056
Z mean eval                  1.9061356
Z variance eval              0.010682837
total_rewards                [6578.70640839 6296.01658627 6647.87899137 6412.69145483 6621.60786681
 6539.4973007  6904.93949966 6519.23629678 6655.26221568 6670.42525279]
total_rewards_mean           6584.626187329445
total_rewards_std            154.76584250645024
total_rewards_max            6904.9394996624
total_rewards_min            6296.016586272183
Number of train steps total  252000
Number of env steps total    758000
Number of rollouts total     0
Train Time (s)               144.06320699770004
(Previous) Eval Time (s)     21.253501236904413
Sample Time (s)              6.580273406114429
Epoch Time (s)               171.89698164071888
Total Train Time (s)         10585.197605942376
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:50:03.739242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #62 | Epoch Duration: 171.9801001548767
2020-01-12 10:50:03.739375 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9030536
Z variance train             0.010661701
KL Divergence                34.51133
KL Loss                      3.451133
QF Loss                      533.4357
VF Loss                      224.12732
Policy Loss                  -799.53485
Q Predictions Mean           795.2047
Q Predictions Std            836.0689
Q Predictions Max            2506.205
Q Predictions Min            -91.86117
V Predictions Mean           804.6668
V Predictions Std            837.33856
V Predictions Max            2508.2083
V Predictions Min            -87.94418
Log Pis Mean                 -1.0170063
Log Pis Std                  3.7692072
Log Pis Max                  15.681114
Log Pis Min                  -6.8727045
Policy mu Mean               -0.02965185
Policy mu Std                0.79105115
Policy mu Max                2.8841016
Policy mu Min                -3.410555
Policy log std Mean          -0.46799955
Policy log std Std           0.25324714
Policy log std Max           -0.16248855
Policy log std Min           -2.387453
Z mean eval                  1.8945932
Z variance eval              0.034098804
total_rewards                [6133.88904043 6035.04528481 5973.69116365 6196.54693396 6231.14843161
 6126.38545327 6229.95174404 6051.97928623 6301.1612887  6305.07116501]
total_rewards_mean           6158.486979171353
total_rewards_std            107.72425081504889
total_rewards_max            6305.071165012144
total_rewards_min            5973.691163654465
Number of train steps total  256000
Number of env steps total    770000
Number of rollouts total     0
Train Time (s)               143.02481592819095
(Previous) Eval Time (s)     21.04295474709943
Sample Time (s)              6.429969357326627
Epoch Time (s)               170.497740032617
Total Train Time (s)         10755.776366087608
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:52:54.318784 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #63 | Epoch Duration: 170.5793161392212
2020-01-12 10:52:54.318916 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8936714
Z variance train             0.03406387
KL Divergence                33.081333
KL Loss                      3.3081334
QF Loss                      395.1482
VF Loss                      165.02176
Policy Loss                  -799.7164
Q Predictions Mean           795.4488
Q Predictions Std            812.8137
Q Predictions Max            2613.428
Q Predictions Min            -78.51393
V Predictions Mean           806.78406
V Predictions Std            818.95404
V Predictions Max            2627.4404
V Predictions Min            -75.4325
Log Pis Mean                 -1.3049312
Log Pis Std                  3.3859644
Log Pis Max                  13.0040455
Log Pis Min                  -8.009828
Policy mu Mean               -0.088264674
Policy mu Std                0.7270105
Policy mu Max                2.7207222
Policy mu Min                -2.8013778
Policy log std Mean          -0.47342777
Policy log std Std           0.23787615
Policy log std Max           0.15596122
Policy log std Min           -2.1306317
Z mean eval                  1.8937544
Z variance eval              0.032910757
total_rewards                [6250.30204844 6413.6037487  6319.19397326 6223.21864185 6300.58138456
 5993.63460393 3371.53694921 6087.01571336 6279.91245524 6478.31883729]
total_rewards_mean           5971.73183558147
total_rewards_std            877.0039317627335
total_rewards_max            6478.318837287303
total_rewards_min            3371.536949209729
Number of train steps total  260000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               143.5806488879025
(Previous) Eval Time (s)     17.724546923767775
Sample Time (s)              6.459860369563103
Epoch Time (s)               167.76505618123338
Total Train Time (s)         10923.619017035235
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:55:42.162398 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #64 | Epoch Duration: 167.84338545799255
2020-01-12 10:55:42.162525 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8933146
Z variance train             0.03284865
KL Divergence                32.189735
KL Loss                      3.2189736
QF Loss                      363.97015
VF Loss                      155.22108
Policy Loss                  -696.5318
Q Predictions Mean           687.1306
Q Predictions Std            756.49896
Q Predictions Max            2562.2593
Q Predictions Min            -81.04364
V Predictions Mean           690.20874
V Predictions Std            759.4493
V Predictions Max            2555.3967
V Predictions Min            -85.60551
Log Pis Mean                 -1.6933634
Log Pis Std                  3.1749356
Log Pis Max                  12.735222
Log Pis Min                  -7.0048766
Policy mu Mean               -0.0028704193
Policy mu Std                0.7041377
Policy mu Max                3.1718159
Policy mu Min                -2.75017
Policy log std Mean          -0.4356241
Policy log std Std           0.21560813
Policy log std Max           -0.12779066
Policy log std Min           -1.9995737
Z mean eval                  1.9643263
Z variance eval              0.022422707
total_rewards                [5977.75288021 5776.0160587  6091.82940861 6288.05318071 5442.73526187
 6015.5980252  5741.71791203 6371.27116296 6278.92847887 6200.92333972]
total_rewards_mean           6018.482570889642
total_rewards_std            277.87865088368335
total_rewards_max            6371.271162955752
total_rewards_min            5442.735261869922
Number of train steps total  264000
Number of env steps total    794000
Number of rollouts total     0
Train Time (s)               141.49094415688887
(Previous) Eval Time (s)     17.660015925299376
Sample Time (s)              5.789603969082236
Epoch Time (s)               164.94056405127048
Total Train Time (s)         11088.639404475689
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 10:58:27.184284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #65 | Epoch Duration: 165.02164816856384
2020-01-12 10:58:27.184468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9642954
Z variance train             0.022471158
KL Divergence                34.296085
KL Loss                      3.4296086
QF Loss                      291.7028
VF Loss                      103.977196
Policy Loss                  -949.0619
Q Predictions Mean           940.9956
Q Predictions Std            887.71405
Q Predictions Max            2549.328
Q Predictions Min            -162.05264
V Predictions Mean           947.9253
V Predictions Std            887.99915
V Predictions Max            2527.7844
V Predictions Min            -93.95788
Log Pis Mean                 -0.87396747
Log Pis Std                  3.7186964
Log Pis Max                  16.326746
Log Pis Min                  -6.937147
Policy mu Mean               -0.0649516
Policy mu Std                0.822369
Policy mu Max                2.8577566
Policy mu Min                -3.2507486
Policy log std Mean          -0.46331108
Policy log std Std           0.25006807
Policy log std Max           -0.10547432
Policy log std Min           -2.1765544
Z mean eval                  1.9880623
Z variance eval              0.03057602
total_rewards                [6345.18806998 6759.26481283 6485.74336491 6195.50284021 6494.32211165
 6308.88445132 6364.44003704 6525.45511405 5964.05923242 6543.01058363]
total_rewards_mean           6398.587061803629
total_rewards_std            206.37954910614604
total_rewards_max            6759.2648128317505
total_rewards_min            5964.059232415425
Number of train steps total  268000
Number of env steps total    806000
Number of rollouts total     0
Train Time (s)               146.52034418284893
(Previous) Eval Time (s)     21.061013142578304
Sample Time (s)              6.558749390300363
Epoch Time (s)               174.1401067157276
Total Train Time (s)         11262.86058436893
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:01:21.408485 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #66 | Epoch Duration: 174.22382760047913
2020-01-12 11:01:21.408766 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9883578
Z variance train             0.03069983
KL Divergence                33.835472
KL Loss                      3.3835473
QF Loss                      196.62027
VF Loss                      93.62791
Policy Loss                  -756.3074
Q Predictions Mean           747.1897
Q Predictions Std            816.43384
Q Predictions Max            2587.6973
Q Predictions Min            -98.25599
V Predictions Mean           755.411
V Predictions Std            815.61005
V Predictions Max            2590.9146
V Predictions Min            -88.82018
Log Pis Mean                 -1.4048967
Log Pis Std                  3.482192
Log Pis Max                  14.167569
Log Pis Min                  -7.397729
Policy mu Mean               -0.068553604
Policy mu Std                0.76549387
Policy mu Max                2.773866
Policy mu Min                -2.9150543
Policy log std Mean          -0.45389572
Policy log std Std           0.20155948
Policy log std Max           -0.13707104
Policy log std Min           -1.894566
Z mean eval                  1.9476534
Z variance eval              0.014498072
total_rewards                [6386.06218552 6610.66714922 6554.25947498 6635.7848597  6277.62167439
 6534.4071712  6745.62575103 6625.77416542 6389.38013214 6480.643831  ]
total_rewards_mean           6524.022639459499
total_rewards_std            134.25286961555585
total_rewards_max            6745.625751030121
total_rewards_min            6277.621674385322
Number of train steps total  272000
Number of env steps total    818000
Number of rollouts total     0
Train Time (s)               141.35383306629956
(Previous) Eval Time (s)     17.545340763404965
Sample Time (s)              6.4322752663865685
Epoch Time (s)               165.3314490960911
Total Train Time (s)         11428.276671955828
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:04:06.825150 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #67 | Epoch Duration: 165.4162266254425
2020-01-12 11:04:06.825327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9495026
Z variance train             0.014513129
KL Divergence                33.638863
KL Loss                      3.3638864
QF Loss                      915.3757
VF Loss                      351.93448
Policy Loss                  -750.275
Q Predictions Mean           737.7329
Q Predictions Std            795.73987
Q Predictions Max            2546.1663
Q Predictions Min            -100.23332
V Predictions Mean           738.83435
V Predictions Std            796.2956
V Predictions Max            2540.413
V Predictions Min            -102.630936
Log Pis Mean                 -1.3221571
Log Pis Std                  3.4468234
Log Pis Max                  11.411898
Log Pis Min                  -6.660722
Policy mu Mean               0.0040029823
Policy mu Std                0.7463625
Policy mu Max                3.341102
Policy mu Min                -2.817051
Policy log std Mean          -0.46910104
Policy log std Std           0.22893475
Policy log std Max           -0.1513705
Policy log std Min           -2.0974493
Z mean eval                  1.9117606
Z variance eval              0.012644713
total_rewards                [6577.4481622  6872.44356186 6715.38265195 6774.1481082  6799.72618195
 6848.07878567 6576.24289906 6665.28158713 6660.97311759 6582.46248213]
total_rewards_mean           6707.218753773841
total_rewards_std            106.6307605052656
total_rewards_max            6872.443561857926
total_rewards_min            6576.242899055701
Number of train steps total  276000
Number of env steps total    830000
Number of rollouts total     0
Train Time (s)               141.31493050884455
(Previous) Eval Time (s)     20.594629519153386
Sample Time (s)              6.557933504227549
Epoch Time (s)               168.4674935322255
Total Train Time (s)         11596.825481682085
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:06:55.375746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #68 | Epoch Duration: 168.5502486228943
2020-01-12 11:06:55.375969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090292
Z variance train             0.01264553
KL Divergence                35.250046
KL Loss                      3.5250046
QF Loss                      323.01556
VF Loss                      178.41084
Policy Loss                  -806.95886
Q Predictions Mean           796.4945
Q Predictions Std            864.6997
Q Predictions Max            2598.8525
Q Predictions Min            -95.19227
V Predictions Mean           804.0812
V Predictions Std            868.6486
V Predictions Max            2600.4648
V Predictions Min            -92.77417
Log Pis Mean                 -1.2888842
Log Pis Std                  3.4355826
Log Pis Max                  9.4405
Log Pis Min                  -6.152956
Policy mu Mean               -0.041863292
Policy mu Std                0.75384337
Policy mu Max                2.6645062
Policy mu Min                -2.2961516
Policy log std Mean          -0.46271133
Policy log std Std           0.24614014
Policy log std Max           -0.15886796
Policy log std Min           -2.4293547
Z mean eval                  1.9282405
Z variance eval              0.016464395
total_rewards                [6637.55033879 6557.91798604 6797.8512828  6759.63766126 6682.06115259
 6810.53797496 6825.22869639 6733.06789363 6855.21062553 6619.97016631]
total_rewards_mean           6727.903377831164
total_rewards_std            94.46907897236079
total_rewards_max            6855.210625531985
total_rewards_min            6557.917986040426
Number of train steps total  280000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               142.8911835681647
(Previous) Eval Time (s)     21.060634987894446
Sample Time (s)              6.363416476175189
Epoch Time (s)               170.31523503223434
Total Train Time (s)         11767.224443089683
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:09:45.779470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #69 | Epoch Duration: 170.40337681770325
2020-01-12 11:09:45.779657 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9284779
Z variance train             0.016544286
KL Divergence                34.971523
KL Loss                      3.4971523
QF Loss                      218.70663
VF Loss                      90.274635
Policy Loss                  -730.20276
Q Predictions Mean           726.4252
Q Predictions Std            806.6503
Q Predictions Max            2633.4746
Q Predictions Min            -83.993904
V Predictions Mean           730.13525
V Predictions Std            810.7442
V Predictions Max            2631.3086
V Predictions Min            -90.43525
Log Pis Mean                 -1.1041367
Log Pis Std                  3.530715
Log Pis Max                  14.623306
Log Pis Min                  -5.6242113
Policy mu Mean               -0.027423477
Policy mu Std                0.77139163
Policy mu Max                3.3018475
Policy mu Min                -2.967915
Policy log std Mean          -0.44741473
Policy log std Std           0.22381204
Policy log std Max           -0.13951744
Policy log std Min           -1.9407089
Z mean eval                  1.9045881
Z variance eval              0.019563163
total_rewards                [6397.73721039 6334.65972206 6134.12455137 6244.53219982 6278.45179098
 6199.39234122 6240.07816942 6302.73183282 6057.80944138 5896.92813372]
total_rewards_mean           6208.64453931663
total_rewards_std            138.99442760472132
total_rewards_max            6397.737210388255
total_rewards_min            5896.928133724845
Number of train steps total  284000
Number of env steps total    854000
Number of rollouts total     0
Train Time (s)               145.16799584403634
(Previous) Eval Time (s)     17.54698609886691
Sample Time (s)              6.362792334519327
Epoch Time (s)               169.07777427742258
Total Train Time (s)         11936.384378995746
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:12:34.939036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #70 | Epoch Duration: 169.15923142433167
2020-01-12 11:12:34.939217 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #70 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9064925
Z variance train             0.019710252
KL Divergence                36.088448
KL Loss                      3.6088448
QF Loss                      657.52423
VF Loss                      247.75795
Policy Loss                  -954.9075
Q Predictions Mean           955.50476
Q Predictions Std            908.3305
Q Predictions Max            2633.0076
Q Predictions Min            -66.7108
V Predictions Mean           957.13446
V Predictions Std            911.1033
V Predictions Max            2625.5413
V Predictions Min            -92.77434
Log Pis Mean                 -0.80169666
Log Pis Std                  3.5094044
Log Pis Max                  9.956644
Log Pis Min                  -7.1128864
Policy mu Mean               -0.014122388
Policy mu Std                0.8351764
Policy mu Max                3.4713573
Policy mu Min                -2.980465
Policy log std Mean          -0.4906595
Policy log std Std           0.25094312
Policy log std Max           -0.10289964
Policy log std Min           -2.2119858
Z mean eval                  1.9259548
Z variance eval              0.023544218
total_rewards                [6207.18402351 6046.19454926 2299.39055116 6406.15013856 6298.8571819
 6767.19379656 6414.78696016 6645.77171238 6619.99180679 6463.21173607]
total_rewards_mean           6016.873245635494
total_rewards_std            1255.6913050618623
total_rewards_max            6767.193796562019
total_rewards_min            2299.3905511628113
Number of train steps total  288000
Number of env steps total    866000
Number of rollouts total     0
Train Time (s)               143.9915888281539
(Previous) Eval Time (s)     17.24979145405814
Sample Time (s)              6.408704467117786
Epoch Time (s)               167.65008474932984
Total Train Time (s)         12104.1184686739
Epoch                        71
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:15:22.674985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #71 | Epoch Duration: 167.73561334609985
2020-01-12 11:15:22.675226 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9274876
Z variance train             0.023443783
KL Divergence                35.6243
KL Loss                      3.56243
QF Loss                      603.8964
VF Loss                      110.7771
Policy Loss                  -898.12805
Q Predictions Mean           892.98694
Q Predictions Std            919.8184
Q Predictions Max            2740.545
Q Predictions Min            -112.776886
V Predictions Mean           903.4154
V Predictions Std            921.7069
V Predictions Max            2760.115
V Predictions Min            -94.450615
Log Pis Mean                 -0.5956864
Log Pis Std                  4.1839256
Log Pis Max                  15.474714
Log Pis Min                  -7.5330453
Policy mu Mean               -0.03236183
Policy mu Std                0.8391715
Policy mu Max                2.7498064
Policy mu Min                -3.6301155
Policy log std Mean          -0.4763801
Policy log std Std           0.24895069
Policy log std Max           0.17862576
Policy log std Min           -2.1130807
Z mean eval                  1.9065393
Z variance eval              0.020648029
total_rewards                [6800.66967287 6848.85127319 6688.03357635 6573.05473772 6421.46356637
 6926.23334063 6416.06024829 6636.83877914 6641.98357476 4944.70215119]
total_rewards_mean           6489.7890920508
total_rewards_std            538.9317912869752
total_rewards_max            6926.233340626881
total_rewards_min            4944.7021511893945
Number of train steps total  292000
Number of env steps total    878000
Number of rollouts total     0
Train Time (s)               142.37295288126916
(Previous) Eval Time (s)     20.63531113183126
Sample Time (s)              6.558693532366306
Epoch Time (s)               169.56695754546672
Total Train Time (s)         12273.768998747226
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:18:12.325227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #72 | Epoch Duration: 169.64983892440796
2020-01-12 11:18:12.325360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9069259
Z variance train             0.020696966
KL Divergence                35.30067
KL Loss                      3.5300672
QF Loss                      423.5443
VF Loss                      120.397644
Policy Loss                  -841.9248
Q Predictions Mean           837.20935
Q Predictions Std            875.8545
Q Predictions Max            2695.063
Q Predictions Min            -105.14013
V Predictions Mean           844.2478
V Predictions Std            881.29944
V Predictions Max            2689.672
V Predictions Min            -96.09946
Log Pis Mean                 -0.8446692
Log Pis Std                  3.6057746
Log Pis Max                  19.177437
Log Pis Min                  -6.6063986
Policy mu Mean               -0.08572644
Policy mu Std                0.79924846
Policy mu Max                3.4459207
Policy mu Min                -3.275269
Policy log std Mean          -0.48352802
Policy log std Std           0.24562743
Policy log std Max           -0.039794087
Policy log std Min           -2.0993092
Z mean eval                  1.9232066
Z variance eval              0.012680945
total_rewards                [6334.56660625 3353.65876259 6607.6835525  6594.60376544 6432.99780352
 6519.50576337 6524.39270468 6190.33679291 6663.14673595 6617.26892699]
total_rewards_mean           6183.816141421094
total_rewards_std            953.38237970731
total_rewards_max            6663.146735953936
total_rewards_min            3353.6587625865504
Number of train steps total  296000
Number of env steps total    890000
Number of rollouts total     0
Train Time (s)               142.93206780217588
(Previous) Eval Time (s)     20.723051264882088
Sample Time (s)              6.42490890994668
Epoch Time (s)               170.08002797700465
Total Train Time (s)         12443.935315628536
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:21:02.493345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #73 | Epoch Duration: 170.16788530349731
2020-01-12 11:21:02.493482 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9219732
Z variance train             0.012649233
KL Divergence                36.754177
KL Loss                      3.6754177
QF Loss                      708.5473
VF Loss                      63.8428
Policy Loss                  -723.7065
Q Predictions Mean           716.6256
Q Predictions Std            813.18713
Q Predictions Max            2688.1958
Q Predictions Min            -118.86739
V Predictions Mean           718.99316
V Predictions Std            814.5323
V Predictions Max            2677.8003
V Predictions Min            -101.12744
Log Pis Mean                 -1.5221188
Log Pis Std                  3.2166948
Log Pis Max                  12.404056
Log Pis Min                  -6.1852627
Policy mu Mean               -0.0399356
Policy mu Std                0.7341676
Policy mu Max                3.1507752
Policy mu Min                -2.9435282
Policy log std Mean          -0.4478356
Policy log std Std           0.22285402
Policy log std Max           -0.15916756
Policy log std Min           -1.9836318
Z mean eval                  1.9176843
Z variance eval              0.039364442
total_rewards                [6365.15914054 6283.68921146 6131.74834958 6167.57811909 6552.78626449
 4372.49032422 6179.08144071 6602.51370961 6229.73777935 6191.17612243]
total_rewards_mean           6107.596046147545
total_rewards_std            598.5209117033972
total_rewards_max            6602.5137096075205
total_rewards_min            4372.490324218205
Number of train steps total  300000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               142.32089658873156
(Previous) Eval Time (s)     20.750394348055124
Sample Time (s)              6.607983416412026
Epoch Time (s)               169.6792743531987
Total Train Time (s)         12613.69556729123
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:23:52.254492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #74 | Epoch Duration: 169.7609167098999
2020-01-12 11:23:52.254641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9142888
Z variance train             0.03954923
KL Divergence                33.758095
KL Loss                      3.3758094
QF Loss                      525.3814
VF Loss                      124.22824
Policy Loss                  -846.33026
Q Predictions Mean           831.631
Q Predictions Std            890.5416
Q Predictions Max            2727.1296
Q Predictions Min            -110.2047
V Predictions Mean           844.54724
V Predictions Std            889.8078
V Predictions Max            2704.8042
V Predictions Min            -97.693756
Log Pis Mean                 -0.8895787
Log Pis Std                  3.9307344
Log Pis Max                  17.172672
Log Pis Min                  -7.6534495
Policy mu Mean               -0.07315045
Policy mu Std                0.81108475
Policy mu Max                3.0775783
Policy mu Min                -3.1038806
Policy log std Mean          -0.4524858
Policy log std Std           0.2220385
Policy log std Max           -0.1042586
Policy log std Min           -2.0909927
Z mean eval                  1.9221071
Z variance eval              0.038345017
total_rewards                [6718.76190197 6772.4146805  6595.03178839 6515.63545106 6433.09545615
 6908.65216277 6557.4211703  1482.94969339 6317.05774773 6836.73879364]
total_rewards_mean           6113.775884589608
total_rewards_std            1553.4502252585623
total_rewards_max            6908.652162770284
total_rewards_min            1482.949693392347
Number of train steps total  304000
Number of env steps total    914000
Number of rollouts total     0
Train Time (s)               144.6765623362735
(Previous) Eval Time (s)     17.308902602177113
Sample Time (s)              6.515462671872228
Epoch Time (s)               168.50092761032283
Total Train Time (s)         12782.307247437537
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:26:40.868918 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #75 | Epoch Duration: 168.61415767669678
2020-01-12 11:26:40.869126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9220686
Z variance train             0.038225066
KL Divergence                33.276627
KL Loss                      3.3276627
QF Loss                      272.47702
VF Loss                      60.09032
Policy Loss                  -827.81665
Q Predictions Mean           821.15845
Q Predictions Std            844.0492
Q Predictions Max            2713.37
Q Predictions Min            -108.16551
V Predictions Mean           824.96594
V Predictions Std            845.4125
V Predictions Max            2690.336
V Predictions Min            -105.538506
Log Pis Mean                 -1.0661168
Log Pis Std                  3.3346736
Log Pis Max                  14.596866
Log Pis Min                  -6.564146
Policy mu Mean               0.010263724
Policy mu Std                0.7738751
Policy mu Max                2.7074406
Policy mu Min                -2.713632
Policy log std Mean          -0.4687407
Policy log std Std           0.23245813
Policy log std Max           -0.11971766
Policy log std Min           -2.0444312
Z mean eval                  1.935648
Z variance eval              0.021667432
total_rewards                [6476.14719352 6040.96465959 6385.53459449 6364.48569017 6451.07591961
 6335.63707979 6426.42537088 6426.62607753 6648.87476771 6605.10635166]
total_rewards_mean           6416.087770494148
total_rewards_std            156.76510137647313
total_rewards_max            6648.874767705496
total_rewards_min            6040.964659586793
Number of train steps total  308000
Number of env steps total    926000
Number of rollouts total     0
Train Time (s)               144.72288407105953
(Previous) Eval Time (s)     17.92733120592311
Sample Time (s)              6.342245437204838
Epoch Time (s)               168.99246071418747
Total Train Time (s)         12951.37879549805
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:29:29.941449 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #76 | Epoch Duration: 169.07216572761536
2020-01-12 11:29:29.941629 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9358187
Z variance train             0.021697322
KL Divergence                34.20354
KL Loss                      3.4203541
QF Loss                      385.87555
VF Loss                      93.6093
Policy Loss                  -879.66986
Q Predictions Mean           875.2638
Q Predictions Std            876.7594
Q Predictions Max            2710.769
Q Predictions Min            -93.82006
V Predictions Mean           882.414
V Predictions Std            878.2482
V Predictions Max            2700.2827
V Predictions Min            -105.51337
Log Pis Mean                 -1.0181878
Log Pis Std                  3.146918
Log Pis Max                  11.357937
Log Pis Min                  -6.000614
Policy mu Mean               0.034117606
Policy mu Std                0.77924865
Policy mu Max                2.657605
Policy mu Min                -2.4177413
Policy log std Mean          -0.48062968
Policy log std Std           0.2408191
Policy log std Max           -0.14605194
Policy log std Min           -2.060026
Z mean eval                  1.9189469
Z variance eval              0.013638318
total_rewards                [6163.72877212 6748.94202955 6535.39745781 6674.36148954 7025.42414481
 6494.51315068 6686.33099415 6709.07501976 6573.75666319 6665.36881776]
total_rewards_mean           6627.689853937109
total_rewards_std            207.5999821366779
total_rewards_max            7025.424144813877
total_rewards_min            6163.728772123472
Number of train steps total  312000
Number of env steps total    938000
Number of rollouts total     0
Train Time (s)               145.14685849659145
(Previous) Eval Time (s)     20.982759467791766
Sample Time (s)              6.589742365758866
Epoch Time (s)               172.71936033014208
Total Train Time (s)         13124.18441857677
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:32:22.747561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #77 | Epoch Duration: 172.805805683136
2020-01-12 11:32:22.747704 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9182926
Z variance train             0.013601027
KL Divergence                35.48971
KL Loss                      3.5489712
QF Loss                      309.7739
VF Loss                      103.51799
Policy Loss                  -761.9066
Q Predictions Mean           756.9069
Q Predictions Std            833.9687
Q Predictions Max            2720.9792
Q Predictions Min            -133.029
V Predictions Mean           758.75793
V Predictions Std            836.022
V Predictions Max            2699.8457
V Predictions Min            -128.14035
Log Pis Mean                 -1.2505851
Log Pis Std                  3.5732014
Log Pis Max                  18.01568
Log Pis Min                  -7.3036304
Policy mu Mean               -0.1042085
Policy mu Std                0.7657626
Policy mu Max                3.0361211
Policy mu Min                -2.945022
Policy log std Mean          -0.469956
Policy log std Std           0.22982384
Policy log std Max           -0.12308204
Policy log std Min           -2.2557588
Z mean eval                  1.94399
Z variance eval              0.02191857
total_rewards                [6784.77869933 2169.16833214 6730.45021197 7087.71559962 6775.75489183
 7106.07600229 6830.26298104 7039.087185   6825.09404071 6844.08188807]
total_rewards_mean           6419.246983199837
total_rewards_std            1422.5907445071173
total_rewards_max            7106.0760022853065
total_rewards_min            2169.168332136087
Number of train steps total  316000
Number of env steps total    950000
Number of rollouts total     0
Train Time (s)               144.8410155349411
(Previous) Eval Time (s)     18.20105986483395
Sample Time (s)              6.321663931012154
Epoch Time (s)               169.3637393307872
Total Train Time (s)         13293.63054038398
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:35:12.194590 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #78 | Epoch Duration: 169.44678473472595
2020-01-12 11:35:12.194738 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9430186
Z variance train             0.02191483
KL Divergence                33.534515
KL Loss                      3.3534515
QF Loss                      461.33008
VF Loss                      208.18115
Policy Loss                  -856.7875
Q Predictions Mean           848.7438
Q Predictions Std            890.2291
Q Predictions Max            2740.0264
Q Predictions Min            -132.73595
V Predictions Mean           868.24896
V Predictions Std            895.4994
V Predictions Max            2756.0156
V Predictions Min            -114.27151
Log Pis Mean                 -0.70113325
Log Pis Std                  3.6826344
Log Pis Max                  17.538399
Log Pis Min                  -7.46621
Policy mu Mean               -0.06077373
Policy mu Std                0.8319159
Policy mu Max                2.7827902
Policy mu Min                -3.3544865
Policy log std Mean          -0.47775874
Policy log std Std           0.2331503
Policy log std Max           -0.115655124
Policy log std Min           -2.1333344
Z mean eval                  1.9231899
Z variance eval              0.010022086
total_rewards                [6791.39886586 6895.59442615 6992.33227579 6781.41576121 6865.21895202
 6736.86717029 6945.50249449 6948.14761575 6630.03037554 6677.94892249]
total_rewards_mean           6826.44568595781
total_rewards_std            116.06020231325866
total_rewards_max            6992.332275786583
total_rewards_min            6630.030375537773
Number of train steps total  320000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               144.18312916485593
(Previous) Eval Time (s)     17.798429735004902
Sample Time (s)              5.395140776410699
Epoch Time (s)               167.37669967627153
Total Train Time (s)         13461.093271906022
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:37:59.662262 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #79 | Epoch Duration: 167.46737694740295
2020-01-12 11:37:59.662589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9211237
Z variance train             0.010034809
KL Divergence                35.451515
KL Loss                      3.5451515
QF Loss                      355.06934
VF Loss                      103.580345
Policy Loss                  -823.3496
Q Predictions Mean           811.9689
Q Predictions Std            843.40314
Q Predictions Max            2738.7295
Q Predictions Min            -121.927315
V Predictions Mean           822.4929
V Predictions Std            846.4049
V Predictions Max            2719.4226
V Predictions Min            -115.60786
Log Pis Mean                 -0.72505337
Log Pis Std                  3.8031275
Log Pis Max                  15.693098
Log Pis Min                  -5.7879877
Policy mu Mean               -0.0045198104
Policy mu Std                0.81326646
Policy mu Max                3.3265326
Policy mu Min                -3.3173363
Policy log std Mean          -0.46581006
Policy log std Std           0.2464985
Policy log std Max           -0.12999254
Policy log std Min           -2.1364317
Z mean eval                  1.9455141
Z variance eval              0.016692108
total_rewards                [6307.72662146 6177.27861646 6249.6712644  6195.71536975 6281.32905756
 6364.4853967  6228.47253397 6278.24448742 6040.67724012 6287.80328186]
total_rewards_mean           6241.140386969256
total_rewards_std            84.48518737274325
total_rewards_max            6364.485396696794
total_rewards_min            6040.677240124791
Number of train steps total  324000
Number of env steps total    974000
Number of rollouts total     0
Train Time (s)               143.84884004993364
(Previous) Eval Time (s)     20.464759598951787
Sample Time (s)              5.559265097603202
Epoch Time (s)               169.87286474648863
Total Train Time (s)         13631.051168244332
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:40:49.620492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #80 | Epoch Duration: 169.95763111114502
2020-01-12 11:40:49.620641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9486698
Z variance train             0.016701987
KL Divergence                35.14409
KL Loss                      3.5144088
QF Loss                      253.83353
VF Loss                      190.0325
Policy Loss                  -826.6418
Q Predictions Mean           821.1393
Q Predictions Std            881.15356
Q Predictions Max            2721.5286
Q Predictions Min            -112.53979
V Predictions Mean           835.4753
V Predictions Std            882.69037
V Predictions Max            2732.1707
V Predictions Min            -123.31951
Log Pis Mean                 -1.0902462
Log Pis Std                  3.1302495
Log Pis Max                  10.575375
Log Pis Min                  -6.5758414
Policy mu Mean               0.02634734
Policy mu Std                0.7751295
Policy mu Max                3.1538591
Policy mu Min                -2.6675916
Policy log std Mean          -0.4725118
Policy log std Std           0.25235796
Policy log std Max           -0.12728155
Policy log std Min           -2.5123024
Z mean eval                  1.9192121
Z variance eval              0.017951565
total_rewards                [5807.87975832 6005.52447291 6360.43147995 6058.8051195  5955.13712917
 6075.44937861 6227.58640689 5981.45796038 6030.04323035 5920.05495236]
total_rewards_mean           6042.236988844628
total_rewards_std            148.19191634261696
total_rewards_max            6360.431479951385
total_rewards_min            5807.879758324435
Number of train steps total  328000
Number of env steps total    986000
Number of rollouts total     0
Train Time (s)               143.20830960012972
(Previous) Eval Time (s)     17.657349943183362
Sample Time (s)              6.617194666527212
Epoch Time (s)               167.4828542098403
Total Train Time (s)         13798.617211640812
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:43:37.190442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #81 | Epoch Duration: 167.56968069076538
2020-01-12 11:43:37.190646 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #81 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9189593
Z variance train             0.017912786
KL Divergence                34.725815
KL Loss                      3.4725816
QF Loss                      789.1039
VF Loss                      154.60805
Policy Loss                  -859.4405
Q Predictions Mean           851.6629
Q Predictions Std            890.95404
Q Predictions Max            2760.5967
Q Predictions Min            -115.70336
V Predictions Mean           865.77814
V Predictions Std            894.70355
V Predictions Max            2759.3745
V Predictions Min            -122.12347
Log Pis Mean                 -1.0074866
Log Pis Std                  3.3948438
Log Pis Max                  15.157591
Log Pis Min                  -7.0500264
Policy mu Mean               -0.054775495
Policy mu Std                0.7789646
Policy mu Max                2.6785607
Policy mu Min                -2.8804224
Policy log std Mean          -0.47855428
Policy log std Std           0.24742727
Policy log std Max           -0.1196104
Policy log std Min           -2.212659
Z mean eval                  1.9384058
Z variance eval              0.038305134
total_rewards                [6369.5886239  6051.82400702 6442.45906118 6010.99870121 6552.7907918
 6452.68356824 6190.55762437 6080.75837601 6028.01449084 6314.57071236]
total_rewards_mean           6249.424595692212
total_rewards_std            191.34260430743757
total_rewards_max            6552.790791803798
total_rewards_min            6010.998701206025
Number of train steps total  332000
Number of env steps total    998000
Number of rollouts total     0
Train Time (s)               142.6130550452508
(Previous) Eval Time (s)     17.538343803025782
Sample Time (s)              6.538192308973521
Epoch Time (s)               166.6895911572501
Total Train Time (s)         13965.399914619513
Epoch                        82
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:46:23.974486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #82 | Epoch Duration: 166.78368401527405
2020-01-12 11:46:23.974732 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.94098
Z variance train             0.03820688
KL Divergence                34.407875
KL Loss                      3.4407876
QF Loss                      254.24976
VF Loss                      48.29139
Policy Loss                  -851.0413
Q Predictions Mean           849.07874
Q Predictions Std            883.9519
Q Predictions Max            2773.583
Q Predictions Min            -106.49184
V Predictions Mean           849.94507
V Predictions Std            885.76495
V Predictions Max            2741.6157
V Predictions Min            -113.35897
Log Pis Mean                 -1.1637769
Log Pis Std                  3.4167147
Log Pis Max                  11.815897
Log Pis Min                  -7.1372414
Policy mu Mean               -0.028736515
Policy mu Std                0.8023472
Policy mu Max                2.5835238
Policy mu Min                -2.9365392
Policy log std Mean          -0.46769217
Policy log std Std           0.22383521
Policy log std Max           -0.11682156
Policy log std Min           -1.9243231
Z mean eval                  1.9712365
Z variance eval              0.026418012
total_rewards                [6690.53044493 6924.87712443 7148.06967873 6990.60276218 6894.89039207
 6816.19710798 6909.37127389 6960.7285762  6930.30762169 7296.81095698]
total_rewards_mean           6956.238593906298
total_rewards_std            158.6878377362714
total_rewards_max            7296.810956981488
total_rewards_min            6690.530444929169
Number of train steps total  336000
Number of env steps total    1010000
Number of rollouts total     0
Train Time (s)               143.27031986089423
(Previous) Eval Time (s)     17.746682967990637
Sample Time (s)              5.50136765325442
Epoch Time (s)               166.5183704821393
Total Train Time (s)         14132.090683217626
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:49:10.668094 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #83 | Epoch Duration: 166.69321298599243
2020-01-12 11:49:10.668265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9672527
Z variance train             0.026458368
KL Divergence                34.10302
KL Loss                      3.410302
QF Loss                      231.01874
VF Loss                      54.513023
Policy Loss                  -812.5151
Q Predictions Mean           804.1588
Q Predictions Std            878.4718
Q Predictions Max            2738.9827
Q Predictions Min            -183.26633
V Predictions Mean           810.53455
V Predictions Std            878.19604
V Predictions Max            2723.628
V Predictions Min            -121.54699
Log Pis Mean                 -1.0447309
Log Pis Std                  3.418666
Log Pis Max                  12.548586
Log Pis Min                  -9.778387
Policy mu Mean               -0.07589989
Policy mu Std                0.7788128
Policy mu Max                3.7346258
Policy mu Min                -2.508574
Policy log std Mean          -0.4776822
Policy log std Std           0.23499379
Policy log std Max           -0.167907
Policy log std Min           -2.0649142
Z mean eval                  1.9605248
Z variance eval              0.04453638
total_rewards                [6904.48494448 7012.20663993 6921.92710338 6723.58486119 7097.62169707
 7184.79453668 7165.20523819 6827.01456413 6954.03183593 6816.4833586 ]
total_rewards_mean           6960.735477959572
total_rewards_std            145.95992093093705
total_rewards_max            7184.794536681355
total_rewards_min            6723.584861194478
Number of train steps total  340000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               145.0343587147072
(Previous) Eval Time (s)     21.011270728893578
Sample Time (s)              6.505604314152151
Epoch Time (s)               172.55123375775293
Total Train Time (s)         14304.726594283711
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:52:03.307271 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #84 | Epoch Duration: 172.63885116577148
2020-01-12 11:52:03.307532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9616792
Z variance train             0.044243637
KL Divergence                33.639698
KL Loss                      3.3639698
QF Loss                      191.5141
VF Loss                      60.443348
Policy Loss                  -757.8577
Q Predictions Mean           750.0014
Q Predictions Std            819.1134
Q Predictions Max            2790.1428
Q Predictions Min            -156.7662
V Predictions Mean           756.552
V Predictions Std            821.15576
V Predictions Max            2795.5232
V Predictions Min            -127.847786
Log Pis Mean                 -1.1185857
Log Pis Std                  3.2382383
Log Pis Max                  9.454233
Log Pis Min                  -6.640612
Policy mu Mean               0.025142223
Policy mu Std                0.7646546
Policy mu Max                2.7468917
Policy mu Min                -2.8183126
Policy log std Mean          -0.4714192
Policy log std Std           0.23887856
Policy log std Max           -0.15221184
Policy log std Min           -2.2144492
Z mean eval                  1.9564724
Z variance eval              0.018473458
total_rewards                [6942.30077971 7047.7705823  6968.82483952 7071.70882836 6845.41130807
 7207.30030764 6856.18192482 6874.28339265 6773.45083073 7097.83206911]
total_rewards_mean           6968.506486291745
total_rewards_std            128.86500159864124
total_rewards_max            7207.3003076391715
total_rewards_min            6773.450830725401
Number of train steps total  344000
Number of env steps total    1034000
Number of rollouts total     0
Train Time (s)               145.20383495790884
(Previous) Eval Time (s)     17.260036647319794
Sample Time (s)              6.524156869854778
Epoch Time (s)               168.9880284750834
Total Train Time (s)         14473.80162749486
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:54:52.382773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #85 | Epoch Duration: 169.07504963874817
2020-01-12 11:54:52.382953 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9584984
Z variance train             0.018495385
KL Divergence                36.376415
KL Loss                      3.6376417
QF Loss                      771.8637
VF Loss                      121.42945
Policy Loss                  -758.9428
Q Predictions Mean           756.10095
Q Predictions Std            858.3358
Q Predictions Max            2790.0806
Q Predictions Min            -144.69232
V Predictions Mean           762.6328
V Predictions Std            859.2581
V Predictions Max            2779.6323
V Predictions Min            -132.52592
Log Pis Mean                 -0.89952475
Log Pis Std                  3.7501333
Log Pis Max                  16.842625
Log Pis Min                  -6.514022
Policy mu Mean               -0.060050827
Policy mu Std                0.779075
Policy mu Max                2.9006786
Policy mu Min                -3.7528172
Policy log std Mean          -0.47166553
Policy log std Std           0.23840795
Policy log std Max           -0.097542375
Policy log std Min           -2.3785365
Z mean eval                  1.917833
Z variance eval              0.011947613
total_rewards                [6723.38336053 6586.81425605 6683.31349468 6531.07100242 6748.38183354
 6824.20884668 6602.60554472 6762.81375439 6715.88557645 6685.54484295]
total_rewards_mean           6686.40225124014
total_rewards_std            84.8442351185703
total_rewards_max            6824.208846676684
total_rewards_min            6531.071002418416
Number of train steps total  348000
Number of env steps total    1046000
Number of rollouts total     0
Train Time (s)               144.9392209239304
(Previous) Eval Time (s)     20.80948308389634
Sample Time (s)              6.651611663401127
Epoch Time (s)               172.40031567122787
Total Train Time (s)         14646.309030967299
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 11:57:44.891635 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #86 | Epoch Duration: 172.50854420661926
2020-01-12 11:57:44.891813 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9193504
Z variance train             0.011947852
KL Divergence                37.54443
KL Loss                      3.754443
QF Loss                      302.48422
VF Loss                      124.549034
Policy Loss                  -758.5971
Q Predictions Mean           749.7369
Q Predictions Std            825.39325
Q Predictions Max            2844.6516
Q Predictions Min            -124.3326
V Predictions Mean           750.0429
V Predictions Std            822.6549
V Predictions Max            2825.7947
V Predictions Min            -135.47217
Log Pis Mean                 -1.2843583
Log Pis Std                  3.178608
Log Pis Max                  17.216084
Log Pis Min                  -9.446639
Policy mu Mean               0.036529597
Policy mu Std                0.75122565
Policy mu Max                3.1452076
Policy mu Min                -3.5980954
Policy log std Mean          -0.4869102
Policy log std Std           0.23340489
Policy log std Max           -0.14696631
Policy log std Min           -2.2146678
Z mean eval                  2.0778606
Z variance eval              0.023066204
total_rewards                [6294.18432362 6613.15722032 6650.41019992 6802.23951372 6505.46209215
 6570.41652318 6727.76468885 6616.44631544 6495.52210843 6415.72260294]
total_rewards_mean           6569.132558857034
total_rewards_std            141.02873619608417
total_rewards_max            6802.239513723461
total_rewards_min            6294.184323624649
Number of train steps total  352000
Number of env steps total    1058000
Number of rollouts total     0
Train Time (s)               144.1187355183065
(Previous) Eval Time (s)     20.705354772042483
Sample Time (s)              6.510303697548807
Epoch Time (s)               171.33439398789778
Total Train Time (s)         14817.737419188954
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:00:36.321513 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #87 | Epoch Duration: 171.4295744895935
2020-01-12 12:00:36.321651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0807996
Z variance train             0.023039198
KL Divergence                35.8896
KL Loss                      3.58896
QF Loss                      208.56233
VF Loss                      139.0743
Policy Loss                  -805.8361
Q Predictions Mean           799.0617
Q Predictions Std            891.35333
Q Predictions Max            2843.275
Q Predictions Min            -144.12999
V Predictions Mean           802.68115
V Predictions Std            890.10406
V Predictions Max            2823.452
V Predictions Min            -143.1641
Log Pis Mean                 -1.184794
Log Pis Std                  3.180121
Log Pis Max                  12.356448
Log Pis Min                  -6.653386
Policy mu Mean               -0.09207025
Policy mu Std                0.7902631
Policy mu Max                3.784519
Policy mu Min                -2.3689399
Policy log std Mean          -0.4646425
Policy log std Std           0.2349661
Policy log std Max           0.15224183
Policy log std Min           -2.1052566
Z mean eval                  1.926891
Z variance eval              0.0233453
total_rewards                [6815.90570081 7289.6496237  7229.51027067 6995.31528024 6939.14556188
 7000.00685251 7141.58500059 7291.11815878 6593.81287209 6688.51545433]
total_rewards_mean           6998.45647756052
total_rewards_std            232.58776071583847
total_rewards_max            7291.118158781056
total_rewards_min            6593.812872091532
Number of train steps total  356000
Number of env steps total    1070000
Number of rollouts total     0
Train Time (s)               143.88833766197786
(Previous) Eval Time (s)     17.587287302594632
Sample Time (s)              6.576064620632678
Epoch Time (s)               168.05168958520517
Total Train Time (s)         14985.870213527232
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:03:24.456768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #88 | Epoch Duration: 168.13499903678894
2020-01-12 12:03:24.456973 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9271028
Z variance train             0.023267645
KL Divergence                35.154015
KL Loss                      3.5154016
QF Loss                      244.61386
VF Loss                      123.666275
Policy Loss                  -853.591
Q Predictions Mean           845.50305
Q Predictions Std            899.7223
Q Predictions Max            2820.118
Q Predictions Min            -136.60895
V Predictions Mean           854.8567
V Predictions Std            898.50446
V Predictions Max            2822.4182
V Predictions Min            -132.92235
Log Pis Mean                 -0.6983094
Log Pis Std                  3.6590133
Log Pis Max                  15.549471
Log Pis Min                  -7.363738
Policy mu Mean               0.044267733
Policy mu Std                0.83111835
Policy mu Max                3.83306
Policy mu Min                -2.9621847
Policy log std Mean          -0.4919586
Policy log std Std           0.24132477
Policy log std Max           -0.16028835
Policy log std Min           -2.203754
Z mean eval                  1.9272244
Z variance eval              0.015736718
total_rewards                [6798.99342897 6993.20036624 7270.62107761 6907.74184678 6765.08952119
 6489.69412808 7149.3802166  6972.35396072 6863.42144868 6931.90696816]
total_rewards_mean           6914.240296301823
total_rewards_std            202.6361452343653
total_rewards_max            7270.6210776110975
total_rewards_min            6489.694128076472
Number of train steps total  360000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               142.0992118776776
(Previous) Eval Time (s)     17.537145932670683
Sample Time (s)              5.57813604734838
Epoch Time (s)               165.21449385769665
Total Train Time (s)         15151.175662376918
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:06:09.767395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #89 | Epoch Duration: 165.31020736694336
2020-01-12 12:06:09.767674 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9291741
Z variance train             0.015707111
KL Divergence                36.509743
KL Loss                      3.6509743
QF Loss                      1000.92725
VF Loss                      66.60585
Policy Loss                  -792.54034
Q Predictions Mean           788.59143
Q Predictions Std            872.82355
Q Predictions Max            2835.4275
Q Predictions Min            -155.32314
V Predictions Mean           792.95
V Predictions Std            875.2994
V Predictions Max            2789.1008
V Predictions Min            -145.24858
Log Pis Mean                 -0.95912737
Log Pis Std                  3.5319088
Log Pis Max                  13.981365
Log Pis Min                  -7.518078
Policy mu Mean               0.027622482
Policy mu Std                0.7943562
Policy mu Max                2.6899016
Policy mu Min                -2.610173
Policy log std Mean          -0.48913732
Policy log std Std           0.23090687
Policy log std Max           -0.09019421
Policy log std Min           -2.1225457
Z mean eval                  1.9263948
Z variance eval              0.03546231
total_rewards                [6962.21252432 6891.21945113 7071.40654509 6987.65388899 7120.20508048
 6950.76157563 7053.64443002 6752.48976576 6952.69758969 6842.34782823]
total_rewards_mean           6958.46386793362
total_rewards_std            104.57742089844858
total_rewards_max            7120.2050804776445
total_rewards_min            6752.4897657570555
Number of train steps total  364000
Number of env steps total    1094000
Number of rollouts total     0
Train Time (s)               144.20610792608932
(Previous) Eval Time (s)     17.521170976106077
Sample Time (s)              6.459666369948536
Epoch Time (s)               168.18694527214393
Total Train Time (s)         15319.446167192422
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:08:58.035822 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #90 | Epoch Duration: 168.26796460151672
2020-01-12 12:08:58.035964 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9271246
Z variance train             0.035411812
KL Divergence                34.936966
KL Loss                      3.4936967
QF Loss                      262.31976
VF Loss                      57.05413
Policy Loss                  -939.1956
Q Predictions Mean           938.13025
Q Predictions Std            945.0635
Q Predictions Max            2806.3594
Q Predictions Min            254.74431
V Predictions Mean           939.3331
V Predictions Std            945.3313
V Predictions Max            2786.2878
V Predictions Min            264.18433
Log Pis Mean                 -0.6832967
Log Pis Std                  3.5991898
Log Pis Max                  12.719261
Log Pis Min                  -7.2155433
Policy mu Mean               -0.021198655
Policy mu Std                0.84060055
Policy mu Max                2.7585504
Policy mu Min                -2.5623043
Policy log std Mean          -0.4961022
Policy log std Std           0.24633025
Policy log std Max           -0.10967898
Policy log std Min           -2.0952933
Z mean eval                  1.9254935
Z variance eval              0.031933405
total_rewards                [6983.59195109 7062.77059384 6930.22395019 6766.88011683 5308.97817283
 7146.32544945 6588.0054982  6606.30241647 6755.48852662 6565.82120332]
total_rewards_mean           6671.438787881707
total_rewards_std            493.75080248192126
total_rewards_max            7146.325449448679
total_rewards_min            5308.978172827709
Number of train steps total  368000
Number of env steps total    1106000
Number of rollouts total     0
Train Time (s)               143.75813356786966
(Previous) Eval Time (s)     20.968512722756714
Sample Time (s)              5.550566884689033
Epoch Time (s)               170.2772131753154
Total Train Time (s)         15489.800794639625
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:11:48.396333 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #91 | Epoch Duration: 170.3601999282837
2020-01-12 12:11:48.396599 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9250515
Z variance train             0.032038443
KL Divergence                34.908085
KL Loss                      3.4908085
QF Loss                      509.2765
VF Loss                      127.969284
Policy Loss                  -722.9397
Q Predictions Mean           712.375
Q Predictions Std            782.9121
Q Predictions Max            2825.6453
Q Predictions Min            -150.62369
V Predictions Mean           715.1199
V Predictions Std            780.5521
V Predictions Max            2791.151
V Predictions Min            -154.92726
Log Pis Mean                 -1.3459429
Log Pis Std                  3.0131645
Log Pis Max                  10.525032
Log Pis Min                  -7.659042
Policy mu Mean               -0.01008385
Policy mu Std                0.76773375
Policy mu Max                3.12268
Policy mu Min                -2.7024932
Policy log std Mean          -0.47551206
Policy log std Std           0.21089685
Policy log std Max           -0.10658145
Policy log std Min           -1.872183
Z mean eval                  1.9480652
Z variance eval              0.028568843
total_rewards                [6896.16222953 6933.43591348 7207.82974161 7108.12725061 7123.51070532
 7130.30406293 7060.38162886 7096.6089008  7156.52609358 6977.71199893]
total_rewards_mean           7069.0598525655105
total_rewards_std            96.23698279492831
total_rewards_max            7207.829741605403
total_rewards_min            6896.162229530173
Number of train steps total  372000
Number of env steps total    1118000
Number of rollouts total     0
Train Time (s)               144.4790194928646
(Previous) Eval Time (s)     20.898349762894213
Sample Time (s)              5.671871499624103
Epoch Time (s)               171.04924075538293
Total Train Time (s)         15660.93359193625
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:14:39.528145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #92 | Epoch Duration: 171.1313989162445
2020-01-12 12:14:39.528281 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9502541
Z variance train             0.028415492
KL Divergence                35.944492
KL Loss                      3.5944493
QF Loss                      451.23682
VF Loss                      175.29254
Policy Loss                  -829.1762
Q Predictions Mean           827.261
Q Predictions Std            898.9086
Q Predictions Max            2883.2905
Q Predictions Min            -146.39136
V Predictions Mean           825.4673
V Predictions Std            899.08154
V Predictions Max            2869.2632
V Predictions Min            -148.23943
Log Pis Mean                 -1.0268289
Log Pis Std                  3.411231
Log Pis Max                  12.243606
Log Pis Min                  -6.4797916
Policy mu Mean               -0.02386024
Policy mu Std                0.77204347
Policy mu Max                2.6899395
Policy mu Min                -2.8781614
Policy log std Mean          -0.49026632
Policy log std Std           0.23146656
Policy log std Max           -0.18375134
Policy log std Min           -2.2068822
Z mean eval                  1.9520752
Z variance eval              0.020687118
total_rewards                [6770.08694816 6852.6263622  6781.78102973 6721.45810336 6630.03339687
 6799.85093726 6984.73607002 6469.20997107 6962.23387439 6923.41478216]
total_rewards_mean           6789.543147521702
total_rewards_std            149.35219887864247
total_rewards_max            6984.736070018523
total_rewards_min            6469.209971071685
Number of train steps total  376000
Number of env steps total    1130000
Number of rollouts total     0
Train Time (s)               143.41464222688228
(Previous) Eval Time (s)     17.472814690787345
Sample Time (s)              6.470811376813799
Epoch Time (s)               167.35826829448342
Total Train Time (s)         15828.368514915928
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:17:26.965516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #93 | Epoch Duration: 167.4371199607849
2020-01-12 12:17:26.965702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.955849
Z variance train             0.020794028
KL Divergence                35.457333
KL Loss                      3.5457332
QF Loss                      971.7628
VF Loss                      47.19342
Policy Loss                  -829.6177
Q Predictions Mean           826.01184
Q Predictions Std            888.1491
Q Predictions Max            2963.528
Q Predictions Min            272.5681
V Predictions Mean           831.42413
V Predictions Std            887.75916
V Predictions Max            2943.7876
V Predictions Min            275.71057
Log Pis Mean                 -0.8349519
Log Pis Std                  3.562833
Log Pis Max                  11.356342
Log Pis Min                  -7.890978
Policy mu Mean               0.011857144
Policy mu Std                0.85243595
Policy mu Max                3.3515043
Policy mu Min                -3.0572422
Policy log std Mean          -0.46886578
Policy log std Std           0.21230197
Policy log std Max           0.17902192
Policy log std Min           -2.102565
Z mean eval                  1.9613756
Z variance eval              0.020575363
total_rewards                [6781.89910206 7135.13516177 7026.1236049  6985.12308895 6958.93112977
 6865.64811754 7001.42536767 6754.56096472 7080.09774399 6962.08331068]
total_rewards_mean           6955.102759205081
total_rewards_std            115.93464218903276
total_rewards_max            7135.135161774803
total_rewards_min            6754.560964716477
Number of train steps total  380000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               144.89263023482636
(Previous) Eval Time (s)     20.879871659446508
Sample Time (s)              6.523120848461986
Epoch Time (s)               172.29562274273485
Total Train Time (s)         16000.890623628162
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:20:19.490706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #94 | Epoch Duration: 172.52475881576538
2020-01-12 12:20:19.490990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #94 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9577183
Z variance train             0.020569151
KL Divergence                35.62691
KL Loss                      3.5626912
QF Loss                      328.0436
VF Loss                      105.83563
Policy Loss                  -762.04297
Q Predictions Mean           758.4116
Q Predictions Std            865.4914
Q Predictions Max            2912.8662
Q Predictions Min            -178.84142
V Predictions Mean           765.37305
V Predictions Std            866.19763
V Predictions Max            2908.577
V Predictions Min            -163.88391
Log Pis Mean                 -0.9066294
Log Pis Std                  3.525547
Log Pis Max                  17.648396
Log Pis Min                  -6.7583046
Policy mu Mean               0.011152982
Policy mu Std                0.80680907
Policy mu Max                2.91809
Policy mu Min                -2.8314044
Policy log std Mean          -0.4720684
Policy log std Std           0.23710132
Policy log std Max           -0.06470287
Policy log std Min           -2.0553463
Z mean eval                  1.9550068
Z variance eval              0.04327026
total_rewards                [6925.4990185  6891.67387614 6958.20214686 6803.17791482 6885.2944383
 6883.72798927 6757.10644823 6975.64832219 6919.30763631 6853.38276128]
total_rewards_mean           6885.302055189028
total_rewards_std            63.63132402670892
total_rewards_max            6975.648322189124
total_rewards_min            6757.106448232212
Number of train steps total  384000
Number of env steps total    1154000
Number of rollouts total     0
Train Time (s)               144.42324313195422
(Previous) Eval Time (s)     17.48837686376646
Sample Time (s)              6.4801661148667336
Epoch Time (s)               168.39178611058742
Total Train Time (s)         16169.366245115642
Epoch                        95
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:23:07.969791 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #95 | Epoch Duration: 168.4786114692688
2020-01-12 12:23:07.969997 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9518551
Z variance train             0.042925913
KL Divergence                34.443462
KL Loss                      3.4443462
QF Loss                      1031.6748
VF Loss                      90.52602
Policy Loss                  -821.28534
Q Predictions Mean           814.4607
Q Predictions Std            921.5163
Q Predictions Max            2898.069
Q Predictions Min            -160.11168
V Predictions Mean           823.7565
V Predictions Std            917.4904
V Predictions Max            2899.3906
V Predictions Min            -148.31297
Log Pis Mean                 -0.9597713
Log Pis Std                  3.2622561
Log Pis Max                  13.871848
Log Pis Min                  -6.8744698
Policy mu Mean               0.01018106
Policy mu Std                0.78635955
Policy mu Max                2.8477485
Policy mu Min                -3.26072
Policy log std Mean          -0.46347722
Policy log std Std           0.21617272
Policy log std Max           -0.0980041
Policy log std Min           -1.8197339
Z mean eval                  1.925991
Z variance eval              0.037870783
total_rewards                [6784.75083446 7108.81177622 7399.1155278  7183.25776872 7205.81909935
 7042.09442055 7076.81791695 7248.69563281 7119.30021553 7059.10557931]
total_rewards_mean           7122.776877169905
total_rewards_std            151.6301973662004
total_rewards_max            7399.115527797064
total_rewards_min            6784.750834458908
Number of train steps total  388000
Number of env steps total    1166000
Number of rollouts total     0
Train Time (s)               144.06890761805698
(Previous) Eval Time (s)     17.57093188771978
Sample Time (s)              6.366818407084793
Epoch Time (s)               168.00665791286156
Total Train Time (s)         16337.459316642024
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:25:56.063161 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #96 | Epoch Duration: 168.092933177948
2020-01-12 12:25:56.063488 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9246712
Z variance train             0.03768177
KL Divergence                33.886417
KL Loss                      3.3886418
QF Loss                      145.71849
VF Loss                      75.80509
Policy Loss                  -778.44586
Q Predictions Mean           773.874
Q Predictions Std            871.4688
Q Predictions Max            2842.3108
Q Predictions Min            -156.5935
V Predictions Mean           781.1615
V Predictions Std            866.9697
V Predictions Max            2833.1519
V Predictions Min            -156.84837
Log Pis Mean                 -0.8810864
Log Pis Std                  3.2318861
Log Pis Max                  10.44112
Log Pis Min                  -5.725468
Policy mu Mean               -0.11117516
Policy mu Std                0.80594635
Policy mu Max                2.6880643
Policy mu Min                -2.6677115
Policy log std Mean          -0.4733659
Policy log std Std           0.21655037
Policy log std Max           -0.12529892
Policy log std Min           -2.4063735
Z mean eval                  1.9261891
Z variance eval              0.015617192
total_rewards                [6910.92650716 7285.85988779 7070.93298224 7059.65686143 7061.45224823
 7394.64542133 7198.90833304 6887.95764664 7079.66250583 7115.98679961]
total_rewards_mean           7106.598919329257
total_rewards_std            146.98487998462107
total_rewards_max            7394.645421327544
total_rewards_min            6887.957646635956
Number of train steps total  392000
Number of env steps total    1178000
Number of rollouts total     0
Train Time (s)               143.565619263798
(Previous) Eval Time (s)     17.26439891103655
Sample Time (s)              6.321033394429833
Epoch Time (s)               167.15105156926438
Total Train Time (s)         16504.68865882093
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:28:43.293686 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #97 | Epoch Duration: 167.2299976348877
2020-01-12 12:28:43.293871 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9236796
Z variance train             0.015629128
KL Divergence                36.926384
KL Loss                      3.6926384
QF Loss                      140.98753
VF Loss                      70.67559
Policy Loss                  -772.65607
Q Predictions Mean           768.79614
Q Predictions Std            896.90076
Q Predictions Max            2890.0928
Q Predictions Min            -181.72795
V Predictions Mean           773.215
V Predictions Std            897.26587
V Predictions Max            2872.159
V Predictions Min            -165.36037
Log Pis Mean                 -0.8491062
Log Pis Std                  3.4017882
Log Pis Max                  16.401505
Log Pis Min                  -6.694831
Policy mu Mean               -0.07999235
Policy mu Std                0.79951745
Policy mu Max                3.4597378
Policy mu Min                -2.3984046
Policy log std Mean          -0.47717237
Policy log std Std           0.22853754
Policy log std Max           -0.14652878
Policy log std Min           -2.084047
Z mean eval                  1.955007
Z variance eval              0.01590431
total_rewards                [7173.46759039 7011.44339548 7295.25433609 7027.43267328 7365.85267069
 7230.93851412 7080.09379425 7203.13389546 7211.9468323  7115.84003063]
total_rewards_mean           7171.540373269328
total_rewards_std            108.20728990294137
total_rewards_max            7365.8526706925395
total_rewards_min            7011.443395475614
Number of train steps total  396000
Number of env steps total    1190000
Number of rollouts total     0
Train Time (s)               145.42305033281446
(Previous) Eval Time (s)     17.334379236679524
Sample Time (s)              6.631349541246891
Epoch Time (s)               169.38877911074087
Total Train Time (s)         16674.180383663625
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:31:32.795630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #98 | Epoch Duration: 169.50161504745483
2020-01-12 12:31:32.795809 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9573311
Z variance train             0.015906803
KL Divergence                38.290527
KL Loss                      3.8290527
QF Loss                      222.62672
VF Loss                      127.45002
Policy Loss                  -823.197
Q Predictions Mean           818.0975
Q Predictions Std            913.699
Q Predictions Max            2958.4922
Q Predictions Min            -166.81929
V Predictions Mean           824.3971
V Predictions Std            913.9169
V Predictions Max            2955.7908
V Predictions Min            -187.14996
Log Pis Mean                 -0.71851224
Log Pis Std                  3.573749
Log Pis Max                  21.183805
Log Pis Min                  -5.614256
Policy mu Mean               -0.015614729
Policy mu Std                0.8101781
Policy mu Max                3.8962865
Policy mu Min                -2.9887483
Policy log std Mean          -0.47551736
Policy log std Std           0.22709781
Policy log std Max           -0.07680419
Policy log std Min           -2.0685337
Z mean eval                  1.9186201
Z variance eval              0.029956728
total_rewards                [7199.1334282  6986.66026459 7219.7231687  7054.786189   7101.66576537
 7397.95722234 7024.74711855 6969.33697813 7163.59485235 7207.62206831]
total_rewards_mean           7132.522705555524
total_rewards_std            124.74690844790118
total_rewards_max            7397.957222338196
total_rewards_min            6969.3369781315105
Number of train steps total  400000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               144.61361826816574
(Previous) Eval Time (s)     21.027083704713732
Sample Time (s)              6.556876257993281
Epoch Time (s)               172.19757823087275
Total Train Time (s)         16846.464620177634
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:34:25.076745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #99 | Epoch Duration: 172.2808063030243
2020-01-12 12:34:25.076882 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198582
Z variance train             0.030087644
KL Divergence                37.73826
KL Loss                      3.773826
QF Loss                      186.96909
VF Loss                      131.99274
Policy Loss                  -789.7919
Q Predictions Mean           787.02893
Q Predictions Std            913.64954
Q Predictions Max            2898.7463
Q Predictions Min            -202.56499
V Predictions Mean           792.09937
V Predictions Std            915.6611
V Predictions Max            2931.6113
V Predictions Min            -197.8871
Log Pis Mean                 -0.8441348
Log Pis Std                  3.5685039
Log Pis Max                  14.654056
Log Pis Min                  -8.287224
Policy mu Mean               -0.032866765
Policy mu Std                0.7899241
Policy mu Max                2.9057257
Policy mu Min                -2.3959796
Policy log std Mean          -0.47089636
Policy log std Std           0.24273388
Policy log std Max           -0.15467562
Policy log std Min           -2.1907928
Z mean eval                  1.9512832
Z variance eval              0.030735204
total_rewards                [6836.95180953 7186.2285294  7232.20174307 6919.99718401 7107.26881144
 7057.73115159 7045.45048829 7153.18812023 6935.67984264 7351.98645977]
total_rewards_mean           7082.668413997375
total_rewards_std            148.87800114147583
total_rewards_max            7351.986459765026
total_rewards_min            6836.951809529374
Number of train steps total  404000
Number of env steps total    1214000
Number of rollouts total     0
Train Time (s)               143.1254305159673
(Previous) Eval Time (s)     17.800623739603907
Sample Time (s)              6.571932315360755
Epoch Time (s)               167.49798657093197
Total Train Time (s)         17014.042863237206
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:37:12.658547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #100 | Epoch Duration: 167.58152103424072
2020-01-12 12:37:12.658900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9481484
Z variance train             0.030712593
KL Divergence                37.734062
KL Loss                      3.7734063
QF Loss                      211.76804
VF Loss                      112.42422
Policy Loss                  -809.84937
Q Predictions Mean           802.0088
Q Predictions Std            887.39594
Q Predictions Max            2985.6897
Q Predictions Min            -166.66971
V Predictions Mean           807.3661
V Predictions Std            890.58704
V Predictions Max            2965.6096
V Predictions Min            -190.80685
Log Pis Mean                 -0.87187636
Log Pis Std                  3.3722038
Log Pis Max                  13.284132
Log Pis Min                  -6.7265606
Policy mu Mean               0.0024157986
Policy mu Std                0.8291998
Policy mu Max                2.8632176
Policy mu Min                -2.5787098
Policy log std Mean          -0.49392834
Policy log std Std           0.22726126
Policy log std Max           -0.093110204
Policy log std Min           -2.0595007
Z mean eval                  1.9123154
Z variance eval              0.046586704
total_rewards                [6494.28234362 7286.10448183 6841.09749333 7078.7067167  7060.63968988
 6948.82282762 7006.3019518  6994.81328263 7154.83236328 7085.67850526]
total_rewards_mean           6995.127965596073
total_rewards_std            201.61603799319053
total_rewards_max            7286.104481830567
total_rewards_min            6494.2823436208755
Number of train steps total  408000
Number of env steps total    1226000
Number of rollouts total     0
Train Time (s)               143.60141613101587
(Previous) Eval Time (s)     17.73103729216382
Sample Time (s)              5.579986117780209
Epoch Time (s)               166.9124395409599
Total Train Time (s)         17181.03221380338
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:39:59.645739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #101 | Epoch Duration: 166.98662400245667
2020-01-12 12:39:59.645866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #101 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9122131
Z variance train             0.046499323
KL Divergence                36.91224
KL Loss                      3.6912239
QF Loss                      204.64801
VF Loss                      425.9266
Policy Loss                  -830.5631
Q Predictions Mean           822.53845
Q Predictions Std            917.2486
Q Predictions Max            2953.9556
Q Predictions Min            280.40887
V Predictions Mean           834.4296
V Predictions Std            918.86285
V Predictions Max            2929.4495
V Predictions Min            291.0007
Log Pis Mean                 -0.5841043
Log Pis Std                  3.594026
Log Pis Max                  12.076417
Log Pis Min                  -7.8194447
Policy mu Mean               0.004250919
Policy mu Std                0.8290791
Policy mu Max                2.7618017
Policy mu Min                -3.0087683
Policy log std Mean          -0.5007985
Policy log std Std           0.2462666
Policy log std Max           -0.11922583
Policy log std Min           -2.0630345
Z mean eval                  1.9185776
Z variance eval              0.036846966
total_rewards                [6674.88464775 6050.55690009 6582.71613513 6281.26385174 6457.9208249
 6409.77093247 6790.2106098  6434.20594852 6581.91656938 6540.74954236]
total_rewards_mean           6480.419596214767
total_rewards_std            197.5528096253992
total_rewards_max            6790.210609800283
total_rewards_min            6050.556900093767
Number of train steps total  412000
Number of env steps total    1238000
Number of rollouts total     0
Train Time (s)               143.72307493630797
(Previous) Eval Time (s)     20.90759125724435
Sample Time (s)              5.638433326967061
Epoch Time (s)               170.26909952051938
Total Train Time (s)         17351.38688650867
Epoch                        102
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:42:50.001589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #102 | Epoch Duration: 170.35562944412231
2020-01-12 12:42:50.001722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9190061
Z variance train             0.036996357
KL Divergence                36.68301
KL Loss                      3.668301
QF Loss                      429.22845
VF Loss                      104.5327
Policy Loss                  -939.28455
Q Predictions Mean           934.9176
Q Predictions Std            1006.88794
Q Predictions Max            3030.2312
Q Predictions Min            -192.72853
V Predictions Mean           932.5804
V Predictions Std            1001.59344
V Predictions Max            2986.3684
V Predictions Min            -193.13354
Log Pis Mean                 -0.19239593
Log Pis Std                  3.7003336
Log Pis Max                  11.6999855
Log Pis Min                  -8.99497
Policy mu Mean               -0.06895702
Policy mu Std                0.870376
Policy mu Max                2.5754828
Policy mu Min                -2.6116986
Policy log std Mean          -0.5038132
Policy log std Std           0.22910304
Policy log std Max           -0.11108971
Policy log std Min           -2.2524993
Z mean eval                  1.9131848
Z variance eval              0.027703404
total_rewards                [6931.07392711 6911.31652707 6916.28483468 7033.84057386 7236.75355923
 7010.04167597 6992.58336973 7092.41402251 6858.28369889 6829.14155748]
total_rewards_mean           6981.173374653488
total_rewards_std            114.56400631425684
total_rewards_max            7236.753559230378
total_rewards_min            6829.141557477321
Number of train steps total  416000
Number of env steps total    1250000
Number of rollouts total     0
Train Time (s)               144.1944802897051
(Previous) Eval Time (s)     21.153590239118785
Sample Time (s)              6.52583810640499
Epoch Time (s)               171.87390863522887
Total Train Time (s)         17523.347225406673
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:45:41.964083 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #103 | Epoch Duration: 171.9622654914856
2020-01-12 12:45:41.964216 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9119923
Z variance train             0.02760329
KL Divergence                36.591766
KL Loss                      3.6591766
QF Loss                      355.2533
VF Loss                      113.76266
Policy Loss                  -781.56665
Q Predictions Mean           781.32465
Q Predictions Std            879.89734
Q Predictions Max            2971.0996
Q Predictions Min            -128.266
V Predictions Mean           782.276
V Predictions Std            881.92126
V Predictions Max            2991.2356
V Predictions Min            -193.10777
Log Pis Mean                 -0.85325295
Log Pis Std                  3.556944
Log Pis Max                  13.674867
Log Pis Min                  -7.6293197
Policy mu Mean               0.029721871
Policy mu Std                0.8053748
Policy mu Max                3.4148166
Policy mu Min                -2.5768363
Policy log std Mean          -0.49369538
Policy log std Std           0.23865134
Policy log std Max           -0.12624529
Policy log std Min           -2.253504
Z mean eval                  1.9161228
Z variance eval              0.026865054
total_rewards                [7080.11604718 7041.72792161 6991.95393567 7321.65221115 7051.88152365
 7375.47083907 7046.49432117 6881.59844924 7268.86431525 7133.40026517]
total_rewards_mean           7119.315982915413
total_rewards_std            148.07295165704585
total_rewards_max            7375.470839065252
total_rewards_min            6881.598449241846
Number of train steps total  420000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               144.76137865707278
(Previous) Eval Time (s)     21.319770948961377
Sample Time (s)              6.57034373190254
Epoch Time (s)               172.6514933379367
Total Train Time (s)         17696.07851255033
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:48:34.697399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #104 | Epoch Duration: 172.73307156562805
2020-01-12 12:48:34.697598 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9199657
Z variance train             0.026847642
KL Divergence                36.331535
KL Loss                      3.6331537
QF Loss                      177.95108
VF Loss                      128.5391
Policy Loss                  -786.4409
Q Predictions Mean           784.1812
Q Predictions Std            859.46
Q Predictions Max            2925.8354
Q Predictions Min            173.25728
V Predictions Mean           791.4624
V Predictions Std            859.21344
V Predictions Max            2927.9653
V Predictions Min            177.5191
Log Pis Mean                 -0.70992106
Log Pis Std                  3.55017
Log Pis Max                  12.903122
Log Pis Min                  -7.2793236
Policy mu Mean               0.020849323
Policy mu Std                0.8100438
Policy mu Max                2.7160182
Policy mu Min                -2.4194555
Policy log std Mean          -0.48243427
Policy log std Std           0.21911544
Policy log std Max           0.016684294
Policy log std Min           -1.8477298
Z mean eval                  1.9044956
Z variance eval              0.055526666
total_rewards                [7313.71779703 7495.45141191 7520.15145555 7445.75068871 7307.38067294
 7515.59825665 7384.09986366 7350.95264182 7497.84761127 7471.37889775]
total_rewards_mean           7430.232929729131
total_rewards_std            79.50700875653034
total_rewards_max            7520.151455553658
total_rewards_min            7307.380672944401
Number of train steps total  424000
Number of env steps total    1274000
Number of rollouts total     0
Train Time (s)               144.52712028520182
(Previous) Eval Time (s)     17.535538257099688
Sample Time (s)              5.701904498971999
Epoch Time (s)               167.7645630412735
Total Train Time (s)         17863.922279125545
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:51:22.543831 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #105 | Epoch Duration: 167.84603238105774
2020-01-12 12:51:22.544111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9023387
Z variance train             0.05563987
KL Divergence                35.090317
KL Loss                      3.5090318
QF Loss                      1831.6276
VF Loss                      178.37271
Policy Loss                  -817.60834
Q Predictions Mean           820.8696
Q Predictions Std            926.6495
Q Predictions Max            3012.8435
Q Predictions Min            -199.35379
V Predictions Mean           819.7685
V Predictions Std            920.3622
V Predictions Max            2977.6545
V Predictions Min            -250.17616
Log Pis Mean                 -0.36028093
Log Pis Std                  3.6196344
Log Pis Max                  14.3547535
Log Pis Min                  -7.2800493
Policy mu Mean               -0.0020337787
Policy mu Std                0.82577497
Policy mu Max                2.529899
Policy mu Min                -2.4691093
Policy log std Mean          -0.51568514
Policy log std Std           0.24168961
Policy log std Max           -0.07920104
Policy log std Min           -2.101961
Z mean eval                  1.9212914
Z variance eval              0.03641849
total_rewards                [7332.94438196 7423.87831011 7496.97089141 7566.78696447 7428.29160515
 7594.16045764 7295.23990967 7474.85704441 7493.19866737 7596.55574093]
total_rewards_mean           7470.288397312033
total_rewards_std            97.61167434436152
total_rewards_max            7596.555740926086
total_rewards_min            7295.239909671807
Number of train steps total  428000
Number of env steps total    1286000
Number of rollouts total     0
Train Time (s)               145.4948024759069
(Previous) Eval Time (s)     21.22278656810522
Sample Time (s)              6.706497674807906
Epoch Time (s)               173.42408671882004
Total Train Time (s)         18037.426344096195
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:54:16.048084 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #106 | Epoch Duration: 173.50380277633667
2020-01-12 12:54:16.048231 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9239724
Z variance train             0.03636636
KL Divergence                35.616932
KL Loss                      3.5616932
QF Loss                      1156.5464
VF Loss                      75.62479
Policy Loss                  -855.18085
Q Predictions Mean           848.7662
Q Predictions Std            939.9918
Q Predictions Max            2943.1384
Q Predictions Min            -227.2128
V Predictions Mean           850.2124
V Predictions Std            938.0852
V Predictions Max            2930.9998
V Predictions Min            -238.77425
Log Pis Mean                 -0.5033512
Log Pis Std                  3.2893548
Log Pis Max                  14.158642
Log Pis Min                  -6.04196
Policy mu Mean               -0.019183343
Policy mu Std                0.82449967
Policy mu Max                2.6877272
Policy mu Min                -2.4937038
Policy log std Mean          -0.5123274
Policy log std Std           0.24086493
Policy log std Max           -0.09537104
Policy log std Min           -2.3237872
Z mean eval                  1.90819
Z variance eval              0.03924941
total_rewards                [7079.91371451 7128.06021893 7284.29242871 7120.66729496 7280.37833744
 7242.91927915 7166.46462145 7303.89062327 7379.48486638 7054.06472779]
total_rewards_mean           7204.013611258201
total_rewards_std            103.23100055042836
total_rewards_max            7379.484866384539
total_rewards_min            7054.064727788141
Number of train steps total  432000
Number of env steps total    1298000
Number of rollouts total     0
Train Time (s)               145.1561213331297
(Previous) Eval Time (s)     17.87301849387586
Sample Time (s)              6.5740503994748
Epoch Time (s)               169.60319022648036
Total Train Time (s)         18207.126162834466
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:57:05.755293 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #107 | Epoch Duration: 169.70679092407227
2020-01-12 12:57:05.755782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #107 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9080664
Z variance train             0.03948683
KL Divergence                37.3465
KL Loss                      3.7346501
QF Loss                      1396.387
VF Loss                      39.721226
Policy Loss                  -938.37604
Q Predictions Mean           938.7648
Q Predictions Std            994.80786
Q Predictions Max            3171.219
Q Predictions Min            239.5251
V Predictions Mean           935.6797
V Predictions Std            992.1613
V Predictions Max            3157.042
V Predictions Min            236.0456
Log Pis Mean                 -0.23342033
Log Pis Std                  3.5909774
Log Pis Max                  13.300819
Log Pis Min                  -8.158692
Policy mu Mean               -0.03888278
Policy mu Std                0.8769801
Policy mu Max                2.449174
Policy mu Min                -2.502029
Policy log std Mean          -0.51083595
Policy log std Std           0.24604046
Policy log std Max           -0.13549732
Policy log std Min           -2.2447495
Z mean eval                  1.9063368
Z variance eval              0.061633624
total_rewards                [6851.39667541 7220.6755688  7322.37475953 7078.72550887 6902.9060456
 7105.45402231 7113.49357434 6819.26869596 7434.61915919 6911.04306633]
total_rewards_mean           7075.995707634696
total_rewards_std            196.48152644496312
total_rewards_max            7434.619159189323
total_rewards_min            6819.268695961751
Number of train steps total  436000
Number of env steps total    1310000
Number of rollouts total     0
Train Time (s)               142.51524862879887
(Previous) Eval Time (s)     17.76117130694911
Sample Time (s)              6.562565880361944
Epoch Time (s)               166.83898581610993
Total Train Time (s)         18374.05369709432
Epoch                        108
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 12:59:52.682858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #108 | Epoch Duration: 166.9267590045929
2020-01-12 12:59:52.683053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9081059
Z variance train             0.062134463
KL Divergence                35.859013
KL Loss                      3.5859013
QF Loss                      171.74023
VF Loss                      122.72737
Policy Loss                  -851.08417
Q Predictions Mean           844.6479
Q Predictions Std            927.25684
Q Predictions Max            2995.3828
Q Predictions Min            177.99358
V Predictions Mean           845.505
V Predictions Std            925.7861
V Predictions Max            2983.0195
V Predictions Min            182.60228
Log Pis Mean                 -0.43036216
Log Pis Std                  3.7020714
Log Pis Max                  12.458061
Log Pis Min                  -7.847006
Policy mu Mean               -0.0036208492
Policy mu Std                0.85864455
Policy mu Max                3.3925426
Policy mu Min                -2.977624
Policy log std Mean          -0.49077502
Policy log std Std           0.22834393
Policy log std Max           -0.14068776
Policy log std Min           -2.0067024
Z mean eval                  1.9272276
Z variance eval              0.12757292
total_rewards                [7471.58946497 7087.35709427 6807.86512466 7140.07353814 7032.06243809
 7378.50430861 7507.8338408  7266.62277801 7258.38489962 7206.42088186]
total_rewards_mean           7215.671436904074
total_rewards_std            201.01526530273446
total_rewards_max            7507.83384080224
total_rewards_min            6807.865124664541
Number of train steps total  440000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               143.8547427719459
(Previous) Eval Time (s)     17.651402975898236
Sample Time (s)              6.479253159835935
Epoch Time (s)               167.98539890768006
Total Train Time (s)         18542.12601461634
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:02:40.756766 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #109 | Epoch Duration: 168.073561668396
2020-01-12 13:02:40.756940 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9280527
Z variance train             0.1268874
KL Divergence                37.429317
KL Loss                      3.7429318
QF Loss                      470.232
VF Loss                      92.32588
Policy Loss                  -760.1286
Q Predictions Mean           756.58325
Q Predictions Std            862.76056
Q Predictions Max            3043.059
Q Predictions Min            -303.75357
V Predictions Mean           753.98413
V Predictions Std            857.5785
V Predictions Max            3018.1267
V Predictions Min            -257.14316
Log Pis Mean                 -1.0864537
Log Pis Std                  3.5456898
Log Pis Max                  14.290344
Log Pis Min                  -7.863919
Policy mu Mean               0.002960734
Policy mu Std                0.81410563
Policy mu Max                2.5935562
Policy mu Min                -2.9445782
Policy log std Mean          -0.4749986
Policy log std Std           0.23077637
Policy log std Max           -0.10855514
Policy log std Min           -2.1209948
Z mean eval                  1.8875366
Z variance eval              0.044112746
total_rewards                [7543.11112517 7343.38792588 7567.90351152 7611.87158479 7499.49656459
 7603.1901754  7597.49106087 7496.92589915 7581.02284374 7567.32794193]
total_rewards_mean           7541.172863304377
total_rewards_std            76.03958066088532
total_rewards_max            7611.871584792599
total_rewards_min            7343.387925879508
Number of train steps total  444000
Number of env steps total    1334000
Number of rollouts total     0
Train Time (s)               145.14623410999775
(Previous) Eval Time (s)     21.108967198990285
Sample Time (s)              6.455439322628081
Epoch Time (s)               172.71064063161612
Total Train Time (s)         18714.917049956974
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:05:33.548428 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #110 | Epoch Duration: 172.7913601398468
2020-01-12 13:05:33.548575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8880463
Z variance train             0.044402517
KL Divergence                37.60445
KL Loss                      3.760445
QF Loss                      237.7527
VF Loss                      42.007004
Policy Loss                  -776.46564
Q Predictions Mean           775.03033
Q Predictions Std            867.4189
Q Predictions Max            3054.4944
Q Predictions Min            312.23987
V Predictions Mean           773.40015
V Predictions Std            867.1907
V Predictions Max            3011.364
V Predictions Min            309.64786
Log Pis Mean                 -1.0138376
Log Pis Std                  3.2418103
Log Pis Max                  11.1862545
Log Pis Min                  -6.3295317
Policy mu Mean               0.012316257
Policy mu Std                0.80221117
Policy mu Max                2.9116411
Policy mu Min                -2.8177445
Policy log std Mean          -0.48673233
Policy log std Std           0.21582386
Policy log std Max           -0.12275705
Policy log std Min           -1.8103812
Z mean eval                  1.9022865
Z variance eval              0.050370812
total_rewards                [7081.5059657  7543.53576731 7277.48006741 7360.66910782 7300.89242344
 7327.75994107 7306.46763724 7121.03569311 7213.4607395  7540.99165857]
total_rewards_mean           7307.379900116468
total_rewards_std            144.6029249580695
total_rewards_max            7543.535767311413
total_rewards_min            7081.505965704212
Number of train steps total  448000
Number of env steps total    1346000
Number of rollouts total     0
Train Time (s)               145.65298531530425
(Previous) Eval Time (s)     18.09470963384956
Sample Time (s)              6.466960986610502
Epoch Time (s)               170.2146559357643
Total Train Time (s)         18885.213521314785
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:08:23.845323 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #111 | Epoch Duration: 170.29664945602417
2020-01-12 13:08:23.845449 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #111 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9039986
Z variance train             0.049729537
KL Divergence                36.491695
KL Loss                      3.6491697
QF Loss                      1405.1643
VF Loss                      259.05408
Policy Loss                  -853.2169
Q Predictions Mean           852.65234
Q Predictions Std            924.5874
Q Predictions Max            3083.4578
Q Predictions Min            -282.27167
V Predictions Mean           866.15063
V Predictions Std            929.2659
V Predictions Max            3099.4607
V Predictions Min            -285.68552
Log Pis Mean                 -0.70494103
Log Pis Std                  3.2510262
Log Pis Max                  13.217918
Log Pis Min                  -7.246575
Policy mu Mean               -0.057437617
Policy mu Std                0.82263553
Policy mu Max                3.538799
Policy mu Min                -2.820245
Policy log std Mean          -0.4911076
Policy log std Std           0.24035822
Policy log std Max           -0.039743915
Policy log std Min           -2.3823073
Z mean eval                  1.9054581
Z variance eval              0.06622856
total_rewards                [7289.64648765 7532.49381457 7345.7478275  7529.78728686 7811.5301482
 7441.10943897 7480.99103629 7774.36640407 7638.49608968 7716.27872823]
total_rewards_mean           7556.044726200933
total_rewards_std            167.53817502530703
total_rewards_max            7811.530148195105
total_rewards_min            7289.646487646022
Number of train steps total  452000
Number of env steps total    1358000
Number of rollouts total     0
Train Time (s)               142.87984588369727
(Previous) Eval Time (s)     17.745346387848258
Sample Time (s)              5.649289525579661
Epoch Time (s)               166.2744817971252
Total Train Time (s)         19051.58230270911
Epoch                        112
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:11:10.217035 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #112 | Epoch Duration: 166.3714780807495
2020-01-12 13:11:10.217222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9094651
Z variance train             0.066540025
KL Divergence                35.9141
KL Loss                      3.5914102
QF Loss                      196.49733
VF Loss                      51.570873
Policy Loss                  -872.6476
Q Predictions Mean           866.8109
Q Predictions Std            962.18097
Q Predictions Max            3109.0315
Q Predictions Min            324.93378
V Predictions Mean           872.9815
V Predictions Std            961.7692
V Predictions Max            3100.9292
V Predictions Min            324.6514
Log Pis Mean                 -0.53830713
Log Pis Std                  3.350883
Log Pis Max                  11.599407
Log Pis Min                  -8.683192
Policy mu Mean               0.050827205
Policy mu Std                0.8340545
Policy mu Max                2.6867223
Policy mu Min                -2.7862499
Policy log std Mean          -0.49042165
Policy log std Std           0.23613343
Policy log std Max           -0.13578013
Policy log std Min           -1.9563973
Z mean eval                  1.9007809
Z variance eval              0.038516693
total_rewards                [4591.38951419 6483.08747535 6385.76829397 6312.86570469 7034.20088381
 6490.47979072 6592.02162545 7136.36593443 6982.26341154 6307.41627828]
total_rewards_mean           6431.585891243546
total_rewards_std            679.1833723732648
total_rewards_max            7136.365934433517
total_rewards_min            4591.389514192275
Number of train steps total  456000
Number of env steps total    1370000
Number of rollouts total     0
Train Time (s)               145.5874309251085
(Previous) Eval Time (s)     18.49061840865761
Sample Time (s)              5.697768978308886
Epoch Time (s)               169.775818312075
Total Train Time (s)         19221.44087025663
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:14:00.078432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #113 | Epoch Duration: 169.86106181144714
2020-01-12 13:14:00.078609 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9011631
Z variance train             0.03859276
KL Divergence                37.03447
KL Loss                      3.703447
QF Loss                      115.08835
VF Loss                      69.73685
Policy Loss                  -860.17303
Q Predictions Mean           857.6362
Q Predictions Std            951.5746
Q Predictions Max            3145.3337
Q Predictions Min            322.2025
V Predictions Mean           854.27527
V Predictions Std            948.4121
V Predictions Max            3117.2192
V Predictions Min            318.51343
Log Pis Mean                 -0.6824604
Log Pis Std                  3.2576005
Log Pis Max                  10.518961
Log Pis Min                  -6.5467157
Policy mu Mean               -0.06810882
Policy mu Std                0.8166818
Policy mu Max                2.3929021
Policy mu Min                -2.4685738
Policy log std Mean          -0.50172096
Policy log std Std           0.23528688
Policy log std Max           -0.14597297
Policy log std Min           -1.8952065
Z mean eval                  1.9165739
Z variance eval              0.03483177
total_rewards                [7387.95023028 7459.22926039 7579.88171534 7232.9194812  7475.48501255
 7705.07643705 7441.46705759 7774.34606089 7348.25686658 7522.10791506]
total_rewards_mean           7492.67200369349
total_rewards_std            153.70668018569066
total_rewards_max            7774.3460608938785
total_rewards_min            7232.919481199336
Number of train steps total  460000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               143.25593352224678
(Previous) Eval Time (s)     20.7247155290097
Sample Time (s)              6.684343710541725
Epoch Time (s)               170.6649927617982
Total Train Time (s)         19392.188857350964
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:16:50.827707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #114 | Epoch Duration: 170.7489676475525
2020-01-12 13:16:50.827842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9169391
Z variance train             0.03489836
KL Divergence                37.321022
KL Loss                      3.7321022
QF Loss                      563.5031
VF Loss                      160.4964
Policy Loss                  -918.4683
Q Predictions Mean           917.9453
Q Predictions Std            1006.29486
Q Predictions Max            3174.943
Q Predictions Min            -299.66113
V Predictions Mean           925.46716
V Predictions Std            1009.45135
V Predictions Max            3177.3132
V Predictions Min            -314.6009
Log Pis Mean                 -0.64203185
Log Pis Std                  3.3479748
Log Pis Max                  12.220511
Log Pis Min                  -8.43899
Policy mu Mean               -0.0069028228
Policy mu Std                0.82823354
Policy mu Max                2.8458598
Policy mu Min                -2.340374
Policy log std Mean          -0.5178518
Policy log std Std           0.2510042
Policy log std Max           -0.13519698
Policy log std Min           -2.045452
Z mean eval                  1.8629748
Z variance eval              0.03024486
total_rewards                [7137.35415643 7319.80341441 7098.84632851 6951.07999592 6974.04739117
 6954.5084906  6920.56350344 7176.1850445  7166.13685626 6848.58734057]
total_rewards_mean           7054.711252181047
total_rewards_std            139.28120157815005
total_rewards_max            7319.803414413312
total_rewards_min            6848.587340569953
Number of train steps total  464000
Number of env steps total    1394000
Number of rollouts total     0
Train Time (s)               143.29337359033525
(Previous) Eval Time (s)     17.866342968773097
Sample Time (s)              6.5710661839693785
Epoch Time (s)               167.73078274307773
Total Train Time (s)         19560.008664316032
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:19:38.648250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #115 | Epoch Duration: 167.8203136920929
2020-01-12 13:19:38.648383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8643568
Z variance train             0.030050997
KL Divergence                37.71864
KL Loss                      3.771864
QF Loss                      1328.3547
VF Loss                      43.57567
Policy Loss                  -817.87854
Q Predictions Mean           814.14386
Q Predictions Std            903.1618
Q Predictions Max            3054.1433
Q Predictions Min            321.97647
V Predictions Mean           814.9961
V Predictions Std            902.37213
V Predictions Max            3042.5315
V Predictions Min            323.58896
Log Pis Mean                 -0.8339603
Log Pis Std                  3.1897955
Log Pis Max                  15.359024
Log Pis Min                  -7.761678
Policy mu Mean               -0.055720065
Policy mu Std                0.8074393
Policy mu Max                3.8086443
Policy mu Min                -3.295555
Policy log std Mean          -0.512848
Policy log std Std           0.2329146
Policy log std Max           -0.13149789
Policy log std Min           -1.798282
Z mean eval                  1.9113111
Z variance eval              0.027153749
total_rewards                [7541.83986259 7426.40661565 7606.1952651  7671.70428588 7627.94930612
 7522.72441121 7685.28793986 7927.10916377 7737.57390235 7645.39965526]
total_rewards_mean           7639.219040777648
total_rewards_std            128.5809645122482
total_rewards_max            7927.109163769693
total_rewards_min            7426.406615645668
Number of train steps total  468000
Number of env steps total    1406000
Number of rollouts total     0
Train Time (s)               142.12256727507338
(Previous) Eval Time (s)     17.5120849609375
Sample Time (s)              5.517080361023545
Epoch Time (s)               165.15173259703442
Total Train Time (s)         19725.24482318759
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:22:23.886237 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #116 | Epoch Duration: 165.2377495765686
2020-01-12 13:22:23.886400 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9126072
Z variance train             0.02712198
KL Divergence                39.05373
KL Loss                      3.905373
QF Loss                      127.00568
VF Loss                      83.04401
Policy Loss                  -790.92725
Q Predictions Mean           786.67664
Q Predictions Std            871.7051
Q Predictions Max            3136.247
Q Predictions Min            339.35434
V Predictions Mean           785.4231
V Predictions Std            868.9775
V Predictions Max            3123.198
V Predictions Min            337.20648
Log Pis Mean                 -0.9350321
Log Pis Std                  3.3906243
Log Pis Max                  15.53838
Log Pis Min                  -8.186732
Policy mu Mean               0.02482766
Policy mu Std                0.80265313
Policy mu Max                2.6167123
Policy mu Min                -3.2009027
Policy log std Mean          -0.5045402
Policy log std Std           0.24614045
Policy log std Max           -0.08879909
Policy log std Min           -2.183859
Z mean eval                  1.8970438
Z variance eval              0.052502535
total_rewards                [6770.02010606 6853.52541577 6830.70160612 6736.40662681 7035.73180251
 6552.36814977 6575.28448152 7124.27092476 6869.35050328 7054.21467063]
total_rewards_mean           6840.187428724127
total_rewards_std            182.9137719131161
total_rewards_max            7124.270924764412
total_rewards_min            6552.368149771533
Number of train steps total  472000
Number of env steps total    1418000
Number of rollouts total     0
Train Time (s)               143.2499834978953
(Previous) Eval Time (s)     21.006833757273853
Sample Time (s)              6.5547933634370565
Epoch Time (s)               170.8116106186062
Total Train Time (s)         19896.150430815294
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:25:14.793201 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #117 | Epoch Duration: 170.90667986869812
2020-01-12 13:25:14.793330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8932397
Z variance train             0.052047856
KL Divergence                36.226376
KL Loss                      3.6226375
QF Loss                      414.04187
VF Loss                      160.24458
Policy Loss                  -951.13855
Q Predictions Mean           947.1282
Q Predictions Std            1011.3005
Q Predictions Max            3217.4246
Q Predictions Min            337.20016
V Predictions Mean           943.9464
V Predictions Std            1011.6994
V Predictions Max            3210.2717
V Predictions Min            337.15628
Log Pis Mean                 -0.22658238
Log Pis Std                  3.756109
Log Pis Max                  14.022488
Log Pis Min                  -6.1848235
Policy mu Mean               -0.017377093
Policy mu Std                0.87407607
Policy mu Max                2.7511168
Policy mu Min                -3.2514203
Policy log std Mean          -0.51549596
Policy log std Std           0.25036687
Policy log std Max           -0.11797637
Policy log std Min           -2.1203167
Z mean eval                  1.9187527
Z variance eval              0.059056066
total_rewards                [7485.80680699 7534.54266589 7780.52383127 7557.89506363 7913.54265272
 7519.79943614 7536.54924682 7841.24279322 7358.78559817 7603.69495628]
total_rewards_mean           7613.238305112495
total_rewards_std            165.86052853211416
total_rewards_max            7913.542652715864
total_rewards_min            7358.785598168658
Number of train steps total  476000
Number of env steps total    1430000
Number of rollouts total     0
Train Time (s)               146.01277970103547
(Previous) Eval Time (s)     17.829049854073673
Sample Time (s)              6.592224487569183
Epoch Time (s)               170.43405404267833
Total Train Time (s)         20066.659782813396
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:28:05.304522 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #118 | Epoch Duration: 170.51109743118286
2020-01-12 13:28:05.304642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9201494
Z variance train             0.059111483
KL Divergence                36.800495
KL Loss                      3.6800497
QF Loss                      552.80695
VF Loss                      134.59952
Policy Loss                  -880.40546
Q Predictions Mean           873.9572
Q Predictions Std            954.3509
Q Predictions Max            3245.014
Q Predictions Min            336.1944
V Predictions Mean           882.3362
V Predictions Std            954.6067
V Predictions Max            3235.073
V Predictions Min            348.3477
Log Pis Mean                 -0.5045211
Log Pis Std                  3.6810694
Log Pis Max                  17.057543
Log Pis Min                  -6.40963
Policy mu Mean               0.016252033
Policy mu Std                0.87295073
Policy mu Max                3.5429413
Policy mu Min                -3.6231174
Policy log std Mean          -0.47680545
Policy log std Std           0.23525366
Policy log std Max           0.10615286
Policy log std Min           -1.7438083
Z mean eval                  1.8499699
Z variance eval              0.041574962
total_rewards                [7166.02203731 6914.99813297 7484.81165074 7413.77446169 7244.08055029
 7277.55873161 7074.07979396 7234.95516712 7568.35890609 7165.87680776]
total_rewards_mean           7254.451623954461
total_rewards_std            184.78010153088542
total_rewards_max            7568.358906085889
total_rewards_min            6914.998132974983
Number of train steps total  480000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               143.69306420860812
(Previous) Eval Time (s)     19.218672181945294
Sample Time (s)              5.581175044644624
Epoch Time (s)               168.49291143519804
Total Train Time (s)         20235.22948155366
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:30:53.875921 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #119 | Epoch Duration: 168.5711760520935
2020-01-12 13:30:53.876085 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8507744
Z variance train             0.041518833
KL Divergence                36.75255
KL Loss                      3.6752548
QF Loss                      1290.2565
VF Loss                      70.82139
Policy Loss                  -866.0432
Q Predictions Mean           867.7007
Q Predictions Std            965.5447
Q Predictions Max            3177.8662
Q Predictions Min            330.15775
V Predictions Mean           868.81903
V Predictions Std            961.71216
V Predictions Max            3162.399
V Predictions Min            330.12518
Log Pis Mean                 -0.894922
Log Pis Std                  3.3007689
Log Pis Max                  13.019893
Log Pis Min                  -7.3243947
Policy mu Mean               0.034265686
Policy mu Std                0.8117967
Policy mu Max                3.182914
Policy mu Min                -2.5562327
Policy log std Mean          -0.4892534
Policy log std Std           0.22296138
Policy log std Max           -0.12204522
Policy log std Min           -1.8146917
Z mean eval                  1.8818638
Z variance eval              0.034975022
total_rewards                [6925.2472698  6858.91219428 7275.48051983 6775.40147855 6987.57238017
 7448.98691894 6921.66228328 6706.0192007  6943.06071979 6693.44193637]
total_rewards_mean           6953.578490169895
total_rewards_std            228.4301472721002
total_rewards_max            7448.986918937869
total_rewards_min            6693.44193637239
Number of train steps total  484000
Number of env steps total    1454000
Number of rollouts total     0
Train Time (s)               146.87898308085278
(Previous) Eval Time (s)     18.239474636036903
Sample Time (s)              5.785669642034918
Epoch Time (s)               170.9041273589246
Total Train Time (s)         20406.21143379761
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:33:44.863941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #120 | Epoch Duration: 170.98768711090088
2020-01-12 13:33:44.864266 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8801218
Z variance train             0.0349185
KL Divergence                37.942436
KL Loss                      3.7942436
QF Loss                      204.29294
VF Loss                      57.038223
Policy Loss                  -849.1939
Q Predictions Mean           845.59106
Q Predictions Std            965.028
Q Predictions Max            3183.6848
Q Predictions Min            333.11838
V Predictions Mean           851.19385
V Predictions Std            961.3914
V Predictions Max            3180.1636
V Predictions Min            346.7709
Log Pis Mean                 -0.604059
Log Pis Std                  3.5697298
Log Pis Max                  14.270751
Log Pis Min                  -8.27758
Policy mu Mean               0.019414816
Policy mu Std                0.8540691
Policy mu Max                2.6416867
Policy mu Min                -2.7371924
Policy log std Mean          -0.50075567
Policy log std Std           0.22682416
Policy log std Max           -0.06873512
Policy log std Min           -1.9365776
Z mean eval                  1.8481607
Z variance eval              0.03928976
total_rewards                [7738.27513516 7634.77287432 7616.52393936 7798.25266689 7611.83880956
 7906.00086824 7459.9396118  7570.34073781 7586.06429675 7191.06110608]
total_rewards_mean           7611.307004595483
total_rewards_std            184.47935887125516
total_rewards_max            7906.000868235701
total_rewards_min            7191.06110608216
Number of train steps total  488000
Number of env steps total    1466000
Number of rollouts total     0
Train Time (s)               145.37275499198586
(Previous) Eval Time (s)     17.57405790919438
Sample Time (s)              6.529192911926657
Epoch Time (s)               169.4760058131069
Total Train Time (s)         20575.76966544846
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:36:34.421792 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #121 | Epoch Duration: 169.55728888511658
2020-01-12 13:36:34.421968 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8494484
Z variance train             0.039281584
KL Divergence                37.28359
KL Loss                      3.728359
QF Loss                      134.6774
VF Loss                      40.87175
Policy Loss                  -881.18616
Q Predictions Mean           877.3775
Q Predictions Std            962.695
Q Predictions Max            3079.1685
Q Predictions Min            320.2457
V Predictions Mean           878.4719
V Predictions Std            961.2964
V Predictions Max            3070.5562
V Predictions Min            323.7233
Log Pis Mean                 -0.47622082
Log Pis Std                  3.5240083
Log Pis Max                  11.546876
Log Pis Min                  -6.755243
Policy mu Mean               0.081701614
Policy mu Std                0.8215505
Policy mu Max                2.4696395
Policy mu Min                -2.436808
Policy log std Mean          -0.5211946
Policy log std Std           0.24995562
Policy log std Max           -0.03588915
Policy log std Min           -2.1510968
Z mean eval                  1.8335276
Z variance eval              0.029113874
total_rewards                [6818.54030908 7301.84926138 6811.34581638 7043.46345132 7380.23103164
 7058.49506673 7224.01447336 7280.98989087 7051.34181705 7344.64222165]
total_rewards_mean           7131.491333945436
total_rewards_std            196.76628675222818
total_rewards_max            7380.231031644503
total_rewards_min            6811.345816376181
Number of train steps total  492000
Number of env steps total    1478000
Number of rollouts total     0
Train Time (s)               146.31620759889483
(Previous) Eval Time (s)     21.24554680706933
Sample Time (s)              6.6221495247446
Epoch Time (s)               174.18390393070877
Total Train Time (s)         20750.058508296497
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:39:28.711457 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #122 | Epoch Duration: 174.28935885429382
2020-01-12 13:39:28.711604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8367221
Z variance train             0.029151142
KL Divergence                37.81427
KL Loss                      3.7814271
QF Loss                      165.36618
VF Loss                      110.80527
Policy Loss                  -836.0016
Q Predictions Mean           830.0836
Q Predictions Std            935.9544
Q Predictions Max            3156.3386
Q Predictions Min            342.55045
V Predictions Mean           830.6066
V Predictions Std            930.6443
V Predictions Max            3125.4104
V Predictions Min            347.80884
Log Pis Mean                 -0.70839316
Log Pis Std                  3.050689
Log Pis Max                  10.095632
Log Pis Min                  -7.283415
Policy mu Mean               -0.009277181
Policy mu Std                0.79680413
Policy mu Max                2.5817778
Policy mu Min                -2.573068
Policy log std Mean          -0.50226146
Policy log std Std           0.25192925
Policy log std Max           -0.07432011
Policy log std Min           -1.7558663
Z mean eval                  1.8661534
Z variance eval              0.03001014
total_rewards                [7511.9200587  7757.97548768 7564.54341975 7816.57207708 7501.55720857
 7598.05298486 7670.92197814 7388.76429501 7783.13872595 7746.39036047]
total_rewards_mean           7633.983659621799
total_rewards_std            135.51428998122637
total_rewards_max            7816.572077081103
total_rewards_min            7388.7642950086865
Number of train steps total  496000
Number of env steps total    1490000
Number of rollouts total     0
Train Time (s)               144.69395993603393
(Previous) Eval Time (s)     18.111950328107923
Sample Time (s)              6.529921711422503
Epoch Time (s)               169.33583197556436
Total Train Time (s)         20919.647980194073
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:42:18.301764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #123 | Epoch Duration: 169.5900604724884
2020-01-12 13:42:18.301900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8668585
Z variance train             0.030100679
KL Divergence                38.71598
KL Loss                      3.871598
QF Loss                      123.925125
VF Loss                      71.89647
Policy Loss                  -822.16125
Q Predictions Mean           817.5211
Q Predictions Std            927.0445
Q Predictions Max            3347.0083
Q Predictions Min            333.78275
V Predictions Mean           824.85846
V Predictions Std            930.52094
V Predictions Max            3355.614
V Predictions Min            349.46088
Log Pis Mean                 -0.7038152
Log Pis Std                  3.5019002
Log Pis Max                  13.319337
Log Pis Min                  -6.827503
Policy mu Mean               -0.030598769
Policy mu Std                0.8222927
Policy mu Max                2.509315
Policy mu Min                -2.5011435
Policy log std Mean          -0.48704568
Policy log std Std           0.23211601
Policy log std Max           -0.017534494
Policy log std Min           -2.2193139
Z mean eval                  1.8611753
Z variance eval              0.042956673
total_rewards                [7158.5776788  7441.98159803 7610.96184775 7603.48293559 7465.75990392
 7448.14934091 7425.04757104 7328.79609936 7547.71176119 7761.80167228]
total_rewards_mean           7479.227040884897
total_rewards_std            157.55871054396033
total_rewards_max            7761.8016722779485
total_rewards_min            7158.577678798395
Number of train steps total  500000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               144.9111647461541
(Previous) Eval Time (s)     20.907197867985815
Sample Time (s)              6.4997995514422655
Epoch Time (s)               172.31816216558218
Total Train Time (s)         21092.048303894233
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:45:10.703282 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #124 | Epoch Duration: 172.40126848220825
2020-01-12 13:45:10.703413 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8614782
Z variance train             0.043078624
KL Divergence                38.983948
KL Loss                      3.8983948
QF Loss                      132.79178
VF Loss                      27.679815
Policy Loss                  -837.3461
Q Predictions Mean           834.04736
Q Predictions Std            924.0828
Q Predictions Max            3197.9822
Q Predictions Min            343.19736
V Predictions Mean           838.538
V Predictions Std            923.52747
V Predictions Max            3189.5955
V Predictions Min            348.5128
Log Pis Mean                 -0.8053962
Log Pis Std                  3.5824857
Log Pis Max                  14.84872
Log Pis Min                  -7.847331
Policy mu Mean               -0.0021737823
Policy mu Std                0.79881424
Policy mu Max                2.5370014
Policy mu Min                -2.7086208
Policy log std Mean          -0.5094947
Policy log std Std           0.25337514
Policy log std Max           -0.1044265
Policy log std Min           -2.1129277
Z mean eval                  1.8212658
Z variance eval              0.117605925
total_rewards                [7274.54397431 7507.9341275  7550.00978697 6708.83347136 7222.65774553
 7564.12971838 7780.65193232 7428.45137594 7646.75578639 7645.93901233]
total_rewards_mean           7432.990693103985
total_rewards_std            290.2047326280812
total_rewards_max            7780.651932322306
total_rewards_min            6708.83347136245
Number of train steps total  504000
Number of env steps total    1514000
Number of rollouts total     0
Train Time (s)               144.13820491638035
(Previous) Eval Time (s)     20.630569559056312
Sample Time (s)              6.479814467951655
Epoch Time (s)               171.2485889433883
Total Train Time (s)         21263.37870433787
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:48:02.035144 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #125 | Epoch Duration: 171.3316352367401
2020-01-12 13:48:02.035279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8215317
Z variance train             0.11672181
KL Divergence                36.655712
KL Loss                      3.6655712
QF Loss                      149.31471
VF Loss                      57.795654
Policy Loss                  -790.8566
Q Predictions Mean           788.6205
Q Predictions Std            888.573
Q Predictions Max            3107.344
Q Predictions Min            336.46533
V Predictions Mean           789.4405
V Predictions Std            887.24396
V Predictions Max            3087.2327
V Predictions Min            334.96527
Log Pis Mean                 -0.9328411
Log Pis Std                  3.084996
Log Pis Max                  15.2427635
Log Pis Min                  -5.618156
Policy mu Mean               0.011956084
Policy mu Std                0.81133354
Policy mu Max                2.6818419
Policy mu Min                -2.7882009
Policy log std Mean          -0.48226514
Policy log std Std           0.22172473
Policy log std Max           -0.11087811
Policy log std Min           -1.7793108
Z mean eval                  1.8387039
Z variance eval              0.040755693
total_rewards                [7486.71964412 7554.35233355 7611.01301615 7596.06526303 7757.60126009
 7930.31481413 7651.93507861 8088.65644543 7723.9233414  7720.25936113]
total_rewards_mean           7712.0840557641595
total_rewards_std            171.66021022549253
total_rewards_max            8088.656445433169
total_rewards_min            7486.719644120486
Number of train steps total  508000
Number of env steps total    1526000
Number of rollouts total     0
Train Time (s)               144.77675651712343
(Previous) Eval Time (s)     21.065692697651684
Sample Time (s)              6.5065997168421745
Epoch Time (s)               172.3490489316173
Total Train Time (s)         21435.882258300204
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:50:54.541644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #126 | Epoch Duration: 172.50624990463257
2020-01-12 13:50:54.541836 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8380674
Z variance train             0.040642887
KL Divergence                38.916622
KL Loss                      3.8916624
QF Loss                      194.88496
VF Loss                      87.83928
Policy Loss                  -974.5589
Q Predictions Mean           971.0128
Q Predictions Std            1050.6014
Q Predictions Max            3262.919
Q Predictions Min            339.52295
V Predictions Mean           968.8373
V Predictions Std            1046.3478
V Predictions Max            3262.0293
V Predictions Min            354.64798
Log Pis Mean                 -0.57238156
Log Pis Std                  3.2350988
Log Pis Max                  10.612283
Log Pis Min                  -6.500764
Policy mu Mean               0.012811299
Policy mu Std                0.84010345
Policy mu Max                2.5021422
Policy mu Min                -2.7318747
Policy log std Mean          -0.509458
Policy log std Std           0.24321648
Policy log std Max           0.03963986
Policy log std Min           -2.086578
Z mean eval                  1.8115892
Z variance eval              0.03108282
total_rewards                [7191.94307909 7615.67641713 7547.94582077 7373.66623268 7586.27329538
 7623.90373134 7477.22216229 7591.17425389 7499.34255099 7716.16888631]
total_rewards_mean           7522.331642987978
total_rewards_std            141.38893519462454
total_rewards_max            7716.168886305765
total_rewards_min            7191.943079089541
Number of train steps total  512000
Number of env steps total    1538000
Number of rollouts total     0
Train Time (s)               144.1370548917912
(Previous) Eval Time (s)     20.85098352096975
Sample Time (s)              6.478341998066753
Epoch Time (s)               171.4663804108277
Total Train Time (s)         21607.430835161358
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:53:46.092195 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #127 | Epoch Duration: 171.55021810531616
2020-01-12 13:53:46.092402 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8122171
Z variance train             0.03117317
KL Divergence                38.859158
KL Loss                      3.8859158
QF Loss                      233.37181
VF Loss                      95.50447
Policy Loss                  -797.2854
Q Predictions Mean           791.7494
Q Predictions Std            899.7598
Q Predictions Max            3268.2913
Q Predictions Min            366.93994
V Predictions Mean           800.39795
V Predictions Std            900.7093
V Predictions Max            3257.6628
V Predictions Min            381.7176
Log Pis Mean                 -0.7087847
Log Pis Std                  3.3647661
Log Pis Max                  13.444852
Log Pis Min                  -6.998047
Policy mu Mean               -0.064943895
Policy mu Std                0.81896716
Policy mu Max                2.3753378
Policy mu Min                -3.73557
Policy log std Mean          -0.48617145
Policy log std Std           0.24131653
Policy log std Max           -0.056463778
Policy log std Min           -2.247407
Z mean eval                  1.8235004
Z variance eval              0.023325099
total_rewards                [7751.78022267 7798.52808675 7968.35544488 7968.19231113 7764.52487425
 7683.84035325 7748.49370311 8035.14914481 7803.66776556 7430.69401936]
total_rewards_mean           7795.322592575672
total_rewards_std            163.65838452198463
total_rewards_max            8035.149144807296
total_rewards_min            7430.694019356463
Number of train steps total  516000
Number of env steps total    1550000
Number of rollouts total     0
Train Time (s)               143.20219663484022
(Previous) Eval Time (s)     20.714538524858654
Sample Time (s)              6.450128743890673
Epoch Time (s)               170.36686390358955
Total Train Time (s)         21777.875229611527
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:56:36.539576 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #128 | Epoch Duration: 170.4470546245575
2020-01-12 13:56:36.539771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #128 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8205944
Z variance train             0.023453532
KL Divergence                40.743225
KL Loss                      4.0743227
QF Loss                      160.72658
VF Loss                      131.05241
Policy Loss                  -911.08704
Q Predictions Mean           911.241
Q Predictions Std            992.3962
Q Predictions Max            3220.5186
Q Predictions Min            365.47995
V Predictions Mean           920.5656
V Predictions Std            992.7454
V Predictions Max            3212.403
V Predictions Min            366.4041
Log Pis Mean                 -0.6439873
Log Pis Std                  3.2368991
Log Pis Max                  9.578053
Log Pis Min                  -11.37783
Policy mu Mean               -0.0017846028
Policy mu Std                0.8324258
Policy mu Max                2.6144614
Policy mu Min                -2.4692621
Policy log std Mean          -0.51133484
Policy log std Std           0.22946976
Policy log std Max           -0.13155514
Policy log std Min           -2.0583744
Z mean eval                  1.8370826
Z variance eval              0.030623298
total_rewards                [7640.97996849 7889.21971027 7649.08786514 7715.28459926 7597.4073414
 7639.83981536 7802.0107001  7850.27472552 7738.4543739  7647.586168  ]
total_rewards_mean           7717.01452674545
total_rewards_std            95.17211369646141
total_rewards_max            7889.219710271635
total_rewards_min            7597.407341404327
Number of train steps total  520000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               143.66975891590118
(Previous) Eval Time (s)     20.85225556930527
Sample Time (s)              6.5533627942204475
Epoch Time (s)               171.0753772794269
Total Train Time (s)         21949.042452285532
Epoch                        129
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 13:59:27.708551 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #129 | Epoch Duration: 171.1686396598816
2020-01-12 13:59:27.708696 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8380425
Z variance train             0.030589228
KL Divergence                39.637558
KL Loss                      3.9637558
QF Loss                      93.968155
VF Loss                      88.51391
Policy Loss                  -747.33936
Q Predictions Mean           747.517
Q Predictions Std            846.2245
Q Predictions Max            3216.586
Q Predictions Min            359.0986
V Predictions Mean           752.58655
V Predictions Std            848.822
V Predictions Max            3235.0527
V Predictions Min            362.4839
Log Pis Mean                 -0.9413626
Log Pis Std                  2.9979014
Log Pis Max                  10.618308
Log Pis Min                  -9.213745
Policy mu Mean               0.015732126
Policy mu Std                0.7790319
Policy mu Max                2.5679026
Policy mu Min                -2.3806226
Policy log std Mean          -0.4887898
Policy log std Std           0.23163384
Policy log std Max           -0.122729495
Policy log std Min           -2.1167278
Z mean eval                  1.8479391
Z variance eval              0.039434493
total_rewards                [7518.24289452 7722.2800696  7487.77548143 7429.12490418 7534.34898487
 7595.98867163 7541.69724786 7842.08173045 7541.76695474 7555.94746377]
total_rewards_mean           7576.925440305493
total_rewards_std            113.91468859699445
total_rewards_max            7842.081730447569
total_rewards_min            7429.124904177288
Number of train steps total  524000
Number of env steps total    1574000
Number of rollouts total     0
Train Time (s)               144.15348891029134
(Previous) Eval Time (s)     21.195497625041753
Sample Time (s)              6.63826256012544
Epoch Time (s)               171.98724909545854
Total Train Time (s)         22121.121800510213
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:02:19.791947 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #130 | Epoch Duration: 172.08315181732178
2020-01-12 14:02:19.792084 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8479557
Z variance train             0.03931167
KL Divergence                40.496727
KL Loss                      4.0496726
QF Loss                      272.22638
VF Loss                      47.3463
Policy Loss                  -856.77423
Q Predictions Mean           854.355
Q Predictions Std            953.03064
Q Predictions Max            3343.5535
Q Predictions Min            353.79312
V Predictions Mean           854.06635
V Predictions Std            949.42175
V Predictions Max            3334.4053
V Predictions Min            363.1797
Log Pis Mean                 -0.90828675
Log Pis Std                  2.9493513
Log Pis Max                  7.690044
Log Pis Min                  -9.09857
Policy mu Mean               0.02511003
Policy mu Std                0.79105455
Policy mu Max                2.5866976
Policy mu Min                -2.3657818
Policy log std Mean          -0.4940451
Policy log std Std           0.2441639
Policy log std Max           -0.022918224
Policy log std Min           -2.1897302
Z mean eval                  1.8197031
Z variance eval              0.030518552
total_rewards                [7397.96665046 7649.09541633 7915.0043156  7765.18771479 7627.25943077
 7827.56519487 7710.38332706 7969.31939292 7694.64637516 7800.79599882]
total_rewards_mean           7735.722381678136
total_rewards_std            153.59822334520595
total_rewards_max            7969.319392924116
total_rewards_min            7397.966650457985
Number of train steps total  528000
Number of env steps total    1586000
Number of rollouts total     0
Train Time (s)               145.58651711791754
(Previous) Eval Time (s)     20.872083269059658
Sample Time (s)              6.608593183103949
Epoch Time (s)               173.06719357008114
Total Train Time (s)         22294.277156444732
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:05:12.949026 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #131 | Epoch Duration: 173.15684413909912
2020-01-12 14:05:12.949170 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8235648
Z variance train             0.0304652
KL Divergence                41.281204
KL Loss                      4.1281204
QF Loss                      127.10039
VF Loss                      80.68078
Policy Loss                  -754.76166
Q Predictions Mean           750.10455
Q Predictions Std            864.94574
Q Predictions Max            3372.2593
Q Predictions Min            372.61035
V Predictions Mean           749.95746
V Predictions Std            858.0941
V Predictions Max            3339.909
V Predictions Min            378.69513
Log Pis Mean                 -0.81891453
Log Pis Std                  3.7001386
Log Pis Max                  17.78699
Log Pis Min                  -8.732503
Policy mu Mean               0.018080527
Policy mu Std                0.79340297
Policy mu Max                2.7478158
Policy mu Min                -3.406079
Policy log std Mean          -0.48622373
Policy log std Std           0.24465686
Policy log std Max           -0.05609697
Policy log std Min           -2.1441226
Z mean eval                  1.757605
Z variance eval              0.037237816
total_rewards                [7881.07257994 7989.81708583 7748.93395641 7991.94951057 8036.47424324
 7992.47590822 7937.53559505 7796.07200675 7974.62970543 7720.89631594]
total_rewards_mean           7906.985690737131
total_rewards_std            107.81822820191258
total_rewards_max            8036.474243237045
total_rewards_min            7720.896315935052
Number of train steps total  532000
Number of env steps total    1598000
Number of rollouts total     0
Train Time (s)               145.1648423038423
(Previous) Eval Time (s)     17.34565239585936
Sample Time (s)              6.628798060119152
Epoch Time (s)               169.13929275982082
Total Train Time (s)         22463.5015640771
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:08:02.190374 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #132 | Epoch Duration: 169.24107193946838
2020-01-12 14:08:02.190614 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #132 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7576202
Z variance train             0.03711044
KL Divergence                39.628704
KL Loss                      3.9628704
QF Loss                      133.92921
VF Loss                      35.76013
Policy Loss                  -974.7502
Q Predictions Mean           973.4297
Q Predictions Std            1038.7949
Q Predictions Max            3383.1897
Q Predictions Min            348.99744
V Predictions Mean           972.7655
V Predictions Std            1034.924
V Predictions Max            3357.0515
V Predictions Min            363.0363
Log Pis Mean                 -0.3085651
Log Pis Std                  3.3882356
Log Pis Max                  11.054456
Log Pis Min                  -7.7440033
Policy mu Mean               0.008387041
Policy mu Std                0.8577038
Policy mu Max                2.9050498
Policy mu Min                -2.5795345
Policy log std Mean          -0.49943212
Policy log std Std           0.24152018
Policy log std Max           -0.02792567
Policy log std Min           -1.9152899
Z mean eval                  1.7823569
Z variance eval              0.037143327
total_rewards                [7567.33352302 7811.53495751 7297.08661684 7600.50484106 7771.3780742
 7626.71215382 7756.75518457 7923.49619689 7722.24997083 7699.87773602]
total_rewards_mean           7677.692925476066
total_rewards_std            161.68969699172405
total_rewards_max            7923.496196892963
total_rewards_min            7297.0866168355315
Number of train steps total  536000
Number of env steps total    1610000
Number of rollouts total     0
Train Time (s)               144.92839886480942
(Previous) Eval Time (s)     20.740257733967155
Sample Time (s)              6.547158513683826
Epoch Time (s)               172.2158151124604
Total Train Time (s)         22635.814114558045
Epoch                        133
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:10:54.490164 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #133 | Epoch Duration: 172.29934668540955
2020-01-12 14:10:54.490313 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7825352
Z variance train             0.03731131
KL Divergence                40.43791
KL Loss                      4.043791
QF Loss                      1477.6377
VF Loss                      119.07679
Policy Loss                  -904.93884
Q Predictions Mean           901.77795
Q Predictions Std            947.6556
Q Predictions Max            3289.3762
Q Predictions Min            376.32318
V Predictions Mean           898.86743
V Predictions Std            945.36224
V Predictions Max            3270.4958
V Predictions Min            371.70676
Log Pis Mean                 -0.44075337
Log Pis Std                  3.5242155
Log Pis Max                  18.338017
Log Pis Min                  -7.886421
Policy mu Mean               0.04639278
Policy mu Std                0.8351306
Policy mu Max                2.9326546
Policy mu Min                -3.1506448
Policy log std Mean          -0.5185037
Policy log std Std           0.22951162
Policy log std Max           -0.12466842
Policy log std Min           -1.7184132
Z mean eval                  1.7542607
Z variance eval              0.020346548
total_rewards                [7944.3257592  7951.87777148 7855.64003529 7914.91240557 7987.81542741
 8093.280855   7807.75311511 7827.78479155 7732.1812168  8253.40491732]
total_rewards_mean           7936.897629471519
total_rewards_std            143.2074207863683
total_rewards_max            8253.404917315227
total_rewards_min            7732.1812168032575
Number of train steps total  540000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               145.91817820305005
(Previous) Eval Time (s)     17.87191461166367
Sample Time (s)              6.513427016790956
Epoch Time (s)               170.30351983150467
Total Train Time (s)         22806.203911382705
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:13:44.882971 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #134 | Epoch Duration: 170.3925404548645
2020-01-12 14:13:44.883176 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7522285
Z variance train             0.020341175
KL Divergence                41.112865
KL Loss                      4.1112866
QF Loss                      94.04376
VF Loss                      36.160748
Policy Loss                  -858.77277
Q Predictions Mean           854.3943
Q Predictions Std            947.5762
Q Predictions Max            3205.154
Q Predictions Min            326.87268
V Predictions Mean           857.1903
V Predictions Std            947.2093
V Predictions Max            3216.1804
V Predictions Min            342.64603
Log Pis Mean                 -0.730898
Log Pis Std                  3.1874325
Log Pis Max                  10.018614
Log Pis Min                  -6.873829
Policy mu Mean               0.0051218886
Policy mu Std                0.8281799
Policy mu Max                2.444793
Policy mu Min                -2.4050725
Policy log std Mean          -0.5197401
Policy log std Std           0.24925742
Policy log std Max           0.027904749
Policy log std Min           -1.8916998
Z mean eval                  1.7438694
Z variance eval              0.061626665
total_rewards                [7117.68505309 7603.99170577 7584.44224309 7338.99471001 7264.31043503
 7223.47613799 7249.63332826 7418.92431003 7387.40662598 6679.95566024]
total_rewards_mean           7286.882020950361
total_rewards_std            249.45163890752735
total_rewards_max            7603.991705768416
total_rewards_min            6679.9556602420735
Number of train steps total  544000
Number of env steps total    1634000
Number of rollouts total     0
Train Time (s)               145.06978103285655
(Previous) Eval Time (s)     21.062059884890914
Sample Time (s)              6.496819732710719
Epoch Time (s)               172.6286606504582
Total Train Time (s)         22978.912667525932
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:16:37.593020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #135 | Epoch Duration: 172.7096869945526
2020-01-12 14:16:37.593200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7433312
Z variance train             0.061525095
KL Divergence                39.24685
KL Loss                      3.924685
QF Loss                      114.83
VF Loss                      28.056816
Policy Loss                  -825.9537
Q Predictions Mean           822.30676
Q Predictions Std            914.09955
Q Predictions Max            3260.5317
Q Predictions Min            352.80777
V Predictions Mean           826.3916
V Predictions Std            914.51337
V Predictions Max            3261.9443
V Predictions Min            352.82248
Log Pis Mean                 -1.2569757
Log Pis Std                  3.0577667
Log Pis Max                  15.1072235
Log Pis Min                  -6.422102
Policy mu Mean               0.0202483
Policy mu Std                0.7696679
Policy mu Max                2.6683629
Policy mu Min                -2.4379058
Policy log std Mean          -0.48846373
Policy log std Std           0.23951235
Policy log std Max           -0.053191185
Policy log std Min           -1.9285353
Z mean eval                  1.728949
Z variance eval              0.027616441
total_rewards                [7612.87997847 7828.63250911 7691.70914418 7700.16060753 7952.91692192
 7657.40032278 7812.63787619 7754.90720842 7612.7274899  7685.72470905]
total_rewards_mean           7730.969676755973
total_rewards_std            101.94010270033357
total_rewards_max            7952.91692191959
total_rewards_min            7612.727489899622
Number of train steps total  548000
Number of env steps total    1646000
Number of rollouts total     0
Train Time (s)               144.42203078093007
(Previous) Eval Time (s)     20.776827164459974
Sample Time (s)              6.510994164273143
Epoch Time (s)               171.7098521096632
Total Train Time (s)         23150.85191868851
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:19:29.543911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #136 | Epoch Duration: 171.95056653022766
2020-01-12 14:19:29.544093 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7306238
Z variance train             0.027589971
KL Divergence                42.04811
KL Loss                      4.204811
QF Loss                      169.19385
VF Loss                      89.48551
Policy Loss                  -928.0183
Q Predictions Mean           925.94775
Q Predictions Std            996.8748
Q Predictions Max            3348.1921
Q Predictions Min            382.79813
V Predictions Mean           929.59546
V Predictions Std            998.4992
V Predictions Max            3351.2595
V Predictions Min            382.09912
Log Pis Mean                 -0.5398996
Log Pis Std                  3.2918835
Log Pis Max                  13.204885
Log Pis Min                  -7.302284
Policy mu Mean               -0.017130135
Policy mu Std                0.8295032
Policy mu Max                2.6592708
Policy mu Min                -2.7927608
Policy log std Mean          -0.5225695
Policy log std Std           0.2628406
Policy log std Max           -0.04151994
Policy log std Min           -2.1002548
Z mean eval                  1.6812592
Z variance eval              0.025864538
total_rewards                [7377.15145713 7470.03544018 7664.36614661 7508.59010866 7525.81416817
 7584.33098895 7635.74159948 7458.48776678 7437.95551676 7449.2646189 ]
total_rewards_mean           7511.173781162911
total_rewards_std            87.28221852058482
total_rewards_max            7664.366146605943
total_rewards_min            7377.151457132921
Number of train steps total  552000
Number of env steps total    1658000
Number of rollouts total     0
Train Time (s)               143.812108641956
(Previous) Eval Time (s)     17.4887810270302
Sample Time (s)              5.673709979280829
Epoch Time (s)               166.97459964826703
Total Train Time (s)         23317.917296231724
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:22:16.604091 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #137 | Epoch Duration: 167.05982613563538
2020-01-12 14:22:16.604378 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6811397
Z variance train             0.025929365
KL Divergence                41.697178
KL Loss                      4.169718
QF Loss                      1767.4293
VF Loss                      144.35196
Policy Loss                  -876.65405
Q Predictions Mean           879.4187
Q Predictions Std            960.37305
Q Predictions Max            3443.4258
Q Predictions Min            387.0552
V Predictions Mean           866.4966
V Predictions Std            954.21
V Predictions Max            3393.4272
V Predictions Min            382.9134
Log Pis Mean                 -0.8673366
Log Pis Std                  3.1024299
Log Pis Max                  12.520013
Log Pis Min                  -6.6202993
Policy mu Mean               0.0067869616
Policy mu Std                0.7825978
Policy mu Max                2.4569364
Policy mu Min                -2.6164176
Policy log std Mean          -0.50242925
Policy log std Std           0.24937904
Policy log std Max           -0.12986861
Policy log std Min           -1.8865056
Z mean eval                  1.7189758
Z variance eval              0.037884094
total_rewards                [7655.99150435 8070.7595127  2245.05594351 1965.09104499 3555.83140443
 8313.42508517 8020.45867633 7955.39379837 8035.1032499  7967.98008008]
total_rewards_mean           6378.509029982279
total_rewards_std            2514.439537110721
total_rewards_max            8313.425085166607
total_rewards_min            1965.091044985128
Number of train steps total  556000
Number of env steps total    1670000
Number of rollouts total     0
Train Time (s)               144.8537277309224
(Previous) Eval Time (s)     20.79012955306098
Sample Time (s)              6.458876014687121
Epoch Time (s)               172.1027332986705
Total Train Time (s)         23490.1010904368
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:25:08.787562 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #138 | Epoch Duration: 172.18297958374023
2020-01-12 14:25:08.787697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7218851
Z variance train             0.037715405
KL Divergence                42.475815
KL Loss                      4.2475815
QF Loss                      125.01979
VF Loss                      221.5585
Policy Loss                  -835.0908
Q Predictions Mean           831.423
Q Predictions Std            928.86206
Q Predictions Max            3451.9705
Q Predictions Min            380.3439
V Predictions Mean           821.80566
V Predictions Std            923.9096
V Predictions Max            3402.9802
V Predictions Min            385.3197
Log Pis Mean                 -0.7199174
Log Pis Std                  3.513939
Log Pis Max                  12.84791
Log Pis Min                  -7.2545214
Policy mu Mean               0.037523832
Policy mu Std                0.8159522
Policy mu Max                2.5374956
Policy mu Min                -2.8244612
Policy log std Mean          -0.49065864
Policy log std Std           0.23238008
Policy log std Max           -0.105009764
Policy log std Min           -1.9795783
Z mean eval                  1.705257
Z variance eval              0.017931748
total_rewards                [7729.36060135 7923.53621912 7807.07155965 7793.84426823 7942.65444242
 7870.73379172 7779.94549926 8228.05877882 7929.44083617 8183.05282024]
total_rewards_mean           7918.769881696554
total_rewards_std            158.66651430012783
total_rewards_max            8228.058778816141
total_rewards_min            7729.360601348091
Number of train steps total  560000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               144.2350407759659
(Previous) Eval Time (s)     20.72712330520153
Sample Time (s)              6.496301501523703
Epoch Time (s)               171.45846558269113
Total Train Time (s)         23661.656405152287
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:28:00.346687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #139 | Epoch Duration: 171.5588402748108
2020-01-12 14:28:00.346923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7078613
Z variance train             0.017957583
KL Divergence                44.437557
KL Loss                      4.4437556
QF Loss                      154.91199
VF Loss                      68.56824
Policy Loss                  -962.73395
Q Predictions Mean           960.1465
Q Predictions Std            1021.94604
Q Predictions Max            3434.551
Q Predictions Min            392.46188
V Predictions Mean           958.04315
V Predictions Std            1020.32684
V Predictions Max            3418.9783
V Predictions Min            385.89203
Log Pis Mean                 -0.27193367
Log Pis Std                  3.2791479
Log Pis Max                  12.361637
Log Pis Min                  -6.551708
Policy mu Mean               0.0127997175
Policy mu Std                0.8657557
Policy mu Max                2.821607
Policy mu Min                -3.3552132
Policy log std Mean          -0.50450176
Policy log std Std           0.23145266
Policy log std Max           -0.09376097
Policy log std Min           -1.8115304
Z mean eval                  1.6705122
Z variance eval              0.026523083
total_rewards                [7599.08982906 7823.06249443 7565.48927858 7825.88369551 7591.76505827
 7632.69361859 7555.71878536 7755.46039005 7562.97507837 7974.6254303 ]
total_rewards_mean           7688.676365852504
total_rewards_std            138.67864423690102
total_rewards_max            7974.6254303041005
total_rewards_min            7555.718785360357
Number of train steps total  564000
Number of env steps total    1694000
Number of rollouts total     0
Train Time (s)               144.3819398516789
(Previous) Eval Time (s)     17.3527836878784
Sample Time (s)              6.581952096428722
Epoch Time (s)               168.31667563598603
Total Train Time (s)         23830.049204952084
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:30:48.743985 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #140 | Epoch Duration: 168.39689111709595
2020-01-12 14:30:48.744156 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #140 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6724755
Z variance train             0.026457597
KL Divergence                42.818604
KL Loss                      4.2818604
QF Loss                      212.34251
VF Loss                      135.14429
Policy Loss                  -939.9152
Q Predictions Mean           936.70435
Q Predictions Std            1014.29156
Q Predictions Max            3321.5918
Q Predictions Min            370.92145
V Predictions Mean           937.4798
V Predictions Std            1013.2774
V Predictions Max            3303.4026
V Predictions Min            374.76117
Log Pis Mean                 -0.6871144
Log Pis Std                  3.2557454
Log Pis Max                  13.116561
Log Pis Min                  -5.780411
Policy mu Mean               -0.07012439
Policy mu Std                0.83426267
Policy mu Max                3.516344
Policy mu Min                -2.5265033
Policy log std Mean          -0.51904243
Policy log std Std           0.26120734
Policy log std Max           -0.09599924
Policy log std Min           -2.169716
Z mean eval                  1.6975071
Z variance eval              0.042786114
total_rewards                [7822.48092932 7963.63732946 7960.46507618 8081.4886635  7926.4575578
 7718.57177261 7926.617254   7555.4719304  8040.40341715 8069.8527669 ]
total_rewards_mean           7906.54466973322
total_rewards_std            157.42048926383583
total_rewards_max            8081.488663503195
total_rewards_min            7555.471930399506
Number of train steps total  568000
Number of env steps total    1706000
Number of rollouts total     0
Train Time (s)               143.56427943194285
(Previous) Eval Time (s)     17.456223923247308
Sample Time (s)              5.601957100909203
Epoch Time (s)               166.62246045609936
Total Train Time (s)         23996.752792484593
Epoch                        141
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:33:35.449086 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #141 | Epoch Duration: 166.70479369163513
2020-01-12 14:33:35.449264 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7005589
Z variance train             0.04286251
KL Divergence                40.545593
KL Loss                      4.054559
QF Loss                      115.20897
VF Loss                      64.20511
Policy Loss                  -873.6405
Q Predictions Mean           871.32886
Q Predictions Std            969.471
Q Predictions Max            3401.6274
Q Predictions Min            395.1911
V Predictions Mean           871.6726
V Predictions Std            966.0788
V Predictions Max            3389.8289
V Predictions Min            397.75433
Log Pis Mean                 -0.8109594
Log Pis Std                  3.3118546
Log Pis Max                  12.546728
Log Pis Min                  -8.114454
Policy mu Mean               0.020435216
Policy mu Std                0.8312705
Policy mu Max                2.6438537
Policy mu Min                -2.7610672
Policy log std Mean          -0.48820606
Policy log std Std           0.23731178
Policy log std Max           -0.057269335
Policy log std Min           -1.8393135
Z mean eval                  1.6875916
Z variance eval              0.06020399
total_rewards                [7761.20754889 8237.20550767 8100.50827142 8114.43361214 8149.25941424
 8261.25916381 7898.71588142 7889.82849439 8199.70635419 8049.27487356]
total_rewards_mean           8066.139912174387
total_rewards_std            157.47443277164214
total_rewards_max            8261.259163808392
total_rewards_min            7761.207548891672
Number of train steps total  572000
Number of env steps total    1718000
Number of rollouts total     0
Train Time (s)               144.45822208793834
(Previous) Eval Time (s)     20.775319639593363
Sample Time (s)              6.494182187598199
Epoch Time (s)               171.7277239151299
Total Train Time (s)         24168.55801911885
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:36:27.254923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #142 | Epoch Duration: 171.8055284023285
2020-01-12 14:36:27.255064 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6896021
Z variance train             0.060075562
KL Divergence                40.33764
KL Loss                      4.033764
QF Loss                      189.56665
VF Loss                      130.34213
Policy Loss                  -902.52246
Q Predictions Mean           901.5034
Q Predictions Std            989.2753
Q Predictions Max            3351.882
Q Predictions Min            -37.8254
V Predictions Mean           895.41144
V Predictions Std            982.9141
V Predictions Max            3335.178
V Predictions Min            -214.0032
Log Pis Mean                 -0.8451228
Log Pis Std                  3.2761903
Log Pis Max                  12.555388
Log Pis Min                  -8.651445
Policy mu Mean               -0.036097694
Policy mu Std                0.810494
Policy mu Max                2.594103
Policy mu Min                -3.5895154
Policy log std Mean          -0.4847399
Policy log std Std           0.2377035
Policy log std Max           1.291451
Policy log std Min           -1.7998374
Z mean eval                  1.7047834
Z variance eval              0.030617535
total_rewards                [8066.2851058  8135.31650548 8126.91911162 8042.00357605 8213.3063808
 8138.23561531 8019.70712105 7888.50909691 7792.18019781 8210.1312531 ]
total_rewards_mean           8063.259396392452
total_rewards_std            128.5811121867668
total_rewards_max            8213.306380795511
total_rewards_min            7792.18019781153
Number of train steps total  576000
Number of env steps total    1730000
Number of rollouts total     0
Train Time (s)               145.63712676102296
(Previous) Eval Time (s)     21.089483039919287
Sample Time (s)              6.348131220322102
Epoch Time (s)               173.07474102126434
Total Train Time (s)         24341.711929821875
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:39:20.410298 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #143 | Epoch Duration: 173.15513491630554
2020-01-12 14:39:20.410439 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.704064
Z variance train             0.030686613
KL Divergence                42.12398
KL Loss                      4.212398
QF Loss                      113.489235
VF Loss                      45.46874
Policy Loss                  -1010.97015
Q Predictions Mean           1008.9187
Q Predictions Std            1047.8348
Q Predictions Max            3357.4624
Q Predictions Min            400.6333
V Predictions Mean           1009.1583
V Predictions Std            1048.1937
V Predictions Max            3351.5803
V Predictions Min            404.53513
Log Pis Mean                 -0.32177144
Log Pis Std                  3.538132
Log Pis Max                  16.532534
Log Pis Min                  -7.637881
Policy mu Mean               0.020259513
Policy mu Std                0.86021394
Policy mu Max                3.0817642
Policy mu Min                -3.2480564
Policy log std Mean          -0.5148467
Policy log std Std           0.25031292
Policy log std Max           -0.1017762
Policy log std Min           -2.1335037
Z mean eval                  1.6947591
Z variance eval              0.027009126
total_rewards                [8047.00475501 7568.39073529 8183.222503   8404.10145962 8132.54909948
 8200.20613759 8215.7009197  7886.8765491  8364.38421852 8050.43495691]
total_rewards_mean           8105.287133420633
total_rewards_std            229.5225003774886
total_rewards_max            8404.101459616077
total_rewards_min            7568.39073529063
Number of train steps total  580000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               144.97247170098126
(Previous) Eval Time (s)     17.71156317880377
Sample Time (s)              6.4146450138650835
Epoch Time (s)               169.09867989365011
Total Train Time (s)         24510.892487373203
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:42:09.594548 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #144 | Epoch Duration: 169.18398070335388
2020-01-12 14:42:09.594817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #144 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.695317
Z variance train             0.0269678
KL Divergence                44.231728
KL Loss                      4.423173
QF Loss                      191.128
VF Loss                      48.93306
Policy Loss                  -1007.4997
Q Predictions Mean           1006.8425
Q Predictions Std            1065.3776
Q Predictions Max            3397.6692
Q Predictions Min            414.46292
V Predictions Mean           1003.80365
V Predictions Std            1061.5966
V Predictions Max            3369.1838
V Predictions Min            414.07217
Log Pis Mean                 -0.34204376
Log Pis Std                  3.390381
Log Pis Max                  11.930021
Log Pis Min                  -6.46827
Policy mu Mean               0.012326922
Policy mu Std                0.85887545
Policy mu Max                2.5322452
Policy mu Min                -2.492989
Policy log std Mean          -0.51445174
Policy log std Std           0.25449014
Policy log std Max           -0.062910855
Policy log std Min           -2.1959438
Z mean eval                  1.6749115
Z variance eval              0.035684813
total_rewards                [7794.33898786 7300.87560858 8461.92328295 8108.01400382 8127.2587326
 8413.23290417 8218.19622205 7924.93592859 7921.8125087  7480.93612209]
total_rewards_mean           7975.152430140026
total_rewards_std            355.7637574371275
total_rewards_max            8461.923282951328
total_rewards_min            7300.875608579461
Number of train steps total  584000
Number of env steps total    1754000
Number of rollouts total     0
Train Time (s)               144.5382714830339
(Previous) Eval Time (s)     20.85779401101172
Sample Time (s)              6.625020549166948
Epoch Time (s)               172.02108604321256
Total Train Time (s)         24682.995791705325
Epoch                        145
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:45:01.697795 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #145 | Epoch Duration: 172.10280060768127
2020-01-12 14:45:01.697924 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6735172
Z variance train             0.035613935
KL Divergence                42.52622
KL Loss                      4.252622
QF Loss                      255.3846
VF Loss                      54.65725
Policy Loss                  -946.40344
Q Predictions Mean           944.51465
Q Predictions Std            1009.6555
Q Predictions Max            3366.6094
Q Predictions Min            405.49487
V Predictions Mean           947.6812
V Predictions Std            1008.7205
V Predictions Max            3344.1775
V Predictions Min            407.7072
Log Pis Mean                 -0.67166626
Log Pis Std                  3.4005477
Log Pis Max                  19.14407
Log Pis Min                  -8.47286
Policy mu Mean               0.05054474
Policy mu Std                0.83535284
Policy mu Max                2.9949129
Policy mu Min                -2.993559
Policy log std Mean          -0.50306886
Policy log std Std           0.24255756
Policy log std Max           0.13695478
Policy log std Min           -2.1443942
Z mean eval                  1.6885169
Z variance eval              0.054299813
total_rewards                [8070.53551971 7833.99562536 8110.71489802 8028.12992089 8164.66064777
 8206.10809325 8162.95653143 8005.88883926 8306.53690481 8258.89763593]
total_rewards_mean           8114.842461644772
total_rewards_std            130.71722440527535
total_rewards_max            8306.536904810138
total_rewards_min            7833.99562536325
Number of train steps total  588000
Number of env steps total    1766000
Number of rollouts total     0
Train Time (s)               144.33919181581587
(Previous) Eval Time (s)     17.89652494667098
Sample Time (s)              6.5246032061986625
Epoch Time (s)               168.7603199686855
Total Train Time (s)         24851.830140058417
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:47:50.532898 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #146 | Epoch Duration: 168.83488082885742
2020-01-12 14:47:50.533016 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6845795
Z variance train             0.054148454
KL Divergence                41.15885
KL Loss                      4.1158853
QF Loss                      1865.0337
VF Loss                      160.36479
Policy Loss                  -873.4857
Q Predictions Mean           878.23566
Q Predictions Std            966.9287
Q Predictions Max            3396.9275
Q Predictions Min            410.0483
V Predictions Mean           882.6689
V Predictions Std            969.22736
V Predictions Max            3403.336
V Predictions Min            415.13788
Log Pis Mean                 -0.88807666
Log Pis Std                  3.4574506
Log Pis Max                  17.322197
Log Pis Min                  -6.8684244
Policy mu Mean               -0.057982665
Policy mu Std                0.81074435
Policy mu Max                2.4160388
Policy mu Min                -2.4674015
Policy log std Mean          -0.48417187
Policy log std Std           0.24627773
Policy log std Max           -0.07049495
Policy log std Min           -2.2624598
Z mean eval                  1.6995739
Z variance eval              0.034144156
total_rewards                [7859.22454082 8193.77730818 8013.94709021 7893.8453172  7969.60654873
 7947.76834788 8168.4819226  8004.80341609 7894.78993762 7613.99045009]
total_rewards_mean           7956.023487942997
total_rewards_std            155.44293010992695
total_rewards_max            8193.777308182089
total_rewards_min            7613.990450090866
Number of train steps total  592000
Number of env steps total    1778000
Number of rollouts total     0
Train Time (s)               142.9382596379146
(Previous) Eval Time (s)     20.754752404987812
Sample Time (s)              5.592764784581959
Epoch Time (s)               169.28577682748437
Total Train Time (s)         25021.19689891627
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:50:39.902128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #147 | Epoch Duration: 169.3690047264099
2020-01-12 14:50:39.902318 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #147 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6993278
Z variance train             0.03419941
KL Divergence                42.05922
KL Loss                      4.205922
QF Loss                      127.78282
VF Loss                      82.48812
Policy Loss                  -968.53265
Q Predictions Mean           967.4706
Q Predictions Std            1025.1672
Q Predictions Max            3507.7
Q Predictions Min            410.52313
V Predictions Mean           967.31824
V Predictions Std            1018.34875
V Predictions Max            3496.1433
V Predictions Min            416.84415
Log Pis Mean                 -0.7544557
Log Pis Std                  3.5216048
Log Pis Max                  13.356436
Log Pis Min                  -6.9355893
Policy mu Mean               -0.013523284
Policy mu Std                0.82396203
Policy mu Max                2.5335357
Policy mu Min                -2.59347
Policy log std Mean          -0.4910238
Policy log std Std           0.23108871
Policy log std Max           -0.083204165
Policy log std Min           -1.9751276
Z mean eval                  1.7093856
Z variance eval              0.06678541
total_rewards                [8372.47539888 8305.17977573 8115.75673478 8009.44016377 8122.9854833
 8193.21883932 8217.34464894 7989.21889769 8407.38607461 8120.50726524]
total_rewards_mean           8185.351328225724
total_rewards_std            134.94795300136974
total_rewards_max            8407.38607460596
total_rewards_min            7989.218897694061
Number of train steps total  596000
Number of env steps total    1790000
Number of rollouts total     0
Train Time (s)               143.79131935117766
(Previous) Eval Time (s)     20.44189016101882
Sample Time (s)              6.652902956586331
Epoch Time (s)               170.8861124687828
Total Train Time (s)         25192.165222160518
Epoch                        148
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:53:30.871925 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #148 | Epoch Duration: 170.96947979927063
2020-01-12 14:53:30.872070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7067196
Z variance train             0.06699556
KL Divergence                41.9236
KL Loss                      4.19236
QF Loss                      117.38296
VF Loss                      54.455948
Policy Loss                  -954.1566
Q Predictions Mean           952.3406
Q Predictions Std            1012.92316
Q Predictions Max            3471.4036
Q Predictions Min            403.38727
V Predictions Mean           958.19775
V Predictions Std            1011.96454
V Predictions Max            3453.7761
V Predictions Min            412.05
Log Pis Mean                 -0.9010433
Log Pis Std                  3.287745
Log Pis Max                  16.721191
Log Pis Min                  -9.495697
Policy mu Mean               0.031325307
Policy mu Std                0.8124128
Policy mu Max                2.7134693
Policy mu Min                -2.8730044
Policy log std Mean          -0.4850712
Policy log std Std           0.2469268
Policy log std Max           -0.08359355
Policy log std Min           -2.003707
Z mean eval                  1.715669
Z variance eval              0.090698436
total_rewards                [7748.58073103 6361.36515373 8195.59929725 7651.27935657 8296.16102852
 7694.80208715 8164.96740115 8046.92387212 7678.53043689 7984.44784922]
total_rewards_mean           7782.26572136293
total_rewards_std            524.211463341087
total_rewards_max            8296.161028523882
total_rewards_min            6361.365153725585
Number of train steps total  600000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               145.54839417291805
(Previous) Eval Time (s)     17.664936828892678
Sample Time (s)              6.532973472028971
Epoch Time (s)               169.7463044738397
Total Train Time (s)         25361.99229719583
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:56:20.703049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #149 | Epoch Duration: 169.83085560798645
2020-01-12 14:56:20.703257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7178047
Z variance train             0.090257175
KL Divergence                40.92842
KL Loss                      4.092842
QF Loss                      175.07375
VF Loss                      136.16455
Policy Loss                  -986.78674
Q Predictions Mean           985.84875
Q Predictions Std            1042.5785
Q Predictions Max            3481.0479
Q Predictions Min            426.7741
V Predictions Mean           981.5595
V Predictions Std            1036.049
V Predictions Max            3461.1594
V Predictions Min            425.38358
Log Pis Mean                 -0.65893745
Log Pis Std                  3.4786277
Log Pis Max                  13.423782
Log Pis Min                  -7.2981043
Policy mu Mean               0.07259724
Policy mu Std                0.8542108
Policy mu Max                3.1013567
Policy mu Min                -2.3794746
Policy log std Mean          -0.501889
Policy log std Std           0.24229398
Policy log std Max           0.16486758
Policy log std Min           -2.094708
Z mean eval                  1.7175245
Z variance eval              0.083317116
total_rewards                [8167.88559685 8560.58897746 8351.27164624 8474.53364765 8248.41556732
 8340.90596232 8366.69041814 8209.67102664 8382.10477929 8013.19984604]
total_rewards_mean           8311.52674679435
total_rewards_std            149.3518186974628
total_rewards_max            8560.588977455489
total_rewards_min            8013.199846044453
Number of train steps total  604000
Number of env steps total    1814000
Number of rollouts total     0
Train Time (s)               142.83142576320097
(Previous) Eval Time (s)     17.749417902436107
Sample Time (s)              6.607822792604566
Epoch Time (s)               167.18866645824164
Total Train Time (s)         25529.259678859264
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 14:59:07.975577 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #150 | Epoch Duration: 167.272141456604
2020-01-12 14:59:07.975853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7179791
Z variance train             0.08380818
KL Divergence                40.16949
KL Loss                      4.016949
QF Loss                      1820.9321
VF Loss                      77.984406
Policy Loss                  -868.7331
Q Predictions Mean           868.7505
Q Predictions Std            920.84644
Q Predictions Max            3464.788
Q Predictions Min            414.7245
V Predictions Mean           875.4043
V Predictions Std            923.4088
V Predictions Max            3488.4612
V Predictions Min            421.67474
Log Pis Mean                 -0.89485383
Log Pis Std                  2.8976307
Log Pis Max                  12.021347
Log Pis Min                  -6.5136757
Policy mu Mean               -0.037747316
Policy mu Std                0.78664505
Policy mu Max                2.3581557
Policy mu Min                -2.7024503
Policy log std Mean          -0.49788514
Policy log std Std           0.24290256
Policy log std Max           0.011012733
Policy log std Min           -1.9909074
Z mean eval                  1.6884816
Z variance eval              0.07300848
total_rewards                [8115.59048734 8309.91026612 8316.04341789 5404.62943859 8199.53613459
 8583.06666864 8097.05125076 8220.6344292  8161.87534571 7937.79186665]
total_rewards_mean           7934.6129305484865
total_rewards_std            858.5124357528223
total_rewards_max            8583.066668639794
total_rewards_min            5404.629438591676
Number of train steps total  608000
Number of env steps total    1826000
Number of rollouts total     0
Train Time (s)               144.23151679104194
(Previous) Eval Time (s)     18.06207419699058
Sample Time (s)              6.582823527511209
Epoch Time (s)               168.87641451554373
Total Train Time (s)         25698.40862738993
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:01:57.142585 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #151 | Epoch Duration: 169.16652417182922
2020-01-12 15:01:57.142844 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.686836
Z variance train             0.0731434
KL Divergence                39.18359
KL Loss                      3.918359
QF Loss                      125.93544
VF Loss                      62.008263
Policy Loss                  -1010.30054
Q Predictions Mean           1006.9208
Q Predictions Std            1051.7389
Q Predictions Max            3697.2412
Q Predictions Min            427.8624
V Predictions Mean           1010.87366
V Predictions Std            1049.6222
V Predictions Max            3678.5056
V Predictions Min            438.3128
Log Pis Mean                 -0.7162546
Log Pis Std                  3.2384782
Log Pis Max                  12.120918
Log Pis Min                  -7.180093
Policy mu Mean               0.040409535
Policy mu Std                0.81921166
Policy mu Max                2.7138135
Policy mu Min                -2.8687184
Policy log std Mean          -0.48667845
Policy log std Std           0.24769405
Policy log std Max           -0.08386749
Policy log std Min           -2.1219926
Z mean eval                  1.6921375
Z variance eval              0.040080428
total_rewards                [8238.45074808 8551.36852417 8340.33021775 8493.60408402 8345.14772428
 8451.59515246 2590.3589485  8534.67624352 8563.24927174 8689.25094588]
total_rewards_mean           7879.803186040503
total_rewards_std            1767.5219843044065
total_rewards_max            8689.250945882563
total_rewards_min            2590.358948500473
Number of train steps total  612000
Number of env steps total    1838000
Number of rollouts total     0
Train Time (s)               142.83559004683048
(Previous) Eval Time (s)     17.5953217279166
Sample Time (s)              6.655787009745836
Epoch Time (s)               167.0866987844929
Total Train Time (s)         25865.605095817707
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:04:44.332549 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #152 | Epoch Duration: 167.18949699401855
2020-01-12 15:04:44.332879 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.693256
Z variance train             0.039960526
KL Divergence                41.038578
KL Loss                      4.103858
QF Loss                      136.55568
VF Loss                      66.44627
Policy Loss                  -942.7849
Q Predictions Mean           941.016
Q Predictions Std            1012.2404
Q Predictions Max            3522.7097
Q Predictions Min            412.33347
V Predictions Mean           942.74115
V Predictions Std            1011.7556
V Predictions Max            3520.0256
V Predictions Min            418.80405
Log Pis Mean                 -0.40801388
Log Pis Std                  3.3802607
Log Pis Max                  15.222777
Log Pis Min                  -7.1442385
Policy mu Mean               0.07008668
Policy mu Std                0.8282158
Policy mu Max                3.059695
Policy mu Min                -2.3629947
Policy log std Mean          -0.50592726
Policy log std Std           0.25840732
Policy log std Max           -0.048333526
Policy log std Min           -2.3577027
Z mean eval                  1.6963199
Z variance eval              0.04144279
total_rewards                [8253.8986913  8382.55545374 8290.22866372 8398.21415992 8497.28918823
 8213.24626783 8567.89602969 8591.49202666 8571.89852553 8200.77476557]
total_rewards_mean           8396.749377219861
total_rewards_std            145.61503610956134
total_rewards_max            8591.492026664331
total_rewards_min            8200.774765567403
Number of train steps total  616000
Number of env steps total    1850000
Number of rollouts total     0
Train Time (s)               144.7978356280364
(Previous) Eval Time (s)     18.97120857099071
Sample Time (s)              6.41348764160648
Epoch Time (s)               170.1825318406336
Total Train Time (s)         26035.876702698413
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:07:34.601915 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #153 | Epoch Duration: 170.26880526542664
2020-01-12 15:07:34.602085 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6955321
Z variance train             0.04150478
KL Divergence                41.28817
KL Loss                      4.128817
QF Loss                      143.51904
VF Loss                      67.00545
Policy Loss                  -971.3444
Q Predictions Mean           969.0608
Q Predictions Std            1012.7698
Q Predictions Max            3600.9263
Q Predictions Min            431.1245
V Predictions Mean           969.1841
V Predictions Std            1012.0774
V Predictions Max            3585.1094
V Predictions Min            431.19998
Log Pis Mean                 -0.63043904
Log Pis Std                  3.3967545
Log Pis Max                  11.379036
Log Pis Min                  -6.421377
Policy mu Mean               0.05623454
Policy mu Std                0.8380802
Policy mu Max                2.9975736
Policy mu Min                -3.0059075
Policy log std Mean          -0.5071673
Policy log std Std           0.2574827
Policy log std Max           -0.083399095
Policy log std Min           -2.121602
Z mean eval                  1.6824646
Z variance eval              0.03998089
total_rewards                [5943.84393829 7112.13828745 6304.53690215 6150.57977367 6837.87557596
 6697.69185472 6641.25379834 6296.21262397 5408.17388127 7632.39623994]
total_rewards_mean           6502.470287575382
total_rewards_std            594.4233814480615
total_rewards_max            7632.396239935801
total_rewards_min            5408.173881268125
Number of train steps total  620000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               144.73534564767033
(Previous) Eval Time (s)     17.482065471820533
Sample Time (s)              6.440991132054478
Epoch Time (s)               168.65840225154534
Total Train Time (s)         26204.624225288164
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:10:23.352315 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #154 | Epoch Duration: 168.75010299682617
2020-01-12 15:10:23.352477 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6773704
Z variance train             0.03989289
KL Divergence                41.444878
KL Loss                      4.144488
QF Loss                      300.15588
VF Loss                      176.63162
Policy Loss                  -932.2978
Q Predictions Mean           929.87787
Q Predictions Std            988.4613
Q Predictions Max            3419.7405
Q Predictions Min            422.8435
V Predictions Mean           939.0667
V Predictions Std            991.24963
V Predictions Max            3439.8638
V Predictions Min            427.20093
Log Pis Mean                 -0.58376443
Log Pis Std                  3.6474376
Log Pis Max                  12.717672
Log Pis Min                  -11.097915
Policy mu Mean               0.084276915
Policy mu Std                0.8590956
Policy mu Max                2.742898
Policy mu Min                -2.9587474
Policy log std Mean          -0.5016393
Policy log std Std           0.2567651
Policy log std Max           -0.09008881
Policy log std Min           -2.2405252
Z mean eval                  1.6808002
Z variance eval              0.039493173
total_rewards                [8080.76744991 8515.91389213 8238.1743592  7423.01857417 8185.88102562
 8361.52447008 7968.03710633 8352.09827542 8153.4835897  8246.0441083 ]
total_rewards_mean           8152.494285086135
total_rewards_std            283.57035849455036
total_rewards_max            8515.913892127788
total_rewards_min            7423.018574167669
Number of train steps total  624000
Number of env steps total    1874000
Number of rollouts total     0
Train Time (s)               143.76098084589466
(Previous) Eval Time (s)     17.13578405790031
Sample Time (s)              5.654736757278442
Epoch Time (s)               166.55150166107342
Total Train Time (s)         26371.25897920644
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:13:09.993242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #155 | Epoch Duration: 166.64058446884155
2020-01-12 15:13:09.993584 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6801609
Z variance train             0.03940464
KL Divergence                42.20976
KL Loss                      4.220976
QF Loss                      216.92978
VF Loss                      105.11313
Policy Loss                  -994.3619
Q Predictions Mean           992.47546
Q Predictions Std            1049.5995
Q Predictions Max            3547.9749
Q Predictions Min            414.82288
V Predictions Mean           993.93567
V Predictions Std            1046.69
V Predictions Max            3539.953
V Predictions Min            424.35324
Log Pis Mean                 -0.6395857
Log Pis Std                  3.3890698
Log Pis Max                  19.446762
Log Pis Min                  -7.691763
Policy mu Mean               -0.035720665
Policy mu Std                0.83088785
Policy mu Max                2.6309373
Policy mu Min                -3.7986195
Policy log std Mean          -0.5072802
Policy log std Std           0.2576026
Policy log std Max           -0.08554143
Policy log std Min           -2.346056
Z mean eval                  1.6838112
Z variance eval              0.03687975
total_rewards                [8087.8685862  8369.23098567 8194.29773205 8254.37643213 8150.03525646
 8431.08460093 8166.73737853 8314.90160849 7733.17214297 8265.90675663]
total_rewards_mean           8196.761148004818
total_rewards_std            183.4596112927521
total_rewards_max            8431.084600929693
total_rewards_min            7733.172142966617
Number of train steps total  628000
Number of env steps total    1886000
Number of rollouts total     0
Train Time (s)               146.90457370504737
(Previous) Eval Time (s)     20.62318090442568
Sample Time (s)              6.463837856426835
Epoch Time (s)               173.99159246589988
Total Train Time (s)         26545.33572577918
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:16:04.069814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #156 | Epoch Duration: 174.0759961605072
2020-01-12 15:16:04.069958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6855221
Z variance train             0.036920257
KL Divergence                40.59921
KL Loss                      4.059921
QF Loss                      156.14551
VF Loss                      134.67978
Policy Loss                  -873.7612
Q Predictions Mean           875.7315
Q Predictions Std            968.9583
Q Predictions Max            3495.8694
Q Predictions Min            430.46246
V Predictions Mean           881.9304
V Predictions Std            968.59985
V Predictions Max            3487.647
V Predictions Min            433.58414
Log Pis Mean                 -0.7079874
Log Pis Std                  3.3622265
Log Pis Max                  16.909262
Log Pis Min                  -9.469059
Policy mu Mean               0.0519211
Policy mu Std                0.8223465
Policy mu Max                3.328805
Policy mu Min                -2.7041535
Policy log std Mean          -0.48393586
Policy log std Std           0.25188404
Policy log std Max           0.0051498413
Policy log std Min           -2.156906
Z mean eval                  1.6692518
Z variance eval              0.0505194
total_rewards                [4134.42259465 7679.50688049 7833.52116349 7824.5074276  7976.00789373
 7753.73525323 8033.68162757 7666.49368759 7930.84792957 7647.68395113]
total_rewards_mean           7448.040840904667
total_rewards_std            1111.7472597465958
total_rewards_max            8033.681627570213
total_rewards_min            4134.4225946502265
Number of train steps total  632000
Number of env steps total    1898000
Number of rollouts total     0
Train Time (s)               145.36902018636465
(Previous) Eval Time (s)     17.324253030121326
Sample Time (s)              6.552715686149895
Epoch Time (s)               169.24598890263587
Total Train Time (s)         26714.66900205007
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:18:53.410110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #157 | Epoch Duration: 169.3400011062622
2020-01-12 15:18:53.410387 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.670131
Z variance train             0.050728105
KL Divergence                40.101505
KL Loss                      4.0101504
QF Loss                      102.37797
VF Loss                      42.350967
Policy Loss                  -972.479
Q Predictions Mean           970.1383
Q Predictions Std            1026.8604
Q Predictions Max            3543.2964
Q Predictions Min            436.03403
V Predictions Mean           972.23627
V Predictions Std            1023.34766
V Predictions Max            3525.9258
V Predictions Min            442.33157
Log Pis Mean                 -0.75842786
Log Pis Std                  3.0300765
Log Pis Max                  10.531879
Log Pis Min                  -7.8359275
Policy mu Mean               0.05407253
Policy mu Std                0.8092073
Policy mu Max                2.8985863
Policy mu Min                -2.909739
Policy log std Mean          -0.482967
Policy log std Std           0.24299757
Policy log std Max           -0.023729205
Policy log std Min           -1.9544766
Z mean eval                  1.6684755
Z variance eval              0.059243787
total_rewards                [5940.00261673 8537.06576284 8520.15981503 8204.50175106 8164.09680543
 6609.34726375 8130.54345052 8338.11404128 8447.38003792 8473.04395161]
total_rewards_mean           7936.425549618754
total_rewards_std            855.5772270742784
total_rewards_max            8537.065762842689
total_rewards_min            5940.002616734299
Number of train steps total  636000
Number of env steps total    1910000
Number of rollouts total     0
Train Time (s)               145.28805463341996
(Previous) Eval Time (s)     21.349528718739748
Sample Time (s)              6.674951656721532
Epoch Time (s)               173.31253500888124
Total Train Time (s)         26888.064600161277
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:21:46.804754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #158 | Epoch Duration: 173.394104719162
2020-01-12 15:21:46.805036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6666578
Z variance train             0.059202127
KL Divergence                39.49934
KL Loss                      3.949934
QF Loss                      125.46012
VF Loss                      35.91261
Policy Loss                  -984.80023
Q Predictions Mean           982.092
Q Predictions Std            996.62305
Q Predictions Max            3566.963
Q Predictions Min            420.77823
V Predictions Mean           982.0785
V Predictions Std            998.7925
V Predictions Max            3567.0232
V Predictions Min            413.30197
Log Pis Mean                 -0.5574315
Log Pis Std                  3.3183858
Log Pis Max                  11.515685
Log Pis Min                  -9.4117565
Policy mu Mean               0.008906503
Policy mu Std                0.8313205
Policy mu Max                2.9669752
Policy mu Min                -2.4077673
Policy log std Mean          -0.5148545
Policy log std Std           0.26446256
Policy log std Max           -0.14521945
Policy log std Min           -2.47193
Z mean eval                  1.6647692
Z variance eval              0.08769739
total_rewards                [8214.69070997 8519.70549844 8119.73163089 8351.10912689 8403.43391663
 8573.24854286 8454.08472371 8620.29238241 8455.73385285 8309.37525718]
total_rewards_mean           8402.140564183897
total_rewards_std            149.1186246627803
total_rewards_max            8620.292382409565
total_rewards_min            8119.731630891425
Number of train steps total  640000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               144.43296390166506
(Previous) Eval Time (s)     21.298181997146457
Sample Time (s)              6.552921161521226
Epoch Time (s)               172.28406706033275
Total Train Time (s)         27060.43429635046
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:24:39.175154 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #159 | Epoch Duration: 172.36994910240173
2020-01-12 15:24:39.175298 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6631695
Z variance train             0.0876924
KL Divergence                38.579678
KL Loss                      3.8579679
QF Loss                      195.24768
VF Loss                      85.20365
Policy Loss                  -987.6028
Q Predictions Mean           986.40546
Q Predictions Std            1046.7224
Q Predictions Max            3604.429
Q Predictions Min            427.89557
V Predictions Mean           987.4212
V Predictions Std            1040.8501
V Predictions Max            3574.9712
V Predictions Min            437.15805
Log Pis Mean                 -0.54161143
Log Pis Std                  3.2286925
Log Pis Max                  11.176964
Log Pis Min                  -6.3900795
Policy mu Mean               0.033344667
Policy mu Std                0.8332597
Policy mu Max                2.7732303
Policy mu Min                -2.5580568
Policy log std Mean          -0.48812118
Policy log std Std           0.25721726
Policy log std Max           -0.085149765
Policy log std Min           -2.10993
Z mean eval                  1.6858761
Z variance eval              0.11312804
total_rewards                [7778.41397073 7997.9124408  7872.32335618 7720.98820196 7903.96943954
 7952.47019068 7882.68079837 7581.91396263 6979.7540867  5462.1666011 ]
total_rewards_mean           7513.259304870393
total_rewards_std            738.6223227968701
total_rewards_max            7997.912440804156
total_rewards_min            5462.166601100374
Number of train steps total  644000
Number of env steps total    1934000
Number of rollouts total     0
Train Time (s)               145.56839477829635
(Previous) Eval Time (s)     21.465846753213555
Sample Time (s)              6.3990280805155635
Epoch Time (s)               173.43326961202547
Total Train Time (s)         27233.94944996247
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:27:32.692805 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #160 | Epoch Duration: 173.5173327922821
2020-01-12 15:27:32.693026 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6855644
Z variance train             0.11323136
KL Divergence                38.715633
KL Loss                      3.8715634
QF Loss                      145.97002
VF Loss                      57.43587
Policy Loss                  -1053.3379
Q Predictions Mean           1049.8362
Q Predictions Std            1089.5018
Q Predictions Max            3642.7822
Q Predictions Min            445.16068
V Predictions Mean           1053.5118
V Predictions Std            1087.329
V Predictions Max            3631.3323
V Predictions Min            446.63358
Log Pis Mean                 -0.31389982
Log Pis Std                  3.5349002
Log Pis Max                  15.372602
Log Pis Min                  -7.2831473
Policy mu Mean               0.07441337
Policy mu Std                0.8648342
Policy mu Max                3.1500065
Policy mu Min                -2.9904642
Policy log std Mean          -0.4997108
Policy log std Std           0.26974827
Policy log std Max           -0.049295485
Policy log std Min           -2.174433
Z mean eval                  1.706269
Z variance eval              0.061629813
total_rewards                [8069.84541031 8445.56400335 8387.10027589 8461.12580091 8287.55237038
 8305.26057917 8405.36678933 8175.68788902 8290.69610197 8186.85685544]
total_rewards_mean           8301.505607577363
total_rewards_std            121.37196527705841
total_rewards_max            8461.12580091366
total_rewards_min            8069.845410312459
Number of train steps total  648000
Number of env steps total    1946000
Number of rollouts total     0
Train Time (s)               144.08012962993234
(Previous) Eval Time (s)     18.6778327813372
Sample Time (s)              6.472726160660386
Epoch Time (s)               169.23068857192993
Total Train Time (s)         27403.291216287762
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:30:22.036610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #161 | Epoch Duration: 169.34345602989197
2020-01-12 15:30:22.036783 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #161 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7067089
Z variance train             0.061644293
KL Divergence                39.990013
KL Loss                      3.9990013
QF Loss                      1927.54
VF Loss                      180.78108
Policy Loss                  -1056.0992
Q Predictions Mean           1053.0657
Q Predictions Std            1083.2035
Q Predictions Max            3586.295
Q Predictions Min            445.11728
V Predictions Mean           1062.9858
V Predictions Std            1083.0472
V Predictions Max            3611.5886
V Predictions Min            451.48813
Log Pis Mean                 -0.5531429
Log Pis Std                  3.2883127
Log Pis Max                  13.208656
Log Pis Min                  -7.936208
Policy mu Mean               0.043832522
Policy mu Std                0.84358853
Policy mu Max                3.0912414
Policy mu Min                -2.6023188
Policy log std Mean          -0.5062376
Policy log std Std           0.28084147
Policy log std Max           0.09842491
Policy log std Min           -2.3637557
Z mean eval                  1.6757586
Z variance eval              0.06733346
total_rewards                [7960.6738216  8227.36965026 8468.24236326 8700.9430975  8266.6804645
 8318.00530653 8484.96176387 8617.67743521 8503.63134857 8559.20573492]
total_rewards_mean           8410.739098620557
total_rewards_std            207.86157226089506
total_rewards_max            8700.943097501446
total_rewards_min            7960.67382159728
Number of train steps total  652000
Number of env steps total    1958000
Number of rollouts total     0
Train Time (s)               145.30942275980487
(Previous) Eval Time (s)     20.777943045832217
Sample Time (s)              6.592671235091984
Epoch Time (s)               172.68003704072908
Total Train Time (s)         27576.06158953719
Epoch                        162
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:33:14.812348 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #162 | Epoch Duration: 172.77539587020874
2020-01-12 15:33:14.812642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6757734
Z variance train             0.06743214
KL Divergence                39.702152
KL Loss                      3.9702153
QF Loss                      2026.3009
VF Loss                      85.45046
Policy Loss                  -960.99036
Q Predictions Mean           960.89606
Q Predictions Std            1032.7604
Q Predictions Max            3561.8257
Q Predictions Min            425.75882
V Predictions Mean           964.9397
V Predictions Std            1034.2883
V Predictions Max            3580.0413
V Predictions Min            436.6621
Log Pis Mean                 -0.4100744
Log Pis Std                  3.575611
Log Pis Max                  13.544498
Log Pis Min                  -5.9498224
Policy mu Mean               0.08590195
Policy mu Std                0.8717773
Policy mu Max                2.9629836
Policy mu Min                -2.8876421
Policy log std Mean          -0.5031908
Policy log std Std           0.26166865
Policy log std Max           -0.0982362
Policy log std Min           -2.3904204
Z mean eval                  1.6633358
Z variance eval              0.055999726
total_rewards                [8731.89896842 8725.92237956 8661.05932159 8683.15826959 8704.42176906
 8703.72434314 8365.46675214 8412.64892987 8213.6919596  8428.93031953]
total_rewards_mean           8563.09230124973
total_rewards_std            179.03720019231207
total_rewards_max            8731.898968420204
total_rewards_min            8213.691959603198
Number of train steps total  656000
Number of env steps total    1970000
Number of rollouts total     0
Train Time (s)               145.7679060101509
(Previous) Eval Time (s)     20.801635336130857
Sample Time (s)              6.622578330338001
Epoch Time (s)               173.19211967661977
Total Train Time (s)         27749.350282585714
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:36:08.101491 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #163 | Epoch Duration: 173.28865218162537
2020-01-12 15:36:08.101626 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #163 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.663591
Z variance train             0.05603979
KL Divergence                39.386177
KL Loss                      3.9386177
QF Loss                      246.87125
VF Loss                      66.25935
Policy Loss                  -986.45715
Q Predictions Mean           983.6944
Q Predictions Std            1018.4226
Q Predictions Max            3645.1917
Q Predictions Min            410.265
V Predictions Mean           982.8601
V Predictions Std            1013.9674
V Predictions Max            3638.7656
V Predictions Min            463.98865
Log Pis Mean                 -0.30612773
Log Pis Std                  3.875925
Log Pis Max                  16.222378
Log Pis Min                  -5.747678
Policy mu Mean               0.031479243
Policy mu Std                0.87018734
Policy mu Max                4.212607
Policy mu Min                -2.76833
Policy log std Mean          -0.48593482
Policy log std Std           0.25187275
Policy log std Max           -0.06016463
Policy log std Min           -2.197948
Z mean eval                  1.652396
Z variance eval              0.059991397
total_rewards                [8482.77786747 8698.36475853 8746.24731885 8687.32933596 8583.4225795
 8399.89611215 8609.75745802 8649.40435838 8762.64917968 8499.86422687]
total_rewards_mean           8611.971319542306
total_rewards_std            114.16327100965566
total_rewards_max            8762.649179675338
total_rewards_min            8399.896112151242
Number of train steps total  660000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               144.91382416989654
(Previous) Eval Time (s)     17.31726120505482
Sample Time (s)              6.554503338877112
Epoch Time (s)               168.78558871382847
Total Train Time (s)         27918.21486007562
Epoch                        164
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:38:56.968099 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #164 | Epoch Duration: 168.86636519432068
2020-01-12 15:38:56.968272 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6520624
Z variance train             0.060126733
KL Divergence                38.88307
KL Loss                      3.8883073
QF Loss                      177.16115
VF Loss                      100.05221
Policy Loss                  -936.2691
Q Predictions Mean           933.2539
Q Predictions Std            977.23883
Q Predictions Max            3624.445
Q Predictions Min            427.17838
V Predictions Mean           934.00745
V Predictions Std            973.2496
V Predictions Max            3598.4578
V Predictions Min            429.54123
Log Pis Mean                 -0.60585624
Log Pis Std                  3.5035627
Log Pis Max                  22.018147
Log Pis Min                  -7.7542787
Policy mu Mean               0.102687955
Policy mu Std                0.8617833
Policy mu Max                3.4867532
Policy mu Min                -2.5813835
Policy log std Mean          -0.4898169
Policy log std Std           0.2581751
Policy log std Max           -0.055503666
Policy log std Min           -2.1160653
Z mean eval                  1.6549307
Z variance eval              0.049500596
total_rewards                [8560.36756444 8804.43648673 8657.3518918  8243.41274752 8583.03812002
 8793.11679864 8420.86880505 8761.42629635 8703.32335427 8494.54362294]
total_rewards_mean           8602.188568776066
total_rewards_std            170.67097506409874
total_rewards_max            8804.436486732982
total_rewards_min            8243.41274752131
Number of train steps total  664000
Number of env steps total    1994000
Number of rollouts total     0
Train Time (s)               145.9682332049124
(Previous) Eval Time (s)     17.64883640082553
Sample Time (s)              6.589735724963248
Epoch Time (s)               170.20680533070117
Total Train Time (s)         28088.503470460884
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:41:47.259983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #165 | Epoch Duration: 170.29151725769043
2020-01-12 15:41:47.260255 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6567894
Z variance train             0.049710847
KL Divergence                38.783916
KL Loss                      3.8783917
QF Loss                      2300.9534
VF Loss                      74.5664
Policy Loss                  -1039.1998
Q Predictions Mean           1037.0245
Q Predictions Std            1075.2072
Q Predictions Max            3612.7527
Q Predictions Min            456.65234
V Predictions Mean           1041.5654
V Predictions Std            1079.2737
V Predictions Max            3619.7522
V Predictions Min            470.455
Log Pis Mean                 -0.606949
Log Pis Std                  3.495847
Log Pis Max                  14.524021
Log Pis Min                  -9.15163
Policy mu Mean               0.040339224
Policy mu Std                0.83455193
Policy mu Max                2.7011616
Policy mu Min                -2.6176834
Policy log std Mean          -0.5019823
Policy log std Std           0.2531119
Policy log std Max           -0.08505887
Policy log std Min           -2.01134
Z mean eval                  1.6605324
Z variance eval              0.08821193
total_rewards                [8706.8521606  8821.33295602 8683.74250931 9104.20513826 8935.74866726
 8832.43370236 8517.35477475 8908.95892219  537.5930163  8725.83854958]
total_rewards_mean           7977.406039662242
total_rewards_std            2484.6063883495144
total_rewards_max            9104.205138262496
total_rewards_min            537.5930162992486
Number of train steps total  668000
Number of env steps total    2006000
Number of rollouts total     0
Train Time (s)               146.48404628923163
(Previous) Eval Time (s)     17.58264566073194
Sample Time (s)              6.506538621149957
Epoch Time (s)               170.57323057111353
Total Train Time (s)         28259.162818637677
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:44:37.923338 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #166 | Epoch Duration: 170.6628942489624
2020-01-12 15:44:37.923517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6599884
Z variance train             0.08812831
KL Divergence                37.18761
KL Loss                      3.7187612
QF Loss                      125.12697
VF Loss                      129.45154
Policy Loss                  -1044.5137
Q Predictions Mean           1042.2798
Q Predictions Std            1071.4978
Q Predictions Max            3527.7073
Q Predictions Min            453.3944
V Predictions Mean           1046.7501
V Predictions Std            1072.6708
V Predictions Max            3550.8145
V Predictions Min            462.24417
Log Pis Mean                 -0.50661314
Log Pis Std                  3.7162547
Log Pis Max                  20.383276
Log Pis Min                  -7.911856
Policy mu Mean               0.017188562
Policy mu Std                0.870014
Policy mu Max                3.0606408
Policy mu Min                -3.49635
Policy log std Mean          -0.48185587
Policy log std Std           0.26425943
Policy log std Max           -0.07888186
Policy log std Min           -2.4321558
Z mean eval                  1.702982
Z variance eval              0.046680797
total_rewards                [8087.70545572 7971.05566275 8444.00460868 8295.40399072 8295.42607427
 8146.72682979 8244.65551981 8108.03837929 8256.18014317 8475.03219699]
total_rewards_mean           8232.42288611841
total_rewards_std            149.78232492859763
total_rewards_max            8475.0321969906
total_rewards_min            7971.055662750041
Number of train steps total  672000
Number of env steps total    2018000
Number of rollouts total     0
Train Time (s)               144.9417073582299
(Previous) Eval Time (s)     20.810718567110598
Sample Time (s)              6.608845453243703
Epoch Time (s)               172.3612713785842
Total Train Time (s)         28431.607398571447
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:47:30.366788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #167 | Epoch Duration: 172.4431381225586
2020-01-12 15:47:30.366933 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7016321
Z variance train             0.04675547
KL Divergence                39.42159
KL Loss                      3.942159
QF Loss                      140.04364
VF Loss                      80.33762
Policy Loss                  -1067.7583
Q Predictions Mean           1068.8872
Q Predictions Std            1101.6366
Q Predictions Max            3605.6501
Q Predictions Min            458.04523
V Predictions Mean           1069.8123
V Predictions Std            1103.8966
V Predictions Max            3614.9998
V Predictions Min            455.02527
Log Pis Mean                 -0.419085
Log Pis Std                  3.468799
Log Pis Max                  12.653125
Log Pis Min                  -6.702613
Policy mu Mean               0.060690235
Policy mu Std                0.8657343
Policy mu Max                2.8345518
Policy mu Min                -2.4403539
Policy log std Mean          -0.49641475
Policy log std Std           0.25748968
Policy log std Max           -0.07634348
Policy log std Min           -2.2391026
Z mean eval                  1.6878445
Z variance eval              0.051007003
total_rewards                [7900.46783036 8184.69743467 8310.31626619 8749.77395926 8276.80498693
 8310.9087901  8414.90839878 8491.06746268 8201.09901321 8251.19720909]
total_rewards_mean           8309.12413512604
total_rewards_std            209.05071653575988
total_rewards_max            8749.773959264885
total_rewards_min            7900.467830360265
Number of train steps total  676000
Number of env steps total    2030000
Number of rollouts total     0
Train Time (s)               146.2720042890869
(Previous) Eval Time (s)     20.62562488298863
Sample Time (s)              6.499655156861991
Epoch Time (s)               173.39728432893753
Total Train Time (s)         28605.098575496115
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:50:23.859825 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #168 | Epoch Duration: 173.49277544021606
2020-01-12 15:50:23.859999 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.687454
Z variance train             0.050934933
KL Divergence                39.88109
KL Loss                      3.9881089
QF Loss                      295.7052
VF Loss                      86.86297
Policy Loss                  -1072.0112
Q Predictions Mean           1070.7645
Q Predictions Std            1109.3578
Q Predictions Max            3642.529
Q Predictions Min            474.8323
V Predictions Mean           1078.8192
V Predictions Std            1110.3694
V Predictions Max            3636.7578
V Predictions Min            478.18896
Log Pis Mean                 -0.6712061
Log Pis Std                  3.4327505
Log Pis Max                  11.017113
Log Pis Min                  -6.7748785
Policy mu Mean               0.0124715455
Policy mu Std                0.82966834
Policy mu Max                2.6371453
Policy mu Min                -2.3315418
Policy log std Mean          -0.50378966
Policy log std Std           0.25258705
Policy log std Max           -0.14151967
Policy log std Min           -2.4408998
Z mean eval                  1.6869953
Z variance eval              0.053444393
total_rewards                [8222.75704986 8769.34860381 8667.29303842 8751.50126783 8714.62780148
 8685.13704641 8756.17191276 8591.48364041 8698.82390947 8863.25572692]
total_rewards_mean           8672.039999738172
total_rewards_std            164.46712489085743
total_rewards_max            8863.25572692445
total_rewards_min            8222.757049858508
Number of train steps total  680000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               145.8144045220688
(Previous) Eval Time (s)     18.04896749276668
Sample Time (s)              6.472155757714063
Epoch Time (s)               170.33552777254954
Total Train Time (s)         28775.51926541142
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:53:14.286049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #169 | Epoch Duration: 170.42587423324585
2020-01-12 15:53:14.286361 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.678326
Z variance train             0.0542598
KL Divergence                39.349335
KL Loss                      3.9349334
QF Loss                      115.38569
VF Loss                      100.75787
Policy Loss                  -923.0727
Q Predictions Mean           923.8257
Q Predictions Std            985.7428
Q Predictions Max            3852.1685
Q Predictions Min            488.97018
V Predictions Mean           931.28723
V Predictions Std            986.6508
V Predictions Max            3862.1404
V Predictions Min            494.59235
Log Pis Mean                 -0.77732897
Log Pis Std                  3.018531
Log Pis Max                  11.096724
Log Pis Min                  -7.9351444
Policy mu Mean               0.03150111
Policy mu Std                0.8071585
Policy mu Max                2.5668807
Policy mu Min                -2.4092195
Policy log std Mean          -0.48112497
Policy log std Std           0.23909311
Policy log std Max           -0.13827014
Policy log std Min           -2.3621607
Z mean eval                  1.6825974
Z variance eval              0.046334367
total_rewards                [8641.91015272 8888.73980555 8773.01330649 8796.47860474 8995.73795362
 8694.15572269 8695.28649672 8702.49986467 8888.052827   8958.91222216]
total_rewards_mean           8803.478695635657
total_rewards_std            116.82498358731809
total_rewards_max            8995.737953622373
total_rewards_min            8641.910152717783
Number of train steps total  684000
Number of env steps total    2054000
Number of rollouts total     0
Train Time (s)               145.4497742978856
(Previous) Eval Time (s)     20.640418864320964
Sample Time (s)              6.541411028243601
Epoch Time (s)               172.63160419045016
Total Train Time (s)         28948.235827020835
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:56:07.003728 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #170 | Epoch Duration: 172.71710586547852
2020-01-12 15:56:07.003941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6831436
Z variance train             0.046361286
KL Divergence                39.943245
KL Loss                      3.9943244
QF Loss                      115.007515
VF Loss                      46.87203
Policy Loss                  -942.1672
Q Predictions Mean           944.5106
Q Predictions Std            1002.2489
Q Predictions Max            3653.888
Q Predictions Min            453.87137
V Predictions Mean           941.97736
V Predictions Std            998.1779
V Predictions Max            3662.0325
V Predictions Min            453.36603
Log Pis Mean                 -0.61720127
Log Pis Std                  3.7740662
Log Pis Max                  17.2194
Log Pis Min                  -7.306044
Policy mu Mean               0.049936432
Policy mu Std                0.8299118
Policy mu Max                2.6820574
Policy mu Min                -2.7269726
Policy log std Mean          -0.4855143
Policy log std Std           0.24522267
Policy log std Max           -0.024852633
Policy log std Min           -2.467192
Z mean eval                  1.7050524
Z variance eval              0.09448192
total_rewards                [8653.16417191 8191.78583263 8793.55862292 8733.481518   8818.76590684
 8798.24848307 8717.48609557 8864.71789551 8843.92545433 8909.30582322]
total_rewards_mean           8732.44398040007
total_rewards_std            193.78923132276046
total_rewards_max            8909.305823221206
total_rewards_min            8191.7858326297865
Number of train steps total  688000
Number of env steps total    2066000
Number of rollouts total     0
Train Time (s)               145.12360028736293
(Previous) Eval Time (s)     17.576523912139237
Sample Time (s)              6.44432009011507
Epoch Time (s)               169.14444428961724
Total Train Time (s)         29117.466860174667
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 15:58:56.239897 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #171 | Epoch Duration: 169.2357897758484
2020-01-12 15:58:56.240164 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.706785
Z variance train             0.09420597
KL Divergence                39.010014
KL Loss                      3.9010015
QF Loss                      108.08577
VF Loss                      56.964302
Policy Loss                  -1012.15857
Q Predictions Mean           1013.34033
Q Predictions Std            1064.8325
Q Predictions Max            3734.7783
Q Predictions Min            470.01334
V Predictions Mean           1013.3255
V Predictions Std            1059.7817
V Predictions Max            3713.7957
V Predictions Min            472.16
Log Pis Mean                 -0.6319942
Log Pis Std                  3.0129151
Log Pis Max                  10.336362
Log Pis Min                  -7.9501543
Policy mu Mean               -0.003745328
Policy mu Std                0.8164501
Policy mu Max                2.4558353
Policy mu Min                -2.3234966
Policy log std Mean          -0.49421227
Policy log std Std           0.2609263
Policy log std Max           -0.06880888
Policy log std Min           -2.427072
Z mean eval                  1.6682355
Z variance eval              0.06003164
total_rewards                [8377.95027439 8412.9917206  8492.48902766 8474.81419142 8686.04625457
 8650.74650746 8485.18638406 8620.08692774 8541.25718181 8582.5044903 ]
total_rewards_mean           8532.407296002064
total_rewards_std            96.51018872477731
total_rewards_max            8686.04625456935
total_rewards_min            8377.950274388246
Number of train steps total  692000
Number of env steps total    2078000
Number of rollouts total     0
Train Time (s)               144.63459149608389
(Previous) Eval Time (s)     20.807526072021574
Sample Time (s)              6.478848413564265
Epoch Time (s)               171.92096598166972
Total Train Time (s)         29289.479592790827
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:01:48.252105 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #172 | Epoch Duration: 172.01175665855408
2020-01-12 16:01:48.252250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6671692
Z variance train             0.06010034
KL Divergence                39.07331
KL Loss                      3.9073312
QF Loss                      218.5209
VF Loss                      59.68052
Policy Loss                  -1067.602
Q Predictions Mean           1065.636
Q Predictions Std            1091.7543
Q Predictions Max            3639.1086
Q Predictions Min            477.81512
V Predictions Mean           1071.2861
V Predictions Std            1091.6047
V Predictions Max            3646.7468
V Predictions Min            476.20978
Log Pis Mean                 -0.6094056
Log Pis Std                  3.657351
Log Pis Max                  18.121746
Log Pis Min                  -10.36287
Policy mu Mean               0.031787086
Policy mu Std                0.8510661
Policy mu Max                2.7436037
Policy mu Min                -3.6127958
Policy log std Mean          -0.48602223
Policy log std Std           0.24332404
Policy log std Max           -0.049574703
Policy log std Min           -2.0343928
Z mean eval                  1.6780691
Z variance eval              0.062889606
total_rewards                [8493.76380846 8803.50052567 8707.00051943 8541.49716024 8620.10012156
 8641.5397058  8753.3827365  8334.10530247 8642.85443628 8528.10379821]
total_rewards_mean           8606.584811460943
total_rewards_std            130.57490989875575
total_rewards_max            8803.500525665982
total_rewards_min            8334.105302474423
Number of train steps total  696000
Number of env steps total    2090000
Number of rollouts total     0
Train Time (s)               147.4393158662133
(Previous) Eval Time (s)     17.911498561967164
Sample Time (s)              6.306300093885511
Epoch Time (s)               171.65711452206597
Total Train Time (s)         29461.219214608893
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:04:39.999537 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #173 | Epoch Duration: 171.74715304374695
2020-01-12 16:04:39.999763 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6771953
Z variance train             0.06303736
KL Divergence                40.09716
KL Loss                      4.009716
QF Loss                      171.9212
VF Loss                      260.6278
Policy Loss                  -1093.9211
Q Predictions Mean           1094.0339
Q Predictions Std            1115.9945
Q Predictions Max            3843.4707
Q Predictions Min            477.94824
V Predictions Mean           1103.3811
V Predictions Std            1119.4736
V Predictions Max            3821.106
V Predictions Min            490.99857
Log Pis Mean                 -0.63847864
Log Pis Std                  3.3520322
Log Pis Max                  13.690289
Log Pis Min                  -8.105515
Policy mu Mean               0.05621764
Policy mu Std                0.8360838
Policy mu Max                2.6801543
Policy mu Min                -2.920197
Policy log std Mean          -0.5023609
Policy log std Std           0.2499272
Policy log std Max           -0.061777055
Policy log std Min           -2.141471
Z mean eval                  1.6952012
Z variance eval              0.08217262
total_rewards                [8994.79626886 8887.80253752 9007.1559942  8952.93364084 8779.99238509
 9049.43228975 8970.81669913 8779.14907914 8766.53432564 8869.16749198]
total_rewards_mean           8905.778071215484
total_rewards_std            99.096490162204
total_rewards_max            9049.432289747085
total_rewards_min            8766.5343256448
Number of train steps total  700000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               145.814381333068
(Previous) Eval Time (s)     18.041688065044582
Sample Time (s)              6.3963568159379065
Epoch Time (s)               170.2524262140505
Total Train Time (s)         29631.557638970204
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:07:30.338697 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #174 | Epoch Duration: 170.33875370025635
2020-01-12 16:07:30.338867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.699496
Z variance train             0.08201949
KL Divergence                40.458797
KL Loss                      4.04588
QF Loss                      2202.725
VF Loss                      43.693214
Policy Loss                  -989.17926
Q Predictions Mean           987.53174
Q Predictions Std            1031.5293
Q Predictions Max            3803.191
Q Predictions Min            479.6905
V Predictions Mean           986.94324
V Predictions Std            1029.3966
V Predictions Max            3798.5305
V Predictions Min            483.41013
Log Pis Mean                 -0.68058753
Log Pis Std                  3.3727345
Log Pis Max                  13.08857
Log Pis Min                  -6.8905516
Policy mu Mean               0.038336482
Policy mu Std                0.83896935
Policy mu Max                2.6149118
Policy mu Min                -2.573729
Policy log std Mean          -0.49962616
Policy log std Std           0.24840404
Policy log std Max           -0.09239374
Policy log std Min           -2.1204078
Z mean eval                  1.6692533
Z variance eval              0.046211023
total_rewards                [8333.73656886 8750.26098998 9034.47775155 8948.32172134 8102.27504625
 8743.94914796 8607.45412672 8698.87804488 8531.88960273 8972.09332575]
total_rewards_mean           8672.333632601772
total_rewards_std            277.96193297027963
total_rewards_max            9034.477751549268
total_rewards_min            8102.275046247401
Number of train steps total  704000
Number of env steps total    2114000
Number of rollouts total     0
Train Time (s)               147.14764814032242
(Previous) Eval Time (s)     17.547311436850578
Sample Time (s)              6.3446714375168085
Epoch Time (s)               171.0396310146898
Total Train Time (s)         29802.680935938843
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:10:21.463682 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #175 | Epoch Duration: 171.12469339370728
2020-01-12 16:10:21.463817 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6701155
Z variance train             0.0460886
KL Divergence                41.09267
KL Loss                      4.109267
QF Loss                      124.47223
VF Loss                      73.095665
Policy Loss                  -956.966
Q Predictions Mean           951.4667
Q Predictions Std            982.78516
Q Predictions Max            3790.957
Q Predictions Min            478.27386
V Predictions Mean           954.1848
V Predictions Std            982.9141
V Predictions Max            3777.9802
V Predictions Min            486.54233
Log Pis Mean                 -0.86854744
Log Pis Std                  3.6279929
Log Pis Max                  18.509642
Log Pis Min                  -8.219343
Policy mu Mean               0.03843839
Policy mu Std                0.8116225
Policy mu Max                2.5132086
Policy mu Min                -3.596787
Policy log std Mean          -0.48347154
Policy log std Std           0.2693095
Policy log std Max           -0.040167928
Policy log std Min           -2.158823
Z mean eval                  1.6875372
Z variance eval              0.081984885
total_rewards                [8439.33403788 8701.4236542  8834.11082476 8797.29582384 8694.45912375
 8570.34329271 8749.04885477 8712.35527044 8668.13716022 8705.15952461]
total_rewards_mean           8687.166756718527
total_rewards_std            106.86248504119249
total_rewards_max            8834.110824755706
total_rewards_min            8439.334037879886
Number of train steps total  708000
Number of env steps total    2126000
Number of rollouts total     0
Train Time (s)               146.53834656393155
(Previous) Eval Time (s)     17.39765392197296
Sample Time (s)              6.364318030420691
Epoch Time (s)               170.3003185163252
Total Train Time (s)         29973.064368319232
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:13:11.851123 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #176 | Epoch Duration: 170.38719606399536
2020-01-12 16:13:11.851307 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6870663
Z variance train             0.0821037
KL Divergence                39.30276
KL Loss                      3.9302762
QF Loss                      134.93512
VF Loss                      38.91426
Policy Loss                  -976.9003
Q Predictions Mean           974.7768
Q Predictions Std            992.91876
Q Predictions Max            3697.3428
Q Predictions Min            494.9932
V Predictions Mean           979.1826
V Predictions Std            993.11835
V Predictions Max            3699.1135
V Predictions Min            488.99396
Log Pis Mean                 -0.59026265
Log Pis Std                  3.3876312
Log Pis Max                  10.000638
Log Pis Min                  -7.647888
Policy mu Mean               0.08149911
Policy mu Std                0.8220604
Policy mu Max                2.6009073
Policy mu Min                -2.5139763
Policy log std Mean          -0.49613747
Policy log std Std           0.2510641
Policy log std Max           -0.054849803
Policy log std Min           -2.2915
Z mean eval                  1.6964394
Z variance eval              0.067754745
total_rewards                [8487.54192292 8404.53119327 8051.99293928 8442.23132165 8560.56940351
 8356.34996091 8678.5822314  8547.65228727 7992.68358381 8418.15471798]
total_rewards_mean           8394.028956199334
total_rewards_std            205.80412014956647
total_rewards_max            8678.582231395738
total_rewards_min            7992.683583807222
Number of train steps total  712000
Number of env steps total    2138000
Number of rollouts total     0
Train Time (s)               146.09187183436006
(Previous) Eval Time (s)     20.882548933383077
Sample Time (s)              6.350449597928673
Epoch Time (s)               173.3248703656718
Total Train Time (s)         30146.475852184463
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:16:05.263603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #177 | Epoch Duration: 173.4121596813202
2020-01-12 16:16:05.263731 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6978409
Z variance train             0.06774948
KL Divergence                40.42994
KL Loss                      4.042994
QF Loss                      138.07967
VF Loss                      29.455578
Policy Loss                  -1188.4291
Q Predictions Mean           1186.4222
Q Predictions Std            1179.2341
Q Predictions Max            3747.4812
Q Predictions Min            495.2209
V Predictions Mean           1187.3906
V Predictions Std            1177.5553
V Predictions Max            3750.9885
V Predictions Min            504.87775
Log Pis Mean                 -0.32210502
Log Pis Std                  3.705509
Log Pis Max                  13.144321
Log Pis Min                  -8.604168
Policy mu Mean               0.04275152
Policy mu Std                0.8962559
Policy mu Max                2.7351732
Policy mu Min                -2.4133248
Policy log std Mean          -0.50958824
Policy log std Std           0.24450162
Policy log std Max           -0.108245075
Policy log std Min           -2.1293695
Z mean eval                  1.6942619
Z variance eval              0.09794376
total_rewards                [8632.95683872 8676.85682769 8846.70275567 8936.89101883 8814.78527627
 8655.71828775 8790.97966925 8984.45267754 8870.11069264 8885.57510328]
total_rewards_mean           8809.502914764484
total_rewards_std            114.22061292773593
total_rewards_max            8984.452677544608
total_rewards_min            8632.956838724718
Number of train steps total  716000
Number of env steps total    2150000
Number of rollouts total     0
Train Time (s)               146.35559205524623
(Previous) Eval Time (s)     20.77053590072319
Sample Time (s)              6.486894185654819
Epoch Time (s)               173.61302214162424
Total Train Time (s)         30320.169105020817
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:18:58.962791 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #178 | Epoch Duration: 173.69892239570618
2020-01-12 16:18:58.963072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6923759
Z variance train             0.09796882
KL Divergence                39.548027
KL Loss                      3.9548028
QF Loss                      61.839207
VF Loss                      34.932076
Policy Loss                  -999.14734
Q Predictions Mean           999.6631
Q Predictions Std            1043.4205
Q Predictions Max            3716.914
Q Predictions Min            490.51797
V Predictions Mean           1002.34155
V Predictions Std            1042.5122
V Predictions Max            3712.7183
V Predictions Min            492.71558
Log Pis Mean                 -0.6330274
Log Pis Std                  3.2349293
Log Pis Max                  12.966345
Log Pis Min                  -6.320859
Policy mu Mean               -0.0055714077
Policy mu Std                0.8329428
Policy mu Max                2.5080755
Policy mu Min                -2.821793
Policy log std Mean          -0.4750462
Policy log std Std           0.22285497
Policy log std Max           -0.10340795
Policy log std Min           -2.2282233
Z mean eval                  1.665493
Z variance eval              0.0717429
total_rewards                [8381.87379153 8549.96148071 8853.64190725 8527.36108798 9025.33989149
 8840.53107773 8804.64839396 8704.600654   8791.36482238 8661.75903721]
total_rewards_mean           8714.108214422427
total_rewards_std            179.3077905254657
total_rewards_max            9025.33989148942
total_rewards_min            8381.873791527078
Number of train steps total  720000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               146.66667354479432
(Previous) Eval Time (s)     21.00497518805787
Sample Time (s)              6.549058952834457
Epoch Time (s)               174.22070768568665
Total Train Time (s)         30494.485300237313
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:21:53.280360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #179 | Epoch Duration: 174.31706285476685
2020-01-12 16:21:53.280609 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6676804
Z variance train             0.07192029
KL Divergence                38.664013
KL Loss                      3.8664014
QF Loss                      163.47878
VF Loss                      63.28457
Policy Loss                  -999.7759
Q Predictions Mean           993.6079
Q Predictions Std            1031.436
Q Predictions Max            3866.0
Q Predictions Min            505.05972
V Predictions Mean           996.6956
V Predictions Std            1030.2202
V Predictions Max            3841.573
V Predictions Min            512.34106
Log Pis Mean                 -0.37884724
Log Pis Std                  3.5527956
Log Pis Max                  12.49021
Log Pis Min                  -6.804724
Policy mu Mean               0.040824775
Policy mu Std                0.87437457
Policy mu Max                3.037385
Policy mu Min                -2.5841727
Policy log std Mean          -0.4913896
Policy log std Std           0.24801785
Policy log std Max           -0.12252971
Policy log std Min           -2.3237867
Z mean eval                  1.6852986
Z variance eval              0.08071253
total_rewards                [8307.95503807 8588.03873402 8505.76663806 2710.04149442 8287.56850041
 8635.45374516 8374.33722866 8378.77664905 8664.99503136 8263.15127305]
total_rewards_mean           7871.608433226717
total_rewards_std            1726.1751648219597
total_rewards_max            8664.99503136222
total_rewards_min            2710.041494419003
Number of train steps total  724000
Number of env steps total    2174000
Number of rollouts total     0
Train Time (s)               147.2059444868937
(Previous) Eval Time (s)     17.471482718829066
Sample Time (s)              6.327668683603406
Epoch Time (s)               171.00509588932618
Total Train Time (s)         30665.56648411695
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:24:44.361942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #180 | Epoch Duration: 171.08116483688354
2020-01-12 16:24:44.362068 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6831768
Z variance train             0.080553666
KL Divergence                39.089607
KL Loss                      3.9089608
QF Loss                      223.28995
VF Loss                      185.13126
Policy Loss                  -1074.1578
Q Predictions Mean           1074.1628
Q Predictions Std            1092.0956
Q Predictions Max            3709.9834
Q Predictions Min            481.3003
V Predictions Mean           1076.3568
V Predictions Std            1086.2292
V Predictions Max            3728.8147
V Predictions Min            479.9881
Log Pis Mean                 -0.031360164
Log Pis Std                  3.6914644
Log Pis Max                  14.1808405
Log Pis Min                  -7.292016
Policy mu Mean               0.06914342
Policy mu Std                0.88528514
Policy mu Max                2.8421896
Policy mu Min                -3.7197642
Policy log std Mean          -0.505972
Policy log std Std           0.27387154
Policy log std Max           -0.040644944
Policy log std Min           -2.1336203
Z mean eval                  1.6642364
Z variance eval              0.07359573
total_rewards                [8071.77297664 8645.21069709 8616.77793377 8133.30952114 8909.45257923
 8494.54120956 8931.40190433 8867.6406523  8492.38885446 8651.72305269]
total_rewards_mean           8581.421938122372
total_rewards_std            282.54105589875655
total_rewards_max            8931.401904331064
total_rewards_min            8071.772976637262
Number of train steps total  728000
Number of env steps total    2186000
Number of rollouts total     0
Train Time (s)               146.1806647819467
(Previous) Eval Time (s)     17.724677585996687
Sample Time (s)              5.538220029789954
Epoch Time (s)               169.44356239773333
Total Train Time (s)         30835.091072749812
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:27:33.889254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #181 | Epoch Duration: 169.52707433700562
2020-01-12 16:27:33.889432 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.666394
Z variance train             0.07386148
KL Divergence                38.181942
KL Loss                      3.8181942
QF Loss                      88.28792
VF Loss                      117.02282
Policy Loss                  -988.9998
Q Predictions Mean           989.24805
Q Predictions Std            1027.7803
Q Predictions Max            3847.2217
Q Predictions Min            500.704
V Predictions Mean           996.5965
V Predictions Std            1031.8088
V Predictions Max            3856.3242
V Predictions Min            501.0525
Log Pis Mean                 -0.35387734
Log Pis Std                  3.3473692
Log Pis Max                  10.734791
Log Pis Min                  -6.961877
Policy mu Mean               0.070555635
Policy mu Std                0.8689796
Policy mu Max                3.0094094
Policy mu Min                -2.5190241
Policy log std Mean          -0.4791762
Policy log std Std           0.23633948
Policy log std Max           -0.08435693
Policy log std Min           -1.9202514
Z mean eval                  1.6807957
Z variance eval              0.064743124
total_rewards                [8706.59883502 8771.12533754 8990.24525982 8800.47538849 8815.26327129
 8713.48342967 8809.10891983 8779.53177383 8965.91448974 8779.91740545]
total_rewards_mean           8813.166411068467
total_rewards_std            89.53680719700253
total_rewards_max            8990.245259819143
total_rewards_min            8706.598835023608
Number of train steps total  732000
Number of env steps total    2198000
Number of rollouts total     0
Train Time (s)               149.24344892520458
(Previous) Eval Time (s)     17.857403772883117
Sample Time (s)              6.533390552736819
Epoch Time (s)               173.6342432508245
Total Train Time (s)         31008.819211825263
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:30:27.620311 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #182 | Epoch Duration: 173.7307367324829
2020-01-12 16:30:27.620498 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6829824
Z variance train             0.06493826
KL Divergence                39.348465
KL Loss                      3.9348466
QF Loss                      123.732704
VF Loss                      142.9529
Policy Loss                  -1080.3712
Q Predictions Mean           1080.1722
Q Predictions Std            1101.5328
Q Predictions Max            3815.661
Q Predictions Min            478.71362
V Predictions Mean           1083.5515
V Predictions Std            1096.1123
V Predictions Max            3804.0725
V Predictions Min            498.78085
Log Pis Mean                 -0.40878057
Log Pis Std                  3.5061734
Log Pis Max                  11.946826
Log Pis Min                  -8.707611
Policy mu Mean               0.11593282
Policy mu Std                0.88142234
Policy mu Max                2.5572546
Policy mu Min                -3.1984022
Policy log std Mean          -0.499899
Policy log std Std           0.25807902
Policy log std Max           -0.076355815
Policy log std Min           -2.2470255
Z mean eval                  1.7054663
Z variance eval              0.06387605
total_rewards                [8609.04569985 8540.91817057 8834.56172915 8796.34900845 8505.38756551
 8575.07879459 8312.59609099 8686.11627069 8478.85044974 5108.41324401]
total_rewards_mean           8244.73170235509
total_rewards_std            1055.4825379121958
total_rewards_max            8834.561729151344
total_rewards_min            5108.413244013979
Number of train steps total  736000
Number of env steps total    2210000
Number of rollouts total     0
Train Time (s)               146.43098805705085
(Previous) Eval Time (s)     20.93689208989963
Sample Time (s)              6.604247314855456
Epoch Time (s)               173.97212746180594
Total Train Time (s)         31182.87598949764
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:33:21.678286 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #183 | Epoch Duration: 174.0576560497284
2020-01-12 16:33:21.678429 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7065881
Z variance train             0.06390907
KL Divergence                39.776844
KL Loss                      3.9776845
QF Loss                      4888.587
VF Loss                      48.15546
Policy Loss                  -1006.6428
Q Predictions Mean           1007.22797
Q Predictions Std            1046.6392
Q Predictions Max            3801.2883
Q Predictions Min            511.84335
V Predictions Mean           1009.0315
V Predictions Std            1041.226
V Predictions Max            3775.3562
V Predictions Min            513.9399
Log Pis Mean                 -0.68028575
Log Pis Std                  3.4260874
Log Pis Max                  10.661764
Log Pis Min                  -7.1725845
Policy mu Mean               0.007901371
Policy mu Std                0.82892424
Policy mu Max                2.9780633
Policy mu Min                -3.4027102
Policy log std Mean          -0.47880825
Policy log std Std           0.2370721
Policy log std Max           0.02617824
Policy log std Min           -1.8947015
Z mean eval                  1.6658407
Z variance eval              0.07405462
total_rewards                [8551.77222059 8900.15261778 8753.70547601 8826.49185518 8678.45074752
 8884.72119487 9010.04493606 8648.13219382 8866.12390708 8492.95586875]
total_rewards_mean           8761.255101766921
total_rewards_std            157.24629860340355
total_rewards_max            9010.044936057562
total_rewards_min            8492.955868752744
Number of train steps total  740000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               146.44592164317146
(Previous) Eval Time (s)     20.677749255672097
Sample Time (s)              6.5903394902125
Epoch Time (s)               173.71401038905606
Total Train Time (s)         31356.66955866618
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:36:15.473873 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #184 | Epoch Duration: 173.79534792900085
2020-01-12 16:36:15.474004 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6681888
Z variance train             0.074279994
KL Divergence                39.36576
KL Loss                      3.9365761
QF Loss                      115.72508
VF Loss                      156.89676
Policy Loss                  -1058.6951
Q Predictions Mean           1059.3735
Q Predictions Std            1089.0216
Q Predictions Max            3764.249
Q Predictions Min            477.86212
V Predictions Mean           1065.9973
V Predictions Std            1090.9125
V Predictions Max            3784.62
V Predictions Min            493.19843
Log Pis Mean                 -0.26908827
Log Pis Std                  3.6085756
Log Pis Max                  18.669975
Log Pis Min                  -7.5180674
Policy mu Mean               0.121090375
Policy mu Std                0.852294
Policy mu Max                2.666929
Policy mu Min                -3.775427
Policy log std Mean          -0.5035259
Policy log std Std           0.2531225
Policy log std Max           -0.025385618
Policy log std Min           -2.2420769
Z mean eval                  1.6881678
Z variance eval              0.0752055
total_rewards                [8960.7718307  8891.70750301 8975.32849256 9165.19634514 9073.00157654
 9133.3876182  9064.66258784 9015.89149942 9110.71160039 8898.28628901]
total_rewards_mean           9028.894534281313
total_rewards_std            91.08990236879298
total_rewards_max            9165.196345138613
total_rewards_min            8891.70750301241
Number of train steps total  744000
Number of env steps total    2234000
Number of rollouts total     0
Train Time (s)               146.0289580952376
(Previous) Eval Time (s)     20.61761238798499
Sample Time (s)              6.599296495318413
Epoch Time (s)               173.24586697854102
Total Train Time (s)         31529.99859035015
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:39:08.804063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #185 | Epoch Duration: 173.32996201515198
2020-01-12 16:39:08.804216 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6929147
Z variance train             0.07503499
KL Divergence                40.433067
KL Loss                      4.043307
QF Loss                      107.75513
VF Loss                      77.071236
Policy Loss                  -1160.8866
Q Predictions Mean           1159.7887
Q Predictions Std            1187.3699
Q Predictions Max            3895.4338
Q Predictions Min            508.6103
V Predictions Mean           1156.3226
V Predictions Std            1179.4282
V Predictions Max            3851.3083
V Predictions Min            510.72162
Log Pis Mean                 -0.12497142
Log Pis Std                  4.0862308
Log Pis Max                  14.847245
Log Pis Min                  -7.8579445
Policy mu Mean               0.034792468
Policy mu Std                0.89092773
Policy mu Max                2.8521965
Policy mu Min                -3.0593386
Policy log std Mean          -0.5130408
Policy log std Std           0.2736389
Policy log std Max           0.053883433
Policy log std Min           -2.652573
Z mean eval                  1.6832106
Z variance eval              0.044726856
total_rewards                [9127.28107347 9217.31309368 9381.53577756 9228.52926014 9224.72640406
 9374.82394744 8873.76168263 9323.7496019  9134.47222852 9045.91052268]
total_rewards_mean           9193.210359207356
total_rewards_std            148.27461606291993
total_rewards_max            9381.535777556284
total_rewards_min            8873.761682633372
Number of train steps total  748000
Number of env steps total    2246000
Number of rollouts total     0
Train Time (s)               146.69075849512592
(Previous) Eval Time (s)     17.503177902661264
Sample Time (s)              6.564194628037512
Epoch Time (s)               170.7581310258247
Total Train Time (s)         31700.83462200174
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:41:59.642702 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #186 | Epoch Duration: 170.83836913108826
2020-01-12 16:41:59.642883 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6812952
Z variance train             0.044778105
KL Divergence                40.98622
KL Loss                      4.0986223
QF Loss                      120.175
VF Loss                      71.116554
Policy Loss                  -971.51263
Q Predictions Mean           965.75305
Q Predictions Std            1000.7689
Q Predictions Max            3814.5374
Q Predictions Min            490.57425
V Predictions Mean           968.2259
V Predictions Std            998.333
V Predictions Max            3797.3052
V Predictions Min            497.30133
Log Pis Mean                 -0.24333163
Log Pis Std                  3.7976022
Log Pis Max                  13.078165
Log Pis Min                  -8.25565
Policy mu Mean               0.07299315
Policy mu Std                0.8828938
Policy mu Max                2.7121458
Policy mu Min                -3.1922593
Policy log std Mean          -0.5220061
Policy log std Std           0.28319255
Policy log std Max           -0.08892533
Policy log std Min           -2.6927388
Z mean eval                  1.6982969
Z variance eval              0.073754236
total_rewards                [8729.11549421 8855.43115109 8534.85000619 8831.61565705 8747.45175516
 8842.92723104 8770.72902408 8771.01114152 8901.01092031 8798.67341147]
total_rewards_mean           8778.28157921226
total_rewards_std            95.49375458707605
total_rewards_max            8901.010920314637
total_rewards_min            8534.850006192728
Number of train steps total  752000
Number of env steps total    2258000
Number of rollouts total     0
Train Time (s)               146.2334445733577
(Previous) Eval Time (s)     20.514015895780176
Sample Time (s)              6.6737998547032475
Epoch Time (s)               173.42126032384112
Total Train Time (s)         31874.334378214553
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:44:53.143604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #187 | Epoch Duration: 173.50058937072754
2020-01-12 16:44:53.143743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.69918
Z variance train             0.07376666
KL Divergence                42.022305
KL Loss                      4.2022305
QF Loss                      203.33348
VF Loss                      58.304123
Policy Loss                  -1030.2057
Q Predictions Mean           1028.2969
Q Predictions Std            1052.1324
Q Predictions Max            3857.9048
Q Predictions Min            514.5825
V Predictions Mean           1027.4722
V Predictions Std            1046.4413
V Predictions Max            3834.3877
V Predictions Min            508.94064
Log Pis Mean                 -0.41910595
Log Pis Std                  3.8669984
Log Pis Max                  30.93509
Log Pis Min                  -6.8133607
Policy mu Mean               0.07851252
Policy mu Std                0.8694224
Policy mu Max                3.6326108
Policy mu Min                -5.131987
Policy log std Mean          -0.5172955
Policy log std Std           0.282295
Policy log std Max           0.24783498
Policy log std Min           -2.7574666
Z mean eval                  1.7012974
Z variance eval              0.06981384
total_rewards                [9055.8527424  9227.38238675 9326.92775445 9275.0929231  9042.88766155
 9357.5628536  9187.13099104 9025.91320589 9145.90520355 8998.66282145]
total_rewards_mean           9164.331854376103
total_rewards_std            124.0970315032281
total_rewards_max            9357.562853595204
total_rewards_min            8998.662821447433
Number of train steps total  756000
Number of env steps total    2270000
Number of rollouts total     0
Train Time (s)               146.06117654778063
(Previous) Eval Time (s)     17.705133387818933
Sample Time (s)              6.505432340782136
Epoch Time (s)               170.2717422763817
Total Train Time (s)         32044.684192322195
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:47:43.496358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #188 | Epoch Duration: 170.35249853134155
2020-01-12 16:47:43.496534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7033889
Z variance train             0.06980344
KL Divergence                42.23034
KL Loss                      4.223034
QF Loss                      180.09535
VF Loss                      54.474594
Policy Loss                  -1079.5981
Q Predictions Mean           1071.3921
Q Predictions Std            1086.5505
Q Predictions Max            3827.7783
Q Predictions Min            499.3461
V Predictions Mean           1075.8838
V Predictions Std            1088.7896
V Predictions Max            3827.151
V Predictions Min            501.15488
Log Pis Mean                 -0.1831907
Log Pis Std                  3.8747375
Log Pis Max                  15.6215725
Log Pis Min                  -6.2285876
Policy mu Mean               0.019477552
Policy mu Std                0.9053817
Policy mu Max                3.1374824
Policy mu Min                -3.2183952
Policy log std Mean          -0.5156011
Policy log std Std           0.27503237
Policy log std Max           -0.07646938
Policy log std Min           -2.2903826
Z mean eval                  1.6967999
Z variance eval              0.07256846
total_rewards                [8055.87149681 8438.19148796 7923.94645699 8513.50889405 8402.25122365
 8342.48249914 8283.66198916 8091.45583201 8566.28655266 8177.85165204]
total_rewards_mean           8279.550808447138
total_rewards_std            200.83890490163424
total_rewards_max            8566.286552657562
total_rewards_min            7923.9464569894135
Number of train steps total  760000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               145.58566031977534
(Previous) Eval Time (s)     20.964581673964858
Sample Time (s)              6.614951249677688
Epoch Time (s)               173.1651932434179
Total Train Time (s)         32217.93081958685
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:50:36.743347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #189 | Epoch Duration: 173.24668431282043
2020-01-12 16:50:36.743489 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.696228
Z variance train             0.072551355
KL Divergence                42.545883
KL Loss                      4.2545886
QF Loss                      4958.597
VF Loss                      58.29444
Policy Loss                  -1021.5836
Q Predictions Mean           1021.991
Q Predictions Std            1050.3866
Q Predictions Max            3894.7454
Q Predictions Min            499.67386
V Predictions Mean           1025.7759
V Predictions Std            1047.016
V Predictions Max            3896.5864
V Predictions Min            511.02496
Log Pis Mean                 -0.86824906
Log Pis Std                  3.1057398
Log Pis Max                  11.126255
Log Pis Min                  -7.6991215
Policy mu Mean               0.03502843
Policy mu Std                0.8167613
Policy mu Max                2.6623375
Policy mu Min                -2.4730887
Policy log std Mean          -0.4988329
Policy log std Std           0.24804287
Policy log std Max           -0.11597058
Policy log std Min           -2.2328906
Z mean eval                  1.7131548
Z variance eval              0.08508169
total_rewards                [8744.03473491 9010.82991797 9198.84992993 9036.29581483 9028.87370554
 9055.00217434 9186.43438188 9279.97704646 9036.0440885  9127.85564615]
total_rewards_mean           9070.419744051094
total_rewards_std            138.4033522907744
total_rewards_max            9279.977046456052
total_rewards_min            8744.034734910481
Number of train steps total  764000
Number of env steps total    2294000
Number of rollouts total     0
Train Time (s)               146.3015253241174
(Previous) Eval Time (s)     20.888772434089333
Sample Time (s)              6.453080204315484
Epoch Time (s)               173.6433779625222
Total Train Time (s)         32391.86983862752
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:53:30.684624 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #190 | Epoch Duration: 173.94103336334229
2020-01-12 16:53:30.684769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7122301
Z variance train             0.085130155
KL Divergence                43.088146
KL Loss                      4.3088145
QF Loss                      111.17697
VF Loss                      73.83535
Policy Loss                  -1075.9713
Q Predictions Mean           1074.2484
Q Predictions Std            1101.0171
Q Predictions Max            3814.6982
Q Predictions Min            524.4989
V Predictions Mean           1079.4575
V Predictions Std            1099.6755
V Predictions Max            3809.6775
V Predictions Min            531.6801
Log Pis Mean                 -0.4649627
Log Pis Std                  3.5166104
Log Pis Max                  13.519795
Log Pis Min                  -7.2708373
Policy mu Mean               0.100054145
Policy mu Std                0.8456689
Policy mu Max                3.5056214
Policy mu Min                -2.8714228
Policy log std Mean          -0.49662375
Policy log std Std           0.26584595
Policy log std Max           -0.06025821
Policy log std Min           -2.2817042
Z mean eval                  1.7108405
Z variance eval              0.09768604
total_rewards                [9064.96492276 8843.84718069 9080.48177216 7849.36996687 8888.08364186
 8996.29248104 8447.2173203  8684.48798925 8790.55424429 8933.08400103]
total_rewards_mean           8757.838352024508
total_rewards_std            351.9387883956527
total_rewards_max            9080.481772161405
total_rewards_min            7849.369966873522
Number of train steps total  768000
Number of env steps total    2306000
Number of rollouts total     0
Train Time (s)               147.20914561674
(Previous) Eval Time (s)     20.798536719288677
Sample Time (s)              6.364354544319212
Epoch Time (s)               174.37203688034788
Total Train Time (s)         32566.33170265844
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:56:25.148654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #191 | Epoch Duration: 174.46378540992737
2020-01-12 16:56:25.148788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.71293
Z variance train             0.09752443
KL Divergence                42.328804
KL Loss                      4.2328806
QF Loss                      109.03102
VF Loss                      39.30071
Policy Loss                  -1110.9706
Q Predictions Mean           1106.7029
Q Predictions Std            1111.5198
Q Predictions Max            3931.006
Q Predictions Min            515.82495
V Predictions Mean           1107.3689
V Predictions Std            1111.3822
V Predictions Max            3916.4011
V Predictions Min            520.30457
Log Pis Mean                 -0.6646637
Log Pis Std                  3.3591914
Log Pis Max                  11.680065
Log Pis Min                  -8.9846525
Policy mu Mean               0.059820037
Policy mu Std                0.846148
Policy mu Max                2.658929
Policy mu Min                -2.3936138
Policy log std Mean          -0.5142879
Policy log std Std           0.2466024
Policy log std Max           -0.031241536
Policy log std Min           -2.1553342
Z mean eval                  1.7075217
Z variance eval              0.09866415
total_rewards                [8667.54094963 2007.01678196 8769.71225676 8387.94578415 7955.34924932
 8181.82273449 8718.43459239 8195.27034475 8292.11266287 8110.82876064]
total_rewards_mean           7728.6034116968485
total_rewards_std            1924.962372848213
total_rewards_max            8769.712256763962
total_rewards_min            2007.016781955846
Number of train steps total  772000
Number of env steps total    2318000
Number of rollouts total     0
Train Time (s)               146.4284183094278
(Previous) Eval Time (s)     17.65025059087202
Sample Time (s)              6.390867673326284
Epoch Time (s)               170.4695365736261
Total Train Time (s)         32736.881064675283
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 16:59:15.700638 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #192 | Epoch Duration: 170.5517373085022
2020-01-12 16:59:15.700818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7113688
Z variance train             0.098663405
KL Divergence                42.053387
KL Loss                      4.205339
QF Loss                      2416.602
VF Loss                      126.08724
Policy Loss                  -1095.1356
Q Predictions Mean           1092.9553
Q Predictions Std            1130.604
Q Predictions Max            3909.1145
Q Predictions Min            508.8816
V Predictions Mean           1088.1948
V Predictions Std            1122.0159
V Predictions Max            3873.28
V Predictions Min            511.42462
Log Pis Mean                 -0.4339831
Log Pis Std                  3.5144646
Log Pis Max                  9.88088
Log Pis Min                  -7.5665216
Policy mu Mean               0.032218274
Policy mu Std                0.86186385
Policy mu Max                2.7161193
Policy mu Min                -2.4632177
Policy log std Mean          -0.5085588
Policy log std Std           0.2539084
Policy log std Max           -0.07049793
Policy log std Min           -2.5394394
Z mean eval                  1.6939878
Z variance eval              0.09998199
total_rewards                [8863.46816519 8971.66166663 9121.9370417  8719.17578061 8961.05348493
 8976.56614979 8960.71069964 9074.09421537 8864.30037384 9004.72990286]
total_rewards_mean           8951.76974805636
total_rewards_std            108.37419163692454
total_rewards_max            9121.937041702251
total_rewards_min            8719.175780609427
Number of train steps total  776000
Number of env steps total    2330000
Number of rollouts total     0
Train Time (s)               146.1112747597508
(Previous) Eval Time (s)     17.79670001938939
Sample Time (s)              6.5550921922549605
Epoch Time (s)               170.46306697139516
Total Train Time (s)         32907.42897571856
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:02:06.251603 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #193 | Epoch Duration: 170.55057764053345
2020-01-12 17:02:06.251878 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #193 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6941035
Z variance train             0.10006094
KL Divergence                41.76322
KL Loss                      4.1763225
QF Loss                      146.84152
VF Loss                      78.51757
Policy Loss                  -1092.3801
Q Predictions Mean           1089.6675
Q Predictions Std            1116.3761
Q Predictions Max            3844.5835
Q Predictions Min            509.43054
V Predictions Mean           1090.3726
V Predictions Std            1113.3141
V Predictions Max            3827.8677
V Predictions Min            510.29926
Log Pis Mean                 -0.6024409
Log Pis Std                  3.4898708
Log Pis Max                  14.074636
Log Pis Min                  -6.2672963
Policy mu Mean               0.04730612
Policy mu Std                0.83883363
Policy mu Max                3.1972768
Policy mu Min                -2.6674995
Policy log std Mean          -0.519337
Policy log std Std           0.27979717
Policy log std Max           -0.07951045
Policy log std Min           -2.7826838
Z mean eval                  1.687499
Z variance eval              0.09934179
total_rewards                [8948.24573182 9311.46456939 9349.55976587 9249.90585742 9321.7475005
 8986.36302182 9233.56369099 9122.57513271  940.2629385  9054.11324564]
total_rewards_mean           8351.780145463623
total_rewards_std            2474.2275092983887
total_rewards_max            9349.55976586637
total_rewards_min            940.2629384956426
Number of train steps total  780000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               146.29665383836254
(Previous) Eval Time (s)     20.944590090774
Sample Time (s)              6.55358438519761
Epoch Time (s)               173.79482831433415
Total Train Time (s)         33081.30736576766
Epoch                        194
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:05:00.131973 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #194 | Epoch Duration: 173.879900932312
2020-01-12 17:05:00.132162 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6905864
Z variance train             0.09944467
KL Divergence                42.120075
KL Loss                      4.2120075
QF Loss                      131.38678
VF Loss                      150.87064
Policy Loss                  -1126.9905
Q Predictions Mean           1123.0107
Q Predictions Std            1117.5967
Q Predictions Max            3954.2698
Q Predictions Min            522.7745
V Predictions Mean           1121.9597
V Predictions Std            1113.3804
V Predictions Max            3896.791
V Predictions Min            509.06122
Log Pis Mean                 -0.33159247
Log Pis Std                  3.605218
Log Pis Max                  12.687901
Log Pis Min                  -7.418553
Policy mu Mean               0.044152368
Policy mu Std                0.85397077
Policy mu Max                2.7186706
Policy mu Min                -3.1039262
Policy log std Mean          -0.5266972
Policy log std Std           0.26946068
Policy log std Max           -0.10856207
Policy log std Min           -2.5221846
Z mean eval                  1.6858763
Z variance eval              0.09752665
total_rewards                [8598.15088834 8791.00557521 8514.59404653 8650.23633292 8925.93605988
 8882.93467989 8755.42190292 8783.56037741 8841.11109079 8696.02344304]
total_rewards_mean           8743.897439692844
total_rewards_std            122.77274595711228
total_rewards_max            8925.936059875186
total_rewards_min            8514.594046525977
Number of train steps total  784000
Number of env steps total    2354000
Number of rollouts total     0
Train Time (s)               145.39813102781773
(Previous) Eval Time (s)     20.768622654955834
Sample Time (s)              6.4320673337206244
Epoch Time (s)               172.59882101649418
Total Train Time (s)         33254.1308147884
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:07:52.968422 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #195 | Epoch Duration: 172.8360824584961
2020-01-12 17:07:52.968644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6869322
Z variance train             0.09857558
KL Divergence                41.740486
KL Loss                      4.174049
QF Loss                      2655.0027
VF Loss                      236.94188
Policy Loss                  -994.03394
Q Predictions Mean           990.6623
Q Predictions Std            1011.4478
Q Predictions Max            3822.3179
Q Predictions Min            508.60336
V Predictions Mean           983.782
V Predictions Std            1001.33344
V Predictions Max            3789.1675
V Predictions Min            504.4289
Log Pis Mean                 -0.41232193
Log Pis Std                  3.2441995
Log Pis Max                  14.015472
Log Pis Min                  -5.7023067
Policy mu Mean               0.065329485
Policy mu Std                0.8528315
Policy mu Max                2.5796323
Policy mu Min                -2.3421009
Policy log std Mean          -0.51113415
Policy log std Std           0.25445306
Policy log std Max           -0.06577748
Policy log std Min           -2.3574493
Z mean eval                  1.6972668
Z variance eval              0.072154336
total_rewards                [9084.05034776 9289.10403729 9106.24619919 9036.86696754 8879.08527931
 8804.35633206 8997.89068029 9159.0003147  9311.77155369 8876.99261705]
total_rewards_mean           9054.536432886644
total_rewards_std            162.50092002550923
total_rewards_max            9311.771553689257
total_rewards_min            8804.35633205933
Number of train steps total  788000
Number of env steps total    2366000
Number of rollouts total     0
Train Time (s)               145.12612400529906
(Previous) Eval Time (s)     20.77337004803121
Sample Time (s)              6.528977301903069
Epoch Time (s)               172.42847135523334
Total Train Time (s)         33426.66569200717
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:10:45.501788 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #196 | Epoch Duration: 172.5330033302307
2020-01-12 17:10:45.501984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #196 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.697056
Z variance train             0.0721449
KL Divergence                42.3384
KL Loss                      4.2338405
QF Loss                      127.26834
VF Loss                      49.471657
Policy Loss                  -1068.5692
Q Predictions Mean           1069.5156
Q Predictions Std            1107.2277
Q Predictions Max            3961.0647
Q Predictions Min            508.89404
V Predictions Mean           1073.2957
V Predictions Std            1105.42
V Predictions Max            3974.995
V Predictions Min            529.3073
Log Pis Mean                 -0.36789978
Log Pis Std                  3.3500416
Log Pis Max                  10.806175
Log Pis Min                  -6.775489
Policy mu Mean               0.06737876
Policy mu Std                0.8642825
Policy mu Max                2.5811691
Policy mu Min                -2.7266467
Policy log std Mean          -0.504394
Policy log std Std           0.25166667
Policy log std Max           0.14978456
Policy log std Min           -2.1345081
Z mean eval                  1.7132845
Z variance eval              0.046563752
total_rewards                [9400.63277713 9239.78458436 9127.05388018 9475.27252825 9140.4557224
 9390.94268946 9268.3348912  9313.07617424 9484.31704902 9369.31508886]
total_rewards_mean           9320.918538510361
total_rewards_std            119.86817339661017
total_rewards_max            9484.317049021536
total_rewards_min            9127.053880182466
Number of train steps total  792000
Number of env steps total    2378000
Number of rollouts total     0
Train Time (s)               146.23433418991044
(Previous) Eval Time (s)     17.264515683054924
Sample Time (s)              6.498865949455649
Epoch Time (s)               169.99771582242101
Total Train Time (s)         33596.77547014784
Epoch                        197
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:13:35.605472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #197 | Epoch Duration: 170.10334062576294
2020-01-12 17:13:35.605644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7101166
Z variance train             0.046656154
KL Divergence                43.33781
KL Loss                      4.3337812
QF Loss                      155.17923
VF Loss                      67.90176
Policy Loss                  -1132.5665
Q Predictions Mean           1129.8606
Q Predictions Std            1136.9994
Q Predictions Max            3843.9482
Q Predictions Min            523.76807
V Predictions Mean           1134.732
V Predictions Std            1139.3578
V Predictions Max            3858.0635
V Predictions Min            518.5453
Log Pis Mean                 -0.20544933
Log Pis Std                  3.8032186
Log Pis Max                  16.528885
Log Pis Min                  -7.123689
Policy mu Mean               0.04097895
Policy mu Std                0.8869602
Policy mu Max                2.7028778
Policy mu Min                -3.1180735
Policy log std Mean          -0.50919896
Policy log std Std           0.25642294
Policy log std Max           -0.016150653
Policy log std Min           -2.4187155
Z mean eval                  1.7298286
Z variance eval              0.034972824
total_rewards                [8885.23527284 9062.23051812 8762.77357894 9080.35799275 8959.74715058
 9061.72889101 9076.00596579 9088.36798266 8815.36808447 8881.20348039]
total_rewards_mean           8967.30189175462
total_rewards_std            116.74922328420581
total_rewards_max            9088.36798265947
total_rewards_min            8762.773578941942
Number of train steps total  796000
Number of env steps total    2390000
Number of rollouts total     0
Train Time (s)               146.79004019405693
(Previous) Eval Time (s)     17.642449305858463
Sample Time (s)              5.566497159190476
Epoch Time (s)               169.99898665910587
Total Train Time (s)         33766.861504524015
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:16:25.700630 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #198 | Epoch Duration: 170.0948028564453
2020-01-12 17:16:25.700950 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #198 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.730148
Z variance train             0.03510184
KL Divergence                45.136093
KL Loss                      4.5136094
QF Loss                      2917.624
VF Loss                      51.886482
Policy Loss                  -1137.0054
Q Predictions Mean           1135.0513
Q Predictions Std            1146.0348
Q Predictions Max            3960.175
Q Predictions Min            509.89648
V Predictions Mean           1136.6287
V Predictions Std            1141.7587
V Predictions Max            3940.1152
V Predictions Min            514.72577
Log Pis Mean                 -0.1736877
Log Pis Std                  3.6384394
Log Pis Max                  12.312453
Log Pis Min                  -7.2218714
Policy mu Mean               0.09689351
Policy mu Std                0.89153004
Policy mu Max                2.5628476
Policy mu Min                -2.536098
Policy log std Mean          -0.51021296
Policy log std Std           0.26506257
Policy log std Max           0.101284266
Policy log std Min           -2.5537746
Z mean eval                  1.6934904
Z variance eval              0.06726597
total_rewards                [9035.13707719 9060.57770612 9034.11948595 8896.19638665 8929.130574
 8953.68668346 9145.33438515 9123.97715044 9074.90246392 9182.21775596]
total_rewards_mean           9043.527966883248
total_rewards_std            89.64946680287748
total_rewards_max            9182.217755956162
total_rewards_min            8896.196386653877
Number of train steps total  800000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               147.95308530004695
(Previous) Eval Time (s)     20.543671780265868
Sample Time (s)              6.628586707636714
Epoch Time (s)               175.12534378794953
Total Train Time (s)         33942.07764771301
Epoch                        199
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:19:20.915157 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #199 | Epoch Duration: 175.21397614479065
2020-01-12 17:19:20.915330 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6934481
Z variance train             0.06693025
KL Divergence                42.637115
KL Loss                      4.2637115
QF Loss                      90.05505
VF Loss                      40.932335
Policy Loss                  -1032.6726
Q Predictions Mean           1031.0654
Q Predictions Std            1054.4419
Q Predictions Max            3895.7703
Q Predictions Min            511.85114
V Predictions Mean           1030.1371
V Predictions Std            1050.9147
V Predictions Max            3871.3066
V Predictions Min            513.6952
Log Pis Mean                 -0.6363443
Log Pis Std                  3.189686
Log Pis Max                  10.824417
Log Pis Min                  -7.319549
Policy mu Mean               0.027788669
Policy mu Std                0.83063024
Policy mu Max                2.7241476
Policy mu Min                -2.7460096
Policy log std Mean          -0.5051399
Policy log std Std           0.2380272
Policy log std Max           -0.10197112
Policy log std Min           -2.2224302
Z mean eval                  1.7046881
Z variance eval              0.07738371
total_rewards                [8635.62865008 9180.35615152 8836.09541041 8560.40554791 8690.61258751
 9056.37352271 8733.50789677 8936.39478769 9041.83369063 9179.53014864]
total_rewards_mean           8885.073839388815
total_rewards_std            214.77102598417872
total_rewards_max            9180.356151517468
total_rewards_min            8560.405547914112
Number of train steps total  804000
Number of env steps total    2414000
Number of rollouts total     0
Train Time (s)               146.65308483038098
(Previous) Eval Time (s)     20.704933612141758
Sample Time (s)              6.581762968562543
Epoch Time (s)               173.93978141108528
Total Train Time (s)         34116.114224698395
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:22:14.952907 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #200 | Epoch Duration: 174.0374550819397
2020-01-12 17:22:14.953039 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #200 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7025543
Z variance train             0.077754855
KL Divergence                43.079063
KL Loss                      4.3079066
QF Loss                      262.73804
VF Loss                      115.987
Policy Loss                  -1062.7311
Q Predictions Mean           1060.2556
Q Predictions Std            1111.2787
Q Predictions Max            3966.4458
Q Predictions Min            505.7833
V Predictions Mean           1065.2811
V Predictions Std            1105.2432
V Predictions Max            3951.12
V Predictions Min            513.8231
Log Pis Mean                 -0.25854868
Log Pis Std                  3.3496912
Log Pis Max                  13.916698
Log Pis Min                  -6.3010397
Policy mu Mean               0.030226903
Policy mu Std                0.8847779
Policy mu Max                2.7222977
Policy mu Min                -2.9807284
Policy log std Mean          -0.5126122
Policy log std Std           0.25592157
Policy log std Max           0.027311087
Policy log std Min           -2.2823534
Z mean eval                  1.7027302
Z variance eval              0.08439375
total_rewards                [9256.29474799 8722.04319239 9008.89110593 9374.49495664 9181.3014047
 9123.07689693 9025.04572697 9247.19248194 9205.59880837 9356.76608279]
total_rewards_mean           9150.070540465571
total_rewards_std            183.67451625353428
total_rewards_max            9374.494956637676
total_rewards_min            8722.043192387528
Number of train steps total  808000
Number of env steps total    2426000
Number of rollouts total     0
Train Time (s)               146.6006886921823
(Previous) Eval Time (s)     20.985144505277276
Sample Time (s)              6.4868084019981325
Epoch Time (s)               174.0726415994577
Total Train Time (s)         34290.268560175784
Epoch                        201
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:25:09.109703 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #201 | Epoch Duration: 174.15656805038452
2020-01-12 17:25:09.109835 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7040704
Z variance train             0.08433118
KL Divergence                43.038284
KL Loss                      4.3038287
QF Loss                      128.56938
VF Loss                      49.131824
Policy Loss                  -969.7598
Q Predictions Mean           967.71985
Q Predictions Std            1004.434
Q Predictions Max            3947.7324
Q Predictions Min            533.07764
V Predictions Mean           967.35486
V Predictions Std            1002.2098
V Predictions Max            3940.7803
V Predictions Min            538.7566
Log Pis Mean                 -0.77706933
Log Pis Std                  3.1419814
Log Pis Max                  11.614351
Log Pis Min                  -6.813018
Policy mu Mean               0.11206687
Policy mu Std                0.8236692
Policy mu Max                2.656862
Policy mu Min                -2.6422122
Policy log std Mean          -0.4997275
Policy log std Std           0.25389695
Policy log std Max           -0.03843385
Policy log std Min           -2.3095987
Z mean eval                  1.7314816
Z variance eval              0.05944872
total_rewards                [8962.89871386 9295.11216908 9079.80439342 9319.55555777 9181.30589408
 9211.80810827 8952.34715282 9023.32113935 9223.57665005 9001.13942716]
total_rewards_mean           9125.08692058484
total_rewards_std            130.77530522034843
total_rewards_max            9319.555557773198
total_rewards_min            8952.347152816446
Number of train steps total  812000
Number of env steps total    2438000
Number of rollouts total     0
Train Time (s)               146.30680440366268
(Previous) Eval Time (s)     17.450661988928914
Sample Time (s)              6.613486037123948
Epoch Time (s)               170.37095242971554
Total Train Time (s)         34460.71851816634
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:27:59.561807 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #202 | Epoch Duration: 170.4518575668335
2020-01-12 17:27:59.561984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7280226
Z variance train             0.059491236
KL Divergence                43.006504
KL Loss                      4.3006506
QF Loss                      218.16162
VF Loss                      49.431828
Policy Loss                  -1145.1229
Q Predictions Mean           1143.084
Q Predictions Std            1154.9609
Q Predictions Max            3938.4329
Q Predictions Min            536.3683
V Predictions Mean           1149.331
V Predictions Std            1150.6135
V Predictions Max            3932.0867
V Predictions Min            536.6733
Log Pis Mean                 -0.23706186
Log Pis Std                  3.62566
Log Pis Max                  13.337173
Log Pis Min                  -6.336797
Policy mu Mean               0.055251688
Policy mu Std                0.87684625
Policy mu Max                2.6041398
Policy mu Min                -3.2638223
Policy log std Mean          -0.5313512
Policy log std Std           0.26353863
Policy log std Max           -0.07100195
Policy log std Min           -2.4740162
Z mean eval                  1.6924375
Z variance eval              0.08173929
total_rewards                [9387.12025017 9582.17877241 9427.4809419  9147.32953664 9358.40084674
 9426.93718343 9466.81209778 9280.15773839 9455.61685981 9345.18268605]
total_rewards_mean           9387.72169133243
total_rewards_std            111.27681166472821
total_rewards_max            9582.178772406234
total_rewards_min            9147.329536635338
Number of train steps total  816000
Number of env steps total    2450000
Number of rollouts total     0
Train Time (s)               146.11444965470582
(Previous) Eval Time (s)     20.962142202071846
Sample Time (s)              6.429278474766761
Epoch Time (s)               173.50587033154443
Total Train Time (s)         34634.30784211354
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:30:53.154419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #203 | Epoch Duration: 173.59225368499756
2020-01-12 17:30:53.154777 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6925848
Z variance train             0.08170718
KL Divergence                41.83606
KL Loss                      4.183606
QF Loss                      2798.2761
VF Loss                      37.48662
Policy Loss                  -891.8705
Q Predictions Mean           889.69214
Q Predictions Std            887.7412
Q Predictions Max            3937.3062
Q Predictions Min            508.95593
V Predictions Mean           891.961
V Predictions Std            886.7543
V Predictions Max            3937.7725
V Predictions Min            503.5324
Log Pis Mean                 -0.3690133
Log Pis Std                  3.2065904
Log Pis Max                  13.994274
Log Pis Min                  -6.6884956
Policy mu Mean               0.117606424
Policy mu Std                0.81976503
Policy mu Max                2.6123426
Policy mu Min                -2.8047683
Policy log std Mean          -0.524576
Policy log std Std           0.26558673
Policy log std Max           -0.0017889738
Policy log std Min           -2.8540447
Z mean eval                  1.6903225
Z variance eval              0.05551973
total_rewards                [8800.95313272 9230.35869249 8869.4653431  9051.99564197 8954.59150072
 9118.55430205 9139.07371282 8960.47036955 9059.11963547 9010.17206148]
total_rewards_mean           9019.47543923861
total_rewards_std            122.16973620274265
total_rewards_max            9230.358692494017
total_rewards_min            8800.953132716475
Number of train steps total  820000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               146.2352784909308
(Previous) Eval Time (s)     20.68618691712618
Sample Time (s)              5.461730735376477
Epoch Time (s)               172.38319614343345
Total Train Time (s)         34806.86846993631
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:33:45.719645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #204 | Epoch Duration: 172.56465578079224
2020-01-12 17:33:45.719865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6906471
Z variance train             0.055423014
KL Divergence                40.743412
KL Loss                      4.0743413
QF Loss                      65.984024
VF Loss                      41.57206
Policy Loss                  -987.5015
Q Predictions Mean           985.16815
Q Predictions Std            1008.15546
Q Predictions Max            3896.6208
Q Predictions Min            526.492
V Predictions Mean           989.71826
V Predictions Std            1005.7356
V Predictions Max            3897.4631
V Predictions Min            531.1801
Log Pis Mean                 -0.5705572
Log Pis Std                  3.1791873
Log Pis Max                  12.076463
Log Pis Min                  -6.6921935
Policy mu Mean               0.04897066
Policy mu Std                0.8237012
Policy mu Max                2.8734207
Policy mu Min                -2.9739344
Policy log std Mean          -0.51332456
Policy log std Std           0.2759577
Policy log std Max           -0.06010151
Policy log std Min           -3.0441368
Z mean eval                  1.694061
Z variance eval              0.17534448
total_rewards                [8522.28581664 8727.04272125 8744.22807007 8729.46642272 8766.65580571
 8536.74072661 8879.14772599 8606.89090823 8767.17556941 8533.12063167]
total_rewards_mean           8681.275439830473
total_rewards_std            116.55600312058928
total_rewards_max            8879.147725985078
total_rewards_min            8522.28581664432
Number of train steps total  824000
Number of env steps total    2474000
Number of rollouts total     0
Train Time (s)               145.50517260935158
(Previous) Eval Time (s)     20.992055953014642
Sample Time (s)              6.4334769560955465
Epoch Time (s)               172.93070551846176
Total Train Time (s)         34979.898139628116
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:36:38.749014 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #205 | Epoch Duration: 173.0289978981018
2020-01-12 17:36:38.749152 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6941204
Z variance train             0.17628342
KL Divergence                36.657467
KL Loss                      3.6657467
QF Loss                      248.04498
VF Loss                      88.03432
Policy Loss                  -1129.4954
Q Predictions Mean           1127.0642
Q Predictions Std            1159.8922
Q Predictions Max            3984.654
Q Predictions Min            529.77014
V Predictions Mean           1126.9668
V Predictions Std            1161.3185
V Predictions Max            4002.2344
V Predictions Min            521.97003
Log Pis Mean                 0.1136894
Log Pis Std                  3.886417
Log Pis Max                  18.714848
Log Pis Min                  -7.621908
Policy mu Mean               -0.018717026
Policy mu Std                0.9463863
Policy mu Max                3.0051389
Policy mu Min                -3.1722193
Policy log std Mean          -0.4756864
Policy log std Std           0.24740605
Policy log std Max           0.0004773736
Policy log std Min           -2.314725
Z mean eval                  1.735349
Z variance eval              0.13897789
total_rewards                [8911.13167997 9168.65687446 9114.3796691  8820.8405071  9021.18266949
 9313.01805684 8943.9738834  9090.06263041 9033.5042699  9062.63102755]
total_rewards_mean           9047.938126821191
total_rewards_std            131.63103981255654
total_rewards_max            9313.018056838313
total_rewards_min            8820.840507096595
Number of train steps total  828000
Number of env steps total    2486000
Number of rollouts total     0
Train Time (s)               146.93720084009692
(Previous) Eval Time (s)     19.570022805128247
Sample Time (s)              6.476296167355031
Epoch Time (s)               172.9835198125802
Total Train Time (s)         35153.00406690873
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:39:31.866612 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #206 | Epoch Duration: 173.11733961105347
2020-01-12 17:39:31.866828 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7378677
Z variance train             0.13888685
KL Divergence                38.66286
KL Loss                      3.866286
QF Loss                      140.82191
VF Loss                      61.11139
Policy Loss                  -1081.3616
Q Predictions Mean           1080.7632
Q Predictions Std            1091.1627
Q Predictions Max            4080.2942
Q Predictions Min            542.2383
V Predictions Mean           1080.7961
V Predictions Std            1087.1604
V Predictions Max            4050.0957
V Predictions Min            548.38025
Log Pis Mean                 -0.15279005
Log Pis Std                  3.5692475
Log Pis Max                  15.352744
Log Pis Min                  -10.105234
Policy mu Mean               0.006608682
Policy mu Std                0.9063831
Policy mu Max                2.5421734
Policy mu Min                -3.4760025
Policy log std Mean          -0.49777377
Policy log std Std           0.24644548
Policy log std Max           -0.021213114
Policy log std Min           -2.464424
Z mean eval                  1.7130544
Z variance eval              0.18530285
total_rewards                [8880.91843699 8741.02966101 8657.50834887 8670.24581531 8858.28912114
 8723.54448849 8954.19656741 8704.649761   8796.88256958 8773.91148641]
total_rewards_mean           8776.117625620971
total_rewards_std            91.79503288819103
total_rewards_max            8954.19656741343
total_rewards_min            8657.508348874024
Number of train steps total  832000
Number of env steps total    2498000
Number of rollouts total     0
Train Time (s)               143.655111821834
(Previous) Eval Time (s)     21.95609152689576
Sample Time (s)              6.91140774730593
Epoch Time (s)               172.5226110960357
Total Train Time (s)         35325.61553229997
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:42:24.472613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #207 | Epoch Duration: 172.60564851760864
2020-01-12 17:42:24.472745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7113113
Z variance train             0.1855948
KL Divergence                37.94906
KL Loss                      3.794906
QF Loss                      234.90213
VF Loss                      29.879597
Policy Loss                  -1166.9312
Q Predictions Mean           1164.167
Q Predictions Std            1187.9684
Q Predictions Max            4133.4634
Q Predictions Min            522.7659
V Predictions Mean           1167.4124
V Predictions Std            1188.6041
V Predictions Max            4139.5127
V Predictions Min            533.93787
Log Pis Mean                 -0.3580705
Log Pis Std                  3.3955433
Log Pis Max                  12.93464
Log Pis Min                  -5.9884186
Policy mu Mean               0.02292051
Policy mu Std                0.8771618
Policy mu Max                2.8516917
Policy mu Min                -2.748975
Policy log std Mean          -0.5326974
Policy log std Std           0.2819091
Policy log std Max           -0.0036711395
Policy log std Min           -2.811674
Z mean eval                  1.7142677
Z variance eval              0.12710182
total_rewards                [9064.49360866 9084.86728605 9062.13478498 9135.35405517 9364.88434989
 9213.11309527 9145.08137325 8970.06269472 8951.31974702 9118.00178156]
total_rewards_mean           9110.931277657304
total_rewards_std            112.81961916722486
total_rewards_max            9364.88434989149
total_rewards_min            8951.319747024985
Number of train steps total  836000
Number of env steps total    2510000
Number of rollouts total     0
Train Time (s)               144.3762525380589
(Previous) Eval Time (s)     20.815607185009867
Sample Time (s)              6.896891946904361
Epoch Time (s)               172.08875166997313
Total Train Time (s)         35497.7839936642
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:45:16.652090 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #208 | Epoch Duration: 172.17924904823303
2020-01-12 17:45:16.652224 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.712814
Z variance train             0.12687448
KL Divergence                38.77152
KL Loss                      3.877152
QF Loss                      2749.7139
VF Loss                      191.15712
Policy Loss                  -1258.1925
Q Predictions Mean           1257.766
Q Predictions Std            1267.8527
Q Predictions Max            4044.3735
Q Predictions Min            502.2954
V Predictions Mean           1268.1592
V Predictions Std            1272.1788
V Predictions Max            4039.4033
V Predictions Min            507.65613
Log Pis Mean                 0.22878888
Log Pis Std                  3.8011475
Log Pis Max                  14.200465
Log Pis Min                  -5.9273806
Policy mu Mean               0.025564425
Policy mu Std                0.9287778
Policy mu Max                2.9686956
Policy mu Min                -3.2209122
Policy log std Mean          -0.5344067
Policy log std Std           0.26013207
Policy log std Max           0.24928093
Policy log std Min           -2.3762124
Z mean eval                  1.7091122
Z variance eval              0.07407548
total_rewards                [9232.34369818 9508.05845685 9397.01060684 9285.29081517 9258.66877188
 9305.32651157 9258.16365039 9274.1542535  9234.30268099 9300.95193063]
total_rewards_mean           9305.427137599567
total_rewards_std            81.03736494843014
total_rewards_max            9508.058456851146
total_rewards_min            9232.343698178307
Number of train steps total  840000
Number of env steps total    2522000
Number of rollouts total     0
Train Time (s)               143.91588306613266
(Previous) Eval Time (s)     21.111531027127057
Sample Time (s)              6.59813128085807
Epoch Time (s)               171.6255453741178
Total Train Time (s)         35669.50284263771
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:48:08.365283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #209 | Epoch Duration: 171.71294379234314
2020-01-12 17:48:08.365472 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7082949
Z variance train             0.074122146
KL Divergence                40.026768
KL Loss                      4.002677
QF Loss                      222.36508
VF Loss                      56.87302
Policy Loss                  -1327.4528
Q Predictions Mean           1321.2494
Q Predictions Std            1299.1411
Q Predictions Max            4117.9688
Q Predictions Min            507.92996
V Predictions Mean           1329.4716
V Predictions Std            1304.4058
V Predictions Max            4104.146
V Predictions Min            525.1413
Log Pis Mean                 0.28042114
Log Pis Std                  3.8466322
Log Pis Max                  12.965671
Log Pis Min                  -6.301421
Policy mu Mean               0.05829531
Policy mu Std                0.94377303
Policy mu Max                2.7349207
Policy mu Min                -2.735943
Policy log std Mean          -0.543623
Policy log std Std           0.28455487
Policy log std Max           -0.07125291
Policy log std Min           -2.5396104
Z mean eval                  1.7066746
Z variance eval              0.089258716
total_rewards                [8553.54979952 9172.39667209 9105.98260973 9221.72387024 9149.98970937
 9216.49968053 8931.03345228 9181.8790011  6384.38570599 9275.86589511]
total_rewards_mean           8819.3306395954
total_rewards_std            835.9284366400548
total_rewards_max            9275.865895107858
total_rewards_min            6384.385705986135
Number of train steps total  844000
Number of env steps total    2534000
Number of rollouts total     0
Train Time (s)               146.73322032624856
(Previous) Eval Time (s)     21.078335050027817
Sample Time (s)              6.955166131723672
Epoch Time (s)               174.76672150800005
Total Train Time (s)         35844.34945812123
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:51:03.219392 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #210 | Epoch Duration: 174.8537561893463
2020-01-12 17:51:03.219650 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7074264
Z variance train             0.08898366
KL Divergence                40.92733
KL Loss                      4.092733
QF Loss                      2491.755
VF Loss                      110.99331
Policy Loss                  -1177.7621
Q Predictions Mean           1178.3198
Q Predictions Std            1211.4381
Q Predictions Max            4103.5386
Q Predictions Min            542.0405
V Predictions Mean           1186.2219
V Predictions Std            1211.5927
V Predictions Max            4108.407
V Predictions Min            550.6748
Log Pis Mean                 -0.07719603
Log Pis Std                  3.733366
Log Pis Max                  13.53549
Log Pis Min                  -5.7263837
Policy mu Mean               0.038000587
Policy mu Std                0.8846872
Policy mu Max                2.6210961
Policy mu Min                -3.0157094
Policy log std Mean          -0.51465064
Policy log std Std           0.2735969
Policy log std Max           -0.04598683
Policy log std Min           -2.4612968
Z mean eval                  1.7068379
Z variance eval              0.12312776
total_rewards                [8894.56475638 6886.04382312 9000.5356847  9434.36435095 8900.3604714
 9006.67538998 9334.43005959 9099.6112185  8797.17300654 8849.34654117]
total_rewards_mean           8820.31053023305
total_rewards_std            673.890988162474
total_rewards_max            9434.364350952283
total_rewards_min            6886.043823123855
Number of train steps total  848000
Number of env steps total    2546000
Number of rollouts total     0
Train Time (s)               145.24092021817341
(Previous) Eval Time (s)     20.682845467701554
Sample Time (s)              5.637660083826631
Epoch Time (s)               171.5614257697016
Total Train Time (s)         36016.002434975
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:53:54.871604 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #211 | Epoch Duration: 171.6517791748047
2020-01-12 17:53:54.871736 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7070545
Z variance train             0.12288682
KL Divergence                40.02068
KL Loss                      4.002068
QF Loss                      120.987816
VF Loss                      79.65114
Policy Loss                  -1173.1714
Q Predictions Mean           1165.3821
Q Predictions Std            1176.556
Q Predictions Max            4043.4602
Q Predictions Min            540.2183
V Predictions Mean           1172.3157
V Predictions Std            1175.8816
V Predictions Max            4009.4634
V Predictions Min            549.72455
Log Pis Mean                 -0.17129433
Log Pis Std                  3.7941308
Log Pis Max                  17.011341
Log Pis Min                  -6.879841
Policy mu Mean               0.028044812
Policy mu Std                0.9055751
Policy mu Max                2.6297326
Policy mu Min                -3.126706
Policy log std Mean          -0.5433321
Policy log std Std           0.30177808
Policy log std Max           -0.047489226
Policy log std Min           -2.7552564
Z mean eval                  1.7146492
Z variance eval              0.13211767
total_rewards                [8551.15927249 8415.28481405 8732.34627108 8643.96811575 8274.45933953
 8531.59150431 8380.38709562 8478.87014943 8168.72043922 8640.78691337]
total_rewards_mean           8481.75739148475
total_rewards_std            166.5428013437008
total_rewards_max            8732.346271083727
total_rewards_min            8168.720439217954
Number of train steps total  852000
Number of env steps total    2558000
Number of rollouts total     0
Train Time (s)               145.87384576303884
(Previous) Eval Time (s)     21.23324052011594
Sample Time (s)              6.437002129852772
Epoch Time (s)               173.54408841300756
Total Train Time (s)         36189.64059030777
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:56:48.512446 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #212 | Epoch Duration: 173.64060735702515
2020-01-12 17:56:48.512581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7150263
Z variance train             0.13211247
KL Divergence                39.828327
KL Loss                      3.9828327
QF Loss                      307.25977
VF Loss                      66.07424
Policy Loss                  -1168.8378
Q Predictions Mean           1167.8677
Q Predictions Std            1181.1508
Q Predictions Max            4096.4756
Q Predictions Min            517.50977
V Predictions Mean           1169.2595
V Predictions Std            1182.7305
V Predictions Max            4113.2373
V Predictions Min            534.58997
Log Pis Mean                 -0.23663333
Log Pis Std                  3.7575884
Log Pis Max                  11.7329235
Log Pis Min                  -6.7338905
Policy mu Mean               0.078871004
Policy mu Std                0.87999105
Policy mu Max                2.7403817
Policy mu Min                -2.4625795
Policy log std Mean          -0.5067051
Policy log std Std           0.29411194
Policy log std Max           -0.08375268
Policy log std Min           -2.782281
Z mean eval                  1.7337275
Z variance eval              0.10577212
total_rewards                [8916.59303144 9238.50155427 9571.39541518 9264.87420882 9192.14958397
 9426.19027467 9597.29501517 9240.11104867 9433.77334602 9187.53577301]
total_rewards_mean           9306.841925122211
total_rewards_std            193.71999282871909
total_rewards_max            9597.295015172485
total_rewards_min            8916.593031439448
Number of train steps total  856000
Number of env steps total    2570000
Number of rollouts total     0
Train Time (s)               146.41540854191408
(Previous) Eval Time (s)     21.058708952274173
Sample Time (s)              6.57752860058099
Epoch Time (s)               174.05164609476924
Total Train Time (s)         36363.778908691835
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 17:59:42.652401 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #213 | Epoch Duration: 174.13972449302673
2020-01-12 17:59:42.652539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7348278
Z variance train             0.10549116
KL Divergence                40.596256
KL Loss                      4.0596256
QF Loss                      198.89307
VF Loss                      40.78517
Policy Loss                  -1215.588
Q Predictions Mean           1212.1553
Q Predictions Std            1233.6992
Q Predictions Max            4108.7866
Q Predictions Min            545.6882
V Predictions Mean           1212.9707
V Predictions Std            1228.0247
V Predictions Max            4095.9084
V Predictions Min            557.4882
Log Pis Mean                 -0.09313153
Log Pis Std                  3.4710288
Log Pis Max                  12.637717
Log Pis Min                  -6.3797736
Policy mu Mean               0.04520963
Policy mu Std                0.8905494
Policy mu Max                3.1741407
Policy mu Min                -3.1147223
Policy log std Mean          -0.55406576
Policy log std Std           0.29840013
Policy log std Max           -0.0071983337
Policy log std Min           -2.7259367
Z mean eval                  1.7440834
Z variance eval              0.08302575
total_rewards                [8835.95622926 9009.54854272 9158.50252556 8993.98975441 9146.51888748
 9102.74506122 8974.82661368 9026.06162089 9195.34471502 9087.04941907]
total_rewards_mean           9053.05433693032
total_rewards_std            101.5320042541595
total_rewards_max            9195.344715015613
total_rewards_min            8835.956229255318
Number of train steps total  860000
Number of env steps total    2582000
Number of rollouts total     0
Train Time (s)               144.70381261780858
(Previous) Eval Time (s)     17.53740318212658
Sample Time (s)              6.401593696791679
Epoch Time (s)               168.64280949672684
Total Train Time (s)         36532.50011877203
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:02:31.376324 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #214 | Epoch Duration: 168.7236704826355
2020-01-12 18:02:31.376504 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7405058
Z variance train             0.08323489
KL Divergence                41.356907
KL Loss                      4.1356907
QF Loss                      153.21512
VF Loss                      140.55891
Policy Loss                  -1111.5717
Q Predictions Mean           1109.4501
Q Predictions Std            1120.4004
Q Predictions Max            4071.3918
Q Predictions Min            544.2443
V Predictions Mean           1119.488
V Predictions Std            1122.305
V Predictions Max            4074.3552
V Predictions Min            549.02386
Log Pis Mean                 -0.24720432
Log Pis Std                  3.732569
Log Pis Max                  18.396563
Log Pis Min                  -6.6269283
Policy mu Mean               0.05669087
Policy mu Std                0.8855157
Policy mu Max                3.0319145
Policy mu Min                -3.100356
Policy log std Mean          -0.5090282
Policy log std Std           0.26792294
Policy log std Max           0.094299436
Policy log std Min           -2.3758526
Z mean eval                  1.7308394
Z variance eval              0.091580875
total_rewards                [9320.91184197 2306.67961979 9562.71235828 9268.84243093 9329.81950442
 9317.22616764 9555.80835372 9562.94373746 9396.69951908 9399.72290879]
total_rewards_mean           8702.136644208244
total_rewards_std            2134.4228405562753
total_rewards_max            9562.9437374616
total_rewards_min            2306.679619786884
Number of train steps total  864000
Number of env steps total    2594000
Number of rollouts total     0
Train Time (s)               145.283290815074
(Previous) Eval Time (s)     17.57725627301261
Sample Time (s)              6.358042251318693
Epoch Time (s)               169.2185893394053
Total Train Time (s)         36701.800054891966
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:05:20.679280 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #215 | Epoch Duration: 169.3025827407837
2020-01-12 18:05:20.679546 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7320902
Z variance train             0.0917941
KL Divergence                41.661938
KL Loss                      4.166194
QF Loss                      2823.598
VF Loss                      62.986244
Policy Loss                  -1113.7609
Q Predictions Mean           1111.5627
Q Predictions Std            1156.464
Q Predictions Max            4132.8486
Q Predictions Min            554.82104
V Predictions Mean           1108.206
V Predictions Std            1154.1094
V Predictions Max            4103.759
V Predictions Min            548.26825
Log Pis Mean                 -0.47848547
Log Pis Std                  3.5919642
Log Pis Max                  15.486395
Log Pis Min                  -14.318243
Policy mu Mean               0.048854876
Policy mu Std                0.8603003
Policy mu Max                2.5131588
Policy mu Min                -3.0673249
Policy log std Mean          -0.51427984
Policy log std Std           0.24143334
Policy log std Max           -0.054030776
Policy log std Min           -2.2676907
Z mean eval                  1.7344316
Z variance eval              0.056700993
total_rewards                [8668.95076803 8914.08250795 8895.26767973 9005.45436789 8854.61857508
 8949.29154215 8882.9589069  8764.82608151 8984.49647435 8954.31646033]
total_rewards_mean           8887.426336392335
total_rewards_std            98.12520675774869
total_rewards_max            9005.454367894064
total_rewards_min            8668.950768029092
Number of train steps total  868000
Number of env steps total    2606000
Number of rollouts total     0
Train Time (s)               146.5494204950519
(Previous) Eval Time (s)     18.015554320067167
Sample Time (s)              6.43099557608366
Epoch Time (s)               170.99597039120272
Total Train Time (s)         36872.90420361003
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:08:11.788456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #216 | Epoch Duration: 171.10870504379272
2020-01-12 18:08:11.788754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #216 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7344086
Z variance train             0.05665636
KL Divergence                42.19182
KL Loss                      4.219182
QF Loss                      133.87013
VF Loss                      42.56513
Policy Loss                  -1124.4424
Q Predictions Mean           1123.1086
Q Predictions Std            1147.007
Q Predictions Max            4140.9395
Q Predictions Min            519.14075
V Predictions Mean           1123.8475
V Predictions Std            1145.4094
V Predictions Max            4131.249
V Predictions Min            539.28845
Log Pis Mean                 -0.54363096
Log Pis Std                  3.2404122
Log Pis Max                  13.445564
Log Pis Min                  -6.8485513
Policy mu Mean               0.0694134
Policy mu Std                0.8622231
Policy mu Max                3.4180315
Policy mu Min                -2.6643555
Policy log std Mean          -0.5281289
Policy log std Std           0.2767771
Policy log std Max           -0.0069844723
Policy log std Min           -2.5401232
Z mean eval                  1.7413776
Z variance eval              0.047825627
total_rewards                [8646.80651683 8717.64366056 8869.58023822 8797.03192554 8759.3615188
 8798.38624986 8808.21618762 8721.00784428 8685.8200649  8792.29331896]
total_rewards_mean           8759.614752557707
total_rewards_std            63.126186403097414
total_rewards_max            8869.580238222145
total_rewards_min            8646.806516831384
Number of train steps total  872000
Number of env steps total    2618000
Number of rollouts total     0
Train Time (s)               147.90211744373664
(Previous) Eval Time (s)     17.89165558340028
Sample Time (s)              5.546857584733516
Epoch Time (s)               171.34063061187044
Total Train Time (s)         37044.32610475365
Epoch                        217
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:11:03.210284 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #217 | Epoch Duration: 171.42124843597412
2020-01-12 18:11:03.210531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #217 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7388332
Z variance train             0.047776576
KL Divergence                44.256176
KL Loss                      4.4256177
QF Loss                      112.94303
VF Loss                      51.68519
Policy Loss                  -1123.3486
Q Predictions Mean           1116.9231
Q Predictions Std            1124.514
Q Predictions Max            4135.0024
Q Predictions Min            544.9842
V Predictions Mean           1121.873
V Predictions Std            1126.1941
V Predictions Max            4132.7183
V Predictions Min            552.2422
Log Pis Mean                 -0.4307107
Log Pis Std                  3.3801324
Log Pis Max                  12.81058
Log Pis Min                  -6.9925246
Policy mu Mean               0.032443017
Policy mu Std                0.8582877
Policy mu Max                2.8030849
Policy mu Min                -2.7362616
Policy log std Mean          -0.53426725
Policy log std Std           0.28124565
Policy log std Max           -0.08821416
Policy log std Min           -2.596902
Z mean eval                  1.7331879
Z variance eval              0.108204916
total_rewards                [9200.4955946  9424.80574845 9545.93730405 9250.47652441 9524.7845507
 9494.16262625 9310.17511646 9521.27006028 9232.42721353 9479.03598904]
total_rewards_mean           9398.357072776811
total_rewards_std            128.67997323850554
total_rewards_max            9545.937304049627
total_rewards_min            9200.49559460044
Number of train steps total  876000
Number of env steps total    2630000
Number of rollouts total     0
Train Time (s)               147.73535219440237
(Previous) Eval Time (s)     17.86169846728444
Sample Time (s)              5.670122170355171
Epoch Time (s)               171.26717283204198
Total Train Time (s)         37215.87718870584
Epoch                        218
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:13:54.774038 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #218 | Epoch Duration: 171.56331539154053
2020-01-12 18:13:54.774260 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7368336
Z variance train             0.10780551
KL Divergence                42.722286
KL Loss                      4.2722287
QF Loss                      129.6864
VF Loss                      34.506783
Policy Loss                  -1157.266
Q Predictions Mean           1157.8423
Q Predictions Std            1169.1244
Q Predictions Max            4143.842
Q Predictions Min            555.6381
V Predictions Mean           1155.6472
V Predictions Std            1167.3868
V Predictions Max            4136.0806
V Predictions Min            556.227
Log Pis Mean                 -0.13102593
Log Pis Std                  3.599447
Log Pis Max                  13.926161
Log Pis Min                  -7.1640854
Policy mu Mean               0.08641704
Policy mu Std                0.8779761
Policy mu Max                2.8490057
Policy mu Min                -2.7902083
Policy log std Mean          -0.5205469
Policy log std Std           0.27353662
Policy log std Max           -0.066838145
Policy log std Min           -2.5102797
Z mean eval                  1.7473152
Z variance eval              0.09340286
total_rewards                [9102.44138012 9342.58838559 9319.38115992 9441.57692619 9357.78238133
 9463.29032523 9271.46674768 9462.7461194  9320.88561769 9127.82493478]
total_rewards_mean           9320.998397793466
total_rewards_std            120.09868819147518
total_rewards_max            9463.290325232436
total_rewards_min            9102.441380119068
Number of train steps total  880000
Number of env steps total    2642000
Number of rollouts total     0
Train Time (s)               147.67492049420252
(Previous) Eval Time (s)     21.013349410146475
Sample Time (s)              6.477473234757781
Epoch Time (s)               175.16574313910678
Total Train Time (s)         37391.136818909086
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:16:50.025487 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #219 | Epoch Duration: 175.25107955932617
2020-01-12 18:16:50.025632 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #219 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7456518
Z variance train             0.093389526
KL Divergence                42.469055
KL Loss                      4.246906
QF Loss                      995.8814
VF Loss                      54.68829
Policy Loss                  -1096.7024
Q Predictions Mean           1095.2302
Q Predictions Std            1123.4882
Q Predictions Max            4176.9004
Q Predictions Min            558.17584
V Predictions Mean           1096.7048
V Predictions Std            1124.7234
V Predictions Max            4190.842
V Predictions Min            555.93744
Log Pis Mean                 -0.19406271
Log Pis Std                  3.7757962
Log Pis Max                  14.645822
Log Pis Min                  -6.7036743
Policy mu Mean               -0.002334457
Policy mu Std                0.8808056
Policy mu Max                2.8049762
Policy mu Min                -3.2355862
Policy log std Mean          -0.51563966
Policy log std Std           0.27644503
Policy log std Max           0.047933698
Policy log std Min           -2.6880848
Z mean eval                  1.7373024
Z variance eval              0.062100053
total_rewards                [8809.26623912 9453.60707178 9066.05352854 9030.58209656 8994.4538219
 9190.03717804 9134.52650181 9367.97689305 9234.17423791 9114.4527067 ]
total_rewards_mean           9139.51302754126
total_rewards_std            176.17732153889614
total_rewards_max            9453.60707178083
total_rewards_min            8809.266239120792
Number of train steps total  884000
Number of env steps total    2654000
Number of rollouts total     0
Train Time (s)               146.5731981229037
(Previous) Eval Time (s)     20.892029155045748
Sample Time (s)              6.519253885373473
Epoch Time (s)               173.98448116332293
Total Train Time (s)         37565.207145153545
Epoch                        220
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:19:44.096377 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #220 | Epoch Duration: 174.07064819335938
2020-01-12 18:19:44.096509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7348568
Z variance train             0.0620976
KL Divergence                43.858837
KL Loss                      4.385884
QF Loss                      707.4806
VF Loss                      100.89576
Policy Loss                  -1258.1005
Q Predictions Mean           1257.1205
Q Predictions Std            1278.9785
Q Predictions Max            4120.485
Q Predictions Min            558.5902
V Predictions Mean           1263.0017
V Predictions Std            1275.6284
V Predictions Max            4119.1895
V Predictions Min            569.12885
Log Pis Mean                 -0.041989423
Log Pis Std                  3.9353745
Log Pis Max                  14.601633
Log Pis Min                  -7.766538
Policy mu Mean               0.045465697
Policy mu Std                0.9088295
Policy mu Max                3.1055262
Policy mu Min                -2.7380679
Policy log std Mean          -0.52947336
Policy log std Std           0.28855664
Policy log std Max           0.1442141
Policy log std Min           -2.5155253
Z mean eval                  1.7403877
Z variance eval              0.047440834
total_rewards                [9286.43463098 9381.21734733 2029.96967168 9257.85473855 9612.25750513
 9549.75305771  872.48441073 9374.88014815 9278.49699619 9473.5511263 ]
total_rewards_mean           7811.6899632762115
total_rewards_std            3192.6528088123155
total_rewards_max            9612.257505127687
total_rewards_min            872.4844107347177
Number of train steps total  888000
Number of env steps total    2666000
Number of rollouts total     0
Train Time (s)               145.6638389849104
(Previous) Eval Time (s)     20.999510334804654
Sample Time (s)              6.590334984008223
Epoch Time (s)               173.25368430372328
Total Train Time (s)         37738.54252606537
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:22:37.435818 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #221 | Epoch Duration: 173.33921432495117
2020-01-12 18:22:37.435958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7409805
Z variance train             0.04738955
KL Divergence                44.12509
KL Loss                      4.4125094
QF Loss                      2853.586
VF Loss                      35.14002
Policy Loss                  -1144.3342
Q Predictions Mean           1142.5901
Q Predictions Std            1148.481
Q Predictions Max            4134.9663
Q Predictions Min            560.5719
V Predictions Mean           1147.1244
V Predictions Std            1148.4631
V Predictions Max            4123.899
V Predictions Min            564.4657
Log Pis Mean                 -0.050237328
Log Pis Std                  3.4449527
Log Pis Max                  14.599347
Log Pis Min                  -4.893965
Policy mu Mean               0.08853513
Policy mu Std                0.8889648
Policy mu Max                3.0229454
Policy mu Min                -3.0891948
Policy log std Mean          -0.5340837
Policy log std Std           0.28502297
Policy log std Max           0.02693218
Policy log std Min           -2.4930644
Z mean eval                  1.7346628
Z variance eval              0.06294651
total_rewards                [9011.58172406 9142.80656285 9277.89389209 8958.07022517 9041.77773304
 8903.77149503 9167.88586858 9081.22019237 9112.13567648 9302.34354202]
total_rewards_mean           9099.94869117068
total_rewards_std            122.22408900996489
total_rewards_max            9302.34354202078
total_rewards_min            8903.771495032874
Number of train steps total  892000
Number of env steps total    2678000
Number of rollouts total     0
Train Time (s)               146.19566773297265
(Previous) Eval Time (s)     19.112906740047038
Sample Time (s)              6.541603402700275
Epoch Time (s)               171.85017787571996
Total Train Time (s)         37910.491256489884
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:25:29.385648 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #222 | Epoch Duration: 171.94957041740417
2020-01-12 18:25:29.385862 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.734588
Z variance train             0.06307542
KL Divergence                43.322453
KL Loss                      4.3322453
QF Loss                      454.2215
VF Loss                      67.70894
Policy Loss                  -1243.0261
Q Predictions Mean           1237.0781
Q Predictions Std            1237.4043
Q Predictions Max            4152.567
Q Predictions Min            547.9941
V Predictions Mean           1243.6855
V Predictions Std            1238.2136
V Predictions Max            4183.9165
V Predictions Min            553.2627
Log Pis Mean                 0.12458263
Log Pis Std                  3.7505465
Log Pis Max                  15.854021
Log Pis Min                  -5.886406
Policy mu Mean               -0.045920044
Policy mu Std                0.90747976
Policy mu Max                3.0666893
Policy mu Min                -3.2222378
Policy log std Mean          -0.54185194
Policy log std Std           0.30201715
Policy log std Max           0.015821755
Policy log std Min           -2.7274556
Z mean eval                  1.7352676
Z variance eval              0.057144053
total_rewards                [9352.52880642 9532.33267849 9158.16015439 9553.24912026 9301.28781379
 9454.17920284 9404.65200372 9430.22953327 9354.09449553 9802.42348034]
total_rewards_mean           9434.313728905428
total_rewards_std            163.59396575140144
total_rewards_max            9802.423480341635
total_rewards_min            9158.160154394103
Number of train steps total  896000
Number of env steps total    2690000
Number of rollouts total     0
Train Time (s)               146.20417060982436
(Previous) Eval Time (s)     17.482033308129758
Sample Time (s)              6.623651725240052
Epoch Time (s)               170.30985564319417
Total Train Time (s)         38080.88241394982
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:28:19.783135 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #223 | Epoch Duration: 170.39707827568054
2020-01-12 18:28:19.783450 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7347504
Z variance train             0.05713568
KL Divergence                44.00722
KL Loss                      4.400722
QF Loss                      178.30365
VF Loss                      52.678497
Policy Loss                  -1315.291
Q Predictions Mean           1315.101
Q Predictions Std            1305.0913
Q Predictions Max            4148.9346
Q Predictions Min            540.81903
V Predictions Mean           1319.1067
V Predictions Std            1301.4744
V Predictions Max            4154.439
V Predictions Min            554.98944
Log Pis Mean                 0.033200577
Log Pis Std                  3.5297515
Log Pis Max                  12.622372
Log Pis Min                  -7.220719
Policy mu Mean               0.02448482
Policy mu Std                0.905386
Policy mu Max                2.9434915
Policy mu Min                -3.154326
Policy log std Mean          -0.52323157
Policy log std Std           0.26793393
Policy log std Max           0.06387758
Policy log std Min           -2.5005622
Z mean eval                  1.732228
Z variance eval              0.07489728
total_rewards                [9167.61554037 9533.55880279 9290.33207363 9593.72116368 9605.48768787
 9498.27269107 9691.98735833 9475.53959216 9690.20336244 9751.05080709]
total_rewards_mean           9529.776907944299
total_rewards_std            174.14798180800537
total_rewards_max            9751.050807089063
total_rewards_min            9167.615540370152
Number of train steps total  900000
Number of env steps total    2702000
Number of rollouts total     0
Train Time (s)               147.3471515593119
(Previous) Eval Time (s)     17.273735930677503
Sample Time (s)              6.456083071418107
Epoch Time (s)               171.0769705614075
Total Train Time (s)         38252.03774689231
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:31:10.938358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #224 | Epoch Duration: 171.15468049049377
2020-01-12 18:31:10.938479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7317854
Z variance train             0.07505366
KL Divergence                43.43254
KL Loss                      4.343254
QF Loss                      94.86341
VF Loss                      67.61196
Policy Loss                  -1180.0935
Q Predictions Mean           1178.055
Q Predictions Std            1186.9836
Q Predictions Max            4136.199
Q Predictions Min            561.72784
V Predictions Mean           1181.8562
V Predictions Std            1186.8021
V Predictions Max            4154.106
V Predictions Min            560.41284
Log Pis Mean                 -0.31564635
Log Pis Std                  3.7436576
Log Pis Max                  15.6778145
Log Pis Min                  -6.7635264
Policy mu Mean               -0.062924005
Policy mu Std                0.87938917
Policy mu Max                2.5894885
Policy mu Min                -3.1219425
Policy log std Mean          -0.54010886
Policy log std Std           0.27498668
Policy log std Max           0.02078098
Policy log std Min           -2.4431295
Z mean eval                  1.7287709
Z variance eval              0.12516762
total_rewards                [9446.92507837 9641.32046158 9522.16916285 9396.11798105 9411.92366726
 9291.44842741 9577.15828963 9394.52242494 9639.57441913 9396.07645585]
total_rewards_mean           9471.723636805464
total_rewards_std            111.66336887279942
total_rewards_max            9641.320461578503
total_rewards_min            9291.448427406607
Number of train steps total  904000
Number of env steps total    2714000
Number of rollouts total     0
Train Time (s)               145.65713091334328
(Previous) Eval Time (s)     18.61435656901449
Sample Time (s)              5.470973840914667
Epoch Time (s)               169.74246132327244
Total Train Time (s)         38421.99140059156
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:34:00.898090 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #225 | Epoch Duration: 169.95948004722595
2020-01-12 18:34:00.898360 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7279022
Z variance train             0.1254052
KL Divergence                42.500145
KL Loss                      4.250015
QF Loss                      190.71034
VF Loss                      56.2739
Policy Loss                  -1224.2383
Q Predictions Mean           1221.4641
Q Predictions Std            1227.067
Q Predictions Max            4148.8193
Q Predictions Min            565.1195
V Predictions Mean           1226.3818
V Predictions Std            1226.3177
V Predictions Max            4156.393
V Predictions Min            562.9021
Log Pis Mean                 0.030081153
Log Pis Std                  3.8749244
Log Pis Max                  17.484325
Log Pis Min                  -6.5489945
Policy mu Mean               0.032415796
Policy mu Std                0.907481
Policy mu Max                3.1310263
Policy mu Min                -3.5178688
Policy log std Mean          -0.5342701
Policy log std Std           0.2635269
Policy log std Max           0.009602547
Policy log std Min           -2.5536835
Z mean eval                  1.7263105
Z variance eval              0.17240453
total_rewards                [8151.57351941 9196.42199524 9300.35903866 9389.53975655 9396.32073677
 8983.56155851 1285.37440942 9106.0420717  9178.15244705 9467.85530694]
total_rewards_mean           8345.520084024101
total_rewards_std            2380.1593731998737
total_rewards_max            9467.85530693801
total_rewards_min            1285.3744094154495
Number of train steps total  908000
Number of env steps total    2726000
Number of rollouts total     0
Train Time (s)               147.9310075440444
(Previous) Eval Time (s)     20.89479874400422
Sample Time (s)              6.4804739584214985
Epoch Time (s)               175.30628024647012
Total Train Time (s)         38597.3795314203
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:36:56.286639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #226 | Epoch Duration: 175.38808798789978
2020-01-12 18:36:56.286775 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.728002
Z variance train             0.17203687
KL Divergence                40.608387
KL Loss                      4.0608387
QF Loss                      173.9826
VF Loss                      43.22136
Policy Loss                  -1060.3564
Q Predictions Mean           1057.0684
Q Predictions Std            1061.9441
Q Predictions Max            4199.1987
Q Predictions Min            565.7418
V Predictions Mean           1060.812
V Predictions Std            1062.9591
V Predictions Max            4179.9346
V Predictions Min            560.80505
Log Pis Mean                 -0.66325784
Log Pis Std                  3.5938666
Log Pis Max                  14.732559
Log Pis Min                  -7.1234794
Policy mu Mean               0.07207286
Policy mu Std                0.829344
Policy mu Max                3.1592574
Policy mu Min                -2.8284945
Policy log std Mean          -0.5081424
Policy log std Std           0.2660056
Policy log std Max           0.053049266
Policy log std Min           -2.4508228
Z mean eval                  1.742232
Z variance eval              0.12382053
total_rewards                [9003.98699302 9463.0752053  9071.99383043 9204.77081659 9395.75616289
 9404.42019817 9351.96949829 9051.24177459 9246.56554275 9289.30164453]
total_rewards_mean           9248.308166657034
total_rewards_std            153.68024508198442
total_rewards_max            9463.075205302306
total_rewards_min            9003.986993020868
Number of train steps total  912000
Number of env steps total    2738000
Number of rollouts total     0
Train Time (s)               148.06949076615274
(Previous) Eval Time (s)     20.544507113751024
Sample Time (s)              6.418978095520288
Epoch Time (s)               175.03297597542405
Total Train Time (s)         38772.50317056617
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:39:51.413158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #227 | Epoch Duration: 175.12628364562988
2020-01-12 18:39:51.413297 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7428453
Z variance train             0.12372893
KL Divergence                39.701035
KL Loss                      3.9701035
QF Loss                      168.67313
VF Loss                      74.73437
Policy Loss                  -1046.229
Q Predictions Mean           1045.1187
Q Predictions Std            1067.871
Q Predictions Max            4221.2437
Q Predictions Min            581.0396
V Predictions Mean           1043.3152
V Predictions Std            1068.0007
V Predictions Max            4196.2373
V Predictions Min            577.33746
Log Pis Mean                 -0.67825913
Log Pis Std                  3.2403164
Log Pis Max                  15.539333
Log Pis Min                  -7.391143
Policy mu Mean               0.04459518
Policy mu Std                0.821991
Policy mu Max                2.755582
Policy mu Min                -2.716633
Policy log std Mean          -0.52300924
Policy log std Std           0.26348233
Policy log std Max           -0.043105185
Policy log std Min           -2.5566974
Z mean eval                  1.7345755
Z variance eval              0.08687471
total_rewards                [9270.258524   9634.61108181 9421.9881397  9667.83166078 9602.55240328
 9449.21851497 9422.16615531 9693.15065019 9415.54805213 9753.26946549]
total_rewards_mean           9533.05946476427
total_rewards_std            148.9845337882129
total_rewards_max            9753.269465489813
total_rewards_min            9270.2585239982
Number of train steps total  916000
Number of env steps total    2750000
Number of rollouts total     0
Train Time (s)               147.97868695715442
(Previous) Eval Time (s)     21.202125573996454
Sample Time (s)              6.532635123934597
Epoch Time (s)               175.71344765508547
Total Train Time (s)         38948.29604360927
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:42:47.209275 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #228 | Epoch Duration: 175.7958824634552
2020-01-12 18:42:47.209410 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7329403
Z variance train             0.08697151
KL Divergence                41.474995
KL Loss                      4.1474996
QF Loss                      98.18147
VF Loss                      46.926987
Policy Loss                  -1216.5331
Q Predictions Mean           1216.9927
Q Predictions Std            1239.4768
Q Predictions Max            4182.011
Q Predictions Min            553.54315
V Predictions Mean           1218.147
V Predictions Std            1237.1798
V Predictions Max            4185.131
V Predictions Min            563.8026
Log Pis Mean                 -0.23346005
Log Pis Std                  3.5403967
Log Pis Max                  15.606242
Log Pis Min                  -7.4487367
Policy mu Mean               0.024799736
Policy mu Std                0.8846811
Policy mu Max                2.5019279
Policy mu Min                -2.3767595
Policy log std Mean          -0.5260937
Policy log std Std           0.27044204
Policy log std Max           0.1608805
Policy log std Min           -2.5790057
Z mean eval                  1.7503252
Z variance eval              0.10696536
total_rewards                [9207.90544216 9487.74680912 9511.26679107 9505.94987673 9729.46959204
 9648.86387838 9680.23009002 9409.92156539 9623.70436964 9555.96651572]
total_rewards_mean           9536.102493027973
total_rewards_std            143.68249462942052
total_rewards_max            9729.469592043322
total_rewards_min            9207.90544216405
Number of train steps total  920000
Number of env steps total    2762000
Number of rollouts total     0
Train Time (s)               145.2490284726955
(Previous) Eval Time (s)     20.835194481071085
Sample Time (s)              6.273639798630029
Epoch Time (s)               172.3578627523966
Total Train Time (s)         39120.73272788152
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:45:39.649641 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #229 | Epoch Duration: 172.44012689590454
2020-01-12 18:45:39.649812 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7517197
Z variance train             0.10741804
KL Divergence                42.40929
KL Loss                      4.240929
QF Loss                      6025.464
VF Loss                      107.76045
Policy Loss                  -1270.0327
Q Predictions Mean           1270.5259
Q Predictions Std            1297.525
Q Predictions Max            4294.4517
Q Predictions Min            581.3585
V Predictions Mean           1267.9736
V Predictions Std            1291.3539
V Predictions Max            4277.3037
V Predictions Min            577.047
Log Pis Mean                 -0.01717591
Log Pis Std                  4.178217
Log Pis Max                  23.108671
Log Pis Min                  -6.8245525
Policy mu Mean               0.07322227
Policy mu Std                0.91099846
Policy mu Max                2.8523219
Policy mu Min                -3.4056435
Policy log std Mean          -0.5416176
Policy log std Std           0.2909687
Policy log std Max           0.25326994
Policy log std Min           -2.4957438
Z mean eval                  1.7426989
Z variance eval              0.107905686
total_rewards                [9293.2566713  9679.55460087 9786.63545593 9484.16954614 9523.87561276
 9396.57965246 9361.11713293 9509.43898198 9845.60312941 9632.71466286]
total_rewards_mean           9551.294544664514
total_rewards_std            172.8525112667496
total_rewards_max            9845.603129407218
total_rewards_min            9293.256671300447
Number of train steps total  924000
Number of env steps total    2774000
Number of rollouts total     0
Train Time (s)               147.00769191095605
(Previous) Eval Time (s)     20.69810054684058
Sample Time (s)              5.529124544002116
Epoch Time (s)               173.23491700179875
Total Train Time (s)         39294.20506564481
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:48:33.131074 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #230 | Epoch Duration: 173.48111820220947
2020-01-12 18:48:33.131305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7423942
Z variance train             0.1080873
KL Divergence                42.356632
KL Loss                      4.2356634
QF Loss                      94.617165
VF Loss                      37.713036
Policy Loss                  -1225.9305
Q Predictions Mean           1225.6372
Q Predictions Std            1224.393
Q Predictions Max            4208.8174
Q Predictions Min            570.45276
V Predictions Mean           1224.7067
V Predictions Std            1224.5012
V Predictions Max            4201.8345
V Predictions Min            568.3288
Log Pis Mean                 -0.26418442
Log Pis Std                  3.2905486
Log Pis Max                  12.295668
Log Pis Min                  -8.650687
Policy mu Mean               0.084849976
Policy mu Std                0.87890416
Policy mu Max                2.9874017
Policy mu Min                -2.532746
Policy log std Mean          -0.52380365
Policy log std Std           0.27189288
Policy log std Max           0.11979866
Policy log std Min           -2.7888055
Z mean eval                  1.7498701
Z variance eval              0.09255205
total_rewards                [9008.2601144  9303.59784349 9013.16786825 1644.05372538 9135.02064473
 9246.88013125 9264.8818557  8986.02193975 9276.12080242 9003.47475397]
total_rewards_mean           8388.147967934301
total_rewards_std            2251.3223382101737
total_rewards_max            9303.597843487916
total_rewards_min            1644.053725382966
Number of train steps total  928000
Number of env steps total    2786000
Number of rollouts total     0
Train Time (s)               146.1963987420313
(Previous) Eval Time (s)     20.745109593030065
Sample Time (s)              6.474832345265895
Epoch Time (s)               173.41634068032727
Total Train Time (s)         39467.71258625435
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:51:26.632772 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #231 | Epoch Duration: 173.50130987167358
2020-01-12 18:51:26.632908 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7487938
Z variance train             0.0926595
KL Divergence                43.00201
KL Loss                      4.300201
QF Loss                      350.2469
VF Loss                      43.850082
Policy Loss                  -1195.9232
Q Predictions Mean           1194.956
Q Predictions Std            1238.4318
Q Predictions Max            4179.4575
Q Predictions Min            562.7443
V Predictions Mean           1197.873
V Predictions Std            1233.6091
V Predictions Max            4170.4736
V Predictions Min            566.7016
Log Pis Mean                 -0.14405349
Log Pis Std                  3.66165
Log Pis Max                  17.244137
Log Pis Min                  -8.479563
Policy mu Mean               0.032286804
Policy mu Std                0.897355
Policy mu Max                3.7077136
Policy mu Min                -4.3373084
Policy log std Mean          -0.5245798
Policy log std Std           0.2713786
Policy log std Max           0.07187992
Policy log std Min           -2.5840917
Z mean eval                  1.7665517
Z variance eval              0.1031481
total_rewards                [9214.54697287 9458.2385275  9314.44763444 9549.95816129 9537.05153606
 9565.16667197 9558.05281282 9501.69448585 9494.47787359 9446.06045156]
total_rewards_mean           9463.96951279312
total_rewards_std            109.13453625333202
total_rewards_max            9565.166671966519
total_rewards_min            9214.546972865517
Number of train steps total  932000
Number of env steps total    2798000
Number of rollouts total     0
Train Time (s)               148.198510334827
(Previous) Eval Time (s)     21.23102974984795
Sample Time (s)              6.339035422541201
Epoch Time (s)               175.76857550721616
Total Train Time (s)         39643.57230284158
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:54:22.494578 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #232 | Epoch Duration: 175.86157298088074
2020-01-12 18:54:22.494719 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #232 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7655274
Z variance train             0.10298546
KL Divergence                43.541187
KL Loss                      4.354119
QF Loss                      173.24835
VF Loss                      120.766685
Policy Loss                  -1132.9915
Q Predictions Mean           1129.9528
Q Predictions Std            1144.9039
Q Predictions Max            4266.0005
Q Predictions Min            567.93256
V Predictions Mean           1133.9313
V Predictions Std            1145.6917
V Predictions Max            4224.6763
V Predictions Min            574.4705
Log Pis Mean                 -0.08891168
Log Pis Std                  3.328378
Log Pis Max                  12.422525
Log Pis Min                  -10.282532
Policy mu Mean               0.061582685
Policy mu Std                0.9073549
Policy mu Max                2.9748201
Policy mu Min                -3.1489732
Policy log std Mean          -0.5313754
Policy log std Std           0.28692243
Policy log std Max           0.047224402
Policy log std Min           -2.6113405
Z mean eval                  1.7548879
Z variance eval              0.08302106
total_rewards                [9172.80931983 9720.20065287 9683.54129359 9440.97692733 9382.5788131
 9540.74638425 9387.23987381 9644.40710222 9531.5643767  9281.55169434]
total_rewards_mean           9478.561643804269
total_rewards_std            169.07081339697888
total_rewards_max            9720.200652870479
total_rewards_min            9172.809319826792
Number of train steps total  936000
Number of env steps total    2810000
Number of rollouts total     0
Train Time (s)               148.6798719149083
(Previous) Eval Time (s)     20.74681560182944
Sample Time (s)              6.6336586670950055
Epoch Time (s)               176.06034618383273
Total Train Time (s)         39819.89907279983
Epoch                        233
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 18:57:18.822276 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #233 | Epoch Duration: 176.32745790481567
2020-01-12 18:57:18.822411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #233 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.752677
Z variance train             0.08309738
KL Divergence                43.716423
KL Loss                      4.3716426
QF Loss                      99.53604
VF Loss                      49.029163
Policy Loss                  -1178.7112
Q Predictions Mean           1173.8575
Q Predictions Std            1170.5176
Q Predictions Max            4285.006
Q Predictions Min            561.45465
V Predictions Mean           1179.4847
V Predictions Std            1173.0594
V Predictions Max            4309.1733
V Predictions Min            560.47656
Log Pis Mean                 -0.12801524
Log Pis Std                  4.0513916
Log Pis Max                  19.523445
Log Pis Min                  -6.470353
Policy mu Mean               0.107124746
Policy mu Std                0.892818
Policy mu Max                3.1027708
Policy mu Min                -3.1790104
Policy log std Mean          -0.5179596
Policy log std Std           0.28534266
Policy log std Max           -0.026420712
Policy log std Min           -2.593227
Z mean eval                  1.7594588
Z variance eval              0.08703445
total_rewards                [ 9539.02149287 10050.98960938  9553.66870993  9898.88562137
  9555.78183174  9579.65578771  9723.40205507  9691.234594
  9678.09191168  9725.06813334]
total_rewards_mean           9699.579974709948
total_rewards_std            157.19059511682528
total_rewards_max            10050.989609379543
total_rewards_min            9539.021492872032
Number of train steps total  940000
Number of env steps total    2822000
Number of rollouts total     0
Train Time (s)               147.90465028211474
(Previous) Eval Time (s)     20.81265427498147
Sample Time (s)              6.415562524925917
Epoch Time (s)               175.13286708202213
Total Train Time (s)         39995.11731131049
Epoch                        234
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:00:14.042858 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #234 | Epoch Duration: 175.22034907341003
2020-01-12 19:00:14.042993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7623447
Z variance train             0.08708357
KL Divergence                43.99018
KL Loss                      4.3990183
QF Loss                      114.339584
VF Loss                      130.00156
Policy Loss                  -1159.3489
Q Predictions Mean           1157.7021
Q Predictions Std            1176.1127
Q Predictions Max            4245.1665
Q Predictions Min            552.63416
V Predictions Mean           1152.67
V Predictions Std            1166.9955
V Predictions Max            4202.7295
V Predictions Min            546.29596
Log Pis Mean                 -0.6427915
Log Pis Std                  3.1261394
Log Pis Max                  12.506096
Log Pis Min                  -6.222555
Policy mu Mean               0.09209762
Policy mu Std                0.82864094
Policy mu Max                2.7166004
Policy mu Min                -2.9933534
Policy log std Mean          -0.52754605
Policy log std Std           0.26871333
Policy log std Max           -0.07734382
Policy log std Min           -2.8941498
Z mean eval                  1.7440736
Z variance eval              0.13200095
total_rewards                [9197.5816714  9223.79259047 9442.62525237 9209.46944807 9363.44985902
 9365.63529339 9379.52090326 9333.29152972 9263.85595581 9257.35298605]
total_rewards_mean           9303.657548956366
total_rewards_std            79.74458363306351
total_rewards_max            9442.62525237448
total_rewards_min            9197.581671402873
Number of train steps total  944000
Number of env steps total    2834000
Number of rollouts total     0
Train Time (s)               146.26748043624684
(Previous) Eval Time (s)     20.765130613930523
Sample Time (s)              6.399905517697334
Epoch Time (s)               173.4325165678747
Total Train Time (s)         40168.6305154711
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:03:07.558337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #235 | Epoch Duration: 173.5152485370636
2020-01-12 19:03:07.558471 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7443731
Z variance train             0.13182107
KL Divergence                42.1919
KL Loss                      4.21919
QF Loss                      173.69598
VF Loss                      82.743324
Policy Loss                  -1338.9216
Q Predictions Mean           1334.9371
Q Predictions Std            1316.5126
Q Predictions Max            4224.2007
Q Predictions Min            577.79395
V Predictions Mean           1336.5875
V Predictions Std            1318.5104
V Predictions Max            4227.4814
V Predictions Min            579.1403
Log Pis Mean                 0.33510742
Log Pis Std                  3.978442
Log Pis Max                  17.412214
Log Pis Min                  -6.6421447
Policy mu Mean               0.051074352
Policy mu Std                0.94190073
Policy mu Max                3.1814303
Policy mu Min                -3.3937378
Policy log std Mean          -0.5386979
Policy log std Std           0.28472272
Policy log std Max           0.036548615
Policy log std Min           -2.9593387
Z mean eval                  1.7415183
Z variance eval              0.14029428
total_rewards                [9307.38261075 9444.2589238  9742.81776089 9235.56989138 9736.74401577
 9533.11919059 9518.2645387  9630.22741579 9696.67235001 9456.26254725]
total_rewards_mean           9530.13192449389
total_rewards_std            165.84429620926548
total_rewards_max            9742.817760892094
total_rewards_min            9235.569891377156
Number of train steps total  948000
Number of env steps total    2846000
Number of rollouts total     0
Train Time (s)               147.1857724711299
(Previous) Eval Time (s)     20.94881410524249
Sample Time (s)              6.424197501968592
Epoch Time (s)               174.55878407834098
Total Train Time (s)         40343.272571347654
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:06:02.201454 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #236 | Epoch Duration: 174.64288997650146
2020-01-12 19:06:02.201586 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7409378
Z variance train             0.13979453
KL Divergence                42.04451
KL Loss                      4.204451
QF Loss                      179.87332
VF Loss                      62.000004
Policy Loss                  -1258.4338
Q Predictions Mean           1254.8398
Q Predictions Std            1235.7494
Q Predictions Max            4200.8193
Q Predictions Min            577.191
V Predictions Mean           1259.7344
V Predictions Std            1238.4583
V Predictions Max            4220.7427
V Predictions Min            579.4726
Log Pis Mean                 -0.064141296
Log Pis Std                  4.358242
Log Pis Max                  26.584398
Log Pis Min                  -5.892085
Policy mu Mean               -0.012388381
Policy mu Std                0.9302486
Policy mu Max                3.2856598
Policy mu Min                -4.382543
Policy log std Mean          -0.52080554
Policy log std Std           0.29007852
Policy log std Max           0.12649095
Policy log std Min           -3.0279634
Z mean eval                  1.7555393
Z variance eval              0.13308448
total_rewards                [8527.57484698 4164.5601825  8065.3162996  2073.39731536 8776.91508098
 7663.0807435  8745.04739764 8902.09271567 8075.17012076 8140.8812634 ]
total_rewards_mean           7313.4035966408355
total_rewards_std            2179.7970043241266
total_rewards_max            8902.092715673678
total_rewards_min            2073.397315361418
Number of train steps total  952000
Number of env steps total    2858000
Number of rollouts total     0
Train Time (s)               146.25779404724017
(Previous) Eval Time (s)     20.880973808001727
Sample Time (s)              6.53899160772562
Epoch Time (s)               173.67775946296751
Total Train Time (s)         40517.02848346345
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:08:55.960502 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #237 | Epoch Duration: 173.75880217552185
2020-01-12 19:08:55.960687 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7550852
Z variance train             0.1328868
KL Divergence                40.875683
KL Loss                      4.0875683
QF Loss                      114.63052
VF Loss                      91.18154
Policy Loss                  -1148.7448
Q Predictions Mean           1149.1184
Q Predictions Std            1168.0715
Q Predictions Max            4311.929
Q Predictions Min            581.18854
V Predictions Mean           1154.7177
V Predictions Std            1172.4915
V Predictions Max            4324.1245
V Predictions Min            584.9489
Log Pis Mean                 -0.28310633
Log Pis Std                  3.4506326
Log Pis Max                  21.639008
Log Pis Min                  -6.637509
Policy mu Mean               0.03856479
Policy mu Std                0.8903793
Policy mu Max                2.7534466
Policy mu Min                -3.1301932
Policy log std Mean          -0.5144677
Policy log std Std           0.2734825
Policy log std Max           0.14652205
Policy log std Min           -2.4577131
Z mean eval                  1.7403314
Z variance eval              0.11732908
total_rewards                [6218.30140692 7400.5442076  8038.56561523 2968.33348393 3171.31999737
 5455.91808553 1614.54268978 2636.30375564 2847.84012573 7683.9041207 ]
total_rewards_mean           4803.557348843454
total_rewards_std            2294.710655628425
total_rewards_max            8038.565615233906
total_rewards_min            1614.5426897805185
Number of train steps total  956000
Number of env steps total    2870000
Number of rollouts total     0
Train Time (s)               146.9847324108705
(Previous) Eval Time (s)     17.378817431163043
Sample Time (s)              6.570080150850117
Epoch Time (s)               170.93362999288365
Total Train Time (s)         40688.04016756918
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:11:46.977190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #238 | Epoch Duration: 171.01626467704773
2020-01-12 19:11:46.977562 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7397734
Z variance train             0.117521666
KL Divergence                41.023403
KL Loss                      4.10234
QF Loss                      132.9189
VF Loss                      122.29071
Policy Loss                  -1251.8754
Q Predictions Mean           1245.7798
Q Predictions Std            1241.8401
Q Predictions Max            4221.3394
Q Predictions Min            564.8528
V Predictions Mean           1245.6187
V Predictions Std            1233.9236
V Predictions Max            4216.3706
V Predictions Min            573.5452
Log Pis Mean                 0.12590367
Log Pis Std                  3.9320297
Log Pis Max                  23.240826
Log Pis Min                  -6.7249384
Policy mu Mean               0.047979075
Policy mu Std                0.947397
Policy mu Max                5.4012117
Policy mu Min                -3.4870517
Policy log std Mean          -0.51210856
Policy log std Std           0.26960713
Policy log std Max           -0.040112257
Policy log std Min           -2.7522287
Z mean eval                  1.769359
Z variance eval              0.20383437
total_rewards                [9595.26468561 9463.80449176 9427.5703037  9688.35994229 9604.57532457
 9467.38053348 9613.95361562 9641.13476819 9748.06900711 9477.86637852]
total_rewards_mean           9572.797905086165
total_rewards_std            102.4930538907365
total_rewards_max            9748.0690071096
total_rewards_min            9427.570303696835
Number of train steps total  960000
Number of env steps total    2882000
Number of rollouts total     0
Train Time (s)               146.19603704707697
(Previous) Eval Time (s)     17.364326817449182
Sample Time (s)              6.656008009798825
Epoch Time (s)               170.21637187432498
Total Train Time (s)         40858.33538107155
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:14:37.273561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #239 | Epoch Duration: 170.29577136039734
2020-01-12 19:14:37.273706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7697443
Z variance train             0.20442705
KL Divergence                41.321583
KL Loss                      4.1321583
QF Loss                      161.51642
VF Loss                      95.096565
Policy Loss                  -1230.995
Q Predictions Mean           1227.3522
Q Predictions Std            1252.1006
Q Predictions Max            4370.191
Q Predictions Min            583.1786
V Predictions Mean           1228.5244
V Predictions Std            1243.479
V Predictions Max            4365.515
V Predictions Min            587.69617
Log Pis Mean                 -0.2040827
Log Pis Std                  3.8038342
Log Pis Max                  18.976147
Log Pis Min                  -5.813304
Policy mu Mean               0.036249157
Policy mu Std                0.8824146
Policy mu Max                3.4418783
Policy mu Min                -3.2778163
Policy log std Mean          -0.51396054
Policy log std Std           0.29290837
Policy log std Max           -0.027433693
Policy log std Min           -2.7066567
Z mean eval                  1.753783
Z variance eval              0.14757663
total_rewards                [9489.60749546 9717.59752625 9604.09264267 9611.74751001 9450.56241673
 9487.35941706 9851.47894701 9643.59456292 9522.55935442 9600.38984621]
total_rewards_mean           9597.898971872366
total_rewards_std            115.01527648717123
total_rewards_max            9851.478947010726
total_rewards_min            9450.562416729397
Number of train steps total  964000
Number of env steps total    2894000
Number of rollouts total     0
Train Time (s)               145.28915762668476
(Previous) Eval Time (s)     20.005855911877006
Sample Time (s)              12.263744393829256
Epoch Time (s)               177.55875793239102
Total Train Time (s)         41035.97555930726
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:17:34.915721 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #240 | Epoch Duration: 177.64188957214355
2020-01-12 19:17:34.915923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7535717
Z variance train             0.1478019
KL Divergence                41.283367
KL Loss                      4.128337
QF Loss                      85.24814
VF Loss                      59.295425
Policy Loss                  -1270.4902
Q Predictions Mean           1268.8276
Q Predictions Std            1285.6353
Q Predictions Max            4247.918
Q Predictions Min            553.3007
V Predictions Mean           1270.0411
V Predictions Std            1281.6582
V Predictions Max            4228.981
V Predictions Min            560.83905
Log Pis Mean                 -0.27866906
Log Pis Std                  3.2091324
Log Pis Max                  10.760291
Log Pis Min                  -8.796211
Policy mu Mean               0.01185518
Policy mu Std                0.88623947
Policy mu Max                2.5212872
Policy mu Min                -2.309916
Policy log std Mean          -0.5322993
Policy log std Std           0.27702394
Policy log std Max           0.03683579
Policy log std Min           -2.7036183
Z mean eval                  1.7555279
Z variance eval              0.11521077
total_rewards                [9368.46827921 9614.31496543 9957.35103509 9622.20331845 9722.32130851
 9518.36011407 9895.83114822 9686.60492376 9922.53296118 9735.81724786]
total_rewards_mean           9704.380530176826
total_rewards_std            176.68320384945196
total_rewards_max            9957.351035086973
total_rewards_min            9368.468279207476
Number of train steps total  968000
Number of env steps total    2906000
Number of rollouts total     0
Train Time (s)               147.4575348799117
(Previous) Eval Time (s)     21.027356008067727
Sample Time (s)              6.273262531496584
Epoch Time (s)               174.758153419476
Total Train Time (s)         41210.81481294893
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:20:29.762653 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #241 | Epoch Duration: 174.84649562835693
2020-01-12 19:20:29.762950 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7553165
Z variance train             0.11537477
KL Divergence                41.670174
KL Loss                      4.1670175
QF Loss                      95.99848
VF Loss                      42.348133
Policy Loss                  -1139.9138
Q Predictions Mean           1136.996
Q Predictions Std            1154.4907
Q Predictions Max            4280.847
Q Predictions Min            577.4439
V Predictions Mean           1141.137
V Predictions Std            1151.7992
V Predictions Max            4265.4053
V Predictions Min            581.39465
Log Pis Mean                 -0.10442451
Log Pis Std                  3.786532
Log Pis Max                  15.370172
Log Pis Min                  -8.657416
Policy mu Mean               0.077679984
Policy mu Std                0.8768772
Policy mu Max                2.5687475
Policy mu Min                -3.121379
Policy log std Mean          -0.5185261
Policy log std Std           0.29285476
Policy log std Max           -0.027443111
Policy log std Min           -2.7237647
Z mean eval                  1.7434313
Z variance eval              0.090328015
total_rewards                [9541.31272588 9622.82065607 9512.86409943 9709.71468569 9633.22243041
 9771.81552948 9720.80388474 9668.58886183 9818.02926137 9645.18831803]
total_rewards_mean           9664.436045294771
total_rewards_std            90.31941987685117
total_rewards_max            9818.029261374239
total_rewards_min            9512.864099432445
Number of train steps total  972000
Number of env steps total    2918000
Number of rollouts total     0
Train Time (s)               147.83431280078366
(Previous) Eval Time (s)     20.820023346226662
Sample Time (s)              6.342322268057615
Epoch Time (s)               174.99665841506794
Total Train Time (s)         41385.96210625628
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:23:24.908200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #242 | Epoch Duration: 175.14505815505981
2020-01-12 19:23:24.908448 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.743277
Z variance train             0.090263925
KL Divergence                41.020523
KL Loss                      4.102052
QF Loss                      235.07556
VF Loss                      62.001694
Policy Loss                  -1051.2185
Q Predictions Mean           1048.563
Q Predictions Std            1068.6287
Q Predictions Max            4343.218
Q Predictions Min            581.14996
V Predictions Mean           1053.446
V Predictions Std            1070.2213
V Predictions Max            4356.4375
V Predictions Min            590.197
Log Pis Mean                 -0.29338676
Log Pis Std                  3.1654117
Log Pis Max                  14.731068
Log Pis Min                  -7.6059847
Policy mu Mean               0.0745933
Policy mu Std                0.8578729
Policy mu Max                2.7099662
Policy mu Min                -2.5289176
Policy log std Mean          -0.5217146
Policy log std Std           0.2903483
Policy log std Max           0.06759566
Policy log std Min           -2.4162245
Z mean eval                  1.7405046
Z variance eval              0.10184844
total_rewards                [9449.82976642 9617.67911817 9533.49903967 9400.18933113 9161.35954457
 1329.40227026 9256.75277929 9328.33718015 9582.00776033 9203.58912218]
total_rewards_mean           8586.264591217221
total_rewards_std            2423.5282635955355
total_rewards_max            9617.679118167634
total_rewards_min            1329.4022702603393
Number of train steps total  976000
Number of env steps total    2930000
Number of rollouts total     0
Train Time (s)               147.0014761062339
(Previous) Eval Time (s)     20.64854386402294
Sample Time (s)              6.428846076596528
Epoch Time (s)               174.07886604685336
Total Train Time (s)         41560.12688823696
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:26:19.073468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #243 | Epoch Duration: 174.16484022140503
2020-01-12 19:26:19.073601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7400625
Z variance train             0.10216812
KL Divergence                41.26239
KL Loss                      4.1262393
QF Loss                      86.1644
VF Loss                      94.77193
Policy Loss                  -1053.2701
Q Predictions Mean           1050.8701
Q Predictions Std            1047.8953
Q Predictions Max            4321.281
Q Predictions Min            573.4082
V Predictions Mean           1058.206
V Predictions Std            1051.2747
V Predictions Max            4307.122
V Predictions Min            582.78674
Log Pis Mean                 -0.38569644
Log Pis Std                  3.4732554
Log Pis Max                  13.311855
Log Pis Min                  -6.989979
Policy mu Mean               0.06256003
Policy mu Std                0.864404
Policy mu Max                3.1574893
Policy mu Min                -3.1732137
Policy log std Mean          -0.5021481
Policy log std Std           0.2733402
Policy log std Max           -0.008643925
Policy log std Min           -2.51032
Z mean eval                  1.746245
Z variance eval              0.12272687
total_rewards                [8675.39151923 8557.95395327 8576.71654798 8662.24498571 8814.13968461
 8540.32764168 8577.13554502 8420.73578825 8776.7660787  8510.22845774]
total_rewards_mean           8611.164020218954
total_rewards_std            114.89219611982645
total_rewards_max            8814.13968461366
total_rewards_min            8420.73578824751
Number of train steps total  980000
Number of env steps total    2942000
Number of rollouts total     0
Train Time (s)               145.63153187185526
(Previous) Eval Time (s)     20.76222208607942
Sample Time (s)              6.432944263797253
Epoch Time (s)               172.82669822173193
Total Train Time (s)         41733.038160453085
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:29:11.986403 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #244 | Epoch Duration: 172.9127061367035
2020-01-12 19:29:11.986535 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #244 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7465522
Z variance train             0.12290241
KL Divergence                41.473034
KL Loss                      4.1473036
QF Loss                      63.876736
VF Loss                      28.068262
Policy Loss                  -1125.5853
Q Predictions Mean           1123.0966
Q Predictions Std            1142.3922
Q Predictions Max            4383.3125
Q Predictions Min            586.70917
V Predictions Mean           1124.6482
V Predictions Std            1137.6709
V Predictions Max            4364.7256
V Predictions Min            592.40564
Log Pis Mean                 -0.41343692
Log Pis Std                  3.7192342
Log Pis Max                  16.857246
Log Pis Min                  -6.8796806
Policy mu Mean               0.06790906
Policy mu Std                0.84742105
Policy mu Max                3.071768
Policy mu Min                -2.9213562
Policy log std Mean          -0.52660465
Policy log std Std           0.28679767
Policy log std Max           0.044259965
Policy log std Min           -2.7207499
Z mean eval                  1.7536799
Z variance eval              0.09292577
total_rewards                [ 9401.82031761  9743.06000706  9641.73144054  9684.43789165
  9792.63591848  9688.89156939  9631.79731749  9494.9398502
  8511.23113671 10004.45109694]
total_rewards_mean           9559.499654606238
total_rewards_std            381.8726467276882
total_rewards_max            10004.451096936282
total_rewards_min            8511.231136713779
Number of train steps total  984000
Number of env steps total    2954000
Number of rollouts total     0
Train Time (s)               147.13269118079916
(Previous) Eval Time (s)     20.84032960794866
Sample Time (s)              6.546165274921805
Epoch Time (s)               174.51918606366962
Total Train Time (s)         41907.63729048194
Epoch                        245
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:32:06.588874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #245 | Epoch Duration: 174.60221147537231
2020-01-12 19:32:06.589124 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.757605
Z variance train             0.09310536
KL Divergence                41.985695
KL Loss                      4.19857
QF Loss                      168.50597
VF Loss                      180.81978
Policy Loss                  -1298.4866
Q Predictions Mean           1295.0479
Q Predictions Std            1276.7852
Q Predictions Max            4271.6494
Q Predictions Min            563.2525
V Predictions Mean           1291.0063
V Predictions Std            1266.802
V Predictions Max            4246.6514
V Predictions Min            588.1915
Log Pis Mean                 0.053647757
Log Pis Std                  3.7410457
Log Pis Max                  22.350365
Log Pis Min                  -7.799821
Policy mu Mean               0.027179683
Policy mu Std                0.9035577
Policy mu Max                3.401928
Policy mu Min                -4.3787894
Policy log std Mean          -0.53548014
Policy log std Std           0.28902376
Policy log std Max           0.18270916
Policy log std Min           -2.343298
Z mean eval                  1.741952
Z variance eval              0.1255991
total_rewards                [9349.87380785 9647.21075538 9652.24171928 9986.90827054 9778.96219524
 9694.90596303 8262.72522524 9959.44548285 9839.52627217 9696.98482609]
total_rewards_mean           9586.878451767969
total_rewards_std            473.3725597484358
total_rewards_max            9986.90827054001
total_rewards_min            8262.725225241616
Number of train steps total  988000
Number of env steps total    2966000
Number of rollouts total     0
Train Time (s)               148.28509284881875
(Previous) Eval Time (s)     20.013280373997986
Sample Time (s)              6.608933925628662
Epoch Time (s)               174.9073071484454
Total Train Time (s)         42082.63267545588
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:35:01.589070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #246 | Epoch Duration: 174.99973845481873
2020-01-12 19:35:01.589337 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.742396
Z variance train             0.12574041
KL Divergence                42.18763
KL Loss                      4.218763
QF Loss                      249.04099
VF Loss                      122.4818
Policy Loss                  -1134.4979
Q Predictions Mean           1132.6044
Q Predictions Std            1142.4135
Q Predictions Max            4294.5356
Q Predictions Min            594.22003
V Predictions Mean           1132.384
V Predictions Std            1137.6532
V Predictions Max            4297.891
V Predictions Min            600.22125
Log Pis Mean                 -0.24487051
Log Pis Std                  3.3126407
Log Pis Max                  10.053282
Log Pis Min                  -6.6233916
Policy mu Mean               0.10837755
Policy mu Std                0.84246606
Policy mu Max                2.6497948
Policy mu Min                -2.4111938
Policy log std Mean          -0.5315239
Policy log std Std           0.2939661
Policy log std Max           -0.025124907
Policy log std Min           -2.565117
Z mean eval                  1.7761278
Z variance eval              0.21891162
total_rewards                [9327.07459755 6943.99354212 9795.29654445 9457.85499822 9508.01460198
 9582.14422624 9831.87033275 9840.46733598 9746.66037073 9640.24391505]
total_rewards_mean           9367.362046506332
total_rewards_std            823.9840846390379
total_rewards_max            9840.467335978165
total_rewards_min            6943.993542118503
Number of train steps total  992000
Number of env steps total    2978000
Number of rollouts total     0
Train Time (s)               144.99456060910597
(Previous) Eval Time (s)     20.642044589389116
Sample Time (s)              6.4396892176009715
Epoch Time (s)               172.07629441609606
Total Train Time (s)         42254.856095574796
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:37:53.838012 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #247 | Epoch Duration: 172.24846172332764
2020-01-12 19:37:53.838247 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7808367
Z variance train             0.21946359
KL Divergence                41.646427
KL Loss                      4.164643
QF Loss                      3137.4502
VF Loss                      71.614
Policy Loss                  -1249.729
Q Predictions Mean           1247.2704
Q Predictions Std            1268.4957
Q Predictions Max            4341.874
Q Predictions Min            553.904
V Predictions Mean           1249.7037
V Predictions Std            1263.8331
V Predictions Max            4333.7554
V Predictions Min            582.7824
Log Pis Mean                 0.13475206
Log Pis Std                  3.945512
Log Pis Max                  13.038726
Log Pis Min                  -6.367713
Policy mu Mean               0.057308603
Policy mu Std                0.9101018
Policy mu Max                3.0814364
Policy mu Min                -3.2372906
Policy log std Mean          -0.5317345
Policy log std Std           0.31471327
Policy log std Max           -0.0015593469
Policy log std Min           -2.7365646
Z mean eval                  1.7895944
Z variance eval              0.20777074
total_rewards                [9285.11854296 9741.3798338  9641.53032895 9551.89385633 9602.09142616
 9423.22838334 8901.55215058 9752.73051394 9654.35256234 9649.21632879]
total_rewards_mean           9520.30939271924
total_rewards_std            246.4663596926194
total_rewards_max            9752.73051394028
total_rewards_min            8901.552150584128
Number of train steps total  996000
Number of env steps total    2990000
Number of rollouts total     0
Train Time (s)               147.26645398605615
(Previous) Eval Time (s)     20.95986649999395
Sample Time (s)              6.370590458158404
Epoch Time (s)               174.5969109442085
Total Train Time (s)         42429.557815935
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:40:48.521030 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #248 | Epoch Duration: 174.68256545066833
2020-01-12 19:40:48.521355 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7857702
Z variance train             0.20802024
KL Divergence                41.312172
KL Loss                      4.1312175
QF Loss                      3491.8516
VF Loss                      86.253624
Policy Loss                  -1291.3575
Q Predictions Mean           1290.3569
Q Predictions Std            1306.7186
Q Predictions Max            4359.3237
Q Predictions Min            575.464
V Predictions Mean           1295.1721
V Predictions Std            1309.8551
V Predictions Max            4366.727
V Predictions Min            578.3418
Log Pis Mean                 -0.4919771
Log Pis Std                  3.702838
Log Pis Max                  11.06343
Log Pis Min                  -8.361116
Policy mu Mean               0.0042738332
Policy mu Std                0.88259333
Policy mu Max                2.7075617
Policy mu Min                -3.3106897
Policy log std Mean          -0.52201027
Policy log std Std           0.28866777
Policy log std Max           -0.020443559
Policy log std Min           -2.7537513
Z mean eval                  1.7741749
Z variance eval              0.19469921
total_rewards                [8953.59386701 9078.20746522 9082.6129015  9184.80300371 9140.97529638
 9161.61964361 9225.32541587 9043.93005791 9106.4554853  9179.93103352]
total_rewards_mean           9115.745417002716
total_rewards_std            75.94817080568373
total_rewards_max            9225.325415871645
total_rewards_min            8953.593867008452
Number of train steps total  1000000
Number of env steps total    3002000
Number of rollouts total     0
Train Time (s)               144.73458814807236
(Previous) Eval Time (s)     20.888639369048178
Sample Time (s)              5.518612444866449
Epoch Time (s)               171.141839961987
Total Train Time (s)         42600.78605386708
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:43:39.751512 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #249 | Epoch Duration: 171.22993779182434
2020-01-12 19:43:39.751645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7708296
Z variance train             0.19426517
KL Divergence                41.50176
KL Loss                      4.150176
QF Loss                      312.63577
VF Loss                      79.54883
Policy Loss                  -1214.9336
Q Predictions Mean           1212.8563
Q Predictions Std            1199.0344
Q Predictions Max            4320.982
Q Predictions Min            566.72766
V Predictions Mean           1216.3716
V Predictions Std            1199.1665
V Predictions Max            4318.967
V Predictions Min            584.54297
Log Pis Mean                 -0.09262577
Log Pis Std                  3.9762115
Log Pis Max                  14.427551
Log Pis Min                  -6.418995
Policy mu Mean               0.010030989
Policy mu Std                0.9012278
Policy mu Max                3.8242
Policy mu Min                -3.318738
Policy log std Mean          -0.51690495
Policy log std Std           0.3031114
Policy log std Max           -0.0356839
Policy log std Min           -2.5228927
Z mean eval                  1.779094
Z variance eval              0.16788673
total_rewards                [9293.24347319 9320.62791688 8982.58661267 9102.22969245 9626.58224729
 9579.82159245 9651.96357395 9203.52862491 9475.62391751 5204.51161802]
total_rewards_mean           8944.07192693135
total_rewards_std            1264.7330786139976
total_rewards_max            9651.963573947622
total_rewards_min            5204.511618020752
Number of train steps total  1004000
Number of env steps total    3014000
Number of rollouts total     0
Train Time (s)               147.85446588508785
(Previous) Eval Time (s)     20.90647173067555
Sample Time (s)              6.4679902866482735
Epoch Time (s)               175.22892790241167
Total Train Time (s)         42776.143607934006
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:46:35.132242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #250 | Epoch Duration: 175.38044667243958
2020-01-12 19:46:35.132575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.781633
Z variance train             0.16794653
KL Divergence                42.087605
KL Loss                      4.2087607
QF Loss                      162.08014
VF Loss                      90.7452
Policy Loss                  -1182.178
Q Predictions Mean           1179.3741
Q Predictions Std            1190.5563
Q Predictions Max            4399.238
Q Predictions Min            568.9331
V Predictions Mean           1177.9407
V Predictions Std            1183.6565
V Predictions Max            4365.2056
V Predictions Min            569.1673
Log Pis Mean                 0.036378667
Log Pis Std                  3.9523475
Log Pis Max                  16.46635
Log Pis Min                  -7.4223256
Policy mu Mean               0.1192106
Policy mu Std                0.8995898
Policy mu Max                3.3675923
Policy mu Min                -2.8045778
Policy log std Mean          -0.53068477
Policy log std Std           0.29475403
Policy log std Max           0.07542354
Policy log std Min           -2.8296185
Z mean eval                  1.7824188
Z variance eval              0.08480109
total_rewards                [9561.63311355 9911.994618   9585.5584945  9769.39539689 9518.80373113
 9730.77940212 9621.22299616 9466.27733852 9639.09516555 9737.44180413]
total_rewards_mean           9654.220206055687
total_rewards_std            126.79299787697703
total_rewards_max            9911.994617998691
total_rewards_min            9466.277338519903
Number of train steps total  1008000
Number of env steps total    3026000
Number of rollouts total     0
Train Time (s)               146.4372411747463
(Previous) Eval Time (s)     20.998735588043928
Sample Time (s)              6.387659186962992
Epoch Time (s)               173.82363594975322
Total Train Time (s)         42950.06826605741
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:49:29.037606 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #251 | Epoch Duration: 173.90480995178223
2020-01-12 19:49:29.037741 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.779948
Z variance train             0.08494794
KL Divergence                42.98838
KL Loss                      4.298838
QF Loss                      115.548996
VF Loss                      40.357155
Policy Loss                  -1172.4442
Q Predictions Mean           1169.6829
Q Predictions Std            1194.9348
Q Predictions Max            4375.903
Q Predictions Min            580.5599
V Predictions Mean           1173.3706
V Predictions Std            1197.6575
V Predictions Max            4377.232
V Predictions Min            584.6308
Log Pis Mean                 -0.47764584
Log Pis Std                  3.542006
Log Pis Max                  12.724888
Log Pis Min                  -6.3510075
Policy mu Mean               0.060035665
Policy mu Std                0.85212046
Policy mu Max                2.9897208
Policy mu Min                -3.0786083
Policy log std Mean          -0.53258693
Policy log std Std           0.2844259
Policy log std Max           -0.03864561
Policy log std Min           -2.686901
Z mean eval                  1.7742409
Z variance eval              0.069273874
total_rewards                [7918.3108124  8404.26100453 1993.11720653 8637.12196374 8686.91210689
 1241.89127459 9086.00930346 9261.13435885 8897.57452191 8543.00803974]
total_rewards_mean           7266.934059262074
total_rewards_std            2851.2990768885734
total_rewards_max            9261.134358845975
total_rewards_min            1241.8912745857501
Number of train steps total  1012000
Number of env steps total    3038000
Number of rollouts total     0
Train Time (s)               145.87022060807794
(Previous) Eval Time (s)     20.873014727141708
Sample Time (s)              6.406892157159746
Epoch Time (s)               173.1501274923794
Total Train Time (s)         43123.30724194879
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:52:22.278305 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #252 | Epoch Duration: 173.24047088623047
2020-01-12 19:52:22.278442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7725197
Z variance train             0.06935481
KL Divergence                42.754585
KL Loss                      4.275459
QF Loss                      116.50628
VF Loss                      61.664944
Policy Loss                  -1372.1632
Q Predictions Mean           1370.2963
Q Predictions Std            1348.9945
Q Predictions Max            4335.462
Q Predictions Min            584.12866
V Predictions Mean           1374.6292
V Predictions Std            1346.0734
V Predictions Max            4324.6953
V Predictions Min            581.8322
Log Pis Mean                 0.16490975
Log Pis Std                  4.2498426
Log Pis Max                  24.896267
Log Pis Min                  -7.650147
Policy mu Mean               0.07763508
Policy mu Std                0.9504339
Policy mu Max                4.084854
Policy mu Min                -4.3351984
Policy log std Mean          -0.5551511
Policy log std Std           0.29576644
Policy log std Max           -0.078214645
Policy log std Min           -2.6446655
Z mean eval                  1.7733316
Z variance eval              0.1054492
total_rewards                [9297.31855359 9524.66210388 9736.58595865 9376.52987659 9495.91938876
 9495.36825022 9577.36126132 9375.93736886 9560.2794408  9671.36630047]
total_rewards_mean           9511.132850312875
total_rewards_std            128.8723389020426
total_rewards_max            9736.58595864641
total_rewards_min            9297.318553588626
Number of train steps total  1016000
Number of env steps total    3050000
Number of rollouts total     0
Train Time (s)               147.20895784022287
(Previous) Eval Time (s)     20.903329230844975
Sample Time (s)              6.391632665414363
Epoch Time (s)               174.5039197364822
Total Train Time (s)         43297.8927455768
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:55:16.865866 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #253 | Epoch Duration: 174.58732438087463
2020-01-12 19:55:16.865999 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.772883
Z variance train             0.10536511
KL Divergence                42.610783
KL Loss                      4.2610784
QF Loss                      314.62955
VF Loss                      47.436485
Policy Loss                  -1174.5073
Q Predictions Mean           1174.7141
Q Predictions Std            1197.613
Q Predictions Max            4362.861
Q Predictions Min            596.42957
V Predictions Mean           1174.3839
V Predictions Std            1198.0925
V Predictions Max            4344.783
V Predictions Min            596.0866
Log Pis Mean                 -0.22037485
Log Pis Std                  3.5147452
Log Pis Max                  14.948996
Log Pis Min                  -5.9011946
Policy mu Mean               0.037654866
Policy mu Std                0.8659603
Policy mu Max                2.5179725
Policy mu Min                -2.5017154
Policy log std Mean          -0.52178925
Policy log std Std           0.2663274
Policy log std Max           0.020970047
Policy log std Min           -2.5639024
Z mean eval                  1.7574002
Z variance eval              0.083392896
total_rewards                [9436.59517697 7645.52392509 9888.78148295 9283.85671157 9772.65494797
 9625.66442201 9476.33448268 9675.11230832 9727.43305852 8940.84725862]
total_rewards_mean           9347.280377469391
total_rewards_std            623.9769262334604
total_rewards_max            9888.781482949382
total_rewards_min            7645.523925085676
Number of train steps total  1020000
Number of env steps total    3062000
Number of rollouts total     0
Train Time (s)               146.61939822230488
(Previous) Eval Time (s)     20.885880242101848
Sample Time (s)              6.405118784401566
Epoch Time (s)               173.9103972488083
Total Train Time (s)         43471.880744062364
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 19:58:10.857068 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #254 | Epoch Duration: 173.99095678329468
2020-01-12 19:58:10.857262 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7567291
Z variance train             0.083589815
KL Divergence                42.660053
KL Loss                      4.2660055
QF Loss                      110.299545
VF Loss                      58.03016
Policy Loss                  -1345.028
Q Predictions Mean           1344.6294
Q Predictions Std            1344.6343
Q Predictions Max            4363.851
Q Predictions Min            570.07184
V Predictions Mean           1344.8416
V Predictions Std            1338.7618
V Predictions Max            4375.342
V Predictions Min            573.71094
Log Pis Mean                 0.19450305
Log Pis Std                  4.052311
Log Pis Max                  16.350153
Log Pis Min                  -6.6292815
Policy mu Mean               0.031369675
Policy mu Std                0.92569155
Policy mu Max                2.7624369
Policy mu Min                -3.1202905
Policy log std Mean          -0.54127717
Policy log std Std           0.287054
Policy log std Max           0.060705245
Policy log std Min           -2.9605079
Z mean eval                  1.7736576
Z variance eval              0.124440074
total_rewards                [9543.0524522  9568.09634856 9348.12763431 9788.60165247 9472.89849871
 9547.89491777 9827.39908861 9432.49402028 9562.72839157 9663.41812542]
total_rewards_mean           9575.471112989708
total_rewards_std            141.8815831949464
total_rewards_max            9827.39908861006
total_rewards_min            9348.127634314687
Number of train steps total  1024000
Number of env steps total    3074000
Number of rollouts total     0
Train Time (s)               146.66588221257553
(Previous) Eval Time (s)     21.13049812288955
Sample Time (s)              6.607282637152821
Epoch Time (s)               174.4036629726179
Total Train Time (s)         43646.37151093315
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:01:05.350325 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #255 | Epoch Duration: 174.4929323196411
2020-01-12 20:01:05.350468 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7696536
Z variance train             0.12433443
KL Divergence                42.53275
KL Loss                      4.253275
QF Loss                      137.61432
VF Loss                      200.22217
Policy Loss                  -1205.2664
Q Predictions Mean           1207.1848
Q Predictions Std            1244.0605
Q Predictions Max            4375.4473
Q Predictions Min            596.6173
V Predictions Mean           1213.2854
V Predictions Std            1244.6924
V Predictions Max            4366.8154
V Predictions Min            603.7684
Log Pis Mean                 -0.05770106
Log Pis Std                  3.5814118
Log Pis Max                  13.804436
Log Pis Min                  -6.3363624
Policy mu Mean               0.07291773
Policy mu Std                0.8686205
Policy mu Max                2.6653752
Policy mu Min                -2.5074222
Policy log std Mean          -0.5305609
Policy log std Std           0.27696538
Policy log std Max           0.04726708
Policy log std Min           -2.407583
Z mean eval                  1.7659814
Z variance eval              0.14784692
total_rewards                [9482.0832671  9526.10796027 9586.63965771 9076.85540055 9432.76884432
 9425.94774397 9457.84490658 9236.0533262  9300.11439827 5282.76617061]
total_rewards_mean           8980.71816755669
total_rewards_std            1240.8661608371513
total_rewards_max            9586.639657705757
total_rewards_min            5282.766170613876
Number of train steps total  1028000
Number of env steps total    3086000
Number of rollouts total     0
Train Time (s)               144.8586970884353
(Previous) Eval Time (s)     20.92569271288812
Sample Time (s)              6.48561123246327
Epoch Time (s)               172.27000103378668
Total Train Time (s)         43818.71970782569
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:03:57.699361 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #256 | Epoch Duration: 172.34879088401794
2020-01-12 20:03:57.699493 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7671797
Z variance train             0.14730713
KL Divergence                41.99893
KL Loss                      4.1998935
QF Loss                      3088.1333
VF Loss                      79.66611
Policy Loss                  -1119.6488
Q Predictions Mean           1117.0925
Q Predictions Std            1146.0569
Q Predictions Max            4369.577
Q Predictions Min            533.8716
V Predictions Mean           1116.3622
V Predictions Std            1140.1249
V Predictions Max            4337.3555
V Predictions Min            562.38873
Log Pis Mean                 -0.24003728
Log Pis Std                  3.6565027
Log Pis Max                  15.823721
Log Pis Min                  -6.151873
Policy mu Mean               0.047149498
Policy mu Std                0.8578993
Policy mu Max                2.84176
Policy mu Min                -2.6344876
Policy log std Mean          -0.51927334
Policy log std Std           0.28049564
Policy log std Max           0.22885507
Policy log std Min           -2.368062
Z mean eval                  1.7467384
Z variance eval              0.07817599
total_rewards                [9360.25716485 9156.6142327  9418.1786055  9062.56081975 9038.25587707
 9232.31632545 9223.43472996 9450.11777444 9547.63202213 9116.12260379]
total_rewards_mean           9260.549015562578
total_rewards_std            166.0094326399013
total_rewards_max            9547.632022130394
total_rewards_min            9038.255877073909
Number of train steps total  1032000
Number of env steps total    3098000
Number of rollouts total     0
Train Time (s)               148.3286285973154
(Previous) Eval Time (s)     17.352066116873175
Sample Time (s)              6.619578615296632
Epoch Time (s)               172.3002733294852
Total Train Time (s)         43991.103924071416
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:06:50.087909 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #257 | Epoch Duration: 172.3882999420166
2020-01-12 20:06:50.088097 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7466068
Z variance train             0.078112744
KL Divergence                43.106705
KL Loss                      4.3106704
QF Loss                      113.54188
VF Loss                      40.66529
Policy Loss                  -1205.5977
Q Predictions Mean           1206.2733
Q Predictions Std            1198.4668
Q Predictions Max            4369.998
Q Predictions Min            589.5702
V Predictions Mean           1204.4309
V Predictions Std            1195.4578
V Predictions Max            4353.837
V Predictions Min            590.47095
Log Pis Mean                 -0.5620737
Log Pis Std                  3.5955713
Log Pis Max                  14.956507
Log Pis Min                  -7.457562
Policy mu Mean               0.058630973
Policy mu Std                0.86694425
Policy mu Max                3.1030345
Policy mu Min                -3.631264
Policy log std Mean          -0.5288134
Policy log std Std           0.26747486
Policy log std Max           0.02033484
Policy log std Min           -2.7380586
Z mean eval                  1.7535006
Z variance eval              0.101828896
total_rewards                [9014.4994191  8955.6178815  9112.27310852 9230.61919304 9226.20428257
 9150.81280974 9030.58887528 9155.16566097 9182.65525363 9303.63480021]
total_rewards_mean           9136.207128455524
total_rewards_std            103.4062988981088
total_rewards_max            9303.634800207385
total_rewards_min            8955.617881498874
Number of train steps total  1036000
Number of env steps total    3110000
Number of rollouts total     0
Train Time (s)               146.43617687094957
(Previous) Eval Time (s)     20.645288208965212
Sample Time (s)              6.701856094412506
Epoch Time (s)               173.78332117432728
Total Train Time (s)         44164.97197356913
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:09:43.956227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #258 | Epoch Duration: 173.8679940700531
2020-01-12 20:09:43.956369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #258 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.757515
Z variance train             0.102180645
KL Divergence                42.70831
KL Loss                      4.270831
QF Loss                      118.2476
VF Loss                      114.67954
Policy Loss                  -1116.6198
Q Predictions Mean           1114.4193
Q Predictions Std            1153.6993
Q Predictions Max            4426.0
Q Predictions Min            592.1076
V Predictions Mean           1110.6354
V Predictions Std            1145.0475
V Predictions Max            4377.2983
V Predictions Min            599.01117
Log Pis Mean                 -0.254673
Log Pis Std                  3.5463016
Log Pis Max                  12.619457
Log Pis Min                  -6.426708
Policy mu Mean               0.10736949
Policy mu Std                0.85020524
Policy mu Max                2.7074182
Policy mu Min                -2.3784518
Policy log std Mean          -0.5272296
Policy log std Std           0.27173275
Policy log std Max           -0.010414362
Policy log std Min           -2.3654675
Z mean eval                  1.7456992
Z variance eval              0.11958937
total_rewards                [ 9582.03346982  9992.80349231  9806.89539839  9841.1413341
  9952.94112694  9750.0695819   9844.52247665 10217.08594831
  9650.18901719  9727.11601141]
total_rewards_mean           9836.479785701767
total_rewards_std            173.98200587888314
total_rewards_max            10217.085948311493
total_rewards_min            9582.033469821065
Number of train steps total  1040000
Number of env steps total    3122000
Number of rollouts total     0
Train Time (s)               144.62589588807896
(Previous) Eval Time (s)     20.62823871569708
Sample Time (s)              6.520058323163539
Epoch Time (s)               171.77419292693958
Total Train Time (s)         44336.82399552921
Epoch                        259
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:12:35.810516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #259 | Epoch Duration: 171.85404872894287
2020-01-12 20:12:35.810658 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7392038
Z variance train             0.11992015
KL Divergence                42.237
KL Loss                      4.2237
QF Loss                      173.88284
VF Loss                      218.82959
Policy Loss                  -1194.1675
Q Predictions Mean           1191.1134
Q Predictions Std            1205.2891
Q Predictions Max            4360.028
Q Predictions Min            601.7235
V Predictions Mean           1202.6624
V Predictions Std            1212.2273
V Predictions Max            4361.2905
V Predictions Min            601.97485
Log Pis Mean                 -0.076390214
Log Pis Std                  3.6655471
Log Pis Max                  12.557689
Log Pis Min                  -7.4810295
Policy mu Mean               0.08533436
Policy mu Std                0.8968728
Policy mu Max                2.8948433
Policy mu Min                -3.3117871
Policy log std Mean          -0.53730637
Policy log std Std           0.29991594
Policy log std Max           0.20123446
Policy log std Min           -2.766329
Z mean eval                  1.7346836
Z variance eval              0.09075831
total_rewards                [8582.13087516 9500.02280516 9639.52496233 9386.68534673 9185.10237711
 9644.74223414 9198.08859355 9127.5286929  9467.13042529 9617.0004374 ]
total_rewards_mean           9334.795674976314
total_rewards_std            310.9070885407209
total_rewards_max            9644.74223414028
total_rewards_min            8582.130875159151
Number of train steps total  1044000
Number of env steps total    3134000
Number of rollouts total     0
Train Time (s)               147.3854846721515
(Previous) Eval Time (s)     17.361706456169486
Sample Time (s)              7.163505083415657
Epoch Time (s)               171.91069621173665
Total Train Time (s)         44508.81322113611
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:15:27.812279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #260 | Epoch Duration: 172.0015058517456
2020-01-12 20:15:27.812466 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7356094
Z variance train             0.090810955
KL Divergence                41.900925
KL Loss                      4.1900926
QF Loss                      128.53183
VF Loss                      121.72565
Policy Loss                  -1248.1598
Q Predictions Mean           1248.9766
Q Predictions Std            1258.8635
Q Predictions Max            4340.17
Q Predictions Min            593.4023
V Predictions Mean           1239.8278
V Predictions Std            1251.0731
V Predictions Max            4293.5386
V Predictions Min            592.1569
Log Pis Mean                 -0.38945076
Log Pis Std                  3.8229377
Log Pis Max                  11.162537
Log Pis Min                  -10.818248
Policy mu Mean               0.0821761
Policy mu Std                0.86427796
Policy mu Max                2.6682222
Policy mu Min                -2.6191435
Policy log std Mean          -0.51123875
Policy log std Std           0.27295086
Policy log std Max           0.022065043
Policy log std Min           -2.7542558
Z mean eval                  1.7592528
Z variance eval              0.115919426
total_rewards                [8733.29606113 9129.99931395 8882.51067484 9690.71167706 9382.29636179
 9319.7893472  9174.00853016 8779.24326081 9368.36617903 9185.75061213]
total_rewards_mean           9164.597201809138
total_rewards_std            283.8344516791523
total_rewards_max            9690.711677056248
total_rewards_min            8733.296061128049
Number of train steps total  1048000
Number of env steps total    3146000
Number of rollouts total     0
Train Time (s)               146.63168477499858
(Previous) Eval Time (s)     20.716114414855838
Sample Time (s)              6.353921830654144
Epoch Time (s)               173.70172102050856
Total Train Time (s)         44682.61376539664
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:18:21.614518 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #261 | Epoch Duration: 173.80190205574036
2020-01-12 20:18:21.614765 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7592831
Z variance train             0.11545143
KL Divergence                40.196453
KL Loss                      4.019645
QF Loss                      94.97003
VF Loss                      149.12033
Policy Loss                  -1268.4645
Q Predictions Mean           1265.7703
Q Predictions Std            1264.2429
Q Predictions Max            4391.273
Q Predictions Min            603.3117
V Predictions Mean           1272.4617
V Predictions Std            1271.0067
V Predictions Max            4393.1777
V Predictions Min            600.84204
Log Pis Mean                 -0.3984337
Log Pis Std                  3.463973
Log Pis Max                  10.35025
Log Pis Min                  -7.520997
Policy mu Mean               0.0481486
Policy mu Std                0.90044373
Policy mu Max                2.6502335
Policy mu Min                -2.714939
Policy log std Mean          -0.5165883
Policy log std Std           0.2921982
Policy log std Max           0.043790698
Policy log std Min           -2.896711
Z mean eval                  1.745047
Z variance eval              0.08715452
total_rewards                [9280.48230629 9383.77209041 9353.4571532  8884.89910416 8916.26078091
 9359.3328798  9383.23904886 9219.88198348 9455.93200074 9036.15902022]
total_rewards_mean           9227.3416368059
total_rewards_std            196.93232675694512
total_rewards_max            9455.93200073663
total_rewards_min            8884.899104160253
Number of train steps total  1052000
Number of env steps total    3158000
Number of rollouts total     0
Train Time (s)               146.6336931148544
(Previous) Eval Time (s)     20.84137403825298
Sample Time (s)              6.371843389701098
Epoch Time (s)               173.84691054280847
Total Train Time (s)         44856.765758476686
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:21:15.765526 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #262 | Epoch Duration: 174.15058064460754
2020-01-12 20:21:15.765764 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #262 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7452042
Z variance train             0.0868842
KL Divergence                41.589752
KL Loss                      4.158975
QF Loss                      180.93974
VF Loss                      126.100494
Policy Loss                  -1238.6925
Q Predictions Mean           1235.9426
Q Predictions Std            1263.0867
Q Predictions Max            4398.207
Q Predictions Min            602.05054
V Predictions Mean           1234.561
V Predictions Std            1256.9209
V Predictions Max            4383.42
V Predictions Min            603.8504
Log Pis Mean                 0.017342582
Log Pis Std                  3.693031
Log Pis Max                  16.862032
Log Pis Min                  -8.191497
Policy mu Mean               -0.00019532256
Policy mu Std                0.8909035
Policy mu Max                2.7036388
Policy mu Min                -2.4853492
Policy log std Mean          -0.524471
Policy log std Std           0.29293114
Policy log std Max           0.0033568144
Policy log std Min           -2.9662037
Z mean eval                  1.7660414
Z variance eval              0.092907295
total_rewards                [9246.33412308 9880.27072724 9510.18602029 9725.82068277 9821.2008116
 9919.45869741 9718.74481617 9807.52747678 9934.84722089 9840.51884968]
total_rewards_mean           9740.490942591063
total_rewards_std            202.05820955649847
total_rewards_max            9934.847220892663
total_rewards_min            9246.334123076897
Number of train steps total  1056000
Number of env steps total    3170000
Number of rollouts total     0
Train Time (s)               145.5090962871909
(Previous) Eval Time (s)     20.74479079199955
Sample Time (s)              6.479285418521613
Epoch Time (s)               172.73317249771208
Total Train Time (s)         45029.58179012034
Epoch                        263
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:24:08.580833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #263 | Epoch Duration: 172.81490421295166
2020-01-12 20:24:08.580970 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7674544
Z variance train             0.09268341
KL Divergence                42.820137
KL Loss                      4.282014
QF Loss                      142.76653
VF Loss                      50.05094
Policy Loss                  -1257.801
Q Predictions Mean           1251.8201
Q Predictions Std            1260.7694
Q Predictions Max            4382.842
Q Predictions Min            579.8911
V Predictions Mean           1256.5542
V Predictions Std            1258.1921
V Predictions Max            4379.6216
V Predictions Min            582.98804
Log Pis Mean                 -0.054270566
Log Pis Std                  3.787392
Log Pis Max                  13.063032
Log Pis Min                  -10.751216
Policy mu Mean               0.07265356
Policy mu Std                0.88973165
Policy mu Max                2.4966269
Policy mu Min                -2.8431544
Policy log std Mean          -0.54232186
Policy log std Std           0.3004154
Policy log std Max           -0.016217709
Policy log std Min           -2.8722336
Z mean eval                  1.7454135
Z variance eval              0.09278419
total_rewards                [9609.03153428 9702.18040305 9696.43015969 9879.92615209 9975.52721157
 9807.92252283 9884.29342294 9895.78264647 9853.73068436 9609.89229134]
total_rewards_mean           9791.471702862966
total_rewards_std            121.90381608184126
total_rewards_max            9975.527211566443
total_rewards_min            9609.031534284286
Number of train steps total  1060000
Number of env steps total    3182000
Number of rollouts total     0
Train Time (s)               147.2457104199566
(Previous) Eval Time (s)     20.704821993596852
Sample Time (s)              6.552130613476038
Epoch Time (s)               174.50266302702948
Total Train Time (s)         45204.166069444735
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:27:03.168274 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #264 | Epoch Duration: 174.58720660209656
2020-01-12 20:27:03.168411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7463608
Z variance train             0.092796125
KL Divergence                43.294846
KL Loss                      4.3294845
QF Loss                      143.43774
VF Loss                      62.886543
Policy Loss                  -1269.644
Q Predictions Mean           1268.9779
Q Predictions Std            1298.0004
Q Predictions Max            4372.104
Q Predictions Min            590.20905
V Predictions Mean           1270.8508
V Predictions Std            1291.8638
V Predictions Max            4331.3604
V Predictions Min            600.31635
Log Pis Mean                 0.019742236
Log Pis Std                  4.2634945
Log Pis Max                  24.542145
Log Pis Min                  -6.686059
Policy mu Mean               0.06087004
Policy mu Std                0.9288629
Policy mu Max                2.9903731
Policy mu Min                -3.6272037
Policy log std Mean          -0.52189523
Policy log std Std           0.2775352
Policy log std Max           0.039422452
Policy log std Min           -2.6491127
Z mean eval                  1.7472773
Z variance eval              0.05981777
total_rewards                [9459.28721303 9735.37377131 9738.73380732 9765.99337355 9759.78076077
 9602.01404775 9704.2133714  9543.49027655 9790.50147059 9757.21633363]
total_rewards_mean           9685.660442589618
total_rewards_std            105.89873033555946
total_rewards_max            9790.501470589665
total_rewards_min            9459.287213026506
Number of train steps total  1064000
Number of env steps total    3194000
Number of rollouts total     0
Train Time (s)               144.91787139233202
(Previous) Eval Time (s)     17.46636558091268
Sample Time (s)              6.586990963667631
Epoch Time (s)               168.97122793691233
Total Train Time (s)         45373.21807850432
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:29:52.224693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #265 | Epoch Duration: 169.0561661720276
2020-01-12 20:29:52.224878 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7451235
Z variance train             0.059518296
KL Divergence                44.472107
KL Loss                      4.447211
QF Loss                      120.551575
VF Loss                      55.106342
Policy Loss                  -1218.0856
Q Predictions Mean           1219.495
Q Predictions Std            1254.5999
Q Predictions Max            4359.777
Q Predictions Min            564.6509
V Predictions Mean           1221.447
V Predictions Std            1255.6483
V Predictions Max            4348.4106
V Predictions Min            555.7788
Log Pis Mean                 -0.2760762
Log Pis Std                  3.6505923
Log Pis Max                  12.610852
Log Pis Min                  -8.276613
Policy mu Mean               0.09583279
Policy mu Std                0.856386
Policy mu Max                2.6970887
Policy mu Min                -2.9787123
Policy log std Mean          -0.5191657
Policy log std Std           0.2841953
Policy log std Max           0.057383537
Policy log std Min           -2.9506981
Z mean eval                  1.7385772
Z variance eval              0.035187196
total_rewards                [9660.143292   9644.99637509 9689.20299252 9679.1998455  9780.75601008
 9926.06666626 9694.02714043 9675.89592774 9911.27479518 9903.64086707]
total_rewards_mean           9756.520391187005
total_rewards_std            108.429066881898
total_rewards_max            9926.066666255521
total_rewards_min            9644.996375090208
Number of train steps total  1068000
Number of env steps total    3206000
Number of rollouts total     0
Train Time (s)               145.79407923389226
(Previous) Eval Time (s)     21.038610205985606
Sample Time (s)              6.791314459405839
Epoch Time (s)               173.6240038992837
Total Train Time (s)         45546.93370489543
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:32:45.940665 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #266 | Epoch Duration: 173.71564984321594
2020-01-12 20:32:45.940807 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #266 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7365135
Z variance train             0.035247542
KL Divergence                45.664352
KL Loss                      4.5664353
QF Loss                      93.18532
VF Loss                      30.372679
Policy Loss                  -1159.3887
Q Predictions Mean           1155.7102
Q Predictions Std            1149.6685
Q Predictions Max            4335.1514
Q Predictions Min            607.82104
V Predictions Mean           1160.4246
V Predictions Std            1148.7865
V Predictions Max            4327.755
V Predictions Min            613.9379
Log Pis Mean                 0.015656546
Log Pis Std                  3.2932482
Log Pis Max                  14.532477
Log Pis Min                  -8.064541
Policy mu Mean               0.12966149
Policy mu Std                0.8757177
Policy mu Max                2.6650927
Policy mu Min                -2.182673
Policy log std Mean          -0.55498165
Policy log std Std           0.30463317
Policy log std Max           0.03918588
Policy log std Min           -2.670804
Z mean eval                  1.7481508
Z variance eval              0.08875714
total_rewards                [8235.15190744 5134.02705917 8943.61360524 8889.50625222 8921.0080086
 9002.74468688 9032.81428565 9189.96434883 8608.06135219 9174.89871434]
total_rewards_mean           8513.179022056202
total_rewards_std            1157.7476838752534
total_rewards_max            9189.964348828462
total_rewards_min            5134.027059169511
Number of train steps total  1072000
Number of env steps total    3218000
Number of rollouts total     0
Train Time (s)               145.32139267586172
(Previous) Eval Time (s)     21.02859862195328
Sample Time (s)              6.4026372381486
Epoch Time (s)               172.7526285359636
Total Train Time (s)         45719.7720606979
Epoch                        267
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:35:38.781981 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #267 | Epoch Duration: 172.84107661247253
2020-01-12 20:35:38.782114 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7478126
Z variance train             0.088783465
KL Divergence                42.81504
KL Loss                      4.281504
QF Loss                      3348.2485
VF Loss                      61.408363
Policy Loss                  -1160.5621
Q Predictions Mean           1160.4563
Q Predictions Std            1190.4075
Q Predictions Max            4379.071
Q Predictions Min            571.579
V Predictions Mean           1155.3696
V Predictions Std            1188.8616
V Predictions Max            4355.9033
V Predictions Min            593.9074
Log Pis Mean                 -0.26281565
Log Pis Std                  3.521033
Log Pis Max                  11.419003
Log Pis Min                  -7.0363874
Policy mu Mean               0.05872916
Policy mu Std                0.860494
Policy mu Max                3.3131218
Policy mu Min                -2.4647305
Policy log std Mean          -0.5362471
Policy log std Std           0.27901968
Policy log std Max           -0.07379049
Policy log std Min           -2.3348083
Z mean eval                  1.7501844
Z variance eval              0.104217276
total_rewards                [9658.85056241 8384.69687762 9658.45727889 9857.11345035 9822.15418681
 9992.98466659 9448.23603542 9723.75927926 9678.1243849  4806.46622039]
total_rewards_mean           9103.08429426427
total_rewards_std            1493.5496332065795
total_rewards_max            9992.98466658966
total_rewards_min            4806.4662203896605
Number of train steps total  1076000
Number of env steps total    3230000
Number of rollouts total     0
Train Time (s)               146.45349782239646
(Previous) Eval Time (s)     17.568248297087848
Sample Time (s)              6.399309926666319
Epoch Time (s)               170.42105604615062
Total Train Time (s)         45890.27335677389
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:38:29.284538 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #268 | Epoch Duration: 170.50232911109924
2020-01-12 20:38:29.284662 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7536707
Z variance train             0.104101166
KL Divergence                43.182846
KL Loss                      4.3182845
QF Loss                      173.51886
VF Loss                      121.20978
Policy Loss                  -1255.8507
Q Predictions Mean           1252.2139
Q Predictions Std            1268.9392
Q Predictions Max            4420.8623
Q Predictions Min            601.2195
V Predictions Mean           1249.9639
V Predictions Std            1260.8335
V Predictions Max            4384.191
V Predictions Min            600.04224
Log Pis Mean                 -0.22825804
Log Pis Std                  3.6361682
Log Pis Max                  15.240686
Log Pis Min                  -6.6483135
Policy mu Mean               0.019539187
Policy mu Std                0.8696629
Policy mu Max                3.1137211
Policy mu Min                -2.821637
Policy log std Mean          -0.5409538
Policy log std Std           0.29847503
Policy log std Max           0.10710096
Policy log std Min           -2.8368092
Z mean eval                  1.7342281
Z variance eval              0.12573054
total_rewards                [9540.67324403 9656.16208556 9788.00592088 9933.9485191  9717.08214636
 9770.28226797 9683.38190284 9562.14080572 9775.18004461 9727.91676694]
total_rewards_mean           9715.477370402125
total_rewards_std            108.78066931246433
total_rewards_max            9933.948519101346
total_rewards_min            9540.67324403384
Number of train steps total  1080000
Number of env steps total    3242000
Number of rollouts total     0
Train Time (s)               148.75103180482984
(Previous) Eval Time (s)     17.32146666571498
Sample Time (s)              5.594295365270227
Epoch Time (s)               171.66679383581504
Total Train Time (s)         46062.01820778148
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:41:21.032517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #269 | Epoch Duration: 171.74774074554443
2020-01-12 20:41:21.032701 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.734925
Z variance train             0.12511994
KL Divergence                40.980484
KL Loss                      4.0980487
QF Loss                      3307.3552
VF Loss                      55.60722
Policy Loss                  -1208.0804
Q Predictions Mean           1206.3738
Q Predictions Std            1205.2891
Q Predictions Max            4292.719
Q Predictions Min            577.8253
V Predictions Mean           1208.6997
V Predictions Std            1200.2239
V Predictions Max            4295.9604
V Predictions Min            586.86945
Log Pis Mean                 -0.5608056
Log Pis Std                  3.4237473
Log Pis Max                  10.542607
Log Pis Min                  -6.4412975
Policy mu Mean               0.068316646
Policy mu Std                0.82910055
Policy mu Max                2.6098995
Policy mu Min                -2.9539247
Policy log std Mean          -0.5160478
Policy log std Std           0.2799233
Policy log std Max           0.114674926
Policy log std Min           -2.5811617
Z mean eval                  1.7548397
Z variance eval              0.08945949
total_rewards                [9482.031321   9487.31077299 9736.73351149 9708.85297019 9490.92930187
 9512.8964819  9600.81628189 9768.73201264 9599.84273855 9618.40251606]
total_rewards_mean           9600.654790858329
total_rewards_std            102.68859804006739
total_rewards_max            9768.732012641207
total_rewards_min            9482.031321004146
Number of train steps total  1084000
Number of env steps total    3254000
Number of rollouts total     0
Train Time (s)               146.60268000885844
(Previous) Eval Time (s)     17.56419771630317
Sample Time (s)              6.462789782322943
Epoch Time (s)               170.62966750748456
Total Train Time (s)         46232.73623618344
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:44:11.754794 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #270 | Epoch Duration: 170.72193717956543
2020-01-12 20:44:11.755028 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7555453
Z variance train             0.08920672
KL Divergence                42.32183
KL Loss                      4.232183
QF Loss                      92.76051
VF Loss                      49.591805
Policy Loss                  -1277.0006
Q Predictions Mean           1276.3308
Q Predictions Std            1281.9404
Q Predictions Max            4400.368
Q Predictions Min            590.3804
V Predictions Mean           1275.7125
V Predictions Std            1275.9762
V Predictions Max            4385.7754
V Predictions Min            593.8369
Log Pis Mean                 -0.11393137
Log Pis Std                  3.4208694
Log Pis Max                  11.889294
Log Pis Min                  -6.542387
Policy mu Mean               0.055158526
Policy mu Std                0.8782008
Policy mu Max                2.682156
Policy mu Min                -2.535752
Policy log std Mean          -0.5436446
Policy log std Std           0.2832663
Policy log std Max           -0.020268738
Policy log std Min           -2.3069928
Z mean eval                  1.7443607
Z variance eval              0.08621048
total_rewards                [9031.98208478 5678.63847641 9170.99171008 9327.15738919 2732.51589279
 8459.21521694 9504.43467068 3694.13234766 9017.40115312 2438.14279284]
total_rewards_mean           6905.461173449983
total_rewards_std            2798.867097438392
total_rewards_max            9504.434670682898
total_rewards_min            2438.1427928446724
Number of train steps total  1088000
Number of env steps total    3266000
Number of rollouts total     0
Train Time (s)               147.19228057935834
(Previous) Eval Time (s)     17.32895897794515
Sample Time (s)              6.598547065164894
Epoch Time (s)               171.11978662246838
Total Train Time (s)         46403.93567018304
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:47:02.956403 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #271 | Epoch Duration: 171.20120930671692
2020-01-12 20:47:02.956581 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7444131
Z variance train             0.085782126
KL Divergence                42.383575
KL Loss                      4.2383575
QF Loss                      180.43394
VF Loss                      81.07958
Policy Loss                  -1219.5262
Q Predictions Mean           1214.7198
Q Predictions Std            1239.7426
Q Predictions Max            4440.586
Q Predictions Min            586.17816
V Predictions Mean           1222.5881
V Predictions Std            1242.797
V Predictions Max            4459.6006
V Predictions Min            597.1973
Log Pis Mean                 -0.437898
Log Pis Std                  3.2550666
Log Pis Max                  11.165357
Log Pis Min                  -6.9576464
Policy mu Mean               0.05111481
Policy mu Std                0.8577328
Policy mu Max                3.459533
Policy mu Min                -2.8054976
Policy log std Mean          -0.52078146
Policy log std Std           0.28934747
Policy log std Max           0.11424762
Policy log std Min           -2.6555288
Z mean eval                  1.7374609
Z variance eval              0.071178116
total_rewards                [8346.9289355  8825.10455415 9442.28414192 8671.70726048 9373.76835071
 9450.36538038 9066.13371641 9307.82733755 9187.76668575 8940.24567317]
total_rewards_mean           9061.213203601312
total_rewards_std            346.9151274033055
total_rewards_max            9450.365380378673
total_rewards_min            8346.928935497464
Number of train steps total  1092000
Number of env steps total    3278000
Number of rollouts total     0
Train Time (s)               147.28848968073726
(Previous) Eval Time (s)     20.461997426114976
Sample Time (s)              6.637129923328757
Epoch Time (s)               174.387617030181
Total Train Time (s)         46578.40435325494
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:49:57.425969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #272 | Epoch Duration: 174.4692575931549
2020-01-12 20:49:57.426112 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7378273
Z variance train             0.07116778
KL Divergence                41.750343
KL Loss                      4.1750345
QF Loss                      3389.3552
VF Loss                      105.16761
Policy Loss                  -1311.3065
Q Predictions Mean           1312.6985
Q Predictions Std            1323.4949
Q Predictions Max            4330.1636
Q Predictions Min            512.96606
V Predictions Mean           1310.274
V Predictions Std            1316.8094
V Predictions Max            4315.374
V Predictions Min            549.35547
Log Pis Mean                 -0.07276502
Log Pis Std                  3.8851311
Log Pis Max                  12.640143
Log Pis Min                  -6.412588
Policy mu Mean               0.034809023
Policy mu Std                0.8857936
Policy mu Max                2.7590334
Policy mu Min                -2.4972398
Policy log std Mean          -0.5288662
Policy log std Std           0.29222944
Policy log std Max           0.05652827
Policy log std Min           -2.9337573
Z mean eval                  1.7335932
Z variance eval              0.09292992
total_rewards                [9295.81588268 9663.92786682 1853.74511099 9629.3875523  9574.30691754
 9688.14170932 9530.02228108 9299.00275534 9720.62159426 9630.18966046]
total_rewards_mean           8788.516133079927
total_rewards_std            2315.950535370803
total_rewards_max            9720.62159426111
total_rewards_min            1853.745110990957
Number of train steps total  1096000
Number of env steps total    3290000
Number of rollouts total     0
Train Time (s)               146.4547862401232
(Previous) Eval Time (s)     17.443616937845945
Sample Time (s)              6.422807740047574
Epoch Time (s)               170.32121091801673
Total Train Time (s)         46748.80904034758
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:52:47.837128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #273 | Epoch Duration: 170.4108967781067
2020-01-12 20:52:47.837342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7349608
Z variance train             0.0930696
KL Divergence                40.347538
KL Loss                      4.034754
QF Loss                      3335.855
VF Loss                      70.39378
Policy Loss                  -1384.7418
Q Predictions Mean           1385.7225
Q Predictions Std            1366.226
Q Predictions Max            4327.263
Q Predictions Min            585.34436
V Predictions Mean           1387.7263
V Predictions Std            1367.7933
V Predictions Max            4311.309
V Predictions Min            574.4044
Log Pis Mean                 -0.0141959265
Log Pis Std                  3.8340762
Log Pis Max                  13.839698
Log Pis Min                  -7.0351276
Policy mu Mean               0.027492968
Policy mu Std                0.88298273
Policy mu Max                2.4742856
Policy mu Min                -3.0555267
Policy log std Mean          -0.54370934
Policy log std Std           0.29239687
Policy log std Max           0.045506477
Policy log std Min           -2.806665
Z mean eval                  1.7576834
Z variance eval              0.071939364
total_rewards                [9185.53642366 9457.71836456 9543.66976431 6782.42140256 9379.53242635
 9741.23716456 9466.97250379 9609.91658317 9396.80923962 9585.30247177]
total_rewards_mean           9214.911634436756
total_rewards_std            823.3387467309844
total_rewards_max            9741.237164562492
total_rewards_min            6782.421402556816
Number of train steps total  1100000
Number of env steps total    3302000
Number of rollouts total     0
Train Time (s)               145.70883277710527
(Previous) Eval Time (s)     20.83021711418405
Sample Time (s)              6.5475135035812855
Epoch Time (s)               173.0865633948706
Total Train Time (s)         46921.98192926776
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:55:41.010111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #274 | Epoch Duration: 173.1726200580597
2020-01-12 20:55:41.010240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7586253
Z variance train             0.07215244
KL Divergence                41.39457
KL Loss                      4.139457
QF Loss                      210.7392
VF Loss                      120.94069
Policy Loss                  -1248.6448
Q Predictions Mean           1245.3901
Q Predictions Std            1267.8595
Q Predictions Max            4345.2363
Q Predictions Min            596.62494
V Predictions Mean           1239.5889
V Predictions Std            1262.9565
V Predictions Max            4302.739
V Predictions Min            593.71545
Log Pis Mean                 -0.1491435
Log Pis Std                  3.8912091
Log Pis Max                  13.694525
Log Pis Min                  -8.179174
Policy mu Mean               0.047808483
Policy mu Std                0.90989345
Policy mu Max                3.115144
Policy mu Min                -2.7271748
Policy log std Mean          -0.53578913
Policy log std Std           0.29092962
Policy log std Max           0.2172997
Policy log std Min           -2.8345075
Z mean eval                  1.7425239
Z variance eval              0.06898398
total_rewards                [9460.55912926 9741.40318782 9724.40992924 9629.06322863 9996.45626637
 9908.08297124 9246.67077599 9527.22045183 9870.94551327 9686.4530979 ]
total_rewards_mean           9679.126455155085
total_rewards_std            213.60427463751532
total_rewards_max            9996.456266368465
total_rewards_min            9246.670775989794
Number of train steps total  1104000
Number of env steps total    3314000
Number of rollouts total     0
Train Time (s)               147.76809813501313
(Previous) Eval Time (s)     21.285306555684656
Sample Time (s)              6.407560394145548
Epoch Time (s)               175.46096508484334
Total Train Time (s)         47097.522965267766
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 20:58:36.553663 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #275 | Epoch Duration: 175.54332661628723
2020-01-12 20:58:36.553801 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7432768
Z variance train             0.069136225
KL Divergence                42.574093
KL Loss                      4.2574096
QF Loss                      144.89163
VF Loss                      99.689316
Policy Loss                  -1250.899
Q Predictions Mean           1247.3203
Q Predictions Std            1266.6183
Q Predictions Max            4349.0796
Q Predictions Min            574.6034
V Predictions Mean           1244.5433
V Predictions Std            1262.4752
V Predictions Max            4330.9907
V Predictions Min            573.58636
Log Pis Mean                 -0.31666213
Log Pis Std                  3.853306
Log Pis Max                  17.190506
Log Pis Min                  -6.8929353
Policy mu Mean               0.062362194
Policy mu Std                0.8660175
Policy mu Max                3.1714425
Policy mu Min                -3.5257285
Policy log std Mean          -0.5154569
Policy log std Std           0.27587366
Policy log std Max           0.11025846
Policy log std Min           -2.5508661
Z mean eval                  1.7648163
Z variance eval              0.078547604
total_rewards                [9069.72196686 7224.20710826 9450.95950634 9375.41940055 9446.15247182
 9367.92043175 9284.56373064 9437.73788319 9460.88036039 9360.32015523]
total_rewards_mean           9147.788301503802
total_rewards_std            650.6490369876992
total_rewards_max            9460.880360392268
total_rewards_min            7224.20710825721
Number of train steps total  1108000
Number of env steps total    3326000
Number of rollouts total     0
Train Time (s)               146.99340754002333
(Previous) Eval Time (s)     19.884230616968125
Sample Time (s)              6.556339040398598
Epoch Time (s)               173.43397719739005
Total Train Time (s)         47271.04510283237
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:01:30.082129 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #276 | Epoch Duration: 173.5282051563263
2020-01-12 21:01:30.082303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.764679
Z variance train             0.07856524
KL Divergence                43.226593
KL Loss                      4.3226595
QF Loss                      102.647484
VF Loss                      49.501194
Policy Loss                  -991.0964
Q Predictions Mean           987.2644
Q Predictions Std            974.0554
Q Predictions Max            4403.011
Q Predictions Min            581.80426
V Predictions Mean           988.02167
V Predictions Std            971.1892
V Predictions Max            4385.987
V Predictions Min            573.72174
Log Pis Mean                 -0.75669634
Log Pis Std                  3.3660727
Log Pis Max                  18.61289
Log Pis Min                  -8.731966
Policy mu Mean               0.06812299
Policy mu Std                0.80612123
Policy mu Max                3.753063
Policy mu Min                -4.0298357
Policy log std Mean          -0.49651837
Policy log std Std           0.26400617
Policy log std Max           -0.055824563
Policy log std Min           -2.8486624
Z mean eval                  1.740016
Z variance eval              0.09686902
total_rewards                [9337.48182007 9459.64236705 9597.34835195 9444.67462635 9667.13708007
 9612.79216978 9484.06077501 9840.65399692 9689.94141777 9632.05697035]
total_rewards_mean           9576.578957530524
total_rewards_std            138.71120927563527
total_rewards_max            9840.653996919851
total_rewards_min            9337.481820071558
Number of train steps total  1112000
Number of env steps total    3338000
Number of rollouts total     0
Train Time (s)               147.48841155134141
(Previous) Eval Time (s)     20.857713548932225
Sample Time (s)              6.50327519653365
Epoch Time (s)               174.8494002968073
Total Train Time (s)         47445.99035245087
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:04:25.030036 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #277 | Epoch Duration: 174.94760537147522
2020-01-12 21:04:25.030172 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7434896
Z variance train             0.09696863
KL Divergence                41.819405
KL Loss                      4.1819406
QF Loss                      3259.271
VF Loss                      123.110275
Policy Loss                  -1240.5762
Q Predictions Mean           1237.8848
Q Predictions Std            1264.3225
Q Predictions Max            4427.5376
Q Predictions Min            591.54236
V Predictions Mean           1237.1461
V Predictions Std            1266.8448
V Predictions Max            4457.8115
V Predictions Min            583.13
Log Pis Mean                 -0.49892074
Log Pis Std                  3.5097435
Log Pis Max                  17.804604
Log Pis Min                  -7.1039195
Policy mu Mean               0.0116665
Policy mu Std                0.82776767
Policy mu Max                2.7733347
Policy mu Min                -3.5363154
Policy log std Mean          -0.5052878
Policy log std Std           0.27190188
Policy log std Max           -0.023944348
Policy log std Min           -2.4260182
Z mean eval                  1.7616742
Z variance eval              0.093697146
total_rewards                [9501.08920455 9591.35804991 9725.86415631 9681.82342503 9707.37959607
 9652.53565263 9608.08521344 9607.17007972 9534.95824684 9611.74894159]
total_rewards_mean           9622.20125661053
total_rewards_std            68.001139687494
total_rewards_max            9725.864156314981
total_rewards_min            9501.089204552223
Number of train steps total  1116000
Number of env steps total    3350000
Number of rollouts total     0
Train Time (s)               145.7023400021717
(Previous) Eval Time (s)     17.358841136097908
Sample Time (s)              6.540822580456734
Epoch Time (s)               169.60200371872634
Total Train Time (s)         47615.67494026944
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:07:14.722530 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #278 | Epoch Duration: 169.6922447681427
2020-01-12 21:07:14.722748 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7637131
Z variance train             0.09373473
KL Divergence                43.673252
KL Loss                      4.3673253
QF Loss                      85.556015
VF Loss                      39.27642
Policy Loss                  -1147.2986
Q Predictions Mean           1143.6907
Q Predictions Std            1155.2415
Q Predictions Max            4362.751
Q Predictions Min            587.3572
V Predictions Mean           1146.2986
V Predictions Std            1153.4796
V Predictions Max            4364.107
V Predictions Min            592.6431
Log Pis Mean                 -0.7190977
Log Pis Std                  3.5888562
Log Pis Max                  23.169933
Log Pis Min                  -6.155051
Policy mu Mean               0.014476043
Policy mu Std                0.8332003
Policy mu Max                4.140258
Policy mu Min                -3.460829
Policy log std Mean          -0.49355236
Policy log std Std           0.2804568
Policy log std Max           0.40330547
Policy log std Min           -2.2532296
Z mean eval                  1.7730224
Z variance eval              0.11972387
total_rewards                [9705.95421544 9645.42182052 9832.42020263 9896.81045353 9948.52727022
 9786.97817433 9906.6341873  9823.97398633 9769.11802533 9812.83329363]
total_rewards_mean           9812.86716292633
total_rewards_std            87.63596718530383
total_rewards_max            9948.527270215978
total_rewards_min            9645.421820524636
Number of train steps total  1120000
Number of env steps total    3362000
Number of rollouts total     0
Train Time (s)               145.88070540875196
(Previous) Eval Time (s)     20.724658160004765
Sample Time (s)              5.653849940747023
Epoch Time (s)               172.25921350950375
Total Train Time (s)         47788.01965285046
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:10:07.064601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #279 | Epoch Duration: 172.3417193889618
2020-01-12 21:10:07.064747 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7749875
Z variance train             0.11954923
KL Divergence                42.854637
KL Loss                      4.285464
QF Loss                      88.41647
VF Loss                      51.865326
Policy Loss                  -1262.2653
Q Predictions Mean           1259.6322
Q Predictions Std            1220.8245
Q Predictions Max            4431.6577
Q Predictions Min            602.4041
V Predictions Mean           1261.9612
V Predictions Std            1216.4175
V Predictions Max            4425.497
V Predictions Min            608.3096
Log Pis Mean                 -0.15354186
Log Pis Std                  4.1109533
Log Pis Max                  16.408554
Log Pis Min                  -8.559284
Policy mu Mean               0.058541086
Policy mu Std                0.87691885
Policy mu Max                2.9466443
Policy mu Min                -3.296139
Policy log std Mean          -0.52103764
Policy log std Std           0.28373384
Policy log std Max           0.039352298
Policy log std Min           -2.7925138
Z mean eval                  1.8014818
Z variance eval              0.07060844
total_rewards                [6513.99871498 6193.8134067  5686.04132414 4793.67195519 6438.65418359
 2073.49520946 7130.25785176 6611.32506525 7623.1469935  6357.64446678]
total_rewards_mean           5942.204917134713
total_rewards_std            1478.030014525223
total_rewards_max            7623.146993500513
total_rewards_min            2073.495209456037
Number of train steps total  1124000
Number of env steps total    3374000
Number of rollouts total     0
Train Time (s)               145.72794235078618
(Previous) Eval Time (s)     20.987641382031143
Sample Time (s)              8.109821412712336
Epoch Time (s)               174.82540514552966
Total Train Time (s)         47962.93135652132
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:13:01.978755 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #280 | Epoch Duration: 174.91390919685364
2020-01-12 21:13:01.978934 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8023672
Z variance train             0.07044431
KL Divergence                44.032
KL Loss                      4.4032
QF Loss                      3550.4016
VF Loss                      52.10685
Policy Loss                  -1318.946
Q Predictions Mean           1317.3202
Q Predictions Std            1302.7037
Q Predictions Max            4339.474
Q Predictions Min            589.56995
V Predictions Mean           1319.641
V Predictions Std            1299.5764
V Predictions Max            4334.733
V Predictions Min            602.37213
Log Pis Mean                 -0.37042367
Log Pis Std                  3.7248483
Log Pis Max                  17.331356
Log Pis Min                  -7.924635
Policy mu Mean               0.073993154
Policy mu Std                0.85528684
Policy mu Max                2.738887
Policy mu Min                -2.775319
Policy log std Mean          -0.52084285
Policy log std Std           0.29186237
Policy log std Max           0.122879624
Policy log std Min           -2.7148266
Z mean eval                  1.7584461
Z variance eval              0.07197299
total_rewards                [9654.13997413 9597.46862019 9888.61269431 9674.33487321 9591.61994637
 9774.55938802 9730.97431618 9801.56598737 9443.76450099 9621.27783347]
total_rewards_mean           9677.831813422075
total_rewards_std            120.1537327422073
total_rewards_max            9888.612694305448
total_rewards_min            9443.7645009913
Number of train steps total  1128000
Number of env steps total    3386000
Number of rollouts total     0
Train Time (s)               145.62832851102576
(Previous) Eval Time (s)     20.688161376863718
Sample Time (s)              6.406944481655955
Epoch Time (s)               172.72343436954543
Total Train Time (s)         48135.73978115199
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:15:54.789206 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #281 | Epoch Duration: 172.81012892723083
2020-01-12 21:15:54.789342 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7626944
Z variance train             0.0721272
KL Divergence                44.05497
KL Loss                      4.405497
QF Loss                      247.41498
VF Loss                      60.52787
Policy Loss                  -1328.0951
Q Predictions Mean           1325.3875
Q Predictions Std            1328.5789
Q Predictions Max            4449.159
Q Predictions Min            609.0485
V Predictions Mean           1325.9556
V Predictions Std            1325.0255
V Predictions Max            4451.638
V Predictions Min            615.00256
Log Pis Mean                 -0.055399675
Log Pis Std                  4.1445045
Log Pis Max                  16.589645
Log Pis Min                  -8.800672
Policy mu Mean               0.070227385
Policy mu Std                0.8859241
Policy mu Max                2.898926
Policy mu Min                -2.7161813
Policy log std Mean          -0.522006
Policy log std Std           0.27372086
Policy log std Max           -0.00424999
Policy log std Min           -2.5997868
Z mean eval                  1.7666109
Z variance eval              0.054257948
total_rewards                [8918.09642975 8928.5050782  8511.20000228 8834.3183625  8609.80192502
 8899.7851917  8719.71955833 8924.78093199 9159.5352537  8644.97001007]
total_rewards_mean           8815.071274354039
total_rewards_std            182.8167378462688
total_rewards_max            9159.535253697355
total_rewards_min            8511.200002278913
Number of train steps total  1132000
Number of env steps total    3398000
Number of rollouts total     0
Train Time (s)               147.3115260968916
(Previous) Eval Time (s)     20.93802823824808
Sample Time (s)              6.588734094519168
Epoch Time (s)               174.83828842965886
Total Train Time (s)         48310.65869535785
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:18:49.711083 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #282 | Epoch Duration: 174.92163515090942
2020-01-12 21:18:49.711249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7642615
Z variance train             0.054446053
KL Divergence                44.91707
KL Loss                      4.491707
QF Loss                      4088.074
VF Loss                      151.99626
Policy Loss                  -1346.1993
Q Predictions Mean           1345.9451
Q Predictions Std            1306.4268
Q Predictions Max            4420.859
Q Predictions Min            600.61816
V Predictions Mean           1351.687
V Predictions Std            1308.657
V Predictions Max            4405.1826
V Predictions Min            593.60815
Log Pis Mean                 0.119096756
Log Pis Std                  3.9447012
Log Pis Max                  15.071226
Log Pis Min                  -8.321809
Policy mu Mean               0.014877605
Policy mu Std                0.9146304
Policy mu Max                2.8977776
Policy mu Min                -2.7641842
Policy log std Mean          -0.52999157
Policy log std Std           0.29831666
Policy log std Max           0.23874247
Policy log std Min           -3.0155551
Z mean eval                  1.7678697
Z variance eval              0.06463901
total_rewards                [9475.96979313 9525.60448614 9901.90048161 9438.9898158  9589.21370132
 9525.85808696 9434.13544797 9657.89637641 9492.82555276 9717.1570933 ]
total_rewards_mean           9575.955083538893
total_rewards_std            139.24558844531285
total_rewards_max            9901.900481609688
total_rewards_min            9434.13544796952
Number of train steps total  1136000
Number of env steps total    3410000
Number of rollouts total     0
Train Time (s)               146.2355166929774
(Previous) Eval Time (s)     20.765631312970072
Sample Time (s)              5.563776773400605
Epoch Time (s)               172.56492477934808
Total Train Time (s)         48483.3029702208
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:21:42.357039 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #283 | Epoch Duration: 172.6456708908081
2020-01-12 21:21:42.357178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7714062
Z variance train             0.064855866
KL Divergence                44.592495
KL Loss                      4.4592495
QF Loss                      3598.9727
VF Loss                      96.67319
Policy Loss                  -1129.9913
Q Predictions Mean           1129.1694
Q Predictions Std            1115.6249
Q Predictions Max            4436.5986
Q Predictions Min            616.14453
V Predictions Mean           1125.8691
V Predictions Std            1109.8324
V Predictions Max            4412.624
V Predictions Min            603.9428
Log Pis Mean                 -0.5145312
Log Pis Std                  3.722901
Log Pis Max                  14.725639
Log Pis Min                  -7.173586
Policy mu Mean               0.05870053
Policy mu Std                0.8501726
Policy mu Max                3.0648584
Policy mu Min                -3.2112489
Policy log std Mean          -0.51183486
Policy log std Std           0.26213416
Policy log std Max           0.3311466
Policy log std Min           -2.7444596
Z mean eval                  1.7715778
Z variance eval              0.04864805
total_rewards                [9677.34949292 9866.20869133 9645.45035518 9786.88092109 9850.11077002
 9890.12219275 9676.35476697 9645.75229583 9558.11991468 9753.35003798]
total_rewards_mean           9734.969943874605
total_rewards_std            105.63671240066257
total_rewards_max            9890.122192751733
total_rewards_min            9558.119914677594
Number of train steps total  1140000
Number of env steps total    3422000
Number of rollouts total     0
Train Time (s)               147.28355960501358
(Previous) Eval Time (s)     20.831867817789316
Sample Time (s)              6.565144828520715
Epoch Time (s)               174.6805722513236
Total Train Time (s)         48658.06526054256
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:24:37.121258 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #284 | Epoch Duration: 174.76397323608398
2020-01-12 21:24:37.121390 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.77222
Z variance train             0.04864514
KL Divergence                45.65871
KL Loss                      4.5658712
QF Loss                      160.55875
VF Loss                      43.305023
Policy Loss                  -1109.3389
Q Predictions Mean           1107.4421
Q Predictions Std            1093.0526
Q Predictions Max            4326.0356
Q Predictions Min            606.48004
V Predictions Mean           1110.5592
V Predictions Std            1090.9778
V Predictions Max            4330.8545
V Predictions Min            611.93774
Log Pis Mean                 -0.30848944
Log Pis Std                  3.483263
Log Pis Max                  14.445216
Log Pis Min                  -6.25606
Policy mu Mean               0.032727662
Policy mu Std                0.8557903
Policy mu Max                2.699662
Policy mu Min                -2.9699984
Policy log std Mean          -0.50108755
Policy log std Std           0.2863527
Policy log std Max           0.40628546
Policy log std Min           -2.467825
Z mean eval                  1.765186
Z variance eval              0.048910514
total_rewards                [ 9976.36875733 10033.68669601 10025.64139399  9873.41960684
  6199.61143162  9983.23698398  9779.32648179  9612.06744385
  9324.76183595  9802.72775488]
total_rewards_mean           9461.084838622957
total_rewards_std            1106.8587737619903
total_rewards_max            10033.686696011615
total_rewards_min            6199.611431621401
Number of train steps total  1144000
Number of env steps total    3434000
Number of rollouts total     0
Train Time (s)               145.21202384121716
(Previous) Eval Time (s)     17.33502593776211
Sample Time (s)              6.528730419464409
Epoch Time (s)               169.07578019844368
Total Train Time (s)         48827.24020955432
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:27:26.303886 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #285 | Epoch Duration: 169.1823799610138
2020-01-12 21:27:26.304078 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7622572
Z variance train             0.048784588
KL Divergence                45.844143
KL Loss                      4.5844145
QF Loss                      112.27789
VF Loss                      223.67195
Policy Loss                  -1208.9602
Q Predictions Mean           1205.3232
Q Predictions Std            1186.396
Q Predictions Max            4348.881
Q Predictions Min            596.5533
V Predictions Mean           1198.977
V Predictions Std            1177.9926
V Predictions Max            4321.607
V Predictions Min            597.61865
Log Pis Mean                 -0.24998365
Log Pis Std                  3.778379
Log Pis Max                  18.347244
Log Pis Min                  -7.0559664
Policy mu Mean               0.046843484
Policy mu Std                0.87995225
Policy mu Max                3.374902
Policy mu Min                -2.6832795
Policy log std Mean          -0.52085525
Policy log std Std           0.28213495
Policy log std Max           0.10611987
Policy log std Min           -2.6348512
Z mean eval                  1.7837347
Z variance eval              0.04696402
total_rewards                [9559.91831182 9750.7852991  9708.60742148 9675.90519765 9786.23321677
 9603.21163466 9780.73639334 9833.3813574  9967.05721939 9949.6834471 ]
total_rewards_mean           9761.55194987138
total_rewards_std            126.39016459935154
total_rewards_max            9967.057219386854
total_rewards_min            9559.91831182262
Number of train steps total  1148000
Number of env steps total    3446000
Number of rollouts total     0
Train Time (s)               146.74777188804
(Previous) Eval Time (s)     17.25803456408903
Sample Time (s)              6.728774580638856
Epoch Time (s)               170.7345810327679
Total Train Time (s)         48998.062092122156
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:30:17.129713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #286 | Epoch Duration: 170.82545948028564
2020-01-12 21:30:17.129966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7828429
Z variance train             0.04706251
KL Divergence                47.168083
KL Loss                      4.7168083
QF Loss                      81.71923
VF Loss                      128.98077
Policy Loss                  -1289.9343
Q Predictions Mean           1288.4451
Q Predictions Std            1294.9152
Q Predictions Max            4432.225
Q Predictions Min            611.50275
V Predictions Mean           1292.9072
V Predictions Std            1296.7457
V Predictions Max            4414.4053
V Predictions Min            614.8895
Log Pis Mean                 -0.19826289
Log Pis Std                  3.9690928
Log Pis Max                  17.394192
Log Pis Min                  -6.6879907
Policy mu Mean               0.025852038
Policy mu Std                0.9019686
Policy mu Max                4.157739
Policy mu Min                -3.3095105
Policy log std Mean          -0.50180846
Policy log std Std           0.2830132
Policy log std Max           0.11397582
Policy log std Min           -2.6340885
Z mean eval                  1.7834523
Z variance eval              0.080649205
total_rewards                [10038.43382557  9834.84920853  9718.31687299  9445.30319938
  9636.91758422  9862.21348337  9740.05315127  9821.09091973
  9690.69839463  9895.70993014]
total_rewards_mean           9768.358656982131
total_rewards_std            153.67089487656648
total_rewards_max            10038.433825567823
total_rewards_min            9445.303199381227
Number of train steps total  1152000
Number of env steps total    3458000
Number of rollouts total     0
Train Time (s)               145.94240709301084
(Previous) Eval Time (s)     20.752828030847013
Sample Time (s)              6.5417518159374595
Epoch Time (s)               173.23698693979532
Total Train Time (s)         49171.381984169595
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:33:10.452389 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #287 | Epoch Duration: 173.32223844528198
2020-01-12 21:33:10.452584 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7859339
Z variance train             0.08038323
KL Divergence                46.030704
KL Loss                      4.6030707
QF Loss                      223.4495
VF Loss                      87.21871
Policy Loss                  -1275.6323
Q Predictions Mean           1273.5724
Q Predictions Std            1267.5414
Q Predictions Max            4402.998
Q Predictions Min            589.1068
V Predictions Mean           1277.4221
V Predictions Std            1266.1124
V Predictions Max            4413.3193
V Predictions Min            605.16956
Log Pis Mean                 -0.016786769
Log Pis Std                  4.2181835
Log Pis Max                  18.101841
Log Pis Min                  -7.477542
Policy mu Mean               0.07887435
Policy mu Std                0.8975007
Policy mu Max                3.2666254
Policy mu Min                -3.862086
Policy log std Mean          -0.52366203
Policy log std Std           0.30712003
Policy log std Max           0.24035239
Policy log std Min           -2.680142
Z mean eval                  1.7888119
Z variance eval              0.051549245
total_rewards                [9113.10130568 9768.55830449 3424.9632535  9965.59130853 9845.86637841
 9959.21691486 9944.5505399  9892.12633573 9555.14061522 9780.76193749]
total_rewards_mean           9124.98768937937
total_rewards_std            1915.778648345489
total_rewards_max            9965.591308526822
total_rewards_min            3424.9632535023907
Number of train steps total  1156000
Number of env steps total    3470000
Number of rollouts total     0
Train Time (s)               146.60124074714258
(Previous) Eval Time (s)     20.741818635258824
Sample Time (s)              6.524375143460929
Epoch Time (s)               173.86743452586234
Total Train Time (s)         49345.35535021592
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:36:04.425710 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #288 | Epoch Duration: 173.97299003601074
2020-01-12 21:36:04.425842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7889764
Z variance train             0.051645886
KL Divergence                44.99638
KL Loss                      4.499638
QF Loss                      172.45413
VF Loss                      51.29037
Policy Loss                  -1360.8175
Q Predictions Mean           1359.7686
Q Predictions Std            1313.137
Q Predictions Max            4403.669
Q Predictions Min            601.1051
V Predictions Mean           1361.5461
V Predictions Std            1308.9231
V Predictions Max            4394.091
V Predictions Min            614.53076
Log Pis Mean                 -0.07416597
Log Pis Std                  3.712958
Log Pis Max                  12.903284
Log Pis Min                  -7.147926
Policy mu Mean               -0.03956072
Policy mu Std                0.88219905
Policy mu Max                2.7929633
Policy mu Min                -2.8367774
Policy log std Mean          -0.52693516
Policy log std Std           0.29014197
Policy log std Max           -9.119511e-05
Policy log std Min           -2.562913
Z mean eval                  1.8058903
Z variance eval              0.049370836
total_rewards                [9629.14162397 9793.22729356 9739.793613   9710.58672933 9205.28387522
 9361.64200311 9607.8951544  9653.84108193 9194.61140406 4621.83717445]
total_rewards_mean           9051.785995302915
total_rewards_std            1490.8585892528051
total_rewards_max            9793.227293557875
total_rewards_min            4621.837174452128
Number of train steps total  1160000
Number of env steps total    3482000
Number of rollouts total     0
Train Time (s)               146.81170956976712
(Previous) Eval Time (s)     20.86482169525698
Sample Time (s)              6.461506320163608
Epoch Time (s)               174.1380375851877
Total Train Time (s)         49519.57362927217
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:38:58.646044 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #289 | Epoch Duration: 174.2201051712036
2020-01-12 21:38:58.646174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8089777
Z variance train             0.048916142
KL Divergence                44.82688
KL Loss                      4.4826884
QF Loss                      131.16002
VF Loss                      112.154854
Policy Loss                  -1315.4913
Q Predictions Mean           1311.9846
Q Predictions Std            1297.9377
Q Predictions Max            4377.295
Q Predictions Min            599.44147
V Predictions Mean           1309.0381
V Predictions Std            1294.9409
V Predictions Max            4367.3135
V Predictions Min            602.0426
Log Pis Mean                 -0.24224955
Log Pis Std                  3.664795
Log Pis Max                  14.304645
Log Pis Min                  -6.1282697
Policy mu Mean               0.07317506
Policy mu Std                0.89600873
Policy mu Max                3.405333
Policy mu Min                -3.5420778
Policy log std Mean          -0.5114183
Policy log std Std           0.2852239
Policy log std Max           0.4066491
Policy log std Min           -2.4759617
Z mean eval                  1.7758442
Z variance eval              0.0701207
total_rewards                [9409.47094207 9457.98498487 9761.30274891 9364.4955835  9189.94982685
 9620.08599778 9564.04062573 9881.39781033 9683.68436247 9212.94416772]
total_rewards_mean           9514.535705024306
total_rewards_std            216.96698416149184
total_rewards_max            9881.397810329128
total_rewards_min            9189.949826850107
Number of train steps total  1164000
Number of env steps total    3494000
Number of rollouts total     0
Train Time (s)               145.8233518130146
(Previous) Eval Time (s)     20.80260653188452
Sample Time (s)              6.556597809307277
Epoch Time (s)               173.1825561542064
Total Train Time (s)         49692.83144956082
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:41:51.905988 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #290 | Epoch Duration: 173.25971865653992
2020-01-12 21:41:51.906117 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7741699
Z variance train             0.07043089
KL Divergence                45.463696
KL Loss                      4.5463696
QF Loss                      3643.0894
VF Loss                      49.178093
Policy Loss                  -1248.7518
Q Predictions Mean           1246.2487
Q Predictions Std            1227.3931
Q Predictions Max            4412.7046
Q Predictions Min            600.29584
V Predictions Mean           1250.2203
V Predictions Std            1224.3274
V Predictions Max            4416.487
V Predictions Min            616.2984
Log Pis Mean                 -0.37017053
Log Pis Std                  3.7967205
Log Pis Max                  15.96657
Log Pis Min                  -6.444874
Policy mu Mean               0.017505998
Policy mu Std                0.8597905
Policy mu Max                2.8887997
Policy mu Min                -3.0238023
Policy log std Mean          -0.49700746
Policy log std Std           0.279869
Policy log std Max           0.013768375
Policy log std Min           -2.4290588
Z mean eval                  1.7743847
Z variance eval              0.10184449
total_rewards                [9694.66507765 9771.46626768 9531.12292654 9677.21968224 9484.6379054
 9712.27725225 9542.31994499 9869.49695908 9641.45188215 9866.97738403]
total_rewards_mean           9679.163528200792
total_rewards_std            126.9904809578937
total_rewards_max            9869.496959077384
total_rewards_min            9484.637905398744
Number of train steps total  1168000
Number of env steps total    3506000
Number of rollouts total     0
Train Time (s)               146.10416641365737
(Previous) Eval Time (s)     21.216266134288162
Sample Time (s)              6.597804294433445
Epoch Time (s)               173.91823684237897
Total Train Time (s)         49866.83250547387
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:44:45.909126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #291 | Epoch Duration: 174.00291347503662
2020-01-12 21:44:45.909269 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #291 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7722896
Z variance train             0.101696454
KL Divergence                44.69092
KL Loss                      4.4690924
QF Loss                      3220.54
VF Loss                      65.32998
Policy Loss                  -1183.2407
Q Predictions Mean           1181.7894
Q Predictions Std            1179.8167
Q Predictions Max            4316.385
Q Predictions Min            599.09845
V Predictions Mean           1189.264
V Predictions Std            1182.0874
V Predictions Max            4339.2583
V Predictions Min            609.9986
Log Pis Mean                 -0.6406333
Log Pis Std                  3.5307643
Log Pis Max                  13.195324
Log Pis Min                  -8.9440365
Policy mu Mean               0.024223946
Policy mu Std                0.839058
Policy mu Max                2.7931514
Policy mu Min                -2.7439356
Policy log std Mean          -0.49955297
Policy log std Std           0.2681348
Policy log std Max           0.007417619
Policy log std Min           -2.5651085
Z mean eval                  1.7606472
Z variance eval              0.07049555
total_rewards                [ 9554.58440381  9665.94559024  9790.56374431  9886.40581116
  9730.99293983  9792.32737444 10087.52878071  9816.38340068
  9931.31944268  9877.94154911]
total_rewards_mean           9813.399303698334
total_rewards_std            139.65698462704322
total_rewards_max            10087.528780712108
total_rewards_min            9554.584403813999
Number of train steps total  1172000
Number of env steps total    3518000
Number of rollouts total     0
Train Time (s)               148.37834131438285
(Previous) Eval Time (s)     19.66342899063602
Sample Time (s)              6.466103165410459
Epoch Time (s)               174.50787347042933
Total Train Time (s)         50041.42384757474
Epoch                        292
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:47:40.505499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #292 | Epoch Duration: 174.59609937667847
2020-01-12 21:47:40.505694 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7573166
Z variance train             0.07048865
KL Divergence                45.945652
KL Loss                      4.5945654
QF Loss                      212.19734
VF Loss                      85.1691
Policy Loss                  -1316.2229
Q Predictions Mean           1313.4551
Q Predictions Std            1317.6665
Q Predictions Max            4366.346
Q Predictions Min            606.2456
V Predictions Mean           1321.6592
V Predictions Std            1321.1127
V Predictions Max            4387.2334
V Predictions Min            607.0357
Log Pis Mean                 -0.28230304
Log Pis Std                  3.7044344
Log Pis Max                  13.419886
Log Pis Min                  -6.5579886
Policy mu Mean               0.08874122
Policy mu Std                0.8476482
Policy mu Max                2.7775476
Policy mu Min                -2.4866803
Policy log std Mean          -0.51742643
Policy log std Std           0.30340925
Policy log std Max           0.1490221
Policy log std Min           -2.6783462
Z mean eval                  1.7835901
Z variance eval              0.13394883
total_rewards                [ 9786.35484164  9785.96812964  9777.39709259  9816.59265174
  9969.45230246 10150.46247233 10334.6011771   9936.16617803
  9761.73991914 10092.1154927 ]
total_rewards_mean           9941.085025737515
total_rewards_std            185.68586783888816
total_rewards_max            10334.601177101635
total_rewards_min            9761.739919144442
Number of train steps total  1176000
Number of env steps total    3530000
Number of rollouts total     0
Train Time (s)               146.2617495143786
(Previous) Eval Time (s)     20.898657848127186
Sample Time (s)              6.493871899787337
Epoch Time (s)               173.65427926229313
Total Train Time (s)         50215.16054207785
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:50:34.243481 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #293 | Epoch Duration: 173.73765325546265
2020-01-12 21:50:34.243617 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7843113
Z variance train             0.13446955
KL Divergence                44.747395
KL Loss                      4.4747396
QF Loss                      83.30455
VF Loss                      36.7655
Policy Loss                  -1234.2246
Q Predictions Mean           1230.7877
Q Predictions Std            1210.2255
Q Predictions Max            4471.8696
Q Predictions Min            623.23755
V Predictions Mean           1235.4695
V Predictions Std            1211.5885
V Predictions Max            4484.7383
V Predictions Min            630.5162
Log Pis Mean                 -0.6223146
Log Pis Std                  3.4817421
Log Pis Max                  12.162188
Log Pis Min                  -8.301773
Policy mu Mean               0.03249288
Policy mu Std                0.83581555
Policy mu Max                2.498312
Policy mu Min                -2.7058034
Policy log std Mean          -0.5012674
Policy log std Std           0.2842324
Policy log std Max           0.22878253
Policy log std Min           -2.6395016
Z mean eval                  1.7871363
Z variance eval              0.065643474
total_rewards                [9711.39282932 9714.65557264 9891.68954528 9494.70129223 9741.4650806
 9718.0149579  9765.81474027 9697.64697162 9928.85709072 9754.50471153]
total_rewards_mean           9741.874279211408
total_rewards_std            111.09896979963305
total_rewards_max            9928.857090715148
total_rewards_min            9494.701292228763
Number of train steps total  1180000
Number of env steps total    3542000
Number of rollouts total     0
Train Time (s)               147.8722472260706
(Previous) Eval Time (s)     20.883575363084674
Sample Time (s)              6.362222519237548
Epoch Time (s)               175.11804510839283
Total Train Time (s)         50390.36641819356
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:53:29.451227 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #294 | Epoch Duration: 175.20751094818115
2020-01-12 21:53:29.451362 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #294 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.788945
Z variance train             0.065576024
KL Divergence                45.146732
KL Loss                      4.514673
QF Loss                      108.29137
VF Loss                      51.06169
Policy Loss                  -1107.1108
Q Predictions Mean           1106.1996
Q Predictions Std            1113.5134
Q Predictions Max            4398.0854
Q Predictions Min            614.6111
V Predictions Mean           1103.0935
V Predictions Std            1110.1309
V Predictions Max            4382.3247
V Predictions Min            615.15515
Log Pis Mean                 -0.8189488
Log Pis Std                  3.685084
Log Pis Max                  14.407267
Log Pis Min                  -8.967124
Policy mu Mean               0.08752885
Policy mu Std                0.82651645
Policy mu Max                3.8015578
Policy mu Min                -3.3320742
Policy log std Mean          -0.4918108
Policy log std Std           0.28174993
Policy log std Max           0.022119045
Policy log std Min           -2.4166465
Z mean eval                  1.7972469
Z variance eval              0.06322133
total_rewards                [9221.39165948 9437.65608062 9399.93686065 9377.85099416 9462.402452
 9432.97173694 9132.94382333 9099.79385166 9114.69673406 9401.45719687]
total_rewards_mean           9308.11013897778
total_rewards_std            140.4265103178095
total_rewards_max            9462.402451998738
total_rewards_min            9099.793851658735
Number of train steps total  1184000
Number of env steps total    3554000
Number of rollouts total     0
Train Time (s)               146.6431085160002
(Previous) Eval Time (s)     20.5017858450301
Sample Time (s)              6.431200892664492
Epoch Time (s)               173.5760952536948
Total Train Time (s)         50564.11758754775
Epoch                        295
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:56:23.204506 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #295 | Epoch Duration: 173.75304746627808
2020-01-12 21:56:23.204642 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8022372
Z variance train             0.06285991
KL Divergence                44.913536
KL Loss                      4.4913535
QF Loss                      147.71423
VF Loss                      57.36821
Policy Loss                  -1329.5085
Q Predictions Mean           1326.4216
Q Predictions Std            1307.8597
Q Predictions Max            4489.7817
Q Predictions Min            621.85944
V Predictions Mean           1326.5116
V Predictions Std            1308.5009
V Predictions Max            4485.5186
V Predictions Min            606.2001
Log Pis Mean                 -0.24486737
Log Pis Std                  4.2440224
Log Pis Max                  21.710302
Log Pis Min                  -7.3248873
Policy mu Mean               0.06422213
Policy mu Std                0.90940714
Policy mu Max                3.7979743
Policy mu Min                -3.21097
Policy log std Mean          -0.49762344
Policy log std Std           0.28703263
Policy log std Max           0.23438823
Policy log std Min           -2.8057988
Z mean eval                  1.8225048
Z variance eval              0.08786689
total_rewards                [9070.95118039 8594.54958323 8290.01829468 7777.7018734  7861.37185387
 8513.73749539 8087.50512516 7832.12661752 8168.11673373 7686.31779673]
total_rewards_mean           8188.2396554111165
total_rewards_std            415.3616959571746
total_rewards_max            9070.951180386957
total_rewards_min            7686.317796730912
Number of train steps total  1188000
Number of env steps total    3566000
Number of rollouts total     0
Train Time (s)               146.73075282294303
(Previous) Eval Time (s)     20.711064288858324
Sample Time (s)              6.4352643811143935
Epoch Time (s)               173.87708149291575
Total Train Time (s)         50738.07854477409
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 21:59:17.167475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #296 | Epoch Duration: 173.96273517608643
2020-01-12 21:59:17.167610 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8256531
Z variance train             0.08727001
KL Divergence                44.771996
KL Loss                      4.4771996
QF Loss                      245.21277
VF Loss                      41.50163
Policy Loss                  -1157.0105
Q Predictions Mean           1155.0613
Q Predictions Std            1143.9895
Q Predictions Max            4397.577
Q Predictions Min            620.24414
V Predictions Mean           1154.8293
V Predictions Std            1141.114
V Predictions Max            4369.067
V Predictions Min            624.5424
Log Pis Mean                 -0.87420774
Log Pis Std                  3.2204695
Log Pis Max                  12.514687
Log Pis Min                  -5.734761
Policy mu Mean               0.061504263
Policy mu Std                0.8073748
Policy mu Max                2.9221423
Policy mu Min                -2.8248937
Policy log std Mean          -0.48920342
Policy log std Std           0.26607257
Policy log std Max           0.17148864
Policy log std Min           -2.3700798
Z mean eval                  1.776922
Z variance eval              0.06602446
total_rewards                [9600.82018182 9947.89001377 9599.93637229 9881.22717991 9854.74122976
 4146.41931455 9903.87656295 9837.98179263 9811.69236048 9933.41037082]
total_rewards_mean           9251.799537898942
total_rewards_std            1705.8449244836427
total_rewards_max            9947.890013767907
total_rewards_min            4146.419314554901
Number of train steps total  1192000
Number of env steps total    3578000
Number of rollouts total     0
Train Time (s)               146.6342815309763
(Previous) Eval Time (s)     20.826059431303293
Sample Time (s)              6.3957953420467675
Epoch Time (s)               173.85613630432636
Total Train Time (s)         50912.01461682981
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:02:11.105282 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #297 | Epoch Duration: 173.93757677078247
2020-01-12 22:02:11.105412 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7753452
Z variance train             0.065744184
KL Divergence                44.130074
KL Loss                      4.4130073
QF Loss                      307.713
VF Loss                      34.060604
Policy Loss                  -1162.9637
Q Predictions Mean           1161.2026
Q Predictions Std            1129.9381
Q Predictions Max            4482.8896
Q Predictions Min            620.6795
V Predictions Mean           1165.2446
V Predictions Std            1128.4967
V Predictions Max            4477.49
V Predictions Min            627.9984
Log Pis Mean                 -0.37792534
Log Pis Std                  3.6560495
Log Pis Max                  20.710644
Log Pis Min                  -6.492455
Policy mu Mean               0.10623851
Policy mu Std                0.853081
Policy mu Max                3.331889
Policy mu Min                -2.9735067
Policy log std Mean          -0.49464807
Policy log std Std           0.26936847
Policy log std Max           0.41083807
Policy log std Min           -2.5652418
Z mean eval                  1.7654731
Z variance eval              0.044286896
total_rewards                [ 9384.25880016  9753.5399584   9847.49533552 10007.83528499
 10024.44678988  9809.22567345  9945.52184422  9803.53835929
  9840.68375081  9993.82449937]
total_rewards_mean           9841.03702960959
total_rewards_std            177.3369451359737
total_rewards_max            10024.446789877977
total_rewards_min            9384.258800163625
Number of train steps total  1196000
Number of env steps total    3590000
Number of rollouts total     0
Train Time (s)               147.7659698203206
(Previous) Eval Time (s)     17.441839011851698
Sample Time (s)              6.526860641781241
Epoch Time (s)               171.73466947395355
Total Train Time (s)         51083.82687009359
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:05:02.920889 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #298 | Epoch Duration: 171.81536436080933
2020-01-12 22:05:02.921065 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7662363
Z variance train             0.04419474
KL Divergence                45.45102
KL Loss                      4.545102
QF Loss                      131.35718
VF Loss                      96.74388
Policy Loss                  -1403.6234
Q Predictions Mean           1397.6633
Q Predictions Std            1336.9595
Q Predictions Max            4412.6494
Q Predictions Min            619.3424
V Predictions Mean           1398.6206
V Predictions Std            1337.1694
V Predictions Max            4419.769
V Predictions Min            624.2218
Log Pis Mean                 -0.14102449
Log Pis Std                  3.6180964
Log Pis Max                  13.570574
Log Pis Min                  -7.01133
Policy mu Mean               0.06840125
Policy mu Std                0.86914355
Policy mu Max                2.9084024
Policy mu Min                -2.4072957
Policy log std Mean          -0.53438693
Policy log std Std           0.31011233
Policy log std Max           -0.05377698
Policy log std Min           -2.9317627
Z mean eval                  1.7752209
Z variance eval              0.074220166
total_rewards                [9456.19410912 9197.45600563 9598.99930434 6147.55755811 9555.02273058
 9367.18184026 9748.29580897 9017.31043123 9500.89703187 9656.47116388]
total_rewards_mean           9124.538598398864
total_rewards_std            1013.5187514260117
total_rewards_max            9748.295808968158
total_rewards_min            6147.557558106802
Number of train steps total  1200000
Number of env steps total    3602000
Number of rollouts total     0
Train Time (s)               145.35767476214096
(Previous) Eval Time (s)     20.77295720623806
Sample Time (s)              6.585640623234212
Epoch Time (s)               172.71627259161323
Total Train Time (s)         51256.62433876749
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:07:55.720166 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #299 | Epoch Duration: 172.798969745636
2020-01-12 22:07:55.720308 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7747421
Z variance train             0.07423786
KL Divergence                45.09706
KL Loss                      4.509706
QF Loss                      3782.5654
VF Loss                      37.434273
Policy Loss                  -1223.245
Q Predictions Mean           1221.0337
Q Predictions Std            1199.2335
Q Predictions Max            4395.873
Q Predictions Min            627.30524
V Predictions Mean           1224.8499
V Predictions Std            1197.0975
V Predictions Max            4389.018
V Predictions Min            621.3709
Log Pis Mean                 -0.43736666
Log Pis Std                  3.8200774
Log Pis Max                  16.496737
Log Pis Min                  -9.028261
Policy mu Mean               0.08393634
Policy mu Std                0.8633996
Policy mu Max                3.2865548
Policy mu Min                -2.7072902
Policy log std Mean          -0.48977718
Policy log std Std           0.2749999
Policy log std Max           0.23198771
Policy log std Min           -2.5429761
Z mean eval                  1.7961047
Z variance eval              0.07271739
total_rewards                [9231.6628517  9760.06165774 9729.40477773 9752.67934466 9766.16304675
 9397.42942754 9620.16833119 9690.16395916 9669.11655925 9570.04129935]
total_rewards_mean           9618.689125506615
total_rewards_std            167.5445171626156
total_rewards_max            9766.163046746362
total_rewards_min            9231.662851698567
Number of train steps total  1204000
Number of env steps total    3614000
Number of rollouts total     0
Train Time (s)               146.76977785630152
(Previous) Eval Time (s)     20.73562667891383
Sample Time (s)              8.129041645675898
Epoch Time (s)               175.63444618089125
Total Train Time (s)         51432.343228037935
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:10:51.441893 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #300 | Epoch Duration: 175.72148418426514
2020-01-12 22:10:51.442030 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #300 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7955515
Z variance train             0.07270336
KL Divergence                43.782867
KL Loss                      4.378287
QF Loss                      332.877
VF Loss                      148.72339
Policy Loss                  -1280.014
Q Predictions Mean           1278.2876
Q Predictions Std            1267.7418
Q Predictions Max            4482.2227
Q Predictions Min            640.1394
V Predictions Mean           1280.8284
V Predictions Std            1271.0627
V Predictions Max            4521.483
V Predictions Min            634.00073
Log Pis Mean                 -0.25972697
Log Pis Std                  3.56801
Log Pis Max                  14.651103
Log Pis Min                  -6.765519
Policy mu Mean               -0.021065215
Policy mu Std                0.8717477
Policy mu Max                3.1865072
Policy mu Min                -2.6083379
Policy log std Mean          -0.5109462
Policy log std Std           0.2921282
Policy log std Max           0.12725812
Policy log std Min           -2.390552
Z mean eval                  1.7961328
Z variance eval              0.069618575
total_rewards                [ 9802.0151278   9699.44526854  9847.73951123 10020.70913508
  9838.01395219  9831.83875143  9984.58770199  9722.35988993
  9974.62458473  9733.63245409]
total_rewards_mean           9845.496637701484
total_rewards_std            108.56575306784231
total_rewards_max            10020.709135082709
total_rewards_min            9699.445268539595
Number of train steps total  1208000
Number of env steps total    3626000
Number of rollouts total     0
Train Time (s)               147.13537891115993
(Previous) Eval Time (s)     20.9792550932616
Sample Time (s)              6.3891238565556705
Epoch Time (s)               174.5037578609772
Total Train Time (s)         51606.979694562964
Epoch                        301
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:13:46.087242 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #301 | Epoch Duration: 174.6450638771057
2020-01-12 22:13:46.087574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #301 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7977053
Z variance train             0.06952851
KL Divergence                44.68281
KL Loss                      4.4682813
QF Loss                      96.74396
VF Loss                      74.89988
Policy Loss                  -1304.4158
Q Predictions Mean           1300.3242
Q Predictions Std            1271.2744
Q Predictions Max            4392.5957
Q Predictions Min            621.89844
V Predictions Mean           1299.4531
V Predictions Std            1267.7158
V Predictions Max            4386.294
V Predictions Min            623.01434
Log Pis Mean                 -0.03864701
Log Pis Std                  3.8446121
Log Pis Max                  17.71598
Log Pis Min                  -6.0567646
Policy mu Mean               0.01314159
Policy mu Std                0.9226242
Policy mu Max                2.8907664
Policy mu Min                -3.2848103
Policy log std Mean          -0.4882224
Policy log std Std           0.2770315
Policy log std Max           0.26449448
Policy log std Min           -2.7558799
Z mean eval                  1.7999731
Z variance eval              0.07085535
total_rewards                [ 9545.90370966 10054.27444372  9735.02181911  9842.6018181
  9762.99802044  9774.73040487  9816.34222279  9701.40066011
 10117.18525593  9936.78480857]
total_rewards_mean           9828.724316330126
total_rewards_std            160.7233027116543
total_rewards_max            10117.18525592806
total_rewards_min            9545.903709655604
Number of train steps total  1212000
Number of env steps total    3638000
Number of rollouts total     0
Train Time (s)               148.6941445628181
(Previous) Eval Time (s)     20.83903538901359
Sample Time (s)              6.476941705681384
Epoch Time (s)               176.01012165751308
Total Train Time (s)         51783.152066549286
Epoch                        302
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:16:42.265884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #302 | Epoch Duration: 176.17805218696594
2020-01-12 22:16:42.266148 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7997215
Z variance train             0.07057479
KL Divergence                44.20946
KL Loss                      4.420946
QF Loss                      202.38177
VF Loss                      72.1368
Policy Loss                  -1174.714
Q Predictions Mean           1166.4226
Q Predictions Std            1120.7981
Q Predictions Max            4449.744
Q Predictions Min            626.19763
V Predictions Mean           1171.1782
V Predictions Std            1122.1384
V Predictions Max            4445.9766
V Predictions Min            627.487
Log Pis Mean                 -0.5434498
Log Pis Std                  4.022326
Log Pis Max                  18.898846
Log Pis Min                  -6.964944
Policy mu Mean               -0.0013154013
Policy mu Std                0.8760498
Policy mu Max                3.4486058
Policy mu Min                -3.5043552
Policy log std Mean          -0.48827
Policy log std Std           0.2763987
Policy log std Max           0.11077744
Policy log std Min           -2.9110389
Z mean eval                  1.7733183
Z variance eval              0.05421058
total_rewards                [ 9589.92368579 10085.72682977 10010.06086752  9926.49256446
  9813.28564654 10132.43847789  9844.61800543  9923.97897051
  9935.02809259  9916.08133771]
total_rewards_mean           9917.763447822004
total_rewards_std            143.86673827494698
total_rewards_max            10132.438477890926
total_rewards_min            9589.923685790814
Number of train steps total  1216000
Number of env steps total    3650000
Number of rollouts total     0
Train Time (s)               146.55261725513265
(Previous) Eval Time (s)     20.812600024975836
Sample Time (s)              6.391945228911936
Epoch Time (s)               173.75716250902042
Total Train Time (s)         51956.99492629757
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:19:36.109118 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #303 | Epoch Duration: 173.84278774261475
2020-01-12 22:19:36.109250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7736838
Z variance train             0.05427807
KL Divergence                44.290207
KL Loss                      4.429021
QF Loss                      148.28806
VF Loss                      40.375397
Policy Loss                  -1291.0541
Q Predictions Mean           1289.9509
Q Predictions Std            1265.8804
Q Predictions Max            4539.987
Q Predictions Min            625.1691
V Predictions Mean           1291.0734
V Predictions Std            1265.9443
V Predictions Max            4540.906
V Predictions Min            620.0627
Log Pis Mean                 -0.3320163
Log Pis Std                  3.5391076
Log Pis Max                  12.459843
Log Pis Min                  -5.988287
Policy mu Mean               0.00015985407
Policy mu Std                0.86376137
Policy mu Max                2.874387
Policy mu Min                -2.7309039
Policy log std Mean          -0.4864192
Policy log std Std           0.27105284
Policy log std Max           0.18617451
Policy log std Min           -2.270648
Z mean eval                  1.765756
Z variance eval              0.08573645
total_rewards                [9526.98556361 9281.7873082  9793.15958492 9674.86047983 9387.54424556
 9665.21957479 9579.99852525 9464.85367618 9657.97899156 8952.43231187]
total_rewards_mean           9498.482026176764
total_rewards_std            231.7773186228015
total_rewards_max            9793.159584920659
total_rewards_min            8952.432311868688
Number of train steps total  1220000
Number of env steps total    3662000
Number of rollouts total     0
Train Time (s)               148.6317911730148
(Previous) Eval Time (s)     17.584219795186073
Sample Time (s)              6.461607371922582
Epoch Time (s)               172.67761834012344
Total Train Time (s)         52129.75681212917
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:22:28.874214 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #304 | Epoch Duration: 172.76485109329224
2020-01-12 22:22:28.874391 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7672135
Z variance train             0.085728295
KL Divergence                42.719284
KL Loss                      4.2719283
QF Loss                      160.20615
VF Loss                      227.56012
Policy Loss                  -1288.1722
Q Predictions Mean           1284.4457
Q Predictions Std            1278.941
Q Predictions Max            4516.4644
Q Predictions Min            624.93274
V Predictions Mean           1277.1361
V Predictions Std            1268.9524
V Predictions Max            4475.447
V Predictions Min            619.6817
Log Pis Mean                 -0.40369207
Log Pis Std                  4.228481
Log Pis Max                  20.997288
Log Pis Min                  -9.429037
Policy mu Mean               0.0030029186
Policy mu Std                0.88400215
Policy mu Max                3.2972324
Policy mu Min                -3.2785535
Policy log std Mean          -0.49148598
Policy log std Std           0.2947284
Policy log std Max           0.037620485
Policy log std Min           -2.578416
Z mean eval                  1.7990776
Z variance eval              0.06866924
total_rewards                [9325.963591   9639.38866346 6745.52607816 9762.14836396 9771.25947909
 9706.86257459 9754.64025295 9406.77695136 9572.01764549 9561.93045086]
total_rewards_mean           9324.651405093642
total_rewards_std            871.609021958248
total_rewards_max            9771.259479094118
total_rewards_min            6745.52607816466
Number of train steps total  1224000
Number of env steps total    3674000
Number of rollouts total     0
Train Time (s)               146.85900598904118
(Previous) Eval Time (s)     18.307155821938068
Sample Time (s)              6.697442340198904
Epoch Time (s)               171.86360415117815
Total Train Time (s)         52301.79360276507
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:25:20.917739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #305 | Epoch Duration: 172.04320073127747
2020-01-12 22:25:20.917941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7985992
Z variance train             0.06862789
KL Divergence                44.439327
KL Loss                      4.443933
QF Loss                      149.81592
VF Loss                      61.45254
Policy Loss                  -1275.624
Q Predictions Mean           1274.5049
Q Predictions Std            1242.9208
Q Predictions Max            4466.6357
Q Predictions Min            627.2416
V Predictions Mean           1276.2631
V Predictions Std            1242.7554
V Predictions Max            4467.7573
V Predictions Min            631.0571
Log Pis Mean                 -0.53933144
Log Pis Std                  3.6731443
Log Pis Max                  12.492868
Log Pis Min                  -7.893554
Policy mu Mean               0.016283752
Policy mu Std                0.8467416
Policy mu Max                2.8555837
Policy mu Min                -2.816742
Policy log std Mean          -0.49351645
Policy log std Std           0.28944808
Policy log std Max           0.09078914
Policy log std Min           -2.6196077
Z mean eval                  1.7916797
Z variance eval              0.082396366
total_rewards                [8962.23615838 9242.78010083 3491.92814336 9329.1191469  9318.22380099
 8938.8725333  9250.1670199  9105.814003   9324.23574955 9408.35786359]
total_rewards_mean           8637.173451979668
total_rewards_std            1721.6788404980134
total_rewards_max            9408.357863591304
total_rewards_min            3491.9281433610345
Number of train steps total  1228000
Number of env steps total    3686000
Number of rollouts total     0
Train Time (s)               146.0020103752613
(Previous) Eval Time (s)     20.445565198082477
Sample Time (s)              6.563765593338758
Epoch Time (s)               173.01134116668254
Total Train Time (s)         52474.89129066048
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:28:14.023278 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #306 | Epoch Duration: 173.10515308380127
2020-01-12 22:28:14.023587 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7935026
Z variance train             0.08210872
KL Divergence                45.301624
KL Loss                      4.5301623
QF Loss                      126.600945
VF Loss                      109.258865
Policy Loss                  -1360.3292
Q Predictions Mean           1359.252
Q Predictions Std            1331.8873
Q Predictions Max            4483.1133
Q Predictions Min            632.4388
V Predictions Mean           1355.7297
V Predictions Std            1321.9446
V Predictions Max            4447.3325
V Predictions Min            631.5299
Log Pis Mean                 -0.22178736
Log Pis Std                  4.007602
Log Pis Max                  13.244955
Log Pis Min                  -7.4860396
Policy mu Mean               0.044446904
Policy mu Std                0.87862676
Policy mu Max                2.9192147
Policy mu Min                -2.5026824
Policy log std Mean          -0.50762725
Policy log std Std           0.29433048
Policy log std Max           0.2171309
Policy log std Min           -2.6851153
Z mean eval                  1.8043737
Z variance eval              0.09714695
total_rewards                [9555.79185273 9395.63616525 9424.58607337 9617.6100549  9474.72424989
 9710.55395606 9302.84174249 9396.79067392 9348.02786456 9344.90489961]
total_rewards_mean           9457.146753277662
total_rewards_std            125.22192866942453
total_rewards_max            9710.553956058711
total_rewards_min            9302.841742487195
Number of train steps total  1232000
Number of env steps total    3698000
Number of rollouts total     0
Train Time (s)               144.75072347419336
(Previous) Eval Time (s)     21.07744924305007
Sample Time (s)              6.600636965595186
Epoch Time (s)               172.42880968283862
Total Train Time (s)         52647.415347011294
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:31:06.550259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #307 | Epoch Duration: 172.52644515037537
2020-01-12 22:31:06.550482 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #307 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8041741
Z variance train             0.09759934
KL Divergence                44.115425
KL Loss                      4.4115424
QF Loss                      137.72667
VF Loss                      230.26747
Policy Loss                  -1259.7378
Q Predictions Mean           1259.7448
Q Predictions Std            1228.326
Q Predictions Max            4476.597
Q Predictions Min            619.0707
V Predictions Mean           1268.7869
V Predictions Std            1233.8253
V Predictions Max            4503.5537
V Predictions Min            627.6394
Log Pis Mean                 -0.3053261
Log Pis Std                  4.115492
Log Pis Max                  23.373491
Log Pis Min                  -7.684518
Policy mu Mean               0.077526174
Policy mu Std                0.90920836
Policy mu Max                3.1731331
Policy mu Min                -4.452347
Policy log std Mean          -0.4875659
Policy log std Std           0.26642326
Policy log std Max           -0.029409587
Policy log std Min           -2.582425
Z mean eval                  1.7777439
Z variance eval              0.07455977
total_rewards                [ 9773.70786804  9611.25395373  9964.7744772   9886.11167285
  9817.17194562  9686.74196867  9882.3952756   9603.61940974
 10065.42856989  9967.31649711]
total_rewards_mean           9825.852163844049
total_rewards_std            148.70190380076596
total_rewards_max            10065.428569892583
total_rewards_min            9603.619409737952
Number of train steps total  1236000
Number of env steps total    3710000
Number of rollouts total     0
Train Time (s)               145.16040387609974
(Previous) Eval Time (s)     17.534940616227686
Sample Time (s)              6.563863026443869
Epoch Time (s)               169.2592075187713
Total Train Time (s)         52816.75679601403
Epoch                        308
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:33:55.897369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #308 | Epoch Duration: 169.34673309326172
2020-01-12 22:33:55.897535 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #308 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7768011
Z variance train             0.074453175
KL Divergence                44.801502
KL Loss                      4.48015
QF Loss                      290.2929
VF Loss                      61.198494
Policy Loss                  -1148.8304
Q Predictions Mean           1142.4834
Q Predictions Std            1108.9772
Q Predictions Max            4462.8354
Q Predictions Min            617.6345
V Predictions Mean           1153.1287
V Predictions Std            1110.8193
V Predictions Max            4466.1387
V Predictions Min            627.57837
Log Pis Mean                 -0.4166856
Log Pis Std                  3.6811256
Log Pis Max                  14.333782
Log Pis Min                  -7.595539
Policy mu Mean               0.04888575
Policy mu Std                0.832394
Policy mu Max                2.7515152
Policy mu Min                -3.2707703
Policy log std Mean          -0.51266605
Policy log std Std           0.29559457
Policy log std Max           0.050203264
Policy log std Min           -2.5651765
Z mean eval                  1.776811
Z variance eval              0.08908029
total_rewards                [ 9425.96184676  9835.67890575 10091.90724705  9767.092064
  9807.49120338  9977.75562138  9614.5010228   9787.30537355
  9680.1883365   9832.19003332]
total_rewards_mean           9782.007165449737
total_rewards_std            174.88513735424436
total_rewards_max            10091.907247052937
total_rewards_min            9425.961846757484
Number of train steps total  1240000
Number of env steps total    3722000
Number of rollouts total     0
Train Time (s)               147.19403685769066
(Previous) Eval Time (s)     20.675275477115065
Sample Time (s)              6.410454101394862
Epoch Time (s)               174.2797664362006
Total Train Time (s)         52991.12078478327
Epoch                        309
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:36:50.264561 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #309 | Epoch Duration: 174.3669068813324
2020-01-12 22:36:50.264693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7767203
Z variance train             0.08894973
KL Divergence                43.74858
KL Loss                      4.3748584
QF Loss                      322.93994
VF Loss                      30.20936
Policy Loss                  -1160.7787
Q Predictions Mean           1156.9486
Q Predictions Std            1165.4595
Q Predictions Max            4451.756
Q Predictions Min            613.729
V Predictions Mean           1158.9637
V Predictions Std            1166.575
V Predictions Max            4444.6987
V Predictions Min            619.3392
Log Pis Mean                 -0.79207695
Log Pis Std                  3.5484397
Log Pis Max                  15.273776
Log Pis Min                  -7.2679873
Policy mu Mean               0.04810205
Policy mu Std                0.8409586
Policy mu Max                2.934445
Policy mu Min                -3.3897822
Policy log std Mean          -0.50179464
Policy log std Std           0.27869108
Policy log std Max           0.09431815
Policy log std Min           -2.494413
Z mean eval                  1.80108
Z variance eval              0.07824404
total_rewards                [10011.95211126  9943.93387989 10097.50991435 10029.56487999
  9979.15105968  9992.76087659  9742.30399858  9720.52169664
  9694.31935735  2978.36951377]
total_rewards_mean           9219.038728809957
total_rewards_std            2084.6198989802697
total_rewards_max            10097.509914351767
total_rewards_min            2978.3695137661334
Number of train steps total  1244000
Number of env steps total    3734000
Number of rollouts total     0
Train Time (s)               145.65282604005188
(Previous) Eval Time (s)     20.65744609804824
Sample Time (s)              6.576770623214543
Epoch Time (s)               172.88704276131466
Total Train Time (s)         53164.091541513335
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:39:43.237107 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #310 | Epoch Duration: 172.97231674194336
2020-01-12 22:39:43.237243 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8007901
Z variance train             0.07823266
KL Divergence                44.869946
KL Loss                      4.4869947
QF Loss                      82.2359
VF Loss                      42.612663
Policy Loss                  -1144.7765
Q Predictions Mean           1145.5264
Q Predictions Std            1139.6516
Q Predictions Max            4436.485
Q Predictions Min            609.04565
V Predictions Mean           1146.7864
V Predictions Std            1134.7092
V Predictions Max            4423.4824
V Predictions Min            623.0147
Log Pis Mean                 -0.43932512
Log Pis Std                  3.4313643
Log Pis Max                  12.650631
Log Pis Min                  -8.274021
Policy mu Mean               0.021535635
Policy mu Std                0.845201
Policy mu Max                2.4625788
Policy mu Min                -2.5442915
Policy log std Mean          -0.504466
Policy log std Std           0.2530017
Policy log std Max           0.26568323
Policy log std Min           -2.425052
Z mean eval                  1.7963327
Z variance eval              0.08562441
total_rewards                [ 9371.58872134  9877.19368266  9796.50796289  9871.70083544
  9549.70862587  9839.08544931 10162.2133726   9905.19537302
  9945.56424738  9591.30051594]
total_rewards_mean           9791.005878646127
total_rewards_std            215.6436442676122
total_rewards_max            10162.213372598844
total_rewards_min            9371.588721342006
Number of train steps total  1248000
Number of env steps total    3746000
Number of rollouts total     0
Train Time (s)               144.85634472128004
(Previous) Eval Time (s)     20.859417208936065
Sample Time (s)              6.444515200331807
Epoch Time (s)               172.1602771305479
Total Train Time (s)         53336.332650802564
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:42:35.480498 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #311 | Epoch Duration: 172.24315810203552
2020-01-12 22:42:35.480637 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7962716
Z variance train             0.08567779
KL Divergence                44.773045
KL Loss                      4.4773045
QF Loss                      270.1863
VF Loss                      33.942
Policy Loss                  -1123.3965
Q Predictions Mean           1118.6387
Q Predictions Std            1114.3601
Q Predictions Max            4618.031
Q Predictions Min            626.9934
V Predictions Mean           1124.553
V Predictions Std            1119.2251
V Predictions Max            4632.068
V Predictions Min            639.48
Log Pis Mean                 -0.7689757
Log Pis Std                  3.5272124
Log Pis Max                  18.776539
Log Pis Min                  -7.0568686
Policy mu Mean               0.060161244
Policy mu Std                0.8401822
Policy mu Max                4.3152504
Policy mu Min                -3.3407934
Policy log std Mean          -0.49474764
Policy log std Std           0.274777
Policy log std Max           0.21635121
Policy log std Min           -2.8879366
Z mean eval                  1.7841647
Z variance eval              0.093428455
total_rewards                [9202.71395987 9557.58793418 8985.58758087 9307.58643076 9382.3437324
 8143.77627286 9306.26527999 9073.49810118 9341.28350261 8967.03476419]
total_rewards_mean           9126.767755891191
total_rewards_std            371.7769591979031
total_rewards_max            9557.587934179573
total_rewards_min            8143.776272856632
Number of train steps total  1252000
Number of env steps total    3758000
Number of rollouts total     0
Train Time (s)               147.1140506430529
(Previous) Eval Time (s)     17.55216360092163
Sample Time (s)              6.460114154964685
Epoch Time (s)               171.12632839893922
Total Train Time (s)         53507.53807624988
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:45:26.689614 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #312 | Epoch Duration: 171.20886301994324
2020-01-12 22:45:26.689782 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7855997
Z variance train             0.093419604
KL Divergence                44.21741
KL Loss                      4.421741
QF Loss                      116.75348
VF Loss                      143.56061
Policy Loss                  -1299.3881
Q Predictions Mean           1297.6934
Q Predictions Std            1300.0734
Q Predictions Max            4489.277
Q Predictions Min            636.1987
V Predictions Mean           1293.2192
V Predictions Std            1288.1655
V Predictions Max            4446.8374
V Predictions Min            635.7293
Log Pis Mean                 -0.6721461
Log Pis Std                  3.6448812
Log Pis Max                  15.823763
Log Pis Min                  -11.856018
Policy mu Mean               -0.024462253
Policy mu Std                0.85921603
Policy mu Max                3.2763436
Policy mu Min                -3.1205933
Policy log std Mean          -0.4841137
Policy log std Std           0.2656746
Policy log std Max           0.30590367
Policy log std Min           -2.514464
Z mean eval                  1.8006792
Z variance eval              0.092416614
total_rewards                [9595.48847177 9812.53663929 9635.07906561 9552.98700666 9786.02892557
 9549.46843    9664.55489219 9599.50034457 9584.84508508 9819.4144142 ]
total_rewards_mean           9659.99032749554
total_rewards_std            101.16555069122911
total_rewards_max            9819.41441420254
total_rewards_min            9549.468429997436
Number of train steps total  1256000
Number of env steps total    3770000
Number of rollouts total     0
Train Time (s)               146.49051501322538
(Previous) Eval Time (s)     20.790774310939014
Sample Time (s)              6.514025928452611
Epoch Time (s)               173.795315252617
Total Train Time (s)         53681.432074513286
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:48:20.585292 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #313 | Epoch Duration: 173.8953833580017
2020-01-12 22:48:20.585440 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #313 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.799708
Z variance train             0.09247057
KL Divergence                44.444786
KL Loss                      4.4444785
QF Loss                      202.6352
VF Loss                      63.65096
Policy Loss                  -1426.0076
Q Predictions Mean           1426.8375
Q Predictions Std            1367.022
Q Predictions Max            4487.449
Q Predictions Min            631.5592
V Predictions Mean           1427.9951
V Predictions Std            1366.9971
V Predictions Max            4473.785
V Predictions Min            623.2108
Log Pis Mean                 -0.053217262
Log Pis Std                  4.021117
Log Pis Max                  13.648204
Log Pis Min                  -8.327703
Policy mu Mean               0.023064354
Policy mu Std                0.8970868
Policy mu Max                2.4380906
Policy mu Min                -2.751778
Policy log std Mean          -0.5148533
Policy log std Std           0.31370705
Policy log std Max           0.009624362
Policy log std Min           -2.8126454
Z mean eval                  1.7752241
Z variance eval              0.068423524
total_rewards                [ 9282.87524261  9920.04625788  9765.68718994  9934.40145568
 10091.94764953  9742.32679589  9993.826551    9885.11271757
 10029.76252079  9738.6155431 ]
total_rewards_mean           9838.460192398943
total_rewards_std            218.22231269309887
total_rewards_max            10091.947649526808
total_rewards_min            9282.875242614244
Number of train steps total  1260000
Number of env steps total    3782000
Number of rollouts total     0
Train Time (s)               145.7166095469147
(Previous) Eval Time (s)     17.284411718137562
Sample Time (s)              6.648063201922923
Epoch Time (s)               169.64908446697518
Total Train Time (s)         53851.16395285772
Epoch                        314
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:51:10.322240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #314 | Epoch Duration: 169.73668003082275
2020-01-12 22:51:10.322419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7749426
Z variance train             0.06850171
KL Divergence                44.03917
KL Loss                      4.403917
QF Loss                      68.12311
VF Loss                      27.99068
Policy Loss                  -1170.3198
Q Predictions Mean           1170.6338
Q Predictions Std            1165.3677
Q Predictions Max            4478.541
Q Predictions Min            639.9777
V Predictions Mean           1169.7449
V Predictions Std            1162.5529
V Predictions Max            4429.2773
V Predictions Min            643.8294
Log Pis Mean                 -0.48028436
Log Pis Std                  3.6581159
Log Pis Max                  12.617698
Log Pis Min                  -6.233508
Policy mu Mean               0.034611553
Policy mu Std                0.83962697
Policy mu Max                2.4909465
Policy mu Min                -3.3860748
Policy log std Mean          -0.4972725
Policy log std Std           0.26124924
Policy log std Max           0.027370632
Policy log std Min           -2.662407
Z mean eval                  1.7949635
Z variance eval              0.08724328
total_rewards                [9335.60425739 9680.77576791 9490.36091915 9499.225024   9612.46711993
 9638.29412838 9409.16427803 9725.75469371 9510.86079607 9254.70256503]
total_rewards_mean           9515.720954959335
total_rewards_std            144.43236627959647
total_rewards_max            9725.754693710238
total_rewards_min            9254.702565025953
Number of train steps total  1264000
Number of env steps total    3794000
Number of rollouts total     0
Train Time (s)               145.1270740358159
(Previous) Eval Time (s)     20.919906778261065
Sample Time (s)              5.716656708158553
Epoch Time (s)               171.7636375222355
Total Train Time (s)         54023.00660692435
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:54:02.167779 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #315 | Epoch Duration: 171.84522557258606
2020-01-12 22:54:02.167919 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #315 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7947447
Z variance train             0.08734233
KL Divergence                44.14329
KL Loss                      4.414329
QF Loss                      86.03195
VF Loss                      59.7796
Policy Loss                  -1238.3792
Q Predictions Mean           1237.2092
Q Predictions Std            1211.3815
Q Predictions Max            4437.7544
Q Predictions Min            640.6839
V Predictions Mean           1234.8733
V Predictions Std            1208.2854
V Predictions Max            4414.7266
V Predictions Min            637.2332
Log Pis Mean                 -0.6166153
Log Pis Std                  3.1903954
Log Pis Max                  14.598618
Log Pis Min                  -7.440077
Policy mu Mean               -0.024926012
Policy mu Std                0.82863426
Policy mu Max                2.2870686
Policy mu Min                -2.44068
Policy log std Mean          -0.5010974
Policy log std Std           0.27332196
Policy log std Max           0.0016109943
Policy log std Min           -2.628548
Z mean eval                  1.7905957
Z variance eval              0.086955115
total_rewards                [ 9792.54153828 10003.92943057  6632.4814116   9808.34272664
  9901.01542641  9919.68597167 10123.69386013  9715.67304113
  9787.7896183  10146.98086906]
total_rewards_mean           9583.213389378898
total_rewards_std            993.0702150906137
total_rewards_max            10146.98086906192
total_rewards_min            6632.481411597136
Number of train steps total  1268000
Number of env steps total    3806000
Number of rollouts total     0
Train Time (s)               145.14495570305735
(Previous) Eval Time (s)     20.871004222426564
Sample Time (s)              6.404998062644154
Epoch Time (s)               172.42095798812807
Total Train Time (s)         54195.51261004293
Epoch                        316
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:56:54.676754 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #316 | Epoch Duration: 172.50873684883118
2020-01-12 22:56:54.676892 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7953287
Z variance train             0.08687654
KL Divergence                42.795906
KL Loss                      4.2795906
QF Loss                      111.549576
VF Loss                      129.90356
Policy Loss                  -1228.9694
Q Predictions Mean           1229.7441
Q Predictions Std            1210.5975
Q Predictions Max            4412.45
Q Predictions Min            397.1112
V Predictions Mean           1236.1638
V Predictions Std            1207.8668
V Predictions Max            4431.8853
V Predictions Min            420.666
Log Pis Mean                 -0.58089465
Log Pis Std                  3.7102644
Log Pis Max                  17.666498
Log Pis Min                  -6.52494
Policy mu Mean               0.04804148
Policy mu Std                0.84052885
Policy mu Max                2.7786055
Policy mu Min                -3.0895662
Policy log std Mean          -0.49979028
Policy log std Std           0.30293205
Policy log std Max           0.13399714
Policy log std Min           -2.7357616
Z mean eval                  1.7866462
Z variance eval              0.08098515
total_rewards                [ 9679.8280732   9984.20153326 10154.36403974  9664.09656082
  9679.46115331 10169.06354437  9724.1910651   9886.92768345
  9946.15768536 10127.31384342]
total_rewards_mean           9901.560518204406
total_rewards_std            195.3988426007276
total_rewards_max            10169.063544371005
total_rewards_min            9664.096560823726
Number of train steps total  1272000
Number of env steps total    3818000
Number of rollouts total     0
Train Time (s)               147.50106215197593
(Previous) Eval Time (s)     21.048378004692495
Sample Time (s)              6.4849837962538
Epoch Time (s)               175.03442395292222
Total Train Time (s)         54370.63554027304
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 22:59:49.803693 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #317 | Epoch Duration: 175.1267008781433
2020-01-12 22:59:49.803853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7888424
Z variance train             0.08096676
KL Divergence                43.924664
KL Loss                      4.3924665
QF Loss                      100.5616
VF Loss                      66.96734
Policy Loss                  -1303.5632
Q Predictions Mean           1302.7944
Q Predictions Std            1272.3824
Q Predictions Max            4485.6377
Q Predictions Min            637.55023
V Predictions Mean           1299.0492
V Predictions Std            1266.7603
V Predictions Max            4483.229
V Predictions Min            637.519
Log Pis Mean                 -0.22578041
Log Pis Std                  3.7003188
Log Pis Max                  15.616499
Log Pis Min                  -6.8604527
Policy mu Mean               -0.026461527
Policy mu Std                0.8778995
Policy mu Max                2.752522
Policy mu Min                -2.5294917
Policy log std Mean          -0.5049451
Policy log std Std           0.27467513
Policy log std Max           0.033811867
Policy log std Min           -2.72507
Z mean eval                  1.8149059
Z variance eval              0.07224999
total_rewards                [9468.0434454  9634.42008977 9432.54877685 9560.13970554 9695.20447001
 9461.60074088 9496.40337415 9562.52945348 9444.99957729 9464.19452372]
total_rewards_mean           9522.008415710177
total_rewards_std            83.79854717986417
total_rewards_max            9695.204470013055
total_rewards_min            9432.548776851441
Number of train steps total  1276000
Number of env steps total    3830000
Number of rollouts total     0
Train Time (s)               147.04323120880872
(Previous) Eval Time (s)     20.58857871964574
Sample Time (s)              6.4745201715268195
Epoch Time (s)               174.10633009998128
Total Train Time (s)         54544.82632547151
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:02:43.999959 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #318 | Epoch Duration: 174.1959934234619
2020-01-12 23:02:44.000158 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8142198
Z variance train             0.07217006
KL Divergence                45.56876
KL Loss                      4.556876
QF Loss                      130.74384
VF Loss                      45.9796
Policy Loss                  -1171.2893
Q Predictions Mean           1168.4698
Q Predictions Std            1142.2971
Q Predictions Max            4515.466
Q Predictions Min            631.99524
V Predictions Mean           1173.1011
V Predictions Std            1139.6653
V Predictions Max            4487.333
V Predictions Min            650.7112
Log Pis Mean                 -0.8331382
Log Pis Std                  3.4860277
Log Pis Max                  18.116556
Log Pis Min                  -10.735769
Policy mu Mean               0.00092520687
Policy mu Std                0.8391631
Policy mu Max                3.3855193
Policy mu Min                -2.88572
Policy log std Mean          -0.49852487
Policy log std Std           0.2731121
Policy log std Max           0.0077904463
Policy log std Min           -2.586977
Z mean eval                  1.8191893
Z variance eval              0.061810352
total_rewards                [9401.33962409 9873.19163202 9609.56025157 9674.01141173 9583.6622926
 9539.0607231  9870.08431981 9624.66075486 9753.39679708 9628.77076237]
total_rewards_mean           9655.773856922451
total_rewards_std            138.00507671496285
total_rewards_max            9873.19163201501
total_rewards_min            9401.339624085032
Number of train steps total  1280000
Number of env steps total    3842000
Number of rollouts total     0
Train Time (s)               146.27230041194707
(Previous) Eval Time (s)     20.824665712192655
Sample Time (s)              6.44978565024212
Epoch Time (s)               173.54675177438185
Total Train Time (s)         54718.458419310395
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:05:37.633829 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #319 | Epoch Duration: 173.6335334777832
2020-01-12 23:05:37.633956 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #319 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8184685
Z variance train             0.06187564
KL Divergence                46.237034
KL Loss                      4.6237035
QF Loss                      133.29282
VF Loss                      46.932415
Policy Loss                  -1355.2161
Q Predictions Mean           1350.6199
Q Predictions Std            1327.2208
Q Predictions Max            4524.739
Q Predictions Min            652.7664
V Predictions Mean           1355.2233
V Predictions Std            1325.4136
V Predictions Max            4517.929
V Predictions Min            650.91406
Log Pis Mean                 -0.1624864
Log Pis Std                  3.9193969
Log Pis Max                  15.417389
Log Pis Min                  -6.569827
Policy mu Mean               0.013450739
Policy mu Std                0.892372
Policy mu Max                3.3218932
Policy mu Min                -3.0201838
Policy log std Mean          -0.510017
Policy log std Std           0.29690346
Policy log std Max           0.020125628
Policy log std Min           -2.7273316
Z mean eval                  1.7931359
Z variance eval              0.06180688
total_rewards                [ 9886.73211423  9772.62332223  2618.94262588 10038.78099806
 10310.4763645   9983.69036037 10110.51527547  6453.70948912
 10301.02820458  9958.26526597]
total_rewards_mean           8943.476402041368
total_rewards_std            2369.8318911249385
total_rewards_max            10310.476364503573
total_rewards_min            2618.9426258784806
Number of train steps total  1284000
Number of env steps total    3854000
Number of rollouts total     0
Train Time (s)               146.6990394545719
(Previous) Eval Time (s)     20.929202146828175
Sample Time (s)              9.112991851754487
Epoch Time (s)               176.74123345315456
Total Train Time (s)         54895.27982244687
Epoch                        320
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:08:34.459470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #320 | Epoch Duration: 176.82540345191956
2020-01-12 23:08:34.459668 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7915913
Z variance train             0.06177526
KL Divergence                46.325565
KL Loss                      4.6325564
QF Loss                      128.34099
VF Loss                      50.620792
Policy Loss                  -1388.82
Q Predictions Mean           1386.7906
Q Predictions Std            1350.8788
Q Predictions Max            4482.2075
Q Predictions Min            648.28625
V Predictions Mean           1391.5123
V Predictions Std            1351.5094
V Predictions Max            4479.8633
V Predictions Min            639.86523
Log Pis Mean                 -0.17547199
Log Pis Std                  3.85754
Log Pis Max                  19.854832
Log Pis Min                  -7.4209986
Policy mu Mean               0.035516363
Policy mu Std                0.8911105
Policy mu Max                3.8539643
Policy mu Min                -3.1948836
Policy log std Mean          -0.5160196
Policy log std Std           0.29072127
Policy log std Max           0.091507375
Policy log std Min           -2.7668412
Z mean eval                  1.8179731
Z variance eval              0.03804742
total_rewards                [9945.8806471  9874.97436651 9465.54198735 9763.76761406 9819.5391115
 9812.33818263 9703.61615315 9785.79274391 9802.25489227 9614.38479763]
total_rewards_mean           9758.809049612424
total_rewards_std            129.4581440029693
total_rewards_max            9945.880647102043
total_rewards_min            9465.541987351919
Number of train steps total  1288000
Number of env steps total    3866000
Number of rollouts total     0
Train Time (s)               146.68735046684742
(Previous) Eval Time (s)     20.63172680605203
Sample Time (s)              6.613966029603034
Epoch Time (s)               173.93304330250248
Total Train Time (s)         55069.29437848274
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:11:28.476901 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #321 | Epoch Duration: 174.01710486412048
2020-01-12 23:11:28.477043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8166513
Z variance train             0.038317334
KL Divergence                46.796886
KL Loss                      4.679689
QF Loss                      162.21094
VF Loss                      57.69388
Policy Loss                  -1267.4938
Q Predictions Mean           1264.154
Q Predictions Std            1229.0376
Q Predictions Max            4502.2944
Q Predictions Min            627.0964
V Predictions Mean           1269.1566
V Predictions Std            1232.9266
V Predictions Max            4494.0605
V Predictions Min            634.14105
Log Pis Mean                 -0.46615365
Log Pis Std                  3.753073
Log Pis Max                  18.552597
Log Pis Min                  -7.2546434
Policy mu Mean               0.035747185
Policy mu Std                0.8575909
Policy mu Max                3.3654106
Policy mu Min                -3.264254
Policy log std Mean          -0.4954169
Policy log std Std           0.28197476
Policy log std Max           0.123829424
Policy log std Min           -2.4824643
Z mean eval                  1.8378938
Z variance eval              0.035229467
total_rewards                [10324.57758033  9747.52261899 10119.68082762  9944.67272504
  9906.82975509  9918.00824619  9890.95708219 10080.13762785
  9993.69216219  9859.33627466]
total_rewards_mean           9978.541490015134
total_rewards_std            153.43310494035367
total_rewards_max            10324.57758033226
total_rewards_min            9747.522618988236
Number of train steps total  1292000
Number of env steps total    3878000
Number of rollouts total     0
Train Time (s)               146.63254825398326
(Previous) Eval Time (s)     20.88586122682318
Sample Time (s)              6.348956322297454
Epoch Time (s)               173.8673658031039
Total Train Time (s)         55243.24179429794
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:14:22.426554 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #322 | Epoch Duration: 173.94941449165344
2020-01-12 23:14:22.426706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8354524
Z variance train             0.035291873
KL Divergence                46.701706
KL Loss                      4.670171
QF Loss                      3749.7876
VF Loss                      121.99382
Policy Loss                  -1243.1213
Q Predictions Mean           1243.5635
Q Predictions Std            1204.2931
Q Predictions Max            4582.2383
Q Predictions Min            651.9841
V Predictions Mean           1250.9438
V Predictions Std            1209.0864
V Predictions Max            4561.851
V Predictions Min            660.2693
Log Pis Mean                 -0.64009196
Log Pis Std                  3.8796325
Log Pis Max                  18.694765
Log Pis Min                  -7.5491266
Policy mu Mean               0.004742379
Policy mu Std                0.8411301
Policy mu Max                2.8816638
Policy mu Min                -2.8058934
Policy log std Mean          -0.49778786
Policy log std Std           0.24876657
Policy log std Max           -0.08993882
Policy log std Min           -2.8222978
Z mean eval                  1.8086367
Z variance eval              0.062253065
total_rewards                [ 9364.36959992  9673.79740586  9690.45054656 10092.37258081
 10087.32805781  9950.09617363  9561.96115514  9586.88468048
  9896.14996053  9609.19845112]
total_rewards_mean           9751.260861186918
total_rewards_std            230.70450009913333
total_rewards_max            10092.372580810903
total_rewards_min            9364.369599920608
Number of train steps total  1296000
Number of env steps total    3890000
Number of rollouts total     0
Train Time (s)               147.6890561892651
(Previous) Eval Time (s)     20.829177561216056
Sample Time (s)              6.518782259896398
Epoch Time (s)               175.03701601037756
Total Train Time (s)         55418.384355042595
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:17:17.571668 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #323 | Epoch Duration: 175.14485335350037
2020-01-12 23:17:17.571819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8083346
Z variance train             0.062205404
KL Divergence                45.60729
KL Loss                      4.560729
QF Loss                      219.96854
VF Loss                      90.42331
Policy Loss                  -1169.7908
Q Predictions Mean           1165.4143
Q Predictions Std            1136.1155
Q Predictions Max            4488.367
Q Predictions Min            624.08887
V Predictions Mean           1172.4409
V Predictions Std            1137.0585
V Predictions Max            4499.5356
V Predictions Min            644.8678
Log Pis Mean                 -0.62989783
Log Pis Std                  3.765229
Log Pis Max                  15.310375
Log Pis Min                  -9.1012745
Policy mu Mean               0.027270874
Policy mu Std                0.83733624
Policy mu Max                2.8599894
Policy mu Min                -2.9920173
Policy log std Mean          -0.48343506
Policy log std Std           0.27185768
Policy log std Max           0.05000502
Policy log std Min           -2.7499425
Z mean eval                  1.8248799
Z variance eval              0.0763
total_rewards                [ 9892.4092187   9971.35117857  9853.27197143  9828.57580705
  9900.41909857  9911.41938252 10035.90893349  9865.60999454
  9741.51747475  9533.69501514]
total_rewards_mean           9853.417807475016
total_rewards_std            130.31311115648865
total_rewards_max            10035.908933488208
total_rewards_min            9533.695015139674
Number of train steps total  1300000
Number of env steps total    3902000
Number of rollouts total     0
Train Time (s)               146.7134806108661
(Previous) Eval Time (s)     20.559383395127952
Sample Time (s)              6.516948052216321
Epoch Time (s)               173.78981205821037
Total Train Time (s)         55592.26152543817
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:20:11.456507 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #324 | Epoch Duration: 173.88453364372253
2020-01-12 23:20:11.456836 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.824578
Z variance train             0.07611875
KL Divergence                44.313255
KL Loss                      4.4313254
QF Loss                      4079.2651
VF Loss                      40.483707
Policy Loss                  -1346.5663
Q Predictions Mean           1344.0398
Q Predictions Std            1286.3104
Q Predictions Max            4565.155
Q Predictions Min            655.9565
V Predictions Mean           1348.6931
V Predictions Std            1291.4928
V Predictions Max            4569.228
V Predictions Min            655.8736
Log Pis Mean                 -0.3258282
Log Pis Std                  3.8476388
Log Pis Max                  16.461363
Log Pis Min                  -6.07214
Policy mu Mean               -0.015268292
Policy mu Std                0.8731474
Policy mu Max                2.870411
Policy mu Min                -2.8070865
Policy log std Mean          -0.4968016
Policy log std Std           0.2829678
Policy log std Max           0.009041667
Policy log std Min           -2.5800118
Z mean eval                  1.8339853
Z variance eval              0.048369553
total_rewards                [7655.44047983 5752.84510276 8559.55563506 7890.42663897 3040.70451243
 7870.0596186  7569.77741771 7917.78743226 8532.0049641  8137.33023499]
total_rewards_mean           7292.593203670394
total_rewards_std            1599.8289582962095
total_rewards_max            8559.55563505779
total_rewards_min            3040.7045124277797
Number of train steps total  1304000
Number of env steps total    3914000
Number of rollouts total     0
Train Time (s)               146.01165640726686
(Previous) Eval Time (s)     20.78400301700458
Sample Time (s)              6.601574673783034
Epoch Time (s)               173.39723409805447
Total Train Time (s)         55766.02625609469
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:23:05.224548 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #325 | Epoch Duration: 173.7674684524536
2020-01-12 23:23:05.224745 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #325 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.83335
Z variance train             0.048315912
KL Divergence                46.083607
KL Loss                      4.608361
QF Loss                      272.6649
VF Loss                      57.4078
Policy Loss                  -1392.077
Q Predictions Mean           1388.9653
Q Predictions Std            1345.9608
Q Predictions Max            4531.745
Q Predictions Min            637.5959
V Predictions Mean           1388.9434
V Predictions Std            1342.5558
V Predictions Max            4516.3325
V Predictions Min            640.2321
Log Pis Mean                 -0.2535825
Log Pis Std                  3.7412157
Log Pis Max                  14.947681
Log Pis Min                  -5.9983234
Policy mu Mean               0.07919838
Policy mu Std                0.87431127
Policy mu Max                3.9232395
Policy mu Min                -2.6082172
Policy log std Mean          -0.50824887
Policy log std Std           0.28710547
Policy log std Max           0.22171384
Policy log std Min           -2.534364
Z mean eval                  1.8194473
Z variance eval              0.07984494
total_rewards                [10063.14229088  9940.3528517  10046.05435381  9908.10160264
  9960.34000501 10107.06768307 10185.11390055 10397.75163036
 10187.67057373 10104.26286518]
total_rewards_mean           10089.985775691639
total_rewards_std            137.38178946202942
total_rewards_max            10397.751630356837
total_rewards_min            9908.101602641507
Number of train steps total  1308000
Number of env steps total    3926000
Number of rollouts total     0
Train Time (s)               146.93553664395586
(Previous) Eval Time (s)     20.508644022978842
Sample Time (s)              6.509763809386641
Epoch Time (s)               173.95394447632134
Total Train Time (s)         55940.234440295026
Epoch                        326
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:25:59.438673 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #326 | Epoch Duration: 174.21376419067383
2020-01-12 23:25:59.438873 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8189042
Z variance train             0.07992017
KL Divergence                45.821995
KL Loss                      4.5821996
QF Loss                      146.47086
VF Loss                      42.22112
Policy Loss                  -1228.2992
Q Predictions Mean           1226.2246
Q Predictions Std            1174.9176
Q Predictions Max            4474.378
Q Predictions Min            661.18445
V Predictions Mean           1230.5381
V Predictions Std            1176.1594
V Predictions Max            4475.9336
V Predictions Min            668.0647
Log Pis Mean                 -0.56933665
Log Pis Std                  3.4682748
Log Pis Max                  13.844731
Log Pis Min                  -7.5461383
Policy mu Mean               0.0020708367
Policy mu Std                0.8483383
Policy mu Max                2.5388198
Policy mu Min                -2.4788399
Policy log std Mean          -0.5099029
Policy log std Std           0.27827972
Policy log std Max           0.07713896
Policy log std Min           -2.617006
Z mean eval                  1.8621187
Z variance eval              0.10776566
total_rewards                [9241.51869715 3750.86294603 9006.04338385 8891.87885532 8894.85209663
 9009.60803255 9293.76660356 9310.69979682 8829.51996668 8875.65679257]
total_rewards_mean           8510.440717116897
total_rewards_std            1595.7857354363714
total_rewards_max            9310.699796821307
total_rewards_min            3750.862946033172
Number of train steps total  1312000
Number of env steps total    3938000
Number of rollouts total     0
Train Time (s)               146.30824392288923
(Previous) Eval Time (s)     18.241675504948944
Sample Time (s)              6.395097536034882
Epoch Time (s)               170.94501696387306
Total Train Time (s)         56111.26459609019
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:28:50.474419 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #327 | Epoch Duration: 171.0354037284851
2020-01-12 23:28:50.474589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #327 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8620383
Z variance train             0.10790123
KL Divergence                45.431343
KL Loss                      4.543134
QF Loss                      3862.7185
VF Loss                      117.93612
Policy Loss                  -1409.451
Q Predictions Mean           1407.2874
Q Predictions Std            1346.8794
Q Predictions Max            4481.8667
Q Predictions Min            654.284
V Predictions Mean           1402.6877
V Predictions Std            1339.959
V Predictions Max            4457.3203
V Predictions Min            659.0607
Log Pis Mean                 -0.29728281
Log Pis Std                  3.7960358
Log Pis Max                  13.533589
Log Pis Min                  -8.252262
Policy mu Mean               -0.026726743
Policy mu Std                0.88632685
Policy mu Max                2.708605
Policy mu Min                -3.2168474
Policy log std Mean          -0.5095651
Policy log std Std           0.27818924
Policy log std Max           -0.0018121004
Policy log std Min           -2.2883432
Z mean eval                  1.8313675
Z variance eval              0.07746356
total_rewards                [ 9838.81789946  9850.49985032  9562.76617602  9785.03172767
  9922.33499537  9945.62468608  9931.15896608  9958.00504511
 10205.32443795  9784.17587104]
total_rewards_mean           9878.373965510118
total_rewards_std            155.5683733692212
total_rewards_max            10205.324437951118
total_rewards_min            9562.766176021874
Number of train steps total  1316000
Number of env steps total    3950000
Number of rollouts total     0
Train Time (s)               147.5890951338224
(Previous) Eval Time (s)     20.83732996881008
Sample Time (s)              6.566782809328288
Epoch Time (s)               174.99320791196078
Total Train Time (s)         56286.33895621169
Epoch                        328
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:31:45.552509 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #328 | Epoch Duration: 175.07779264450073
2020-01-12 23:31:45.552643 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #328 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8293676
Z variance train             0.077918395
KL Divergence                46.89896
KL Loss                      4.689896
QF Loss                      138.33032
VF Loss                      128.92958
Policy Loss                  -1319.5686
Q Predictions Mean           1314.9475
Q Predictions Std            1260.4956
Q Predictions Max            4476.746
Q Predictions Min            639.8118
V Predictions Mean           1325.3961
V Predictions Std            1262.5817
V Predictions Max            4491.972
V Predictions Min            631.5764
Log Pis Mean                 0.08046979
Log Pis Std                  3.886015
Log Pis Max                  15.821927
Log Pis Min                  -7.590043
Policy mu Mean               0.09035381
Policy mu Std                0.8972683
Policy mu Max                4.14953
Policy mu Min                -3.5200028
Policy log std Mean          -0.54867506
Policy log std Std           0.31237826
Policy log std Max           -0.03648019
Policy log std Min           -2.7964916
Z mean eval                  1.8025023
Z variance eval              0.110143624
total_rewards                [ 9909.14046996 10338.47805041 10087.04965074 10208.8109192
  9973.00429657 10130.07544009 10150.05962816  9641.31886906
 10140.02985021  9621.06639731]
total_rewards_mean           10019.903357169329
total_rewards_std            224.06662362382178
total_rewards_max            10338.478050408634
total_rewards_min            9621.066397310584
Number of train steps total  1320000
Number of env steps total    3962000
Number of rollouts total     0
Train Time (s)               146.94836933119223
(Previous) Eval Time (s)     17.24934294912964
Sample Time (s)              6.405183338560164
Epoch Time (s)               170.60289561888203
Total Train Time (s)         56457.02025509672
Epoch                        329
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:34:36.237303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #329 | Epoch Duration: 170.68454885482788
2020-01-12 23:34:36.237476 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8021635
Z variance train             0.110085115
KL Divergence                46.6348
KL Loss                      4.6634803
QF Loss                      3838.9453
VF Loss                      60.507942
Policy Loss                  -1221.7848
Q Predictions Mean           1216.9954
Q Predictions Std            1161.827
Q Predictions Max            4548.9717
Q Predictions Min            519.55835
V Predictions Mean           1218.295
V Predictions Std            1161.3622
V Predictions Max            4540.39
V Predictions Min            526.74536
Log Pis Mean                 -0.5185359
Log Pis Std                  3.8059914
Log Pis Max                  12.619298
Log Pis Min                  -6.8114953
Policy mu Mean               0.07273104
Policy mu Std                0.83797127
Policy mu Max                3.2814226
Policy mu Min                -2.7174768
Policy log std Mean          -0.5144411
Policy log std Std           0.30123442
Policy log std Max           0.038885415
Policy log std Min           -2.8665273
Z mean eval                  1.8286982
Z variance eval              0.07674527
total_rewards                [9049.59526166 9527.78907598 9320.7703519  9524.09966737 9393.69055367
 9638.03030938 9565.3394443  9260.89437662 9318.62315743 9506.10269979]
total_rewards_mean           9410.493489810211
total_rewards_std            167.61747429416508
total_rewards_max            9638.030309378453
total_rewards_min            9049.595261660394
Number of train steps total  1324000
Number of env steps total    3974000
Number of rollouts total     0
Train Time (s)               146.55700511205941
(Previous) Eval Time (s)     20.7774381400086
Sample Time (s)              6.404016450513154
Epoch Time (s)               173.73845970258117
Total Train Time (s)         56630.84298846731
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:37:30.064240 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #330 | Epoch Duration: 173.82656383514404
2020-01-12 23:37:30.064531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #330 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8327217
Z variance train             0.07668658
KL Divergence                47.327793
KL Loss                      4.7327795
QF Loss                      131.69771
VF Loss                      118.96875
Policy Loss                  -1238.0488
Q Predictions Mean           1235.5544
Q Predictions Std            1173.2623
Q Predictions Max            4517.8545
Q Predictions Min            652.6937
V Predictions Mean           1232.993
V Predictions Std            1166.9231
V Predictions Max            4506.5273
V Predictions Min            642.2624
Log Pis Mean                 -0.6541594
Log Pis Std                  3.5114238
Log Pis Max                  14.2097435
Log Pis Min                  -8.389521
Policy mu Mean               -0.008253339
Policy mu Std                0.8160523
Policy mu Max                2.4989476
Policy mu Min                -2.8821933
Policy log std Mean          -0.50788605
Policy log std Std           0.2767612
Policy log std Max           0.00046658516
Policy log std Min           -2.44751
Z mean eval                  1.8329633
Z variance eval              0.07045446
total_rewards                [ 9399.23851361 10194.91122584 10156.42956264  9849.88943468
  9927.27515143  9871.94254234  9801.21662823 10060.54163895
  9786.2688524  10018.52121967]
total_rewards_mean           9906.623476979918
total_rewards_std            216.7044445528123
total_rewards_max            10194.91122584031
total_rewards_min            9399.23851361444
Number of train steps total  1328000
Number of env steps total    3986000
Number of rollouts total     0
Train Time (s)               146.25544716976583
(Previous) Eval Time (s)     20.822639302816242
Sample Time (s)              6.446203996427357
Epoch Time (s)               173.52429046900943
Total Train Time (s)         56804.452338489704
Epoch                        331
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:40:23.674884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #331 | Epoch Duration: 173.61017775535583
2020-01-12 23:40:23.675067 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8351854
Z variance train             0.07059305
KL Divergence                46.512833
KL Loss                      4.6512833
QF Loss                      241.54883
VF Loss                      36.29786
Policy Loss                  -1485.35
Q Predictions Mean           1481.7775
Q Predictions Std            1384.3191
Q Predictions Max            4472.8604
Q Predictions Min            656.1197
V Predictions Mean           1484.6603
V Predictions Std            1380.6879
V Predictions Max            4462.073
V Predictions Min            653.49884
Log Pis Mean                 -0.13280942
Log Pis Std                  3.8704088
Log Pis Max                  14.194908
Log Pis Min                  -5.9922967
Policy mu Mean               0.06215481
Policy mu Std                0.91108334
Policy mu Max                3.771106
Policy mu Min                -3.0158763
Policy log std Mean          -0.5221524
Policy log std Std           0.30045345
Policy log std Max           -0.09355542
Policy log std Min           -2.6785421
Z mean eval                  1.8152514
Z variance eval              0.074680954
total_rewards                [ 9963.77490107  9777.47015837  9964.98752385 10008.18482827
  9874.83367309  9843.0457182  10226.85463583  9677.31024158
 10123.99944561  9720.46463652]
total_rewards_mean           9918.092576239893
total_rewards_std            165.66388753727935
total_rewards_max            10226.854635834668
total_rewards_min            9677.310241581643
Number of train steps total  1332000
Number of env steps total    3998000
Number of rollouts total     0
Train Time (s)               147.5805674381554
(Previous) Eval Time (s)     20.908862388692796
Sample Time (s)              6.411856855265796
Epoch Time (s)               174.901286682114
Total Train Time (s)         56979.43693455914
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:43:18.662911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #332 | Epoch Duration: 174.98767066001892
2020-01-12 23:43:18.663145 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8155787
Z variance train             0.074708626
KL Divergence                45.998295
KL Loss                      4.5998297
QF Loss                      4199.7236
VF Loss                      67.31695
Policy Loss                  -1139.9938
Q Predictions Mean           1137.4448
Q Predictions Std            1102.211
Q Predictions Max            4524.96
Q Predictions Min            663.6632
V Predictions Mean           1134.7856
V Predictions Std            1098.5431
V Predictions Max            4503.7886
V Predictions Min            659.7857
Log Pis Mean                 -0.95836425
Log Pis Std                  3.4024549
Log Pis Max                  12.790806
Log Pis Min                  -7.2361484
Policy mu Mean               0.05909562
Policy mu Std                0.8093788
Policy mu Max                2.4893606
Policy mu Min                -2.5540988
Policy log std Mean          -0.49387464
Policy log std Std           0.2612322
Policy log std Max           0.051922023
Policy log std Min           -2.625378
Z mean eval                  1.8061682
Z variance eval              0.09122591
total_rewards                [8656.18276164 9305.82778496 8930.2450811  9255.37823156 9185.96769367
 8978.52340445 9263.97839126 9063.84823882 9305.93179412 8970.64600582]
total_rewards_mean           9091.652938739786
total_rewards_std            200.27092675845572
total_rewards_max            9305.931794122962
total_rewards_min            8656.182761637829
Number of train steps total  1336000
Number of env steps total    4010000
Number of rollouts total     0
Train Time (s)               146.27871873276308
(Previous) Eval Time (s)     21.430413161870092
Sample Time (s)              6.606893048156053
Epoch Time (s)               174.31602494278923
Total Train Time (s)         57153.83585699415
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:46:13.063789 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #333 | Epoch Duration: 174.4005160331726
2020-01-12 23:46:13.063923 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8060621
Z variance train             0.090751484
KL Divergence                43.99221
KL Loss                      4.399221
QF Loss                      189.6778
VF Loss                      225.8501
Policy Loss                  -1379.4615
Q Predictions Mean           1381.2661
Q Predictions Std            1322.3804
Q Predictions Max            4603.777
Q Predictions Min            679.93726
V Predictions Mean           1390.5798
V Predictions Std            1322.4695
V Predictions Max            4624.897
V Predictions Min            678.6757
Log Pis Mean                 -0.04936929
Log Pis Std                  4.065462
Log Pis Max                  14.215408
Log Pis Min                  -7.295275
Policy mu Mean               -0.023982817
Policy mu Std                0.89597714
Policy mu Max                2.9063976
Policy mu Min                -2.9195757
Policy log std Mean          -0.49305758
Policy log std Std           0.30590767
Policy log std Max           -0.013739824
Policy log std Min           -2.6469064
Z mean eval                  1.8217099
Z variance eval              0.0866249
total_rewards                [9580.36897603 9594.23251819 9605.31125362 9773.97632217 9496.26255874
 9665.75294844 9629.98851816 9721.04508397 9869.70411517 9507.01992551]
total_rewards_mean           9644.366222000903
total_rewards_std            110.9291345903558
total_rewards_max            9869.704115172895
total_rewards_min            9496.26255873641
Number of train steps total  1340000
Number of env steps total    4022000
Number of rollouts total     0
Train Time (s)               145.47550945496187
(Previous) Eval Time (s)     17.272665590047836
Sample Time (s)              6.3704776600934565
Epoch Time (s)               169.11865270510316
Total Train Time (s)         57323.03227137448
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:49:02.263382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #334 | Epoch Duration: 169.19934558868408
2020-01-12 23:49:02.263566 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #334 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8212506
Z variance train             0.08680912
KL Divergence                44.48769
KL Loss                      4.448769
QF Loss                      2997.9644
VF Loss                      93.59709
Policy Loss                  -1387.5334
Q Predictions Mean           1386.2847
Q Predictions Std            1320.0217
Q Predictions Max            4632.7114
Q Predictions Min            662.24976
V Predictions Mean           1389.9861
V Predictions Std            1316.5831
V Predictions Max            4630.9185
V Predictions Min            665.3816
Log Pis Mean                 -0.08654553
Log Pis Std                  4.1824265
Log Pis Max                  19.767733
Log Pis Min                  -9.237613
Policy mu Mean               -0.016641228
Policy mu Std                0.90480673
Policy mu Max                3.6595688
Policy mu Min                -3.7621388
Policy log std Mean          -0.5036669
Policy log std Std           0.30933473
Policy log std Max           0.10315621
Policy log std Min           -2.5682952
Z mean eval                  1.8208838
Z variance eval              0.09730226
total_rewards                [10076.68707859  9842.32336811 10144.07154159  9807.73536395
 10094.99276842  9938.99162073 10109.12612744  9698.63475731
 10026.61918312  9779.66698719]
total_rewards_mean           9951.884879643836
total_rewards_std            151.67230023900407
total_rewards_max            10144.071541586107
total_rewards_min            9698.634757309357
Number of train steps total  1344000
Number of env steps total    4034000
Number of rollouts total     0
Train Time (s)               150.32923045614734
(Previous) Eval Time (s)     20.636019038967788
Sample Time (s)              6.561267789918929
Epoch Time (s)               177.52651728503406
Total Train Time (s)         57500.636335468385
Epoch                        335
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:51:59.869575 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #335 | Epoch Duration: 177.605877161026
2020-01-12 23:51:59.869716 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #335 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8201965
Z variance train             0.09715905
KL Divergence                45.08085
KL Loss                      4.508085
QF Loss                      3876.1233
VF Loss                      54.064537
Policy Loss                  -1275.8412
Q Predictions Mean           1273.0046
Q Predictions Std            1224.116
Q Predictions Max            4494.3647
Q Predictions Min            640.3293
V Predictions Mean           1276.7845
V Predictions Std            1222.8495
V Predictions Max            4481.308
V Predictions Min            635.97455
Log Pis Mean                 -0.3021875
Log Pis Std                  3.926213
Log Pis Max                  13.239311
Log Pis Min                  -6.6824846
Policy mu Mean               -0.0022186302
Policy mu Std                0.8739285
Policy mu Max                2.9330559
Policy mu Min                -2.74411
Policy log std Mean          -0.50017446
Policy log std Std           0.29791358
Policy log std Max           0.046095908
Policy log std Min           -2.6930082
Z mean eval                  1.8246889
Z variance eval              0.07085391
total_rewards                [ 9730.15613255  9812.13415365  9857.57735841 10323.45587015
 10065.36047988 10176.73462023 10126.22136555  9812.27137845
  9922.87451305 10046.41530766]
total_rewards_mean           9987.320117959995
total_rewards_std            180.60817036202104
total_rewards_max            10323.455870148886
total_rewards_min            9730.156132553591
Number of train steps total  1348000
Number of env steps total    4046000
Number of rollouts total     0
Train Time (s)               145.4739891490899
(Previous) Eval Time (s)     20.769424594007432
Sample Time (s)              6.486803446430713
Epoch Time (s)               172.73021718952805
Total Train Time (s)         57673.643714384176
Epoch                        336
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:54:52.884071 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #336 | Epoch Duration: 173.014244556427
2020-01-12 23:54:52.884253 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #336 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.824501
Z variance train             0.07071011
KL Divergence                45.61443
KL Loss                      4.561443
QF Loss                      85.25052
VF Loss                      48.875824
Policy Loss                  -1370.4395
Q Predictions Mean           1368.4302
Q Predictions Std            1328.7148
Q Predictions Max            4577.7383
Q Predictions Min            669.1449
V Predictions Mean           1371.7151
V Predictions Std            1328.5729
V Predictions Max            4549.5093
V Predictions Min            672.7522
Log Pis Mean                 -0.400388
Log Pis Std                  3.6268806
Log Pis Max                  12.760285
Log Pis Min                  -6.7662034
Policy mu Mean               -0.0032765232
Policy mu Std                0.8468688
Policy mu Max                3.3513446
Policy mu Min                -2.7041373
Policy log std Mean          -0.5001902
Policy log std Std           0.27603158
Policy log std Max           0.05202961
Policy log std Min           -2.622629
Z mean eval                  1.8296293
Z variance eval              0.094293915
total_rewards                [ 9631.65818954  9928.71277106  9845.66783413 10031.04288806
 10065.93011192  9775.85204384 10113.9492131   9946.52752081
 10057.86276787  9785.65739573]
total_rewards_mean           9918.286073606843
total_rewards_std            147.81462918669575
total_rewards_max            10113.949213101807
total_rewards_min            9631.658189540587
Number of train steps total  1352000
Number of env steps total    4058000
Number of rollouts total     0
Train Time (s)               148.26231301994994
(Previous) Eval Time (s)     20.64838545070961
Sample Time (s)              6.387514457572252
Epoch Time (s)               175.2982129282318
Total Train Time (s)         57849.02417322993
Epoch                        337
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-12 23:57:48.268345 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #337 | Epoch Duration: 175.38394713401794
2020-01-12 23:57:48.268534 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8250828
Z variance train             0.094017506
KL Divergence                44.817734
KL Loss                      4.4817734
QF Loss                      4183.844
VF Loss                      72.870056
Policy Loss                  -1231.5205
Q Predictions Mean           1232.4106
Q Predictions Std            1214.4067
Q Predictions Max            4522.7876
Q Predictions Min            658.5801
V Predictions Mean           1236.3867
V Predictions Std            1213.8818
V Predictions Max            4519.9517
V Predictions Min            654.58514
Log Pis Mean                 -0.69964486
Log Pis Std                  3.683207
Log Pis Max                  14.469589
Log Pis Min                  -7.6673164
Policy mu Mean               0.039348017
Policy mu Std                0.8262759
Policy mu Max                2.5949953
Policy mu Min                -2.9042504
Policy log std Mean          -0.48851028
Policy log std Std           0.2957867
Policy log std Max           0.16578472
Policy log std Min           -2.82328
Z mean eval                  1.8247025
Z variance eval              0.062182963
total_rewards                [ 9539.86456534  9697.00914038  9626.64320358  9529.56695084
 10016.31351664  9869.92514756  9563.22733402  9802.43377464
  9701.08057946  9410.98855929]
total_rewards_mean           9675.705277176205
total_rewards_std            171.9987291747585
total_rewards_max            10016.313516643248
total_rewards_min            9410.98855929051
Number of train steps total  1356000
Number of env steps total    4070000
Number of rollouts total     0
Train Time (s)               147.1937460140325
(Previous) Eval Time (s)     20.916537881828845
Sample Time (s)              6.33578815497458
Epoch Time (s)               174.44607205083594
Total Train Time (s)         58023.614666817244
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:00:42.861713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #338 | Epoch Duration: 174.59305262565613
2020-01-13 00:00:42.861861 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8255999
Z variance train             0.0622875
KL Divergence                45.940117
KL Loss                      4.594012
QF Loss                      1009.62006
VF Loss                      67.70579
Policy Loss                  -1332.5548
Q Predictions Mean           1329.6956
Q Predictions Std            1272.8235
Q Predictions Max            4699.8286
Q Predictions Min            647.429
V Predictions Mean           1332.437
V Predictions Std            1270.4755
V Predictions Max            4676.386
V Predictions Min            672.6284
Log Pis Mean                 -0.11108866
Log Pis Std                  3.7952259
Log Pis Max                  20.280216
Log Pis Min                  -5.350403
Policy mu Mean               0.021614274
Policy mu Std                0.88503253
Policy mu Max                5.219601
Policy mu Min                -2.9790115
Policy log std Mean          -0.5124027
Policy log std Std           0.2880978
Policy log std Max           0.037814856
Policy log std Min           -2.7916653
Z mean eval                  1.8409512
Z variance eval              0.06553675
total_rewards                [9624.70690371 9884.88730146 9916.69437527 9872.98334827 9952.02085798
 9862.52642801 9925.1325537  9872.14114155 9627.83233539 9877.86008259]
total_rewards_mean           9841.678532792164
total_rewards_std            110.94726761029656
total_rewards_max            9952.020857981466
total_rewards_min            9624.70690370725
Number of train steps total  1360000
Number of env steps total    4082000
Number of rollouts total     0
Train Time (s)               147.41266050515696
(Previous) Eval Time (s)     17.556980613153428
Sample Time (s)              6.339962052181363
Epoch Time (s)               171.30960317049176
Total Train Time (s)         58194.998364359606
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:03:34.248746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #339 | Epoch Duration: 171.3867838382721
2020-01-13 00:03:34.248865 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8405278
Z variance train             0.065351084
KL Divergence                46.034184
KL Loss                      4.6034184
QF Loss                      138.38667
VF Loss                      70.109726
Policy Loss                  -1401.8776
Q Predictions Mean           1400.2915
Q Predictions Std            1347.1049
Q Predictions Max            4559.214
Q Predictions Min            650.71814
V Predictions Mean           1396.9766
V Predictions Std            1342.2205
V Predictions Max            4536.4253
V Predictions Min            655.40533
Log Pis Mean                 -0.23670647
Log Pis Std                  4.1280675
Log Pis Max                  15.618782
Log Pis Min                  -8.191832
Policy mu Mean               0.065535516
Policy mu Std                0.8892071
Policy mu Max                2.897707
Policy mu Min                -3.1344872
Policy log std Mean          -0.5033185
Policy log std Std           0.30009052
Policy log std Max           0.14634961
Policy log std Min           -2.7476664
Z mean eval                  1.8498852
Z variance eval              0.07301996
total_rewards                [8023.06173584 8156.78576302 8288.87301534 8330.54136651 8104.12629644
 8371.20349841 8174.80098978 8153.93947439 8255.33552314 8419.98045885]
total_rewards_mean           8227.864812170876
total_rewards_std            119.60852506659585
total_rewards_max            8419.980458845694
total_rewards_min            8023.061735839242
Number of train steps total  1364000
Number of env steps total    4094000
Number of rollouts total     0
Train Time (s)               146.22127603320405
(Previous) Eval Time (s)     20.8803131300956
Sample Time (s)              8.344155779574066
Epoch Time (s)               175.44574494287372
Total Train Time (s)         58370.52180456743
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:06:29.774582 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #340 | Epoch Duration: 175.52561902999878
2020-01-13 00:06:29.774756 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.852677
Z variance train             0.07317206
KL Divergence                46.112698
KL Loss                      4.61127
QF Loss                      221.73683
VF Loss                      47.9816
Policy Loss                  -1299.4442
Q Predictions Mean           1295.6025
Q Predictions Std            1249.2568
Q Predictions Max            4577.008
Q Predictions Min            661.2148
V Predictions Mean           1297.1434
V Predictions Std            1245.9032
V Predictions Max            4561.2017
V Predictions Min            674.25726
Log Pis Mean                 -0.38822836
Log Pis Std                  3.896987
Log Pis Max                  15.256684
Log Pis Min                  -7.558311
Policy mu Mean               -0.011467062
Policy mu Std                0.86836106
Policy mu Max                2.660948
Policy mu Min                -2.9300728
Policy log std Mean          -0.50153524
Policy log std Std           0.29677328
Policy log std Max           -0.05904159
Policy log std Min           -2.5435028
Z mean eval                  1.8404335
Z variance eval              0.11922457
total_rewards                [ 9949.17734456  9749.32314102  9965.42005497  9922.84195161
 10090.88565048 10042.02506564  9715.36662084  9884.44602747
  9915.32501267  9990.74855602]
total_rewards_mean           9922.555942527808
total_rewards_std            111.4655902011986
total_rewards_max            10090.885650483751
total_rewards_min            9715.366620836106
Number of train steps total  1368000
Number of env steps total    4106000
Number of rollouts total     0
Train Time (s)               148.3010449227877
(Previous) Eval Time (s)     20.393329040147364
Sample Time (s)              6.4877264546230435
Epoch Time (s)               175.1821004175581
Total Train Time (s)         58545.78569179773
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:09:25.045006 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #341 | Epoch Duration: 175.2701325416565
2020-01-13 00:09:25.045171 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8391638
Z variance train             0.1193429
KL Divergence                45.02854
KL Loss                      4.5028543
QF Loss                      4055.372
VF Loss                      72.47125
Policy Loss                  -1606.7693
Q Predictions Mean           1604.4607
Q Predictions Std            1460.5403
Q Predictions Max            4598.351
Q Predictions Min            657.5799
V Predictions Mean           1609.1652
V Predictions Std            1458.1654
V Predictions Max            4597.1987
V Predictions Min            663.2641
Log Pis Mean                 -0.00095997006
Log Pis Std                  4.153386
Log Pis Max                  16.298584
Log Pis Min                  -7.849018
Policy mu Mean               -0.056151617
Policy mu Std                0.9105393
Policy mu Max                2.6859853
Policy mu Min                -2.9017134
Policy log std Mean          -0.53383493
Policy log std Std           0.31036174
Policy log std Max           0.19569308
Policy log std Min           -2.6190486
Z mean eval                  1.8432564
Z variance eval              0.069820076
total_rewards                [ 9739.77145273  9634.20961977 10036.87528429  9630.93634981
  9791.43967253  9562.07171998  9804.04636005  9821.64637661
  9862.06044876  9856.17183853]
total_rewards_mean           9773.92291230462
total_rewards_std            131.59827514617575
total_rewards_max            10036.875284287935
total_rewards_min            9562.071719977088
Number of train steps total  1372000
Number of env steps total    4118000
Number of rollouts total     0
Train Time (s)               146.87822971399873
(Previous) Eval Time (s)     18.241755773779005
Sample Time (s)              6.427176746539772
Epoch Time (s)               171.5471622343175
Total Train Time (s)         58717.42795168236
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:12:16.691863 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #342 | Epoch Duration: 171.6465549468994
2020-01-13 00:12:16.692070 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8436859
Z variance train             0.06977452
KL Divergence                47.05431
KL Loss                      4.705431
QF Loss                      216.69626
VF Loss                      33.445423
Policy Loss                  -1271.9297
Q Predictions Mean           1268.6332
Q Predictions Std            1242.551
Q Predictions Max            4512.7534
Q Predictions Min            650.5856
V Predictions Mean           1271.3823
V Predictions Std            1240.1438
V Predictions Max            4501.913
V Predictions Min            659.3523
Log Pis Mean                 -0.7987901
Log Pis Std                  3.4466445
Log Pis Max                  11.477796
Log Pis Min                  -6.851809
Policy mu Mean               -0.008658107
Policy mu Std                0.8267645
Policy mu Max                2.8384542
Policy mu Min                -2.871006
Policy log std Mean          -0.48863062
Policy log std Std           0.28352392
Policy log std Max           0.005528748
Policy log std Min           -2.7160075
Z mean eval                  1.8291639
Z variance eval              0.10008357
total_rewards                [ 9918.42413959 10198.88004905 10074.01287068  9736.97627757
 10131.57418062  9895.28044424  9968.31054893 10008.13868258
  9970.85469948  9993.90350788]
total_rewards_mean           9989.635540061408
total_rewards_std            122.48595176056602
total_rewards_max            10198.880049045581
total_rewards_min            9736.976277569733
Number of train steps total  1376000
Number of env steps total    4130000
Number of rollouts total     0
Train Time (s)               146.69321072567254
(Previous) Eval Time (s)     20.772946750279516
Sample Time (s)              6.493485406041145
Epoch Time (s)               173.9596428819932
Total Train Time (s)         58891.47322723316
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:15:10.739983 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #343 | Epoch Duration: 174.047771692276
2020-01-13 00:15:10.740114 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8286438
Z variance train             0.10022275
KL Divergence                46.168427
KL Loss                      4.6168427
QF Loss                      189.30765
VF Loss                      56.32193
Policy Loss                  -1362.183
Q Predictions Mean           1360.7943
Q Predictions Std            1323.7476
Q Predictions Max            4488.953
Q Predictions Min            674.7807
V Predictions Mean           1364.8024
V Predictions Std            1321.1168
V Predictions Max            4502.7417
V Predictions Min            660.0426
Log Pis Mean                 -0.15203883
Log Pis Std                  3.9195986
Log Pis Max                  16.629911
Log Pis Min                  -7.454934
Policy mu Mean               0.02080444
Policy mu Std                0.90160733
Policy mu Max                3.1080942
Policy mu Min                -3.4374814
Policy log std Mean          -0.5110834
Policy log std Std           0.30277073
Policy log std Max           -0.042701185
Policy log std Min           -2.8012547
Z mean eval                  1.833217
Z variance eval              0.093521655
total_rewards                [9256.60445543 9246.75927937 9640.34548032 9391.84179435 9391.94449892
 9265.15321437 9375.99236938 9342.3712048  9525.39571121 9264.99054682]
total_rewards_mean           9370.139855497135
total_rewards_std            122.08966069483756
total_rewards_max            9640.345480315169
total_rewards_min            9246.759279371354
Number of train steps total  1380000
Number of env steps total    4142000
Number of rollouts total     0
Train Time (s)               146.74374176608399
(Previous) Eval Time (s)     17.42936285911128
Sample Time (s)              6.314222876448184
Epoch Time (s)               170.48732750164345
Total Train Time (s)         59062.28018979821
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:18:01.569327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #344 | Epoch Duration: 170.82907724380493
2020-01-13 00:18:01.569579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8334459
Z variance train             0.09328767
KL Divergence                46.81523
KL Loss                      4.6815233
QF Loss                      121.86545
VF Loss                      60.815144
Policy Loss                  -1323.2635
Q Predictions Mean           1318.1304
Q Predictions Std            1193.3145
Q Predictions Max            4491.0635
Q Predictions Min            678.69885
V Predictions Mean           1325.1672
V Predictions Std            1191.5223
V Predictions Max            4475.6978
V Predictions Min            678.47534
Log Pis Mean                 -0.36271286
Log Pis Std                  3.7822237
Log Pis Max                  19.356867
Log Pis Min                  -6.2234683
Policy mu Mean               -0.03377303
Policy mu Std                0.8807373
Policy mu Max                3.0925176
Policy mu Min                -4.3731294
Policy log std Mean          -0.5054669
Policy log std Std           0.2856803
Policy log std Max           0.48508108
Policy log std Min           -2.4486349
Z mean eval                  1.8328295
Z variance eval              0.0922366
total_rewards                [9736.86242955 9878.57574357 9904.59337075 9699.81917271 9730.37970448
 9722.66113182 9864.93294729 9855.3821113  9746.37018483 9875.98186864]
total_rewards_mean           9801.555866492736
total_rewards_std            76.0745804122873
total_rewards_max            9904.593370746583
total_rewards_min            9699.81917270711
Number of train steps total  1384000
Number of env steps total    4154000
Number of rollouts total     0
Train Time (s)               146.60409619892016
(Previous) Eval Time (s)     20.888385785743594
Sample Time (s)              6.488904841244221
Epoch Time (s)               173.98138682590798
Total Train Time (s)         59236.375948396046
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:20:55.649698 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #345 | Epoch Duration: 174.07993912696838
2020-01-13 00:20:55.649839 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8321819
Z variance train             0.092349485
KL Divergence                46.684517
KL Loss                      4.668452
QF Loss                      169.61911
VF Loss                      57.880905
Policy Loss                  -1352.8619
Q Predictions Mean           1348.4375
Q Predictions Std            1304.598
Q Predictions Max            4542.7603
Q Predictions Min            681.9153
V Predictions Mean           1353.8079
V Predictions Std            1300.7972
V Predictions Max            4522.7026
V Predictions Min            679.6164
Log Pis Mean                 -0.39963818
Log Pis Std                  4.2549896
Log Pis Max                  19.321692
Log Pis Min                  -8.390442
Policy mu Mean               0.015077568
Policy mu Std                0.8698117
Policy mu Max                3.1122491
Policy mu Min                -3.1848516
Policy log std Mean          -0.48184335
Policy log std Std           0.2779943
Policy log std Max           0.078504264
Policy log std Min           -2.5302434
Z mean eval                  1.8561354
Z variance eval              0.082350455
total_rewards                [10048.48832518 10088.67384354 10421.99805828  9844.36663651
 10063.9817483  10402.79759365 10108.34191363 10403.22093857
  9862.44634161 10388.49198999]
total_rewards_mean           10163.28073892526
total_rewards_std            213.6408136376865
total_rewards_max            10421.998058275145
total_rewards_min            9844.366636511548
Number of train steps total  1388000
Number of env steps total    4166000
Number of rollouts total     0
Train Time (s)               147.08229421125725
(Previous) Eval Time (s)     20.716909378767014
Sample Time (s)              6.587531710974872
Epoch Time (s)               174.38673530099913
Total Train Time (s)         59410.84829856083
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:23:50.125172 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #346 | Epoch Duration: 174.4752335548401
2020-01-13 00:23:50.125306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #346 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8578688
Z variance train             0.08221245
KL Divergence                47.59751
KL Loss                      4.7597513
QF Loss                      221.94824
VF Loss                      143.76259
Policy Loss                  -1492.6504
Q Predictions Mean           1485.0426
Q Predictions Std            1366.2386
Q Predictions Max            4558.7456
Q Predictions Min            668.2183
V Predictions Mean           1487.175
V Predictions Std            1357.773
V Predictions Max            4521.3438
V Predictions Min            700.5715
Log Pis Mean                 0.17247921
Log Pis Std                  4.612528
Log Pis Max                  18.49457
Log Pis Min                  -7.9665833
Policy mu Mean               0.08923557
Policy mu Std                0.93457013
Policy mu Max                3.3448257
Policy mu Min                -3.331242
Policy log std Mean          -0.5322592
Policy log std Std           0.32736325
Policy log std Max           0.054721594
Policy log std Min           -2.793089
Z mean eval                  1.8566797
Z variance eval              0.13749304
total_rewards                [ 9789.68933703  9669.31464109 10171.33931157 10157.0955964
  9833.07937579  9939.17239313  9860.84328966  9798.09725865
  9935.32733124 10105.55670162]
total_rewards_mean           9925.951523618442
total_rewards_std            161.1844812601454
total_rewards_max            10171.3393115735
total_rewards_min            9669.314641091987
Number of train steps total  1392000
Number of env steps total    4178000
Number of rollouts total     0
Train Time (s)               146.39732149569318
(Previous) Eval Time (s)     17.516058631706983
Sample Time (s)              6.571978659834713
Epoch Time (s)               170.48535878723487
Total Train Time (s)         59581.41064221552
Epoch                        347
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:26:40.689612 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #347 | Epoch Duration: 170.56421089172363
2020-01-13 00:26:40.689729 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #347 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8562987
Z variance train             0.13777256
KL Divergence                47.027695
KL Loss                      4.7027698
QF Loss                      139.17206
VF Loss                      61.147087
Policy Loss                  -1377.6332
Q Predictions Mean           1372.8462
Q Predictions Std            1276.6189
Q Predictions Max            4536.1426
Q Predictions Min            676.6622
V Predictions Mean           1378.5878
V Predictions Std            1278.0819
V Predictions Max            4529.1567
V Predictions Min            678.01465
Log Pis Mean                 -0.21583363
Log Pis Std                  3.905712
Log Pis Max                  16.519909
Log Pis Min                  -7.9273834
Policy mu Mean               0.0069204415
Policy mu Std                0.90333414
Policy mu Max                3.944686
Policy mu Min                -2.9716158
Policy log std Mean          -0.50323313
Policy log std Std           0.30059195
Policy log std Max           0.16491002
Policy log std Min           -2.562983
Z mean eval                  1.8476801
Z variance eval              0.08796762
total_rewards                [ 9893.6326677  10314.17808352 10074.3805561   9897.14385363
  9928.25860642 10027.88660459 10043.41771597  9896.35844381
 10101.21600856  9848.60103678]
total_rewards_mean           10002.507357708011
total_rewards_std            133.33729787174616
total_rewards_max            10314.178083517045
total_rewards_min            9848.601036783615
Number of train steps total  1396000
Number of env steps total    4190000
Number of rollouts total     0
Train Time (s)               144.3998355390504
(Previous) Eval Time (s)     20.72651378484443
Sample Time (s)              5.65494659403339
Epoch Time (s)               170.78129591792822
Total Train Time (s)         59752.27984481864
Epoch                        348
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:29:31.561868 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #348 | Epoch Duration: 170.87204551696777
2020-01-13 00:29:31.562000 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.847317
Z variance train             0.0878471
KL Divergence                48.395638
KL Loss                      4.839564
QF Loss                      364.64505
VF Loss                      36.31974
Policy Loss                  -1256.8934
Q Predictions Mean           1255.617
Q Predictions Std            1194.6049
Q Predictions Max            4570.4443
Q Predictions Min            688.3916
V Predictions Mean           1257.1515
V Predictions Std            1188.8682
V Predictions Max            4552.7935
V Predictions Min            692.2869
Log Pis Mean                 -0.7506112
Log Pis Std                  3.6249874
Log Pis Max                  14.195293
Log Pis Min                  -10.3397455
Policy mu Mean               0.0717719
Policy mu Std                0.83563757
Policy mu Max                3.0358732
Policy mu Min                -3.126992
Policy log std Mean          -0.48148933
Policy log std Std           0.2722331
Policy log std Max           0.01765585
Policy log std Min           -2.6362927
Z mean eval                  1.8624494
Z variance eval              0.06141011
total_rewards                [ 9881.43255477 10171.29720186  9772.88319347 10010.63195647
 10057.95672567  9826.93811936 10179.25716946  9851.81571753
 10115.16513393  9874.61113506]
total_rewards_mean           9974.198890757221
total_rewards_std            143.11728296888913
total_rewards_max            10179.25716946413
total_rewards_min            9772.883193465861
Number of train steps total  1400000
Number of env steps total    4202000
Number of rollouts total     0
Train Time (s)               145.86519985971972
(Previous) Eval Time (s)     20.902857689652592
Sample Time (s)              6.479375948663801
Epoch Time (s)               173.24743349803612
Total Train Time (s)         59925.61039251974
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:32:24.893986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #349 | Epoch Duration: 173.33189129829407
2020-01-13 00:32:24.894119 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8612331
Z variance train             0.0613809
KL Divergence                48.939754
KL Loss                      4.8939757
QF Loss                      201.48355
VF Loss                      169.38062
Policy Loss                  -1380.9829
Q Predictions Mean           1379.2739
Q Predictions Std            1312.5623
Q Predictions Max            4607.2163
Q Predictions Min            681.7146
V Predictions Mean           1389.8884
V Predictions Std            1315.8057
V Predictions Max            4635.7124
V Predictions Min            695.2076
Log Pis Mean                 -0.12871502
Log Pis Std                  3.897133
Log Pis Max                  14.942531
Log Pis Min                  -7.6354218
Policy mu Mean               0.07304492
Policy mu Std                0.91413623
Policy mu Max                3.0418255
Policy mu Min                -2.800838
Policy log std Mean          -0.51091576
Policy log std Std           0.2985345
Policy log std Max           0.04423046
Policy log std Min           -2.7122142
Z mean eval                  1.849289
Z variance eval              0.07283457
total_rewards                [ 9575.07457336  9911.81803409  9764.07129512 10263.62059012
 10031.05259721 10091.10105023  9978.61951248 10189.22572734
 10232.19481941 10036.07713881]
total_rewards_mean           10007.285533816232
total_rewards_std            203.39818509340697
total_rewards_max            10263.620590121665
total_rewards_min            9575.074573362768
Number of train steps total  1404000
Number of env steps total    4214000
Number of rollouts total     0
Train Time (s)               146.51579332724214
(Previous) Eval Time (s)     20.802566334605217
Sample Time (s)              6.556663405150175
Epoch Time (s)               173.87502306699753
Total Train Time (s)         60099.566186717246
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:35:18.853347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #350 | Epoch Duration: 173.9591302871704
2020-01-13 00:35:18.853479 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #350 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8497334
Z variance train             0.072962254
KL Divergence                49.548218
KL Loss                      4.954822
QF Loss                      175.31404
VF Loss                      74.50957
Policy Loss                  -1515.1267
Q Predictions Mean           1512.0448
Q Predictions Std            1375.5514
Q Predictions Max            4550.8916
Q Predictions Min            685.2018
V Predictions Mean           1518.4492
V Predictions Std            1375.366
V Predictions Max            4551.167
V Predictions Min            687.09033
Log Pis Mean                 0.45178097
Log Pis Std                  4.450904
Log Pis Max                  18.46
Log Pis Min                  -6.643337
Policy mu Mean               0.02468059
Policy mu Std                0.9767721
Policy mu Max                3.108381
Policy mu Min                -3.3104708
Policy log std Mean          -0.5204467
Policy log std Std           0.30388638
Policy log std Max           -0.044879615
Policy log std Min           -2.8399036
Z mean eval                  1.8619545
Z variance eval              0.07303933
total_rewards                [ 9979.10349783 10264.60921311  9662.38602866 10071.94888796
 10076.36003757 10059.36458107  9989.6812923  10184.77317964
 10163.29496566 10095.15153305]
total_rewards_mean           10054.66732168357
total_rewards_std            154.61275739747015
total_rewards_max            10264.6092131054
total_rewards_min            9662.386028659937
Number of train steps total  1408000
Number of env steps total    4226000
Number of rollouts total     0
Train Time (s)               149.47894290694967
(Previous) Eval Time (s)     20.69077391922474
Sample Time (s)              6.454261219128966
Epoch Time (s)               176.62397804530337
Total Train Time (s)         60276.27410187572
Epoch                        351
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:38:15.564746 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #351 | Epoch Duration: 176.71116828918457
2020-01-13 00:38:15.564888 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #351 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8631217
Z variance train             0.073069274
KL Divergence                49.00699
KL Loss                      4.900699
QF Loss                      142.3876
VF Loss                      73.71319
Policy Loss                  -1366.8645
Q Predictions Mean           1363.7317
Q Predictions Std            1278.6663
Q Predictions Max            4601.0967
Q Predictions Min            687.04645
V Predictions Mean           1365.3843
V Predictions Std            1273.3303
V Predictions Max            4593.2095
V Predictions Min            692.2533
Log Pis Mean                 -0.08354321
Log Pis Std                  4.1205335
Log Pis Max                  17.510796
Log Pis Min                  -8.025678
Policy mu Mean               0.083417766
Policy mu Std                0.9105896
Policy mu Max                3.5714743
Policy mu Min                -3.2962334
Policy log std Mean          -0.52076554
Policy log std Std           0.30777198
Policy log std Max           0.013059527
Policy log std Min           -2.819493
Z mean eval                  1.8504517
Z variance eval              0.07553662
total_rewards                [ 9692.10201096  9969.87007202  9715.89969848  9815.3044551
  9739.58471661  9613.31581595 10017.35727552  9919.87746519
  9818.65449238  9796.29686839]
total_rewards_mean           9809.826287058997
total_rewards_std            121.37414530727435
total_rewards_max            10017.35727552313
total_rewards_min            9613.31581595248
Number of train steps total  1412000
Number of env steps total    4238000
Number of rollouts total     0
Train Time (s)               146.28346044383943
(Previous) Eval Time (s)     20.740760545246303
Sample Time (s)              6.457725353073329
Epoch Time (s)               173.48194634215906
Total Train Time (s)         60449.85863009794
Epoch                        352
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:41:09.159346 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #352 | Epoch Duration: 173.5943579673767
2020-01-13 00:41:09.159484 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #352 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8483646
Z variance train             0.07544076
KL Divergence                47.94437
KL Loss                      4.794437
QF Loss                      122.53633
VF Loss                      91.2699
Policy Loss                  -1531.867
Q Predictions Mean           1531.8639
Q Predictions Std            1408.1052
Q Predictions Max            4578.7666
Q Predictions Min            682.3524
V Predictions Mean           1526.6578
V Predictions Std            1399.3855
V Predictions Max            4558.5127
V Predictions Min            678.58826
Log Pis Mean                 0.080535874
Log Pis Std                  3.8680766
Log Pis Max                  14.609116
Log Pis Min                  -7.5763226
Policy mu Mean               0.016443362
Policy mu Std                0.9041299
Policy mu Max                2.6854074
Policy mu Min                -2.6100526
Policy log std Mean          -0.52228695
Policy log std Std           0.3077607
Policy log std Max           -0.018633366
Policy log std Min           -2.866218
Z mean eval                  1.8480438
Z variance eval              0.10293715
total_rewards                [ 9749.29482221 10152.89426882 10029.66766913  9801.08822929
  9926.55501404 10303.59222372 10051.18159903 10277.44994168
  9759.82820295 10214.72483577]
total_rewards_mean           10026.627680664235
total_rewards_std            200.13374294095095
total_rewards_max            10303.592223724412
total_rewards_min            9749.294822207728
Number of train steps total  1416000
Number of env steps total    4250000
Number of rollouts total     0
Train Time (s)               147.1821274808608
(Previous) Eval Time (s)     20.9338300623931
Sample Time (s)              6.5439105136319995
Epoch Time (s)               174.6598680568859
Total Train Time (s)         60624.602142375894
Epoch                        353
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:44:03.903043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #353 | Epoch Duration: 174.74346256256104
2020-01-13 00:44:03.903178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #353 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.848726
Z variance train             0.10251161
KL Divergence                47.63917
KL Loss                      4.7639174
QF Loss                      178.12326
VF Loss                      95.31075
Policy Loss                  -1442.6187
Q Predictions Mean           1439.0608
Q Predictions Std            1351.3805
Q Predictions Max            4561.414
Q Predictions Min            665.60114
V Predictions Mean           1438.8865
V Predictions Std            1350.205
V Predictions Max            4562.9106
V Predictions Min            689.83905
Log Pis Mean                 0.27439058
Log Pis Std                  4.2074466
Log Pis Max                  18.740677
Log Pis Min                  -8.208524
Policy mu Mean               0.11083261
Policy mu Std                0.9305595
Policy mu Max                3.0914378
Policy mu Min                -3.489496
Policy log std Mean          -0.5177876
Policy log std Std           0.29663217
Policy log std Max           0.11405349
Policy log std Min           -2.904211
Z mean eval                  1.881594
Z variance eval              0.06506904
total_rewards                [ 9775.58560389  9946.42181755 10018.1874166   9569.40172085
  9851.79930825 10098.20192068  9980.370648    9840.53365642
 10021.8291443   9954.22374534]
total_rewards_mean           9905.655498187816
total_rewards_std            144.90104147726095
total_rewards_max            10098.20192068184
total_rewards_min            9569.401720847662
Number of train steps total  1420000
Number of env steps total    4262000
Number of rollouts total     0
Train Time (s)               146.25058292178437
(Previous) Eval Time (s)     20.748722524847835
Sample Time (s)              6.500010514631867
Epoch Time (s)               173.49931596126407
Total Train Time (s)         60798.182764337864
Epoch                        354
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:46:57.485258 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #354 | Epoch Duration: 173.58198308944702
2020-01-13 00:46:57.485392 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #354 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.881538
Z variance train             0.06492968
KL Divergence                49.040997
KL Loss                      4.9041
QF Loss                      124.8899
VF Loss                      173.06395
Policy Loss                  -1229.473
Q Predictions Mean           1225.2249
Q Predictions Std            1172.5316
Q Predictions Max            4591.919
Q Predictions Min            655.1089
V Predictions Mean           1228.7463
V Predictions Std            1170.1934
V Predictions Max            4561.577
V Predictions Min            697.51636
Log Pis Mean                 -0.36916476
Log Pis Std                  3.876764
Log Pis Max                  18.25143
Log Pis Min                  -6.772699
Policy mu Mean               0.058277216
Policy mu Std                0.86661
Policy mu Max                3.0480905
Policy mu Min                -4.089854
Policy log std Mean          -0.52049613
Policy log std Std           0.29545557
Policy log std Max           -0.06434187
Policy log std Min           -2.8631225
Z mean eval                  1.8537203
Z variance eval              0.06058227
total_rewards                [ 9892.78693415  9750.10655888 10007.58970216 10324.3781215
 10204.16504838 10063.0023127  10169.78499054  9883.53248682
 10218.18426989 10045.08894906]
total_rewards_mean           10055.861937407806
total_rewards_std            169.0255170560671
total_rewards_max            10324.378121500093
total_rewards_min            9750.10655887887
Number of train steps total  1424000
Number of env steps total    4274000
Number of rollouts total     0
Train Time (s)               147.11119894869626
(Previous) Eval Time (s)     19.31167462375015
Sample Time (s)              6.345767810475081
Epoch Time (s)               172.7686413829215
Total Train Time (s)         60971.03306262847
Epoch                        355
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:49:50.341769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #355 | Epoch Duration: 172.85626339912415
2020-01-13 00:49:50.341960 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #355 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8537728
Z variance train             0.06055795
KL Divergence                48.08824
KL Loss                      4.808824
QF Loss                      167.72624
VF Loss                      103.606026
Policy Loss                  -1349.9442
Q Predictions Mean           1347.8163
Q Predictions Std            1270.4658
Q Predictions Max            4644.329
Q Predictions Min            701.39075
V Predictions Mean           1347.0519
V Predictions Std            1269.458
V Predictions Max            4650.618
V Predictions Min            703.61804
Log Pis Mean                 -0.5167564
Log Pis Std                  3.748653
Log Pis Max                  18.7029
Log Pis Min                  -7.2248955
Policy mu Mean               0.03163379
Policy mu Std                0.8548907
Policy mu Max                3.020635
Policy mu Min                -2.6186583
Policy log std Mean          -0.50243783
Policy log std Std           0.2804168
Policy log std Max           0.075195074
Policy log std Min           -2.5525265
Z mean eval                  1.8609943
Z variance eval              0.07598624
total_rewards                [ 9635.35765255  9945.89512493 10219.18388148 10097.3103237
 10359.51130764  9982.73988636 10064.82170716  1493.34001155
  9988.05244381  9989.74257633]
total_rewards_mean           9177.595491550785
total_rewards_std            2567.6286873372906
total_rewards_max            10359.511307635656
total_rewards_min            1493.3400115500292
Number of train steps total  1428000
Number of env steps total    4286000
Number of rollouts total     0
Train Time (s)               144.66256770538166
(Previous) Eval Time (s)     20.904944290407002
Sample Time (s)              6.385996394790709
Epoch Time (s)               171.95350839057937
Total Train Time (s)         61143.07343854988
Epoch                        356
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:52:42.386135 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #356 | Epoch Duration: 172.04404473304749
2020-01-13 00:52:42.386267 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #356 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8611896
Z variance train             0.07605184
KL Divergence                47.679867
KL Loss                      4.767987
QF Loss                      102.41341
VF Loss                      44.615925
Policy Loss                  -1351.1964
Q Predictions Mean           1346.0148
Q Predictions Std            1272.4662
Q Predictions Max            4552.6587
Q Predictions Min            692.18475
V Predictions Mean           1348.2103
V Predictions Std            1270.2443
V Predictions Max            4552.68
V Predictions Min            693.6235
Log Pis Mean                 -0.16995054
Log Pis Std                  4.2517753
Log Pis Max                  20.572536
Log Pis Min                  -7.159783
Policy mu Mean               0.07527397
Policy mu Std                0.8977369
Policy mu Max                3.5874307
Policy mu Min                -3.1016245
Policy log std Mean          -0.51815176
Policy log std Std           0.30474165
Policy log std Max           0.27702963
Policy log std Min           -2.7268133
Z mean eval                  1.8264391
Z variance eval              0.08286072
total_rewards                [ 9563.60775766  9571.12015623  9977.07050095  9869.33029534
  9726.23734422  9838.94996982  9853.38106536  9772.00856347
  9580.40896966 10013.41900545]
total_rewards_mean           9776.553362817434
total_rewards_std            155.977389391517
total_rewards_max            10013.419005450085
total_rewards_min            9563.607757663869
Number of train steps total  1432000
Number of env steps total    4298000
Number of rollouts total     0
Train Time (s)               145.15819940716028
(Previous) Eval Time (s)     17.74588004918769
Sample Time (s)              6.478155167773366
Epoch Time (s)               169.38223462412134
Total Train Time (s)         61312.53783490928
Epoch                        357
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:55:31.854200 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #357 | Epoch Duration: 169.4678177833557
2020-01-13 00:55:31.854380 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #357 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8244965
Z variance train             0.08283038
KL Divergence                45.287586
KL Loss                      4.5287585
QF Loss                      565.8202
VF Loss                      198.26428
Policy Loss                  -1375.8119
Q Predictions Mean           1373.8086
Q Predictions Std            1288.2517
Q Predictions Max            4712.8315
Q Predictions Min            713.46686
V Predictions Mean           1373.4158
V Predictions Std            1286.5881
V Predictions Max            4707.641
V Predictions Min            706.75323
Log Pis Mean                 -0.2391325
Log Pis Std                  4.014742
Log Pis Max                  17.647861
Log Pis Min                  -6.113115
Policy mu Mean               0.14753209
Policy mu Std                0.90652937
Policy mu Max                3.3243134
Policy mu Min                -2.7243736
Policy log std Mean          -0.50081897
Policy log std Std           0.3179667
Policy log std Max           0.020028293
Policy log std Min           -3.0257497
Z mean eval                  1.8421446
Z variance eval              0.0826164
total_rewards                [ 9669.86430105  9734.03042479  9992.33192812  9928.24122598
  9791.60967291  9957.0152517   9869.64994211  9860.45286806
 10022.95394319 10001.3248589 ]
total_rewards_mean           9882.747441680021
total_rewards_std            113.89613105986167
total_rewards_max            10022.953943187596
total_rewards_min            9669.864301047337
Number of train steps total  1436000
Number of env steps total    4310000
Number of rollouts total     0
Train Time (s)               146.02048127399758
(Previous) Eval Time (s)     20.861144644673914
Sample Time (s)              6.463406052440405
Epoch Time (s)               173.3450319711119
Total Train Time (s)         61486.077863588
Epoch                        358
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 00:58:25.414847 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #358 | Epoch Duration: 173.56033635139465
2020-01-13 00:58:25.415109 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8453735
Z variance train             0.082847096
KL Divergence                45.6274
KL Loss                      4.56274
QF Loss                      144.40259
VF Loss                      33.046715
Policy Loss                  -1242.2997
Q Predictions Mean           1239.3613
Q Predictions Std            1147.5435
Q Predictions Max            4612.604
Q Predictions Min            692.2751
V Predictions Mean           1243.0227
V Predictions Std            1149.7834
V Predictions Max            4602.748
V Predictions Min            700.3417
Log Pis Mean                 -0.4797287
Log Pis Std                  3.483205
Log Pis Max                  17.585466
Log Pis Min                  -7.358797
Policy mu Mean               0.010662545
Policy mu Std                0.84263384
Policy mu Max                3.5719917
Policy mu Min                -3.1559563
Policy log std Mean          -0.4629661
Policy log std Std           0.27142653
Policy log std Max           0.30314738
Policy log std Min           -2.6692352
Z mean eval                  1.8548696
Z variance eval              0.0680264
total_rewards                [ 9701.18640983  9850.2866486   9818.77297475  9761.97032535
  9817.44027499  9539.35563946  9882.56401639  9933.75798989
 10071.13100509  9777.0935673 ]
total_rewards_mean           9815.355885164772
total_rewards_std            133.68541819667448
total_rewards_max            10071.131005088248
total_rewards_min            9539.355639464899
Number of train steps total  1440000
Number of env steps total    4322000
Number of rollouts total     0
Train Time (s)               148.36556641198695
(Previous) Eval Time (s)     20.98266609897837
Sample Time (s)              6.348034780006856
Epoch Time (s)               175.69626729097217
Total Train Time (s)         61661.88767816126
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:01:21.209103 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #359 | Epoch Duration: 175.79378366470337
2020-01-13 01:01:21.209237 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8570051
Z variance train             0.06794588
KL Divergence                46.47085
KL Loss                      4.647085
QF Loss                      271.49536
VF Loss                      38.072727
Policy Loss                  -1279.5435
Q Predictions Mean           1278.6025
Q Predictions Std            1184.7512
Q Predictions Max            4488.761
Q Predictions Min            687.24774
V Predictions Mean           1279.2676
V Predictions Std            1183.8655
V Predictions Max            4477.689
V Predictions Min            694.147
Log Pis Mean                 -0.57549506
Log Pis Std                  3.497228
Log Pis Max                  12.042032
Log Pis Min                  -9.439621
Policy mu Mean               0.053488106
Policy mu Std                0.8236874
Policy mu Max                2.7926624
Policy mu Min                -2.3891802
Policy log std Mean          -0.49153543
Policy log std Std           0.29494715
Policy log std Max           0.15815002
Policy log std Min           -2.7477162
Z mean eval                  1.8577036
Z variance eval              0.077561885
total_rewards                [9909.57666816 9834.86818363 9949.27741223 9879.30276137 9597.68890918
 9641.7788345  9821.77746795 9907.42684598 9687.71375456 9810.16437416]
total_rewards_mean           9803.957521171833
total_rewards_std            115.03430179874155
total_rewards_max            9949.277412226642
total_rewards_min            9597.688909179962
Number of train steps total  1444000
Number of env steps total    4334000
Number of rollouts total     0
Train Time (s)               145.26331496797502
(Previous) Eval Time (s)     20.701958978082985
Sample Time (s)              8.133673972915858
Epoch Time (s)               174.09894791897386
Total Train Time (s)         61836.07495500101
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:04:15.398303 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #360 | Epoch Duration: 174.18896770477295
2020-01-13 01:04:15.398437 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #360 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8587701
Z variance train             0.0776149
KL Divergence                47.738262
KL Loss                      4.773826
QF Loss                      8217.021
VF Loss                      88.303185
Policy Loss                  -1339.2173
Q Predictions Mean           1337.9532
Q Predictions Std            1272.3597
Q Predictions Max            4601.986
Q Predictions Min            681.8224
V Predictions Mean           1333.7246
V Predictions Std            1268.4474
V Predictions Max            4592.4478
V Predictions Min            690.299
Log Pis Mean                 -0.5095546
Log Pis Std                  3.242269
Log Pis Max                  13.790972
Log Pis Min                  -6.340557
Policy mu Mean               0.021975951
Policy mu Std                0.8417512
Policy mu Max                2.8337297
Policy mu Min                -2.7334628
Policy log std Mean          -0.49032807
Policy log std Std           0.27623418
Policy log std Max           -0.006203145
Policy log std Min           -2.6114874
Z mean eval                  1.8440173
Z variance eval              0.07079522
total_rewards                [10095.58359704  9892.28554026 10096.86166888  9783.58384837
 10153.03301476  9916.31845991  9908.50525524  9852.9577162
  9844.40684351 10094.41179203]
total_rewards_mean           9963.794773619033
total_rewards_std            125.45350548942909
total_rewards_max            10153.033014763696
total_rewards_min            9783.583848368264
Number of train steps total  1448000
Number of env steps total    4346000
Number of rollouts total     0
Train Time (s)               148.2155560622923
(Previous) Eval Time (s)     20.930695451330394
Sample Time (s)              6.528435806278139
Epoch Time (s)               175.67468731990084
Total Train Time (s)         62011.83573226398
Epoch                        361
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:07:11.162423 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #361 | Epoch Duration: 175.7638909816742
2020-01-13 01:07:11.162556 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #361 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.845287
Z variance train             0.0708726
KL Divergence                47.243793
KL Loss                      4.7243795
QF Loss                      4779.64
VF Loss                      69.33417
Policy Loss                  -1353.4777
Q Predictions Mean           1349.2417
Q Predictions Std            1250.9185
Q Predictions Max            4650.763
Q Predictions Min            707.69324
V Predictions Mean           1352.9016
V Predictions Std            1248.5706
V Predictions Max            4632.3057
V Predictions Min            707.77527
Log Pis Mean                 -0.19530661
Log Pis Std                  3.6174672
Log Pis Max                  14.914707
Log Pis Min                  -8.072503
Policy mu Mean               0.013597135
Policy mu Std                0.8715546
Policy mu Max                3.0605924
Policy mu Min                -3.0696988
Policy log std Mean          -0.51542026
Policy log std Std           0.31585848
Policy log std Max           -0.02049321
Policy log std Min           -2.6551943
Z mean eval                  1.8383939
Z variance eval              0.10216625
total_rewards                [ 9747.25100703  9477.15740065 10080.50213657 10002.80695326
  9595.31095892  9947.56212868  9993.724023    9759.21599835
  9863.02002541 10096.05924423]
total_rewards_mean           9856.260987608945
total_rewards_std            197.3970716057565
total_rewards_max            10096.059244227885
total_rewards_min            9477.157400653656
Number of train steps total  1452000
Number of env steps total    4358000
Number of rollouts total     0
Train Time (s)               145.76617284491658
(Previous) Eval Time (s)     20.75638945400715
Sample Time (s)              6.541879638563842
Epoch Time (s)               173.06444193748757
Total Train Time (s)         62184.97846966004
Epoch                        362
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:10:04.308707 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #362 | Epoch Duration: 173.14603900909424
2020-01-13 01:10:04.308899 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8384529
Z variance train             0.1024044
KL Divergence                45.58058
KL Loss                      4.5580583
QF Loss                      133.00044
VF Loss                      42.49553
Policy Loss                  -1277.5936
Q Predictions Mean           1277.7207
Q Predictions Std            1247.397
Q Predictions Max            4627.6733
Q Predictions Min            653.8135
V Predictions Mean           1280.8682
V Predictions Std            1242.5782
V Predictions Max            4620.4062
V Predictions Min            668.04974
Log Pis Mean                 -0.5225414
Log Pis Std                  3.6151755
Log Pis Max                  15.953471
Log Pis Min                  -7.02795
Policy mu Mean               0.05737573
Policy mu Std                0.83457536
Policy mu Max                2.5235531
Policy mu Min                -2.6683047
Policy log std Mean          -0.4840764
Policy log std Std           0.27171406
Policy log std Max           0.03287661
Policy log std Min           -2.657131
Z mean eval                  1.8566902
Z variance eval              0.08506473
total_rewards                [8565.79282715 8302.88343846 9576.6493326  9109.76396899 3827.33942707
 8875.78086326 8969.05545795 9237.03507038 9378.76822853 8523.63027381]
total_rewards_mean           8436.669888820754
total_rewards_std            1582.5629934469673
total_rewards_max            9576.649332601366
total_rewards_min            3827.339427074365
Number of train steps total  1456000
Number of env steps total    4370000
Number of rollouts total     0
Train Time (s)               146.9422320551239
(Previous) Eval Time (s)     20.92936616158113
Sample Time (s)              6.510731665417552
Epoch Time (s)               174.38232988212258
Total Train Time (s)         62359.44496897096
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:12:58.779834 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #363 | Epoch Duration: 174.470805644989
2020-01-13 01:12:58.779978 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8551229
Z variance train             0.085217856
KL Divergence                46.51379
KL Loss                      4.651379
QF Loss                      342.4103
VF Loss                      83.01464
Policy Loss                  -1222.1837
Q Predictions Mean           1220.5872
Q Predictions Std            1195.9498
Q Predictions Max            4631.477
Q Predictions Min            680.1671
V Predictions Mean           1224.0249
V Predictions Std            1195.1599
V Predictions Max            4642.9175
V Predictions Min            684.22656
Log Pis Mean                 -0.61169064
Log Pis Std                  3.6577814
Log Pis Max                  17.333158
Log Pis Min                  -7.150735
Policy mu Mean               0.101583205
Policy mu Std                0.83461004
Policy mu Max                3.2144675
Policy mu Min                -3.449287
Policy log std Mean          -0.4916632
Policy log std Std           0.2684664
Policy log std Max           -0.07861376
Policy log std Min           -2.6627352
Z mean eval                  1.859567
Z variance eval              0.05522721
total_rewards                [9943.27879746 9670.63923683 9434.23258038 9687.51489152 9405.72400417
 9669.77246602 9489.11061962 9162.34213496 9512.58697135 9830.29684905]
total_rewards_mean           9580.549855136498
total_rewards_std            214.78238852540355
total_rewards_max            9943.278797462268
total_rewards_min            9162.34213496021
Number of train steps total  1460000
Number of env steps total    4382000
Number of rollouts total     0
Train Time (s)               145.78922959789634
(Previous) Eval Time (s)     17.723533776123077
Sample Time (s)              6.45414467016235
Epoch Time (s)               169.96690804418176
Total Train Time (s)         62529.49612938007
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:15:48.835190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #364 | Epoch Duration: 170.05509638786316
2020-01-13 01:15:48.835367 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8588616
Z variance train             0.05528129
KL Divergence                48.011845
KL Loss                      4.8011847
QF Loss                      74.914795
VF Loss                      40.457592
Policy Loss                  -1324.7317
Q Predictions Mean           1323.5712
Q Predictions Std            1271.4158
Q Predictions Max            4671.691
Q Predictions Min            682.2637
V Predictions Mean           1323.008
V Predictions Std            1268.6141
V Predictions Max            4662.07
V Predictions Min            686.58325
Log Pis Mean                 -0.7338573
Log Pis Std                  3.607448
Log Pis Max                  13.718275
Log Pis Min                  -6.3713765
Policy mu Mean               0.06573415
Policy mu Std                0.7943346
Policy mu Max                2.5968304
Policy mu Min                -2.9405835
Policy log std Mean          -0.4861773
Policy log std Std           0.30225545
Policy log std Max           0.055418193
Policy log std Min           -2.6381109
Z mean eval                  1.8443062
Z variance eval              0.08299732
total_rewards                [ 9930.12872019 10239.78987481 10144.94801141  9965.56291844
  9792.03097339  9969.65365723 10062.30892762 10152.05947373
  9679.74134765 10268.05087242]
total_rewards_mean           10020.427477688234
total_rewards_std            180.5540298975575
total_rewards_max            10268.05087242068
total_rewards_min            9679.741347654981
Number of train steps total  1464000
Number of env steps total    4394000
Number of rollouts total     0
Train Time (s)               145.89375209994614
(Previous) Eval Time (s)     20.67879368085414
Sample Time (s)              6.563134719617665
Epoch Time (s)               173.13568050041795
Total Train Time (s)         62702.712294443976
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:18:42.053651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #365 | Epoch Duration: 173.2181534767151
2020-01-13 01:18:42.053797 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #365 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8471782
Z variance train             0.0830139
KL Divergence                45.155277
KL Loss                      4.5155277
QF Loss                      160.79004
VF Loss                      298.30127
Policy Loss                  -1340.8502
Q Predictions Mean           1338.4514
Q Predictions Std            1262.0308
Q Predictions Max            4639.7285
Q Predictions Min            684.7921
V Predictions Mean           1340.4144
V Predictions Std            1255.2847
V Predictions Max            4623.1646
V Predictions Min            686.80914
Log Pis Mean                 -0.55714285
Log Pis Std                  3.9847658
Log Pis Max                  16.713001
Log Pis Min                  -7.876581
Policy mu Mean               0.058192234
Policy mu Std                0.8638374
Policy mu Max                3.255702
Policy mu Min                -3.4209325
Policy log std Mean          -0.47455287
Policy log std Std           0.2927251
Policy log std Max           0.06737888
Policy log std Min           -2.9541752
Z mean eval                  1.8577582
Z variance eval              0.06824687
total_rewards                [ 9771.84841364  9999.29257337  9893.23563407  9651.81948039
  9967.93187405 10219.06262493  9688.88594541 10057.35887486
 10051.29446174 10041.67127106]
total_rewards_mean           9934.240115353618
total_rewards_std            171.72790601951488
total_rewards_max            10219.062624934408
total_rewards_min            9651.819480393657
Number of train steps total  1468000
Number of env steps total    4406000
Number of rollouts total     0
Train Time (s)               145.9803829290904
(Previous) Eval Time (s)     20.722102309111506
Sample Time (s)              6.420011936221272
Epoch Time (s)               173.1224971744232
Total Train Time (s)         62875.92160390457
Epoch                        366
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:21:35.265212 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #366 | Epoch Duration: 173.21131491661072
2020-01-13 01:21:35.265347 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8582951
Z variance train             0.06823022
KL Divergence                46.25193
KL Loss                      4.625193
QF Loss                      175.5272
VF Loss                      67.889244
Policy Loss                  -1338.0399
Q Predictions Mean           1333.0883
Q Predictions Std            1257.9575
Q Predictions Max            4650.99
Q Predictions Min            687.28876
V Predictions Mean           1341.875
V Predictions Std            1262.0939
V Predictions Max            4639.9214
V Predictions Min            697.07153
Log Pis Mean                 -0.4382679
Log Pis Std                  3.9304254
Log Pis Max                  15.590043
Log Pis Min                  -7.5465384
Policy mu Mean               0.04437824
Policy mu Std                0.88996184
Policy mu Max                3.4268847
Policy mu Min                -2.6872616
Policy log std Mean          -0.48115337
Policy log std Std           0.28200895
Policy log std Max           -0.037985682
Policy log std Min           -2.8382342
Z mean eval                  1.8727022
Z variance eval              0.08660668
total_rewards                [ 9608.18074917 10091.81295236  9559.31662289 10017.17175172
  9497.90592955  9681.165552    9796.67286717  9960.37888116
  9417.4091444   9394.09950056]
total_rewards_mean           9702.41139509777
total_rewards_std            239.5938252220751
total_rewards_max            10091.812952355658
total_rewards_min            9394.099500563332
Number of train steps total  1472000
Number of env steps total    4418000
Number of rollouts total     0
Train Time (s)               145.94146282412112
(Previous) Eval Time (s)     20.794119416736066
Sample Time (s)              6.479675690177828
Epoch Time (s)               173.215257931035
Total Train Time (s)         63049.21640000399
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:24:28.563087 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #367 | Epoch Duration: 173.29764342308044
2020-01-13 01:24:28.563222 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8661268
Z variance train             0.08657605
KL Divergence                46.37815
KL Loss                      4.637815
QF Loss                      456.0761
VF Loss                      257.0418
Policy Loss                  -1237.6528
Q Predictions Mean           1237.3054
Q Predictions Std            1191.8408
Q Predictions Max            4593.918
Q Predictions Min            688.1935
V Predictions Mean           1248.4353
V Predictions Std            1196.6211
V Predictions Max            4622.269
V Predictions Min            691.36316
Log Pis Mean                 -0.59966975
Log Pis Std                  3.5812612
Log Pis Max                  12.187182
Log Pis Min                  -6.73626
Policy mu Mean               0.14193697
Policy mu Std                0.82664454
Policy mu Max                2.723677
Policy mu Min                -2.5621188
Policy log std Mean          -0.47991106
Policy log std Std           0.27289647
Policy log std Max           0.089524806
Policy log std Min           -2.7199678
Z mean eval                  1.8745295
Z variance eval              0.06753503
total_rewards                [9668.54571457 9624.70882031 9744.41060742 9701.50706788 9351.1273502
 9722.06458535 9719.97601224 9662.11569554 9431.84647722 9759.89445358]
total_rewards_mean           9638.619678429579
total_rewards_std            130.56958259908316
total_rewards_max            9759.89445358119
total_rewards_min            9351.127350200124
Number of train steps total  1476000
Number of env steps total    4430000
Number of rollouts total     0
Train Time (s)               146.59506458230317
(Previous) Eval Time (s)     20.712419072631747
Sample Time (s)              6.599893202073872
Epoch Time (s)               173.90737685700879
Total Train Time (s)         63223.208734185435
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:27:22.561034 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #368 | Epoch Duration: 173.99771571159363
2020-01-13 01:27:22.561174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8746071
Z variance train             0.067481205
KL Divergence                48.04349
KL Loss                      4.8043494
QF Loss                      90.842575
VF Loss                      28.949436
Policy Loss                  -1336.3514
Q Predictions Mean           1331.6907
Q Predictions Std            1275.9974
Q Predictions Max            4610.5044
Q Predictions Min            695.4032
V Predictions Mean           1335.9102
V Predictions Std            1272.3864
V Predictions Max            4601.1685
V Predictions Min            704.2146
Log Pis Mean                 -0.6051181
Log Pis Std                  3.6131175
Log Pis Max                  12.57281
Log Pis Min                  -7.0333786
Policy mu Mean               0.015791018
Policy mu Std                0.82429963
Policy mu Max                2.682476
Policy mu Min                -2.714042
Policy log std Mean          -0.5013218
Policy log std Std           0.29751766
Policy log std Max           -0.10248256
Policy log std Min           -2.640863
Z mean eval                  1.856795
Z variance eval              0.07131281
total_rewards                [9411.26545504 9895.06028922 9484.65731087 9659.20155837 9828.95663506
 5093.93967665 9600.89659503 9930.14684252 9727.34973159 9622.25828911]
total_rewards_mean           9225.37323834521
total_rewards_std            1386.3170583669153
total_rewards_max            9930.146842517439
total_rewards_min            5093.939676650215
Number of train steps total  1480000
Number of env steps total    4442000
Number of rollouts total     0
Train Time (s)               147.3023287258111
(Previous) Eval Time (s)     17.24756547017023
Sample Time (s)              6.497730576898903
Epoch Time (s)               171.04762477288023
Total Train Time (s)         63394.33408117015
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:30:13.690867 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #369 | Epoch Duration: 171.12958002090454
2020-01-13 01:30:13.691052 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #369 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8598144
Z variance train             0.07161415
KL Divergence                49.136944
KL Loss                      4.9136944
QF Loss                      98.16275
VF Loss                      92.626656
Policy Loss                  -1349.4565
Q Predictions Mean           1349.793
Q Predictions Std            1296.2275
Q Predictions Max            4578.64
Q Predictions Min            690.5608
V Predictions Mean           1352.8489
V Predictions Std            1299.2585
V Predictions Max            4563.395
V Predictions Min            688.2837
Log Pis Mean                 -0.9120597
Log Pis Std                  3.541335
Log Pis Max                  11.619145
Log Pis Min                  -6.994156
Policy mu Mean               0.04050609
Policy mu Std                0.84388053
Policy mu Max                3.0287564
Policy mu Min                -2.5214
Policy log std Mean          -0.4578903
Policy log std Std           0.2654365
Policy log std Max           0.14870101
Policy log std Min           -2.6645093
Z mean eval                  1.854358
Z variance eval              0.06874547
total_rewards                [ 9425.68511575 10257.69891977  9961.69950342 10111.46737541
 10202.35788256 10011.80773666 10110.55359934 10055.75321787
  2884.66001391  9899.44992654]
total_rewards_mean           9292.113329123937
total_rewards_std            2146.94422203026
total_rewards_max            10257.698919772032
total_rewards_min            2884.660013912916
Number of train steps total  1484000
Number of env steps total    4454000
Number of rollouts total     0
Train Time (s)               147.83454036479816
(Previous) Eval Time (s)     20.411029533017427
Sample Time (s)              6.528864238411188
Epoch Time (s)               174.77443413622677
Total Train Time (s)         63569.193658747245
Epoch                        370
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:33:08.553021 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #370 | Epoch Duration: 174.861829996109
2020-01-13 01:33:08.553174 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8541634
Z variance train             0.06893162
KL Divergence                46.917095
KL Loss                      4.6917095
QF Loss                      4683.848
VF Loss                      58.310852
Policy Loss                  -1551.3397
Q Predictions Mean           1547.6241
Q Predictions Std            1417.0452
Q Predictions Max            4532.076
Q Predictions Min            670.7988
V Predictions Mean           1548.2786
V Predictions Std            1411.2917
V Predictions Max            4523.0396
V Predictions Min            683.11926
Log Pis Mean                 -0.3023495
Log Pis Std                  4.0676756
Log Pis Max                  15.839283
Log Pis Min                  -8.670622
Policy mu Mean               0.05018246
Policy mu Std                0.8867885
Policy mu Max                2.9913054
Policy mu Min                -3.1964545
Policy log std Mean          -0.51132244
Policy log std Std           0.2960332
Policy log std Max           0.20096171
Policy log std Min           -2.6050892
Z mean eval                  1.8763683
Z variance eval              0.07306431
total_rewards                [8244.61842996 5073.83805833 8764.74729385 8767.07577321 1629.51881748
 8892.32131145 8259.2769084  8428.3062154  8750.48970293 8349.66927419]
total_rewards_mean           7515.98617851958
total_rewards_std            2230.8799542155757
total_rewards_max            8892.321311451113
total_rewards_min            1629.518817480986
Number of train steps total  1488000
Number of env steps total    4466000
Number of rollouts total     0
Train Time (s)               147.39492608513683
(Previous) Eval Time (s)     20.9735300228931
Sample Time (s)              6.406075118109584
Epoch Time (s)               174.77453122613952
Total Train Time (s)         63744.33805178199
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:36:03.700751 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #371 | Epoch Duration: 175.14745569229126
2020-01-13 01:36:03.700971 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8720888
Z variance train             0.073074535
KL Divergence                47.69825
KL Loss                      4.769825
QF Loss                      331.6851
VF Loss                      108.66548
Policy Loss                  -1352.3418
Q Predictions Mean           1351.0457
Q Predictions Std            1301.351
Q Predictions Max            4626.189
Q Predictions Min            671.53815
V Predictions Mean           1353.5793
V Predictions Std            1295.0857
V Predictions Max            4585.764
V Predictions Min            700.2465
Log Pis Mean                 -0.36471152
Log Pis Std                  3.7204103
Log Pis Max                  21.732737
Log Pis Min                  -8.568241
Policy mu Mean               0.08448354
Policy mu Std                0.88928103
Policy mu Max                3.6636395
Policy mu Min                -3.0022204
Policy log std Mean          -0.5035999
Policy log std Std           0.26188946
Policy log std Max           0.05197537
Policy log std Min           -2.683847
Z mean eval                  1.9058424
Z variance eval              0.06104355
total_rewards                [9753.58612202 9333.77489575 9486.86455093 9367.65327141 9486.12817034
 9397.77186115 9452.98021453 9394.73211707 9688.05736486 9852.59965197]
total_rewards_mean           9521.414822002083
total_rewards_std            169.90181035573443
total_rewards_max            9852.599651970617
total_rewards_min            9333.774895745524
Number of train steps total  1492000
Number of env steps total    4478000
Number of rollouts total     0
Train Time (s)               146.59874951420352
(Previous) Eval Time (s)     20.981097446754575
Sample Time (s)              6.522314988542348
Epoch Time (s)               174.10216194950044
Total Train Time (s)         63918.51693839207
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:38:57.882557 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #372 | Epoch Duration: 174.1814386844635
2020-01-13 01:38:57.882708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9049795
Z variance train             0.0607522
KL Divergence                48.642387
KL Loss                      4.8642387
QF Loss                      91.0038
VF Loss                      214.60056
Policy Loss                  -1233.3805
Q Predictions Mean           1231.8986
Q Predictions Std            1141.8549
Q Predictions Max            4566.988
Q Predictions Min            705.5357
V Predictions Mean           1232.3484
V Predictions Std            1140.3953
V Predictions Max            4551.835
V Predictions Min            710.21094
Log Pis Mean                 -0.39557493
Log Pis Std                  3.5991518
Log Pis Max                  14.736191
Log Pis Min                  -8.40066
Policy mu Mean               0.0778608
Policy mu Std                0.85922694
Policy mu Max                2.7416258
Policy mu Min                -2.3560505
Policy log std Mean          -0.46265492
Policy log std Std           0.26083586
Policy log std Max           0.16277283
Policy log std Min           -2.577678
Z mean eval                  1.8623168
Z variance eval              0.058080144
total_rewards                [9443.40970657 9766.75244381 9655.70725521 9918.20865009 9550.06125299
 9741.52534271 9651.22224449 9589.77093432 9759.91473567 9705.1500342 ]
total_rewards_mean           9678.172260006422
total_rewards_std            125.48259800309691
total_rewards_max            9918.208650092116
total_rewards_min            9443.409706570092
Number of train steps total  1496000
Number of env steps total    4490000
Number of rollouts total     0
Train Time (s)               146.01743032922968
(Previous) Eval Time (s)     20.649838144890964
Sample Time (s)              6.465938136447221
Epoch Time (s)               173.13320661056787
Total Train Time (s)         64091.74090041593
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:41:51.108636 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #373 | Epoch Duration: 173.22582721710205
2020-01-13 01:41:51.108773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #373 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8645595
Z variance train             0.058060437
KL Divergence                49.232185
KL Loss                      4.9232187
QF Loss                      113.167465
VF Loss                      126.327354
Policy Loss                  -1428.1129
Q Predictions Mean           1425.0156
Q Predictions Std            1345.8099
Q Predictions Max            4581.4663
Q Predictions Min            681.4493
V Predictions Mean           1434.5802
V Predictions Std            1349.5704
V Predictions Max            4597.5034
V Predictions Min            688.4541
Log Pis Mean                 -0.57074857
Log Pis Std                  3.6628945
Log Pis Max                  11.933704
Log Pis Min                  -7.974207
Policy mu Mean               -0.008136186
Policy mu Std                0.872685
Policy mu Max                3.2477179
Policy mu Min                -3.2476995
Policy log std Mean          -0.47760853
Policy log std Std           0.28437066
Policy log std Max           0.074451864
Policy log std Min           -2.5244699
Z mean eval                  1.8720691
Z variance eval              0.05864207
total_rewards                [ 9228.82554547 10100.39399054  9878.93817079  9795.15052845
  9610.96302845 10101.76195003  9746.20920291  9963.08387714
 10144.30837407  9845.33522547]
total_rewards_mean           9841.496989333416
total_rewards_std            261.2278984076381
total_rewards_max            10144.308374074217
total_rewards_min            9228.82554547207
Number of train steps total  1500000
Number of env steps total    4502000
Number of rollouts total     0
Train Time (s)               145.9852113253437
(Previous) Eval Time (s)     18.915250062942505
Sample Time (s)              6.517569481860846
Epoch Time (s)               171.41803087014705
Total Train Time (s)         64263.241047421936
Epoch                        374
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:44:42.614874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #374 | Epoch Duration: 171.50599217414856
2020-01-13 01:44:42.615054 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #374 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8733565
Z variance train             0.058594126
KL Divergence                48.069878
KL Loss                      4.806988
QF Loss                      487.33093
VF Loss                      70.43212
Policy Loss                  -1362.6978
Q Predictions Mean           1359.4316
Q Predictions Std            1282.5581
Q Predictions Max            4546.3716
Q Predictions Min            684.4458
V Predictions Mean           1365.4731
V Predictions Std            1282.1063
V Predictions Max            4537.2036
V Predictions Min            681.5605
Log Pis Mean                 -0.046076875
Log Pis Std                  4.1570277
Log Pis Max                  19.397678
Log Pis Min                  -6.298489
Policy mu Mean               0.045988362
Policy mu Std                0.87617815
Policy mu Max                3.0377815
Policy mu Min                -2.3313034
Policy log std Mean          -0.52103645
Policy log std Std           0.31902114
Policy log std Max           0.011676669
Policy log std Min           -2.7963984
Z mean eval                  1.8519018
Z variance eval              0.051588416
total_rewards                [ 9759.25579558  9952.82258957  9855.29699376  9822.78864855
  9746.84980753 10261.80299203  9739.36913308  9764.17843707
  9824.38198439 10047.8364642 ]
total_rewards_mean           9877.458284576824
total_rewards_std            158.6372221626767
total_rewards_max            10261.802992032495
total_rewards_min            9739.369133079592
Number of train steps total  1504000
Number of env steps total    4514000
Number of rollouts total     0
Train Time (s)               147.46908017387614
(Previous) Eval Time (s)     20.74203820992261
Sample Time (s)              6.422376410569996
Epoch Time (s)               174.63349479436874
Total Train Time (s)         64437.95572407404
Epoch                        375
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:47:37.333249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #375 | Epoch Duration: 174.71807503700256
2020-01-13 01:47:37.333382 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8527569
Z variance train             0.05146869
KL Divergence                48.920998
KL Loss                      4.8921
QF Loss                      4283.911
VF Loss                      61.36199
Policy Loss                  -1177.6538
Q Predictions Mean           1177.2274
Q Predictions Std            1134.8536
Q Predictions Max            4563.5015
Q Predictions Min            692.9888
V Predictions Mean           1181.5487
V Predictions Std            1133.6555
V Predictions Max            4566.878
V Predictions Min            691.4291
Log Pis Mean                 -0.818128
Log Pis Std                  3.5149739
Log Pis Max                  13.045515
Log Pis Min                  -7.363297
Policy mu Mean               0.06544609
Policy mu Std                0.7996116
Policy mu Max                2.5946445
Policy mu Min                -2.6598012
Policy log std Mean          -0.4785782
Policy log std Std           0.29886204
Policy log std Max           0.06389916
Policy log std Min           -2.9975765
Z mean eval                  1.8877121
Z variance eval              0.05429084
total_rewards                [9775.4859337  9663.36033872 9821.13861025 9899.8259116  9635.38882195
 9725.60534284 9584.71623649 9605.6960997  9839.84463366 9796.58132513]
total_rewards_mean           9734.76432540506
total_rewards_std            102.69286692628799
total_rewards_max            9899.825911599646
total_rewards_min            9584.71623649335
Number of train steps total  1508000
Number of env steps total    4526000
Number of rollouts total     0
Train Time (s)               146.5798662211746
(Previous) Eval Time (s)     20.766570428851992
Sample Time (s)              6.353318152949214
Epoch Time (s)               173.6997548029758
Total Train Time (s)         64611.73657546425
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:50:31.118058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #376 | Epoch Duration: 173.7845802307129
2020-01-13 01:50:31.118191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8891817
Z variance train             0.05412261
KL Divergence                49.278618
KL Loss                      4.9278617
QF Loss                      188.60461
VF Loss                      221.97289
Policy Loss                  -1403.4576
Q Predictions Mean           1401.602
Q Predictions Std            1351.9827
Q Predictions Max            4605.5884
Q Predictions Min            690.7526
V Predictions Mean           1396.1794
V Predictions Std            1344.0605
V Predictions Max            4598.462
V Predictions Min            691.0826
Log Pis Mean                 -0.5086727
Log Pis Std                  3.7280076
Log Pis Max                  12.025011
Log Pis Min                  -7.0365314
Policy mu Mean               0.04438859
Policy mu Std                0.86374885
Policy mu Max                2.689698
Policy mu Min                -2.6745632
Policy log std Mean          -0.4914128
Policy log std Std           0.3011539
Policy log std Max           0.004956007
Policy log std Min           -2.700985
Z mean eval                  1.8784506
Z variance eval              0.07369449
total_rewards                [9830.23066763 9873.88504108 9982.62502551 9911.54331345 9564.99325842
 9867.2771766  9535.86820532 9491.88751294 9524.77640956 9785.01468792]
total_rewards_mean           9736.81012984239
total_rewards_std            176.82278908869893
total_rewards_max            9982.625025512074
total_rewards_min            9491.887512936335
Number of train steps total  1512000
Number of env steps total    4538000
Number of rollouts total     0
Train Time (s)               145.9759434047155
(Previous) Eval Time (s)     18.780366893857718
Sample Time (s)              6.5756055768579245
Epoch Time (s)               171.33191587543115
Total Train Time (s)         64783.15810635267
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:53:22.543880 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #377 | Epoch Duration: 171.42557621002197
2020-01-13 01:53:22.544076 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #377 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8783257
Z variance train             0.073640004
KL Divergence                49.98961
KL Loss                      4.998961
QF Loss                      107.15909
VF Loss                      88.775986
Policy Loss                  -1311.6166
Q Predictions Mean           1309.2953
Q Predictions Std            1250.8107
Q Predictions Max            4567.1045
Q Predictions Min            692.26373
V Predictions Mean           1316.243
V Predictions Std            1253.2958
V Predictions Max            4585.7837
V Predictions Min            695.0303
Log Pis Mean                 -0.34927756
Log Pis Std                  4.07571
Log Pis Max                  22.59872
Log Pis Min                  -9.336418
Policy mu Mean               0.12467283
Policy mu Std                0.8696991
Policy mu Max                3.4552784
Policy mu Min                -3.4474747
Policy log std Mean          -0.483747
Policy log std Std           0.27180234
Policy log std Max           -0.03493753
Policy log std Min           -2.430083
Z mean eval                  1.8636315
Z variance eval              0.08437241
total_rewards                [ 9884.23214215  9845.31090512  9964.26847708  9871.09781088
  9861.1540425  10172.89529209 10259.5531585  10098.89612856
 10035.48255359 10018.33527748]
total_rewards_mean           10001.122578794502
total_rewards_std            135.32379300436355
total_rewards_max            10259.553158503899
total_rewards_min            9845.310905116237
Number of train steps total  1516000
Number of env steps total    4550000
Number of rollouts total     0
Train Time (s)               145.6304522929713
(Previous) Eval Time (s)     17.486366973724216
Sample Time (s)              6.606286349706352
Epoch Time (s)               169.72310561640188
Total Train Time (s)         64952.974975013174
Epoch                        378
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:56:12.368848 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #378 | Epoch Duration: 169.82459378242493
2020-01-13 01:56:12.369155 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8648698
Z variance train             0.08427806
KL Divergence                48.81436
KL Loss                      4.8814363
QF Loss                      4143.829
VF Loss                      94.36327
Policy Loss                  -1357.0913
Q Predictions Mean           1350.7317
Q Predictions Std            1319.9967
Q Predictions Max            4572.3647
Q Predictions Min            693.63544
V Predictions Mean           1352.4526
V Predictions Std            1313.982
V Predictions Max            4542.9175
V Predictions Min            692.5985
Log Pis Mean                 -0.73985416
Log Pis Std                  3.5772917
Log Pis Max                  11.939463
Log Pis Min                  -9.071801
Policy mu Mean               0.059381362
Policy mu Std                0.8483426
Policy mu Max                3.4313107
Policy mu Min                -2.8575697
Policy log std Mean          -0.49625146
Policy log std Std           0.30080262
Policy log std Max           -0.010328352
Policy log std Min           -2.6150818
Z mean eval                  1.8911839
Z variance eval              0.09610556
total_rewards                [9154.9978098  9418.12507202 9168.1876093  9092.92055287 9346.22424731
 9272.68744628 9106.27343312 9297.29535943 9016.0494305  9345.53341038]
total_rewards_mean           9221.829437101394
total_rewards_std            125.3995112947056
total_rewards_max            9418.125072015091
total_rewards_min            9016.049430504596
Number of train steps total  1520000
Number of env steps total    4562000
Number of rollouts total     0
Train Time (s)               147.9935928718187
(Previous) Eval Time (s)     20.703739661723375
Sample Time (s)              6.0328971622511744
Epoch Time (s)               174.73022969579324
Total Train Time (s)         65127.78539409116
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 01:59:07.180121 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #379 | Epoch Duration: 174.8107578754425
2020-01-13 01:59:07.180254 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8903253
Z variance train             0.09679222
KL Divergence                49.513382
KL Loss                      4.9513383
QF Loss                      4212.922
VF Loss                      69.50273
Policy Loss                  -1275.4385
Q Predictions Mean           1272.2983
Q Predictions Std            1247.8866
Q Predictions Max            4517.77
Q Predictions Min            678.69867
V Predictions Mean           1279.5656
V Predictions Std            1250.463
V Predictions Max            4527.057
V Predictions Min            685.593
Log Pis Mean                 -0.7475784
Log Pis Std                  3.6823223
Log Pis Max                  14.32426
Log Pis Min                  -6.23864
Policy mu Mean               0.052413326
Policy mu Std                0.82359385
Policy mu Max                3.0384197
Policy mu Min                -2.6233156
Policy log std Mean          -0.4741056
Policy log std Std           0.27518812
Policy log std Max           0.07576728
Policy log std Min           -2.806288
Z mean eval                  1.9115146
Z variance eval              0.122425176
total_rewards                [9316.61175347 9894.82550863 9226.9385677  9357.06360616 9799.66013854
 9193.49394249 9111.40337268 9907.42773971 9859.50943572 9285.73826778]
total_rewards_mean           9495.267233289673
total_rewards_std            309.869292920655
total_rewards_max            9907.42773970602
total_rewards_min            9111.403372679206
Number of train steps total  1524000
Number of env steps total    4574000
Number of rollouts total     0
Train Time (s)               145.38703901832923
(Previous) Eval Time (s)     20.757535024080426
Sample Time (s)              9.667046279180795
Epoch Time (s)               175.81162032159045
Total Train Time (s)         65303.676605890505
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:02:03.074185 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #380 | Epoch Duration: 175.89383721351624
2020-01-13 02:02:03.074317 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #380 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9097958
Z variance train             0.122848235
KL Divergence                49.871918
KL Loss                      4.9871917
QF Loss                      104.273285
VF Loss                      55.488876
Policy Loss                  -1429.0654
Q Predictions Mean           1430.2382
Q Predictions Std            1393.8066
Q Predictions Max            4643.3467
Q Predictions Min            682.2826
V Predictions Mean           1431.7933
V Predictions Std            1389.4744
V Predictions Max            4631.1353
V Predictions Min            693.72534
Log Pis Mean                 -0.0950571
Log Pis Std                  3.9896061
Log Pis Max                  13.884285
Log Pis Min                  -6.259799
Policy mu Mean               0.044379156
Policy mu Std                0.87781304
Policy mu Max                2.80202
Policy mu Min                -2.74337
Policy log std Mean          -0.49447322
Policy log std Std           0.27528292
Policy log std Max           -0.06160289
Policy log std Min           -2.5288646
Z mean eval                  1.8902848
Z variance eval              0.09111163
total_rewards                [ 9956.37725297 10116.04604728 10160.72979594 10528.38805598
 10544.77191348 10371.61645099 10325.29314689 10319.00681739
 10080.69152425 10178.79194004]
total_rewards_mean           10258.171294519712
total_rewards_std            182.97741560931294
total_rewards_max            10544.771913479039
total_rewards_min            9956.377252967484
Number of train steps total  1528000
Number of env steps total    4586000
Number of rollouts total     0
Train Time (s)               147.17296544322744
(Previous) Eval Time (s)     20.69597431831062
Sample Time (s)              6.41876144008711
Epoch Time (s)               174.28770120162517
Total Train Time (s)         65478.06792785274
Epoch                        381
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:04:57.469283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #381 | Epoch Duration: 174.39487051963806
2020-01-13 02:04:57.469420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.889546
Z variance train             0.091347516
KL Divergence                49.574787
KL Loss                      4.957479
QF Loss                      143.38548
VF Loss                      140.23366
Policy Loss                  -1319.5021
Q Predictions Mean           1317.7166
Q Predictions Std            1276.6633
Q Predictions Max            4522.3877
Q Predictions Min            671.98706
V Predictions Mean           1328.0442
V Predictions Std            1279.332
V Predictions Max            4541.4224
V Predictions Min            699.8771
Log Pis Mean                 -0.6203114
Log Pis Std                  3.6145096
Log Pis Max                  16.266825
Log Pis Min                  -10.058009
Policy mu Mean               0.048218112
Policy mu Std                0.86379737
Policy mu Max                3.2186873
Policy mu Min                -4.3629103
Policy log std Mean          -0.48435125
Policy log std Std           0.26703313
Policy log std Max           0.0036036372
Policy log std Min           -2.324059
Z mean eval                  1.8951944
Z variance eval              0.11654963
total_rewards                [ 9919.54446449 10495.40435337 10272.70183772 10387.30945939
  7385.04395634 10272.72657506 10218.21167305 10192.46056748
 10284.64298126 10377.27125576]
total_rewards_mean           9980.531712391978
total_rewards_std            877.0901242423059
total_rewards_max            10495.404353371452
total_rewards_min            7385.043956343066
Number of train steps total  1532000
Number of env steps total    4598000
Number of rollouts total     0
Train Time (s)               147.43155474821106
(Previous) Eval Time (s)     20.827033730689436
Sample Time (s)              6.389928185380995
Epoch Time (s)               174.6485166642815
Total Train Time (s)         65652.85013167001
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:07:52.254520 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #382 | Epoch Duration: 174.78500413894653
2020-01-13 02:07:52.254667 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #382 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8971351
Z variance train             0.11596942
KL Divergence                49.559055
KL Loss                      4.9559054
QF Loss                      343.6308
VF Loss                      200.1422
Policy Loss                  -1370.5541
Q Predictions Mean           1365.8002
Q Predictions Std            1309.8289
Q Predictions Max            4621.5337
Q Predictions Min            683.55853
V Predictions Mean           1362.8613
V Predictions Std            1299.6565
V Predictions Max            4591.5747
V Predictions Min            676.0936
Log Pis Mean                 -0.295713
Log Pis Std                  3.5996482
Log Pis Max                  14.090097
Log Pis Min                  -7.3290095
Policy mu Mean               0.041946918
Policy mu Std                0.8942907
Policy mu Max                3.5028
Policy mu Min                -3.1218584
Policy log std Mean          -0.50378555
Policy log std Std           0.30407238
Policy log std Max           0.15377104
Policy log std Min           -2.7430675
Z mean eval                  1.8952847
Z variance eval              0.1369302
total_rewards                [ 9822.86032444  9932.39801591 10290.69103599  9778.02415338
  7441.35133644 10011.59007516  9407.77094011  9765.73052146
  9891.14364361 10007.46422236]
total_rewards_mean           9634.902426886349
total_rewards_std            761.6495815746009
total_rewards_max            10290.69103599409
total_rewards_min            7441.351336443568
Number of train steps total  1536000
Number of env steps total    4610000
Number of rollouts total     0
Train Time (s)               146.3406353201717
(Previous) Eval Time (s)     19.111975512001663
Sample Time (s)              6.442974720615894
Epoch Time (s)               171.89558555278927
Total Train Time (s)         65824.8221931993
Epoch                        383
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:10:44.228649 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #383 | Epoch Duration: 171.97388458251953
2020-01-13 02:10:44.228781 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.895698
Z variance train             0.1367574
KL Divergence                49.288246
KL Loss                      4.928825
QF Loss                      110.54071
VF Loss                      50.77611
Policy Loss                  -1273.8097
Q Predictions Mean           1273.229
Q Predictions Std            1227.7203
Q Predictions Max            4566.8896
Q Predictions Min            678.5529
V Predictions Mean           1271.5636
V Predictions Std            1218.4852
V Predictions Max            4548.713
V Predictions Min            687.5646
Log Pis Mean                 -0.8547034
Log Pis Std                  3.3356996
Log Pis Max                  12.310268
Log Pis Min                  -5.935505
Policy mu Mean               0.025870046
Policy mu Std                0.80943096
Policy mu Max                2.633931
Policy mu Min                -2.4321449
Policy log std Mean          -0.47138834
Policy log std Std           0.24050955
Policy log std Max           0.016303658
Policy log std Min           -2.7038317
Z mean eval                  1.9035523
Z variance eval              0.09112503
total_rewards                [9805.06780356 9605.65035664 9781.15323929 9684.56101401 9854.68923379
 9489.76015025 9895.99722315 9526.28098342 9655.7417608  9729.63897842]
total_rewards_mean           9702.85407433318
total_rewards_std            128.9355940540727
total_rewards_max            9895.997223153629
total_rewards_min            9489.760150246919
Number of train steps total  1540000
Number of env steps total    4622000
Number of rollouts total     0
Train Time (s)               147.62035322422162
(Previous) Eval Time (s)     20.74056278122589
Sample Time (s)              5.581156665459275
Epoch Time (s)               173.94207267090678
Total Train Time (s)         65998.84810821246
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:13:38.258190 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #384 | Epoch Duration: 174.029314994812
2020-01-13 02:13:38.258328 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9047047
Z variance train             0.0906706
KL Divergence                48.64567
KL Loss                      4.8645673
QF Loss                      4550.5454
VF Loss                      145.57423
Policy Loss                  -1371.8453
Q Predictions Mean           1370.268
Q Predictions Std            1302.8373
Q Predictions Max            4700.114
Q Predictions Min            680.45264
V Predictions Mean           1364.4208
V Predictions Std            1293.964
V Predictions Max            4681.375
V Predictions Min            690.16986
Log Pis Mean                 -0.48252323
Log Pis Std                  3.6925607
Log Pis Max                  18.175653
Log Pis Min                  -8.225813
Policy mu Mean               0.017248712
Policy mu Std                0.8820387
Policy mu Max                2.9999309
Policy mu Min                -3.338814
Policy log std Mean          -0.4764212
Policy log std Std           0.26501012
Policy log std Max           0.097031355
Policy log std Min           -2.645468
Z mean eval                  1.8827059
Z variance eval              0.07058672
total_rewards                [ 9824.21743551  9870.06093209  9911.2823155   9850.01310712
 10057.93047434  9704.71018786  9868.13497198 10103.40336055
  9931.84338291  9621.03999895]
total_rewards_mean           9874.263616682345
total_rewards_std            136.7270443148174
total_rewards_max            10103.403360551709
total_rewards_min            9621.039998954497
Number of train steps total  1544000
Number of env steps total    4634000
Number of rollouts total     0
Train Time (s)               147.22266611177474
(Previous) Eval Time (s)     20.63532943185419
Sample Time (s)              6.489180014934391
Epoch Time (s)               174.34717555856332
Total Train Time (s)         66173.29110403499
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:16:32.704470 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #385 | Epoch Duration: 174.44603204727173
2020-01-13 02:16:32.704644 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #385 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8815473
Z variance train             0.07050952
KL Divergence                48.015472
KL Loss                      4.8015475
QF Loss                      88.58998
VF Loss                      77.5449
Policy Loss                  -1362.3651
Q Predictions Mean           1361.3921
Q Predictions Std            1292.3824
Q Predictions Max            4635.543
Q Predictions Min            696.75696
V Predictions Mean           1362.4426
V Predictions Std            1291.0468
V Predictions Max            4608.857
V Predictions Min            698.6242
Log Pis Mean                 -0.43609193
Log Pis Std                  3.8358235
Log Pis Max                  14.5136
Log Pis Min                  -7.046588
Policy mu Mean               0.05321659
Policy mu Std                0.87740266
Policy mu Max                2.8220086
Policy mu Min                -3.2565691
Policy log std Mean          -0.4621273
Policy log std Std           0.2684683
Policy log std Max           -0.07856831
Policy log std Min           -2.3541474
Z mean eval                  1.8741112
Z variance eval              0.08466537
total_rewards                [ 9580.65716835 10139.2922156   9975.23592676  9777.62018511
 10006.0011701   9798.5117571  10192.45956504  9296.84161637
 10094.25175073 10208.75121912]
total_rewards_mean           9906.962257427058
total_rewards_std            279.8790711116719
total_rewards_max            10208.75121912379
total_rewards_min            9296.841616368101
Number of train steps total  1548000
Number of env steps total    4646000
Number of rollouts total     0
Train Time (s)               147.02580833202228
(Previous) Eval Time (s)     21.01948000723496
Sample Time (s)              5.618510524742305
Epoch Time (s)               173.66379886399955
Total Train Time (s)         66347.03587124357
Epoch                        386
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:19:26.451574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #386 | Epoch Duration: 173.7467999458313
2020-01-13 02:19:26.451706 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #386 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8752114
Z variance train             0.08471556
KL Divergence                47.04331
KL Loss                      4.704331
QF Loss                      322.9041
VF Loss                      65.78241
Policy Loss                  -1476.9084
Q Predictions Mean           1474.9913
Q Predictions Std            1412.7407
Q Predictions Max            4573.7354
Q Predictions Min            682.5473
V Predictions Mean           1478.4866
V Predictions Std            1409.7052
V Predictions Max            4562.1724
V Predictions Min            688.25574
Log Pis Mean                 -0.42684162
Log Pis Std                  3.9500926
Log Pis Max                  13.37689
Log Pis Min                  -8.024233
Policy mu Mean               0.037790466
Policy mu Std                0.9085021
Policy mu Max                3.2215068
Policy mu Min                -2.8796232
Policy log std Mean          -0.48016873
Policy log std Std           0.2891063
Policy log std Max           -0.025840938
Policy log std Min           -2.6700325
Z mean eval                  1.901823
Z variance eval              0.06951566
total_rewards                [ 9922.22070781  9737.82762957  9994.93782965  9634.72936663
  9933.59420461  8702.61407952 10099.63696185 10009.02367408
 10233.96095396  9764.34312096]
total_rewards_mean           9803.288852865753
total_rewards_std            403.63105393480583
total_rewards_max            10233.960953964099
total_rewards_min            8702.614079521925
Number of train steps total  1552000
Number of env steps total    4658000
Number of rollouts total     0
Train Time (s)               146.18365166382864
(Previous) Eval Time (s)     20.734043068718165
Sample Time (s)              6.482313010841608
Epoch Time (s)               173.40000774338841
Total Train Time (s)         66520.51829900686
Epoch                        387
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:22:19.939808 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #387 | Epoch Duration: 173.48800611495972
2020-01-13 02:22:19.939941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8999485
Z variance train             0.07017151
KL Divergence                48.295616
KL Loss                      4.8295617
QF Loss                      237.2309
VF Loss                      146.28653
Policy Loss                  -1299.7925
Q Predictions Mean           1295.333
Q Predictions Std            1239.0123
Q Predictions Max            4390.5034
Q Predictions Min            627.6116
V Predictions Mean           1291.0153
V Predictions Std            1231.6228
V Predictions Max            4357.549
V Predictions Min            653.1528
Log Pis Mean                 -0.2823229
Log Pis Std                  3.7880468
Log Pis Max                  19.842842
Log Pis Min                  -6.8442607
Policy mu Mean               0.122609295
Policy mu Std                0.8723011
Policy mu Max                3.0502315
Policy mu Min                -2.763727
Policy log std Mean          -0.5074384
Policy log std Std           0.28026125
Policy log std Max           -0.04724419
Policy log std Min           -2.578574
Z mean eval                  1.8992189
Z variance eval              0.08997854
total_rewards                [ 9992.8572176  10030.7224103  10115.92501704  9867.56256009
  9990.41605376 10382.59232251 10111.34667459 10098.00960827
 10279.62443036 10288.17370271]
total_rewards_mean           10115.722999723936
total_rewards_std            150.917743081549
total_rewards_max            10382.592322512995
total_rewards_min            9867.562560090386
Number of train steps total  1556000
Number of env steps total    4670000
Number of rollouts total     0
Train Time (s)               144.4777842978947
(Previous) Eval Time (s)     20.957605473231524
Sample Time (s)              6.340437537524849
Epoch Time (s)               171.77582730865106
Total Train Time (s)         66692.38316213572
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:25:11.805306 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #388 | Epoch Duration: 171.86526727676392
2020-01-13 02:25:11.805444 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #388 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8987204
Z variance train             0.09011395
KL Divergence                48.425285
KL Loss                      4.842529
QF Loss                      221.11778
VF Loss                      36.644543
Policy Loss                  -1308.4253
Q Predictions Mean           1304.102
Q Predictions Std            1227.1985
Q Predictions Max            4589.328
Q Predictions Min            693.4028
V Predictions Mean           1306.868
V Predictions Std            1229.1643
V Predictions Max            4589.693
V Predictions Min            704.7774
Log Pis Mean                 -0.6968523
Log Pis Std                  3.6748917
Log Pis Max                  12.22304
Log Pis Min                  -7.2281013
Policy mu Mean               0.03057913
Policy mu Std                0.8518098
Policy mu Max                3.2549334
Policy mu Min                -2.8614638
Policy log std Mean          -0.4864631
Policy log std Std           0.26927108
Policy log std Max           -0.055342674
Policy log std Min           -2.3364913
Z mean eval                  1.9072285
Z variance eval              0.06950181
total_rewards                [10024.09484984 10063.98781432 10431.60488367 10109.20115255
 10307.88131007  9874.76004892 10055.8497286  10105.320112
 10230.16519795 10149.68165789]
total_rewards_mean           10135.254675582577
total_rewards_std            148.32817618368313
total_rewards_max            10431.604883669619
total_rewards_min            9874.760048918153
Number of train steps total  1560000
Number of env steps total    4682000
Number of rollouts total     0
Train Time (s)               145.51547252899036
(Previous) Eval Time (s)     20.923224737867713
Sample Time (s)              6.484979311469942
Epoch Time (s)               172.923676578328
Total Train Time (s)         66865.39026572695
Epoch                        389
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:28:04.814475 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #389 | Epoch Duration: 173.00893354415894
2020-01-13 02:28:04.814606 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #389 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.903992
Z variance train             0.069136776
KL Divergence                49.289806
KL Loss                      4.928981
QF Loss                      329.67566
VF Loss                      98.13901
Policy Loss                  -1399.5602
Q Predictions Mean           1399.2511
Q Predictions Std            1331.4027
Q Predictions Max            4617.217
Q Predictions Min            677.0626
V Predictions Mean           1403.6993
V Predictions Std            1328.7468
V Predictions Max            4622.042
V Predictions Min            689.49115
Log Pis Mean                 -0.3122967
Log Pis Std                  3.9972737
Log Pis Max                  15.4096
Log Pis Min                  -6.6008863
Policy mu Mean               0.08555964
Policy mu Std                0.87432253
Policy mu Max                3.1559243
Policy mu Min                -3.170525
Policy log std Mean          -0.49958527
Policy log std Std           0.2865004
Policy log std Max           -0.0063121915
Policy log std Min           -2.7243795
Z mean eval                  1.8877227
Z variance eval              0.082491145
total_rewards                [10089.10846199 10131.84432662  9931.74355496 10299.35234109
 10105.13363692  9958.21696179 10209.37449088  9931.84899394
 10110.61231432 10219.82148397]
total_rewards_mean           10098.70565664817
total_rewards_std            120.00152256082555
total_rewards_max            10299.352341088186
total_rewards_min            9931.74355495897
Number of train steps total  1564000
Number of env steps total    4694000
Number of rollouts total     0
Train Time (s)               145.38560410775244
(Previous) Eval Time (s)     20.563520544208586
Sample Time (s)              6.488403321243823
Epoch Time (s)               172.43752797320485
Total Train Time (s)         67037.9182320172
Epoch                        390
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:30:57.344583 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #390 | Epoch Duration: 172.52986979484558
2020-01-13 02:30:57.344722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #390 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8861424
Z variance train             0.082233384
KL Divergence                48.42465
KL Loss                      4.842465
QF Loss                      1424.9521
VF Loss                      138.24815
Policy Loss                  -1476.3822
Q Predictions Mean           1477.5317
Q Predictions Std            1390.1486
Q Predictions Max            4616.67
Q Predictions Min            693.7515
V Predictions Mean           1481.3752
V Predictions Std            1391.9945
V Predictions Max            4647.0493
V Predictions Min            704.3722
Log Pis Mean                 0.09456141
Log Pis Std                  3.7611911
Log Pis Max                  13.056921
Log Pis Min                  -5.5130253
Policy mu Mean               0.107567914
Policy mu Std                0.91286236
Policy mu Max                2.8072503
Policy mu Min                -2.7117753
Policy log std Mean          -0.49535012
Policy log std Std           0.2669025
Policy log std Max           -0.0704487
Policy log std Min           -2.616741
Z mean eval                  1.8760185
Z variance eval              0.07646864
total_rewards                [ 9738.64287302  9889.6417485  10188.9473026   9990.60838944
 10022.88971496  9993.4117046  10063.37543344 10094.59637313
  9933.13147753  9959.65499271]
total_rewards_mean           9987.49000099314
total_rewards_std            115.90606508074741
total_rewards_max            10188.947302600725
total_rewards_min            9738.642873020823
Number of train steps total  1568000
Number of env steps total    4706000
Number of rollouts total     0
Train Time (s)               146.27276569698006
(Previous) Eval Time (s)     17.514762572944164
Sample Time (s)              6.617209106683731
Epoch Time (s)               170.40473737660795
Total Train Time (s)         67208.41193868872
Epoch                        391
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:33:47.842122 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #391 | Epoch Duration: 170.49728417396545
2020-01-13 02:33:47.842294 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #391 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8754389
Z variance train             0.07624092
KL Divergence                47.886322
KL Loss                      4.7886324
QF Loss                      238.96756
VF Loss                      74.49184
Policy Loss                  -1351.1353
Q Predictions Mean           1344.7388
Q Predictions Std            1265.9229
Q Predictions Max            4548.9253
Q Predictions Min            682.1016
V Predictions Mean           1350.9624
V Predictions Std            1262.4153
V Predictions Max            4524.3574
V Predictions Min            680.04584
Log Pis Mean                 -0.4002482
Log Pis Std                  3.606474
Log Pis Max                  12.189025
Log Pis Min                  -6.291816
Policy mu Mean               0.0829666
Policy mu Std                0.8625842
Policy mu Max                2.9970357
Policy mu Min                -2.7836628
Policy log std Mean          -0.49225548
Policy log std Std           0.30370212
Policy log std Max           -0.0041605234
Policy log std Min           -2.967675
Z mean eval                  1.9052607
Z variance eval              0.087996885
total_rewards                [ 9788.06876266 10051.89731148 10046.49940822 10142.60843961
  9811.15173522  9919.09869266 10010.73800214  9686.71036158
  9861.88494645  9904.82131444]
total_rewards_mean           9922.347897446916
total_rewards_std            133.57327317692543
total_rewards_max            10142.608439607238
total_rewards_min            9686.710361584199
Number of train steps total  1572000
Number of env steps total    4718000
Number of rollouts total     0
Train Time (s)               146.96382901910692
(Previous) Eval Time (s)     20.756376903038472
Sample Time (s)              6.572071221657097
Epoch Time (s)               174.2922771438025
Total Train Time (s)         67382.7918473729
Epoch                        392
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:36:42.228563 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #392 | Epoch Duration: 174.38606929779053
2020-01-13 02:36:42.228838 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #392 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9043131
Z variance train             0.08790706
KL Divergence                47.985104
KL Loss                      4.7985106
QF Loss                      198.24417
VF Loss                      40.434155
Policy Loss                  -1253.43
Q Predictions Mean           1249.044
Q Predictions Std            1178.2765
Q Predictions Max            4556.0835
Q Predictions Min            685.5494
V Predictions Mean           1254.4713
V Predictions Std            1177.8674
V Predictions Max            4535.9893
V Predictions Min            681.8884
Log Pis Mean                 -0.66509604
Log Pis Std                  3.5987546
Log Pis Max                  15.00477
Log Pis Min                  -6.4677014
Policy mu Mean               0.08104371
Policy mu Std                0.8223866
Policy mu Max                2.966594
Policy mu Min                -2.8613195
Policy log std Mean          -0.4762024
Policy log std Std           0.2738823
Policy log std Max           -0.011745423
Policy log std Min           -2.281291
Z mean eval                  1.8933156
Z variance eval              0.10633089
total_rewards                [ 9903.48893391 10199.33546354 10449.80951319 10209.93621709
 10245.68160853 10240.0583153  10091.96982588 10150.62829146
 10290.92624293 10332.41774029]
total_rewards_mean           10211.425215211919
total_rewards_std            138.82327668273743
total_rewards_max            10449.809513192737
total_rewards_min            9903.488933913202
Number of train steps total  1576000
Number of env steps total    4730000
Number of rollouts total     0
Train Time (s)               146.08845992106944
(Previous) Eval Time (s)     20.626837758813053
Sample Time (s)              5.633285072632134
Epoch Time (s)               172.34858275251463
Total Train Time (s)         67555.24207505444
Epoch                        393
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:39:34.682531 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #393 | Epoch Duration: 172.4535174369812
2020-01-13 02:39:34.682724 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #393 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.896175
Z variance train             0.10630341
KL Divergence                47.268238
KL Loss                      4.726824
QF Loss                      629.7744
VF Loss                      51.266205
Policy Loss                  -1340.2639
Q Predictions Mean           1337.0735
Q Predictions Std            1255.7408
Q Predictions Max            4570.6777
Q Predictions Min            668.98236
V Predictions Mean           1342.1182
V Predictions Std            1255.4723
V Predictions Max            4562.848
V Predictions Min            676.3086
Log Pis Mean                 -0.23062836
Log Pis Std                  3.5601318
Log Pis Max                  10.929634
Log Pis Min                  -7.9260406
Policy mu Mean               0.12932657
Policy mu Std                0.87808925
Policy mu Max                2.8067694
Policy mu Min                -2.4082968
Policy log std Mean          -0.50943774
Policy log std Std           0.29851186
Policy log std Max           -0.01970157
Policy log std Min           -2.817096
Z mean eval                  1.8851728
Z variance eval              0.07160795
total_rewards                [10054.39630099 10095.16536547 10265.74692683 10267.75460518
 10284.89928894 10256.94947546  9881.63941073 10309.45293056
 10211.17637704 10404.72210955]
total_rewards_mean           10203.190279076083
total_rewards_std            143.81338541151737
total_rewards_max            10404.72210954645
total_rewards_min            9881.639410733544
Number of train steps total  1580000
Number of env steps total    4742000
Number of rollouts total     0
Train Time (s)               147.57199665205553
(Previous) Eval Time (s)     20.550741785671562
Sample Time (s)              5.755672336090356
Epoch Time (s)               173.87841077381745
Total Train Time (s)         67729.20655962871
Epoch                        394
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:42:28.654895 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #394 | Epoch Duration: 173.97203826904297
2020-01-13 02:42:28.655043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #394 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8825204
Z variance train             0.07156132
KL Divergence                47.863907
KL Loss                      4.786391
QF Loss                      4322.563
VF Loss                      137.18787
Policy Loss                  -1342.9341
Q Predictions Mean           1340.9174
Q Predictions Std            1287.8755
Q Predictions Max            4544.294
Q Predictions Min            672.5672
V Predictions Mean           1340.375
V Predictions Std            1278.9353
V Predictions Max            4525.5913
V Predictions Min            680.2921
Log Pis Mean                 -0.6889212
Log Pis Std                  3.5366714
Log Pis Max                  11.350292
Log Pis Min                  -7.4817615
Policy mu Mean               0.0056784055
Policy mu Std                0.8474052
Policy mu Max                2.4648013
Policy mu Min                -2.412916
Policy log std Mean          -0.4945508
Policy log std Std           0.2651586
Policy log std Max           -0.026863873
Policy log std Min           -2.5784612
Z mean eval                  1.8672445
Z variance eval              0.03916168
total_rewards                [ 9884.7571182  10161.71159031 10091.74229165 10376.86198327
 10358.30245117 10475.35964844 10446.78126866 10298.65646177
 10413.37770135 10174.47619047]
total_rewards_mean           10268.202670531142
total_rewards_std            177.4897543644053
total_rewards_max            10475.359648442049
total_rewards_min            9884.757118203936
Number of train steps total  1584000
Number of env steps total    4754000
Number of rollouts total     0
Train Time (s)               147.3232988701202
(Previous) Eval Time (s)     19.657551805954427
Sample Time (s)              6.355615169741213
Epoch Time (s)               173.33646584581584
Total Train Time (s)         67902.6222065757
Epoch                        395
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:45:22.073231 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #395 | Epoch Duration: 173.4180281162262
2020-01-13 02:45:22.073441 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #395 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.867061
Z variance train             0.039123215
KL Divergence                49.350285
KL Loss                      4.9350286
QF Loss                      146.10896
VF Loss                      44.79104
Policy Loss                  -1325.3201
Q Predictions Mean           1322.6266
Q Predictions Std            1268.0208
Q Predictions Max            4630.8257
Q Predictions Min            700.7541
V Predictions Mean           1324.1895
V Predictions Std            1264.7229
V Predictions Max            4624.9614
V Predictions Min            700.9733
Log Pis Mean                 -0.3264502
Log Pis Std                  4.063251
Log Pis Max                  22.486332
Log Pis Min                  -6.8523273
Policy mu Mean               0.033119325
Policy mu Std                0.89072263
Policy mu Max                3.27666
Policy mu Min                -3.0869071
Policy log std Mean          -0.4890343
Policy log std Std           0.26420406
Policy log std Max           0.29679108
Policy log std Min           -2.7463543
Z mean eval                  1.8766603
Z variance eval              0.0410124
total_rewards                [10162.02317076 10183.25542795 10424.68273847 10359.3737206
 10080.95985627 10208.11717868 10384.93439864 10433.71066426
 10414.64633713 10251.2773055 ]
total_rewards_mean           10290.298079826014
total_rewards_std            121.58444256599867
total_rewards_max            10433.710664262491
total_rewards_min            10080.959856265967
Number of train steps total  1588000
Number of env steps total    4766000
Number of rollouts total     0
Train Time (s)               144.67909861914814
(Previous) Eval Time (s)     20.825641923118383
Sample Time (s)              5.394221387337893
Epoch Time (s)               170.8989619296044
Total Train Time (s)         68073.60068234382
Epoch                        396
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:48:13.053722 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #396 | Epoch Duration: 170.98016047477722
2020-01-13 02:48:13.053856 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #396 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8772275
Z variance train             0.041085124
KL Divergence                48.85475
KL Loss                      4.885475
QF Loss                      147.3132
VF Loss                      117.58589
Policy Loss                  -1357.0221
Q Predictions Mean           1354.6329
Q Predictions Std            1268.3251
Q Predictions Max            4611.677
Q Predictions Min            664.9964
V Predictions Mean           1359.9358
V Predictions Std            1265.9365
V Predictions Max            4578.183
V Predictions Min            676.8047
Log Pis Mean                 -0.1168339
Log Pis Std                  4.183656
Log Pis Max                  16.460957
Log Pis Min                  -11.871697
Policy mu Mean               0.06628954
Policy mu Std                0.89998406
Policy mu Max                3.685719
Policy mu Min                -2.757251
Policy log std Mean          -0.5114947
Policy log std Std           0.28447354
Policy log std Max           0.18368179
Policy log std Min           -2.7951095
Z mean eval                  1.8909365
Z variance eval              0.05186034
total_rewards                [10023.98830982 10596.89281975 10473.77646032  9987.74993344
 10277.17060274  9937.68708112 10069.68785204 10083.9259122
 10310.52935858 10424.69955197]
total_rewards_mean           10218.610788196322
total_rewards_std            217.47838948455043
total_rewards_max            10596.892819752682
total_rewards_min            9937.68708111611
Number of train steps total  1592000
Number of env steps total    4778000
Number of rollouts total     0
Train Time (s)               147.92868971591815
(Previous) Eval Time (s)     20.861705656629056
Sample Time (s)              6.400278631132096
Epoch Time (s)               175.1906740036793
Total Train Time (s)         68248.87812365964
Epoch                        397
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:51:08.333739 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #397 | Epoch Duration: 175.2797863483429
2020-01-13 02:51:08.333879 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #397 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8907467
Z variance train             0.051840723
KL Divergence                49.261124
KL Loss                      4.9261127
QF Loss                      4376.8154
VF Loss                      46.741604
Policy Loss                  -1356.5066
Q Predictions Mean           1356.567
Q Predictions Std            1305.5358
Q Predictions Max            4617.6553
Q Predictions Min            681.7818
V Predictions Mean           1353.1069
V Predictions Std            1301.7406
V Predictions Max            4588.977
V Predictions Min            680.7207
Log Pis Mean                 -0.04543773
Log Pis Std                  3.9766803
Log Pis Max                  17.971598
Log Pis Min                  -7.990786
Policy mu Mean               0.06239305
Policy mu Std                0.9122026
Policy mu Max                2.8414156
Policy mu Min                -2.833856
Policy log std Mean          -0.49133205
Policy log std Std           0.28893113
Policy log std Max           -0.055936456
Policy log std Min           -2.9678657
Z mean eval                  1.9103525
Z variance eval              0.079182066
total_rewards                [ 9835.0883486  10242.98875589 10299.72696914 10424.02645012
 10234.71972628 10163.13316062 10502.45548794 10308.4341195
 10134.5280055  10325.00608797]
total_rewards_mean           10247.01071115569
total_rewards_std            172.84582822229805
total_rewards_max            10502.455487940464
total_rewards_min            9835.08834860254
Number of train steps total  1596000
Number of env steps total    4790000
Number of rollouts total     0
Train Time (s)               147.34677468892187
(Previous) Eval Time (s)     20.978184663690627
Sample Time (s)              6.457738631870598
Epoch Time (s)               174.7826979844831
Total Train Time (s)         68423.73816756858
Epoch                        398
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:54:03.196241 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #398 | Epoch Duration: 174.86226391792297
2020-01-13 02:54:03.196374 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #398 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9073935
Z variance train             0.079215325
KL Divergence                48.960293
KL Loss                      4.8960295
QF Loss                      183.23956
VF Loss                      34.27533
Policy Loss                  -1261.4558
Q Predictions Mean           1262.0872
Q Predictions Std            1206.3676
Q Predictions Max            4674.51
Q Predictions Min            671.10754
V Predictions Mean           1264.2981
V Predictions Std            1203.9199
V Predictions Max            4654.2974
V Predictions Min            684.9982
Log Pis Mean                 -0.7786428
Log Pis Std                  3.5198557
Log Pis Max                  11.9752
Log Pis Min                  -7.0705013
Policy mu Mean               0.036928397
Policy mu Std                0.8224587
Policy mu Max                2.5638378
Policy mu Min                -2.84967
Policy log std Mean          -0.46785152
Policy log std Std           0.27113998
Policy log std Max           0.02387768
Policy log std Min           -2.4173791
Z mean eval                  1.9394159
Z variance eval              0.07506261
total_rewards                [10136.97303095 10479.08104253 10388.31105129 10260.4150996
 10305.3330965   9985.18368427 10315.61136304  9919.82697182
 10116.45980959 10180.12083983]
total_rewards_mean           10208.731598941926
total_rewards_std            166.33863752927164
total_rewards_max            10479.081042526643
total_rewards_min            9919.82697181788
Number of train steps total  1600000
Number of env steps total    4802000
Number of rollouts total     0
Train Time (s)               145.57254185900092
(Previous) Eval Time (s)     17.791263420134783
Sample Time (s)              6.505859424825758
Epoch Time (s)               169.86966470396146
Total Train Time (s)         68593.68638642877
Epoch                        399
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:56:53.148063 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #399 | Epoch Duration: 169.95157957077026
2020-01-13 02:56:53.148225 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9404914
Z variance train             0.075068824
KL Divergence                49.514652
KL Loss                      4.951465
QF Loss                      298.41324
VF Loss                      95.846375
Policy Loss                  -1362.9908
Q Predictions Mean           1362.7937
Q Predictions Std            1325.5211
Q Predictions Max            4625.2534
Q Predictions Min            689.18164
V Predictions Mean           1368.6948
V Predictions Std            1323.6149
V Predictions Max            4643.391
V Predictions Min            699.0817
Log Pis Mean                 -0.5438384
Log Pis Std                  3.662629
Log Pis Max                  16.383741
Log Pis Min                  -8.572298
Policy mu Mean               0.032556053
Policy mu Std                0.87408143
Policy mu Max                2.653739
Policy mu Min                -2.9973626
Policy log std Mean          -0.47978005
Policy log std Std           0.29913327
Policy log std Max           0.010383248
Policy log std Min           -2.6812658
Z mean eval                  1.8975118
Z variance eval              0.08046272
total_rewards                [10455.7329956  10491.3390127  10625.92697884 10501.68698817
 10494.55973583 10505.56412011 10403.99038304 10378.10642102
 10472.99106497 10446.55331257]
total_rewards_mean           10477.645101285198
total_rewards_std            63.73389472241659
total_rewards_max            10625.926978844653
total_rewards_min            10378.106421021039
Number of train steps total  1604000
Number of env steps total    4814000
Number of rollouts total     0
Train Time (s)               147.54965612711385
(Previous) Eval Time (s)     20.726361530832946
Sample Time (s)              7.856264054309577
Epoch Time (s)               176.13228171225637
Total Train Time (s)         68769.90114028193
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 02:59:49.372402 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #400 | Epoch Duration: 176.22403979301453
2020-01-13 02:59:49.372601 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #400 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8959926
Z variance train             0.08060728
KL Divergence                49.043262
KL Loss                      4.9043264
QF Loss                      268.07703
VF Loss                      54.187744
Policy Loss                  -1392.2711
Q Predictions Mean           1386.0889
Q Predictions Std            1364.6765
Q Predictions Max            4764.547
Q Predictions Min            707.3445
V Predictions Mean           1392.8737
V Predictions Std            1365.1265
V Predictions Max            4758.2
V Predictions Min            711.6903
Log Pis Mean                 -0.34766886
Log Pis Std                  3.823209
Log Pis Max                  16.607677
Log Pis Min                  -8.138903
Policy mu Mean               0.0417417
Policy mu Std                0.85917664
Policy mu Max                2.822535
Policy mu Min                -2.4961216
Policy log std Mean          -0.5044164
Policy log std Std           0.28639013
Policy log std Max           0.0030941367
Policy log std Min           -2.7194276
Z mean eval                  1.8907025
Z variance eval              0.07908176
total_rewards                [10181.13560882 10634.45164651 10583.8271003  10628.47556263
 10380.98344822 10429.38348584 10494.38948414 10508.51010645
 10451.60816255 10658.85153375]
total_rewards_mean           10495.161613920476
total_rewards_std            137.79757237536944
total_rewards_max            10658.851533746281
total_rewards_min            10181.135608824967
Number of train steps total  1608000
Number of env steps total    4826000
Number of rollouts total     0
Train Time (s)               146.24460635427386
(Previous) Eval Time (s)     20.84005969297141
Sample Time (s)              5.436967414338142
Epoch Time (s)               172.5216334615834
Total Train Time (s)         68942.50756613119
Epoch                        401
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:02:41.981393 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #401 | Epoch Duration: 172.60865473747253
2020-01-13 03:02:41.981527 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #401 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8914257
Z variance train             0.07958003
KL Divergence                49.156322
KL Loss                      4.9156322
QF Loss                      144.6893
VF Loss                      71.054504
Policy Loss                  -1442.1516
Q Predictions Mean           1439.4854
Q Predictions Std            1354.0951
Q Predictions Max            4672.2397
Q Predictions Min            654.2663
V Predictions Mean           1445.7979
V Predictions Std            1356.6324
V Predictions Max            4662.3774
V Predictions Min            636.99146
Log Pis Mean                 0.0688279
Log Pis Std                  3.8911655
Log Pis Max                  15.387388
Log Pis Min                  -5.5450206
Policy mu Mean               0.1214571
Policy mu Std                0.9058417
Policy mu Max                2.89713
Policy mu Min                -2.6584604
Policy log std Mean          -0.50110143
Policy log std Std           0.29672113
Policy log std Max           -0.029788017
Policy log std Min           -3.006113
Z mean eval                  1.9087007
Z variance eval              0.04927544
total_rewards                [10020.70742393 10454.5346494   9973.21762765 10294.8074457
 10469.3633284  10253.60824097 10293.83901451 10424.46012263
 10239.88335794 10065.7624949 ]
total_rewards_mean           10249.018370604685
total_rewards_std            169.57398051487638
total_rewards_max            10469.363328402946
total_rewards_min            9973.217627652788
Number of train steps total  1612000
Number of env steps total    4838000
Number of rollouts total     0
Train Time (s)               147.01670192694291
(Previous) Eval Time (s)     17.268064606003463
Sample Time (s)              6.365338065195829
Epoch Time (s)               170.6501045981422
Total Train Time (s)         69113.23715629894
Epoch                        402
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:05:32.715181 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #402 | Epoch Duration: 170.73354125022888
2020-01-13 03:05:32.715357 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9093287
Z variance train             0.04923575
KL Divergence                50.174175
KL Loss                      5.0174174
QF Loss                      130.29462
VF Loss                      37.90901
Policy Loss                  -1413.2888
Q Predictions Mean           1412.3329
Q Predictions Std            1371.0259
Q Predictions Max            4663.105
Q Predictions Min            698.7093
V Predictions Mean           1416.2777
V Predictions Std            1368.8014
V Predictions Max            4666.217
V Predictions Min            705.22375
Log Pis Mean                 0.020787477
Log Pis Std                  3.697312
Log Pis Max                  11.540907
Log Pis Min                  -7.9941416
Policy mu Mean               0.016952919
Policy mu Std                0.92344886
Policy mu Max                2.7234552
Policy mu Min                -2.5282722
Policy log std Mean          -0.50719875
Policy log std Std           0.27393925
Policy log std Max           -0.06504363
Policy log std Min           -2.7799015
Z mean eval                  1.9020351
Z variance eval              0.08188798
total_rewards                [10007.84151399 10614.85266385 10094.26223764 10242.07418013
 10403.6013173  10487.15937296 10377.75813903 10472.34304095
 10439.91042286 10056.50760039]
total_rewards_mean           10319.63104890899
total_rewards_std            196.64491308272758
total_rewards_max            10614.852663852991
total_rewards_min            10007.841513985688
Number of train steps total  1616000
Number of env steps total    4850000
Number of rollouts total     0
Train Time (s)               147.07247551577166
(Previous) Eval Time (s)     20.87780385883525
Sample Time (s)              6.531084469053894
Epoch Time (s)               174.4813638436608
Total Train Time (s)         69288.06970913243
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:08:27.581230 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #403 | Epoch Duration: 174.86558175086975
2020-01-13 03:08:27.581730 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #403 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9019037
Z variance train             0.0818142
KL Divergence                50.639668
KL Loss                      5.0639668
QF Loss                      88.938576
VF Loss                      66.23644
Policy Loss                  -1551.7
Q Predictions Mean           1547.9917
Q Predictions Std            1460.049
Q Predictions Max            4646.807
Q Predictions Min            704.4257
V Predictions Mean           1546.9537
V Predictions Std            1455.52
V Predictions Max            4628.9937
V Predictions Min            708.3448
Log Pis Mean                 0.123206556
Log Pis Std                  4.027325
Log Pis Max                  13.753431
Log Pis Min                  -7.54463
Policy mu Mean               0.116163135
Policy mu Std                0.93766564
Policy mu Max                2.8512459
Policy mu Min                -2.7034023
Policy log std Mean          -0.51527065
Policy log std Std           0.29420364
Policy log std Max           -0.07583785
Policy log std Min           -2.6284375
Z mean eval                  1.9048783
Z variance eval              0.045196317
total_rewards                [ 9853.45148005 10458.6067557  10681.29294056 10422.30578566
  9992.68060252 10487.70317458 10473.59654123 10334.78775473
 10483.45138259 10573.59633811]
total_rewards_mean           10376.147275571167
total_rewards_std            244.22400095114963
total_rewards_max            10681.292940562615
total_rewards_min            9853.451480046451
Number of train steps total  1620000
Number of env steps total    4862000
Number of rollouts total     0
Train Time (s)               147.56863400200382
(Previous) Eval Time (s)     18.257526158355176
Sample Time (s)              5.612033978104591
Epoch Time (s)               171.4381941384636
Total Train Time (s)         69459.62204274116
Epoch                        404
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:11:19.112996 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #404 | Epoch Duration: 171.53094005584717
2020-01-13 03:11:19.113278 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9035791
Z variance train             0.045097522
KL Divergence                51.89647
KL Loss                      5.189647
QF Loss                      62.448708
VF Loss                      56.872597
Policy Loss                  -1257.701
Q Predictions Mean           1254.8469
Q Predictions Std            1191.9884
Q Predictions Max            4626.693
Q Predictions Min            691.5789
V Predictions Mean           1257.6493
V Predictions Std            1193.6772
V Predictions Max            4629.8423
V Predictions Min            693.3224
Log Pis Mean                 -0.4249233
Log Pis Std                  3.9518464
Log Pis Max                  15.262182
Log Pis Min                  -7.9909487
Policy mu Mean               0.119920574
Policy mu Std                0.8579678
Policy mu Max                2.7288961
Policy mu Min                -2.9017231
Policy log std Mean          -0.47444698
Policy log std Std           0.28718987
Policy log std Max           -0.03533888
Policy log std Min           -2.5285473
Z mean eval                  1.9271549
Z variance eval              0.04545523
total_rewards                [ 9040.36581613 10410.81695893 10068.99932588 10149.08265198
 10351.85605264 10059.15801608 10149.79738909 10524.50109978
 10437.13109981 10131.39816965]
total_rewards_mean           10132.310657996222
total_rewards_std            396.835718402072
total_rewards_max            10524.501099779998
total_rewards_min            9040.365816128613
Number of train steps total  1624000
Number of env steps total    4874000
Number of rollouts total     0
Train Time (s)               145.59316671732813
(Previous) Eval Time (s)     20.78404233790934
Sample Time (s)              6.371390086598694
Epoch Time (s)               172.74859914183617
Total Train Time (s)         69632.66144053452
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:14:12.156340 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #405 | Epoch Duration: 173.04278588294983
2020-01-13 03:14:12.156680 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #405 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9306023
Z variance train             0.045355685
KL Divergence                50.717556
KL Loss                      5.071756
QF Loss                      143.01958
VF Loss                      45.46712
Policy Loss                  -1531.0287
Q Predictions Mean           1530.2045
Q Predictions Std            1459.9777
Q Predictions Max            4650.2153
Q Predictions Min            692.61646
V Predictions Mean           1527.9799
V Predictions Std            1455.456
V Predictions Max            4634.5786
V Predictions Min            695.5101
Log Pis Mean                 -0.2509101
Log Pis Std                  3.544971
Log Pis Max                  13.789306
Log Pis Min                  -5.608187
Policy mu Mean               0.06766143
Policy mu Std                0.8921502
Policy mu Max                2.7028346
Policy mu Min                -2.6613083
Policy log std Mean          -0.50934815
Policy log std Std           0.292061
Policy log std Max           0.22581631
Policy log std Min           -2.540585
Z mean eval                  1.9113026
Z variance eval              0.08933032
total_rewards                [ 9761.91476524 10010.41458741 10270.51801116 10328.67489336
 10347.02692754 10356.99700205 10338.74287618 10512.5149663
 10399.43254536 10310.53518988]
total_rewards_mean           10263.677176447924
total_rewards_std            205.91625140606521
total_rewards_max            10512.514966299592
total_rewards_min            9761.914765244146
Number of train steps total  1628000
Number of env steps total    4886000
Number of rollouts total     0
Train Time (s)               146.05503563396633
(Previous) Eval Time (s)     17.530388582963496
Sample Time (s)              6.448921694420278
Epoch Time (s)               170.0343459113501
Total Train Time (s)         69802.78374348581
Epoch                        406
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:17:02.282554 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #406 | Epoch Duration: 170.12565636634827
2020-01-13 03:17:02.282780 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9119383
Z variance train             0.089284636
KL Divergence                49.54314
KL Loss                      4.954314
QF Loss                      157.936
VF Loss                      52.6373
Policy Loss                  -1454.8331
Q Predictions Mean           1450.8176
Q Predictions Std            1381.1001
Q Predictions Max            4662.2383
Q Predictions Min            680.4296
V Predictions Mean           1456.5164
V Predictions Std            1381.1368
V Predictions Max            4666.107
V Predictions Min            702.14764
Log Pis Mean                 -0.13694774
Log Pis Std                  4.0394444
Log Pis Max                  19.566591
Log Pis Min                  -7.128259
Policy mu Mean               0.1017443
Policy mu Std                0.88972336
Policy mu Max                4.0167212
Policy mu Min                -3.9662228
Policy log std Mean          -0.4972858
Policy log std Std           0.28805614
Policy log std Max           0.0031924248
Policy log std Min           -2.7353864
Z mean eval                  1.9184656
Z variance eval              0.047562502
total_rewards                [9021.55353495 6900.03137473 9729.35908047 9466.39622991 9685.21852307
 9504.84158563 9458.07763539 9735.17372541 9643.30610432 9683.70311934]
total_rewards_mean           9282.76609132259
total_rewards_std            819.5275435459471
total_rewards_max            9735.173725410787
total_rewards_min            6900.031374726737
Number of train steps total  1632000
Number of env steps total    4898000
Number of rollouts total     0
Train Time (s)               145.95770594710484
(Previous) Eval Time (s)     20.674642940983176
Sample Time (s)              6.458085722755641
Epoch Time (s)               173.09043461084366
Total Train Time (s)         69975.98031010525
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:19:55.481938 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #407 | Epoch Duration: 173.19901204109192
2020-01-13 03:19:55.482072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9198542
Z variance train             0.047561683
KL Divergence                51.408974
KL Loss                      5.1408973
QF Loss                      96.77911
VF Loss                      187.27856
Policy Loss                  -1518.1522
Q Predictions Mean           1517.7821
Q Predictions Std            1472.9191
Q Predictions Max            4738.781
Q Predictions Min            693.8588
V Predictions Mean           1525.6038
V Predictions Std            1474.5701
V Predictions Max            4770.2017
V Predictions Min            694.8026
Log Pis Mean                 -0.6332035
Log Pis Std                  3.698829
Log Pis Max                  14.706481
Log Pis Min                  -8.317611
Policy mu Mean               0.06600802
Policy mu Std                0.86539733
Policy mu Max                3.2599237
Policy mu Min                -3.059905
Policy log std Mean          -0.50233513
Policy log std Std           0.29137227
Policy log std Max           -0.05104947
Policy log std Min           -2.734068
Z mean eval                  1.9040403
Z variance eval              0.03472104
total_rewards                [10152.06355342 10122.14515676 10233.30280918 10111.63739746
 10521.9490896  10700.99210519 10579.2912821  10337.13915585
 10645.89598697 10548.57732447]
total_rewards_mean           10395.299386100949
total_rewards_std            217.60067023640474
total_rewards_max            10700.992105191368
total_rewards_min            10111.637397455697
Number of train steps total  1636000
Number of env steps total    4910000
Number of rollouts total     0
Train Time (s)               144.6892712879926
(Previous) Eval Time (s)     20.71940801013261
Sample Time (s)              6.486786783207208
Epoch Time (s)               171.89546608133242
Total Train Time (s)         70147.95798850898
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:22:47.462829 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #408 | Epoch Duration: 171.9806604385376
2020-01-13 03:22:47.462966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #408 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9032748
Z variance train             0.034642346
KL Divergence                51.761208
KL Loss                      5.1761208
QF Loss                      104.74103
VF Loss                      95.21057
Policy Loss                  -1260.4647
Q Predictions Mean           1259.0157
Q Predictions Std            1239.2526
Q Predictions Max            4615.688
Q Predictions Min            687.251
V Predictions Mean           1264.0597
V Predictions Std            1241.2789
V Predictions Max            4634.2075
V Predictions Min            688.8315
Log Pis Mean                 -0.40070802
Log Pis Std                  3.6125154
Log Pis Max                  13.137016
Log Pis Min                  -6.237115
Policy mu Mean               0.10500238
Policy mu Std                0.852738
Policy mu Max                3.1923788
Policy mu Min                -2.959377
Policy log std Mean          -0.47051883
Policy log std Std           0.27973184
Policy log std Max           -0.061506122
Policy log std Min           -2.6840854
Z mean eval                  1.8972183
Z variance eval              0.060329385
total_rewards                [10195.38218519 10174.75402601 10508.35572272 10060.4427909
 10131.16641144 10338.56199815  2537.62374708 10559.44402788
 10329.98891393  9897.65084255]
total_rewards_mean           9473.337066583337
total_rewards_std            2319.661342378474
total_rewards_max            10559.444027883215
total_rewards_min            2537.6237470791493
Number of train steps total  1640000
Number of env steps total    4922000
Number of rollouts total     0
Train Time (s)               149.62660721875727
(Previous) Eval Time (s)     20.683767335955054
Sample Time (s)              6.628593503963202
Epoch Time (s)               176.93896805867553
Total Train Time (s)         70324.97663286468
Epoch                        409
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:25:44.484660 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #409 | Epoch Duration: 177.02158951759338
2020-01-13 03:25:44.484827 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.898361
Z variance train             0.06061256
KL Divergence                50.95791
KL Loss                      5.095791
QF Loss                      580.7645
VF Loss                      47.348183
Policy Loss                  -1438.6224
Q Predictions Mean           1437.777
Q Predictions Std            1358.7539
Q Predictions Max            4689.0454
Q Predictions Min            693.52045
V Predictions Mean           1438.1655
V Predictions Std            1355.6604
V Predictions Max            4654.231
V Predictions Min            688.8895
Log Pis Mean                 0.0021902397
Log Pis Std                  3.784885
Log Pis Max                  15.419238
Log Pis Min                  -7.8187304
Policy mu Mean               0.04670159
Policy mu Std                0.90317976
Policy mu Max                3.212234
Policy mu Min                -2.8004475
Policy log std Mean          -0.5012701
Policy log std Std           0.28457695
Policy log std Max           0.04518783
Policy log std Min           -2.761546
Z mean eval                  1.9216158
Z variance eval              0.06236539
total_rewards                [10022.64123292 10038.89546783 10047.19971788 10186.22987949
 10238.73484746 10241.2308908  10461.76211658 10444.33594291
 10288.71633908  4367.73002242]
total_rewards_mean           9633.747645737843
total_rewards_std            1761.5105611830609
total_rewards_max            10461.762116584921
total_rewards_min            4367.730022415902
Number of train steps total  1644000
Number of env steps total    4934000
Number of rollouts total     0
Train Time (s)               146.64515613717958
(Previous) Eval Time (s)     20.76957193063572
Sample Time (s)              5.4242078815586865
Epoch Time (s)               172.838935949374
Total Train Time (s)         70497.90971040679
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:28:37.419859 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #410 | Epoch Duration: 172.9349136352539
2020-01-13 03:28:37.419993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #410 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9217046
Z variance train             0.062167536
KL Divergence                50.92323
KL Loss                      5.092323
QF Loss                      175.8577
VF Loss                      58.330154
Policy Loss                  -1362.3218
Q Predictions Mean           1361.1067
Q Predictions Std            1339.69
Q Predictions Max            4733.2837
Q Predictions Min            695.8612
V Predictions Mean           1362.2195
V Predictions Std            1333.0293
V Predictions Max            4724.6846
V Predictions Min            700.52045
Log Pis Mean                 -0.3443896
Log Pis Std                  3.6539109
Log Pis Max                  10.355797
Log Pis Min                  -8.437069
Policy mu Mean               0.09024197
Policy mu Std                0.8729348
Policy mu Max                2.748036
Policy mu Min                -2.7594228
Policy log std Mean          -0.48251942
Policy log std Std           0.28990763
Policy log std Max           -0.06692338
Policy log std Min           -2.789962
Z mean eval                  1.8893859
Z variance eval              0.059290547
total_rewards                [10137.45131425 10207.89222409 10451.94323063 10088.34109845
 10351.68973896 10551.80174229 10329.90292221 10122.36233376
 10376.69305231 10847.73137168]
total_rewards_mean           10346.580902862454
total_rewards_std            220.34316417667227
total_rewards_max            10847.731371677062
total_rewards_min            10088.34109844847
Number of train steps total  1648000
Number of env steps total    4946000
Number of rollouts total     0
Train Time (s)               146.55383007135242
(Previous) Eval Time (s)     17.470764236990362
Sample Time (s)              6.364544781856239
Epoch Time (s)               170.38913909019902
Total Train Time (s)         70668.39760744246
Epoch                        411
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:31:27.914958 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #411 | Epoch Duration: 170.4948501586914
2020-01-13 03:31:27.915147 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8896393
Z variance train             0.05889716
KL Divergence                49.90686
KL Loss                      4.990686
QF Loss                      69.42998
VF Loss                      34.356316
Policy Loss                  -1242.4695
Q Predictions Mean           1242.7384
Q Predictions Std            1214.2166
Q Predictions Max            4677.659
Q Predictions Min            675.4875
V Predictions Mean           1243.9016
V Predictions Std            1213.8802
V Predictions Max            4675.113
V Predictions Min            686.46515
Log Pis Mean                 -0.457246
Log Pis Std                  3.6575263
Log Pis Max                  12.163237
Log Pis Min                  -7.83512
Policy mu Mean               0.09167
Policy mu Std                0.84581834
Policy mu Max                2.6422222
Policy mu Min                -2.52305
Policy log std Mean          -0.47864732
Policy log std Std           0.2753019
Policy log std Max           -0.06319037
Policy log std Min           -2.9306457
Z mean eval                  1.9081268
Z variance eval              0.055146944
total_rewards                [ 9848.33846484 10292.50883623 10028.20097492 10089.21525888
  9517.09762357 10369.75066999 10026.41766858 10370.56570939
 10027.27065446  9888.68974276]
total_rewards_mean           10045.805560361478
total_rewards_std            248.4746601945126
total_rewards_max            10370.565709386727
total_rewards_min            9517.097623573798
Number of train steps total  1652000
Number of env steps total    4958000
Number of rollouts total     0
Train Time (s)               147.36103295581415
(Previous) Eval Time (s)     20.875341047067195
Sample Time (s)              6.434187808539718
Epoch Time (s)               174.67056181142107
Total Train Time (s)         70843.17032394651
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:34:22.693947 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #412 | Epoch Duration: 174.77866458892822
2020-01-13 03:34:22.694092 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #412 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9079773
Z variance train             0.05508669
KL Divergence                50.664608
KL Loss                      5.066461
QF Loss                      136.69135
VF Loss                      113.4421
Policy Loss                  -1325.5526
Q Predictions Mean           1324.5194
Q Predictions Std            1288.1747
Q Predictions Max            4674.022
Q Predictions Min            659.9891
V Predictions Mean           1331.2811
V Predictions Std            1290.5143
V Predictions Max            4694.6235
V Predictions Min            676.55066
Log Pis Mean                 -0.6195383
Log Pis Std                  3.7897599
Log Pis Max                  14.223317
Log Pis Min                  -12.076387
Policy mu Mean               0.03737031
Policy mu Std                0.87058735
Policy mu Max                3.2809937
Policy mu Min                -3.1132305
Policy log std Mean          -0.48413816
Policy log std Std           0.27450758
Policy log std Max           0.08145416
Policy log std Min           -2.9153934
Z mean eval                  1.8864071
Z variance eval              0.051914968
total_rewards                [10580.00491185 10118.82530119 10666.94815985 10183.22600935
 10531.34490025 10748.34644654 10324.94926125 10384.12463992
 10712.05620115 10317.45854227]
total_rewards_mean           10456.728437362563
total_rewards_std            211.23580225983247
total_rewards_max            10748.346446542624
total_rewards_min            10118.825301186498
Number of train steps total  1656000
Number of env steps total    4970000
Number of rollouts total     0
Train Time (s)               148.456434473861
(Previous) Eval Time (s)     20.48492588987574
Sample Time (s)              6.3358022519387305
Epoch Time (s)               175.27716261567548
Total Train Time (s)         71018.52901811246
Epoch                        413
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:37:18.056480 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #413 | Epoch Duration: 175.36228942871094
2020-01-13 03:37:18.056617 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8858938
Z variance train             0.051822376
KL Divergence                50.775673
KL Loss                      5.0775676
QF Loss                      4485.117
VF Loss                      64.52556
Policy Loss                  -1490.6953
Q Predictions Mean           1491.9856
Q Predictions Std            1442.7046
Q Predictions Max            4629.524
Q Predictions Min            670.9963
V Predictions Mean           1494.7422
V Predictions Std            1436.3093
V Predictions Max            4623.161
V Predictions Min            689.27954
Log Pis Mean                 -0.32219306
Log Pis Std                  3.6351945
Log Pis Max                  14.979469
Log Pis Min                  -8.619598
Policy mu Mean               0.065692045
Policy mu Std                0.8824567
Policy mu Max                3.0950818
Policy mu Min                -2.8651373
Policy log std Mean          -0.4962966
Policy log std Std           0.28560624
Policy log std Max           0.051529706
Policy log std Min           -2.706001
Z mean eval                  1.9047245
Z variance eval              0.049020458
total_rewards                [10072.19847103 10370.01947789 10360.97302424 10315.86294732
 10229.49907985 10288.96337508 10559.46132728 10265.31797594
 10351.71114117 10360.88567238]
total_rewards_mean           10317.489249217893
total_rewards_std            117.34700059451615
total_rewards_max            10559.461327275943
total_rewards_min            10072.19847102722
Number of train steps total  1660000
Number of env steps total    4982000
Number of rollouts total     0
Train Time (s)               146.4452155227773
(Previous) Eval Time (s)     17.613607332110405
Sample Time (s)              6.5380096337758005
Epoch Time (s)               170.5968324886635
Total Train Time (s)         71189.20772393327
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:40:08.742268 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #414 | Epoch Duration: 170.68549585342407
2020-01-13 03:40:08.742588 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9030335
Z variance train             0.049007714
KL Divergence                51.117786
KL Loss                      5.1117787
QF Loss                      4479.4785
VF Loss                      88.2288
Policy Loss                  -1353.4705
Q Predictions Mean           1351.0798
Q Predictions Std            1318.5839
Q Predictions Max            4616.165
Q Predictions Min            683.39874
V Predictions Mean           1355.4924
V Predictions Std            1323.6558
V Predictions Max            4643.148
V Predictions Min            679.95953
Log Pis Mean                 -0.33871046
Log Pis Std                  3.7094655
Log Pis Max                  13.109023
Log Pis Min                  -7.0882816
Policy mu Mean               0.028483475
Policy mu Std                0.8574167
Policy mu Max                3.1066918
Policy mu Min                -2.6727235
Policy log std Mean          -0.49156967
Policy log std Std           0.31515914
Policy log std Max           0.040480673
Policy log std Min           -2.799239
Z mean eval                  1.9117801
Z variance eval              0.047973588
total_rewards                [10077.03456934 10158.32913838 10236.51563998  9917.54576903
 10272.09990461 10564.78818909 10304.47774205 10251.84277101
 10334.63319189 10392.38527851]
total_rewards_mean           10250.965219388254
total_rewards_std            167.0348732766465
total_rewards_max            10564.788189088142
total_rewards_min            9917.545769028582
Number of train steps total  1664000
Number of env steps total    4994000
Number of rollouts total     0
Train Time (s)               145.84422278031707
(Previous) Eval Time (s)     20.85423147585243
Sample Time (s)              6.639511271379888
Epoch Time (s)               173.3379655275494
Total Train Time (s)         71362.6301852935
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:43:02.164233 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #415 | Epoch Duration: 173.42139196395874
2020-01-13 03:43:02.164369 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9090321
Z variance train             0.048072636
KL Divergence                49.95606
KL Loss                      4.995606
QF Loss                      318.5901
VF Loss                      28.482796
Policy Loss                  -1249.6987
Q Predictions Mean           1249.278
Q Predictions Std            1200.3038
Q Predictions Max            4674.6636
Q Predictions Min            678.27954
V Predictions Mean           1251.0793
V Predictions Std            1199.079
V Predictions Max            4694.9233
V Predictions Min            681.37836
Log Pis Mean                 -0.37968627
Log Pis Std                  3.4127333
Log Pis Max                  17.227453
Log Pis Min                  -6.808982
Policy mu Mean               0.07913401
Policy mu Std                0.85954875
Policy mu Max                2.8972535
Policy mu Min                -3.759299
Policy log std Mean          -0.47546014
Policy log std Std           0.2672964
Policy log std Max           0.061985493
Policy log std Min           -2.9416418
Z mean eval                  1.9202328
Z variance eval              0.09039552
total_rewards                [ 9993.91765485 10566.68320112 10196.55062133 10384.13437764
 10134.2606386  10565.42222314 10461.37687632 10085.54778094
 10337.67582365 10389.53666379]
total_rewards_mean           10311.510586137098
total_rewards_std            189.9075533160327
total_rewards_max            10566.683201115393
total_rewards_min            9993.91765484697
Number of train steps total  1668000
Number of env steps total    5006000
Number of rollouts total     0
Train Time (s)               145.22856312105432
(Previous) Eval Time (s)     17.817012610845268
Sample Time (s)              6.609399145934731
Epoch Time (s)               169.65497487783432
Total Train Time (s)         71532.36522533651
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:45:51.903394 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #416 | Epoch Duration: 169.73891472816467
2020-01-13 03:45:51.903576 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #416 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9192501
Z variance train             0.09033766
KL Divergence                49.96923
KL Loss                      4.996923
QF Loss                      217.94226
VF Loss                      67.3744
Policy Loss                  -1413.004
Q Predictions Mean           1409.77
Q Predictions Std            1384.7948
Q Predictions Max            4738.61
Q Predictions Min            670.6586
V Predictions Mean           1416.2336
V Predictions Std            1379.1298
V Predictions Max            4704.6855
V Predictions Min            683.3442
Log Pis Mean                 -0.4071174
Log Pis Std                  3.849716
Log Pis Max                  19.150265
Log Pis Min                  -6.771483
Policy mu Mean               0.05351563
Policy mu Std                0.8955893
Policy mu Max                2.9305935
Policy mu Min                -2.8508265
Policy log std Mean          -0.49699935
Policy log std Std           0.29463968
Policy log std Max           -0.08809477
Policy log std Min           -2.9315991
Z mean eval                  1.8951561
Z variance eval              0.052683067
total_rewards                [ 9727.27015001 10176.86886251 10121.20768424  9867.93726966
 10190.17784999 10019.09770919 10055.09683776 10108.17784449
 10195.10561784 10183.04586313]
total_rewards_mean           10064.398568882605
total_rewards_std            148.04280162705882
total_rewards_max            10195.105617840225
total_rewards_min            9727.2701500129
Number of train steps total  1672000
Number of env steps total    5018000
Number of rollouts total     0
Train Time (s)               145.67443236894906
(Previous) Eval Time (s)     20.715956420172006
Sample Time (s)              6.584896146319807
Epoch Time (s)               172.97528493544087
Total Train Time (s)         71705.42732709227
Epoch                        417
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:48:44.968321 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #417 | Epoch Duration: 173.06461453437805
2020-01-13 03:48:44.968467 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8953774
Z variance train             0.052962057
KL Divergence                49.511055
KL Loss                      4.9511056
QF Loss                      147.67294
VF Loss                      52.705566
Policy Loss                  -1439.3813
Q Predictions Mean           1438.3054
Q Predictions Std            1395.9504
Q Predictions Max            4737.3696
Q Predictions Min            680.9345
V Predictions Mean           1436.2761
V Predictions Std            1387.0684
V Predictions Max            4721.2246
V Predictions Min            682.11176
Log Pis Mean                 -0.29648617
Log Pis Std                  3.687315
Log Pis Max                  13.249498
Log Pis Min                  -8.209368
Policy mu Mean               0.10772133
Policy mu Std                0.8801426
Policy mu Max                2.6569192
Policy mu Min                -2.8670819
Policy log std Mean          -0.49844554
Policy log std Std           0.30773842
Policy log std Max           -0.034392744
Policy log std Min           -3.170532
Z mean eval                  1.895586
Z variance eval              0.088887885
total_rewards                [10088.34513316 10077.87525678 10521.53872767 10389.75032566
 10083.67515606 10197.44777532 10502.97726864 10217.50387416
 10444.2439429  10459.48073907]
total_rewards_mean           10298.283819942477
total_rewards_std            174.01191359615746
total_rewards_max            10521.538727670284
total_rewards_min            10077.875256780952
Number of train steps total  1676000
Number of env steps total    5030000
Number of rollouts total     0
Train Time (s)               145.51977327885106
(Previous) Eval Time (s)     20.817774121183902
Sample Time (s)              6.534645848441869
Epoch Time (s)               172.87219324847683
Total Train Time (s)         71878.37664187187
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:51:37.920300 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #418 | Epoch Duration: 172.95173263549805
2020-01-13 03:51:37.920431 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #418 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8945484
Z variance train             0.088657215
KL Divergence                48.90981
KL Loss                      4.890981
QF Loss                      110.48957
VF Loss                      58.332558
Policy Loss                  -1344.0865
Q Predictions Mean           1341.951
Q Predictions Std            1320.4264
Q Predictions Max            4679.668
Q Predictions Min            695.7211
V Predictions Mean           1342.4121
V Predictions Std            1314.1053
V Predictions Max            4659.051
V Predictions Min            697.92316
Log Pis Mean                 -0.21328449
Log Pis Std                  3.8451986
Log Pis Max                  20.92426
Log Pis Min                  -9.538202
Policy mu Mean               0.08821279
Policy mu Std                0.8951096
Policy mu Max                3.0155115
Policy mu Min                -3.3716512
Policy log std Mean          -0.48944154
Policy log std Std           0.28181142
Policy log std Max           -0.0489676
Policy log std Min           -2.5961473
Z mean eval                  1.9051679
Z variance eval              0.05230831
total_rewards                [10416.77257356 10656.82271874 10457.33151102 10798.62037093
 10824.28035009 10887.39538031 10300.35000963 10763.71902259
 10827.9754278  10887.51777466]
total_rewards_mean           10682.078513932396
total_rewards_std            203.31446523542408
total_rewards_max            10887.517774659673
total_rewards_min            10300.3500096262
Number of train steps total  1680000
Number of env steps total    5042000
Number of rollouts total     0
Train Time (s)               146.3434685477987
(Previous) Eval Time (s)     20.63211562903598
Sample Time (s)              6.596232309937477
Epoch Time (s)               173.57181648677215
Total Train Time (s)         72052.0823740419
Epoch                        419
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:54:31.648677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #419 | Epoch Duration: 173.72810888290405
2020-01-13 03:54:31.648967 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046484
Z variance train             0.05262629
KL Divergence                49.78643
KL Loss                      4.978643
QF Loss                      120.057945
VF Loss                      71.24375
Policy Loss                  -1300.93
Q Predictions Mean           1299.4507
Q Predictions Std            1281.3684
Q Predictions Max            4729.4883
Q Predictions Min            688.50275
V Predictions Mean           1302.5768
V Predictions Std            1278.6549
V Predictions Max            4696.3623
V Predictions Min            688.43896
Log Pis Mean                 -0.56312174
Log Pis Std                  3.4269521
Log Pis Max                  11.639732
Log Pis Min                  -6.4594936
Policy mu Mean               -0.01335979
Policy mu Std                0.86223793
Policy mu Max                2.7800672
Policy mu Min                -2.7978168
Policy log std Mean          -0.4914458
Policy log std Std           0.27327588
Policy log std Max           -0.065935045
Policy log std Min           -3.060028
Z mean eval                  1.9179713
Z variance eval              0.054015595
total_rewards                [10254.34737091 10511.01109638 10620.1810199  10533.99846966
 10650.14811662 10500.47665591 10726.56947747 10432.80855638
 10542.22862795 10795.45072685]
total_rewards_mean           10556.722011803544
total_rewards_std            145.38206802569715
total_rewards_max            10795.450726851666
total_rewards_min            10254.347370908674
Number of train steps total  1684000
Number of env steps total    5054000
Number of rollouts total     0
Train Time (s)               146.03571323072538
(Previous) Eval Time (s)     20.81830655504018
Sample Time (s)              8.621596432756633
Epoch Time (s)               175.4756162185222
Total Train Time (s)         72227.6696280567
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 03:57:27.223142 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #420 | Epoch Duration: 175.57396984100342
2020-01-13 03:57:27.223279 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9196889
Z variance train             0.05403748
KL Divergence                50.20552
KL Loss                      5.020552
QF Loss                      106.13934
VF Loss                      79.413086
Policy Loss                  -1275.3733
Q Predictions Mean           1271.3417
Q Predictions Std            1239.26
Q Predictions Max            4706.5996
Q Predictions Min            688.83923
V Predictions Mean           1270.0295
V Predictions Std            1234.7999
V Predictions Max            4698.298
V Predictions Min            685.8922
Log Pis Mean                 -0.540437
Log Pis Std                  3.5205674
Log Pis Max                  12.268975
Log Pis Min                  -6.8160996
Policy mu Mean               0.066494934
Policy mu Std                0.8388445
Policy mu Max                3.4995947
Policy mu Min                -2.7597845
Policy log std Mean          -0.48797974
Policy log std Std           0.29075852
Policy log std Max           -0.008509815
Policy log std Min           -2.7096539
Z mean eval                  1.9067341
Z variance eval              0.04999695
total_rewards                [10333.45146788 10611.68770626 10887.40679357 10793.68170566
 10623.99611504 10718.42673641 10846.21095839 10612.01032177
 10341.50779513 10583.14073054]
total_rewards_mean           10635.152033065577
total_rewards_std            179.27927390153852
total_rewards_max            10887.406793573924
total_rewards_min            10333.451467876517
Number of train steps total  1688000
Number of env steps total    5066000
Number of rollouts total     0
Train Time (s)               147.33268348500133
(Previous) Eval Time (s)     20.714878904633224
Sample Time (s)              6.3484950377605855
Epoch Time (s)               174.39605742739514
Total Train Time (s)         72402.14744600747
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:00:21.704058 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #421 | Epoch Duration: 174.48068380355835
2020-01-13 04:00:21.704192 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #421 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9034961
Z variance train             0.049895417
KL Divergence                50.50301
KL Loss                      5.050301
QF Loss                      107.02425
VF Loss                      95.32562
Policy Loss                  -1361.4302
Q Predictions Mean           1359.0994
Q Predictions Std            1310.4183
Q Predictions Max            4746.247
Q Predictions Min            664.00146
V Predictions Mean           1362.4174
V Predictions Std            1311.7568
V Predictions Max            4756.7393
V Predictions Min            651.03265
Log Pis Mean                 -0.13518824
Log Pis Std                  3.959503
Log Pis Max                  17.24668
Log Pis Min                  -8.73677
Policy mu Mean               0.049543116
Policy mu Std                0.9002575
Policy mu Max                3.225898
Policy mu Min                -3.286909
Policy log std Mean          -0.4933783
Policy log std Std           0.27321997
Policy log std Max           -0.043605924
Policy log std Min           -2.8751194
Z mean eval                  1.8832439
Z variance eval              0.08442445
total_rewards                [10032.52220915 10406.20459433 10648.18329795 10845.52407724
 10506.48368447 10312.50778881 10656.80287969 10678.32437418
 10810.86886657 10878.07362057]
total_rewards_mean           10577.549539296473
total_rewards_std            252.92294044922812
total_rewards_max            10878.073620570245
total_rewards_min            10032.522209152547
Number of train steps total  1692000
Number of env steps total    5078000
Number of rollouts total     0
Train Time (s)               146.9567560260184
(Previous) Eval Time (s)     20.609389916993678
Sample Time (s)              6.396866306196898
Epoch Time (s)               173.963012249209
Total Train Time (s)         72576.19756108476
Epoch                        422
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:03:15.757486 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #422 | Epoch Duration: 174.05319356918335
2020-01-13 04:03:15.757621 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #422 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8823969
Z variance train             0.084244385
KL Divergence                49.655647
KL Loss                      4.9655647
QF Loss                      156.62694
VF Loss                      118.66877
Policy Loss                  -1404.0399
Q Predictions Mean           1400.989
Q Predictions Std            1371.9249
Q Predictions Max            4703.492
Q Predictions Min            665.93884
V Predictions Mean           1400.9017
V Predictions Std            1362.0557
V Predictions Max            4686.586
V Predictions Min            675.0156
Log Pis Mean                 -0.6697594
Log Pis Std                  3.7378368
Log Pis Max                  14.782316
Log Pis Min                  -6.591645
Policy mu Mean               0.01472953
Policy mu Std                0.86166537
Policy mu Max                3.5941627
Policy mu Min                -2.6805322
Policy log std Mean          -0.49515995
Policy log std Std           0.29295358
Policy log std Max           0.0014413297
Policy log std Min           -2.9152918
Z mean eval                  1.8961376
Z variance eval              0.11275921
total_rewards                [ 9809.26084644 10281.70338736 10397.46283387 10173.8047025
 10145.81597742 10202.16503894 10150.49236571 10174.65949614
 10302.74507946 10063.77433644]
total_rewards_mean           10170.188406427493
total_rewards_std            150.09687150024817
total_rewards_max            10397.462833867252
total_rewards_min            9809.260846436482
Number of train steps total  1696000
Number of env steps total    5090000
Number of rollouts total     0
Train Time (s)               147.9545729327947
(Previous) Eval Time (s)     21.001318227965385
Sample Time (s)              6.574464097153395
Epoch Time (s)               175.53035525791347
Total Train Time (s)         72751.81169264344
Epoch                        423
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:06:11.375543 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #423 | Epoch Duration: 175.61781120300293
2020-01-13 04:06:11.375723 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #423 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.894201
Z variance train             0.112690076
KL Divergence                49.22386
KL Loss                      4.922386
QF Loss                      327.42172
VF Loss                      73.52609
Policy Loss                  -1551.0044
Q Predictions Mean           1543.9172
Q Predictions Std            1468.678
Q Predictions Max            4798.392
Q Predictions Min            691.71246
V Predictions Mean           1551.2965
V Predictions Std            1465.6459
V Predictions Max            4791.703
V Predictions Min            702.4459
Log Pis Mean                 -0.07596585
Log Pis Std                  4.229339
Log Pis Max                  23.620754
Log Pis Min                  -8.451209
Policy mu Mean               0.031022834
Policy mu Std                0.92968464
Policy mu Max                3.2298107
Policy mu Min                -3.572475
Policy log std Mean          -0.52026385
Policy log std Std           0.29819816
Policy log std Max           -0.049028724
Policy log std Min           -2.729099
Z mean eval                  1.9062674
Z variance eval              0.107914865
total_rewards                [10342.09043922 10620.17305676 10544.79981012 10565.63469913
 10627.95122393 10722.13909673 10739.58433593 10285.65310691
 10383.67995529 10773.05959156]
total_rewards_mean           10560.476531559934
total_rewards_std            163.17850744769967
total_rewards_max            10773.059591562493
total_rewards_min            10285.653106913234
Number of train steps total  1700000
Number of env steps total    5102000
Number of rollouts total     0
Train Time (s)               145.97968639899045
(Previous) Eval Time (s)     21.007165275048465
Sample Time (s)              6.403328616637737
Epoch Time (s)               173.39018029067665
Total Train Time (s)         72925.28572511999
Epoch                        424
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:09:04.852073 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #424 | Epoch Duration: 173.4762237071991
2020-01-13 04:09:04.852206 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9078194
Z variance train             0.108356334
KL Divergence                49.100407
KL Loss                      4.910041
QF Loss                      171.79646
VF Loss                      68.39865
Policy Loss                  -1514.0137
Q Predictions Mean           1512.9221
Q Predictions Std            1467.0681
Q Predictions Max            4695.462
Q Predictions Min            695.8809
V Predictions Mean           1509.7793
V Predictions Std            1459.8679
V Predictions Max            4678.2925
V Predictions Min            697.9403
Log Pis Mean                 -0.33023864
Log Pis Std                  4.071907
Log Pis Max                  15.026672
Log Pis Min                  -7.3767443
Policy mu Mean               0.073474
Policy mu Std                0.8790862
Policy mu Max                2.777174
Policy mu Min                -2.7942383
Policy log std Mean          -0.50430393
Policy log std Std           0.2945523
Policy log std Max           -0.051397145
Policy log std Min           -2.7429802
Z mean eval                  1.8830004
Z variance eval              0.07587813
total_rewards                [9780.32830344 9533.79953125 9794.37508154 9435.71211414 5882.20342252
 8812.7479142  9089.89911379 9788.63869989 9645.69092619 9749.88054792]
total_rewards_mean           9151.327565488007
total_rewards_std            1133.6101621210091
total_rewards_max            9794.375081542148
total_rewards_min            5882.20342252042
Number of train steps total  1704000
Number of env steps total    5114000
Number of rollouts total     0
Train Time (s)               145.18037056317553
(Previous) Eval Time (s)     20.70946630835533
Sample Time (s)              6.477448559831828
Epoch Time (s)               172.3672854313627
Total Train Time (s)         73097.72871010425
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:11:57.297420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #425 | Epoch Duration: 172.4451162815094
2020-01-13 04:11:57.297552 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8817803
Z variance train             0.07568092
KL Divergence                48.78075
KL Loss                      4.878075
QF Loss                      92.53147
VF Loss                      57.096195
Policy Loss                  -1452.8613
Q Predictions Mean           1449.2374
Q Predictions Std            1384.9773
Q Predictions Max            4741.1743
Q Predictions Min            663.6585
V Predictions Mean           1455.1782
V Predictions Std            1382.9597
V Predictions Max            4691.38
V Predictions Min            679.9805
Log Pis Mean                 -0.0023521483
Log Pis Std                  3.9969285
Log Pis Max                  13.569023
Log Pis Min                  -7.1639566
Policy mu Mean               0.08742782
Policy mu Std                0.9242485
Policy mu Max                3.2683961
Policy mu Min                -2.5247812
Policy log std Mean          -0.50161725
Policy log std Std           0.31714454
Policy log std Max           -0.0070199966
Policy log std Min           -2.8351846
Z mean eval                  1.8815165
Z variance eval              0.05259949
total_rewards                [10743.0611087  11044.86549384 10936.61725261 10889.41037995
 10719.67192232 10757.91020471 11069.61288059 10649.83768015
 10655.7289245  10802.4977244 ]
total_rewards_mean           10826.921357176443
total_rewards_std            143.83893871685893
total_rewards_max            11069.61288058858
total_rewards_min            10649.83768014959
Number of train steps total  1708000
Number of env steps total    5126000
Number of rollouts total     0
Train Time (s)               146.02187874075025
(Previous) Eval Time (s)     20.964037926401943
Sample Time (s)              6.386199675966054
Epoch Time (s)               173.37211634311825
Total Train Time (s)         73271.19776715711
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:14:50.769246 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #426 | Epoch Duration: 173.47160005569458
2020-01-13 04:14:50.769384 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8810203
Z variance train             0.05242799
KL Divergence                50.42947
KL Loss                      5.0429473
QF Loss                      12615.893
VF Loss                      78.05677
Policy Loss                  -1382.4568
Q Predictions Mean           1379.1156
Q Predictions Std            1281.0632
Q Predictions Max            4711.8535
Q Predictions Min            675.17883
V Predictions Mean           1385.1665
V Predictions Std            1278.4944
V Predictions Max            4703.565
V Predictions Min            692.48114
Log Pis Mean                 -0.0261468
Log Pis Std                  4.12001
Log Pis Max                  14.686729
Log Pis Min                  -7.691976
Policy mu Mean               0.06707336
Policy mu Std                0.9057575
Policy mu Max                2.9326742
Policy mu Min                -3.0936062
Policy log std Mean          -0.5051878
Policy log std Std           0.2848545
Policy log std Max           -0.08872169
Policy log std Min           -2.587383
Z mean eval                  1.882745
Z variance eval              0.084159344
total_rewards                [ 9899.00211365 10727.31462526 10428.35441824 10260.84465061
 10528.27344507 10556.55665729 10210.91577309 10375.40738054
 10009.64821855 10047.56173905]
total_rewards_mean           10304.387902135357
total_rewards_std            253.1391206950038
total_rewards_max            10727.314625262055
total_rewards_min            9899.002113652292
Number of train steps total  1712000
Number of env steps total    5138000
Number of rollouts total     0
Train Time (s)               147.19543016003445
(Previous) Eval Time (s)     20.69324969733134
Sample Time (s)              6.390401181764901
Epoch Time (s)               174.2790810391307
Total Train Time (s)         73445.56434388366
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:17:45.138911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #427 | Epoch Duration: 174.3694293498993
2020-01-13 04:17:45.139049 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8813183
Z variance train             0.0848428
KL Divergence                50.271935
KL Loss                      5.0271935
QF Loss                      106.22778
VF Loss                      81.139114
Policy Loss                  -1438.2771
Q Predictions Mean           1436.7894
Q Predictions Std            1376.5328
Q Predictions Max            4728.0273
Q Predictions Min            694.3598
V Predictions Mean           1436.936
V Predictions Std            1380.125
V Predictions Max            4729.0063
V Predictions Min            693.0442
Log Pis Mean                 -0.36538562
Log Pis Std                  3.8452222
Log Pis Max                  14.96969
Log Pis Min                  -8.22176
Policy mu Mean               0.035875197
Policy mu Std                0.8541421
Policy mu Max                2.7181063
Policy mu Min                -2.8269384
Policy log std Mean          -0.48820877
Policy log std Std           0.29766077
Policy log std Max           0.07099354
Policy log std Min           -3.0396955
Z mean eval                  1.897753
Z variance eval              0.07532557
total_rewards                [10353.99949639 10814.12189332 10590.37630034 10602.00137884
 10570.45143868 10389.29006195 10817.77317937 10686.25663023
 10846.390428   10727.52924142]
total_rewards_mean           10639.819004853196
total_rewards_std            163.61987422745588
total_rewards_max            10846.390427995426
total_rewards_min            10353.999496387021
Number of train steps total  1716000
Number of env steps total    5150000
Number of rollouts total     0
Train Time (s)               145.45114495698363
(Previous) Eval Time (s)     17.679213162045926
Sample Time (s)              6.564122166018933
Epoch Time (s)               169.69448028504848
Total Train Time (s)         73615.35480933543
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:20:34.954350 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #428 | Epoch Duration: 169.8151569366455
2020-01-13 04:20:34.954678 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #428 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8977578
Z variance train             0.075260974
KL Divergence                49.89399
KL Loss                      4.989399
QF Loss                      174.16055
VF Loss                      57.602997
Policy Loss                  -1244.3351
Q Predictions Mean           1241.0162
Q Predictions Std            1207.2877
Q Predictions Max            4721.5874
Q Predictions Min            687.12933
V Predictions Mean           1247.1249
V Predictions Std            1203.3602
V Predictions Max            4739.6123
V Predictions Min            702.47943
Log Pis Mean                 -0.32065892
Log Pis Std                  4.015864
Log Pis Max                  18.795448
Log Pis Min                  -6.8898687
Policy mu Mean               0.07331815
Policy mu Std                0.8871283
Policy mu Max                3.6560488
Policy mu Min                -2.7155125
Policy log std Mean          -0.48769593
Policy log std Std           0.27985093
Policy log std Max           0.06385577
Policy log std Min           -2.6231873
Z mean eval                  1.8989786
Z variance eval              0.05113002
total_rewards                [ 9942.5749371  10248.22241107 10190.68763715 10030.49886403
 10031.63452162 10191.29757543 10030.00001437  9828.6675321
 10311.56389378 10144.09349107]
total_rewards_mean           10094.924087771762
total_rewards_std            140.63550380268313
total_rewards_max            10311.563893775574
total_rewards_min            9828.667532098843
Number of train steps total  1720000
Number of env steps total    5162000
Number of rollouts total     0
Train Time (s)               148.3274369230494
(Previous) Eval Time (s)     20.919686214998364
Sample Time (s)              6.638114570174366
Epoch Time (s)               175.88523770822212
Total Train Time (s)         73791.33675222797
Epoch                        429
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:23:30.925713 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #429 | Epoch Duration: 175.97081971168518
2020-01-13 04:23:30.925857 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.900494
Z variance train             0.051228743
KL Divergence                51.5524
KL Loss                      5.15524
QF Loss                      195.35889
VF Loss                      65.525826
Policy Loss                  -1446.9036
Q Predictions Mean           1443.7968
Q Predictions Std            1376.5957
Q Predictions Max            4755.944
Q Predictions Min            659.9003
V Predictions Mean           1450.9425
V Predictions Std            1376.2563
V Predictions Max            4760.945
V Predictions Min            681.48535
Log Pis Mean                 0.10315192
Log Pis Std                  4.2405386
Log Pis Max                  21.33192
Log Pis Min                  -6.7418203
Policy mu Mean               0.04858015
Policy mu Std                0.94248825
Policy mu Max                3.803758
Policy mu Min                -3.4389307
Policy log std Mean          -0.5024056
Policy log std Std           0.31422895
Policy log std Max           -0.020439506
Policy log std Min           -3.0640583
Z mean eval                  1.886885
Z variance eval              0.08246843
total_rewards                [10248.67103213 10821.63781382 10657.64355585 10557.51483471
 10384.94256488 10771.72299969 10350.34606744 10563.00864207
 10540.81924728 10931.02376796]
total_rewards_mean           10582.733052583873
total_rewards_std            206.6917246342968
total_rewards_max            10931.023767961393
total_rewards_min            10248.671032129674
Number of train steps total  1724000
Number of env steps total    5174000
Number of rollouts total     0
Train Time (s)               147.18829761072993
(Previous) Eval Time (s)     20.831570502836257
Sample Time (s)              6.512115796096623
Epoch Time (s)               174.5319839096628
Total Train Time (s)         73965.95450416859
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:26:25.546757 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #430 | Epoch Duration: 174.62080264091492
2020-01-13 04:26:25.546893 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #430 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8860216
Z variance train             0.082351334
KL Divergence                50.82055
KL Loss                      5.082055
QF Loss                      237.53929
VF Loss                      73.34516
Policy Loss                  -1353.3473
Q Predictions Mean           1350.1384
Q Predictions Std            1312.2878
Q Predictions Max            4756.881
Q Predictions Min            676.89197
V Predictions Mean           1354.6863
V Predictions Std            1313.1101
V Predictions Max            4775.644
V Predictions Min            678.5368
Log Pis Mean                 -0.19093198
Log Pis Std                  3.8410575
Log Pis Max                  16.573545
Log Pis Min                  -6.9224186
Policy mu Mean               0.09888067
Policy mu Std                0.86865866
Policy mu Max                3.4176552
Policy mu Min                -2.7237153
Policy log std Mean          -0.48908213
Policy log std Std           0.29003766
Policy log std Max           -0.054974318
Policy log std Min           -3.0262687
Z mean eval                  1.9241663
Z variance eval              0.106581315
total_rewards                [10435.10563475 10380.55953228 10428.51767829 10678.80818903
 10675.21848584 10617.5896902  10760.78710401 10388.84265396
 10871.87189208  5205.19939801]
total_rewards_mean           10044.250025845158
total_rewards_std            1621.0051155546655
total_rewards_max            10871.871892080017
total_rewards_min            5205.199398005823
Number of train steps total  1728000
Number of env steps total    5186000
Number of rollouts total     0
Train Time (s)               147.2366073615849
(Previous) Eval Time (s)     20.78831843007356
Sample Time (s)              6.382857249584049
Epoch Time (s)               174.4077830412425
Total Train Time (s)         74140.43988292804
Epoch                        431
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:29:20.037383 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #431 | Epoch Duration: 174.49039363861084
2020-01-13 04:29:20.037516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #431 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9280317
Z variance train             0.1061942
KL Divergence                49.39197
KL Loss                      4.939197
QF Loss                      130.10303
VF Loss                      60.506226
Policy Loss                  -1283.7834
Q Predictions Mean           1280.5907
Q Predictions Std            1260.852
Q Predictions Max            4807.0063
Q Predictions Min            696.17566
V Predictions Mean           1285.4177
V Predictions Std            1262.0133
V Predictions Max            4821.53
V Predictions Min            698.3948
Log Pis Mean                 -0.41143608
Log Pis Std                  4.047982
Log Pis Max                  17.165508
Log Pis Min                  -8.583809
Policy mu Mean               0.061752196
Policy mu Std                0.8843565
Policy mu Max                3.4753914
Policy mu Min                -3.192459
Policy log std Mean          -0.4903345
Policy log std Std           0.2812607
Policy log std Max           0.13885558
Policy log std Min           -2.9134183
Z mean eval                  1.8951963
Z variance eval              0.0868473
total_rewards                [10164.83774372 10558.32087417 10490.74836458 10404.9884343
 10470.25692796 10415.32479048 10532.21734534 10710.60369618
 10496.19744396 10599.22134983]
total_rewards_mean           10484.271697053126
total_rewards_std            136.2643786765058
total_rewards_max            10710.60369618493
total_rewards_min            10164.837743721117
Number of train steps total  1732000
Number of env steps total    5198000
Number of rollouts total     0
Train Time (s)               146.2763920542784
(Previous) Eval Time (s)     17.562435451895
Sample Time (s)              6.324753407854587
Epoch Time (s)               170.163580914028
Total Train Time (s)         74310.69605106348
Epoch                        432
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:32:10.297962 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #432 | Epoch Duration: 170.26034140586853
2020-01-13 04:32:10.298131 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #432 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8937212
Z variance train             0.08669703
KL Divergence                48.528835
KL Loss                      4.852884
QF Loss                      4459.1426
VF Loss                      58.41676
Policy Loss                  -1200.8743
Q Predictions Mean           1197.833
Q Predictions Std            1164.2252
Q Predictions Max            4870.623
Q Predictions Min            686.65094
V Predictions Mean           1200.3389
V Predictions Std            1161.6222
V Predictions Max            4848.613
V Predictions Min            691.6614
Log Pis Mean                 -0.4050876
Log Pis Std                  3.5907907
Log Pis Max                  21.558306
Log Pis Min                  -6.410951
Policy mu Mean               0.07818698
Policy mu Std                0.8494072
Policy mu Max                3.8779628
Policy mu Min                -3.2926114
Policy log std Mean          -0.46784726
Policy log std Std           0.28342587
Policy log std Max           -0.016708732
Policy log std Min           -3.0891795
Z mean eval                  1.8889297
Z variance eval              0.06489781
total_rewards                [10467.69113388 10802.85584091 10463.66676284 10684.30310003
 10577.6253947  10331.88986526 10343.82983424 10697.5382136
 10500.77258309 10793.99532206]
total_rewards_mean           10566.416805060619
total_rewards_std            163.72915810926537
total_rewards_max            10802.855840913791
total_rewards_min            10331.889865263336
Number of train steps total  1736000
Number of env steps total    5210000
Number of rollouts total     0
Train Time (s)               146.5844216630794
(Previous) Eval Time (s)     20.562145273201168
Sample Time (s)              6.312064338475466
Epoch Time (s)               173.45863127475604
Total Train Time (s)         74484.23353413166
Epoch                        433
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:35:03.840182 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #433 | Epoch Duration: 173.54191780090332
2020-01-13 04:35:03.840358 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #433 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8878514
Z variance train             0.065038815
KL Divergence                48.724487
KL Loss                      4.872449
QF Loss                      4297.9946
VF Loss                      84.02727
Policy Loss                  -1369.9265
Q Predictions Mean           1369.0579
Q Predictions Std            1323.8356
Q Predictions Max            4775.8833
Q Predictions Min            676.7667
V Predictions Mean           1375.0271
V Predictions Std            1323.0685
V Predictions Max            4776.9893
V Predictions Min            676.2895
Log Pis Mean                 -0.33028796
Log Pis Std                  3.4939146
Log Pis Max                  16.93302
Log Pis Min                  -6.3316565
Policy mu Mean               0.048905477
Policy mu Std                0.8839806
Policy mu Max                3.184321
Policy mu Min                -2.6295125
Policy log std Mean          -0.49362978
Policy log std Std           0.2693448
Policy log std Max           -0.06294137
Policy log std Min           -2.8175974
Z mean eval                  1.8742397
Z variance eval              0.05191944
total_rewards                [10693.20436706 10719.23510677 10598.2336079  10772.3395106
 10400.73613767 10419.20388286 10487.38298972 10838.02673681
 10613.65001154 10761.67984085]
total_rewards_mean           10630.369219177855
total_rewards_std            145.4113241961455
total_rewards_max            10838.026736812184
total_rewards_min            10400.73613766929
Number of train steps total  1740000
Number of env steps total    5222000
Number of rollouts total     0
Train Time (s)               146.41853273799643
(Previous) Eval Time (s)     20.786485355813056
Sample Time (s)              6.325193568132818
Epoch Time (s)               173.5302116619423
Total Train Time (s)         74657.85079065152
Epoch                        434
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:37:57.459826 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #434 | Epoch Duration: 173.61934566497803
2020-01-13 04:37:57.459966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #434 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8738976
Z variance train             0.051647115
KL Divergence                48.31939
KL Loss                      4.831939
QF Loss                      191.65158
VF Loss                      70.80016
Policy Loss                  -1350.5415
Q Predictions Mean           1346.8376
Q Predictions Std            1313.7162
Q Predictions Max            4785.46
Q Predictions Min            675.0755
V Predictions Mean           1352.2319
V Predictions Std            1310.5593
V Predictions Max            4792.4004
V Predictions Min            681.351
Log Pis Mean                 -0.006816961
Log Pis Std                  4.184349
Log Pis Max                  17.582193
Log Pis Min                  -5.790014
Policy mu Mean               0.11709329
Policy mu Std                0.9169178
Policy mu Max                3.040636
Policy mu Min                -3.3898966
Policy log std Mean          -0.4933103
Policy log std Std           0.30044016
Policy log std Max           -0.010066092
Policy log std Min           -3.2357724
Z mean eval                  1.8918314
Z variance eval              0.08637954
total_rewards                [10621.74544821 10557.75178572 10786.63753525 10969.70960457
 11214.0793925  10623.30274041 10647.02921958 10418.47293142
 10419.07588078 10604.55888857]
total_rewards_mean           10686.236342700307
total_rewards_std            233.44466836461703
total_rewards_max            11214.079392495849
total_rewards_min            10418.472931420536
Number of train steps total  1744000
Number of env steps total    5234000
Number of rollouts total     0
Train Time (s)               148.96664359094575
(Previous) Eval Time (s)     20.64462794503197
Sample Time (s)              6.375989323016256
Epoch Time (s)               175.98726085899398
Total Train Time (s)         74833.92304163845
Epoch                        435
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:40:53.540986 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #435 | Epoch Duration: 176.08088660240173
2020-01-13 04:40:53.541259 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.892342
Z variance train             0.08637828
KL Divergence                47.022778
KL Loss                      4.7022777
QF Loss                      496.3579
VF Loss                      58.515633
Policy Loss                  -1334.6271
Q Predictions Mean           1328.6095
Q Predictions Std            1315.3157
Q Predictions Max            4664.184
Q Predictions Min            652.9601
V Predictions Mean           1330.2986
V Predictions Std            1312.8026
V Predictions Max            4659.47
V Predictions Min            647.09094
Log Pis Mean                 -0.38539892
Log Pis Std                  3.5663652
Log Pis Max                  12.998675
Log Pis Min                  -7.275393
Policy mu Mean               0.086793415
Policy mu Std                0.85351676
Policy mu Max                3.2867332
Policy mu Min                -2.860735
Policy log std Mean          -0.5008945
Policy log std Std           0.28980342
Policy log std Max           0.060969293
Policy log std Min           -2.932266
Z mean eval                  1.9022696
Z variance eval              0.064708285
total_rewards                [10309.34900388 10860.17168144 10621.76515654 10617.93614702
 10659.37078674 10504.44135972 10573.97515621 10763.39808053
 10550.91970565 10730.04970782]
total_rewards_mean           10619.137678555287
total_rewards_std            144.44881323123596
total_rewards_max            10860.171681443737
total_rewards_min            10309.349003877876
Number of train steps total  1748000
Number of env steps total    5246000
Number of rollouts total     0
Train Time (s)               145.40669959411025
(Previous) Eval Time (s)     20.76350947888568
Sample Time (s)              6.641254153102636
Epoch Time (s)               172.81146322609857
Total Train Time (s)         75006.8224198604
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:43:46.442490 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #436 | Epoch Duration: 172.90104031562805
2020-01-13 04:43:46.442639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9033388
Z variance train             0.06450491
KL Divergence                48.147057
KL Loss                      4.814706
QF Loss                      3870.54
VF Loss                      76.30322
Policy Loss                  -1331.9419
Q Predictions Mean           1329.8254
Q Predictions Std            1342.3696
Q Predictions Max            4744.6377
Q Predictions Min            655.34265
V Predictions Mean           1334.2776
V Predictions Std            1342.9243
V Predictions Max            4735.1196
V Predictions Min            672.9894
Log Pis Mean                 -0.24181113
Log Pis Std                  3.944247
Log Pis Max                  20.157825
Log Pis Min                  -6.7531786
Policy mu Mean               0.11774423
Policy mu Std                0.88931006
Policy mu Max                3.6538706
Policy mu Min                -2.617689
Policy log std Mean          -0.50355166
Policy log std Std           0.28469872
Policy log std Max           -0.08490078
Policy log std Min           -3.0811844
Z mean eval                  1.8996906
Z variance eval              0.067385815
total_rewards                [10079.69902094 10759.930695   10502.30997988 10876.47850755
 10622.90385638 10592.25382656 10929.98497135 10515.42788543
 10482.4738373  10822.41681558]
total_rewards_mean           10618.387939596385
total_rewards_std            236.38998084635406
total_rewards_max            10929.984971345204
total_rewards_min            10079.69902093693
Number of train steps total  1752000
Number of env steps total    5258000
Number of rollouts total     0
Train Time (s)               149.061324252747
(Previous) Eval Time (s)     20.915003903210163
Sample Time (s)              6.511465047951788
Epoch Time (s)               176.48779320390895
Total Train Time (s)         75183.404877414
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:46:43.026990 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #437 | Epoch Duration: 176.5842502117157
2020-01-13 04:46:43.027123 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #437 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8989229
Z variance train             0.06747687
KL Divergence                48.550888
KL Loss                      4.8550887
QF Loss                      123.74895
VF Loss                      101.10213
Policy Loss                  -1285.7838
Q Predictions Mean           1283.9177
Q Predictions Std            1306.2596
Q Predictions Max            4858.434
Q Predictions Min            681.3532
V Predictions Mean           1292.3
V Predictions Std            1306.0327
V Predictions Max            4861.191
V Predictions Min            687.7664
Log Pis Mean                 -0.47562033
Log Pis Std                  4.046032
Log Pis Max                  14.194849
Log Pis Min                  -7.817528
Policy mu Mean               0.031137249
Policy mu Std                0.8884835
Policy mu Max                3.3620358
Policy mu Min                -2.9690905
Policy log std Mean          -0.4630272
Policy log std Std           0.2623892
Policy log std Max           0.0016680956
Policy log std Min           -2.753735
Z mean eval                  1.905318
Z variance eval              0.08134098
total_rewards                [10786.30556562 10680.37062064 10880.47166279 10533.5718247
 10923.92870649 10570.06670466 10443.91587996 10884.41479802
 10546.40489628 10620.20482344]
total_rewards_mean           10686.965548260981
total_rewards_std            162.16556343828782
total_rewards_max            10923.928706494398
total_rewards_min            10443.915879964276
Number of train steps total  1756000
Number of env steps total    5270000
Number of rollouts total     0
Train Time (s)               147.59594786912203
(Previous) Eval Time (s)     20.43109474517405
Sample Time (s)              6.4354451284743845
Epoch Time (s)               174.46248774277046
Total Train Time (s)         75358.04490848258
Epoch                        438
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:49:37.673911 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #438 | Epoch Duration: 174.64667510986328
2020-01-13 04:49:37.674099 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #438 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9083488
Z variance train             0.081280716
KL Divergence                48.426056
KL Loss                      4.8426056
QF Loss                      72.46973
VF Loss                      36.948334
Policy Loss                  -1282.8861
Q Predictions Mean           1282.9004
Q Predictions Std            1301.1752
Q Predictions Max            4811.3643
Q Predictions Min            685.94336
V Predictions Mean           1283.9363
V Predictions Std            1295.4712
V Predictions Max            4778.2075
V Predictions Min            692.682
Log Pis Mean                 -0.6052912
Log Pis Std                  3.619214
Log Pis Max                  13.373043
Log Pis Min                  -8.147602
Policy mu Mean               0.064528584
Policy mu Std                0.8250993
Policy mu Max                2.7022896
Policy mu Min                -2.6291642
Policy log std Mean          -0.45895162
Policy log std Std           0.25049204
Policy log std Max           -0.025914252
Policy log std Min           -2.837773
Z mean eval                  1.9105585
Z variance eval              0.043925
total_rewards                [10833.68614578 10482.66998607 10902.07557484 10830.14884825
 10889.07091943 11047.54123837 10987.33387407 11160.84979895
 11093.97231891 11058.77508747]
total_rewards_mean           10928.612379215967
total_rewards_std            183.20784662889136
total_rewards_max            11160.849798954565
total_rewards_min            10482.66998606699
Number of train steps total  1760000
Number of env steps total    5282000
Number of rollouts total     0
Train Time (s)               146.88190671615303
(Previous) Eval Time (s)     17.41251872293651
Sample Time (s)              6.520229780115187
Epoch Time (s)               170.81465521920472
Total Train Time (s)         75528.94158150302
Epoch                        439
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:52:28.572821 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #439 | Epoch Duration: 170.89857649803162
2020-01-13 04:52:28.572998 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9111761
Z variance train             0.04381271
KL Divergence                50.921337
KL Loss                      5.092134
QF Loss                      154.80547
VF Loss                      51.667023
Policy Loss                  -1271.0724
Q Predictions Mean           1264.302
Q Predictions Std            1260.3855
Q Predictions Max            4887.1167
Q Predictions Min            701.1659
V Predictions Mean           1269.2085
V Predictions Std            1260.1168
V Predictions Max            4883.755
V Predictions Min            697.8492
Log Pis Mean                 -0.36198288
Log Pis Std                  4.0197854
Log Pis Max                  21.104958
Log Pis Min                  -6.8494473
Policy mu Mean               0.056986142
Policy mu Std                0.8832137
Policy mu Max                3.7293394
Policy mu Min                -2.537609
Policy log std Mean          -0.48903608
Policy log std Std           0.30122378
Policy log std Max           0.011072338
Policy log std Min           -2.546293
Z mean eval                  1.9137408
Z variance eval              0.03418284
total_rewards                [10416.81348523 10855.37606623 10699.12427737 10856.73129808
 10539.56236767 10783.14183274 10744.75988081 10861.66035602
 10969.3356756  10771.47706672]
total_rewards_mean           10749.798230646466
total_rewards_std            155.73828884183746
total_rewards_max            10969.335675598577
total_rewards_min            10416.813485227065
Number of train steps total  1764000
Number of env steps total    5294000
Number of rollouts total     0
Train Time (s)               147.89311720291153
(Previous) Eval Time (s)     20.657317908946425
Sample Time (s)              7.583876258227974
Epoch Time (s)               176.13431137008592
Total Train Time (s)         75705.16471066
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:55:24.798219 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #440 | Epoch Duration: 176.22509241104126
2020-01-13 04:55:24.798363 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #440 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.914182
Z variance train             0.034205116
KL Divergence                51.3877
KL Loss                      5.13877
QF Loss                      68.580185
VF Loss                      94.7126
Policy Loss                  -1319.5542
Q Predictions Mean           1316.1873
Q Predictions Std            1290.5023
Q Predictions Max            4810.6567
Q Predictions Min            676.2456
V Predictions Mean           1320.4882
V Predictions Std            1292.2347
V Predictions Max            4806.079
V Predictions Min            669.5284
Log Pis Mean                 -0.51541317
Log Pis Std                  3.7319255
Log Pis Max                  13.601404
Log Pis Min                  -9.351805
Policy mu Mean               0.09104705
Policy mu Std                0.84399176
Policy mu Max                3.1805816
Policy mu Min                -2.7973566
Policy log std Mean          -0.47984418
Policy log std Std           0.2735839
Policy log std Max           0.059610724
Policy log std Min           -2.9412837
Z mean eval                  1.887716
Z variance eval              0.05588659
total_rewards                [10342.86627061 10430.4240902  10638.69767868 10758.73327809
 10660.23308307 10503.58784914 10810.30532365 10379.822672
 10827.80792398 10916.21522971]
total_rewards_mean           10626.869339913386
total_rewards_std            192.83830723978514
total_rewards_max            10916.215229712769
total_rewards_min            10342.866270605793
Number of train steps total  1768000
Number of env steps total    5306000
Number of rollouts total     0
Train Time (s)               145.27159711020067
(Previous) Eval Time (s)     17.868515198118985
Sample Time (s)              6.4437551479786634
Epoch Time (s)               169.58386745629832
Total Train Time (s)         75874.83484175615
Epoch                        441
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 04:58:14.474969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #441 | Epoch Duration: 169.67648267745972
2020-01-13 04:58:14.475140 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8874075
Z variance train             0.0560924
KL Divergence                51.149185
KL Loss                      5.1149187
QF Loss                      92.6946
VF Loss                      90.6104
Policy Loss                  -1315.8386
Q Predictions Mean           1311.0427
Q Predictions Std            1268.7136
Q Predictions Max            4865.192
Q Predictions Min            671.3598
V Predictions Mean           1317.3728
V Predictions Std            1273.886
V Predictions Max            4875.0093
V Predictions Min            666.8563
Log Pis Mean                 -0.03970565
Log Pis Std                  4.261072
Log Pis Max                  18.72725
Log Pis Min                  -7.9607477
Policy mu Mean               0.06203735
Policy mu Std                0.9135028
Policy mu Max                3.7028172
Policy mu Min                -2.9338515
Policy log std Mean          -0.4888809
Policy log std Std           0.31071526
Policy log std Max           0.10440463
Policy log std Min           -2.738863
Z mean eval                  1.9056883
Z variance eval              0.03648042
total_rewards                [10311.67333826 10575.39908324 10274.32860759 10723.99733276
 10306.93000572 10651.71135817 10622.12361924 10510.01457503
 10308.94976477 10698.45852214]
total_rewards_mean           10498.358620692143
total_rewards_std            171.29512567881525
total_rewards_max            10723.997332757232
total_rewards_min            10274.328607589936
Number of train steps total  1772000
Number of env steps total    5318000
Number of rollouts total     0
Train Time (s)               146.37976440275088
(Previous) Eval Time (s)     20.992337252013385
Sample Time (s)              6.5587994256056845
Epoch Time (s)               173.93090108036995
Total Train Time (s)         76048.91744983243
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:01:08.566744 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #442 | Epoch Duration: 174.0914385318756
2020-01-13 05:01:08.567020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9019239
Z variance train             0.03643264
KL Divergence                52.11959
KL Loss                      5.2119594
QF Loss                      4348.2593
VF Loss                      51.147655
Policy Loss                  -1398.3738
Q Predictions Mean           1396.4763
Q Predictions Std            1393.856
Q Predictions Max            4870.7188
Q Predictions Min            704.8461
V Predictions Mean           1400.9666
V Predictions Std            1392.2279
V Predictions Max            4871.3145
V Predictions Min            708.0085
Log Pis Mean                 -0.25744826
Log Pis Std                  4.0351005
Log Pis Max                  16.345615
Log Pis Min                  -7.3717084
Policy mu Mean               0.048291445
Policy mu Std                0.88867754
Policy mu Max                3.288211
Policy mu Min                -2.9023492
Policy log std Mean          -0.4726895
Policy log std Std           0.28585932
Policy log std Max           -0.046676874
Policy log std Min           -3.1511214
Z mean eval                  1.8922046
Z variance eval              0.048251662
total_rewards                [10255.78457046 10540.29595992  9907.5878142   5474.54669538
  8122.7939517  10467.22767796 10404.52186518 10149.79181661
 10524.9808118  10290.68826136]
total_rewards_mean           9613.82194245751
total_rewards_std            1537.6170677552605
total_rewards_max            10540.295959919315
total_rewards_min            5474.546695378802
Number of train steps total  1776000
Number of env steps total    5330000
Number of rollouts total     0
Train Time (s)               146.48040924593806
(Previous) Eval Time (s)     20.81905736681074
Sample Time (s)              6.541000257711858
Epoch Time (s)               173.84046687046066
Total Train Time (s)         76223.01585422223
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:04:02.666870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #443 | Epoch Duration: 174.0996744632721
2020-01-13 05:04:02.667053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8910172
Z variance train             0.04828289
KL Divergence                51.187668
KL Loss                      5.118767
QF Loss                      198.99167
VF Loss                      80.00702
Policy Loss                  -1322.6162
Q Predictions Mean           1315.8457
Q Predictions Std            1285.898
Q Predictions Max            4768.604
Q Predictions Min            674.7879
V Predictions Mean           1324.9028
V Predictions Std            1282.2942
V Predictions Max            4757.753
V Predictions Min            679.8705
Log Pis Mean                 -0.2474423
Log Pis Std                  3.8860393
Log Pis Max                  18.17808
Log Pis Min                  -7.9646797
Policy mu Mean               0.06136781
Policy mu Std                0.9117294
Policy mu Max                3.1090693
Policy mu Min                -2.938628
Policy log std Mean          -0.49722457
Policy log std Std           0.3093273
Policy log std Max           0.18074647
Policy log std Min           -3.1005142
Z mean eval                  1.910737
Z variance eval              0.057356376
total_rewards                [10644.50502128 10574.54376932 11016.68877209 11030.89277994
 10817.19451744 10820.70963282 10763.29960598 10852.14329232
 10803.07841388 11075.21620227]
total_rewards_mean           10839.827200733565
total_rewards_std            154.90528001103868
total_rewards_max            11075.216202268039
total_rewards_min            10574.543769322048
Number of train steps total  1780000
Number of env steps total    5342000
Number of rollouts total     0
Train Time (s)               145.56446985993534
(Previous) Eval Time (s)     17.66420510970056
Sample Time (s)              6.595969972200692
Epoch Time (s)               169.8246449418366
Total Train Time (s)         76392.92377431085
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:06:52.576375 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #444 | Epoch Duration: 169.90912413597107
2020-01-13 05:06:52.576648 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.912013
Z variance train             0.057532698
KL Divergence                51.164913
KL Loss                      5.1164913
QF Loss                      134.97841
VF Loss                      27.306276
Policy Loss                  -1281.639
Q Predictions Mean           1277.6819
Q Predictions Std            1235.7252
Q Predictions Max            4750.379
Q Predictions Min            697.92163
V Predictions Mean           1279.7217
V Predictions Std            1239.3375
V Predictions Max            4753.5483
V Predictions Min            698.29736
Log Pis Mean                 -0.51191944
Log Pis Std                  3.7083616
Log Pis Max                  18.764584
Log Pis Min                  -6.5357814
Policy mu Mean               0.04001121
Policy mu Std                0.8515303
Policy mu Max                3.2724206
Policy mu Min                -3.1162517
Policy log std Mean          -0.49299923
Policy log std Std           0.27243245
Policy log std Max           0.022485375
Policy log std Min           -2.6446636
Z mean eval                  1.8955872
Z variance eval              0.054313023
total_rewards                [10459.36428551 10785.55120664 10719.42158838 10531.90261113
 10924.67497149 10498.97849752 10542.37383825 10294.68265075
 10693.47784164 10495.29502888]
total_rewards_mean           10594.572252018124
total_rewards_std            174.54847388005467
total_rewards_max            10924.674971485105
total_rewards_min            10294.68265075018
Number of train steps total  1784000
Number of env steps total    5354000
Number of rollouts total     0
Train Time (s)               147.59928074618801
(Previous) Eval Time (s)     20.730800893623382
Sample Time (s)              6.6078863511793315
Epoch Time (s)               174.93796799099073
Total Train Time (s)         76567.97256495524
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:09:47.632492 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #445 | Epoch Duration: 175.05564141273499
2020-01-13 05:09:47.632768 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8980078
Z variance train             0.05428972
KL Divergence                51.275143
KL Loss                      5.1275144
QF Loss                      175.93661
VF Loss                      100.27701
Policy Loss                  -1362.6761
Q Predictions Mean           1358.5466
Q Predictions Std            1330.2316
Q Predictions Max            4865.887
Q Predictions Min            688.1488
V Predictions Mean           1357.9152
V Predictions Std            1321.862
V Predictions Max            4837.6313
V Predictions Min            685.6066
Log Pis Mean                 0.00753811
Log Pis Std                  4.1276298
Log Pis Max                  25.271465
Log Pis Min                  -6.018547
Policy mu Mean               0.06628395
Policy mu Std                0.90696996
Policy mu Max                3.3074
Policy mu Min                -3.2903125
Policy log std Mean          -0.48785368
Policy log std Std           0.30070966
Policy log std Max           0.024104297
Policy log std Min           -2.8990614
Z mean eval                  1.8815918
Z variance eval              0.064834476
total_rewards                [10608.94736119  9974.27285855 10871.57131704 10842.80761947
 10930.16765344 10909.86930368 10651.84961494 10591.16593103
 10979.2526439  11079.93300478]
total_rewards_mean           10743.98373080193
total_rewards_std            299.828655875769
total_rewards_max            11079.933004779734
total_rewards_min            9974.27285855108
Number of train steps total  1788000
Number of env steps total    5366000
Number of rollouts total     0
Train Time (s)               146.93666121084243
(Previous) Eval Time (s)     20.51930050039664
Sample Time (s)              6.365057336166501
Epoch Time (s)               173.82101904740557
Total Train Time (s)         76741.88534819335
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:12:41.549082 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #446 | Epoch Duration: 173.9160599708557
2020-01-13 05:12:41.549353 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8830054
Z variance train             0.06504502
KL Divergence                50.771446
KL Loss                      5.0771446
QF Loss                      144.78186
VF Loss                      34.18989
Policy Loss                  -1286.0836
Q Predictions Mean           1283.5444
Q Predictions Std            1261.1454
Q Predictions Max            4851.6113
Q Predictions Min            682.4289
V Predictions Mean           1284.0747
V Predictions Std            1262.5505
V Predictions Max            4877.705
V Predictions Min            684.0425
Log Pis Mean                 -0.6893713
Log Pis Std                  3.9249666
Log Pis Max                  21.303701
Log Pis Min                  -7.318077
Policy mu Mean               0.032436416
Policy mu Std                0.8562693
Policy mu Max                3.369184
Policy mu Min                -3.496525
Policy log std Mean          -0.49797186
Policy log std Std           0.27690062
Policy log std Max           -0.06941146
Policy log std Min           -2.9823616
Z mean eval                  1.8981116
Z variance eval              0.14356716
total_rewards                [10415.24480199 10531.73197384 10661.93732599 10443.93321698
 10736.18612382 10474.81501017 10767.4266886  10709.80203214
 10194.3089911  10380.8591541 ]
total_rewards_mean           10531.624531872914
total_rewards_std            175.25697208575423
total_rewards_max            10767.42668859883
total_rewards_min            10194.308991096243
Number of train steps total  1792000
Number of env steps total    5378000
Number of rollouts total     0
Train Time (s)               146.16488880105317
(Previous) Eval Time (s)     20.63489160174504
Sample Time (s)              5.462374303024262
Epoch Time (s)               172.26215470582247
Total Train Time (s)         76914.2359900428
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:15:33.902833 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #447 | Epoch Duration: 172.3533263206482
2020-01-13 05:15:33.902969 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #447 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8982611
Z variance train             0.14389266
KL Divergence                50.12352
KL Loss                      5.012352
QF Loss                      8737.493
VF Loss                      46.80094
Policy Loss                  -1320.727
Q Predictions Mean           1318.852
Q Predictions Std            1309.6154
Q Predictions Max            4768.844
Q Predictions Min            644.6998
V Predictions Mean           1323.3721
V Predictions Std            1311.0338
V Predictions Max            4774.263
V Predictions Min            649.8079
Log Pis Mean                 -0.4441889
Log Pis Std                  3.7995276
Log Pis Max                  15.66493
Log Pis Min                  -7.6932
Policy mu Mean               0.039350316
Policy mu Std                0.84439826
Policy mu Max                2.5861745
Policy mu Min                -2.9854774
Policy log std Mean          -0.49059796
Policy log std Std           0.28611732
Policy log std Max           0.05222091
Policy log std Min           -2.9233792
Z mean eval                  1.9184468
Z variance eval              0.10065961
total_rewards                [10648.66897765 11042.97375689  8291.51855557 11119.85390359
 10711.9183323  10633.88145575 10649.73290553 10826.93188866
 10848.18284901 10917.59688857]
total_rewards_mean           10569.125951351683
total_rewards_std            775.790218455531
total_rewards_max            11119.853903587875
total_rewards_min            8291.518555574845
Number of train steps total  1796000
Number of env steps total    5390000
Number of rollouts total     0
Train Time (s)               146.48958264896646
(Previous) Eval Time (s)     20.81534635089338
Sample Time (s)              6.334420608356595
Epoch Time (s)               173.63934960821643
Total Train Time (s)         77087.95536437398
Epoch                        448
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:18:27.627249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #448 | Epoch Duration: 173.72416019439697
2020-01-13 05:18:27.627456 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9158598
Z variance train             0.100943014
KL Divergence                49.03042
KL Loss                      4.903042
QF Loss                      8349.672
VF Loss                      88.23596
Policy Loss                  -1393.0292
Q Predictions Mean           1395.1072
Q Predictions Std            1399.8668
Q Predictions Max            4911.713
Q Predictions Min            680.71265
V Predictions Mean           1396.0779
V Predictions Std            1401.0039
V Predictions Max            4901.075
V Predictions Min            685.6511
Log Pis Mean                 -0.3000125
Log Pis Std                  3.9829884
Log Pis Max                  21.834137
Log Pis Min                  -6.225214
Policy mu Mean               0.013732982
Policy mu Std                0.8941395
Policy mu Max                3.3193917
Policy mu Min                -3.3831735
Policy log std Mean          -0.50687784
Policy log std Std           0.28820494
Policy log std Max           0.18306679
Policy log std Min           -3.062467
Z mean eval                  1.8972889
Z variance eval              0.082726315
total_rewards                [10715.60118651 11041.01081421 10935.4271895  10923.55339117
 11002.69891993 10738.31470287 11057.99250846 10270.16417564
 10953.23368181 10950.41927973]
total_rewards_mean           10858.841584983673
total_rewards_std            224.15989814164064
total_rewards_max            11057.99250845567
total_rewards_min            10270.164175640937
Number of train steps total  1800000
Number of env steps total    5402000
Number of rollouts total     0
Train Time (s)               146.13015120103955
(Previous) Eval Time (s)     18.852964421734214
Sample Time (s)              6.491886574309319
Epoch Time (s)               171.47500219708309
Total Train Time (s)         77259.53402850451
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:21:19.213508 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #449 | Epoch Duration: 171.58589339256287
2020-01-13 05:21:19.213684 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #449 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8978183
Z variance train             0.082758754
KL Divergence                48.727913
KL Loss                      4.8727913
QF Loss                      4241.573
VF Loss                      80.904274
Policy Loss                  -1426.2838
Q Predictions Mean           1425.1796
Q Predictions Std            1404.8323
Q Predictions Max            4825.5977
Q Predictions Min            687.8501
V Predictions Mean           1433.4036
V Predictions Std            1406.3484
V Predictions Max            4826.961
V Predictions Min            701.7157
Log Pis Mean                 -0.43500116
Log Pis Std                  3.7521777
Log Pis Max                  10.644165
Log Pis Min                  -6.7002707
Policy mu Mean               0.10187882
Policy mu Std                0.85305965
Policy mu Max                2.7893357
Policy mu Min                -2.6546197
Policy log std Mean          -0.5227662
Policy log std Std           0.30821192
Policy log std Max           0.01823324
Policy log std Min           -3.068052
Z mean eval                  1.8917307
Z variance eval              0.12818784
total_rewards                [10749.24143854  4303.0296123  10724.73676068  3437.7230329
 10584.58479335 11056.611835   10767.77905433  6521.74270363
 10708.73608734 11083.0278908 ]
total_rewards_mean           8993.72132088726
total_rewards_std            2868.81110560702
total_rewards_max            11083.027890799212
total_rewards_min            3437.7230329042573
Number of train steps total  1804000
Number of env steps total    5414000
Number of rollouts total     0
Train Time (s)               146.49587798304856
(Previous) Eval Time (s)     18.981058911420405
Sample Time (s)              6.496600104030222
Epoch Time (s)               171.97353699849918
Total Train Time (s)         77431.59048984153
Epoch                        450
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:24:11.277843 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #450 | Epoch Duration: 172.06400656700134
2020-01-13 05:24:11.278072 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #450 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.89077
Z variance train             0.12800337
KL Divergence                48.6845
KL Loss                      4.86845
QF Loss                      109.3065
VF Loss                      113.22561
Policy Loss                  -1336.994
Q Predictions Mean           1336.8479
Q Predictions Std            1311.5807
Q Predictions Max            4827.2334
Q Predictions Min            687.435
V Predictions Mean           1345.2522
V Predictions Std            1311.9183
V Predictions Max            4836.5845
V Predictions Min            674.9966
Log Pis Mean                 -0.23987766
Log Pis Std                  4.0880795
Log Pis Max                  13.666697
Log Pis Min                  -7.990329
Policy mu Mean               0.05307922
Policy mu Std                0.9010162
Policy mu Max                3.1495557
Policy mu Min                -2.6854901
Policy log std Mean          -0.49094367
Policy log std Std           0.27096292
Policy log std Max           0.023384154
Policy log std Min           -2.71782
Z mean eval                  1.8944464
Z variance eval              0.14666024
total_rewards                [10920.6367918   7656.8306622  10649.35440036 11177.20275182
 10985.95136605 10907.25496397 10950.22431196 11048.87804517
 10770.0541391  10928.83351824]
total_rewards_mean           10599.522095066448
total_rewards_std            990.2127460181099
total_rewards_max            11177.202751823472
total_rewards_min            7656.830662196094
Number of train steps total  1808000
Number of env steps total    5426000
Number of rollouts total     0
Train Time (s)               147.23455089796335
(Previous) Eval Time (s)     20.69714109832421
Sample Time (s)              6.514999872073531
Epoch Time (s)               174.44669186836109
Total Train Time (s)         77606.11908712797
Epoch                        451
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:27:05.809539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #451 | Epoch Duration: 174.53130793571472
2020-01-13 05:27:05.809674 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8943882
Z variance train             0.14622995
KL Divergence                48.014416
KL Loss                      4.8014417
QF Loss                      4222.1074
VF Loss                      50.046844
Policy Loss                  -1453.191
Q Predictions Mean           1452.0205
Q Predictions Std            1435.664
Q Predictions Max            4857.5693
Q Predictions Min            680.723
V Predictions Mean           1454.7223
V Predictions Std            1432.1332
V Predictions Max            4836.9873
V Predictions Min            683.7331
Log Pis Mean                 0.13178068
Log Pis Std                  4.3225107
Log Pis Max                  18.835323
Log Pis Min                  -9.06859
Policy mu Mean               0.03512877
Policy mu Std                0.94179773
Policy mu Max                3.1803744
Policy mu Min                -2.7786782
Policy log std Mean          -0.5080428
Policy log std Std           0.29039884
Policy log std Max           0.0040914416
Policy log std Min           -3.0901425
Z mean eval                  1.8963821
Z variance eval              0.11797075
total_rewards                [10347.73731484 10671.38040502 10690.19835391 10901.89040432
 10255.77891918 11011.76485768  2495.77854759  9993.30750538
 10726.20607542 10134.18659405]
total_rewards_mean           9722.822897738904
total_rewards_std            2429.8361710689887
total_rewards_max            11011.764857682589
total_rewards_min            2495.7785475912815
Number of train steps total  1812000
Number of env steps total    5438000
Number of rollouts total     0
Train Time (s)               145.68957131821662
(Previous) Eval Time (s)     20.556891046930104
Sample Time (s)              6.450925251469016
Epoch Time (s)               172.69738761661574
Total Train Time (s)         77778.90839222632
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:29:58.606539 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #452 | Epoch Duration: 172.7967348098755
2020-01-13 05:29:58.606819 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8955473
Z variance train             0.117573895
KL Divergence                48.19087
KL Loss                      4.819087
QF Loss                      311.1854
VF Loss                      70.43654
Policy Loss                  -1280.6964
Q Predictions Mean           1278.8259
Q Predictions Std            1267.1512
Q Predictions Max            4870.552
Q Predictions Min            676.8642
V Predictions Mean           1286.2631
V Predictions Std            1264.8483
V Predictions Max            4885.5635
V Predictions Min            682.19525
Log Pis Mean                 -0.012343243
Log Pis Std                  3.9236643
Log Pis Max                  13.995291
Log Pis Min                  -5.708015
Policy mu Mean               0.017927554
Policy mu Std                0.9158984
Policy mu Max                3.713221
Policy mu Min                -3.0017295
Policy log std Mean          -0.49508798
Policy log std Std           0.2762162
Policy log std Max           -0.0020994544
Policy log std Min           -2.5531352
Z mean eval                  1.8964208
Z variance eval              0.14979401
total_rewards                [10693.36122858 10834.68894599 10681.14720698 10778.60976148
 10666.34310902 10766.30020047 10942.38518892 10775.53395541
 10853.29216118 10689.80466816]
total_rewards_mean           10768.146642617043
total_rewards_std            84.77461380103364
total_rewards_max            10942.385188918402
total_rewards_min            10666.343109016023
Number of train steps total  1816000
Number of env steps total    5450000
Number of rollouts total     0
Train Time (s)               145.38865894498304
(Previous) Eval Time (s)     20.66732067707926
Sample Time (s)              6.550375580321997
Epoch Time (s)               172.6063552023843
Total Train Time (s)         77951.59479331179
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:32:51.294993 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #453 | Epoch Duration: 172.68799352645874
2020-01-13 05:32:51.295134 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8918955
Z variance train             0.15021011
KL Divergence                46.90715
KL Loss                      4.6907153
QF Loss                      161.27039
VF Loss                      86.84529
Policy Loss                  -1338.571
Q Predictions Mean           1333.7098
Q Predictions Std            1312.5156
Q Predictions Max            4909.813
Q Predictions Min            680.4733
V Predictions Mean           1343.8818
V Predictions Std            1314.1578
V Predictions Max            4943.104
V Predictions Min            678.55084
Log Pis Mean                 -0.18238865
Log Pis Std                  3.6568203
Log Pis Max                  16.152554
Log Pis Min                  -6.3587513
Policy mu Mean               0.09187934
Policy mu Std                0.87300795
Policy mu Max                3.483766
Policy mu Min                -3.2025573
Policy log std Mean          -0.51262087
Policy log std Std           0.29463425
Policy log std Max           -0.079093575
Policy log std Min           -2.8090026
Z mean eval                  1.8811651
Z variance eval              0.1372255
total_rewards                [10363.49093845 10677.6515986  10988.45790726 10833.34468372
 10475.5264934  11115.6078236  10765.93082573 10437.32058648
 10431.69238942 10677.31608509]
total_rewards_mean           10676.633933174657
total_rewards_std            240.46536920384807
total_rewards_max            11115.607823599774
total_rewards_min            10363.49093844964
Number of train steps total  1820000
Number of env steps total    5462000
Number of rollouts total     0
Train Time (s)               146.54011026583612
(Previous) Eval Time (s)     20.660541265737265
Sample Time (s)              6.566249906085432
Epoch Time (s)               173.76690143765882
Total Train Time (s)         78125.43942013616
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:35:45.141708 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #454 | Epoch Duration: 173.84647822380066
2020-01-13 05:35:45.141842 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8790417
Z variance train             0.1369888
KL Divergence                46.78776
KL Loss                      4.6787763
QF Loss                      98.96087
VF Loss                      50.109
Policy Loss                  -1332.4108
Q Predictions Mean           1332.7222
Q Predictions Std            1371.244
Q Predictions Max            4861.3716
Q Predictions Min            680.93646
V Predictions Mean           1334.9214
V Predictions Std            1370.3728
V Predictions Max            4852.997
V Predictions Min            682.72473
Log Pis Mean                 -0.4637345
Log Pis Std                  3.5903194
Log Pis Max                  13.402579
Log Pis Min                  -6.307931
Policy mu Mean               0.08214142
Policy mu Std                0.8590985
Policy mu Max                2.806993
Policy mu Min                -2.341168
Policy log std Mean          -0.4803585
Policy log std Std           0.29724845
Policy log std Max           0.07613391
Policy log std Min           -2.9432585
Z mean eval                  1.87703
Z variance eval              0.15928957
total_rewards                [10959.91572464 10976.37502352  7227.5303118  11011.56082108
 10805.81121522 11209.76997883 10901.65473577  4326.86288276
  2460.2643896  10972.84964354]
total_rewards_mean           9085.259472676971
total_rewards_std            3084.177007919418
total_rewards_max            11209.769978833805
total_rewards_min            2460.264389601882
Number of train steps total  1824000
Number of env steps total    5474000
Number of rollouts total     0
Train Time (s)               146.1452081790194
(Previous) Eval Time (s)     20.601239568088204
Sample Time (s)              6.431381857488304
Epoch Time (s)               173.1778296045959
Total Train Time (s)         78298.70160811488
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:38:38.408406 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #455 | Epoch Duration: 173.2664520740509
2020-01-13 05:38:38.408591 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8777726
Z variance train             0.15933585
KL Divergence                47.263508
KL Loss                      4.726351
QF Loss                      125.079315
VF Loss                      40.09571
Policy Loss                  -1261.7798
Q Predictions Mean           1260.7919
Q Predictions Std            1261.1749
Q Predictions Max            4971.253
Q Predictions Min            683.11725
V Predictions Mean           1261.7075
V Predictions Std            1256.1936
V Predictions Max            4958.583
V Predictions Min            689.77014
Log Pis Mean                 -0.52714264
Log Pis Std                  3.7150524
Log Pis Max                  16.401615
Log Pis Min                  -6.846851
Policy mu Mean               0.031161392
Policy mu Std                0.8463659
Policy mu Max                2.8162966
Policy mu Min                -2.8058
Policy log std Mean          -0.4699054
Policy log std Std           0.26088306
Policy log std Max           0.17681256
Policy log std Min           -3.2440238
Z mean eval                  1.9102137
Z variance eval              0.15005085
total_rewards                [10584.85034936 11195.06561429 11336.89161477 11169.19238675
 10758.25482179 10737.23234443 10976.17289572 10982.49500014
 11072.28472195 10717.64831306]
total_rewards_mean           10953.00880622636
total_rewards_std            233.1843500936559
total_rewards_max            11336.891614771814
total_rewards_min            10584.850349356162
Number of train steps total  1828000
Number of env steps total    5486000
Number of rollouts total     0
Train Time (s)               146.28025486227125
(Previous) Eval Time (s)     17.553029103204608
Sample Time (s)              5.7747227172367275
Epoch Time (s)               169.60800668271258
Total Train Time (s)         78468.39501549723
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:41:28.106412 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #456 | Epoch Duration: 169.69767141342163
2020-01-13 05:41:28.106613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.909819
Z variance train             0.15012941
KL Divergence                48.25519
KL Loss                      4.825519
QF Loss                      244.11487
VF Loss                      93.050125
Policy Loss                  -1598.3359
Q Predictions Mean           1596.7449
Q Predictions Std            1561.0327
Q Predictions Max            4961.64
Q Predictions Min            707.5679
V Predictions Mean           1595.84
V Predictions Std            1558.231
V Predictions Max            4950.899
V Predictions Min            705.87177
Log Pis Mean                 0.20288816
Log Pis Std                  4.0837383
Log Pis Max                  14.077455
Log Pis Min                  -7.8017006
Policy mu Mean               0.105428346
Policy mu Std                0.9247552
Policy mu Max                3.438371
Policy mu Min                -2.7180946
Policy log std Mean          -0.5253412
Policy log std Std           0.33297235
Policy log std Max           0.011527926
Policy log std Min           -2.9251113
Z mean eval                  1.8834327
Z variance eval              0.08861502
total_rewards                [10361.69436735 10272.90539492  4647.75341183 10521.38748608
 10442.7852674  10600.45001418 10572.46800704 10576.15796406
 10590.46418712 10516.0419514 ]
total_rewards_mean           9910.210805136705
total_rewards_std            1757.1081784891603
total_rewards_max            10600.450014178412
total_rewards_min            4647.753411825078
Number of train steps total  1832000
Number of env steps total    5498000
Number of rollouts total     0
Train Time (s)               145.38320007221773
(Previous) Eval Time (s)     20.823622571770102
Sample Time (s)              6.38406097702682
Epoch Time (s)               172.59088362101465
Total Train Time (s)         78641.07281193044
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:44:20.789516 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #457 | Epoch Duration: 172.6827392578125
2020-01-13 05:44:20.789705 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #457 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8832384
Z variance train             0.088624954
KL Divergence                48.310436
KL Loss                      4.8310437
QF Loss                      131.0792
VF Loss                      58.17727
Policy Loss                  -1505.8469
Q Predictions Mean           1502.4905
Q Predictions Std            1491.0674
Q Predictions Max            4960.8926
Q Predictions Min            686.80975
V Predictions Mean           1510.8397
V Predictions Std            1489.2134
V Predictions Max            4945.905
V Predictions Min            696.7612
Log Pis Mean                 -0.08536706
Log Pis Std                  3.7779837
Log Pis Max                  23.878967
Log Pis Min                  -6.218171
Policy mu Mean               0.07701835
Policy mu Std                0.9120711
Policy mu Max                3.441033
Policy mu Min                -2.924437
Policy log std Mean          -0.52007365
Policy log std Std           0.29019082
Policy log std Max           -0.053328693
Policy log std Min           -2.938697
Z mean eval                  1.8892654
Z variance eval              0.061988372
total_rewards                [ 9970.07490403 10564.59030287  8980.36106314 10530.92290263
 10040.49268718 10424.25685543  2541.72238901  8455.86149775
 10896.81119249 10342.41868945]
total_rewards_mean           9274.75124839736
total_rewards_std            2355.732708568687
total_rewards_max            10896.81119248925
total_rewards_min            2541.722389011683
Number of train steps total  1836000
Number of env steps total    5510000
Number of rollouts total     0
Train Time (s)               147.29853372601792
(Previous) Eval Time (s)     21.004796106833965
Sample Time (s)              6.472396778874099
Epoch Time (s)               174.775726611726
Total Train Time (s)         78815.9547014148
Epoch                        458
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:47:15.675147 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #458 | Epoch Duration: 174.8853099346161
2020-01-13 05:47:15.675288 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8876864
Z variance train             0.06198298
KL Divergence                49.57578
KL Loss                      4.957578
QF Loss                      190.00531
VF Loss                      27.493376
Policy Loss                  -1362.2667
Q Predictions Mean           1361.4912
Q Predictions Std            1367.6449
Q Predictions Max            4930.997
Q Predictions Min            686.28827
V Predictions Mean           1364.1172
V Predictions Std            1363.9231
V Predictions Max            4923.9775
V Predictions Min            690.0906
Log Pis Mean                 -0.068887964
Log Pis Std                  4.197683
Log Pis Max                  24.448935
Log Pis Min                  -7.1302576
Policy mu Mean               0.08237127
Policy mu Std                0.91370416
Policy mu Max                3.6378846
Policy mu Min                -4.0116067
Policy log std Mean          -0.50880325
Policy log std Std           0.29413784
Policy log std Max           0.017705888
Policy log std Min           -2.9697964
Z mean eval                  1.904365
Z variance eval              0.054545116
total_rewards                [10672.74211336 10716.52945824 10877.63837607 10843.29637805
 11283.18000984 10846.98328148 10751.82693402 10828.42843197
 10773.78505584 10881.07912332]
total_rewards_mean           10847.54891621803
total_rewards_std            159.5353937912421
total_rewards_max            11283.180009836538
total_rewards_min            10672.742113357011
Number of train steps total  1840000
Number of env steps total    5522000
Number of rollouts total     0
Train Time (s)               146.54742319323123
(Previous) Eval Time (s)     20.73665491119027
Sample Time (s)              6.575991722755134
Epoch Time (s)               173.86006982717663
Total Train Time (s)         78989.91084654769
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:50:09.638567 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #459 | Epoch Duration: 173.96316480636597
2020-01-13 05:50:09.638781 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9026988
Z variance train             0.05444293
KL Divergence                51.012215
KL Loss                      5.1012216
QF Loss                      90.80066
VF Loss                      63.72102
Policy Loss                  -1429.9531
Q Predictions Mean           1429.1816
Q Predictions Std            1452.7177
Q Predictions Max            4995.831
Q Predictions Min            704.8311
V Predictions Mean           1434.6053
V Predictions Std            1452.2661
V Predictions Max            4994.632
V Predictions Min            713.534
Log Pis Mean                 -0.23260084
Log Pis Std                  3.6518412
Log Pis Max                  15.43363
Log Pis Min                  -7.658534
Policy mu Mean               0.03326461
Policy mu Std                0.9052829
Policy mu Max                3.139291
Policy mu Min                -2.7270865
Policy log std Mean          -0.49945745
Policy log std Std           0.28360137
Policy log std Max           0.040359944
Policy log std Min           -2.7884793
Z mean eval                  1.8909731
Z variance eval              0.07918452
total_rewards                [10589.33270108 10970.54728556 11125.99401537 11002.35714765
 10922.56758013 10934.84307904 10758.05343323 10930.17687738
 11022.30606691 10669.09531265]
total_rewards_mean           10892.527349900036
total_rewards_std            159.22987219599264
total_rewards_max            11125.994015365113
total_rewards_min            10589.332701080077
Number of train steps total  1844000
Number of env steps total    5534000
Number of rollouts total     0
Train Time (s)               146.4363874271512
(Previous) Eval Time (s)     20.760548822116107
Sample Time (s)              12.687214400619268
Epoch Time (s)               179.88415064988658
Total Train Time (s)         79169.88309581764
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:53:09.616429 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #460 | Epoch Duration: 179.97750234603882
2020-01-13 05:53:09.616620 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8904483
Z variance train             0.0793394
KL Divergence                50.73609
KL Loss                      5.0736094
QF Loss                      192.78552
VF Loss                      69.25722
Policy Loss                  -1437.6821
Q Predictions Mean           1436.305
Q Predictions Std            1414.0869
Q Predictions Max            4972.3613
Q Predictions Min            698.5021
V Predictions Mean           1437.1917
V Predictions Std            1412.1343
V Predictions Max            4971.539
V Predictions Min            696.3659
Log Pis Mean                 -0.06304833
Log Pis Std                  4.39167
Log Pis Max                  16.87181
Log Pis Min                  -6.5205264
Policy mu Mean               0.037630454
Policy mu Std                0.917547
Policy mu Max                2.5744562
Policy mu Min                -2.8532643
Policy log std Mean          -0.51636344
Policy log std Std           0.29636282
Policy log std Max           0.0014389753
Policy log std Min           -3.166156
Z mean eval                  1.9063431
Z variance eval              0.03828411
total_rewards                [10250.90083104 10752.99785637 10763.17763427 10217.82142663
 11005.52652676 10763.51021614 10439.14459066 10081.26004834
 11068.42760135 10401.92277121]
total_rewards_mean           10574.468950278038
total_rewards_std            325.00147572040515
total_rewards_max            11068.427601347676
total_rewards_min            10081.26004834004
Number of train steps total  1848000
Number of env steps total    5546000
Number of rollouts total     0
Train Time (s)               147.34830001695082
(Previous) Eval Time (s)     20.778069878928363
Sample Time (s)              6.4701144327409565
Epoch Time (s)               174.59648432862014
Total Train Time (s)         79344.56088691996
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:56:04.298126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #461 | Epoch Duration: 174.68137860298157
2020-01-13 05:56:04.298263 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #461 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046692
Z variance train             0.038234077
KL Divergence                52.27316
KL Loss                      5.227316
QF Loss                      102.883415
VF Loss                      90.60936
Policy Loss                  -1412.1487
Q Predictions Mean           1409.0074
Q Predictions Std            1419.3037
Q Predictions Max            4935.3154
Q Predictions Min            699.7846
V Predictions Mean           1418.489
V Predictions Std            1420.2362
V Predictions Max            4949.3755
V Predictions Min            702.2342
Log Pis Mean                 -0.011594322
Log Pis Std                  3.9127812
Log Pis Max                  12.062646
Log Pis Min                  -7.459061
Policy mu Mean               0.08613498
Policy mu Std                0.8917188
Policy mu Max                3.3490036
Policy mu Min                -2.8154528
Policy log std Mean          -0.5309709
Policy log std Std           0.3258561
Policy log std Max           -0.04775229
Policy log std Min           -2.9782064
Z mean eval                  1.9299333
Z variance eval              0.0711736
total_rewards                [10277.81813232 10770.39362387 10424.22071918 11014.47688519
 10903.88412963 10976.83027241 11011.49018371 11025.66633353
 10793.86799797 10926.74147333]
total_rewards_mean           10812.5389751125
total_rewards_std            247.58914267075536
total_rewards_max            11025.666333525218
total_rewards_min            10277.818132315668
Number of train steps total  1852000
Number of env steps total    5558000
Number of rollouts total     0
Train Time (s)               146.7788669941947
(Previous) Eval Time (s)     21.09874525759369
Sample Time (s)              6.3334707682952285
Epoch Time (s)               174.2110830200836
Total Train Time (s)         79518.85822705505
Epoch                        462
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 05:58:58.599196 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #462 | Epoch Duration: 174.3008270263672
2020-01-13 05:58:58.599371 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.92852
Z variance train             0.07164474
KL Divergence                50.76503
KL Loss                      5.0765033
QF Loss                      196.98402
VF Loss                      38.523994
Policy Loss                  -1413.8032
Q Predictions Mean           1409.1824
Q Predictions Std            1403.0155
Q Predictions Max            5023.701
Q Predictions Min            705.69073
V Predictions Mean           1414.9557
V Predictions Std            1401.9265
V Predictions Max            4997.3545
V Predictions Min            703.36035
Log Pis Mean                 -0.047372043
Log Pis Std                  3.9818876
Log Pis Max                  14.611339
Log Pis Min                  -6.646678
Policy mu Mean               0.11129713
Policy mu Std                0.9098279
Policy mu Max                3.3784711
Policy mu Min                -3.1366887
Policy log std Mean          -0.52653104
Policy log std Std           0.304095
Policy log std Max           0.099654555
Policy log std Min           -2.9586663
Z mean eval                  1.89444
Z variance eval              0.07753505
total_rewards                [10765.10772074 10900.91519094 10905.71146958 10786.34732199
 11079.10948368 10994.36516567 10483.29904952 10681.79227691
 10590.75606355 11057.82096984]
total_rewards_mean           10824.522471240834
total_rewards_std            188.93287118533115
total_rewards_max            11079.109483678714
total_rewards_min            10483.299049518335
Number of train steps total  1856000
Number of env steps total    5570000
Number of rollouts total     0
Train Time (s)               146.1811050591059
(Previous) Eval Time (s)     17.54022894660011
Sample Time (s)              6.330197154544294
Epoch Time (s)               170.0515311602503
Total Train Time (s)         79688.99335803138
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:01:48.738463 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #463 | Epoch Duration: 170.13894724845886
2020-01-13 06:01:48.738654 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #463 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8944263
Z variance train             0.077645466
KL Divergence                50.9314
KL Loss                      5.09314
QF Loss                      128.68387
VF Loss                      66.94386
Policy Loss                  -1500.0724
Q Predictions Mean           1497.6648
Q Predictions Std            1476.9108
Q Predictions Max            5004.3877
Q Predictions Min            699.3096
V Predictions Mean           1498.8702
V Predictions Std            1479.0613
V Predictions Max            5011.249
V Predictions Min            705.8989
Log Pis Mean                 0.0020401292
Log Pis Std                  4.1038446
Log Pis Max                  18.014107
Log Pis Min                  -6.342431
Policy mu Mean               0.05722438
Policy mu Std                0.92467296
Policy mu Max                3.012131
Policy mu Min                -3.4542592
Policy log std Mean          -0.50007653
Policy log std Std           0.29269984
Policy log std Max           0.078152835
Policy log std Min           -3.0819004
Z mean eval                  1.9042677
Z variance eval              0.09391199
total_rewards                [10390.72708279 10998.21463703 10790.1073516  11066.650545
 11095.99620452 10706.13787624 10540.07481073 11162.29214019
 10908.31023819 10815.2207367 ]
total_rewards_mean           10847.373162299255
total_rewards_std            237.22455699808486
total_rewards_max            11162.292140194902
total_rewards_min            10390.727082789832
Number of train steps total  1860000
Number of env steps total    5582000
Number of rollouts total     0
Train Time (s)               145.9456521049142
(Previous) Eval Time (s)     17.842334665823728
Sample Time (s)              6.429427412804216
Epoch Time (s)               170.21741418354213
Total Train Time (s)         79859.2956757322
Epoch                        464
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:04:39.045579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #464 | Epoch Duration: 170.30671525001526
2020-01-13 06:04:39.045854 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.905381
Z variance train             0.09386529
KL Divergence                50.81174
KL Loss                      5.0811744
QF Loss                      389.43597
VF Loss                      40.895363
Policy Loss                  -1342.6548
Q Predictions Mean           1339.1733
Q Predictions Std            1358.9259
Q Predictions Max            5083.173
Q Predictions Min            706.1784
V Predictions Mean           1343.1437
V Predictions Std            1356.8284
V Predictions Max            5015.5596
V Predictions Min            705.5775
Log Pis Mean                 -0.2406742
Log Pis Std                  3.9735436
Log Pis Max                  14.178722
Log Pis Min                  -7.3380065
Policy mu Mean               0.04113962
Policy mu Std                0.89572865
Policy mu Max                3.0843453
Policy mu Min                -2.7086544
Policy log std Mean          -0.49481153
Policy log std Std           0.30400616
Policy log std Max           0.059927344
Policy log std Min           -2.9820342
Z mean eval                  1.9018055
Z variance eval              0.0797833
total_rewards                [10783.43088075 11172.3539105  11145.08654901 11092.97331845
 11304.85342611 11116.89665706 11081.22177312 10946.65690658
 11214.25443114 10934.44786158]
total_rewards_mean           11079.217571430057
total_rewards_std            144.84229641133106
total_rewards_max            11304.853426114809
total_rewards_min            10783.43088074607
Number of train steps total  1864000
Number of env steps total    5594000
Number of rollouts total     0
Train Time (s)               146.326757799834
(Previous) Eval Time (s)     20.641468650195748
Sample Time (s)              6.393634412437677
Epoch Time (s)               173.36186086246744
Total Train Time (s)         80032.73647603998
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:07:32.488784 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #465 | Epoch Duration: 173.44274973869324
2020-01-13 06:07:32.488942 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #465 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9040706
Z variance train             0.07986385
KL Divergence                51.02527
KL Loss                      5.102527
QF Loss                      4555.6787
VF Loss                      118.02367
Policy Loss                  -1394.4857
Q Predictions Mean           1393.466
Q Predictions Std            1402.2827
Q Predictions Max            4990.5825
Q Predictions Min            696.2401
V Predictions Mean           1385.7753
V Predictions Std            1395.0312
V Predictions Max            4956.1665
V Predictions Min            699.82465
Log Pis Mean                 0.004979305
Log Pis Std                  3.9779332
Log Pis Max                  15.382381
Log Pis Min                  -6.991977
Policy mu Mean               0.056325775
Policy mu Std                0.9048963
Policy mu Max                2.560525
Policy mu Min                -2.861113
Policy log std Mean          -0.49192753
Policy log std Std           0.28335822
Policy log std Max           -0.01944092
Policy log std Min           -2.5022297
Z mean eval                  1.8977209
Z variance eval              0.075611606
total_rewards                [10588.32410513  3708.90409784  7319.27874311 10850.09408993
 10925.22311342 10798.31019821 11121.09821596 10869.2661335
 10452.67715619 11058.87451186]
total_rewards_mean           9769.205036516278
total_rewards_std            2283.2483398111017
total_rewards_max            11121.09821595887
total_rewards_min            3708.9040978408943
Number of train steps total  1868000
Number of env steps total    5606000
Number of rollouts total     0
Train Time (s)               146.5892332638614
(Previous) Eval Time (s)     20.991606883239
Sample Time (s)              6.4883266421966255
Epoch Time (s)               174.06916678929701
Total Train Time (s)         80206.88354482502
Epoch                        466
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:10:26.639775 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #466 | Epoch Duration: 174.15070343017578
2020-01-13 06:10:26.639957 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.898155
Z variance train             0.0754288
KL Divergence                49.319313
KL Loss                      4.9319315
QF Loss                      4203.176
VF Loss                      38.808083
Policy Loss                  -1505.8032
Q Predictions Mean           1504.226
Q Predictions Std            1521.9896
Q Predictions Max            4962.046
Q Predictions Min            698.65405
V Predictions Mean           1507.3025
V Predictions Std            1517.7719
V Predictions Max            4964.413
V Predictions Min            702.2797
Log Pis Mean                 -0.12744129
Log Pis Std                  3.7905934
Log Pis Max                  15.0334015
Log Pis Min                  -5.69446
Policy mu Mean               0.015414494
Policy mu Std                0.90964663
Policy mu Max                3.1454458
Policy mu Min                -3.4323356
Policy log std Mean          -0.5091925
Policy log std Std           0.28931844
Policy log std Max           0.019714475
Policy log std Min           -2.9405572
Z mean eval                  1.9342234
Z variance eval              0.08097483
total_rewards                [10667.91815875 10638.13026121 10047.28458706 10707.90051441
 10493.90405366 10832.23528165 10852.73554474 10397.82078123
 10765.02878424 10796.6626781 ]
total_rewards_mean           10619.96206450454
total_rewards_std            235.59940113859724
total_rewards_max            10852.735544742767
total_rewards_min            10047.284587057467
Number of train steps total  1872000
Number of env steps total    5618000
Number of rollouts total     0
Train Time (s)               149.84639490395784
(Previous) Eval Time (s)     20.69963901815936
Sample Time (s)              6.640363079961389
Epoch Time (s)               177.1863970020786
Total Train Time (s)         80384.15296738967
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:13:23.911478 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #467 | Epoch Duration: 177.27139401435852
2020-01-13 06:13:23.911624 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9357811
Z variance train             0.08104898
KL Divergence                50.63583
KL Loss                      5.063583
QF Loss                      141.08417
VF Loss                      46.78643
Policy Loss                  -1495.7389
Q Predictions Mean           1496.3269
Q Predictions Std            1510.9442
Q Predictions Max            5037.032
Q Predictions Min            673.054
V Predictions Mean           1493.124
V Predictions Std            1503.1544
V Predictions Max            5030.722
V Predictions Min            672.57007
Log Pis Mean                 0.040970713
Log Pis Std                  4.2209225
Log Pis Max                  22.272442
Log Pis Min                  -6.1763253
Policy mu Mean               -0.02211746
Policy mu Std                0.91754436
Policy mu Max                2.9467084
Policy mu Min                -3.1610296
Policy log std Mean          -0.4973286
Policy log std Std           0.28753284
Policy log std Max           -0.03518641
Policy log std Min           -2.794537
Z mean eval                  1.9118057
Z variance eval              0.07757226
total_rewards                [10171.51242949  9790.56138324 10390.21727852 10048.27983279
 10157.9454873   9984.36007376 10100.91636142 10418.20995358
 10055.05189563 10298.63412991]
total_rewards_mean           10141.568882564135
total_rewards_std            181.64584926376168
total_rewards_max            10418.209953578276
total_rewards_min            9790.561383244809
Number of train steps total  1876000
Number of env steps total    5630000
Number of rollouts total     0
Train Time (s)               146.93145877402276
(Previous) Eval Time (s)     20.987081818748266
Sample Time (s)              6.49509046273306
Epoch Time (s)               174.41363105550408
Total Train Time (s)         80558.64949877327
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:16:18.411527 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #468 | Epoch Duration: 174.49975180625916
2020-01-13 06:16:18.411752 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9121056
Z variance train             0.0775271
KL Divergence                49.499893
KL Loss                      4.9499893
QF Loss                      274.08038
VF Loss                      67.05533
Policy Loss                  -1524.1951
Q Predictions Mean           1519.2361
Q Predictions Std            1506.1125
Q Predictions Max            4860.576
Q Predictions Min            666.31165
V Predictions Mean           1522.4116
V Predictions Std            1508.1493
V Predictions Max            4830.562
V Predictions Min            678.25806
Log Pis Mean                 0.006069474
Log Pis Std                  3.7658951
Log Pis Max                  12.234846
Log Pis Min                  -5.89418
Policy mu Mean               0.03915518
Policy mu Std                0.9213236
Policy mu Max                2.8926644
Policy mu Min                -2.5968542
Policy log std Mean          -0.5091467
Policy log std Std           0.28292263
Policy log std Max           -0.028164208
Policy log std Min           -2.566405
Z mean eval                  1.8997482
Z variance eval              0.08620671
total_rewards                [11006.12068723 11111.92129857 11197.96943568 11255.42026759
 11201.24081931 10789.72501419 10888.87593947 11024.19426701
 11458.95964428 11211.86826934]
total_rewards_mean           11114.629564267827
total_rewards_std            184.05851119528714
total_rewards_max            11458.959644284796
total_rewards_min            10789.725014193067
Number of train steps total  1880000
Number of env steps total    5642000
Number of rollouts total     0
Train Time (s)               144.87706909375265
(Previous) Eval Time (s)     17.964134177193046
Sample Time (s)              6.313470317050815
Epoch Time (s)               169.1546735879965
Total Train Time (s)         80727.88962696819
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:19:07.658095 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #469 | Epoch Duration: 169.2462077140808
2020-01-13 06:19:07.658257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8988708
Z variance train             0.086034335
KL Divergence                50.20752
KL Loss                      5.020752
QF Loss                      223.31522
VF Loss                      41.562107
Policy Loss                  -1391.9946
Q Predictions Mean           1388.3274
Q Predictions Std            1414.7264
Q Predictions Max            4942.7397
Q Predictions Min            701.855
V Predictions Mean           1390.396
V Predictions Std            1413.6566
V Predictions Max            4937.7344
V Predictions Min            703.9648
Log Pis Mean                 -0.08373403
Log Pis Std                  4.1959066
Log Pis Max                  19.834631
Log Pis Min                  -6.7451854
Policy mu Mean               0.04713446
Policy mu Std                0.8990403
Policy mu Max                3.1198704
Policy mu Min                -3.0776954
Policy log std Mean          -0.49410978
Policy log std Std           0.29663876
Policy log std Max           0.64274585
Policy log std Min           -2.930779
Z mean eval                  1.9465272
Z variance eval              0.10792641
total_rewards                [ 5017.78220965 10711.72362615 10108.2033531  10347.55055763
  6728.36609718  9922.25025175 10197.98157443 10646.74164294
 10655.37924646 10551.56319309]
total_rewards_mean           9488.754175237696
total_rewards_std            1864.0995102043987
total_rewards_max            10711.72362614961
total_rewards_min            5017.782209654667
Number of train steps total  1884000
Number of env steps total    5654000
Number of rollouts total     0
Train Time (s)               146.2207966791466
(Previous) Eval Time (s)     17.625145617872477
Sample Time (s)              6.338951169047505
Epoch Time (s)               170.18489346606657
Total Train Time (s)         80898.15451486176
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:21:57.929433 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #470 | Epoch Duration: 170.27103447914124
2020-01-13 06:21:57.929613 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.945735
Z variance train             0.1078009
KL Divergence                50.19498
KL Loss                      5.0194983
QF Loss                      267.9864
VF Loss                      67.60443
Policy Loss                  -1310.7927
Q Predictions Mean           1311.1578
Q Predictions Std            1320.8882
Q Predictions Max            4935.015
Q Predictions Min            695.60614
V Predictions Mean           1317.6694
V Predictions Std            1320.8018
V Predictions Max            4914.177
V Predictions Min            699.9674
Log Pis Mean                 -0.6834066
Log Pis Std                  3.477547
Log Pis Max                  13.217736
Log Pis Min                  -7.7725377
Policy mu Mean               0.040283155
Policy mu Std                0.85421723
Policy mu Max                2.6063464
Policy mu Min                -2.763673
Policy log std Mean          -0.47042522
Policy log std Std           0.252242
Policy log std Max           0.014385104
Policy log std Min           -2.3408854
Z mean eval                  1.9020954
Z variance eval              0.059701808
total_rewards                [10932.4924989  11194.75862418 10774.66990052 11075.70778261
 10831.34821667 11120.80021836 10850.26428785 11005.52711471
 11029.52279879 11048.32780845]
total_rewards_mean           10986.341925103174
total_rewards_std            128.77216250600154
total_rewards_max            11194.758624176602
total_rewards_min            10774.66990051865
Number of train steps total  1888000
Number of env steps total    5666000
Number of rollouts total     0
Train Time (s)               146.51118022203445
(Previous) Eval Time (s)     20.782484869938344
Sample Time (s)              6.357478577177972
Epoch Time (s)               173.65114366915077
Total Train Time (s)         81071.88931461051
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:24:51.667366 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #471 | Epoch Duration: 173.73761916160583
2020-01-13 06:24:51.667517 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #471 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9046685
Z variance train             0.059680752
KL Divergence                51.81332
KL Loss                      5.181332
QF Loss                      116.75201
VF Loss                      39.919456
Policy Loss                  -1364.4567
Q Predictions Mean           1360.9136
Q Predictions Std            1342.9758
Q Predictions Max            4939.248
Q Predictions Min            707.8516
V Predictions Mean           1363.0518
V Predictions Std            1342.2438
V Predictions Max            4937.4062
V Predictions Min            707.3256
Log Pis Mean                 -0.19136432
Log Pis Std                  3.9745934
Log Pis Max                  14.153146
Log Pis Min                  -6.765851
Policy mu Mean               0.046342343
Policy mu Std                0.88999355
Policy mu Max                3.4279509
Policy mu Min                -2.8243797
Policy log std Mean          -0.49910673
Policy log std Std           0.2805549
Policy log std Max           0.14655697
Policy log std Min           -2.82943
Z mean eval                  1.9043581
Z variance eval              0.03876396
total_rewards                [10625.13310875 11105.46812051 11120.05618114 11318.09650179
 10852.4076245  11043.6999986  11080.41829681 11298.50345706
 10352.49901757 11152.43731305]
total_rewards_mean           10994.871961978457
total_rewards_std            287.8791215277325
total_rewards_max            11318.096501785252
total_rewards_min            10352.499017570846
Number of train steps total  1892000
Number of env steps total    5678000
Number of rollouts total     0
Train Time (s)               147.6002483149059
(Previous) Eval Time (s)     20.76616905629635
Sample Time (s)              6.238984188530594
Epoch Time (s)               174.60540155973285
Total Train Time (s)         81246.58268728014
Epoch                        472
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:27:46.368494 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #472 | Epoch Duration: 174.7008557319641
2020-01-13 06:27:46.368700 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9053196
Z variance train             0.038859166
KL Divergence                53.41358
KL Loss                      5.341358
QF Loss                      2220.936
VF Loss                      108.33225
Policy Loss                  -1385.425
Q Predictions Mean           1380.7351
Q Predictions Std            1377.1395
Q Predictions Max            4969.3765
Q Predictions Min            330.04764
V Predictions Mean           1383.7319
V Predictions Std            1371.914
V Predictions Max            4956.5024
V Predictions Min            716.1331
Log Pis Mean                 -0.14858802
Log Pis Std                  4.1000395
Log Pis Max                  17.236443
Log Pis Min                  -8.057421
Policy mu Mean               0.060691725
Policy mu Std                0.90613234
Policy mu Max                3.169164
Policy mu Min                -3.2978404
Policy log std Mean          -0.51401854
Policy log std Std           0.29928002
Policy log std Max           -0.03928125
Policy log std Min           -2.773388
Z mean eval                  1.9210787
Z variance eval              0.05522249
total_rewards                [10444.05159977 10643.74112695 10848.71538242 10848.52244899
 10665.88272425 10893.5200308  10629.41340416 10807.24057546
 11036.56322511 10837.42343009]
total_rewards_mean           10765.507394797762
total_rewards_std            160.3728912438485
total_rewards_max            11036.563225106196
total_rewards_min            10444.051599769062
Number of train steps total  1896000
Number of env steps total    5690000
Number of rollouts total     0
Train Time (s)               146.02566036675125
(Previous) Eval Time (s)     20.71144007332623
Sample Time (s)              6.475900081451982
Epoch Time (s)               173.21300052152947
Total Train Time (s)         81419.88288313244
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:30:39.676841 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #473 | Epoch Duration: 173.30797410011292
2020-01-13 06:30:39.677048 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9229391
Z variance train             0.055282645
KL Divergence                52.649258
KL Loss                      5.264926
QF Loss                      178.03833
VF Loss                      84.07631
Policy Loss                  -1480.5052
Q Predictions Mean           1477.4048
Q Predictions Std            1467.6039
Q Predictions Max            5042.1836
Q Predictions Min            693.48785
V Predictions Mean           1480.7505
V Predictions Std            1466.2935
V Predictions Max            5015.8794
V Predictions Min            698.43567
Log Pis Mean                 0.1612994
Log Pis Std                  3.9319742
Log Pis Max                  16.746246
Log Pis Min                  -8.320455
Policy mu Mean               0.08616351
Policy mu Std                0.9175488
Policy mu Max                2.7740273
Policy mu Min                -3.1177535
Policy log std Mean          -0.5140763
Policy log std Std           0.30302346
Policy log std Max           0.038535744
Policy log std Min           -2.9753125
Z mean eval                  1.9100962
Z variance eval              0.061217755
total_rewards                [10473.40643426 11044.23091241 10805.43157174 11224.31751825
 11243.85701465 10784.23967781 10959.91990865 11537.44813732
 11165.74959366 11257.63597223]
total_rewards_mean           11049.623674098995
total_rewards_std            288.6402926289083
total_rewards_max            11537.448137324405
total_rewards_min            10473.406434264098
Number of train steps total  1900000
Number of env steps total    5702000
Number of rollouts total     0
Train Time (s)               146.13698118831962
(Previous) Eval Time (s)     17.55434784805402
Sample Time (s)              6.4445712878368795
Epoch Time (s)               170.13590032421052
Total Train Time (s)         81590.11779532162
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:33:29.907299 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #474 | Epoch Duration: 170.23010802268982
2020-01-13 06:33:29.907426 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.909878
Z variance train             0.06114787
KL Divergence                52.260525
KL Loss                      5.2260528
QF Loss                      4340.2476
VF Loss                      119.18564
Policy Loss                  -1608.1349
Q Predictions Mean           1603.5507
Q Predictions Std            1547.21
Q Predictions Max            5004.372
Q Predictions Min            703.65985
V Predictions Mean           1612.917
V Predictions Std            1546.969
V Predictions Max            5006.9062
V Predictions Min            712.1132
Log Pis Mean                 0.0739446
Log Pis Std                  3.845382
Log Pis Max                  13.2386265
Log Pis Min                  -7.819598
Policy mu Mean               0.036541257
Policy mu Std                0.92676437
Policy mu Max                3.1383789
Policy mu Min                -3.2900372
Policy log std Mean          -0.54351825
Policy log std Std           0.32046193
Policy log std Max           0.069793105
Policy log std Min           -3.0453513
Z mean eval                  1.9412501
Z variance eval              0.09927571
total_rewards                [10442.39026894 10883.29390644 10730.87242304 10838.01104536
 10683.57411856 11013.49603436 10830.88652971 10746.74844186
 10724.79483234 10611.21236709]
total_rewards_mean           10750.52799676799
total_rewards_std            148.591083625154
total_rewards_max            11013.49603436174
total_rewards_min            10442.390268939647
Number of train steps total  1904000
Number of env steps total    5714000
Number of rollouts total     0
Train Time (s)               144.97644892381504
(Previous) Eval Time (s)     18.946407571900636
Sample Time (s)              5.3985868049785495
Epoch Time (s)               169.32144330069423
Total Train Time (s)         81759.52181272721
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:36:19.320484 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #475 | Epoch Duration: 169.41292357444763
2020-01-13 06:36:19.320770 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9420536
Z variance train             0.0994717
KL Divergence                50.961502
KL Loss                      5.0961504
QF Loss                      364.52533
VF Loss                      177.13486
Policy Loss                  -1449.3782
Q Predictions Mean           1445.5295
Q Predictions Std            1443.6648
Q Predictions Max            4996.174
Q Predictions Min            699.0154
V Predictions Mean           1444.7388
V Predictions Std            1439.056
V Predictions Max            4977.1646
V Predictions Min            706.4408
Log Pis Mean                 0.030737206
Log Pis Std                  4.1159625
Log Pis Max                  19.502075
Log Pis Min                  -5.8206654
Policy mu Mean               0.054369193
Policy mu Std                0.93027186
Policy mu Max                3.3039904
Policy mu Min                -3.1314957
Policy log std Mean          -0.52987784
Policy log std Std           0.30634946
Policy log std Max           0.018318892
Policy log std Min           -2.9480867
Z mean eval                  1.9219061
Z variance eval              0.0644934
total_rewards                [10704.27067813 10831.99600311 11053.14782413 10969.32581858
 11131.54954544 10531.12824112 10803.93091052 10722.60587716
 10599.55473556  3779.8109137 ]
total_rewards_mean           10112.732054743869
total_rewards_std            2118.750248442419
total_rewards_max            11131.549545435022
total_rewards_min            3779.810913701394
Number of train steps total  1908000
Number of env steps total    5726000
Number of rollouts total     0
Train Time (s)               145.99292594008148
(Previous) Eval Time (s)     18.571296812966466
Sample Time (s)              6.496478038374335
Epoch Time (s)               171.06070079142228
Total Train Time (s)         81930.66845519375
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:39:10.475043 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #476 | Epoch Duration: 171.1540687084198
2020-01-13 06:39:10.475220 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9215797
Z variance train             0.0644102
KL Divergence                51.76545
KL Loss                      5.176545
QF Loss                      148.6279
VF Loss                      65.55623
Policy Loss                  -1375.8143
Q Predictions Mean           1374.1105
Q Predictions Std            1374.2666
Q Predictions Max            4992.796
Q Predictions Min            709.285
V Predictions Mean           1377.5881
V Predictions Std            1373.4618
V Predictions Max            5006.9175
V Predictions Min            710.4366
Log Pis Mean                 -0.14660412
Log Pis Std                  3.8423984
Log Pis Max                  14.845793
Log Pis Min                  -7.796835
Policy mu Mean               0.056566115
Policy mu Std                0.9087318
Policy mu Max                3.3689997
Policy mu Min                -2.7435658
Policy log std Mean          -0.51040274
Policy log std Std           0.2835738
Policy log std Max           -6.812811e-05
Policy log std Min           -2.7377353
Z mean eval                  1.9382589
Z variance eval              0.07342229
total_rewards                [10494.38520104 11079.80951688 10270.20112471 11016.52913955
 11055.99616407 10727.59088454 10757.74693469  7848.54919204
 10722.86923251 11243.80190985]
total_rewards_mean           10521.747929988725
total_rewards_std            933.3572168686921
total_rewards_max            11243.80190985262
total_rewards_min            7848.54919203871
Number of train steps total  1912000
Number of env steps total    5738000
Number of rollouts total     0
Train Time (s)               146.44279421307147
(Previous) Eval Time (s)     17.49807812506333
Sample Time (s)              6.540099622681737
Epoch Time (s)               170.48097196081653
Total Train Time (s)         82101.25821323413
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:42:01.067995 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #477 | Epoch Duration: 170.5926399230957
2020-01-13 06:42:01.068163 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #477 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9385636
Z variance train             0.07307295
KL Divergence                52.064342
KL Loss                      5.2064342
QF Loss                      311.86453
VF Loss                      119.08108
Policy Loss                  -1469.3341
Q Predictions Mean           1470.8298
Q Predictions Std            1479.9359
Q Predictions Max            5045.476
Q Predictions Min            708.6676
V Predictions Mean           1471.0474
V Predictions Std            1481.2026
V Predictions Max            5049.3164
V Predictions Min            711.97815
Log Pis Mean                 -0.36409104
Log Pis Std                  3.341307
Log Pis Max                  10.855498
Log Pis Min                  -7.0987706
Policy mu Mean               0.04609257
Policy mu Std                0.88407004
Policy mu Max                2.8240075
Policy mu Min                -2.295888
Policy log std Mean          -0.506406
Policy log std Std           0.2969356
Policy log std Max           0.015345156
Policy log std Min           -2.9158983
Z mean eval                  1.9299568
Z variance eval              0.10658576
total_rewards                [11073.44185022 11135.9225355  10931.74546114 11045.66647093
 11062.53188798 10763.27223995 10909.33135842 11023.6810065
 11378.18290707  3903.74672839]
total_rewards_mean           10322.752244610003
total_rewards_std            2145.053197381442
total_rewards_max            11378.182907066455
total_rewards_min            3903.7467283864407
Number of train steps total  1916000
Number of env steps total    5750000
Number of rollouts total     0
Train Time (s)               145.77133054286242
(Previous) Eval Time (s)     20.994496474973857
Sample Time (s)              5.496454646345228
Epoch Time (s)               172.2622816641815
Total Train Time (s)         82273.60583481751
Epoch                        478
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:44:53.417442 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #478 | Epoch Duration: 172.34915041923523
2020-01-13 06:44:53.417579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #478 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9299237
Z variance train             0.106579706
KL Divergence                51.326534
KL Loss                      5.1326537
QF Loss                      4624.7905
VF Loss                      46.80402
Policy Loss                  -1471.5432
Q Predictions Mean           1471.9856
Q Predictions Std            1447.4788
Q Predictions Max            5030.6875
Q Predictions Min            698.8049
V Predictions Mean           1472.9326
V Predictions Std            1445.4672
V Predictions Max            5013.8296
V Predictions Min            690.9491
Log Pis Mean                 -0.4342942
Log Pis Std                  3.955201
Log Pis Max                  30.82098
Log Pis Min                  -8.323935
Policy mu Mean               -0.0025851277
Policy mu Std                0.88631725
Policy mu Max                4.9911547
Policy mu Min                -4.8986325
Policy log std Mean          -0.50897795
Policy log std Std           0.27937806
Policy log std Max           -0.03760436
Policy log std Min           -2.9815927
Z mean eval                  1.9169581
Z variance eval              0.07589391
total_rewards                [10912.57657116 11098.49832939 10449.07518703 11146.63708802
 10542.8707315  10969.94798221 10960.04839066 11075.96666963
 11132.51566476 10861.13327287]
total_rewards_mean           10914.926988722236
total_rewards_std            228.9263891838117
total_rewards_max            11146.637088020572
total_rewards_min            10449.075187027302
Number of train steps total  1920000
Number of env steps total    5762000
Number of rollouts total     0
Train Time (s)               145.67179154977202
(Previous) Eval Time (s)     20.833420569542795
Sample Time (s)              6.588676243554801
Epoch Time (s)               173.09388836286962
Total Train Time (s)         82446.8092748574
Epoch                        479
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:47:46.623639 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #479 | Epoch Duration: 173.20596313476562
2020-01-13 06:47:46.623769 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #479 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9170904
Z variance train             0.075952135
KL Divergence                52.2453
KL Loss                      5.22453
QF Loss                      4823.877
VF Loss                      108.94285
Policy Loss                  -1390.6871
Q Predictions Mean           1390.1254
Q Predictions Std            1394.6223
Q Predictions Max            5087.4395
Q Predictions Min            703.66235
V Predictions Mean           1398.7285
V Predictions Std            1395.322
V Predictions Max            5087.968
V Predictions Min            712.6094
Log Pis Mean                 -0.20261204
Log Pis Std                  3.9276202
Log Pis Max                  17.113379
Log Pis Min                  -8.458815
Policy mu Mean               0.07365552
Policy mu Std                0.9090248
Policy mu Max                2.842454
Policy mu Min                -3.1087933
Policy log std Mean          -0.5027702
Policy log std Std           0.3024813
Policy log std Max           -0.0046758354
Policy log std Min           -2.944003
Z mean eval                  1.9371055
Z variance eval              0.04834003
total_rewards                [10462.87170378 10786.48675718 10735.66551991 10671.50497685
 10618.52214277 10398.26452177 10851.91329962 10725.44082392
 10733.68830939 10676.8276809 ]
total_rewards_mean           10666.118573608652
total_rewards_std            133.18932309875538
total_rewards_max            10851.91329961959
total_rewards_min            10398.264521770541
Number of train steps total  1924000
Number of env steps total    5774000
Number of rollouts total     0
Train Time (s)               145.20507576689124
(Previous) Eval Time (s)     20.543459633830935
Sample Time (s)              9.357812229543924
Epoch Time (s)               175.1063476302661
Total Train Time (s)         82622.09535995545
Epoch                        480
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:50:41.916645 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #480 | Epoch Duration: 175.29275393486023
2020-01-13 06:50:41.916884 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #480 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.937013
Z variance train             0.04834043
KL Divergence                54.550858
KL Loss                      5.4550858
QF Loss                      128.84842
VF Loss                      132.71507
Policy Loss                  -1442.434
Q Predictions Mean           1439.1498
Q Predictions Std            1427.5397
Q Predictions Max            5070.1616
Q Predictions Min            716.1996
V Predictions Mean           1435.3552
V Predictions Std            1424.9089
V Predictions Max            5042.5693
V Predictions Min            712.80804
Log Pis Mean                 -0.08497582
Log Pis Std                  3.9510744
Log Pis Max                  14.801898
Log Pis Min                  -8.917055
Policy mu Mean               0.03795256
Policy mu Std                0.9198515
Policy mu Max                3.2024722
Policy mu Min                -4.7321105
Policy log std Mean          -0.50886893
Policy log std Std           0.3076216
Policy log std Max           0.19354713
Policy log std Min           -2.882358
Z mean eval                  1.9692732
Z variance eval              0.03745597
total_rewards                [10581.52575357 10986.0354508  11138.20857527 10903.19513956
 10797.53569024 10780.07510739 10937.72946363 10969.75662728
 10814.28627298 10691.7802423 ]
total_rewards_mean           10860.012832301272
total_rewards_std            152.13956339301632
total_rewards_max            11138.208575270059
total_rewards_min            10581.525753570622
Number of train steps total  1928000
Number of env steps total    5786000
Number of rollouts total     0
Train Time (s)               146.53895801771432
(Previous) Eval Time (s)     20.80060675693676
Sample Time (s)              6.466960404999554
Epoch Time (s)               173.80652517965063
Total Train Time (s)         82795.98320999835
Epoch                        481
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:53:35.807397 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #481 | Epoch Duration: 173.89035058021545
2020-01-13 06:53:35.807532 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #481 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9693766
Z variance train             0.037395053
KL Divergence                53.976505
KL Loss                      5.3976507
QF Loss                      84.94588
VF Loss                      82.693245
Policy Loss                  -1416.0228
Q Predictions Mean           1412.0756
Q Predictions Std            1421.6146
Q Predictions Max            5019.7905
Q Predictions Min            699.7934
V Predictions Mean           1415.9609
V Predictions Std            1421.7878
V Predictions Max            5030.835
V Predictions Min            701.8262
Log Pis Mean                 -0.0464302
Log Pis Std                  3.981182
Log Pis Max                  16.694613
Log Pis Min                  -6.8252063
Policy mu Mean               0.051084857
Policy mu Std                0.9166088
Policy mu Max                3.3369873
Policy mu Min                -2.651164
Policy log std Mean          -0.48058796
Policy log std Std           0.2742504
Policy log std Max           -0.0041770935
Policy log std Min           -2.6100702
Z mean eval                  1.9761477
Z variance eval              0.042614684
total_rewards                [10412.79478474 11122.31697936 11263.68689292 10765.25121594
 10677.51969168 11076.16035287 11023.38883807 10989.80138139
 11077.08028867 10956.57526464]
total_rewards_mean           10936.457569029031
total_rewards_std            237.12967944979815
total_rewards_max            11263.686892919362
total_rewards_min            10412.794784737769
Number of train steps total  1932000
Number of env steps total    5798000
Number of rollouts total     0
Train Time (s)               146.34212571708485
(Previous) Eval Time (s)     20.615726411808282
Sample Time (s)              6.473025491926819
Epoch Time (s)               173.43087762081996
Total Train Time (s)         82969.49496896612
Epoch                        482
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:56:29.324363 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #482 | Epoch Duration: 173.51673483848572
2020-01-13 06:56:29.324496 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9789568
Z variance train             0.042562027
KL Divergence                54.525787
KL Loss                      5.452579
QF Loss                      415.30884
VF Loss                      90.72963
Policy Loss                  -1390.0847
Q Predictions Mean           1387.2959
Q Predictions Std            1414.0348
Q Predictions Max            5019.422
Q Predictions Min            699.47723
V Predictions Mean           1392.0417
V Predictions Std            1411.001
V Predictions Max            5019.1846
V Predictions Min            696.22516
Log Pis Mean                 -0.079107806
Log Pis Std                  4.091357
Log Pis Max                  17.440125
Log Pis Min                  -7.5784945
Policy mu Mean               0.016362902
Policy mu Std                0.93215674
Policy mu Max                4.23165
Policy mu Min                -3.4624796
Policy log std Mean          -0.48944935
Policy log std Std           0.29558548
Policy log std Max           0.33884355
Policy log std Min           -3.0141518
Z mean eval                  1.9454267
Z variance eval              0.04254834
total_rewards                [10715.70098637 10667.65604079 11065.85269419 10879.59185096
 10622.53924284 10373.9616072  11056.1380031  10650.78119119
 10784.70231981 10602.96571051]
total_rewards_mean           10741.988964695545
total_rewards_std            201.9681794420593
total_rewards_max            11065.85269418751
total_rewards_min            10373.961607199722
Number of train steps total  1936000
Number of env steps total    5810000
Number of rollouts total     0
Train Time (s)               146.23701600497589
(Previous) Eval Time (s)     20.69924806896597
Sample Time (s)              6.304866271559149
Epoch Time (s)               173.241130345501
Total Train Time (s)         83142.8266882482
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 06:59:22.659126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #483 | Epoch Duration: 173.33453249931335
2020-01-13 06:59:22.659257 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9451978
Z variance train             0.0426062
KL Divergence                54.307434
KL Loss                      5.4307437
QF Loss                      93.58286
VF Loss                      33.579403
Policy Loss                  -1385.7599
Q Predictions Mean           1384.6838
Q Predictions Std            1405.13
Q Predictions Max            5087.316
Q Predictions Min            686.1892
V Predictions Mean           1385.3654
V Predictions Std            1400.3682
V Predictions Max            5052.7607
V Predictions Min            707.45
Log Pis Mean                 -0.4753527
Log Pis Std                  3.5704572
Log Pis Max                  11.902157
Log Pis Min                  -7.3502254
Policy mu Mean               0.03301279
Policy mu Std                0.86823106
Policy mu Max                2.7155745
Policy mu Min                -2.6191165
Policy log std Mean          -0.4934486
Policy log std Std           0.26674742
Policy log std Max           -0.0540002
Policy log std Min           -2.8198137
Z mean eval                  1.95738
Z variance eval              0.054835726
total_rewards                [10356.75829916 11058.51401962 11077.00772916 11035.04407885
 10979.48302005 10937.30410438 11055.14572195 11134.61747748
 11144.16262557 11108.61672486]
total_rewards_mean           10988.665380110357
total_rewards_std            219.3518659918495
total_rewards_max            11144.162625565496
total_rewards_min            10356.758299160785
Number of train steps total  1940000
Number of env steps total    5822000
Number of rollouts total     0
Train Time (s)               146.39351431978866
(Previous) Eval Time (s)     21.153218193911016
Sample Time (s)              6.453431409783661
Epoch Time (s)               174.00016392348334
Total Train Time (s)         83316.90810581436
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:02:16.745677 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #484 | Epoch Duration: 174.08632349967957
2020-01-13 07:02:16.745814 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #484 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9557072
Z variance train             0.054739468
KL Divergence                53.76587
KL Loss                      5.376587
QF Loss                      102.346924
VF Loss                      78.00208
Policy Loss                  -1572.4355
Q Predictions Mean           1566.0039
Q Predictions Std            1531.2759
Q Predictions Max            4966.7393
Q Predictions Min            695.5759
V Predictions Mean           1569.5193
V Predictions Std            1526.9531
V Predictions Max            4952.2666
V Predictions Min            700.0793
Log Pis Mean                 0.15987879
Log Pis Std                  4.252282
Log Pis Max                  22.14328
Log Pis Min                  -7.5532575
Policy mu Mean               0.024124483
Policy mu Std                0.9453691
Policy mu Max                4.5093217
Policy mu Min                -3.8601558
Policy log std Mean          -0.5027843
Policy log std Std           0.2819894
Policy log std Max           0.2391034
Policy log std Min           -2.4361587
Z mean eval                  1.9583254
Z variance eval              0.055874597
total_rewards                [11009.12229625 10871.39475379 10986.65734384 10712.36166389
 10770.65279228 11045.18750013 10966.61321259 11211.39310888
 11282.76218016  9161.91563331]
total_rewards_mean           10801.806048511973
total_rewards_std            571.4613115496348
total_rewards_max            11282.762180162412
total_rewards_min            9161.915633305362
Number of train steps total  1944000
Number of env steps total    5834000
Number of rollouts total     0
Train Time (s)               146.3954515978694
(Previous) Eval Time (s)     20.738516284618527
Sample Time (s)              6.472948368173093
Epoch Time (s)               173.60691625066102
Total Train Time (s)         83490.60799352312
Epoch                        485
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:05:10.447759 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #485 | Epoch Duration: 173.7018482685089
2020-01-13 07:05:10.447900 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #485 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9594568
Z variance train             0.05595585
KL Divergence                54.853333
KL Loss                      5.4853334
QF Loss                      93.67799
VF Loss                      251.47589
Policy Loss                  -1493.9791
Q Predictions Mean           1492.3896
Q Predictions Std            1513.509
Q Predictions Max            5019.5713
Q Predictions Min            713.07666
V Predictions Mean           1496.6304
V Predictions Std            1512.919
V Predictions Max            5039.502
V Predictions Min            720.80316
Log Pis Mean                 -0.049738526
Log Pis Std                  3.9673846
Log Pis Max                  19.076355
Log Pis Min                  -7.6999006
Policy mu Mean               -0.011742544
Policy mu Std                0.9130639
Policy mu Max                4.165495
Policy mu Min                -3.399548
Policy log std Mean          -0.50905174
Policy log std Std           0.2847112
Policy log std Max           -0.06492394
Policy log std Min           -2.7844129
Z mean eval                  1.9226011
Z variance eval              0.053735264
total_rewards                [11097.25885303 11011.27930944  4318.4229068  10664.97383921
 10722.56941573  7016.23552817 10935.51691758 11112.5833255
 11015.1763217  11048.44702624]
total_rewards_mean           9894.24634433899
total_rewards_std            2202.388422199075
total_rewards_max            11112.58332549745
total_rewards_min            4318.422906797959
Number of train steps total  1948000
Number of env steps total    5846000
Number of rollouts total     0
Train Time (s)               146.76564952731133
(Previous) Eval Time (s)     21.27900206670165
Sample Time (s)              6.492278041318059
Epoch Time (s)               174.53692963533103
Total Train Time (s)         83665.22462728061
Epoch                        486
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:08:05.066744 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #486 | Epoch Duration: 174.61874914169312
2020-01-13 07:08:05.066876 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9212223
Z variance train             0.05382859
KL Divergence                53.12845
KL Loss                      5.3128448
QF Loss                      114.50653
VF Loss                      83.81926
Policy Loss                  -1292.2568
Q Predictions Mean           1287.6536
Q Predictions Std            1287.3813
Q Predictions Max            4963.4424
Q Predictions Min            710.7223
V Predictions Mean           1294.7427
V Predictions Std            1289.64
V Predictions Max            4958.143
V Predictions Min            715.3325
Log Pis Mean                 -0.59941816
Log Pis Std                  3.7429721
Log Pis Max                  15.335223
Log Pis Min                  -7.383543
Policy mu Mean               0.011817004
Policy mu Std                0.8345059
Policy mu Max                3.2484727
Policy mu Min                -2.9993284
Policy log std Mean          -0.49974445
Policy log std Std           0.25557977
Policy log std Max           -0.040153086
Policy log std Min           -2.5204318
Z mean eval                  1.9446714
Z variance eval              0.049134355
total_rewards                [10928.14771469 10816.9790382  11089.63604125 11086.88300115
 11185.3028744  10655.16679217 11018.49110733 10853.29618325
 10853.38799265 10892.06035118]
total_rewards_mean           10937.935109627693
total_rewards_std            149.65936951715716
total_rewards_max            11185.302874404384
total_rewards_min            10655.166792170658
Number of train steps total  1952000
Number of env steps total    5858000
Number of rollouts total     0
Train Time (s)               147.72733874525875
(Previous) Eval Time (s)     17.47055237693712
Sample Time (s)              6.40812756260857
Epoch Time (s)               171.60601868480444
Total Train Time (s)         83836.90765724238
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:10:56.754169 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #487 | Epoch Duration: 171.68716549873352
2020-01-13 07:10:56.754344 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9446996
Z variance train             0.049068123
KL Divergence                53.445724
KL Loss                      5.3445725
QF Loss                      305.7442
VF Loss                      66.65883
Policy Loss                  -1490.2375
Q Predictions Mean           1487.143
Q Predictions Std            1485.9208
Q Predictions Max            5002.408
Q Predictions Min            705.7877
V Predictions Mean           1490.3641
V Predictions Std            1480.8246
V Predictions Max            4986.288
V Predictions Min            708.4897
Log Pis Mean                 0.014526013
Log Pis Std                  4.227763
Log Pis Max                  22.754826
Log Pis Min                  -6.7148705
Policy mu Mean               0.07356844
Policy mu Std                0.91941
Policy mu Max                3.8309798
Policy mu Min                -3.7071712
Policy log std Mean          -0.5026904
Policy log std Std           0.31373593
Policy log std Max           -0.029058099
Policy log std Min           -3.042889
Z mean eval                  1.9381412
Z variance eval              0.06005478
total_rewards                [10468.48163604 11099.68284002 11130.36353529 11148.78269826
 10616.90396092 10869.5582145  10982.32229454 10938.68057022
 10615.96235365 11115.32122731]
total_rewards_mean           10898.605933074885
total_rewards_std            236.09445608991933
total_rewards_max            11148.782698261128
total_rewards_min            10468.48163603935
Number of train steps total  1956000
Number of env steps total    5870000
Number of rollouts total     0
Train Time (s)               146.08274261187762
(Previous) Eval Time (s)     17.419769917149097
Sample Time (s)              6.389797583222389
Epoch Time (s)               169.8923101122491
Total Train Time (s)         84006.88329979079
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:13:46.736399 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #488 | Epoch Duration: 169.9819095134735
2020-01-13 07:13:46.736597 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #488 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9375412
Z variance train             0.059852958
KL Divergence                52.882275
KL Loss                      5.2882276
QF Loss                      9205.094
VF Loss                      126.374176
Policy Loss                  -1343.932
Q Predictions Mean           1340.2211
Q Predictions Std            1316.7458
Q Predictions Max            4979.33
Q Predictions Min            712.22064
V Predictions Mean           1337.8865
V Predictions Std            1312.4347
V Predictions Max            4956.414
V Predictions Min            710.1344
Log Pis Mean                 -0.31710798
Log Pis Std                  3.6837862
Log Pis Max                  17.153667
Log Pis Min                  -7.7848554
Policy mu Mean               0.057055544
Policy mu Std                0.889537
Policy mu Max                2.8416789
Policy mu Min                -3.5108619
Policy log std Mean          -0.4834763
Policy log std Std           0.2683077
Policy log std Max           0.0358842
Policy log std Min           -2.5037935
Z mean eval                  1.9335206
Z variance eval              0.04502097
total_rewards                [10279.4984387  10102.36011311 10011.87503935 10497.77784695
 10158.70099246 10294.68555273 10426.48812872 10504.52952331
  7085.33263948 10196.28866769]
total_rewards_mean           9955.753694250398
total_rewards_std            969.4960661662184
total_rewards_max            10504.529523313282
total_rewards_min            7085.332639479658
Number of train steps total  1960000
Number of env steps total    5882000
Number of rollouts total     0
Train Time (s)               146.72635693196207
(Previous) Eval Time (s)     20.985753951128572
Sample Time (s)              6.367701159790158
Epoch Time (s)               174.0798120428808
Total Train Time (s)         84181.05207213946
Epoch                        489
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:16:40.909771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #489 | Epoch Duration: 174.17302250862122
2020-01-13 07:16:40.909976 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #489 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9343103
Z variance train             0.044902317
KL Divergence                53.374916
KL Loss                      5.3374915
QF Loss                      410.21814
VF Loss                      136.72723
Policy Loss                  -1368.079
Q Predictions Mean           1366.7825
Q Predictions Std            1391.4911
Q Predictions Max            5057.355
Q Predictions Min            703.56305
V Predictions Mean           1373.2458
V Predictions Std            1388.1617
V Predictions Max            5043.0713
V Predictions Min            712.02625
Log Pis Mean                 -0.24347012
Log Pis Std                  4.084296
Log Pis Max                  24.356047
Log Pis Min                  -8.301779
Policy mu Mean               0.028199038
Policy mu Std                0.91468996
Policy mu Max                3.6019006
Policy mu Min                -3.6024704
Policy log std Mean          -0.49217138
Policy log std Std           0.266083
Policy log std Max           -0.021850526
Policy log std Min           -2.7541308
Z mean eval                  1.9350755
Z variance eval              0.033555787
total_rewards                [10976.99257723 11001.49132812 11129.42707009 10729.05839897
 11497.68066896 11156.04488128 10718.02832826 10966.3656533
 10891.49952413 10872.95348216]
total_rewards_mean           10993.954191250175
total_rewards_std            217.00582533620235
total_rewards_max            11497.68066895682
total_rewards_min            10718.028328257642
Number of train steps total  1964000
Number of env steps total    5894000
Number of rollouts total     0
Train Time (s)               147.9416747679934
(Previous) Eval Time (s)     17.9857235760428
Sample Time (s)              6.3824056959711015
Epoch Time (s)               172.3098040400073
Total Train Time (s)         84353.448759072
Epoch                        490
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:19:33.311434 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #490 | Epoch Duration: 172.4013020992279
2020-01-13 07:19:33.311622 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #490 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9340433
Z variance train             0.03345848
KL Divergence                53.00472
KL Loss                      5.300472
QF Loss                      4360.878
VF Loss                      90.465965
Policy Loss                  -1386.9103
Q Predictions Mean           1386.6255
Q Predictions Std            1389.5698
Q Predictions Max            5035.524
Q Predictions Min            711.2699
V Predictions Mean           1383.1174
V Predictions Std            1386.9846
V Predictions Max            5027.6772
V Predictions Min            709.4045
Log Pis Mean                 -0.3000763
Log Pis Std                  3.6581514
Log Pis Max                  18.211031
Log Pis Min                  -6.398287
Policy mu Mean               0.032862693
Policy mu Std                0.8911175
Policy mu Max                3.2790208
Policy mu Min                -3.559864
Policy log std Mean          -0.5110021
Policy log std Std           0.2713104
Policy log std Max           0.12447268
Policy log std Min           -2.8964915
Z mean eval                  1.9444809
Z variance eval              0.059387065
total_rewards                [10677.87155359 10937.86790553 10769.43592864 10930.45396975
 10682.35675995 10773.01893938 10814.55661306 10895.78934051
 10827.63894164 10832.4268923 ]
total_rewards_mean           10814.141684436076
total_rewards_std            86.97485948994915
total_rewards_max            10937.867905533181
total_rewards_min            10677.87155359129
Number of train steps total  1968000
Number of env steps total    5906000
Number of rollouts total     0
Train Time (s)               146.5605505942367
(Previous) Eval Time (s)     20.715407208073884
Sample Time (s)              6.482214357238263
Epoch Time (s)               173.75817215954885
Total Train Time (s)         84527.28812773107
Epoch                        491
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:22:27.153081 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #491 | Epoch Duration: 173.84133124351501
2020-01-13 07:22:27.153213 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #491 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9447606
Z variance train             0.059369873
KL Divergence                51.16221
KL Loss                      5.116221
QF Loss                      4631.518
VF Loss                      66.615
Policy Loss                  -1372.0012
Q Predictions Mean           1371.612
Q Predictions Std            1367.8993
Q Predictions Max            4986.0195
Q Predictions Min            706.3628
V Predictions Mean           1367.3417
V Predictions Std            1363.2114
V Predictions Max            4944.6606
V Predictions Min            706.88495
Log Pis Mean                 0.01598242
Log Pis Std                  4.293718
Log Pis Max                  20.177704
Log Pis Min                  -8.025471
Policy mu Mean               -0.016672349
Policy mu Std                0.92411095
Policy mu Max                3.0789747
Policy mu Min                -4.0825872
Policy log std Mean          -0.4950594
Policy log std Std           0.2656351
Policy log std Max           -0.031531036
Policy log std Min           -2.3704424
Z mean eval                  1.9338996
Z variance eval              0.06801527
total_rewards                [10535.73710344 11303.53433008 10778.5455754  10826.84732061
 10819.93002365 11226.66975857 10734.50915949 10749.74231605
 11161.18720322 10915.07232051]
total_rewards_mean           10905.177511103504
total_rewards_std            233.85822436597962
total_rewards_max            11303.534330080794
total_rewards_min            10535.737103443967
Number of train steps total  1972000
Number of env steps total    5918000
Number of rollouts total     0
Train Time (s)               147.8821032908745
(Previous) Eval Time (s)     17.333984605968
Sample Time (s)              6.351521612145007
Epoch Time (s)               171.56760950898752
Total Train Time (s)         84698.9335016869
Epoch                        492
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:25:18.801126 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #492 | Epoch Duration: 171.64781832695007
2020-01-13 07:25:18.801249 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9332927
Z variance train             0.067967705
KL Divergence                50.04956
KL Loss                      5.0049562
QF Loss                      123.61888
VF Loss                      71.96081
Policy Loss                  -1379.7454
Q Predictions Mean           1374.2703
Q Predictions Std            1393.9899
Q Predictions Max            5034.424
Q Predictions Min            710.8836
V Predictions Mean           1378.1123
V Predictions Std            1389.2223
V Predictions Max            5036.7026
V Predictions Min            713.86084
Log Pis Mean                 0.02567634
Log Pis Std                  4.0299897
Log Pis Max                  16.520973
Log Pis Min                  -7.567665
Policy mu Mean               0.05566053
Policy mu Std                0.90914106
Policy mu Max                3.275959
Policy mu Min                -2.7109885
Policy log std Mean          -0.47848177
Policy log std Std           0.30573928
Policy log std Max           -0.013814092
Policy log std Min           -2.8033571
Z mean eval                  1.9287109
Z variance eval              0.046984974
total_rewards                [ 9984.92942351 10160.40369556 10211.90127334  9995.57488896
 10325.12715843  9750.86663642 10210.63015936 10264.28486565
 10121.43634555  9988.64526621]
total_rewards_mean           10101.379971300079
total_rewards_std            162.77640661482283
total_rewards_max            10325.12715842606
total_rewards_min            9750.8666364242
Number of train steps total  1976000
Number of env steps total    5930000
Number of rollouts total     0
Train Time (s)               145.5660469578579
(Previous) Eval Time (s)     17.52568938676268
Sample Time (s)              5.3674680553376675
Epoch Time (s)               168.45920439995825
Total Train Time (s)         84867.48035105085
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:28:07.351988 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #493 | Epoch Duration: 168.55064797401428
2020-01-13 07:28:07.352111 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9293587
Z variance train             0.04691381
KL Divergence                51.124096
KL Loss                      5.1124096
QF Loss                      450.9043
VF Loss                      102.18129
Policy Loss                  -1572.074
Q Predictions Mean           1568.7886
Q Predictions Std            1525.6692
Q Predictions Max            5118.533
Q Predictions Min            709.25653
V Predictions Mean           1572.0203
V Predictions Std            1523.0581
V Predictions Max            5093.862
V Predictions Min            709.3226
Log Pis Mean                 0.20608917
Log Pis Std                  4.9643555
Log Pis Max                  17.942144
Log Pis Min                  -7.464965
Policy mu Mean               0.07818348
Policy mu Std                0.9880751
Policy mu Max                3.4904933
Policy mu Min                -3.679077
Policy log std Mean          -0.48626027
Policy log std Std           0.33424005
Policy log std Max           0.24560654
Policy log std Min           -2.85629
Z mean eval                  1.9441601
Z variance eval              0.047016706
total_rewards                [10264.60269134 10997.50446412 10363.28450375 10789.53524384
 10874.24331543 10932.98585968 10724.54929325 11011.00915417
  4251.69878184 10859.60728065]
total_rewards_mean           10106.902058806816
total_rewards_std            1966.4652938483482
total_rewards_max            11011.009154173325
total_rewards_min            4251.698781840886
Number of train steps total  1980000
Number of env steps total    5942000
Number of rollouts total     0
Train Time (s)               146.5278155207634
(Previous) Eval Time (s)     20.660610872786492
Sample Time (s)              5.472637462895364
Epoch Time (s)               172.66106385644525
Total Train Time (s)         85040.2244244623
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:31:00.099515 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #494 | Epoch Duration: 172.74730491638184
2020-01-13 07:31:00.099651 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9462849
Z variance train             0.04713069
KL Divergence                51.057434
KL Loss                      5.1057434
QF Loss                      395.48895
VF Loss                      49.001217
Policy Loss                  -1536.409
Q Predictions Mean           1535.6903
Q Predictions Std            1514.0067
Q Predictions Max            5112.707
Q Predictions Min            703.2636
V Predictions Mean           1533.152
V Predictions Std            1505.4829
V Predictions Max            5085.004
V Predictions Min            706.32605
Log Pis Mean                 0.3129847
Log Pis Std                  4.385354
Log Pis Max                  18.13654
Log Pis Min                  -9.528437
Policy mu Mean               0.07712681
Policy mu Std                0.9752122
Policy mu Max                3.4178593
Policy mu Min                -3.5831227
Policy log std Mean          -0.5119776
Policy log std Std           0.2923961
Policy log std Max           0.026080638
Policy log std Min           -2.831251
Z mean eval                  1.9695852
Z variance eval              0.058959454
total_rewards                [10608.69482356 11081.46955808  3945.81888488 10824.12324169
 10413.33055545 10688.50597685 10833.36193388 10980.25242261
 10833.6180529  10906.7073154 ]
total_rewards_mean           10111.58827652928
total_rewards_std            2063.1325991763597
total_rewards_max            11081.469558077617
total_rewards_min            3945.8188848825102
Number of train steps total  1984000
Number of env steps total    5954000
Number of rollouts total     0
Train Time (s)               146.55975976586342
(Previous) Eval Time (s)     18.630853567738086
Sample Time (s)              6.406934988219291
Epoch Time (s)               171.5975483218208
Total Train Time (s)         85211.91761019407
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:33:51.797876 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #495 | Epoch Duration: 171.69809985160828
2020-01-13 07:33:51.798128 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9683117
Z variance train             0.058931697
KL Divergence                50.343777
KL Loss                      5.0343776
QF Loss                      145.66403
VF Loss                      32.28474
Policy Loss                  -1315.7747
Q Predictions Mean           1315.4602
Q Predictions Std            1324.735
Q Predictions Max            5069.4946
Q Predictions Min            716.09094
V Predictions Mean           1315.8942
V Predictions Std            1322.0679
V Predictions Max            5069.3286
V Predictions Min            716.59064
Log Pis Mean                 -0.3150779
Log Pis Std                  3.6002717
Log Pis Max                  12.82064
Log Pis Min                  -6.2894506
Policy mu Mean               0.07082063
Policy mu Std                0.90497804
Policy mu Max                3.8145833
Policy mu Min                -3.034503
Policy log std Mean          -0.46858993
Policy log std Std           0.2878816
Policy log std Max           0.029656291
Policy log std Min           -2.8382206
Z mean eval                  1.9343226
Z variance eval              0.048055835
total_rewards                [10854.53066512 10834.67827645 10416.78250519 11071.16244572
 10421.87905435  3855.66428912 11051.57184703 11065.80308809
 11137.54355798 10828.52064855]
total_rewards_mean           10153.8136377594
total_rewards_std            2113.3966835624233
total_rewards_max            11137.54355798461
total_rewards_min            3855.6642891153224
Number of train steps total  1988000
Number of env steps total    5966000
Number of rollouts total     0
Train Time (s)               145.48283686721697
(Previous) Eval Time (s)     20.801163877360523
Sample Time (s)              6.496887960005552
Epoch Time (s)               172.78088870458305
Total Train Time (s)         85384.7826434793
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:36:44.665720 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #496 | Epoch Duration: 172.86741733551025
2020-01-13 07:36:44.665860 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #496 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9336386
Z variance train             0.04797704
KL Divergence                51.09329
KL Loss                      5.1093287
QF Loss                      4813.1104
VF Loss                      61.234474
Policy Loss                  -1626.9344
Q Predictions Mean           1624.384
Q Predictions Std            1559.3126
Q Predictions Max            5015.9053
Q Predictions Min            729.92285
V Predictions Mean           1627.2981
V Predictions Std            1558.1582
V Predictions Max            5011.3145
V Predictions Min            730.961
Log Pis Mean                 0.5093559
Log Pis Std                  4.4558587
Log Pis Max                  17.12281
Log Pis Min                  -7.025797
Policy mu Mean               0.013515919
Policy mu Std                0.9870281
Policy mu Max                3.3298657
Policy mu Min                -2.9134212
Policy log std Mean          -0.5230395
Policy log std Std           0.31566152
Policy log std Max           0.081062436
Policy log std Min           -2.9508858
Z mean eval                  1.9212301
Z variance eval              0.04078402
total_rewards                [10261.44805494 10693.82639448 10625.35963338 11128.96876985
 11011.67025831 10508.50958605 10862.12952648 10829.05622319
 10447.83084557 11142.86166819]
total_rewards_mean           10751.16609604388
total_rewards_std            281.46683253110604
total_rewards_max            11142.861668188125
total_rewards_min            10261.44805494406
Number of train steps total  1992000
Number of env steps total    5978000
Number of rollouts total     0
Train Time (s)               146.29631162295118
(Previous) Eval Time (s)     21.086207349784672
Sample Time (s)              6.484760878607631
Epoch Time (s)               173.86727985134348
Total Train Time (s)         85558.74689351534
Epoch                        497
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:39:38.632953 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #497 | Epoch Duration: 173.9669952392578
2020-01-13 07:39:38.633110 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.922147
Z variance train             0.04080583
KL Divergence                51.910995
KL Loss                      5.1910996
QF Loss                      195.6391
VF Loss                      128.22949
Policy Loss                  -1428.0156
Q Predictions Mean           1425.239
Q Predictions Std            1403.5796
Q Predictions Max            4986.506
Q Predictions Min            723.7554
V Predictions Mean           1422.5061
V Predictions Std            1395.3865
V Predictions Max            4973.1816
V Predictions Min            722.0271
Log Pis Mean                 0.059744097
Log Pis Std                  4.1543946
Log Pis Max                  12.816454
Log Pis Min                  -9.699412
Policy mu Mean               0.058047216
Policy mu Std                0.92973983
Policy mu Max                2.8766944
Policy mu Min                -3.0656548
Policy log std Mean          -0.5112796
Policy log std Std           0.27993947
Policy log std Max           0.048995286
Policy log std Min           -2.4944253
Z mean eval                  1.9678091
Z variance eval              0.06536892
total_rewards                [10335.00216843 10992.86569192 11126.51949252 11099.21400092
  7210.41453546 10914.30602086 10710.60427923 10709.17435236
 10808.20112206 10725.28490591]
total_rewards_mean           10463.1586569671
total_rewards_std            1106.1204013389724
total_rewards_max            11126.519492521935
total_rewards_min            7210.414535455862
Number of train steps total  1996000
Number of env steps total    5990000
Number of rollouts total     0
Train Time (s)               143.9210781501606
(Previous) Eval Time (s)     20.730806838721037
Sample Time (s)              6.5298263086006045
Epoch Time (s)               171.18171129748225
Total Train Time (s)         85730.01020016521
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:42:29.898853 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #498 | Epoch Duration: 171.2656421661377
2020-01-13 07:42:29.898987 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #498 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9674351
Z variance train             0.06523304
KL Divergence                51.367996
KL Loss                      5.1368
QF Loss                      225.59964
VF Loss                      71.424446
Policy Loss                  -1469.0365
Q Predictions Mean           1468.3701
Q Predictions Std            1471.0298
Q Predictions Max            5080.473
Q Predictions Min            717.2096
V Predictions Mean           1471.218
V Predictions Std            1468.2836
V Predictions Max            5064.6714
V Predictions Min            720.6552
Log Pis Mean                 -0.12104863
Log Pis Std                  4.266109
Log Pis Max                  17.547075
Log Pis Min                  -12.351983
Policy mu Mean               -0.010652614
Policy mu Std                0.9155258
Policy mu Max                3.28209
Policy mu Min                -2.6966798
Policy log std Mean          -0.4783775
Policy log std Std           0.28886473
Policy log std Max           -0.02190137
Policy log std Min           -2.7130966
Z mean eval                  1.9334366
Z variance eval              0.06347112
total_rewards                [10707.17166018 10830.01247721 10919.39405581 10773.18910855
 10494.5456633  10773.7245833  11253.59412496 11007.18957873
 10914.24894746 10911.82638243]
total_rewards_mean           10858.489658193004
total_rewards_std            189.34283076971823
total_rewards_max            11253.594124960337
total_rewards_min            10494.54566329862
Number of train steps total  2000000
Number of env steps total    6002000
Number of rollouts total     0
Train Time (s)               143.24613559106365
(Previous) Eval Time (s)     20.925614381674677
Sample Time (s)              5.953868164215237
Epoch Time (s)               170.12561813695356
Total Train Time (s)         85900.30776325567
Epoch                        499
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:45:20.206020 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #499 | Epoch Duration: 170.3068881034851
2020-01-13 07:45:20.206332 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Iteration #499 | Started Training: True
2020-01-13 07:45:21.049499 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] Variant:
2020-01-13 07:45:21.049849 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] {
  "env_name": "Humanoid-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 4000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train4000_no-clear_H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false
  }
}
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0043402454
Z variance train             0.69638485
KL Divergence                0.14567924
KL Loss                      0.014567924
QF Loss                      1191.7229
VF Loss                      130.72073
Policy Loss                  -11.4011345
Q Predictions Mean           0.00764025
Q Predictions Std            0.011238864
Q Predictions Max            0.04310349
Q Predictions Min            -0.021389062
V Predictions Mean           0.0038442065
V Predictions Std            0.014050508
V Predictions Max            0.04862334
V Predictions Min            -0.03060108
Log Pis Mean                 -11.315548
Log Pis Std                  0.9056481
Log Pis Max                  -8.520826
Log Pis Min                  -13.320554
Policy mu Mean               0.0018080731
Policy mu Std                0.010425097
Policy mu Max                0.031899374
Policy mu Min                -0.032006025
Policy log std Mean          0.00021106945
Policy log std Std           0.01053859
Policy log std Max           0.03166568
Policy log std Min           -0.03848222
Z mean eval                  0.06853108
Z variance eval              0.06645299
total_rewards                [300.4675976  257.790033   270.98363495 236.65626187 227.05380714
 231.23973644 252.71536936 356.64839267 185.96261949 285.55899107]
total_rewards_mean           260.5076443587644
total_rewards_std            44.43746335918658
total_rewards_max            356.64839266778534
total_rewards_min            185.96261949305804
Number of train steps total  4000
Number of env steps total    4358
Number of rollouts total     0
Train Time (s)               606.2097322354093
(Previous) Eval Time (s)     0
Sample Time (s)              12.368887207470834
Epoch Time (s)               618.5786194428802
Total Train Time (s)         620.1729110521264
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 07:55:41.349556 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #0 | Epoch Duration: 620.1761212348938
2020-01-13 07:55:41.349743 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068718895
Z variance train             0.067393266
KL Divergence                5.2058916
KL Loss                      0.5205892
QF Loss                      6777.198
VF Loss                      1792.6904
Policy Loss                  -601.4089
Q Predictions Mean           603.1009
Q Predictions Std            169.09335
Q Predictions Max            802.5871
Q Predictions Min            20.418232
V Predictions Mean           632.77515
V Predictions Std            134.73769
V Predictions Max            769.3812
V Predictions Min            92.24913
Log Pis Mean                 0.71483517
Log Pis Std                  6.145467
Log Pis Max                  26.469664
Log Pis Min                  -9.940231
Policy mu Mean               0.44704154
Policy mu Std                0.9233956
Policy mu Max                2.526168
Policy mu Min                -2.2364988
Policy log std Mean          -0.33716184
Policy log std Std           0.1432918
Policy log std Max           -0.05204345
Policy log std Min           -0.82434314
Z mean eval                  0.10080697
Z variance eval              0.058994792
total_rewards                [114.18752964 125.47376289 171.46146922 103.63078731 157.82041163
 121.95409716 126.71050532 118.95999833 117.63061637 135.24163164]
total_rewards_mean           129.30708094931867
total_rewards_std            19.57549259210832
total_rewards_max            171.46146921602096
total_rewards_min            103.63078730857983
Number of train steps total  8000
Number of env steps total    6687
Number of rollouts total     0
Train Time (s)               621.2773914118297
(Previous) Eval Time (s)     0.60490966681391
Sample Time (s)              6.418831641320139
Epoch Time (s)               628.3011327199638
Total Train Time (s)         1248.5964274378493
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:06:09.773069 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #1 | Epoch Duration: 628.4231917858124
2020-01-13 08:06:09.773210 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.102051176
Z variance train             0.05930243
KL Divergence                5.2827034
KL Loss                      0.52827036
QF Loss                      13018.764
VF Loss                      7437.596
Policy Loss                  -935.868
Q Predictions Mean           931.0088
Q Predictions Std            378.8415
Q Predictions Max            1359.8055
Q Predictions Min            -6.659147
V Predictions Mean           986.6991
V Predictions Std            351.13986
V Predictions Max            1350.7948
V Predictions Min            14.575318
Log Pis Mean                 4.4488077
Log Pis Std                  8.438391
Log Pis Max                  35.271084
Log Pis Min                  -10.270897
Policy mu Mean               0.09873951
Policy mu Std                1.1868559
Policy mu Max                2.9305441
Policy mu Min                -2.7609706
Policy log std Mean          -0.39786327
Policy log std Std           0.15558182
Policy log std Max           -0.014882941
Policy log std Min           -0.9568889
Z mean eval                  0.06126678
Z variance eval              0.025563437
total_rewards                [259.54510548 183.80486826 201.28239908 200.86372364 236.93961822
 184.11252463 233.91623847 296.77038714 259.36011262 218.30325634]
total_rewards_mean           227.48982338686042
total_rewards_std            34.99112321223254
total_rewards_max            296.77038714198045
total_rewards_min            183.80486825672162
Number of train steps total  12000
Number of env steps total    8998
Number of rollouts total     0
Train Time (s)               619.3642974817194
(Previous) Eval Time (s)     1.341297369915992
Sample Time (s)              5.351354390848428
Epoch Time (s)               626.0569492424838
Total Train Time (s)         1874.7608123244718
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:16:35.938327 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #2 | Epoch Duration: 626.1650166511536
2020-01-13 08:16:35.938466 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06493211
Z variance train             0.025519526
KL Divergence                7.3594866
KL Loss                      0.7359487
QF Loss                      58942.56
VF Loss                      15497.958
Policy Loss                  -1345.8572
Q Predictions Mean           1327.2117
Q Predictions Std            658.3403
Q Predictions Max            2074.3
Q Predictions Min            -21.098286
V Predictions Mean           1416.7246
V Predictions Std            642.6211
V Predictions Max            2211.509
V Predictions Min            33.298172
Log Pis Mean                 9.309435
Log Pis Std                  8.313051
Log Pis Max                  37.723755
Log Pis Min                  -12.419032
Policy mu Mean               0.40324426
Policy mu Std                1.2953775
Policy mu Max                3.0070953
Policy mu Min                -2.8816504
Policy log std Mean          -0.46636087
Policy log std Std           0.13018054
Policy log std Max           0.00043188035
Policy log std Min           -0.94616085
Z mean eval                  0.021212643
Z variance eval              0.1529579
total_rewards                [221.52511497 175.9044675  170.05536944 220.56471166 198.50536733
 189.09909771 232.25977924  76.43009398 326.99286915 187.29509795]
total_rewards_mean           199.86319689377007
total_rewards_std            59.23107997727441
total_rewards_max            326.9928691481779
total_rewards_min            76.43009398295604
Number of train steps total  16000
Number of env steps total    11345
Number of rollouts total     0
Train Time (s)               615.2338705831207
(Previous) Eval Time (s)     0.8878098907880485
Sample Time (s)              6.087246513925493
Epoch Time (s)               622.2089269878343
Total Train Time (s)         2497.0803658282384
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:26:58.259314 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #3 | Epoch Duration: 622.3207318782806
2020-01-13 08:26:58.259518 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021797288
Z variance train             0.1520433
KL Divergence                5.32824
KL Loss                      0.532824
QF Loss                      20974.734
VF Loss                      5795.7974
Policy Loss                  -1738.1931
Q Predictions Mean           1669.3455
Q Predictions Std            687.96246
Q Predictions Max            2601.8213
Q Predictions Min            8.84386
V Predictions Mean           1740.4476
V Predictions Std            643.1283
V Predictions Max            2505.2793
V Predictions Min            70.30013
Log Pis Mean                 9.967209
Log Pis Std                  10.781316
Log Pis Max                  47.371613
Log Pis Min                  -10.9389105
Policy mu Mean               0.38502744
Policy mu Std                1.3399967
Policy mu Max                3.3200307
Policy mu Min                -3.3523917
Policy log std Mean          -0.4645298
Policy log std Std           0.14009488
Policy log std Max           -0.02723467
Policy log std Min           -0.9718349
Z mean eval                  0.026663596
Z variance eval              0.03833467
total_rewards                [314.85892437 237.41393003 257.28374416 193.34702943 297.54286261
 369.55725462 267.64377322 309.05825765 233.45200818 272.00546536]
total_rewards_mean           275.21632496234304
total_rewards_std            47.30812696549875
total_rewards_max            369.5572546165351
total_rewards_min            193.34702943326081
Number of train steps total  20000
Number of env steps total    13603
Number of rollouts total     0
Train Time (s)               617.9801468239166
(Previous) Eval Time (s)     1.3422230896539986
Sample Time (s)              5.910424160305411
Epoch Time (s)               625.232794073876
Total Train Time (s)         3122.651546710171
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:37:23.831763 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #4 | Epoch Duration: 625.5720875263214
2020-01-13 08:37:23.831941 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02767297
Z variance train             0.03849287
KL Divergence                5.990398
KL Loss                      0.5990398
QF Loss                      39249.76
VF Loss                      9138.6875
Policy Loss                  -1814.7124
Q Predictions Mean           1767.6455
Q Predictions Std            870.2788
Q Predictions Max            2912.692
Q Predictions Min            -26.974016
V Predictions Mean           1848.7086
V Predictions Std            837.70776
V Predictions Max            2808.0083
V Predictions Min            33.13639
Log Pis Mean                 12.9037895
Log Pis Std                  9.802577
Log Pis Max                  60.444176
Log Pis Min                  -10.142849
Policy mu Mean               0.24262844
Policy mu Std                1.4718003
Policy mu Max                4.376961
Policy mu Min                -3.4178994
Policy log std Mean          -0.4886926
Policy log std Std           0.1296628
Policy log std Max           -0.049118176
Policy log std Min           -1.023069
Z mean eval                  0.027715033
Z variance eval              0.13027146
total_rewards                [186.30042065 295.20523914 205.18211443 191.50377249 246.64898999
 245.09564436 299.35185474 233.62132586 263.25545701 227.59786978]
total_rewards_mean           239.3762688451402
total_rewards_std            37.17482481920771
total_rewards_max            299.3518547423652
total_rewards_min            186.30042064893416
Number of train steps total  24000
Number of env steps total    15944
Number of rollouts total     0
Train Time (s)               619.455240979325
(Previous) Eval Time (s)     1.3085952731780708
Sample Time (s)              6.460244078189135
Epoch Time (s)               627.2240803306922
Total Train Time (s)         3749.984698449727
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:47:51.166593 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #5 | Epoch Duration: 627.3345062732697
2020-01-13 08:47:51.166845 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028138716
Z variance train             0.12983575
KL Divergence                4.712037
KL Loss                      0.4712037
QF Loss                      29905.0
VF Loss                      6967.1445
Policy Loss                  -1936.4899
Q Predictions Mean           1897.7264
Q Predictions Std            855.9949
Q Predictions Max            3003.773
Q Predictions Min            46.52227
V Predictions Mean           1935.6002
V Predictions Std            826.5133
V Predictions Max            2994.6328
V Predictions Min            54.80488
Log Pis Mean                 9.883849
Log Pis Std                  10.906933
Log Pis Max                  47.076954
Log Pis Min                  -11.918604
Policy mu Mean               0.2899508
Policy mu Std                1.3494184
Policy mu Max                3.4780276
Policy mu Min                -3.6446702
Policy log std Mean          -0.45804015
Policy log std Std           0.13475382
Policy log std Max           -0.053323314
Policy log std Min           -0.9933896
Z mean eval                  0.11898961
Z variance eval              0.06472856
total_rewards                [190.04223599 195.46294958 132.45811933 183.14978    178.99626263
 219.99356648 173.24807781 141.79084341 186.35684932 189.73348795]
total_rewards_mean           179.12321724871262
total_rewards_std            24.17350747264556
total_rewards_max            219.9935664767187
total_rewards_min            132.45811932722103
Number of train steps total  28000
Number of env steps total    18385
Number of rollouts total     0
Train Time (s)               584.0295012309216
(Previous) Eval Time (s)     0.9014598377980292
Sample Time (s)              6.550785182509571
Epoch Time (s)               591.4817462512292
Total Train Time (s)         4341.5734233204275
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 08:57:42.754589 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #6 | Epoch Duration: 591.5875728130341
2020-01-13 08:57:42.754737 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1209057
Z variance train             0.06514456
KL Divergence                6.7213116
KL Loss                      0.6721312
QF Loss                      52433.156
VF Loss                      4968.0566
Policy Loss                  -1646.8671
Q Predictions Mean           1616.579
Q Predictions Std            925.62695
Q Predictions Max            2723.943
Q Predictions Min            16.300262
V Predictions Mean           1667.1323
V Predictions Std            908.6433
V Predictions Max            2675.953
V Predictions Min            69.267
Log Pis Mean                 7.768812
Log Pis Std                  9.962883
Log Pis Max                  59.01145
Log Pis Min                  -10.656872
Policy mu Mean               0.20253089
Policy mu Std                1.3078691
Policy mu Max                6.7968607
Policy mu Min                -3.3347385
Policy log std Mean          -0.45481008
Policy log std Std           0.1432427
Policy log std Max           -0.04015836
Policy log std Min           -1.177388
Z mean eval                  0.17316036
Z variance eval              0.056867123
total_rewards                [206.28011519 226.55447022 232.5201941  228.94003954 197.16059508
 203.68498887 198.49333714 258.66326076 205.91305518 211.32775282]
total_rewards_mean           216.9537808896307
total_rewards_std            18.422631595867614
total_rewards_max            258.663260764035
total_rewards_min            197.16059507673208
Number of train steps total  32000
Number of env steps total    20706
Number of rollouts total     0
Train Time (s)               617.5781462988816
(Previous) Eval Time (s)     1.016481134109199
Sample Time (s)              6.123846739530563
Epoch Time (s)               624.7184741725214
Total Train Time (s)         4966.407778648194
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:08:07.589417 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #7 | Epoch Duration: 624.8345828056335
2020-01-13 09:08:07.589563 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.17249987
Z variance train             0.0565616
KL Divergence                6.345482
KL Loss                      0.6345482
QF Loss                      10694.803
VF Loss                      6274.543
Policy Loss                  -1375.7006
Q Predictions Mean           1341.3367
Q Predictions Std            923.3774
Q Predictions Max            2774.493
Q Predictions Min            9.332965
V Predictions Mean           1390.8391
V Predictions Std            917.5956
V Predictions Max            2779.2986
V Predictions Min            12.72995
Log Pis Mean                 8.320689
Log Pis Std                  10.603148
Log Pis Max                  45.699726
Log Pis Min                  -16.686047
Policy mu Mean               0.4255521
Policy mu Std                1.2598251
Policy mu Max                3.8824682
Policy mu Min                -3.5324078
Policy log std Mean          -0.4509218
Policy log std Std           0.15203983
Policy log std Max           0.09161362
Policy log std Min           -1.0150139
Z mean eval                  0.060551323
Z variance eval              0.066377476
total_rewards                [161.69709352 156.46381172 204.64885998 168.88962316 167.65850778
  86.76230851 122.04247697 161.94981767 127.83172205 187.60225178]
total_rewards_mean           154.55464731317372
total_rewards_std            32.33431944891896
total_rewards_max            204.64885997921007
total_rewards_min            86.7623085116848
Number of train steps total  36000
Number of env steps total    23047
Number of rollouts total     0
Train Time (s)               621.396258554887
(Previous) Eval Time (s)     0.7619316130876541
Sample Time (s)              5.966347928158939
Epoch Time (s)               628.1245380961336
Total Train Time (s)         5594.802220939659
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:18:35.985778 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #8 | Epoch Duration: 628.3961007595062
2020-01-13 09:18:35.985959 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060336787
Z variance train             0.06687559
KL Divergence                6.184512
KL Loss                      0.61845124
QF Loss                      11169.865
VF Loss                      5349.2803
Policy Loss                  -1408.4935
Q Predictions Mean           1354.8009
Q Predictions Std            847.45044
Q Predictions Max            2677.9392
Q Predictions Min            68.17694
V Predictions Mean           1418.9104
V Predictions Std            854.2164
V Predictions Max            2720.4727
V Predictions Min            56.06941
Log Pis Mean                 10.170301
Log Pis Std                  10.93205
Log Pis Max                  46.794537
Log Pis Min                  -10.229253
Policy mu Mean               0.348507
Policy mu Std                1.335248
Policy mu Max                3.8288553
Policy mu Min                -3.6572106
Policy log std Mean          -0.45956635
Policy log std Std           0.15415768
Policy log std Max           0.056491986
Policy log std Min           -0.9972673
Z mean eval                  0.032951258
Z variance eval              0.06757961
total_rewards                [324.27957226 307.30226223 307.66744194 289.52332976 353.50882798
 283.69995831 319.02629185 311.91148328 428.37312342 246.14641019]
total_rewards_mean           317.1438701225581
total_rewards_std            45.6999839363902
total_rewards_max            428.37312341576126
total_rewards_min            246.14641019022397
Number of train steps total  40000
Number of env steps total    25356
Number of rollouts total     0
Train Time (s)               612.2805794770829
(Previous) Eval Time (s)     1.5034568873234093
Sample Time (s)              6.281712712254375
Epoch Time (s)               620.0657490766607
Total Train Time (s)         6214.972882105503
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:28:56.156574 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #9 | Epoch Duration: 620.1704912185669
2020-01-13 09:28:56.156700 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #9 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032407414
Z variance train             0.06766488
KL Divergence                6.4773817
KL Loss                      0.64773816
QF Loss                      8557.959
VF Loss                      3624.6812
Policy Loss                  -1305.0465
Q Predictions Mean           1260.3103
Q Predictions Std            821.33417
Q Predictions Max            2837.478
Q Predictions Min            -61.89819
V Predictions Mean           1300.977
V Predictions Std            817.7476
V Predictions Max            2701.2356
V Predictions Min            61.454216
Log Pis Mean                 7.0536804
Log Pis Std                  9.512706
Log Pis Max                  43.67151
Log Pis Min                  -12.779663
Policy mu Mean               0.42505425
Policy mu Std                1.2079523
Policy mu Max                3.2710211
Policy mu Min                -4.441779
Policy log std Mean          -0.4217537
Policy log std Std           0.14563207
Policy log std Max           0.10602696
Policy log std Min           -1.0630231
Z mean eval                  0.056189917
Z variance eval              0.19453037
total_rewards                [196.22890586 252.93652706 188.71756074 276.03850116 209.7050575
 196.64648767 262.14460906 222.43988646 363.89701727 469.2435939 ]
total_rewards_mean           263.79981466787467
total_rewards_std            84.76246862717096
total_rewards_max            469.24359390148993
total_rewards_min            188.71756074479177
Number of train steps total  44000
Number of env steps total    27647
Number of rollouts total     0
Train Time (s)               618.8572295266204
(Previous) Eval Time (s)     1.3120173537172377
Sample Time (s)              5.344771404750645
Epoch Time (s)               625.5140182850882
Total Train Time (s)         6840.594247744419
Epoch                        10
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:39:21.779420 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #10 | Epoch Duration: 625.6226122379303
2020-01-13 09:39:21.779597 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05661316
Z variance train             0.19331387
KL Divergence                5.329618
KL Loss                      0.5329618
QF Loss                      11855.51
VF Loss                      8560.756
Policy Loss                  -1180.7913
Q Predictions Mean           1160.2617
Q Predictions Std            753.1248
Q Predictions Max            2472.4097
Q Predictions Min            -23.571358
V Predictions Mean           1191.6394
V Predictions Std            758.8483
V Predictions Max            2477.5962
V Predictions Min            34.09246
Log Pis Mean                 6.6047883
Log Pis Std                  9.836729
Log Pis Max                  47.457035
Log Pis Min                  -12.467882
Policy mu Mean               0.23817736
Policy mu Std                1.2511116
Policy mu Max                3.818815
Policy mu Min                -3.5362554
Policy log std Mean          -0.42671636
Policy log std Std           0.14698945
Policy log std Max           0.06936492
Policy log std Min           -0.98039716
Z mean eval                  0.054499447
Z variance eval              0.05580773
total_rewards                [291.38811452 407.07610509 240.88021426 449.99448765 336.49681387
 366.39087859 385.1314432  335.70792929 380.68568096 345.65179676]
total_rewards_mean           353.9403464192836
total_rewards_std            55.94085555604307
total_rewards_max            449.9944876514992
total_rewards_min            240.8802142597599
Number of train steps total  48000
Number of env steps total    30018
Number of rollouts total     0
Train Time (s)               620.0605390421115
(Previous) Eval Time (s)     1.872207717038691
Sample Time (s)              6.219058820977807
Epoch Time (s)               628.151805580128
Total Train Time (s)         7468.866510207299
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 09:49:50.051727 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #11 | Epoch Duration: 628.2719957828522
2020-01-13 09:49:50.051874 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05481906
Z variance train             0.05573485
KL Divergence                6.559971
KL Loss                      0.6559971
QF Loss                      5064.875
VF Loss                      2579.0376
Policy Loss                  -1033.8569
Q Predictions Mean           996.5437
Q Predictions Std            701.0634
Q Predictions Max            2507.3306
Q Predictions Min            -3.1998892
V Predictions Mean           1040.162
V Predictions Std            705.7361
V Predictions Max            2486.7727
V Predictions Min            18.807013
Log Pis Mean                 4.8319154
Log Pis Std                  9.709708
Log Pis Max                  47.470924
Log Pis Min                  -12.874664
Policy mu Mean               0.29224548
Policy mu Std                1.1747607
Policy mu Max                3.4727561
Policy mu Min                -3.687754
Policy log std Mean          -0.4092916
Policy log std Std           0.14793107
Policy log std Max           0.08522509
Policy log std Min           -0.9837956
Z mean eval                  0.033894077
Z variance eval              0.06371639
total_rewards                [427.13050736 423.38508121 612.55584848 307.97190452 318.91233558
 338.8013231  353.46972649 348.52110765 278.11165278 338.57643757]
total_rewards_mean           374.7435924761023
total_rewards_std            90.72953081526688
total_rewards_max            612.5558484845305
total_rewards_min            278.1116527810985
Number of train steps total  52000
Number of env steps total    32434
Number of rollouts total     0
Train Time (s)               620.1797642619349
(Previous) Eval Time (s)     1.923002720810473
Sample Time (s)              6.20877300016582
Epoch Time (s)               628.3115399829112
Total Train Time (s)         8097.300282844808
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:00:18.486411 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #12 | Epoch Duration: 628.4344372749329
2020-01-13 10:00:18.486550 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033332583
Z variance train             0.06389205
KL Divergence                5.4138527
KL Loss                      0.5413853
QF Loss                      4530.2964
VF Loss                      2940.1514
Policy Loss                  -967.0379
Q Predictions Mean           931.0617
Q Predictions Std            606.87
Q Predictions Max            1989.1193
Q Predictions Min            10.619
V Predictions Mean           948.9748
V Predictions Std            608.2521
V Predictions Max            1934.6116
V Predictions Min            7.607077
Log Pis Mean                 3.078371
Log Pis Std                  8.763756
Log Pis Max                  42.022217
Log Pis Min                  -14.538452
Policy mu Mean               0.26435548
Policy mu Std                1.0812613
Policy mu Max                3.561141
Policy mu Min                -3.680192
Policy log std Mean          -0.3788092
Policy log std Std           0.14396068
Policy log std Max           0.030031428
Policy log std Min           -0.9546957
Z mean eval                  0.010777338
Z variance eval              0.16889435
total_rewards                [242.50314856 259.38979379 220.58021955 355.57982211 305.95509276
 235.14681228 265.3737716  264.24984348 252.83194509 243.96838517]
total_rewards_mean           264.5578834372621
total_rewards_std            37.24657621862289
total_rewards_max            355.5798221147917
total_rewards_min            220.58021955184998
Number of train steps total  56000
Number of env steps total    34794
Number of rollouts total     0
Train Time (s)               615.7129907677881
(Previous) Eval Time (s)     1.5153833250515163
Sample Time (s)              6.548197476193309
Epoch Time (s)               623.776571569033
Total Train Time (s)         8721.381994694937
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:10:42.568984 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #13 | Epoch Duration: 624.0823030471802
2020-01-13 10:10:42.569119 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008941521
Z variance train             0.1698822
KL Divergence                3.6321898
KL Loss                      0.363219
QF Loss                      15527.259
VF Loss                      5002.762
Policy Loss                  -912.5708
Q Predictions Mean           887.77795
Q Predictions Std            509.1785
Q Predictions Max            1688.4668
Q Predictions Min            1.2384433
V Predictions Mean           927.02515
V Predictions Std            500.28857
V Predictions Max            1832.3231
V Predictions Min            10.503605
Log Pis Mean                 2.413116
Log Pis Std                  9.310196
Log Pis Max                  41.967873
Log Pis Min                  -16.636398
Policy mu Mean               0.2875795
Policy mu Std                1.0779662
Policy mu Max                4.2069
Policy mu Min                -3.5824509
Policy log std Mean          -0.38639307
Policy log std Std           0.14380433
Policy log std Max           0.039361924
Policy log std Min           -1.0131205
Z mean eval                  0.030892273
Z variance eval              0.0975278
total_rewards                [383.82102647 342.90040891 304.81269884 381.67489628 554.21877349
 253.15126732 294.97472568 373.99629702 349.25926541 393.26734038]
total_rewards_mean           363.207669979742
total_rewards_std            76.84805188558542
total_rewards_max            554.2187734877473
total_rewards_min            253.15126731529975
Number of train steps total  60000
Number of env steps total    37132
Number of rollouts total     0
Train Time (s)               618.4731858312152
(Previous) Eval Time (s)     1.7222810699604452
Sample Time (s)              6.210482593625784
Epoch Time (s)               626.4059494948015
Total Train Time (s)         9347.907741439994
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:21:09.096191 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #14 | Epoch Duration: 626.5269651412964
2020-01-13 10:21:09.096364 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029462436
Z variance train             0.09739886
KL Divergence                4.119316
KL Loss                      0.4119316
QF Loss                      3685.9697
VF Loss                      1377.1599
Policy Loss                  -853.8672
Q Predictions Mean           838.3723
Q Predictions Std            455.32877
Q Predictions Max            1666.1711
Q Predictions Min            27.55964
V Predictions Mean           856.83594
V Predictions Std            459.05447
V Predictions Max            1603.5948
V Predictions Min            32.51732
Log Pis Mean                 1.6620548
Log Pis Std                  7.7078204
Log Pis Max                  32.77373
Log Pis Min                  -13.13362
Policy mu Mean               0.4035405
Policy mu Std                1.0009712
Policy mu Max                3.4183106
Policy mu Min                -3.09776
Policy log std Mean          -0.38000622
Policy log std Std           0.1276395
Policy log std Max           -0.027733997
Policy log std Min           -1.0426953
Z mean eval                  0.04492682
Z variance eval              0.06851921
total_rewards                [249.07871886 301.84578341 381.84800081 284.79411333 318.53139962
 584.1512816  435.99232767 214.75655345 369.30484061 210.23452427]
total_rewards_mean           335.05375436182214
total_rewards_std            108.14146503776479
total_rewards_max            584.1512816032645
total_rewards_min            210.23452426826296
Number of train steps total  64000
Number of env steps total    39629
Number of rollouts total     0
Train Time (s)               611.6057959948666
(Previous) Eval Time (s)     1.7835876317694783
Sample Time (s)              7.052610348910093
Epoch Time (s)               620.4419939755462
Total Train Time (s)         9968.45341799967
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:31:29.642144 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #15 | Epoch Duration: 620.5456595420837
2020-01-13 10:31:29.642283 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045401625
Z variance train             0.068848506
KL Divergence                5.125695
KL Loss                      0.51256955
QF Loss                      3980.7
VF Loss                      1038.4625
Policy Loss                  -853.7392
Q Predictions Mean           841.3761
Q Predictions Std            415.49136
Q Predictions Max            1391.4944
Q Predictions Min            13.481223
V Predictions Mean           859.87415
V Predictions Std            408.09122
V Predictions Max            1377.8715
V Predictions Min            24.771786
Log Pis Mean                 -0.65506625
Log Pis Std                  7.2247953
Log Pis Max                  31.819893
Log Pis Min                  -14.7767515
Policy mu Mean               0.2646987
Policy mu Std                0.94748163
Policy mu Max                2.9161146
Policy mu Min                -2.9556494
Policy log std Mean          -0.33925033
Policy log std Std           0.119088665
Policy log std Max           0.01744318
Policy log std Min           -0.9089734
Z mean eval                  0.02926143
Z variance eval              0.04325978
total_rewards                [299.54810356 365.81775039 426.78332046 367.07637527 308.26767197
 394.74262769 528.95156226 371.65184196 362.04440082 280.70028723]
total_rewards_mean           370.5583941614937
total_rewards_std            67.77895830043467
total_rewards_max            528.9515622635404
total_rewards_min            280.7002872266004
Number of train steps total  68000
Number of env steps total    42066
Number of rollouts total     0
Train Time (s)               609.6534370970912
(Previous) Eval Time (s)     1.7253268077038229
Sample Time (s)              6.4752484848722816
Epoch Time (s)               617.8540123896673
Total Train Time (s)         10586.404594317544
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:41:47.594023 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #16 | Epoch Duration: 617.9516425132751
2020-01-13 10:41:47.594159 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030014148
Z variance train             0.043344777
KL Divergence                5.89343
KL Loss                      0.589343
QF Loss                      3678.4966
VF Loss                      1301.9327
Policy Loss                  -801.92
Q Predictions Mean           784.9763
Q Predictions Std            397.9849
Q Predictions Max            1343.7847
Q Predictions Min            56.0845
V Predictions Mean           809.6121
V Predictions Std            393.48245
V Predictions Max            1352.0197
V Predictions Min            69.921776
Log Pis Mean                 -0.7260581
Log Pis Std                  7.09322
Log Pis Max                  31.664663
Log Pis Min                  -16.4595
Policy mu Mean               0.2880924
Policy mu Std                0.9284168
Policy mu Max                2.94774
Policy mu Min                -3.3786511
Policy log std Mean          -0.33781528
Policy log std Std           0.12888488
Policy log std Max           -0.046652652
Policy log std Min           -0.9360233
Z mean eval                  0.019284582
Z variance eval              0.114475295
total_rewards                [269.76165738 448.20828126 454.88339664 389.06500868 396.94077679
 333.8365008  367.98535475 335.97540554 293.08672705 310.87010322]
total_rewards_mean           360.0613212107013
total_rewards_std            59.45795574387775
total_rewards_max            454.8833966397536
total_rewards_min            269.7616573772618
Number of train steps total  72000
Number of env steps total    44503
Number of rollouts total     0
Train Time (s)               609.8853801796213
(Previous) Eval Time (s)     1.690373548772186
Sample Time (s)              5.876716621685773
Epoch Time (s)               617.4524703500792
Total Train Time (s)         11203.963494356256
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 10:52:05.153547 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #17 | Epoch Duration: 617.5592904090881
2020-01-13 10:52:05.153684 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01884113
Z variance train             0.11447022
KL Divergence                4.819152
KL Loss                      0.4819152
QF Loss                      1706.7675
VF Loss                      859.30975
Policy Loss                  -785.56433
Q Predictions Mean           766.868
Q Predictions Std            404.27884
Q Predictions Max            1315.4604
Q Predictions Min            0.63584054
V Predictions Mean           775.4791
V Predictions Std            397.74152
V Predictions Max            1317.0824
V Predictions Min            39.621193
Log Pis Mean                 -1.2021241
Log Pis Std                  6.198236
Log Pis Max                  30.08073
Log Pis Min                  -11.653976
Policy mu Mean               0.3104961
Policy mu Std                0.8851932
Policy mu Max                3.112736
Policy mu Min                -2.9523327
Policy log std Mean          -0.3243126
Policy log std Std           0.11800627
Policy log std Max           -0.040773734
Policy log std Min           -0.89751434
Z mean eval                  0.02086604
Z variance eval              0.1116446
total_rewards                [309.4948116  478.61143575 497.98924595 459.90183392 387.67078359
 287.62511217 318.70867006 458.99390787 412.56598514 374.41771087]
total_rewards_mean           398.5979496925855
total_rewards_std            71.56986482945501
total_rewards_max            497.9892459496171
total_rewards_min            287.62511217078617
Number of train steps total  76000
Number of env steps total    46913
Number of rollouts total     0
Train Time (s)               605.0408186009154
(Previous) Eval Time (s)     1.9868756011128426
Sample Time (s)              6.551526281051338
Epoch Time (s)               613.5792204830796
Total Train Time (s)         11817.645128930453
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:02:18.836178 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #18 | Epoch Duration: 613.6823813915253
2020-01-13 11:02:18.836312 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021943254
Z variance train             0.11130246
KL Divergence                4.1444
KL Loss                      0.41444
QF Loss                      1259.9016
VF Loss                      736.43945
Policy Loss                  -788.0246
Q Predictions Mean           773.9684
Q Predictions Std            399.75513
Q Predictions Max            1335.4652
Q Predictions Min            11.557592
V Predictions Mean           775.5751
V Predictions Std            398.76968
V Predictions Max            1331.7654
V Predictions Min            49.70333
Log Pis Mean                 -1.4725137
Log Pis Std                  6.5780625
Log Pis Max                  22.119844
Log Pis Min                  -15.345551
Policy mu Mean               0.2935252
Policy mu Std                0.89373255
Policy mu Max                2.7509274
Policy mu Min                -2.8177714
Policy log std Mean          -0.33053124
Policy log std Std           0.119649425
Policy log std Max           -0.056657784
Policy log std Min           -0.8468338
Z mean eval                  0.017091123
Z variance eval              0.13143946
total_rewards                [509.15168066 549.30362634 600.84002348 411.55831374 454.28878945
 439.65868181 472.40304079 448.31336773 557.57560347 445.29004242]
total_rewards_mean           488.8383169880482
total_rewards_std            58.93320837589466
total_rewards_max            600.8400234786819
total_rewards_min            411.5583137362613
Number of train steps total  80000
Number of env steps total    49400
Number of rollouts total     0
Train Time (s)               605.5517834899947
(Previous) Eval Time (s)     2.531769667286426
Sample Time (s)              6.764254912734032
Epoch Time (s)               614.8478080700152
Total Train Time (s)         12432.595210982021
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:12:33.786773 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #19 | Epoch Duration: 614.9503643512726
2020-01-13 11:12:33.786907 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017399441
Z variance train             0.13100716
KL Divergence                3.9804883
KL Loss                      0.39804885
QF Loss                      1312.365
VF Loss                      565.85815
Policy Loss                  -749.9998
Q Predictions Mean           736.3123
Q Predictions Std            403.18985
Q Predictions Max            1342.3492
Q Predictions Min            -0.83727586
V Predictions Mean           751.26196
V Predictions Std            400.7347
V Predictions Max            1339.4352
V Predictions Min            -1.3809786
Log Pis Mean                 -2.0198967
Log Pis Std                  7.314555
Log Pis Max                  32.39582
Log Pis Min                  -13.283704
Policy mu Mean               0.2425232
Policy mu Std                0.8829452
Policy mu Max                2.8670433
Policy mu Min                -2.6865842
Policy log std Mean          -0.31757757
Policy log std Std           0.12041418
Policy log std Max           -0.0098653585
Policy log std Min           -1.0059648
Z mean eval                  0.035507705
Z variance eval              0.044178743
total_rewards                [359.18406121 395.74708417 354.03942334 399.32316793 430.73863611
 652.603158   500.73522971 452.17451011 390.69199933 390.12987823]
total_rewards_mean           432.53671481404444
total_rewards_std            84.27189693154476
total_rewards_max            652.6031580032809
total_rewards_min            354.03942334384686
Number of train steps total  84000
Number of env steps total    52228
Number of rollouts total     0
Train Time (s)               608.5965428240597
(Previous) Eval Time (s)     2.291784966364503
Sample Time (s)              11.465284641366452
Epoch Time (s)               622.3536124317907
Total Train Time (s)         13055.066663160454
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:22:56.259053 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #20 | Epoch Duration: 622.4720492362976
2020-01-13 11:22:56.259181 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03732509
Z variance train             0.04413726
KL Divergence                5.5811768
KL Loss                      0.5581177
QF Loss                      2523.0344
VF Loss                      1172.2198
Policy Loss                  -810.9617
Q Predictions Mean           783.75494
Q Predictions Std            433.42188
Q Predictions Max            1363.4594
Q Predictions Min            -61.115677
V Predictions Mean           810.1228
V Predictions Std            429.70837
V Predictions Max            1375.6624
V Predictions Min            -1.1654041
Log Pis Mean                 -1.6753621
Log Pis Std                  6.435284
Log Pis Max                  24.595543
Log Pis Min                  -12.277819
Policy mu Mean               0.19942604
Policy mu Std                0.9090934
Policy mu Max                3.8105614
Policy mu Min                -3.7129443
Policy log std Mean          -0.32829157
Policy log std Std           0.12038885
Policy log std Max           0.0042862594
Policy log std Min           -0.867207
Z mean eval                  0.030763399
Z variance eval              0.08460708
total_rewards                [563.22859625 388.09209782 438.25394601 317.87838869 400.10474211
 510.91171731 328.74431041 431.19139982 602.10972358 377.51792721]
total_rewards_mean           435.80328492195497
total_rewards_std            90.48725035923167
total_rewards_max            602.1097235751301
total_rewards_min            317.8783886935403
Number of train steps total  88000
Number of env steps total    55088
Number of rollouts total     0
Train Time (s)               600.618961807806
(Previous) Eval Time (s)     2.2408209280110896
Sample Time (s)              7.16003959113732
Epoch Time (s)               610.0198223269545
Total Train Time (s)         13665.187823066022
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:33:06.380771 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #21 | Epoch Duration: 610.1214964389801
2020-01-13 11:33:06.380905 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03245915
Z variance train             0.08523266
KL Divergence                4.9619026
KL Loss                      0.49619028
QF Loss                      1554.9082
VF Loss                      732.9863
Policy Loss                  -797.17834
Q Predictions Mean           781.46814
Q Predictions Std            415.95972
Q Predictions Max            1370.1582
Q Predictions Min            36.568195
V Predictions Mean           784.6194
V Predictions Std            420.53534
V Predictions Max            1376.792
V Predictions Min            8.545077
Log Pis Mean                 -1.4523785
Log Pis Std                  5.4408536
Log Pis Max                  26.968199
Log Pis Min                  -15.039082
Policy mu Mean               0.30057648
Policy mu Std                0.8649148
Policy mu Max                2.9174578
Policy mu Min                -2.6070676
Policy log std Mean          -0.33433595
Policy log std Std           0.116920285
Policy log std Max           -0.062478364
Policy log std Min           -0.8232209
Z mean eval                  0.030337611
Z variance eval              0.101013005
total_rewards                [441.09486182 446.09074616 403.33593248 482.24551871 422.00795642
 417.06243772 387.56233435 373.98933618 371.68074064 418.00658764]
total_rewards_mean           416.3076452144064
total_rewards_std            32.652948036483416
total_rewards_max            482.2455187144768
total_rewards_min            371.680740643328
Number of train steps total  92000
Number of env steps total    57954
Number of rollouts total     0
Train Time (s)               607.0199704961851
(Previous) Eval Time (s)     2.1607807306572795
Sample Time (s)              7.254433034919202
Epoch Time (s)               616.4351842617616
Total Train Time (s)         14281.732058817055
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:43:22.925790 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #22 | Epoch Duration: 616.5447890758514
2020-01-13 11:43:22.925930 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030841947
Z variance train             0.10133548
KL Divergence                4.6069703
KL Loss                      0.46069703
QF Loss                      1278.0786
VF Loss                      669.827
Policy Loss                  -784.04266
Q Predictions Mean           779.04517
Q Predictions Std            416.05978
Q Predictions Max            1391.7638
Q Predictions Min            17.408361
V Predictions Mean           778.20074
V Predictions Std            408.82877
V Predictions Max            1386.6552
V Predictions Min            11.697655
Log Pis Mean                 -2.3892436
Log Pis Std                  5.329727
Log Pis Max                  17.55904
Log Pis Min                  -14.954213
Policy mu Mean               0.26839694
Policy mu Std                0.84977144
Policy mu Max                2.905533
Policy mu Min                -2.4649675
Policy log std Mean          -0.3232534
Policy log std Std           0.1089467
Policy log std Max           0.008204788
Policy log std Min           -0.9332549
Z mean eval                  0.0477522
Z variance eval              0.110343
total_rewards                [431.00856827 547.33017223 358.26598247 353.6481415  293.01259677
 391.93671578 552.21142474 567.07759078 403.84937458 387.09438072]
total_rewards_mean           428.5434947842865
total_rewards_std            90.10358254763727
total_rewards_max            567.0775907847651
total_rewards_min            293.01259676591064
Number of train steps total  96000
Number of env steps total    60785
Number of rollouts total     0
Train Time (s)               609.236483943183
(Previous) Eval Time (s)     2.141372077167034
Sample Time (s)              6.677159772254527
Epoch Time (s)               618.0550157926045
Total Train Time (s)         14899.90920251282
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 11:53:41.103740 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #23 | Epoch Duration: 618.1777126789093
2020-01-13 11:53:41.103870 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048544105
Z variance train             0.11061786
KL Divergence                3.904406
KL Loss                      0.3904406
QF Loss                      1912.5381
VF Loss                      824.75104
Policy Loss                  -829.2701
Q Predictions Mean           811.35144
Q Predictions Std            418.4545
Q Predictions Max            1384.928
Q Predictions Min            17.805546
V Predictions Mean           826.61365
V Predictions Std            416.46576
V Predictions Max            1393.829
V Predictions Min            56.828606
Log Pis Mean                 -2.1269832
Log Pis Std                  5.6519737
Log Pis Max                  27.851414
Log Pis Min                  -13.196211
Policy mu Mean               0.26555544
Policy mu Std                0.8575209
Policy mu Max                3.015927
Policy mu Min                -3.0840886
Policy log std Mean          -0.32414022
Policy log std Std           0.1160506
Policy log std Max           0.025746971
Policy log std Min           -0.87429833
Z mean eval                  0.04118206
Z variance eval              0.051545672
total_rewards                [671.51083011 529.9348452  714.64301846 491.80144665 534.44384028
 486.87173765 383.55614332 437.87220261 252.78543235 417.38921498]
total_rewards_mean           492.0808711619776
total_rewards_std            127.49161700522491
total_rewards_max            714.643018455515
total_rewards_min            252.78543235486515
Number of train steps total  100000
Number of env steps total    63677
Number of rollouts total     0
Train Time (s)               612.1987726059742
(Previous) Eval Time (s)     2.5179346930235624
Sample Time (s)              6.949718456249684
Epoch Time (s)               621.6664257552475
Total Train Time (s)         15521.685531751718
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:04:02.880966 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #24 | Epoch Duration: 621.7770006656647
2020-01-13 12:04:02.881104 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042155955
Z variance train             0.05168696
KL Divergence                5.5460806
KL Loss                      0.55460805
QF Loss                      1176.2163
VF Loss                      708.9727
Policy Loss                  -811.5829
Q Predictions Mean           798.23596
Q Predictions Std            428.2217
Q Predictions Max            1412.3212
Q Predictions Min            10.530852
V Predictions Mean           801.4988
V Predictions Std            422.23105
V Predictions Max            1400.6875
V Predictions Min            24.608953
Log Pis Mean                 -1.69923
Log Pis Std                  6.81837
Log Pis Max                  32.55288
Log Pis Min                  -12.278776
Policy mu Mean               0.31568062
Policy mu Std                0.85132223
Policy mu Max                2.9434896
Policy mu Min                -3.082546
Policy log std Mean          -0.3276481
Policy log std Std           0.11711932
Policy log std Max           -0.060532227
Policy log std Min           -0.87392145
Z mean eval                  0.06535418
Z variance eval              0.06617593
total_rewards                [562.21680455 414.60416185 725.66424085 457.40591398 438.89936588
 441.67617946 439.06799429 377.61106614 424.54370988 379.77695128]
total_rewards_mean           466.14663881682674
total_rewards_std            99.20455343263299
total_rewards_max            725.6642408537904
total_rewards_min            377.61106613658166
Number of train steps total  104000
Number of env steps total    66383
Number of rollouts total     0
Train Time (s)               611.543492496945
(Previous) Eval Time (s)     2.46562291495502
Sample Time (s)              6.729081969708204
Epoch Time (s)               620.7381973816082
Total Train Time (s)         16142.545939490665
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:14:23.742207 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #25 | Epoch Duration: 620.8610036373138
2020-01-13 12:14:23.742344 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0670184
Z variance train             0.06624363
KL Divergence                4.7303386
KL Loss                      0.47303388
QF Loss                      1415.1191
VF Loss                      1003.5268
Policy Loss                  -864.9739
Q Predictions Mean           857.7815
Q Predictions Std            435.95502
Q Predictions Max            1474.1246
Q Predictions Min            14.159474
V Predictions Mean           869.76117
V Predictions Std            425.60843
V Predictions Max            1450.181
V Predictions Min            44.75704
Log Pis Mean                 -2.023017
Log Pis Std                  6.801514
Log Pis Max                  33.859585
Log Pis Min                  -13.232526
Policy mu Mean               0.21327792
Policy mu Std                0.87488854
Policy mu Max                3.071818
Policy mu Min                -3.439757
Policy log std Mean          -0.3333187
Policy log std Std           0.12785724
Policy log std Max           -0.040468976
Policy log std Min           -0.9326554
Z mean eval                  0.071024805
Z variance eval              0.08132839
total_rewards                [467.21967328 394.40688479 497.84530893 509.41876144 528.08727377
 433.29605137 446.15333663 421.00080281 537.71302346 523.03126958]
total_rewards_mean           475.81723860614
total_rewards_std            47.750509540908475
total_rewards_max            537.7130234599447
total_rewards_min            394.40688479068245
Number of train steps total  108000
Number of env steps total    69159
Number of rollouts total     0
Train Time (s)               617.4211919740774
(Previous) Eval Time (s)     2.3718103682622313
Sample Time (s)              6.7871438870206475
Epoch Time (s)               626.5801462293603
Total Train Time (s)         16769.250483348034
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:24:50.451736 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #26 | Epoch Duration: 626.709242105484
2020-01-13 12:24:50.452047 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.070423655
Z variance train             0.0813449
KL Divergence                4.652231
KL Loss                      0.46522313
QF Loss                      1289.3586
VF Loss                      579.4412
Policy Loss                  -851.6979
Q Predictions Mean           842.0922
Q Predictions Std            419.8952
Q Predictions Max            1441.2498
Q Predictions Min            36.571728
V Predictions Mean           841.0561
V Predictions Std            421.1822
V Predictions Max            1438.8893
V Predictions Min            39.50779
Log Pis Mean                 -2.834858
Log Pis Std                  5.324415
Log Pis Max                  24.150787
Log Pis Min                  -14.363508
Policy mu Mean               0.2588805
Policy mu Std                0.8325554
Policy mu Max                2.9642396
Policy mu Min                -3.150439
Policy log std Mean          -0.31730956
Policy log std Std           0.11608731
Policy log std Max           -0.051335387
Policy log std Min           -0.83448285
Z mean eval                  0.06738392
Z variance eval              0.051000226
total_rewards                [455.4200753  391.10331436 528.43925183 492.4791676  538.32684086
 532.69656189 534.27730584 560.21358373 347.87088427 358.08216278]
total_rewards_mean           473.89091484544076
total_rewards_std            76.49635948505745
total_rewards_max            560.2135837334621
total_rewards_min            347.8708842707505
Number of train steps total  112000
Number of env steps total    71932
Number of rollouts total     0
Train Time (s)               606.509810521733
(Previous) Eval Time (s)     2.3446211898699403
Sample Time (s)              6.30486993258819
Epoch Time (s)               615.1593016441911
Total Train Time (s)         17384.514378423803
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:35:05.713590 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #27 | Epoch Duration: 615.261322259903
2020-01-13 12:35:05.713727 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06731297
Z variance train             0.05093476
KL Divergence                5.2412786
KL Loss                      0.5241279
QF Loss                      1380.5405
VF Loss                      700.3502
Policy Loss                  -873.9782
Q Predictions Mean           860.1001
Q Predictions Std            434.68777
Q Predictions Max            1474.7375
Q Predictions Min            14.785358
V Predictions Mean           876.5842
V Predictions Std            434.95535
V Predictions Max            1478.8612
V Predictions Min            0.8796439
Log Pis Mean                 -2.4013958
Log Pis Std                  6.0466595
Log Pis Max                  24.71059
Log Pis Min                  -12.742112
Policy mu Mean               0.23275273
Policy mu Std                0.8681949
Policy mu Max                2.757377
Policy mu Min                -3.207464
Policy log std Mean          -0.31740472
Policy log std Std           0.11995541
Policy log std Max           0.030013457
Policy log std Min           -0.81191707
Z mean eval                  0.060190298
Z variance eval              0.14171836
total_rewards                [571.78590457 455.65198454 465.82493738 411.07861138 321.01096338
 427.75339962 527.51256822 528.78083281 512.17527309 472.59766551]
total_rewards_mean           469.41721405089737
total_rewards_std            68.25166101937667
total_rewards_max            571.7859045665298
total_rewards_min            321.0109633752697
Number of train steps total  116000
Number of env steps total    74841
Number of rollouts total     0
Train Time (s)               611.1676101847552
(Previous) Eval Time (s)     2.2628547409549356
Sample Time (s)              7.0403459328226745
Epoch Time (s)               620.4708108585328
Total Train Time (s)         18005.106573668774
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:45:26.306579 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #28 | Epoch Duration: 620.5927500724792
2020-01-13 12:45:26.306733 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06191771
Z variance train             0.14167456
KL Divergence                3.9860404
KL Loss                      0.39860404
QF Loss                      1382.77
VF Loss                      793.3561
Policy Loss                  -853.3927
Q Predictions Mean           841.15515
Q Predictions Std            468.417
Q Predictions Max            1498.874
Q Predictions Min            13.255581
V Predictions Mean           846.8412
V Predictions Std            467.8199
V Predictions Max            1482.9531
V Predictions Min            -5.844466
Log Pis Mean                 -1.8102661
Log Pis Std                  6.4245567
Log Pis Max                  29.935246
Log Pis Min                  -15.693123
Policy mu Mean               0.2886956
Policy mu Std                0.8496243
Policy mu Max                3.4637718
Policy mu Min                -2.989703
Policy log std Mean          -0.32865828
Policy log std Std           0.119504005
Policy log std Max           -0.021822184
Policy log std Min           -0.8985682
Z mean eval                  0.09403913
Z variance eval              0.19218169
total_rewards                [409.06816805 269.4964671  524.72832788 415.33701951 617.06467828
 734.05176156 463.39395139 425.08550593 483.24350487 508.44579296]
total_rewards_mean           484.9915177536406
total_rewards_std            119.46376168672461
total_rewards_max            734.0517615614359
total_rewards_min            269.4964671041627
Number of train steps total  120000
Number of env steps total    77858
Number of rollouts total     0
Train Time (s)               607.8083266238682
(Previous) Eval Time (s)     2.484282192774117
Sample Time (s)              7.43673289148137
Epoch Time (s)               617.7293417081237
Total Train Time (s)         18622.93221313879
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 12:55:44.133189 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #29 | Epoch Duration: 617.8263585567474
2020-01-13 12:55:44.133319 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09399406
Z variance train             0.19268312
KL Divergence                3.5768027
KL Loss                      0.3576803
QF Loss                      1346.8445
VF Loss                      636.35596
Policy Loss                  -847.4227
Q Predictions Mean           841.85767
Q Predictions Std            453.79742
Q Predictions Max            1493.2983
Q Predictions Min            -4.427484
V Predictions Mean           847.49475
V Predictions Std            449.3778
V Predictions Max            1489.0857
V Predictions Min            19.962395
Log Pis Mean                 -2.821162
Log Pis Std                  6.0225034
Log Pis Max                  27.485846
Log Pis Min                  -15.2020855
Policy mu Mean               0.2618389
Policy mu Std                0.8405374
Policy mu Max                3.0705476
Policy mu Min                -2.9674902
Policy log std Mean          -0.322696
Policy log std Std           0.11671467
Policy log std Max           0.038034365
Policy log std Min           -1.0393103
Z mean eval                  0.0886577
Z variance eval              0.14932445
total_rewards                [333.41642637 517.62541775 534.78507634 553.2842636  447.34635809
 499.66729544 445.20077073 421.5403276  299.03317015 511.08450776]
total_rewards_mean           456.2983613836965
total_rewards_std            80.90336822017059
total_rewards_max            553.2842636001735
total_rewards_min            299.0331701453251
Number of train steps total  124000
Number of env steps total    80685
Number of rollouts total     0
Train Time (s)               606.3360614147969
(Previous) Eval Time (s)     2.4545674389228225
Sample Time (s)              7.094578966964036
Epoch Time (s)               615.8852078206837
Total Train Time (s)         19238.91958815325
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:06:00.121265 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #30 | Epoch Duration: 615.9878516197205
2020-01-13 13:06:00.121395 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08512698
Z variance train             0.14961073
KL Divergence                3.0433538
KL Loss                      0.3043354
QF Loss                      1523.1149
VF Loss                      775.1148
Policy Loss                  -860.24835
Q Predictions Mean           859.70715
Q Predictions Std            449.62445
Q Predictions Max            1494.5829
Q Predictions Min            23.224909
V Predictions Mean           873.7372
V Predictions Std            447.12082
V Predictions Max            1501.3652
V Predictions Min            47.410816
Log Pis Mean                 -2.424923
Log Pis Std                  6.0639844
Log Pis Max                  30.893566
Log Pis Min                  -13.54823
Policy mu Mean               0.24601673
Policy mu Std                0.8477698
Policy mu Max                2.7925732
Policy mu Min                -2.8437762
Policy log std Mean          -0.32491168
Policy log std Std           0.123982124
Policy log std Max           -0.018819511
Policy log std Min           -0.9634791
Z mean eval                  0.10126662
Z variance eval              0.09654404
total_rewards                [620.73332303 374.62373114 424.4480372  447.41547338 524.73935764
 515.30639944 534.49584749 531.53525138 509.04212542 490.23320315]
total_rewards_mean           497.2572749262731
total_rewards_std            64.7314898673099
total_rewards_max            620.7333230270572
total_rewards_min            374.62373113700954
Number of train steps total  128000
Number of env steps total    83479
Number of rollouts total     0
Train Time (s)               614.769242094364
(Previous) Eval Time (s)     2.5641017141751945
Sample Time (s)              6.759815101046115
Epoch Time (s)               624.0931589095853
Total Train Time (s)         19863.113502623048
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-13 13:16:24.317250 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #31 | Epoch Duration: 624.1957433223724
2020-01-13 13:16:24.317427 UTC | [2020_01_10_09_29_40] [2020_01_11_08_20_36] [2020_01_12_07_53_38] [2020_01_13_07_45_21] Iteration #31 | Started Training: True
