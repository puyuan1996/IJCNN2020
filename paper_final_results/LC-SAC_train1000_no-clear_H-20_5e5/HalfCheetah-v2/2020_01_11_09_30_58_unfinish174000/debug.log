---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0015201619
Z variance train             0.69264114
KL Divergence                0.14971898
KL Loss                      0.014971899
QF Loss                      32.371784
VF Loss                      16.538906
Policy Loss                  -4.035804
Q Predictions Mean           0.0036291555
Q Predictions Std            0.002453938
Q Predictions Max            0.013234481
Q Predictions Min            -0.0022524772
V Predictions Mean           0.0029185028
V Predictions Std            0.0014939969
V Predictions Max            0.0071519334
V Predictions Min            -0.000653669
Log Pis Mean                 -4.064831
Log Pis Std                  0.5246426
Log Pis Max                  -2.2257078
Log Pis Min                  -5.3402777
Policy mu Mean               -0.0006778512
Policy mu Std                0.0014411181
Policy mu Max                0.0035296434
Policy mu Min                -0.0050696675
Policy log std Mean          0.000738925
Policy log std Std           0.0011386123
Policy log std Max           0.0049709105
Policy log std Min           -0.0033788155
Z mean eval                  0.07993744
Z variance eval              0.32485247
total_rewards                [-200.82907101 -202.76848645 -168.74245878 -232.31895182 -220.13140052
 -212.3383889  -226.08169056 -120.83841821 -218.3369065  -135.31654978]
total_rewards_mean           -193.77023225472038
total_rewards_std            36.96797392052177
total_rewards_max            -120.8384182108695
total_rewards_min            -232.3189518241989
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               31.282528204843402
(Previous) Eval Time (s)     0
Sample Time (s)              30.15089809242636
Epoch Time (s)               61.43342629726976
Total Train Time (s)         88.84280491713434
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:32:27.762176 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #0 | Epoch Duration: 88.84666299819946
2020-01-11 09:32:27.762379 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07835974
Z variance train             0.33578882
KL Divergence                1.1684575
KL Loss                      0.11684575
QF Loss                      14.789925
VF Loss                      3.5173538
Policy Loss                  -14.803765
Q Predictions Mean           10.779072
Q Predictions Std            6.6848345
Q Predictions Max            28.215405
Q Predictions Min            -6.1339226
V Predictions Mean           15.420614
V Predictions Std            6.321533
V Predictions Max            30.021038
V Predictions Min            -1.2740269
Log Pis Mean                 -3.2535362
Log Pis Std                  1.3246145
Log Pis Max                  0.6511984
Log Pis Min                  -6.5906816
Policy mu Mean               0.09648109
Policy mu Std                0.4450997
Policy mu Max                1.1736729
Policy mu Min                -1.3065996
Policy log std Mean          -0.18879552
Policy log std Std           0.077634394
Policy log std Max           -0.08752225
Policy log std Min           -0.43323752
Z mean eval                  0.22500324
Z variance eval              0.13169323
total_rewards                [-200.14584303 -242.15254698 -284.64994695 -242.56218723 -235.53361072
 -198.37059878 -235.11872719 -236.8546247  -214.17362031 -264.53065285]
total_rewards_mean           -235.4092358749761
total_rewards_std            25.372917462329237
total_rewards_max            -198.37059878300934
total_rewards_min            -284.64994694706746
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               30.879661465995014
(Previous) Eval Time (s)     27.412906241137534
Sample Time (s)              22.467444519046694
Epoch Time (s)               80.76001222617924
Total Train Time (s)         169.52885462203994
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:33:48.451266 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #1 | Epoch Duration: 80.68870210647583
2020-01-11 09:33:48.451571 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #1 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22587089
Z variance train             0.13049558
KL Divergence                3.1642394
KL Loss                      0.31642395
QF Loss                      34.187645
VF Loss                      5.099211
Policy Loss                  -28.973028
Q Predictions Mean           25.473892
Q Predictions Std            10.219346
Q Predictions Max            62.92463
Q Predictions Min            -3.5590649
V Predictions Mean           29.424427
V Predictions Std            9.8846
V Predictions Max            68.13687
V Predictions Min            5.0687485
Log Pis Mean                 -3.5062134
Log Pis Std                  1.0859234
Log Pis Max                  0.0016558766
Log Pis Min                  -7.534276
Policy mu Mean               0.020472305
Policy mu Std                0.37830496
Policy mu Max                1.3228645
Policy mu Min                -1.2648107
Policy log std Mean          -0.18281329
Policy log std Std           0.06932604
Policy log std Max           -0.05493781
Policy log std Min           -0.4418341
Z mean eval                  0.4366208
Z variance eval              0.08436639
total_rewards                [-264.47025993 -277.17459009 -254.08721252 -247.84073219 -242.9712891
 -263.57358716 -292.24720484 -241.42823686 -245.26586305 -245.56727435]
total_rewards_mean           -257.46262500927
total_rewards_std            15.957175147557543
total_rewards_max            -241.4282368622492
total_rewards_min            -292.2472048401007
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               31.203827689867467
(Previous) Eval Time (s)     27.341280607972294
Sample Time (s)              23.04788814811036
Epoch Time (s)               81.59299644595012
Total Train Time (s)         251.59368136012927
Epoch                        2
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:10.515292 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #2 | Epoch Duration: 82.0635118484497
2020-01-11 09:35:10.515471 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.43565378
Z variance train             0.084201396
KL Divergence                4.8077207
KL Loss                      0.48077208
QF Loss                      36.738667
VF Loss                      7.615075
Policy Loss                  -43.12816
Q Predictions Mean           39.194317
Q Predictions Std            13.250546
Q Predictions Max            85.675735
Q Predictions Min            -3.2411332
V Predictions Mean           43.626335
V Predictions Std            12.417139
V Predictions Max            79.00407
V Predictions Min            -0.5445509
Log Pis Mean                 -3.1287332
Log Pis Std                  1.5452608
Log Pis Max                  1.7656198
Log Pis Min                  -8.724302
Policy mu Mean               0.066637784
Policy mu Std                0.47198477
Policy mu Max                1.8134552
Policy mu Min                -1.3583819
Policy log std Mean          -0.20153923
Policy log std Std           0.09314299
Policy log std Max           7.034652e-05
Policy log std Min           -0.6536395
Z mean eval                  0.65564376
Z variance eval              0.0458109
total_rewards                [-161.97096196 -181.25996467 -160.20721111 -212.30009532 -203.11699627
 -179.74121454 -151.54230731 -171.16730712 -136.22365779 -218.70594424]
total_rewards_mean           -177.62356603179987
total_rewards_std            25.57742651214993
total_rewards_max            -136.22365778745254
total_rewards_min            -218.70594423686362
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               30.50432626903057
(Previous) Eval Time (s)     27.811487597879022
Sample Time (s)              21.65523344743997
Epoch Time (s)               79.97104731434956
Total Train Time (s)         331.9024976002984
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:36:30.825816 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #3 | Epoch Duration: 80.31020545959473
2020-01-11 09:36:30.826020 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6630057
Z variance train             0.044580724
KL Divergence                7.3903823
KL Loss                      0.7390382
QF Loss                      33.999825
VF Loss                      8.407857
Policy Loss                  -59.162487
Q Predictions Mean           55.42431
Q Predictions Std            15.97362
Q Predictions Max            110.08674
Q Predictions Min            -9.916785
V Predictions Mean           58.90364
V Predictions Std            15.103675
V Predictions Max            107.87996
V Predictions Min            0.15744306
Log Pis Mean                 -2.9543755
Log Pis Std                  1.7350848
Log Pis Max                  3.798399
Log Pis Min                  -7.824932
Policy mu Mean               0.018923905
Policy mu Std                0.51861316
Policy mu Max                1.8961312
Policy mu Min                -1.7239045
Policy log std Mean          -0.2119714
Policy log std Std           0.10100964
Policy log std Max           -0.06413683
Policy log std Min           -0.5824467
Z mean eval                  0.8020009
Z variance eval              0.050723605
total_rewards                [-153.02118313 -166.25615525 -224.9905118  -157.353563   -151.70931495
 -151.67136606 -145.34570543 -173.69564171 -183.47780554 -108.58247541]
total_rewards_mean           -161.61037222773217
total_rewards_std            28.333849668781042
total_rewards_max            -108.58247540695703
total_rewards_min            -224.99051180276723
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               30.629740813281387
(Previous) Eval Time (s)     28.150364140048623
Sample Time (s)              22.358004365116358
Epoch Time (s)               81.13810931844637
Total Train Time (s)         412.80799443414435
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:37:51.731560 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #4 | Epoch Duration: 80.9054012298584
2020-01-11 09:37:51.731743 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8057186
Z variance train             0.04912064
KL Divergence                8.044588
KL Loss                      0.8044588
QF Loss                      41.17598
VF Loss                      11.064675
Policy Loss                  -73.76578
Q Predictions Mean           69.34883
Q Predictions Std            17.089077
Q Predictions Max            119.19427
Q Predictions Min            9.302284
V Predictions Mean           71.62541
V Predictions Std            16.807451
V Predictions Max            118.83016
V Predictions Min            8.948689
Log Pis Mean                 -3.061572
Log Pis Std                  1.7076039
Log Pis Max                  3.2548497
Log Pis Min                  -7.445352
Policy mu Mean               -0.008753528
Policy mu Std                0.49865893
Policy mu Max                1.8039142
Policy mu Min                -1.9925624
Policy log std Mean          -0.20137449
Policy log std Std           0.103393145
Policy log std Max           -0.056216855
Policy log std Min           -0.6666055
Z mean eval                  0.901347
Z variance eval              0.051752865
total_rewards                [-158.12344484 -112.1703421  -189.88269211 -158.47393257 -193.03128145
 -177.54146635 -158.08879611 -139.09107738 -150.04927092 -189.59665954]
total_rewards_mean           -162.60489633579056
total_rewards_std            24.358223582763216
total_rewards_max            -112.17034209850152
total_rewards_min            -193.03128145128008
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               30.80589438881725
(Previous) Eval Time (s)     27.917344293091446
Sample Time (s)              23.297137051355094
Epoch Time (s)               82.02037573326379
Total Train Time (s)         495.4503342662938
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:39:14.374535 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #5 | Epoch Duration: 82.64265465736389
2020-01-11 09:39:14.374689 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9027621
Z variance train             0.051680595
KL Divergence                8.843341
KL Loss                      0.8843341
QF Loss                      33.450153
VF Loss                      6.4520445
Policy Loss                  -85.952385
Q Predictions Mean           81.73154
Q Predictions Std            19.306187
Q Predictions Max            164.27942
Q Predictions Min            19.26034
V Predictions Mean           85.901886
V Predictions Std            19.529678
V Predictions Max            167.90323
V Predictions Min            39.925488
Log Pis Mean                 -3.1801076
Log Pis Std                  1.6333816
Log Pis Max                  3.4466276
Log Pis Min                  -6.481405
Policy mu Mean               -0.012619029
Policy mu Std                0.46316916
Policy mu Max                1.8580676
Policy mu Min                -1.928293
Policy log std Mean          -0.20114447
Policy log std Std           0.09241416
Policy log std Max           0.0064579993
Policy log std Min           -0.696
Z mean eval                  0.9766189
Z variance eval              0.04702075
total_rewards                [-149.07605836 -145.53239557 -146.88562668 -148.95878947  -90.98746393
 -163.70930106 -128.32661636 -171.68806721 -118.97231745  -97.44061771]
total_rewards_mean           -136.15772537889487
total_rewards_std            25.399308748104495
total_rewards_max            -90.98746392741118
total_rewards_min            -171.6880672061502
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               31.502125311177224
(Previous) Eval Time (s)     28.539308989886194
Sample Time (s)              22.301208697259426
Epoch Time (s)               82.34264299832284
Total Train Time (s)         576.8459163047373
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:35.772669 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #6 | Epoch Duration: 81.39785718917847
2020-01-11 09:40:35.772861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97602445
Z variance train             0.04694254
KL Divergence                9.758129
KL Loss                      0.9758129
QF Loss                      57.943726
VF Loss                      18.13096
Policy Loss                  -98.24181
Q Predictions Mean           96.45314
Q Predictions Std            24.753475
Q Predictions Max            164.3506
Q Predictions Min            41.61074
V Predictions Mean           100.26493
V Predictions Std            24.65675
V Predictions Max            177.36543
V Predictions Min            53.839314
Log Pis Mean                 -3.0864115
Log Pis Std                  1.4867457
Log Pis Max                  2.2095249
Log Pis Min                  -7.0574064
Policy mu Mean               0.048770864
Policy mu Std                0.4794033
Policy mu Max                1.809677
Policy mu Min                -1.9506223
Policy log std Mean          -0.20490937
Policy log std Std           0.083888486
Policy log std Max           0.12673739
Policy log std Min           -0.6467075
Z mean eval                  1.0186815
Z variance eval              0.050217815
total_rewards                [ -44.41206089  -79.48092391  -70.81271431 -146.84353258 -114.38220065
  -84.89470599 -117.734346   -131.61554423 -144.30347488  -83.26479511]
total_rewards_mean           -101.77442985578094
total_rewards_std            32.431021986847945
total_rewards_max            -44.41206089256293
total_rewards_min            -146.8435325752307
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               31.23419266194105
(Previous) Eval Time (s)     27.594204633962363
Sample Time (s)              23.25204490032047
Epoch Time (s)               82.08044219622388
Total Train Time (s)         658.0619021113962
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:41:56.989240 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #7 | Epoch Duration: 81.21623992919922
2020-01-11 09:41:56.989439 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0185368
Z variance train             0.050598264
KL Divergence                10.043104
KL Loss                      1.0043105
QF Loss                      41.45702
VF Loss                      12.81398
Policy Loss                  -111.64321
Q Predictions Mean           106.722916
Q Predictions Std            27.16031
Q Predictions Max            193.7343
Q Predictions Min            70.06034
V Predictions Mean           109.72436
V Predictions Std            25.983679
V Predictions Max            195.03882
V Predictions Min            75.16518
Log Pis Mean                 -3.1263309
Log Pis Std                  1.5191318
Log Pis Max                  2.7373748
Log Pis Min                  -7.1388397
Policy mu Mean               -0.030586729
Policy mu Std                0.4794564
Policy mu Max                1.5562617
Policy mu Min                -2.002719
Policy log std Mean          -0.21957035
Policy log std Std           0.09361458
Policy log std Max           0.09777486
Policy log std Min           -0.72312665
Z mean eval                  1.0942835
Z variance eval              0.04344431
total_rewards                [-56.27239054   1.69540573   5.72586809 -61.7749005  -29.92085982
 -32.97786786   5.04803372 -28.97104048 -51.09173236   4.40024093]
total_rewards_mean           -24.413924308035945
total_rewards_std            25.564256140392047
total_rewards_max            5.725868093499321
total_rewards_min            -61.77490049563736
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               31.158348460216075
(Previous) Eval Time (s)     26.729710310697556
Sample Time (s)              22.90138601604849
Epoch Time (s)               80.78944478696212
Total Train Time (s)         740.0623128400184
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:18.990441 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #8 | Epoch Duration: 82.00086569786072
2020-01-11 09:43:18.990619 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.09183
Z variance train             0.043615095
KL Divergence                11.392872
KL Loss                      1.1392872
QF Loss                      32.58496
VF Loss                      17.83353
Policy Loss                  -122.612335
Q Predictions Mean           119.35448
Q Predictions Std            30.67128
Q Predictions Max            216.82132
Q Predictions Min            75.554535
V Predictions Mean           125.10418
V Predictions Std            31.594719
V Predictions Max            229.34958
V Predictions Min            84.95755
Log Pis Mean                 -3.2488508
Log Pis Std                  1.474577
Log Pis Max                  2.0143466
Log Pis Min                  -7.5491924
Policy mu Mean               -0.005070189
Policy mu Std                0.47742093
Policy mu Max                1.8484424
Policy mu Min                -1.8989244
Policy log std Mean          -0.21700753
Policy log std Std           0.08917145
Policy log std Max           0.03202007
Policy log std Min           -0.7190094
Z mean eval                  1.1381837
Z variance eval              0.04430213
total_rewards                [ 20.56950252  14.02535825  73.89255714  91.3083509   92.53113151
  82.08657403   4.39718752 149.59806207  73.19182402  66.12986567]
total_rewards_mean           66.77304136287702
total_rewards_std            41.545256201266014
total_rewards_max            149.59806206599572
total_rewards_min            4.397187516308273
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               30.566280148923397
(Previous) Eval Time (s)     27.9408347918652
Sample Time (s)              23.24390358151868
Epoch Time (s)               81.75101852230728
Total Train Time (s)         821.5306851188652
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:44:40.460055 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #9 | Epoch Duration: 81.46929216384888
2020-01-11 09:44:40.460260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.133028
Z variance train             0.044331484
KL Divergence                12.234659
KL Loss                      1.2234659
QF Loss                      35.513264
VF Loss                      19.547712
Policy Loss                  -128.97498
Q Predictions Mean           126.09135
Q Predictions Std            32.016544
Q Predictions Max            244.68954
Q Predictions Min            86.734436
V Predictions Mean           132.01956
V Predictions Std            32.9003
V Predictions Max            256.5565
V Predictions Min            95.96737
Log Pis Mean                 -3.0672739
Log Pis Std                  1.683093
Log Pis Max                  5.0131574
Log Pis Min                  -7.2425747
Policy mu Mean               -0.011444359
Policy mu Std                0.50485533
Policy mu Max                1.7981929
Policy mu Min                -2.1223986
Policy log std Mean          -0.22838606
Policy log std Std           0.09285361
Policy log std Max           0.020523667
Policy log std Min           -0.7683546
Z mean eval                  1.1322503
Z variance eval              0.039528586
total_rewards                [ 33.5665265  122.36252509 193.16586231 135.33365709 153.98854041
 171.82841966  57.1803142  101.56130533 131.69781382  78.15365863]
total_rewards_mean           117.88386230365184
total_rewards_std            47.99538561943817
total_rewards_max            193.16586230634329
total_rewards_min            33.56652649890937
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               31.3660002136603
(Previous) Eval Time (s)     27.65877843508497
Sample Time (s)              22.83519466686994
Epoch Time (s)               81.8599733156152
Total Train Time (s)         903.9868268193677
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:02.917538 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #10 | Epoch Duration: 82.45713329315186
2020-01-11 09:46:02.917726 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1347691
Z variance train             0.03951291
KL Divergence                12.276606
KL Loss                      1.2276605
QF Loss                      33.68023
VF Loss                      10.375688
Policy Loss                  -147.69983
Q Predictions Mean           142.5132
Q Predictions Std            39.87548
Q Predictions Max            279.19415
Q Predictions Min            98.349144
V Predictions Mean           146.49722
V Predictions Std            39.639725
V Predictions Max            283.80582
V Predictions Min            103.64554
Log Pis Mean                 -3.0778902
Log Pis Std                  1.5110328
Log Pis Max                  2.0815492
Log Pis Min                  -8.04791
Policy mu Mean               -0.020445859
Policy mu Std                0.47572753
Policy mu Max                1.6900885
Policy mu Min                -1.4956285
Policy log std Mean          -0.23273455
Policy log std Std           0.09489862
Policy log std Max           0.07173778
Policy log std Min           -0.7228459
Z mean eval                  1.1641713
Z variance eval              0.03627351
total_rewards                [109.88897122 105.43027799 230.13187946 255.41306564 141.23434957
 183.73054183 190.73140345 158.55002862 174.90547836 193.85448763]
total_rewards_mean           174.38704837737822
total_rewards_std            45.46574668063686
total_rewards_max            255.4130656408421
total_rewards_min            105.43027798734101
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               30.954024689737707
(Previous) Eval Time (s)     28.25562819512561
Sample Time (s)              23.060216513928026
Epoch Time (s)               82.26986939879134
Total Train Time (s)         985.7231395915151
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:47:24.655263 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #11 | Epoch Duration: 81.73738884925842
2020-01-11 09:47:24.655468 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1616275
Z variance train             0.036166646
KL Divergence                12.779986
KL Loss                      1.2779987
QF Loss                      43.357536
VF Loss                      8.479563
Policy Loss                  -156.5703
Q Predictions Mean           152.84154
Q Predictions Std            42.583286
Q Predictions Max            314.51566
Q Predictions Min            106.26481
V Predictions Mean           156.96124
V Predictions Std            42.01075
V Predictions Max            309.15826
V Predictions Min            110.86297
Log Pis Mean                 -2.970049
Log Pis Std                  1.5612094
Log Pis Max                  2.2961462
Log Pis Min                  -6.757117
Policy mu Mean               -0.058495235
Policy mu Std                0.48692524
Policy mu Max                1.6990263
Policy mu Min                -1.5769061
Policy log std Mean          -0.24607833
Policy log std Std           0.1010238
Policy log std Max           0.036857665
Policy log std Min           -0.7095067
Z mean eval                  1.1796161
Z variance eval              0.035937134
total_rewards                [313.04626655 270.02617913 217.76333964 390.89539388 198.41489171
 172.97877122 310.36162047 346.27241507 279.10284536 197.11646193]
total_rewards_mean           269.5978184967797
total_rewards_std            68.24565142332685
total_rewards_max            390.89539387911736
total_rewards_min            172.9787712181966
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               30.73579427599907
(Previous) Eval Time (s)     27.722824529279023
Sample Time (s)              23.074334785807878
Epoch Time (s)               81.53295359108597
Total Train Time (s)         1066.883723301813
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:48:45.816829 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #12 | Epoch Duration: 81.16121053695679
2020-01-11 09:48:45.817057 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1805618
Z variance train             0.035982534
KL Divergence                12.948805
KL Loss                      1.2948805
QF Loss                      33.65877
VF Loss                      10.2216835
Policy Loss                  -159.26308
Q Predictions Mean           155.32071
Q Predictions Std            41.23714
Q Predictions Max            319.36438
Q Predictions Min            111.01356
V Predictions Mean           158.66278
V Predictions Std            40.30182
V Predictions Max            317.04443
V Predictions Min            118.16551
Log Pis Mean                 -3.0218148
Log Pis Std                  1.5203948
Log Pis Max                  4.1830196
Log Pis Min                  -6.6819253
Policy mu Mean               0.045301702
Policy mu Std                0.48875883
Policy mu Max                1.8024282
Policy mu Min                -1.9853652
Policy log std Mean          -0.23462623
Policy log std Std           0.10225036
Policy log std Max           0.14872093
Policy log std Min           -0.71061534
Z mean eval                  1.1844629
Z variance eval              0.04272435
total_rewards                [513.91443674 445.07862697 418.89370057 276.35928426 397.46738212
 397.16801522 306.34192605 372.31540449 397.6663129  276.4861728 ]
total_rewards_mean           380.1691262136316
total_rewards_std            71.78701972184412
total_rewards_max            513.9144367449906
total_rewards_min            276.3592842630214
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               30.616104275919497
(Previous) Eval Time (s)     27.35073783993721
Sample Time (s)              22.226598078384995
Epoch Time (s)               80.1934401942417
Total Train Time (s)         1148.1272029485554
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:50:07.061324 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #13 | Epoch Duration: 81.24409055709839
2020-01-11 09:50:07.061515 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #13 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1838614
Z variance train             0.042702354
KL Divergence                13.127537
KL Loss                      1.3127537
QF Loss                      35.101772
VF Loss                      12.881174
Policy Loss                  -173.2161
Q Predictions Mean           169.15393
Q Predictions Std            48.646175
Q Predictions Max            355.24738
Q Predictions Min            115.96021
V Predictions Mean           172.30122
V Predictions Std            48.912655
V Predictions Max            347.97458
V Predictions Min            121.21125
Log Pis Mean                 -2.7489102
Log Pis Std                  1.5877421
Log Pis Max                  2.3705928
Log Pis Min                  -7.446942
Policy mu Mean               0.021554159
Policy mu Std                0.5356501
Policy mu Max                1.9423994
Policy mu Min                -1.6323805
Policy log std Mean          -0.25923833
Policy log std Std           0.12519392
Policy log std Max           0.11545859
Policy log std Min           -0.91879785
Z mean eval                  1.1798432
Z variance eval              0.033920567
total_rewards                [1080.10432338 1318.944368    350.92123176  419.75815047  840.20825756
  479.94070331 1275.34411813  405.07643646  664.64394018  794.60671968]
total_rewards_mean           762.9548248935638
total_rewards_std            344.18243748662786
total_rewards_max            1318.9443680042398
total_rewards_min            350.9212317618292
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               31.174784757662565
(Previous) Eval Time (s)     28.401082387194037
Sample Time (s)              22.178720062598586
Epoch Time (s)               81.75458720745519
Total Train Time (s)         1229.0617710277438
Epoch                        14
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:51:27.997070 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #14 | Epoch Duration: 80.93541383743286
2020-01-11 09:51:27.997258 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1786008
Z variance train             0.033883102
KL Divergence                13.491608
KL Loss                      1.3491608
QF Loss                      41.049576
VF Loss                      13.280671
Policy Loss                  -203.02661
Q Predictions Mean           199.25887
Q Predictions Std            65.033745
Q Predictions Max            376.96426
Q Predictions Min            127.3021
V Predictions Mean           201.32588
V Predictions Std            64.84946
V Predictions Max            374.60956
V Predictions Min            131.13881
Log Pis Mean                 -2.715607
Log Pis Std                  1.6946076
Log Pis Max                  4.4224405
Log Pis Min                  -6.8258114
Policy mu Mean               0.016896686
Policy mu Std                0.5880427
Policy mu Max                2.0395164
Policy mu Min                -2.0384872
Policy log std Mean          -0.27519205
Policy log std Std           0.1221252
Policy log std Max           0.049510993
Policy log std Min           -0.8148135
Z mean eval                  1.2357035
Z variance eval              0.03492287
total_rewards                [1821.02729056  701.50676868 1519.87409679 1234.50205444 1801.67373143
 1536.34244705 1137.5319286  1494.85745685 1822.82791939  624.70914657]
total_rewards_mean           1369.4852840358367
total_rewards_std            416.5672209385302
total_rewards_max            1822.8279193909525
total_rewards_min            624.7091465665416
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               31.072036435827613
(Previous) Eval Time (s)     27.581547719892114
Sample Time (s)              22.41868360200897
Epoch Time (s)               81.0722677577287
Total Train Time (s)         1308.8397087650374
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:47.776933 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #15 | Epoch Duration: 79.77953886985779
2020-01-11 09:52:47.777110 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2368205
Z variance train             0.03492842
KL Divergence                13.544209
KL Loss                      1.3544209
QF Loss                      43.87442
VF Loss                      15.074235
Policy Loss                  -205.66624
Q Predictions Mean           201.05676
Q Predictions Std            72.37625
Q Predictions Max            408.06833
Q Predictions Min            134.45547
V Predictions Mean           206.97675
V Predictions Std            73.79414
V Predictions Max            415.86432
V Predictions Min            139.20882
Log Pis Mean                 -2.408657
Log Pis Std                  2.077685
Log Pis Max                  5.4321384
Log Pis Min                  -7.7204423
Policy mu Mean               0.024089614
Policy mu Std                0.6172652
Policy mu Max                2.3932045
Policy mu Min                -1.7264677
Policy log std Mean          -0.27551207
Policy log std Std           0.13703531
Policy log std Max           0.10670206
Policy log std Min           -1.0834877
Z mean eval                  1.2656448
Z variance eval              0.031946324
total_rewards                [2055.93768758 1955.13873017 2029.61739805 2191.98630611  926.14471931
 2130.19329615 2123.3880868  2106.1428148  2109.62418764 1248.24340049]
total_rewards_mean           1887.6416627096278
total_rewards_std            411.14417831085075
total_rewards_max            2191.9863061120595
total_rewards_min            926.1447193084119
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               31.14617990097031
(Previous) Eval Time (s)     26.28848956199363
Sample Time (s)              22.552295421250165
Epoch Time (s)               79.9869648842141
Total Train Time (s)         1389.9355632211082
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:54:08.873401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #16 | Epoch Duration: 81.09614562988281
2020-01-11 09:54:08.873613 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2692006
Z variance train             0.03188368
KL Divergence                14.859533
KL Loss                      1.4859533
QF Loss                      44.182533
VF Loss                      20.94289
Policy Loss                  -235.49886
Q Predictions Mean           230.97327
Q Predictions Std            90.757835
Q Predictions Max            457.3693
Q Predictions Min            143.67831
V Predictions Mean           233.48508
V Predictions Std            88.46681
V Predictions Max            452.8161
V Predictions Min            146.75853
Log Pis Mean                 -1.9479457
Log Pis Std                  2.3873606
Log Pis Max                  5.521472
Log Pis Min                  -7.4464626
Policy mu Mean               0.0320873
Policy mu Std                0.6907971
Policy mu Max                2.0358553
Policy mu Min                -2.0057642
Policy log std Mean          -0.311577
Policy log std Std           0.16038263
Policy log std Max           -0.038918905
Policy log std Min           -1.0441618
Z mean eval                  1.3201697
Z variance eval              0.026469907
total_rewards                [2140.91034703 2172.5857636  2253.58421676 2185.12443549 2240.48129377
 2181.18646232 2167.10508605 2042.93949895  612.3757868  2342.97468337]
total_rewards_mean           2033.926757413198
total_rewards_std            479.6110530678901
total_rewards_max            2342.9746833714867
total_rewards_min            612.375786797576
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               31.007586885243654
(Previous) Eval Time (s)     27.39729680912569
Sample Time (s)              23.08671848429367
Epoch Time (s)               81.49160217866302
Total Train Time (s)         1472.7163184694946
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:55:31.654614 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #17 | Epoch Duration: 82.78083848953247
2020-01-11 09:55:31.654773 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3170698
Z variance train             0.02650646
KL Divergence                15.612611
KL Loss                      1.561261
QF Loss                      76.17983
VF Loss                      17.641594
Policy Loss                  -283.33002
Q Predictions Mean           279.27545
Q Predictions Std            116.150154
Q Predictions Max            510.45593
Q Predictions Min            151.87903
V Predictions Mean           284.24774
V Predictions Std            115.18494
V Predictions Max            515.0004
V Predictions Min            161.26428
Log Pis Mean                 -1.9163857
Log Pis Std                  2.3108473
Log Pis Max                  6.192054
Log Pis Min                  -6.736388
Policy mu Mean               -0.0199283
Policy mu Std                0.69060296
Policy mu Max                1.940068
Policy mu Min                -2.324714
Policy log std Mean          -0.33289167
Policy log std Std           0.16259013
Policy log std Max           -0.0580066
Policy log std Min           -1.0386759
Z mean eval                  1.3549879
Z variance eval              0.028707916
total_rewards                [ 881.28183339 2614.60223307 1025.92089835 2494.0007342  2393.80208523
 2610.69360139 2480.51524847  997.25732629 2631.61443176 2614.12455688]
total_rewards_mean           2074.381294901762
total_rewards_std            728.5127030549461
total_rewards_max            2631.614431759717
total_rewards_min            881.2818333911125
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               30.919151170179248
(Previous) Eval Time (s)     28.686214711982757
Sample Time (s)              22.387102692387998
Epoch Time (s)               81.99246857455
Total Train Time (s)         1554.1737942122854
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:56:53.113642 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #18 | Epoch Duration: 81.45872473716736
2020-01-11 09:56:53.113833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3551931
Z variance train             0.028780153
KL Divergence                15.7446995
KL Loss                      1.5744699
QF Loss                      69.863594
VF Loss                      28.553965
Policy Loss                  -289.918
Q Predictions Mean           285.71964
Q Predictions Std            120.274284
Q Predictions Max            557.13794
Q Predictions Min            160.3371
V Predictions Mean           291.44238
V Predictions Std            119.49723
V Predictions Max            564.1017
V Predictions Min            167.31177
Log Pis Mean                 -1.5050884
Log Pis Std                  2.4119902
Log Pis Max                  7.00255
Log Pis Min                  -6.3680797
Policy mu Mean               0.061992038
Policy mu Std                0.7387179
Policy mu Max                2.1461446
Policy mu Min                -2.1810036
Policy log std Mean          -0.33011582
Policy log std Std           0.16480318
Policy log std Max           -0.024815135
Policy log std Min           -1.0989262
Z mean eval                  1.3994142
Z variance eval              0.022932207
total_rewards                [2775.66955567 2773.10287566 1968.3092764  2920.4988994  2059.98008743
 2727.31423354 1220.15871892 2717.63646318 2735.11275622 2708.96805601]
total_rewards_mean           2460.675092242788
total_rewards_std            512.2717078391642
total_rewards_max            2920.498899395399
total_rewards_min            1220.1587189215456
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               31.250473340041935
(Previous) Eval Time (s)     28.152134232223034
Sample Time (s)              22.786119532305747
Epoch Time (s)               82.18872710457072
Total Train Time (s)         1636.1405198709108
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:58:15.084879 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #19 | Epoch Duration: 81.97090816497803
2020-01-11 09:58:15.085152 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3987851
Z variance train             0.02287886
KL Divergence                16.299252
KL Loss                      1.6299251
QF Loss                      75.50303
VF Loss                      30.106155
Policy Loss                  -308.59656
Q Predictions Mean           306.16443
Q Predictions Std            141.7257
Q Predictions Max            606.37006
Q Predictions Min            158.54907
V Predictions Mean           311.66693
V Predictions Std            140.27504
V Predictions Max            613.7364
V Predictions Min            166.7363
Log Pis Mean                 -1.4629819
Log Pis Std                  2.686466
Log Pis Max                  8.187489
Log Pis Min                  -9.898722
Policy mu Mean               0.068701655
Policy mu Std                0.76305723
Policy mu Max                2.1524034
Policy mu Min                -2.0959938
Policy log std Mean          -0.34218946
Policy log std Std           0.17343818
Policy log std Max           -0.039045908
Policy log std Min           -1.1252127
Z mean eval                  1.4300785
Z variance eval              0.030331725
total_rewards                [2790.06859174 2803.74423108 1176.69020632  725.52845988 2805.31894118
 2841.38621487 2700.32560025 2948.85036194 2755.94171939 2811.86998389]
total_rewards_mean           2435.972431053963
total_rewards_std            751.6271252667807
total_rewards_max            2948.8503619394724
total_rewards_min            725.5284598794142
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               32.64294188283384
(Previous) Eval Time (s)     27.93399286363274
Sample Time (s)              22.26885146368295
Epoch Time (s)               82.84578621014953
Total Train Time (s)         1719.5642258808948
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:59:38.506868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #20 | Epoch Duration: 83.42148447036743
2020-01-11 09:59:38.507107 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4298657
Z variance train             0.03043807
KL Divergence                15.579622
KL Loss                      1.5579623
QF Loss                      89.93002
VF Loss                      48.363453
Policy Loss                  -362.60373
Q Predictions Mean           358.3661
Q Predictions Std            156.83704
Q Predictions Max            669.961
Q Predictions Min            172.89629
V Predictions Mean           359.66238
V Predictions Std            153.92207
V Predictions Max            644.98694
V Predictions Min            179.02591
Log Pis Mean                 -1.269341
Log Pis Std                  2.7269034
Log Pis Max                  7.0305924
Log Pis Min                  -8.673935
Policy mu Mean               0.07143982
Policy mu Std                0.80241597
Policy mu Max                2.2005517
Policy mu Min                -2.4863932
Policy log std Mean          -0.37559056
Policy log std Std           0.17814064
Policy log std Max           -0.05009433
Policy log std Min           -1.0794735
Z mean eval                  1.4743454
Z variance eval              0.032330833
total_rewards                [2946.161615   3103.62101661 3009.21172601 2941.98683816 2945.60401413
 2873.05083868 3030.74439769 2931.79228848 2940.40434882 3090.60319312]
total_rewards_mean           2981.3180276704197
total_rewards_std            70.73133089782851
total_rewards_max            3103.6210166058113
total_rewards_min            2873.050838680747
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               33.13077902700752
(Previous) Eval Time (s)     28.509332423098385
Sample Time (s)              23.53684837091714
Epoch Time (s)               85.17695982102305
Total Train Time (s)         1805.2259539235383
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:01:04.170224 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #21 | Epoch Duration: 85.66290950775146
2020-01-11 10:01:04.170464 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4731365
Z variance train             0.03265255
KL Divergence                15.984253
KL Loss                      1.5984253
QF Loss                      72.32254
VF Loss                      48.85364
Policy Loss                  -371.4996
Q Predictions Mean           369.98425
Q Predictions Std            175.52034
Q Predictions Max            727.9038
Q Predictions Min            183.38359
V Predictions Mean           376.2398
V Predictions Std            176.53116
V Predictions Max            723.2956
V Predictions Min            189.74956
Log Pis Mean                 -1.2138946
Log Pis Std                  2.9987116
Log Pis Max                  8.656765
Log Pis Min                  -7.5642166
Policy mu Mean               0.085791595
Policy mu Std                0.7878126
Policy mu Max                2.7732449
Policy mu Min                -2.2590654
Policy log std Mean          -0.3838047
Policy log std Std           0.19350566
Policy log std Max           -0.07561052
Policy log std Min           -1.1758821
Z mean eval                  1.5196606
Z variance eval              0.026429653
total_rewards                [2927.40869478 3057.57765496 3147.15026365 3189.55025218 2806.54301728
 2104.50023151 1850.04292095 3017.68996436 3250.69188759 2932.6555651 ]
total_rewards_mean           2828.381045234907
total_rewards_std            447.3340898288127
total_rewards_max            3250.691887589831
total_rewards_min            1850.0429209526621
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               33.67555905133486
(Previous) Eval Time (s)     28.994902901817113
Sample Time (s)              23.040207132697105
Epoch Time (s)               85.71066908584908
Total Train Time (s)         1890.3942754934542
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:02:29.340285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #22 | Epoch Duration: 85.16963386535645
2020-01-11 10:02:29.340606 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5178933
Z variance train             0.02650084
KL Divergence                16.8987
KL Loss                      1.6898701
QF Loss                      139.18611
VF Loss                      30.888386
Policy Loss                  -445.29916
Q Predictions Mean           437.4017
Q Predictions Std            193.56242
Q Predictions Max            752.95544
Q Predictions Min            190.37123
V Predictions Mean           447.3595
V Predictions Std            194.86687
V Predictions Max            760.57416
V Predictions Min            196.65929
Log Pis Mean                 -0.8625451
Log Pis Std                  2.8413756
Log Pis Max                  6.8236313
Log Pis Min                  -7.6027412
Policy mu Mean               0.055795997
Policy mu Std                0.8558265
Policy mu Max                2.5082383
Policy mu Min                -2.2316067
Policy log std Mean          -0.4000986
Policy log std Std           0.18913463
Policy log std Max           -0.018077075
Policy log std Min           -1.1232285
Z mean eval                  1.5382296
Z variance eval              0.043498676
total_rewards                [3119.71499602 3259.79939536 3195.88615725 3197.57831615 3296.82222448
 3126.2025427  1761.09795542 3170.0976506  3334.47897664 3022.89900382]
total_rewards_mean           3048.457721844851
total_rewards_std            437.72103300965426
total_rewards_max            3334.478976639122
total_rewards_min            1761.0979554156593
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               32.47954228706658
(Previous) Eval Time (s)     28.45322960615158
Sample Time (s)              23.275572823826224
Epoch Time (s)               84.20834471704438
Total Train Time (s)         1974.9011042262428
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:03:53.847943 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #23 | Epoch Duration: 84.50712561607361
2020-01-11 10:03:53.848132 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #23 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.538862
Z variance train             0.043508217
KL Divergence                15.297827
KL Loss                      1.5297827
QF Loss                      107.296814
VF Loss                      42.32123
Policy Loss                  -470.53595
Q Predictions Mean           466.27853
Q Predictions Std            209.80774
Q Predictions Max            836.1322
Q Predictions Min            201.60175
V Predictions Mean           470.83176
V Predictions Std            208.58983
V Predictions Max            842.0093
V Predictions Min            204.3878
Log Pis Mean                 -0.60493946
Log Pis Std                  2.928569
Log Pis Max                  7.4657974
Log Pis Min                  -7.850007
Policy mu Mean               0.12478397
Policy mu Std                0.85901165
Policy mu Max                2.36241
Policy mu Min                -2.08647
Policy log std Mean          -0.41054782
Policy log std Std           0.19582534
Policy log std Max           -0.027548462
Policy log std Min           -1.2293991
Z mean eval                  1.6017148
Z variance eval              0.038147435
total_rewards                [3225.26231821 3175.84733054 3231.04830286 3230.20429382 3254.14164909
 3220.41640235 3272.39114732 3230.96672965 3331.72168981 3121.12072564]
total_rewards_mean           3229.3120589298273
total_rewards_std            52.56041509458865
total_rewards_max            3331.7216898097417
total_rewards_min            3121.120725642358
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               33.56406134273857
(Previous) Eval Time (s)     28.75166823901236
Sample Time (s)              22.968437008094043
Epoch Time (s)               85.28416658984497
Total Train Time (s)         2061.003243458923
Epoch                        24
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:05:19.952128 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #24 | Epoch Duration: 86.10382771492004
2020-01-11 10:05:19.952451 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6009958
Z variance train             0.03813895
KL Divergence                15.8843775
KL Loss                      1.5884378
QF Loss                      101.90107
VF Loss                      34.421326
Policy Loss                  -479.44955
Q Predictions Mean           476.30164
Q Predictions Std            230.4271
Q Predictions Max            878.4982
Q Predictions Min            204.78773
V Predictions Mean           481.58096
V Predictions Std            229.94565
V Predictions Max            870.4342
V Predictions Min            207.95317
Log Pis Mean                 -0.5105235
Log Pis Std                  3.0908217
Log Pis Max                  8.409803
Log Pis Min                  -7.072196
Policy mu Mean               0.06995011
Policy mu Std                0.873976
Policy mu Max                2.299274
Policy mu Min                -2.5432096
Policy log std Mean          -0.41862914
Policy log std Std           0.21255104
Policy log std Max           -0.041984946
Policy log std Min           -1.3219897
Z mean eval                  1.6756713
Z variance eval              0.026377996
total_rewards                [3256.80054167 3378.74960159 2228.34692517 3410.2457355  3551.80671901
 3316.79798904 3515.9079766  3587.12709579 3442.19820997 3461.87945687]
total_rewards_mean           3314.9860251222076
total_rewards_std            374.91180664099716
total_rewards_max            3587.127095788458
total_rewards_min            2228.3469251742454
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               32.52485264604911
(Previous) Eval Time (s)     29.570984139107168
Sample Time (s)              22.677499408833683
Epoch Time (s)               84.77333619398996
Total Train Time (s)         2143.6060259547085
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:42.555460 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #25 | Epoch Duration: 82.60279369354248
2020-01-11 10:06:42.555639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6768005
Z variance train             0.02645328
KL Divergence                17.421984
KL Loss                      1.7421983
QF Loss                      108.68051
VF Loss                      45.463932
Policy Loss                  -525.11115
Q Predictions Mean           518.7407
Q Predictions Std            244.03227
Q Predictions Max            901.0218
Q Predictions Min            211.43459
V Predictions Mean           522.2763
V Predictions Std            243.26256
V Predictions Max            888.92633
V Predictions Min            219.65639
Log Pis Mean                 -0.49691117
Log Pis Std                  3.1934493
Log Pis Max                  7.10886
Log Pis Min                  -8.308132
Policy mu Mean               0.11413791
Policy mu Std                0.9046226
Policy mu Max                2.4826894
Policy mu Min                -2.8455997
Policy log std Mean          -0.42471138
Policy log std Std           0.21628374
Policy log std Max           0.059777007
Policy log std Min           -1.4481275
Z mean eval                  1.7323917
Z variance eval              0.021093944
total_rewards                [ 587.88087872 3643.90123568 3693.46157817 3456.28085848 3391.99685875
 3496.84858481 3429.96975902 3524.44296196 3443.19442827 3301.43947399]
total_rewards_mean           3196.941661784772
total_rewards_std            876.4627763093397
total_rewards_max            3693.461578167049
total_rewards_min            587.8808787182994
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               32.815090311691165
(Previous) Eval Time (s)     27.40008606389165
Sample Time (s)              23.01055916491896
Epoch Time (s)               83.22573554050177
Total Train Time (s)         2229.0768666104414
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:08:08.027976 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #26 | Epoch Duration: 85.4721908569336
2020-01-11 10:08:08.028185 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7304657
Z variance train             0.021068295
KL Divergence                18.692509
KL Loss                      1.8692509
QF Loss                      128.73743
VF Loss                      38.20308
Policy Loss                  -552.62445
Q Predictions Mean           547.7346
Q Predictions Std            259.22888
Q Predictions Max            972.52313
Q Predictions Min            219.99603
V Predictions Mean           553.68915
V Predictions Std            258.22043
V Predictions Max            965.98114
V Predictions Min            224.93562
Log Pis Mean                 -0.41006547
Log Pis Std                  3.11503
Log Pis Max                  9.351208
Log Pis Min                  -6.5640807
Policy mu Mean               0.091566205
Policy mu Std                0.8975853
Policy mu Max                2.4113617
Policy mu Min                -2.46001
Policy log std Mean          -0.43226162
Policy log std Std           0.20771381
Policy log std Max           -0.022678092
Policy log std Min           -1.3974218
Z mean eval                  1.7464516
Z variance eval              0.022124996
total_rewards                [3624.6538856  3410.59195999 3483.08327611 3484.49044225 3530.76160805
 3599.57289556 3565.16843471 3539.12845504 3573.15175312 3535.60510094]
total_rewards_mean           3534.620781138131
total_rewards_std            59.43990831909798
total_rewards_max            3624.653885598101
total_rewards_min            3410.5919599897793
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               33.833372300025076
(Previous) Eval Time (s)     29.646165372803807
Sample Time (s)              23.93695364613086
Epoch Time (s)               87.41649131895974
Total Train Time (s)         2316.230979983695
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:35.183630 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #27 | Epoch Duration: 87.1552906036377
2020-01-11 10:09:35.183891 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7488823
Z variance train             0.022139642
KL Divergence                18.781567
KL Loss                      1.8781567
QF Loss                      147.2796
VF Loss                      36.620266
Policy Loss                  -591.0202
Q Predictions Mean           587.872
Q Predictions Std            272.9128
Q Predictions Max            980.7149
Q Predictions Min            229.08015
V Predictions Mean           587.86035
V Predictions Std            271.4249
V Predictions Max            979.1401
V Predictions Min            227.57732
Log Pis Mean                 -0.030872919
Log Pis Std                  3.5383313
Log Pis Max                  10.63592
Log Pis Min                  -9.051558
Policy mu Mean               0.071513735
Policy mu Std                0.96545476
Policy mu Max                2.4331594
Policy mu Min                -2.5206296
Policy log std Mean          -0.44340536
Policy log std Std           0.21780662
Policy log std Max           0.025141433
Policy log std Min           -1.4918679
Z mean eval                  1.8110771
Z variance eval              0.015109161
total_rewards                [3518.24394529 3538.41329594 3494.12662046 3418.02692999 3445.42847491
 3422.99634584 3492.53637054 3548.58153737 3461.06727053 3545.03311157]
total_rewards_mean           3488.445390241738
total_rewards_std            47.004933546974804
total_rewards_max            3548.5815373743685
total_rewards_min            3418.026929987102
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               32.71275597810745
(Previous) Eval Time (s)     29.38447932386771
Sample Time (s)              23.38550410233438
Epoch Time (s)               85.48273940430954
Total Train Time (s)         2401.1964098997414
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:11:00.152027 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #28 | Epoch Duration: 84.96794080734253
2020-01-11 10:11:00.152350 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8121979
Z variance train             0.015128637
KL Divergence                20.748886
KL Loss                      2.0748887
QF Loss                      146.43983
VF Loss                      109.70557
Policy Loss                  -642.3956
Q Predictions Mean           632.53784
Q Predictions Std            290.73505
Q Predictions Max            1076.512
Q Predictions Min            222.21414
V Predictions Mean           633.91174
V Predictions Std            286.59183
V Predictions Max            1065.6129
V Predictions Min            223.87663
Log Pis Mean                 -0.10686302
Log Pis Std                  3.2410183
Log Pis Max                  8.875432
Log Pis Min                  -7.308128
Policy mu Mean               0.04848659
Policy mu Std                0.9127369
Policy mu Max                2.3790493
Policy mu Min                -2.5961432
Policy log std Mean          -0.44376835
Policy log std Std           0.21413638
Policy log std Max           0.07748029
Policy log std Min           -1.3711109
Z mean eval                  1.8401861
Z variance eval              0.01794907
total_rewards                [3623.96936929 3594.50135236 3765.01054227 3725.2656945  3686.68142535
 3463.59744698 3617.79519233 1679.96880924 3572.86589905 3651.41115023]
total_rewards_mean           3438.106688159192
total_rewards_std            591.4190924377835
total_rewards_max            3765.0105422683528
total_rewards_min            1679.9688092438644
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               33.78640498733148
(Previous) Eval Time (s)     28.86929231416434
Sample Time (s)              23.54719650838524
Epoch Time (s)               86.20289380988106
Total Train Time (s)         2487.9705864698626
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:26.926712 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #29 | Epoch Duration: 86.77418065071106
2020-01-11 10:12:26.926928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8398006
Z variance train             0.017942
KL Divergence                20.81009
KL Loss                      2.081009
QF Loss                      120.728745
VF Loss                      41.64657
Policy Loss                  -647.42896
Q Predictions Mean           641.0531
Q Predictions Std            296.68732
Q Predictions Max            1067.5123
Q Predictions Min            231.43747
V Predictions Mean           645.25574
V Predictions Std            293.94064
V Predictions Max            1062.1227
V Predictions Min            241.50479
Log Pis Mean                 -0.12664983
Log Pis Std                  3.4233148
Log Pis Max                  10.379229
Log Pis Min                  -7.02652
Policy mu Mean               0.089868404
Policy mu Std                0.9293665
Policy mu Max                2.4633155
Policy mu Min                -2.6430335
Policy log std Mean          -0.44893527
Policy log std Std           0.21689178
Policy log std Max           -0.015713274
Policy log std Min           -1.3272274
Z mean eval                  1.8777685
Z variance eval              0.017170548
total_rewards                [3708.2668536  3517.87909508 3636.16037642 3679.19766056 3828.54193038
 3721.84528943 3723.65480674 3688.70256514 3800.28549023 3772.54141498]
total_rewards_mean           3707.707548255699
total_rewards_std            83.76001410774504
total_rewards_max            3828.5419303791045
total_rewards_min            3517.879095076308
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               31.22840493079275
(Previous) Eval Time (s)     29.440172566100955
Sample Time (s)              23.16971821244806
Epoch Time (s)               83.83829570934176
Total Train Time (s)         2570.2249971553683
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:13:49.182478 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #30 | Epoch Duration: 82.25540161132812
2020-01-11 10:13:49.182674 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8793666
Z variance train             0.017193278
KL Divergence                21.576355
KL Loss                      2.1576355
QF Loss                      137.11826
VF Loss                      33.997726
Policy Loss                  -691.6441
Q Predictions Mean           690.1566
Q Predictions Std            331.315
Q Predictions Max            1120.1852
Q Predictions Min            248.82622
V Predictions Mean           690.1187
V Predictions Std            327.3913
V Predictions Max            1117.6963
V Predictions Min            256.10886
Log Pis Mean                 -0.73449486
Log Pis Std                  3.063672
Log Pis Max                  9.348474
Log Pis Min                  -6.1808577
Policy mu Mean               0.097212255
Policy mu Std                0.8502805
Policy mu Max                2.4793155
Policy mu Min                -2.2739499
Policy log std Mean          -0.43777624
Policy log std Std           0.22781686
Policy log std Max           -0.0017333776
Policy log std Min           -1.5364562
Z mean eval                  1.9071783
Z variance eval              0.01624388
total_rewards                [3665.29945252 3886.91349322 3704.72907322 3729.9791925  3744.35345209
 3893.19202414 3760.491664   3852.91473361 3751.27407058 3839.98437297]
total_rewards_mean           3782.9131528848898
total_rewards_std            75.41431422906484
total_rewards_max            3893.1920241365174
total_rewards_min            3665.2994525151857
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               31.35969841014594
(Previous) Eval Time (s)     27.856947750784457
Sample Time (s)              22.845608113799244
Epoch Time (s)               82.06225427472964
Total Train Time (s)         2651.475520135835
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:10.434070 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #31 | Epoch Duration: 81.25126266479492
2020-01-11 10:15:10.434244 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.90476
Z variance train             0.016243717
KL Divergence                22.027493
KL Loss                      2.2027493
QF Loss                      328.57697
VF Loss                      65.946884
Policy Loss                  -727.00183
Q Predictions Mean           718.5487
Q Predictions Std            310.13074
Q Predictions Max            1116.3743
Q Predictions Min            236.84848
V Predictions Mean           730.88116
V Predictions Std            310.68066
V Predictions Max            1129.0526
V Predictions Min            245.04022
Log Pis Mean                 0.14851418
Log Pis Std                  3.4882627
Log Pis Max                  11.905404
Log Pis Min                  -9.163441
Policy mu Mean               0.071284175
Policy mu Std                0.9448283
Policy mu Max                2.659757
Policy mu Min                -2.6055253
Policy log std Mean          -0.48339257
Policy log std Std           0.24482764
Policy log std Max           -0.04086697
Policy log std Min           -1.7101657
Z mean eval                  1.9403751
Z variance eval              0.01496958
total_rewards                [3974.91709047 4007.68219731 3787.87073162 3766.40245606 3983.84932462
 3737.69876501 3808.59270405 3926.29901713 3962.1137315  4049.40519187]
total_rewards_mean           3900.483120964965
total_rewards_std            107.80831496267845
total_rewards_max            4049.4051918726245
total_rewards_min            3737.6987650090723
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               31.354226001072675
(Previous) Eval Time (s)     27.045585389714688
Sample Time (s)              22.745321285910904
Epoch Time (s)               81.14513267669827
Total Train Time (s)         2733.8255157768726
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:16:32.785548 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #32 | Epoch Duration: 82.3511643409729
2020-01-11 10:16:32.785739 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9409113
Z variance train             0.014993122
KL Divergence                22.889397
KL Loss                      2.2889397
QF Loss                      108.40101
VF Loss                      40.850517
Policy Loss                  -763.2809
Q Predictions Mean           758.7499
Q Predictions Std            335.92856
Q Predictions Max            1197.0276
Q Predictions Min            263.5823
V Predictions Mean           764.1343
V Predictions Std            336.28552
V Predictions Max            1200.9287
V Predictions Min            265.62228
Log Pis Mean                 0.21919185
Log Pis Std                  3.4577909
Log Pis Max                  15.36074
Log Pis Min                  -8.152205
Policy mu Mean               0.1522629
Policy mu Std                0.94765407
Policy mu Max                2.9142678
Policy mu Min                -2.411192
Policy log std Mean          -0.47828832
Policy log std Std           0.24390684
Policy log std Max           -0.050852835
Policy log std Min           -1.6868677
Z mean eval                  1.9485435
Z variance eval              0.021703295
total_rewards                [3752.04013712 3967.17709752 3834.03479214 3832.98832179 3798.80596356
 3847.5608693  3967.71351442 3958.24899573 3898.44745856 3614.9299917 ]
total_rewards_mean           3847.1947141840456
total_rewards_std            104.68923345356362
total_rewards_max            3967.713514417897
total_rewards_min            3614.929991703674
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               31.177020700648427
(Previous) Eval Time (s)     28.251252529211342
Sample Time (s)              22.593506139703095
Epoch Time (s)               82.02177936956286
Total Train Time (s)         2815.370868950151
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:54.332244 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #33 | Epoch Duration: 81.54636526107788
2020-01-11 10:17:54.332440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9478829
Z variance train             0.0216609
KL Divergence                21.522484
KL Loss                      2.1522484
QF Loss                      123.83351
VF Loss                      82.66338
Policy Loss                  -760.066
Q Predictions Mean           757.7439
Q Predictions Std            359.1161
Q Predictions Max            1251.12
Q Predictions Min            253.76935
V Predictions Mean           766.40735
V Predictions Std            356.84497
V Predictions Max            1260.9072
V Predictions Min            269.12213
Log Pis Mean                 0.007882997
Log Pis Std                  3.486558
Log Pis Max                  11.322649
Log Pis Min                  -9.627664
Policy mu Mean               0.07583495
Policy mu Std                0.9324827
Policy mu Max                2.4416218
Policy mu Min                -2.3711135
Policy log std Mean          -0.48182616
Policy log std Std           0.24553402
Policy log std Max           -0.044685513
Policy log std Min           -1.7263768
Z mean eval                  1.9752792
Z variance eval              0.018091237
total_rewards                [4111.87340473 4057.3067137  3997.31360685 3869.5127553  3945.82298633
 4054.71457358 4099.42160353 4160.31674355 4010.48175588 4027.59346127]
total_rewards_mean           4033.4357604706347
total_rewards_std            80.02535115338911
total_rewards_max            4160.316743554317
total_rewards_min            3869.512755298018
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               31.32300064060837
(Previous) Eval Time (s)     27.77557635633275
Sample Time (s)              20.873764706775546
Epoch Time (s)               79.97234170371667
Total Train Time (s)         2895.498157621827
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:19:14.469270 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #34 | Epoch Duration: 80.13666796684265
2020-01-11 10:19:14.469806 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #34 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9738508
Z variance train             0.018072994
KL Divergence                22.510391
KL Loss                      2.2510393
QF Loss                      180.54262
VF Loss                      78.8511
Policy Loss                  -833.8063
Q Predictions Mean           832.9532
Q Predictions Std            368.88608
Q Predictions Max            1279.563
Q Predictions Min            264.76996
V Predictions Mean           833.90735
V Predictions Std            368.4531
V Predictions Max            1279.9772
V Predictions Min            265.98312
Log Pis Mean                 0.47465172
Log Pis Std                  3.5525868
Log Pis Max                  10.971694
Log Pis Min                  -6.4417667
Policy mu Mean               0.021831928
Policy mu Std                0.9690475
Policy mu Max                2.7301314
Policy mu Min                -2.6212683
Policy log std Mean          -0.4811581
Policy log std Std           0.23689565
Policy log std Max           -0.038725376
Policy log std Min           -1.6664307
Z mean eval                  1.9792624
Z variance eval              0.019367019
total_rewards                [4036.96242894 4002.57641686 4105.59422135 4112.86660275 4058.9972871
 4213.21863698 4148.80280842 3971.43099708 3976.5590829  3973.71164173]
total_rewards_mean           4060.0720124106447
total_rewards_std            78.94129911683392
total_rewards_max            4213.21863698148
total_rewards_min            3971.4309970781296
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               30.748200244270265
(Previous) Eval Time (s)     27.93953431583941
Sample Time (s)              22.10673202201724
Epoch Time (s)               80.79446658212692
Total Train Time (s)         2976.2918414375745
Epoch                        35
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:20:35.256454 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #35 | Epoch Duration: 80.7862377166748
2020-01-11 10:20:35.256639 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9802281
Z variance train             0.019334689
KL Divergence                22.69873
KL Loss                      2.2698731
QF Loss                      176.94846
VF Loss                      64.42146
Policy Loss                  -848.0074
Q Predictions Mean           841.088
Q Predictions Std            382.28098
Q Predictions Max            1296.5256
Q Predictions Min            272.61603
V Predictions Mean           846.66406
V Predictions Std            380.4301
V Predictions Max            1298.0669
V Predictions Min            276.2732
Log Pis Mean                 -0.007447321
Log Pis Std                  3.3079772
Log Pis Max                  10.378077
Log Pis Min                  -6.1354537
Policy mu Mean               0.017157031
Policy mu Std                0.933511
Policy mu Max                2.4217062
Policy mu Min                -2.4967015
Policy log std Mean          -0.48188722
Policy log std Std           0.24573044
Policy log std Max           0.0011275262
Policy log std Min           -1.5996387
Z mean eval                  2.0062916
Z variance eval              0.017677048
total_rewards                [4024.29235209 3956.70523291 4106.39947703 4175.88926679 4216.64980534
 4118.75040051 4196.24436349 4205.66408173 3981.37906082 4080.08309547]
total_rewards_mean           4106.205713618532
total_rewards_std            89.74090711987198
total_rewards_max            4216.649805341771
total_rewards_min            3956.705232911302
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               31.259476360864937
(Previous) Eval Time (s)     27.931023311801255
Sample Time (s)              22.651144224684685
Epoch Time (s)               81.84164389735088
Total Train Time (s)         3057.277790784836
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:56.243144 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #36 | Epoch Duration: 80.98637223243713
2020-01-11 10:21:56.243361 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0046673
Z variance train             0.017643198
KL Divergence                23.185955
KL Loss                      2.3185956
QF Loss                      183.84326
VF Loss                      65.10809
Policy Loss                  -851.7425
Q Predictions Mean           845.90216
Q Predictions Std            389.0508
Q Predictions Max            1335.7449
Q Predictions Min            263.22018
V Predictions Mean           855.404
V Predictions Std            389.66666
V Predictions Max            1344.719
V Predictions Min            270.31503
Log Pis Mean                 -0.095661126
Log Pis Std                  3.4616923
Log Pis Max                  12.76536
Log Pis Min                  -6.856677
Policy mu Mean               0.07142859
Policy mu Std                0.9423389
Policy mu Max                2.501352
Policy mu Min                -2.30604
Policy log std Mean          -0.46090773
Policy log std Std           0.23270959
Policy log std Max           0.035345957
Policy log std Min           -1.3933423
Z mean eval                  2.013846
Z variance eval              0.017405102
total_rewards                [4177.7819984  4129.83696847 4146.91397364 4298.5115515  4215.03507575
 4103.30409745 4161.38258734 4302.24543809 4072.95941915 4078.14239225]
total_rewards_mean           4168.61135020351
total_rewards_std            77.84397227473646
total_rewards_max            4302.245438089036
total_rewards_min            4072.959419147781
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               31.85145627707243
(Previous) Eval Time (s)     27.075440646149218
Sample Time (s)              21.500817864201963
Epoch Time (s)               80.42771478742361
Total Train Time (s)         3138.736484156456
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:23:17.703430 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #37 | Epoch Duration: 81.45994806289673
2020-01-11 10:23:17.703615 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0126405
Z variance train             0.017392967
KL Divergence                23.351387
KL Loss                      2.3351388
QF Loss                      231.42125
VF Loss                      52.57604
Policy Loss                  -905.81976
Q Predictions Mean           900.40784
Q Predictions Std            407.25793
Q Predictions Max            1402.3134
Q Predictions Min            272.41724
V Predictions Mean           908.5509
V Predictions Std            405.0556
V Predictions Max            1423.9669
V Predictions Min            280.26617
Log Pis Mean                 0.46162832
Log Pis Std                  3.6594849
Log Pis Max                  11.790085
Log Pis Min                  -6.7382255
Policy mu Mean               0.04119908
Policy mu Std                0.9802458
Policy mu Max                2.478971
Policy mu Min                -2.3752806
Policy log std Mean          -0.4901866
Policy log std Std           0.252759
Policy log std Max           -0.035702378
Policy log std Min           -1.8814162
Z mean eval                  2.023473
Z variance eval              0.019995693
total_rewards                [4188.65671144 4415.9649545  4407.7754186  4441.66458094 4320.01388196
 4424.10194262 4465.0843004  4415.07479688 4471.89169425 4389.57801331]
total_rewards_mean           4393.980629489235
total_rewards_std            79.41905533543586
total_rewards_max            4471.891694251296
total_rewards_min            4188.656711437787
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               31.029344724025577
(Previous) Eval Time (s)     28.107383267953992
Sample Time (s)              22.79334571538493
Epoch Time (s)               81.9300737073645
Total Train Time (s)         3221.105213801842
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:40.074137 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #38 | Epoch Duration: 82.37037253379822
2020-01-11 10:24:40.074358 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0236516
Z variance train             0.01996401
KL Divergence                23.072716
KL Loss                      2.3072717
QF Loss                      167.72864
VF Loss                      102.06381
Policy Loss                  -937.0148
Q Predictions Mean           936.602
Q Predictions Std            407.29858
Q Predictions Max            1395.5293
Q Predictions Min            266.954
V Predictions Mean           938.0705
V Predictions Std            403.44547
V Predictions Max            1382.4348
V Predictions Min            275.17932
Log Pis Mean                 0.7910099
Log Pis Std                  3.6843047
Log Pis Max                  10.510146
Log Pis Min                  -7.5885653
Policy mu Mean               0.0563129
Policy mu Std                1.0156212
Policy mu Max                2.6234434
Policy mu Min                -2.5435517
Policy log std Mean          -0.4961364
Policy log std Std           0.26275483
Policy log std Max           -0.013640389
Policy log std Min           -1.6974229
Z mean eval                  2.0429032
Z variance eval              0.013954902
total_rewards                [4351.4290198  4361.12377422 4466.7724219  4398.65726286 4399.84422075
 4343.84568833 4393.32183941 4385.74107443 4284.24060191 4262.07009303]
total_rewards_mean           4364.704599664143
total_rewards_std            56.30217644457159
total_rewards_max            4466.772421895949
total_rewards_min            4262.070093033316
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               31.81956434296444
(Previous) Eval Time (s)     28.547343663405627
Sample Time (s)              21.99971121083945
Epoch Time (s)               82.36661921720952
Total Train Time (s)         3303.930345137138
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:26:02.900526 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #39 | Epoch Duration: 82.82601261138916
2020-01-11 10:26:02.900719 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #39 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0420988
Z variance train             0.013915581
KL Divergence                24.488659
KL Loss                      2.448866
QF Loss                      373.81067
VF Loss                      75.65582
Policy Loss                  -946.5494
Q Predictions Mean           939.4425
Q Predictions Std            425.78574
Q Predictions Max            1462.3452
Q Predictions Min            269.34604
V Predictions Mean           943.54083
V Predictions Std            422.20294
V Predictions Max            1470.1844
V Predictions Min            280.62677
Log Pis Mean                 0.3869719
Log Pis Std                  3.5401373
Log Pis Max                  10.419273
Log Pis Min                  -6.801856
Policy mu Mean               0.00092670694
Policy mu Std                0.9758509
Policy mu Max                2.5289237
Policy mu Min                -2.2757843
Policy log std Mean          -0.48688698
Policy log std Std           0.25407597
Policy log std Max           -0.045001
Policy log std Min           -1.5372269
Z mean eval                  2.035019
Z variance eval              0.015154158
total_rewards                [4304.1627912  4550.19694116 4425.91323538 4535.25125089 4462.165037
 4498.31488309 4295.70876727 4462.22241687 4480.61985208 4693.62930493]
total_rewards_mean           4470.818447985714
total_rewards_std            110.25066454161379
total_rewards_max            4693.6293049274755
total_rewards_min            4295.708767268059
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               31.738999634981155
(Previous) Eval Time (s)     29.00643179891631
Sample Time (s)              22.23379666497931
Epoch Time (s)               82.97922809887677
Total Train Time (s)         3386.074085570406
Epoch                        40
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:25.045377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #40 | Epoch Duration: 82.14451503753662
2020-01-11 10:27:25.045565 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0355237
Z variance train             0.01523519
KL Divergence                23.670883
KL Loss                      2.3670883
QF Loss                      223.66342
VF Loss                      65.56641
Policy Loss                  -984.54926
Q Predictions Mean           985.2811
Q Predictions Std            418.87955
Q Predictions Max            1511.8523
Q Predictions Min            261.6789
V Predictions Mean           988.3817
V Predictions Std            417.05368
V Predictions Max            1503.659
V Predictions Min            269.33276
Log Pis Mean                 0.4930182
Log Pis Std                  3.640217
Log Pis Max                  9.048473
Log Pis Min                  -8.764563
Policy mu Mean               0.05126953
Policy mu Std                1.0047516
Policy mu Max                2.7711482
Policy mu Min                -2.428476
Policy log std Mean          -0.50416213
Policy log std Std           0.26825914
Policy log std Max           -0.043543786
Policy log std Min           -1.8605369
Z mean eval                  1.9935888
Z variance eval              0.07588675
total_rewards                [4175.86776715 4380.40621634 4405.07400553 4419.47539358 4222.00287182
 4378.48111776 4373.57546051 4323.2441621  4434.78141015 4283.95297706]
total_rewards_mean           4339.686138199341
total_rewards_std            82.49788136243853
total_rewards_max            4434.781410153428
total_rewards_min            4175.867767150898
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               31.121267006266862
(Previous) Eval Time (s)     28.171402517240494
Sample Time (s)              23.047017930075526
Epoch Time (s)               82.33968745358288
Total Train Time (s)         3469.083707562182
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:48.056874 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #41 | Epoch Duration: 83.01115822792053
2020-01-11 10:28:48.057090 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.993887
Z variance train             0.07526262
KL Divergence                21.435652
KL Loss                      2.1435652
QF Loss                      184.67133
VF Loss                      74.748024
Policy Loss                  -964.0892
Q Predictions Mean           964.234
Q Predictions Std            432.24625
Q Predictions Max            1548.9978
Q Predictions Min            265.36325
V Predictions Mean           966.8187
V Predictions Std            432.0748
V Predictions Max            1554.5219
V Predictions Min            269.3691
Log Pis Mean                 0.17747094
Log Pis Std                  3.4141943
Log Pis Max                  10.897291
Log Pis Min                  -9.020287
Policy mu Mean               -0.010112348
Policy mu Std                0.9801398
Policy mu Max                2.3578756
Policy mu Min                -2.3249097
Policy log std Mean          -0.4769791
Policy log std Std           0.2529658
Policy log std Max           -0.055658385
Policy log std Min           -1.5748355
Z mean eval                  2.0230165
Z variance eval              0.044674855
total_rewards                [4648.63261138 4629.41398654 4589.25944983 4656.92718448 4579.48914545
 4597.71774049 4458.23036563 4550.23315279 4641.18291924 4662.85291203]
total_rewards_mean           4601.393946786975
total_rewards_std            59.34200867090498
total_rewards_max            4662.852912029577
total_rewards_min            4458.230365626417
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               31.421416639350355
(Previous) Eval Time (s)     28.84252368938178
Sample Time (s)              22.59837858332321
Epoch Time (s)               82.86231891205534
Total Train Time (s)         3550.5812860717997
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:30:09.557807 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #42 | Epoch Duration: 81.50052809715271
2020-01-11 10:30:09.558100 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0205379
Z variance train             0.044591166
KL Divergence                22.185968
KL Loss                      2.218597
QF Loss                      256.0641
VF Loss                      73.85019
Policy Loss                  -1057.3815
Q Predictions Mean           1051.379
Q Predictions Std            460.973
Q Predictions Max            1598.9381
Q Predictions Min            279.13824
V Predictions Mean           1057.5535
V Predictions Std            459.51157
V Predictions Max            1601.4326
V Predictions Min            286.20358
Log Pis Mean                 0.37084842
Log Pis Std                  3.6416245
Log Pis Max                  10.496767
Log Pis Min                  -7.481943
Policy mu Mean               0.06352362
Policy mu Std                1.0138581
Policy mu Max                3.1743298
Policy mu Min                -2.5674188
Policy log std Mean          -0.49380842
Policy log std Std           0.26857635
Policy log std Max           0.00443615
Policy log std Min           -1.6397294
Z mean eval                  2.0388005
Z variance eval              0.029388988
total_rewards                [4579.40108003 4635.32868659 4589.82300123 4473.87223172 4596.62214183
 4528.63401111 4431.42446427 4535.27879355 4568.64873041 4429.1730798 ]
total_rewards_mean           4536.820622056781
total_rewards_std            67.560104896262
total_rewards_max            4635.3286865919445
total_rewards_min            4429.173079804523
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               31.60208289604634
(Previous) Eval Time (s)     27.480404898058623
Sample Time (s)              22.25041037797928
Epoch Time (s)               81.33289817208424
Total Train Time (s)         3631.9321217220277
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:30.909015 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #43 | Epoch Duration: 81.35068655014038
2020-01-11 10:31:30.909247 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0401275
Z variance train             0.029361105
KL Divergence                22.984314
KL Loss                      2.2984314
QF Loss                      259.0703
VF Loss                      72.77893
Policy Loss                  -1103.6119
Q Predictions Mean           1096.6392
Q Predictions Std            444.48672
Q Predictions Max            1631.3965
Q Predictions Min            266.16794
V Predictions Mean           1099.6592
V Predictions Std            440.5605
V Predictions Max            1614.9246
V Predictions Min            271.0834
Log Pis Mean                 1.2116547
Log Pis Std                  3.8815448
Log Pis Max                  13.026007
Log Pis Min                  -5.7804437
Policy mu Mean               0.0572494
Policy mu Std                1.074131
Policy mu Max                2.4792116
Policy mu Min                -2.8657053
Policy log std Mean          -0.5115985
Policy log std Std           0.28123385
Policy log std Max           -0.027022704
Policy log std Min           -1.8635153
Z mean eval                  2.0653927
Z variance eval              0.021079166
total_rewards                [4760.21583577 4725.79256396 4849.97742806 4667.96369635 4807.28050003
 4624.01954468 5019.55272899 4571.47103889 4731.49151269 4720.36689579]
total_rewards_mean           4747.813174519113
total_rewards_std            119.27785287972603
total_rewards_max            5019.552728986684
total_rewards_min            4571.471038889534
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               31.140321366954595
(Previous) Eval Time (s)     27.49784696381539
Sample Time (s)              21.060775371734053
Epoch Time (s)               79.69894370250404
Total Train Time (s)         3712.3602463994175
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:32:51.338330 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #44 | Epoch Duration: 80.42892003059387
2020-01-11 10:32:51.338515 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0657783
Z variance train             0.021055453
KL Divergence                23.984676
KL Loss                      2.3984678
QF Loss                      201.30704
VF Loss                      77.72123
Policy Loss                  -1113.5012
Q Predictions Mean           1108.2661
Q Predictions Std            435.5848
Q Predictions Max            1625.7754
Q Predictions Min            267.67224
V Predictions Mean           1108.9104
V Predictions Std            430.73566
V Predictions Max            1617.376
V Predictions Min            269.94724
Log Pis Mean                 1.0020742
Log Pis Std                  3.6742427
Log Pis Max                  10.624571
Log Pis Min                  -6.990963
Policy mu Mean               0.08176132
Policy mu Std                1.0386329
Policy mu Max                2.6924875
Policy mu Min                -2.533888
Policy log std Mean          -0.5091723
Policy log std Std           0.26561403
Policy log std Max           0.032076538
Policy log std Min           -1.6706741
Z mean eval                  2.0710201
Z variance eval              0.017879738
total_rewards                [4587.26497838 4655.26861478 4628.47715599 4686.38639619 4897.09225552
 4829.34076359 4715.25055015 4716.67935509 4651.18232008 4708.05454579]
total_rewards_mean           4707.499693556814
total_rewards_std            88.30724057200281
total_rewards_max            4897.092255523622
total_rewards_min            4587.264978376738
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               31.355830643791705
(Previous) Eval Time (s)     28.22748169116676
Sample Time (s)              22.204573074821383
Epoch Time (s)               81.78788540977985
Total Train Time (s)         3793.924988921266
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:12.905971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #45 | Epoch Duration: 81.56729412078857
2020-01-11 10:34:12.906260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0703704
Z variance train             0.017906923
KL Divergence                24.410831
KL Loss                      2.4410832
QF Loss                      204.93094
VF Loss                      112.79609
Policy Loss                  -1124.469
Q Predictions Mean           1119.8071
Q Predictions Std            476.6844
Q Predictions Max            1672.9882
Q Predictions Min            279.53442
V Predictions Mean           1122.8269
V Predictions Std            474.74945
V Predictions Max            1673.1393
V Predictions Min            278.446
Log Pis Mean                 1.172645
Log Pis Std                  3.875973
Log Pis Max                  13.403608
Log Pis Min                  -7.0309086
Policy mu Mean               0.085123055
Policy mu Std                1.0561439
Policy mu Max                3.0788853
Policy mu Min                -2.8191946
Policy log std Mean          -0.5110636
Policy log std Std           0.27512676
Policy log std Max           -0.042955175
Policy log std Min           -1.7486303
Z mean eval                  2.072871
Z variance eval              0.015657576
total_rewards                [4949.59896733 4762.52721436 4905.89596348 4750.77963264 5009.43601909
 4931.87414516 4819.3113862  4821.42626426 4761.67849827 5010.34658505]
total_rewards_mean           4872.287467584832
total_rewards_std            96.41906173944491
total_rewards_max            5010.346585053749
total_rewards_min            4750.779632639114
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               31.542483313009143
(Previous) Eval Time (s)     28.006522127892822
Sample Time (s)              21.531737339217216
Epoch Time (s)               81.08074278011918
Total Train Time (s)         3874.5143678183667
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:35:33.496007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #46 | Epoch Duration: 80.58957552909851
2020-01-11 10:35:33.496191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0763588
Z variance train             0.015775451
KL Divergence                25.042408
KL Loss                      2.5042408
QF Loss                      207.28114
VF Loss                      203.66766
Policy Loss                  -1191.5206
Q Predictions Mean           1188.9609
Q Predictions Std            474.15118
Q Predictions Max            1684.2894
Q Predictions Min            260.7245
V Predictions Mean           1180.4968
V Predictions Std            466.57254
V Predictions Max            1661.7896
V Predictions Min            269.21957
Log Pis Mean                 0.60410345
Log Pis Std                  3.5007372
Log Pis Max                  11.96684
Log Pis Min                  -6.654749
Policy mu Mean               0.023665795
Policy mu Std                1.0116143
Policy mu Max                2.7916465
Policy mu Min                -2.7262201
Policy log std Mean          -0.4992796
Policy log std Std           0.27105367
Policy log std Max           -0.03634625
Policy log std Min           -1.837738
Z mean eval                  2.0676816
Z variance eval              0.015228677
total_rewards                [4891.72504992 4327.12215365 4879.68161515 4979.28072382 4838.77355613
 4799.34870944 4753.52267441 4961.5201512  4823.02113221 4976.08188804]
total_rewards_mean           4823.0077653978615
total_rewards_std            180.69632677247742
total_rewards_max            4979.2807238191035
total_rewards_min            4327.122153648742
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               31.24342101207003
(Previous) Eval Time (s)     27.51504789479077
Sample Time (s)              22.646737348288298
Epoch Time (s)               81.4052062551491
Total Train Time (s)         3956.264512630645
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:55.247734 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #47 | Epoch Duration: 81.75140523910522
2020-01-11 10:36:55.247916 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #47 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0650043
Z variance train             0.015227435
KL Divergence                25.131706
KL Loss                      2.5131707
QF Loss                      201.988
VF Loss                      112.093956
Policy Loss                  -1188.6703
Q Predictions Mean           1186.6465
Q Predictions Std            462.72107
Q Predictions Max            1783.1506
Q Predictions Min            259.26382
V Predictions Mean           1193.3657
V Predictions Std            460.66037
V Predictions Max            1764.6825
V Predictions Min            266.56958
Log Pis Mean                 1.1793385
Log Pis Std                  3.8176885
Log Pis Max                  10.959795
Log Pis Min                  -7.4058495
Policy mu Mean               0.06381178
Policy mu Std                1.0671451
Policy mu Max                2.6909554
Policy mu Min                -2.6402152
Policy log std Mean          -0.5204261
Policy log std Std           0.28479588
Policy log std Max           0.017204255
Policy log std Min           -1.9199024
Z mean eval                  2.075172
Z variance eval              0.013680605
total_rewards                [4893.11479347 5010.34609667 4911.61093698 4892.73422185 4996.41282983
 4944.84327372 4867.14475194 4871.53465599 4943.90295016 4992.48467265]
total_rewards_mean           4932.412918325712
total_rewards_std            50.57892798465066
total_rewards_max            5010.346096667866
total_rewards_min            4867.144751935819
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               31.284674047026783
(Previous) Eval Time (s)     27.860915489960462
Sample Time (s)              20.739544483833015
Epoch Time (s)               79.88513402082026
Total Train Time (s)         4035.782058820594
Epoch                        48
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:38:14.765088 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #48 | Epoch Duration: 79.51705527305603
2020-01-11 10:38:14.765226 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0760856
Z variance train             0.013659455
KL Divergence                25.725376
KL Loss                      2.5725377
QF Loss                      191.82202
VF Loss                      81.9395
Policy Loss                  -1248.7411
Q Predictions Mean           1242.9453
Q Predictions Std            467.1571
Q Predictions Max            1797.5553
Q Predictions Min            270.30853
V Predictions Mean           1247.0927
V Predictions Std            464.44995
V Predictions Max            1778.2529
V Predictions Min            265.51788
Log Pis Mean                 1.6347833
Log Pis Std                  4.0486765
Log Pis Max                  12.66481
Log Pis Min                  -5.379085
Policy mu Mean               0.03397544
Policy mu Std                1.1157937
Policy mu Max                2.914334
Policy mu Min                -3.1011784
Policy log std Mean          -0.54698527
Policy log std Std           0.2870548
Policy log std Max           -0.010382742
Policy log std Min           -1.8966838
Z mean eval                  2.0662074
Z variance eval              0.011545819
total_rewards                [4926.83051345 4959.10013017 4927.21492366 5036.41011351 4955.34977719
 4923.58395926 5082.70110378 5229.82621307 4932.22884861 4929.96911654]
total_rewards_mean           4990.321469924843
total_rewards_std            94.71170225018832
total_rewards_max            5229.826213071207
total_rewards_min            4923.58395926469
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               31.00441701244563
(Previous) Eval Time (s)     27.49252914870158
Sample Time (s)              22.51261919364333
Epoch Time (s)               81.00956535479054
Total Train Time (s)         4117.120109434705
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:36.105547 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #49 | Epoch Duration: 81.34021234512329
2020-01-11 10:39:36.105752 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0660713
Z variance train             0.0115471985
KL Divergence                25.974792
KL Loss                      2.5974793
QF Loss                      263.41345
VF Loss                      90.20712
Policy Loss                  -1277.8147
Q Predictions Mean           1275.1204
Q Predictions Std            478.67084
Q Predictions Max            1813.9114
Q Predictions Min            270.10657
V Predictions Mean           1279.8071
V Predictions Std            476.76434
V Predictions Max            1802.772
V Predictions Min            277.02762
Log Pis Mean                 1.6285872
Log Pis Std                  4.1001515
Log Pis Max                  13.679377
Log Pis Min                  -7.8622875
Policy mu Mean               0.013217506
Policy mu Std                1.1221533
Policy mu Max                2.6683939
Policy mu Min                -2.8402045
Policy log std Mean          -0.56321406
Policy log std Std           0.2884459
Policy log std Max           -0.01610884
Policy log std Min           -1.9041153
Z mean eval                  2.0404449
Z variance eval              0.01606578
total_rewards                [4950.46837622 5037.05865745 4981.8518377  5285.61645753 5130.00151828
 5098.23970586 5071.83729075 5190.41966077 4898.55697402 5088.68436996]
total_rewards_mean           5073.2734848534155
total_rewards_std            108.70606686614127
total_rewards_max            5285.616457526616
total_rewards_min            4898.556974019945
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               31.644688901957124
(Previous) Eval Time (s)     27.82284165127203
Sample Time (s)              22.867839088197798
Epoch Time (s)               82.33536964142695
Total Train Time (s)         4199.293257548939
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:40:58.280987 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #50 | Epoch Duration: 82.17509627342224
2020-01-11 10:40:58.281171 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0396523
Z variance train             0.016042575
KL Divergence                24.845804
KL Loss                      2.4845805
QF Loss                      238.59036
VF Loss                      111.83638
Policy Loss                  -1287.2949
Q Predictions Mean           1282.7407
Q Predictions Std            476.90744
Q Predictions Max            1771.8518
Q Predictions Min            258.39487
V Predictions Mean           1280.8806
V Predictions Std            474.05124
V Predictions Max            1771.6102
V Predictions Min            265.36697
Log Pis Mean                 1.2912883
Log Pis Std                  3.913008
Log Pis Max                  12.745909
Log Pis Min                  -6.6440773
Policy mu Mean               0.016449139
Policy mu Std                1.0871814
Policy mu Max                3.0007837
Policy mu Min                -2.4288247
Policy log std Mean          -0.5526409
Policy log std Std           0.3004458
Policy log std Max           -0.012514636
Policy log std Min           -1.922509
Z mean eval                  2.0406127
Z variance eval              0.014806658
total_rewards                [5105.21705717 5073.49016231 5160.87880212 5016.41411928 5192.99461186
 5134.2607817  5166.64871372 4972.07921864 5127.32431611 5050.74482161]
total_rewards_mean           5100.00526045127
total_rewards_std            67.24811082696866
total_rewards_max            5192.994611859931
total_rewards_min            4972.079218638237
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               31.322198836132884
(Previous) Eval Time (s)     27.662229637615383
Sample Time (s)              22.475300974678248
Epoch Time (s)               81.45972944842651
Total Train Time (s)         4280.918583967723
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:19.908441 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #51 | Epoch Duration: 81.62712335586548
2020-01-11 10:42:19.908674 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0411544
Z variance train             0.014802593
KL Divergence                25.315384
KL Loss                      2.5315385
QF Loss                      261.18912
VF Loss                      120.93497
Policy Loss                  -1292.7474
Q Predictions Mean           1285.0791
Q Predictions Std            515.24615
Q Predictions Max            1907.0498
Q Predictions Min            270.95032
V Predictions Mean           1286.9615
V Predictions Std            511.87936
V Predictions Max            1894.976
V Predictions Min            275.60632
Log Pis Mean                 1.3329716
Log Pis Std                  4.1445737
Log Pis Max                  12.797676
Log Pis Min                  -7.859056
Policy mu Mean               0.001841087
Policy mu Std                1.0941694
Policy mu Max                2.7276564
Policy mu Min                -2.9146543
Policy log std Mean          -0.5373023
Policy log std Std           0.29684287
Policy log std Max           0.07881293
Policy log std Min           -1.9939736
Z mean eval                  2.0344698
Z variance eval              0.01780422
total_rewards                [5030.01659313 5325.06958331 5228.13118635 5436.11467827 5147.10392081
 5068.54602961 5129.93423741 5172.88467733 5021.26101477 5119.96132754]
total_rewards_mean           5167.9023248518515
total_rewards_std            124.4395692633454
total_rewards_max            5436.114678266391
total_rewards_min            5021.2610147694
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               31.747415489982814
(Previous) Eval Time (s)     27.829238282050937
Sample Time (s)              20.581413054373115
Epoch Time (s)               80.15806682640687
Total Train Time (s)         4361.340093057137
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:43:40.329691 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #52 | Epoch Duration: 80.42085266113281
2020-01-11 10:43:40.329856 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0347552
Z variance train             0.0178316
KL Divergence                24.965954
KL Loss                      2.4965954
QF Loss                      382.361
VF Loss                      121.0157
Policy Loss                  -1307.4385
Q Predictions Mean           1308.0325
Q Predictions Std            545.37
Q Predictions Max            1899.9353
Q Predictions Min            272.74936
V Predictions Mean           1312.2448
V Predictions Std            543.90265
V Predictions Max            1886.9008
V Predictions Min            273.7721
Log Pis Mean                 1.3385425
Log Pis Std                  4.156401
Log Pis Max                  13.804295
Log Pis Min                  -6.5577583
Policy mu Mean               0.002426366
Policy mu Std                1.0902941
Policy mu Max                2.8783932
Policy mu Min                -3.0471666
Policy log std Mean          -0.5329924
Policy log std Std           0.29352486
Policy log std Max           0.0009998083
Policy log std Min           -2.1698294
Z mean eval                  2.0071363
Z variance eval              0.034767695
total_rewards                [5032.86453133 5094.1245739  5240.2989436  4875.87593843 5048.13654648
 5065.41262274 4935.31949792 5007.58738189 5284.33086265 5121.31623473]
total_rewards_mean           5070.526713366178
total_rewards_std            118.2152473661397
total_rewards_max            5284.330862645135
total_rewards_min            4875.875938431835
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               31.317281652241945
(Previous) Eval Time (s)     28.091733722016215
Sample Time (s)              22.19188640639186
Epoch Time (s)               81.60090178065002
Total Train Time (s)         4441.725893240422
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:45:00.717209 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #53 | Epoch Duration: 80.38721990585327
2020-01-11 10:45:00.717393 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0069218
Z variance train             0.034664042
KL Divergence                24.00577
KL Loss                      2.400577
QF Loss                      218.45148
VF Loss                      186.49527
Policy Loss                  -1346.9608
Q Predictions Mean           1347.7358
Q Predictions Std            534.7764
Q Predictions Max            1897.229
Q Predictions Min            261.7562
V Predictions Mean           1357.352
V Predictions Std            534.7135
V Predictions Max            1904.5417
V Predictions Min            270.70688
Log Pis Mean                 1.3796117
Log Pis Std                  3.965239
Log Pis Max                  12.558211
Log Pis Min                  -6.4389715
Policy mu Mean               -0.0325509
Policy mu Std                1.0983862
Policy mu Max                3.0105762
Policy mu Min                -2.7394373
Policy log std Mean          -0.54474133
Policy log std Std           0.30255046
Policy log std Max           0.028759003
Policy log std Min           -1.9557035
Z mean eval                  2.0049224
Z variance eval              0.034230836
total_rewards                [4898.40120382 5078.73231125 5041.34588493 5068.91629349 5101.52681303
 5076.74681937 5182.76349376 5184.48020603 4973.80141735 5008.7331068 ]
total_rewards_mean           5061.544754982662
total_rewards_std            83.36564236950754
total_rewards_max            5184.480206034946
total_rewards_min            4898.401203816653
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               31.543838298879564
(Previous) Eval Time (s)     26.877722769975662
Sample Time (s)              22.609442011918873
Epoch Time (s)               81.0310030807741
Total Train Time (s)         4525.156349443831
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:46:24.149257 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #54 | Epoch Duration: 83.4317262172699
2020-01-11 10:46:24.149448 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.004387
Z variance train             0.03435813
KL Divergence                24.224218
KL Loss                      2.422422
QF Loss                      213.10257
VF Loss                      97.846504
Policy Loss                  -1366.5072
Q Predictions Mean           1362.8536
Q Predictions Std            539.83307
Q Predictions Max            1921.3357
Q Predictions Min            266.73407
V Predictions Mean           1365.8851
V Predictions Std            535.81793
V Predictions Max            1914.1335
V Predictions Min            267.93124
Log Pis Mean                 1.3634953
Log Pis Std                  4.1130123
Log Pis Max                  12.610235
Log Pis Min                  -7.104994
Policy mu Mean               -0.023150042
Policy mu Std                1.0894113
Policy mu Max                2.496416
Policy mu Min                -2.6550415
Policy log std Mean          -0.5402175
Policy log std Std           0.30552065
Policy log std Max           -0.044600368
Policy log std Min           -2.1116223
Z mean eval                  2.0121858
Z variance eval              0.015406938
total_rewards                [5010.12849576 5040.45951704 5177.45293303 5167.65215622 5298.10046962
 5192.57958523 5092.32201194 5197.93823459 5128.99911329 4979.30819666]
total_rewards_mean           5128.494071338489
total_rewards_std            93.24789079232444
total_rewards_max            5298.10046962108
total_rewards_min            4979.308196663509
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               31.58744387002662
(Previous) Eval Time (s)     29.27814471302554
Sample Time (s)              21.90343284374103
Epoch Time (s)               82.76902142679319
Total Train Time (s)         4607.381397745572
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:46.375872 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #55 | Epoch Duration: 82.22626805305481
2020-01-11 10:47:46.376067 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.011755
Z variance train             0.015390444
KL Divergence                26.027256
KL Loss                      2.6027257
QF Loss                      450.10468
VF Loss                      151.62494
Policy Loss                  -1349.5355
Q Predictions Mean           1343.7957
Q Predictions Std            563.96387
Q Predictions Max            1926.0446
Q Predictions Min            259.61063
V Predictions Mean           1341.894
V Predictions Std            560.05615
V Predictions Max            1923.7134
V Predictions Min            254.48138
Log Pis Mean                 1.5490551
Log Pis Std                  4.3614893
Log Pis Max                  13.278366
Log Pis Min                  -7.9514875
Policy mu Mean               0.017815627
Policy mu Std                1.1225011
Policy mu Max                3.0243137
Policy mu Min                -2.854451
Policy log std Mean          -0.5405118
Policy log std Std           0.30331966
Policy log std Max           0.020679712
Policy log std Min           -2.1498404
Z mean eval                  2.01327
Z variance eval              0.013254347
total_rewards                [5400.50010304 5321.66965982 5050.14090435 5382.70592167 5288.79231793
 5426.97674235 5217.26021693 5104.44317521 5435.60377268 5247.11013115]
total_rewards_mean           5287.520294513384
total_rewards_std            126.80891986993436
total_rewards_max            5435.603772678169
total_rewards_min            5050.1409043499825
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               31.54009644081816
(Previous) Eval Time (s)     28.73512487532571
Sample Time (s)              21.59174938686192
Epoch Time (s)               81.86697070300579
Total Train Time (s)         4688.4212221177295
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:49:07.416750 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #56 | Epoch Duration: 81.04054355621338
2020-01-11 10:49:07.416928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.013412
Z variance train             0.013257189
KL Divergence                26.304714
KL Loss                      2.6304715
QF Loss                      186.75409
VF Loss                      104.31715
Policy Loss                  -1452.2537
Q Predictions Mean           1448.1792
Q Predictions Std            521.4464
Q Predictions Max            1997.1183
Q Predictions Min            265.12915
V Predictions Mean           1448.9573
V Predictions Std            519.81
V Predictions Max            1996.0529
V Predictions Min            261.02188
Log Pis Mean                 1.8268006
Log Pis Std                  4.193028
Log Pis Max                  13.182152
Log Pis Min                  -7.1729927
Policy mu Mean               0.013410619
Policy mu Std                1.123053
Policy mu Max                3.6184366
Policy mu Min                -2.6133795
Policy log std Mean          -0.56616914
Policy log std Std           0.319007
Policy log std Max           -0.02939248
Policy log std Min           -2.0276005
Z mean eval                  2.0241408
Z variance eval              0.012960577
total_rewards                [5282.15457277 5507.87620614 5364.9493047  5364.59054877 5404.48443469
 5598.961664   5303.06108524 5457.21272559 5372.8705233  5350.54944757]
total_rewards_mean           5400.671051274322
total_rewards_std            91.35664543505837
total_rewards_max            5598.9616639961805
total_rewards_min            5282.154572767092
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               31.612659459002316
(Previous) Eval Time (s)     27.908404592890292
Sample Time (s)              22.80804098211229
Epoch Time (s)               82.3291050340049
Total Train Time (s)         4769.271528150886
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:28.269435 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #57 | Epoch Duration: 80.85235333442688
2020-01-11 10:50:28.269641 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0236485
Z variance train             0.012966692
KL Divergence                26.627434
KL Loss                      2.6627433
QF Loss                      334.8048
VF Loss                      109.00946
Policy Loss                  -1461.8983
Q Predictions Mean           1456.3042
Q Predictions Std            527.4136
Q Predictions Max            2030.7473
Q Predictions Min            265.9786
V Predictions Mean           1459.749
V Predictions Std            524.68195
V Predictions Max            2026.1891
V Predictions Min            267.5097
Log Pis Mean                 2.099419
Log Pis Std                  4.135749
Log Pis Max                  12.546692
Log Pis Min                  -6.661998
Policy mu Mean               -0.04303831
Policy mu Std                1.1685997
Policy mu Max                2.973418
Policy mu Min                -2.7680788
Policy log std Mean          -0.5594494
Policy log std Std           0.30243412
Policy log std Max           -0.06474964
Policy log std Min           -2.040035
Z mean eval                  2.0247533
Z variance eval              0.01942766
total_rewards                [5394.61946297 5216.07761413 5432.47950546 5124.38710234 5359.46815593
 5577.67401839 5227.12468826 5489.88888804 5503.94964236 5374.42398628]
total_rewards_mean           5370.009306415826
total_rewards_std            135.83659236021455
total_rewards_max            5577.674018386609
total_rewards_min            5124.3871023395
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               31.638057584874332
(Previous) Eval Time (s)     26.43130757380277
Sample Time (s)              22.740424748510122
Epoch Time (s)               80.80978990718722
Total Train Time (s)         4851.194862604607
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:51:50.193889 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #58 | Epoch Duration: 81.92411684989929
2020-01-11 10:51:50.194081 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.023825
Z variance train             0.019533407
KL Divergence                26.00922
KL Loss                      2.600922
QF Loss                      174.98682
VF Loss                      77.321365
Policy Loss                  -1447.1724
Q Predictions Mean           1444.693
Q Predictions Std            606.5482
Q Predictions Max            2055.7827
Q Predictions Min            256.9505
V Predictions Mean           1447.4823
V Predictions Std            607.18384
V Predictions Max            2050.2485
V Predictions Min            258.51175
Log Pis Mean                 1.0951242
Log Pis Std                  4.045174
Log Pis Max                  12.963133
Log Pis Min                  -8.69061
Policy mu Mean               0.021376481
Policy mu Std                1.0692366
Policy mu Max                2.9663901
Policy mu Min                -2.6079614
Policy log std Mean          -0.52501667
Policy log std Std           0.31286258
Policy log std Max           -0.02417034
Policy log std Min           -2.0927596
Z mean eval                  2.0134416
Z variance eval              0.029431995
total_rewards                [5373.31673397 5378.48335603 5300.36514387 5302.94410958 5742.83841852
 5207.93072695 5423.79489722 5153.70838257 5517.58346097 5394.00218468]
total_rewards_mean           5379.496741436111
total_rewards_std            156.79109217584238
total_rewards_max            5742.838418524939
total_rewards_min            5153.708382573983
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               30.51310090208426
(Previous) Eval Time (s)     27.545318874996156
Sample Time (s)              21.9799940045923
Epoch Time (s)               80.03841378167272
Total Train Time (s)         4932.688118043356
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:11.688861 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #59 | Epoch Duration: 81.49463558197021
2020-01-11 10:53:11.689054 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0132232
Z variance train             0.029720504
KL Divergence                25.07177
KL Loss                      2.507177
QF Loss                      444.69482
VF Loss                      198.72275
Policy Loss                  -1347.4083
Q Predictions Mean           1350.2262
Q Predictions Std            623.8859
Q Predictions Max            2013.3926
Q Predictions Min            257.5933
V Predictions Mean           1355.5858
V Predictions Std            626.3804
V Predictions Max            2027.051
V Predictions Min            253.84709
Log Pis Mean                 1.2123965
Log Pis Std                  4.3447614
Log Pis Max                  13.460878
Log Pis Min                  -7.5068817
Policy mu Mean               0.03332339
Policy mu Std                1.0693278
Policy mu Max                2.6895792
Policy mu Min                -2.6253655
Policy log std Mean          -0.53502965
Policy log std Std           0.32185394
Policy log std Max           0.011178106
Policy log std Min           -2.119517
Z mean eval                  2.0093799
Z variance eval              0.025849689
total_rewards                [5118.98416714 5219.7689264  5338.98221686 5216.29489641 5514.20308594
 5239.07578609 5499.96736649 5309.64430765 5289.34136087 5324.0732402 ]
total_rewards_mean           5307.033535405951
total_rewards_std            117.3043127906101
total_rewards_max            5514.20308594005
total_rewards_min            5118.9841671448385
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               31.930295537225902
(Previous) Eval Time (s)     29.001213295850903
Sample Time (s)              21.979140787851065
Epoch Time (s)               82.91064962092787
Total Train Time (s)         5014.703381260391
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:54:33.707058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #60 | Epoch Duration: 82.01784086227417
2020-01-11 10:54:33.707377 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.008575
Z variance train             0.025867725
KL Divergence                25.040833
KL Loss                      2.5040834
QF Loss                      307.7169
VF Loss                      127.49503
Policy Loss                  -1450.769
Q Predictions Mean           1444.117
Q Predictions Std            579.5972
Q Predictions Max            2079.2097
Q Predictions Min            224.80968
V Predictions Mean           1450.2307
V Predictions Std            573.2246
V Predictions Max            2063.3933
V Predictions Min            237.03133
Log Pis Mean                 1.7236204
Log Pis Std                  4.2640586
Log Pis Max                  14.762294
Log Pis Min                  -8.528137
Policy mu Mean               -0.018282406
Policy mu Std                1.1329323
Policy mu Max                3.0073707
Policy mu Min                -2.907153
Policy log std Mean          -0.56341445
Policy log std Std           0.32291925
Policy log std Max           0.047390193
Policy log std Min           -2.1326532
Z mean eval                  2.0379953
Z variance eval              0.019211907
total_rewards                [5577.68449783 5781.47382883 5728.99980782 5576.31033472 5771.88471686
 5651.40523014 5570.29478038 5644.96415316 5705.92108074 5538.90817031]
total_rewards_mean           5654.784660078785
total_rewards_std            84.06057861095499
total_rewards_max            5781.473828827806
total_rewards_min            5538.908170309849
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               33.22074736887589
(Previous) Eval Time (s)     28.10809353319928
Sample Time (s)              22.074639656580985
Epoch Time (s)               83.40348055865616
Total Train Time (s)         5098.71564652957
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:57.719681 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #61 | Epoch Duration: 84.01211190223694
2020-01-11 10:55:57.719931 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0390244
Z variance train             0.01917678
KL Divergence                26.420734
KL Loss                      2.6420734
QF Loss                      476.9852
VF Loss                      180.68924
Policy Loss                  -1485.6599
Q Predictions Mean           1479.4028
Q Predictions Std            608.9895
Q Predictions Max            2141.0403
Q Predictions Min            249.69115
V Predictions Mean           1487.6469
V Predictions Std            605.97345
V Predictions Max            2151.4517
V Predictions Min            261.11465
Log Pis Mean                 2.1727595
Log Pis Std                  4.3968334
Log Pis Max                  13.666006
Log Pis Min                  -7.9204087
Policy mu Mean               0.022429146
Policy mu Std                1.1645663
Policy mu Max                3.3534355
Policy mu Min                -2.8084035
Policy log std Mean          -0.5783078
Policy log std Std           0.3388798
Policy log std Max           0.06948975
Policy log std Min           -2.064958
Z mean eval                  2.0267282
Z variance eval              0.020318303
total_rewards                [5353.29010415 5305.78798421 5438.62155004 4996.54825495 5369.83099347
 5192.37344707 5130.50448859 5198.22218029 5233.13471645 5536.8442075 ]
total_rewards_mean           5275.515792672284
total_rewards_std            149.76344943847496
total_rewards_max            5536.84420750107
total_rewards_min            4996.548254946272
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               33.86086726281792
(Previous) Eval Time (s)     28.716258583124727
Sample Time (s)              23.406370665878057
Epoch Time (s)               85.9834965118207
Total Train Time (s)         5185.839077274781
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:57:24.845883 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #62 | Epoch Duration: 87.12571811676025
2020-01-11 10:57:24.846238 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0254183
Z variance train             0.020229498
KL Divergence                25.799393
KL Loss                      2.5799394
QF Loss                      385.3214
VF Loss                      140.55156
Policy Loss                  -1602.4569
Q Predictions Mean           1606.8513
Q Predictions Std            552.4492
Q Predictions Max            2180.0444
Q Predictions Min            256.64227
V Predictions Mean           1609.4652
V Predictions Std            552.4448
V Predictions Max            2183.3796
V Predictions Min            224.21202
Log Pis Mean                 1.8200808
Log Pis Std                  4.1533217
Log Pis Max                  12.251984
Log Pis Min                  -7.4068375
Policy mu Mean               -0.088115536
Policy mu Std                1.1367687
Policy mu Max                2.885927
Policy mu Min                -2.9193997
Policy log std Mean          -0.5747276
Policy log std Std           0.3268146
Policy log std Max           -0.031159759
Policy log std Min           -2.0426183
Z mean eval                  2.0525863
Z variance eval              0.013073881
total_rewards                [5278.78957789 5364.42702941 5415.35154788 5298.08208453 5364.57554704
 5356.46542279 5229.76175621 5360.63285913 5382.26187734 5319.5053651 ]
total_rewards_mean           5336.985306732579
total_rewards_std            52.294195144086466
total_rewards_max            5415.351547879533
total_rewards_min            5229.761756207668
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               33.36486695101485
(Previous) Eval Time (s)     29.858100766316056
Sample Time (s)              23.793877604883164
Epoch Time (s)               87.01684532221407
Total Train Time (s)         5271.678896309808
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:50.686426 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #63 | Epoch Duration: 85.83999538421631
2020-01-11 10:58:50.686647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0540826
Z variance train             0.013032375
KL Divergence                27.190304
KL Loss                      2.7190304
QF Loss                      356.1452
VF Loss                      64.165886
Policy Loss                  -1592.29
Q Predictions Mean           1592.383
Q Predictions Std            559.15265
Q Predictions Max            2164.615
Q Predictions Min            245.32793
V Predictions Mean           1593.7474
V Predictions Std            555.9762
V Predictions Max            2161.7026
V Predictions Min            251.05127
Log Pis Mean                 2.0926342
Log Pis Std                  4.5518923
Log Pis Max                  14.601321
Log Pis Min                  -7.2139826
Policy mu Mean               -0.08946123
Policy mu Std                1.1585116
Policy mu Max                2.9546804
Policy mu Min                -2.8058636
Policy log std Mean          -0.564356
Policy log std Std           0.32068107
Policy log std Max           0.022530377
Policy log std Min           -2.2817595
Z mean eval                  2.054189
Z variance eval              0.01288003
total_rewards                [5720.60426659 5901.51581184 5706.79318643 5756.56278306 5790.21840744
 5496.68122363 5884.25790511 5667.71427195 5766.43540726 5769.77753422]
total_rewards_mean           5746.056079751717
total_rewards_std            108.08368356459093
total_rewards_max            5901.515811840177
total_rewards_min            5496.681223627512
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               33.91810190118849
(Previous) Eval Time (s)     28.680819565895945
Sample Time (s)              23.8484271094203
Epoch Time (s)               86.44734857650474
Total Train Time (s)         5358.433065568563
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:00:17.443121 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #64 | Epoch Duration: 86.75624799728394
2020-01-11 11:00:17.443430 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0540252
Z variance train             0.012903348
KL Divergence                27.017483
KL Loss                      2.7017484
QF Loss                      205.95905
VF Loss                      76.24681
Policy Loss                  -1620.2056
Q Predictions Mean           1619.3275
Q Predictions Std            557.336
Q Predictions Max            2169.5056
Q Predictions Min            229.25378
V Predictions Mean           1620.4087
V Predictions Std            554.80383
V Predictions Max            2151.1865
V Predictions Min            244.8899
Log Pis Mean                 2.3243842
Log Pis Std                  4.2773857
Log Pis Max                  15.218156
Log Pis Min                  -5.5830703
Policy mu Mean               -0.028565481
Policy mu Std                1.1718726
Policy mu Max                2.8725832
Policy mu Min                -2.827321
Policy log std Mean          -0.59094524
Policy log std Std           0.3253409
Policy log std Max           -0.07583135
Policy log std Min           -2.092714
Z mean eval                  2.034642
Z variance eval              0.04763553
total_rewards                [5683.54255834 5704.70885809 5664.77282275 5638.66904341 5639.81553245
 5714.95162652 5735.74772724 5736.1183425  5673.72508981 5888.98080475]
total_rewards_mean           5708.103240585529
total_rewards_std            68.8992796125034
total_rewards_max            5888.980804748531
total_rewards_min            5638.669043407141
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               33.49394419416785
(Previous) Eval Time (s)     28.98928249720484
Sample Time (s)              23.83618614729494
Epoch Time (s)               86.31941283866763
Total Train Time (s)         5444.335825035814
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:43.347218 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #65 | Epoch Duration: 85.90357613563538
2020-01-11 11:01:43.347468 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0345607
Z variance train             0.047717333
KL Divergence                25.569908
KL Loss                      2.5569909
QF Loss                      338.8183
VF Loss                      158.34091
Policy Loss                  -1508.8704
Q Predictions Mean           1510.5662
Q Predictions Std            598.4036
Q Predictions Max            2117.0679
Q Predictions Min            220.29977
V Predictions Mean           1502.4551
V Predictions Std            596.81024
V Predictions Max            2108.321
V Predictions Min            225.04968
Log Pis Mean                 1.8126863
Log Pis Std                  4.2458467
Log Pis Max                  13.202741
Log Pis Min                  -7.6153655
Policy mu Mean               -0.08486283
Policy mu Std                1.1093374
Policy mu Max                3.7663553
Policy mu Min                -2.8438592
Policy log std Mean          -0.5862491
Policy log std Std           0.33123106
Policy log std Max           -0.021607608
Policy log std Min           -2.3054254
Z mean eval                  2.0732608
Z variance eval              0.023040187
total_rewards                [5841.81391376 5952.22600992 5865.86436821 5915.20162249 5971.71165608
 5910.1876292  5900.82545751 5939.18818815 6048.85643433 5984.51138499]
total_rewards_mean           5933.038666464469
total_rewards_std            57.16391319870196
total_rewards_max            6048.856434325807
total_rewards_min            5841.813913758132
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               33.77890321193263
(Previous) Eval Time (s)     28.573060653172433
Sample Time (s)              21.608794504776597
Epoch Time (s)               83.96075836988166
Total Train Time (s)         5528.717976918444
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:03:07.730720 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #66 | Epoch Duration: 84.3830943107605
2020-01-11 11:03:07.730940 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0731924
Z variance train             0.02302443
KL Divergence                26.461395
KL Loss                      2.6461396
QF Loss                      235.99539
VF Loss                      88.856834
Policy Loss                  -1562.9843
Q Predictions Mean           1561.955
Q Predictions Std            662.89453
Q Predictions Max            2196.7732
Q Predictions Min            244.54477
V Predictions Mean           1566.9236
V Predictions Std            659.78375
V Predictions Max            2199.2686
V Predictions Min            241.54808
Log Pis Mean                 1.7291133
Log Pis Std                  4.470781
Log Pis Max                  13.013176
Log Pis Min                  -5.985433
Policy mu Mean               0.004097845
Policy mu Std                1.1294845
Policy mu Max                2.9447913
Policy mu Min                -3.0819604
Policy log std Mean          -0.5454212
Policy log std Std           0.3474875
Policy log std Max           0.102757156
Policy log std Min           -2.1069102
Z mean eval                  2.0955136
Z variance eval              0.013792193
total_rewards                [5737.36634618 5898.60183577 5924.15912513 5917.62546856 5953.25917131
 5797.75080442 5830.95244718 5801.05118653 5870.72133674 5845.14717923]
total_rewards_mean           5857.663490106059
total_rewards_std            64.13900655414236
total_rewards_max            5953.259171309892
total_rewards_min            5737.36634618312
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               34.33328831382096
(Previous) Eval Time (s)     28.99503556918353
Sample Time (s)              23.671087882947177
Epoch Time (s)               86.99941176595166
Total Train Time (s)         5616.43619381031
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:35.450833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #67 | Epoch Duration: 87.71974611282349
2020-01-11 11:04:35.451031 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #67 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0970707
Z variance train             0.013803745
KL Divergence                27.715683
KL Loss                      2.7715683
QF Loss                      229.73602
VF Loss                      99.41829
Policy Loss                  -1641.2261
Q Predictions Mean           1635.1548
Q Predictions Std            579.3409
Q Predictions Max            2255.6995
Q Predictions Min            238.49467
V Predictions Mean           1638.0681
V Predictions Std            576.6452
V Predictions Max            2236.8767
V Predictions Min            243.66182
Log Pis Mean                 1.670243
Log Pis Std                  3.8188024
Log Pis Max                  13.659279
Log Pis Min                  -7.170472
Policy mu Mean               0.018325772
Policy mu Std                1.1132969
Policy mu Max                2.9587586
Policy mu Min                -2.685468
Policy log std Mean          -0.5651023
Policy log std Std           0.3221919
Policy log std Max           0.038921
Policy log std Min           -2.0961962
Z mean eval                  2.0838563
Z variance eval              0.011064863
total_rewards                [5870.04387009 5905.54532701 5968.61152172 6008.9666343  5742.9911026
 5897.89156686 5842.88642814 5860.00601628 5697.25852503 6062.20540799]
total_rewards_mean           5885.640640002779
total_rewards_std            106.0093838829731
total_rewards_max            6062.205407991227
total_rewards_min            5697.258525027953
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               33.22641342692077
(Previous) Eval Time (s)     29.715038198046386
Sample Time (s)              23.874159247614443
Epoch Time (s)               86.8156108725816
Total Train Time (s)         5702.6540380558
Epoch                        68
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:06:01.670529 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #68 | Epoch Duration: 86.21934723854065
2020-01-11 11:06:01.670760 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0819497
Z variance train             0.011045547
KL Divergence                28.423595
KL Loss                      2.8423595
QF Loss                      408.3325
VF Loss                      177.35391
Policy Loss                  -1598.2646
Q Predictions Mean           1595.3691
Q Predictions Std            633.54065
Q Predictions Max            2222.441
Q Predictions Min            232.79854
V Predictions Mean           1602.5865
V Predictions Std            632.82104
V Predictions Max            2236.5322
V Predictions Min            243.75876
Log Pis Mean                 2.5809503
Log Pis Std                  4.4662027
Log Pis Max                  14.429176
Log Pis Min                  -5.635748
Policy mu Mean               -0.05606849
Policy mu Std                1.208436
Policy mu Max                3.41036
Policy mu Min                -2.7092867
Policy log std Mean          -0.5744757
Policy log std Std           0.33312744
Policy log std Max           -0.010628611
Policy log std Min           -2.4634151
Z mean eval                  2.0926025
Z variance eval              0.01164424
total_rewards                [5761.49429066 5821.17837162 5915.55649189 5969.69744422 6191.73372815
 5980.96007262 5979.84565105 5818.1583395  5914.21921282 5884.38081431]
total_rewards_mean           5923.722441683605
total_rewards_std            114.0401281353854
total_rewards_max            6191.73372814644
total_rewards_min            5761.494290660418
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               33.92594486521557
(Previous) Eval Time (s)     29.118336235173047
Sample Time (s)              22.5183638012968
Epoch Time (s)               85.56264490168542
Total Train Time (s)         5788.1949321520515
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:27.212624 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #69 | Epoch Duration: 85.54172015190125
2020-01-11 11:07:27.212800 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0943716
Z variance train             0.011673568
KL Divergence                28.996618
KL Loss                      2.8996618
QF Loss                      438.46933
VF Loss                      129.57812
Policy Loss                  -1642.9235
Q Predictions Mean           1639.4998
Q Predictions Std            642.5633
Q Predictions Max            2271.9395
Q Predictions Min            237.29791
V Predictions Mean           1638.6522
V Predictions Std            636.9745
V Predictions Max            2242.5752
V Predictions Min            236.21213
Log Pis Mean                 1.8174763
Log Pis Std                  4.153148
Log Pis Max                  12.245399
Log Pis Min                  -6.0209136
Policy mu Mean               0.08255458
Policy mu Std                1.1195666
Policy mu Max                2.8909614
Policy mu Min                -2.450357
Policy log std Mean          -0.58163494
Policy log std Std           0.34637278
Policy log std Max           -0.033139795
Policy log std Min           -2.1706736
Z mean eval                  2.1016607
Z variance eval              0.011923835
total_rewards                [6001.79139899 5943.09200256 6029.5300707  6014.79996738 6067.66000125
 6042.17067271 5945.21526318 6059.05205181 5931.04291715 5883.47355335]
total_rewards_mean           5991.7827899082395
total_rewards_std            59.02187190983176
total_rewards_max            6067.660001248
total_rewards_min            5883.4735533488765
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               33.033643026370555
(Previous) Eval Time (s)     29.09702240396291
Sample Time (s)              23.398571940604597
Epoch Time (s)               85.52923737093806
Total Train Time (s)         5873.224006571807
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:08:52.243736 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #70 | Epoch Duration: 85.03079771995544
2020-01-11 11:08:52.243924 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.102152
Z variance train             0.011881178
KL Divergence                29.307533
KL Loss                      2.9307535
QF Loss                      242.74435
VF Loss                      130.07253
Policy Loss                  -1661.451
Q Predictions Mean           1659.6771
Q Predictions Std            637.1956
Q Predictions Max            2308.9946
Q Predictions Min            235.28268
V Predictions Mean           1655.4197
V Predictions Std            630.4683
V Predictions Max            2287.785
V Predictions Min            241.30844
Log Pis Mean                 2.4097986
Log Pis Std                  4.3220277
Log Pis Max                  13.908327
Log Pis Min                  -6.2991114
Policy mu Mean               -0.03422207
Policy mu Std                1.1656649
Policy mu Max                2.739013
Policy mu Min                -2.6938107
Policy log std Mean          -0.58906394
Policy log std Std           0.33664277
Policy log std Max           -0.047555357
Policy log std Min           -2.148845
Z mean eval                  2.099486
Z variance eval              0.014072609
total_rewards                [5896.48071562 6000.87138147 6149.75725187 5967.3044107  5692.00421338
 5910.02184673 5939.60866919 5882.39266124 6028.63633127 5727.33605352]
total_rewards_mean           5919.441353498444
total_rewards_std            128.42041158520055
total_rewards_max            6149.757251866341
total_rewards_min            5692.0042133815305
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               31.56630276190117
(Previous) Eval Time (s)     28.598134248983115
Sample Time (s)              22.832471795380116
Epoch Time (s)               82.9969088062644
Total Train Time (s)         5956.226402248722
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:15.247720 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #71 | Epoch Duration: 83.00365734100342
2020-01-11 11:10:15.247894 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #71 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0972707
Z variance train             0.014099918
KL Divergence                29.420046
KL Loss                      2.9420047
QF Loss                      461.50885
VF Loss                      271.8603
Policy Loss                  -1784.0004
Q Predictions Mean           1783.7297
Q Predictions Std            552.6394
Q Predictions Max            2333.5005
Q Predictions Min            230.09521
V Predictions Mean           1796.0752
V Predictions Std            544.9087
V Predictions Max            2347.072
V Predictions Min            245.54745
Log Pis Mean                 1.9477649
Log Pis Std                  4.199779
Log Pis Max                  14.339385
Log Pis Min                  -6.7605777
Policy mu Mean               -0.037640553
Policy mu Std                1.1457485
Policy mu Max                3.0470953
Policy mu Min                -2.753489
Policy log std Mean          -0.61021596
Policy log std Std           0.3413965
Policy log std Max           0.025689691
Policy log std Min           -2.3181841
Z mean eval                  2.0871596
Z variance eval              0.013581817
total_rewards                [5974.04276412 6191.01186975 6114.12244729 6189.82039446 6127.6343554
 6250.41691344 5948.62286841 5896.37577379 6106.6098375  6091.92340038]
total_rewards_mean           6089.058062453961
total_rewards_std            109.1301795278632
total_rewards_max            6250.416913438549
total_rewards_min            5896.37577379083
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               31.23246879922226
(Previous) Eval Time (s)     28.604533900041133
Sample Time (s)              23.01376499934122
Epoch Time (s)               82.85076769860461
Total Train Time (s)         6037.607088102493
Epoch                        72
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:11:36.629887 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #72 | Epoch Duration: 81.38185834884644
2020-01-11 11:11:36.630064 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #72 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.088297
Z variance train             0.013584899
KL Divergence                28.712194
KL Loss                      2.8712194
QF Loss                      287.73566
VF Loss                      144.98694
Policy Loss                  -1673.5808
Q Predictions Mean           1670.3284
Q Predictions Std            628.2927
Q Predictions Max            2254.8298
Q Predictions Min            178.31087
V Predictions Mean           1671.5623
V Predictions Std            624.9462
V Predictions Max            2256.1465
V Predictions Min            219.47527
Log Pis Mean                 2.0107691
Log Pis Std                  4.381879
Log Pis Max                  15.139852
Log Pis Min                  -6.461306
Policy mu Mean               -0.033444766
Policy mu Std                1.132883
Policy mu Max                3.4174132
Policy mu Min                -3.2109635
Policy log std Mean          -0.59144944
Policy log std Std           0.34043708
Policy log std Max           0.39829198
Policy log std Min           -2.10734
Z mean eval                  2.0855472
Z variance eval              0.015771419
total_rewards                [6056.13538551 6167.55110991 6033.90178203 6301.03925415 6251.3457514
 6335.30321597 6088.39541447 5996.39485228 6234.37438629 6131.39362046]
total_rewards_mean           6159.583477249113
total_rewards_std            111.33506788975154
total_rewards_max            6335.303215971844
total_rewards_min            5996.394852284366
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               32.028457100037485
(Previous) Eval Time (s)     27.13530923705548
Sample Time (s)              22.40794648276642
Epoch Time (s)               81.57171281985939
Total Train Time (s)         6120.496538940817
Epoch                        73
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:59.521316 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #73 | Epoch Duration: 82.89111423492432
2020-01-11 11:12:59.521507 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0829456
Z variance train             0.015787052
KL Divergence                28.38974
KL Loss                      2.838974
QF Loss                      317.6906
VF Loss                      375.7648
Policy Loss                  -1620.8213
Q Predictions Mean           1623.8385
Q Predictions Std            696.7949
Q Predictions Max            2369.4626
Q Predictions Min            216.99594
V Predictions Mean           1638.0404
V Predictions Std            696.613
V Predictions Max            2362.8857
V Predictions Min            220.73717
Log Pis Mean                 1.7844996
Log Pis Std                  4.4231963
Log Pis Max                  14.945031
Log Pis Min                  -6.8453064
Policy mu Mean               -0.053721216
Policy mu Std                1.1366625
Policy mu Max                2.8887918
Policy mu Min                -2.7730458
Policy log std Mean          -0.57496405
Policy log std Std           0.34069622
Policy log std Max           -0.0013042092
Policy log std Min           -2.1682572
Z mean eval                  2.097365
Z variance eval              0.022150425
total_rewards                [6038.06150055 6193.7584051  6220.37264466 6192.43709363 6006.72631192
 6345.80159439 6213.56403154 6114.60211506 6161.20930186 6430.97391217]
total_rewards_mean           6191.7506910888505
total_rewards_std            121.2427473444249
total_rewards_max            6430.973912168036
total_rewards_min            6006.726311922985
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               31.83042331971228
(Previous) Eval Time (s)     28.45436543179676
Sample Time (s)              22.582369415089488
Epoch Time (s)               82.86715816659853
Total Train Time (s)         6203.157266685739
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:14:22.183696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #74 | Epoch Duration: 82.66202521324158
2020-01-11 11:14:22.183910 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0953338
Z variance train             0.022086024
KL Divergence                28.051376
KL Loss                      2.8051376
QF Loss                      421.44403
VF Loss                      229.32138
Policy Loss                  -1776.8141
Q Predictions Mean           1769.3373
Q Predictions Std            620.0654
Q Predictions Max            2452.779
Q Predictions Min            211.99585
V Predictions Mean           1776.9658
V Predictions Std            614.4709
V Predictions Max            2475.5444
V Predictions Min            229.39946
Log Pis Mean                 2.5029273
Log Pis Std                  4.3813357
Log Pis Max                  14.084156
Log Pis Min                  -6.784932
Policy mu Mean               -0.074602894
Policy mu Std                1.1695241
Policy mu Max                2.9728124
Policy mu Min                -2.7080154
Policy log std Mean          -0.61930066
Policy log std Std           0.34025046
Policy log std Max           -0.07641886
Policy log std Min           -2.2160373
Z mean eval                  2.0955396
Z variance eval              0.0211276
total_rewards                [6165.01297531 6312.28054688 6341.73892246 6417.61135302 6256.36372655
 6222.39087414 6334.98757824 6399.51301628 6470.16498208 6322.76446655]
total_rewards_mean           6324.282844149853
total_rewards_std            87.5093854142323
total_rewards_max            6470.164982077686
total_rewards_min            6165.012975305183
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               31.772151921875775
(Previous) Eval Time (s)     28.248885050415993
Sample Time (s)              21.256525094620883
Epoch Time (s)               81.27756206691265
Total Train Time (s)         6284.550940855872
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:43.579727 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #75 | Epoch Duration: 81.39562821388245
2020-01-11 11:15:43.580017 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0933452
Z variance train             0.021007104
KL Divergence                27.855131
KL Loss                      2.7855132
QF Loss                      301.0777
VF Loss                      175.91002
Policy Loss                  -1779.442
Q Predictions Mean           1781.8313
Q Predictions Std            647.4751
Q Predictions Max            2431.0156
Q Predictions Min            219.37886
V Predictions Mean           1787.7917
V Predictions Std            647.04486
V Predictions Max            2419.649
V Predictions Min            227.01611
Log Pis Mean                 2.3321924
Log Pis Std                  4.285305
Log Pis Max                  14.23316
Log Pis Min                  -5.962763
Policy mu Mean               -0.030345224
Policy mu Std                1.1766378
Policy mu Max                3.1160839
Policy mu Min                -2.8929005
Policy log std Mean          -0.5947221
Policy log std Std           0.3514268
Policy log std Max           -0.03581506
Policy log std Min           -2.228064
Z mean eval                  2.1001167
Z variance eval              0.018153023
total_rewards                [6396.82240901 6307.51128099 6299.97775389 6509.21459477 6399.50105621
 6093.45598631 6262.57056864 6332.32633919 6439.37777647 6477.85041857]
total_rewards_mean           6351.860818403792
total_rewards_std            115.05219720189389
total_rewards_max            6509.214594767351
total_rewards_min            6093.455986306117
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               32.28954933490604
(Previous) Eval Time (s)     28.36658034613356
Sample Time (s)              21.985120948404074
Epoch Time (s)               82.64125062944368
Total Train Time (s)         6367.242208614945
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:17:06.272411 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #76 | Epoch Duration: 82.69216871261597
2020-01-11 11:17:06.272635 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1020591
Z variance train             0.018251449
KL Divergence                28.486172
KL Loss                      2.8486173
QF Loss                      380.73248
VF Loss                      159.18684
Policy Loss                  -1789.928
Q Predictions Mean           1786.756
Q Predictions Std            624.2061
Q Predictions Max            2396.669
Q Predictions Min            219.85318
V Predictions Mean           1789.7229
V Predictions Std            623.6722
V Predictions Max            2400.4697
V Predictions Min            206.69519
Log Pis Mean                 2.0871572
Log Pis Std                  4.254151
Log Pis Max                  15.729063
Log Pis Min                  -6.958583
Policy mu Mean               -0.02815026
Policy mu Std                1.1589617
Policy mu Max                2.9010863
Policy mu Min                -2.958884
Policy log std Mean          -0.59529036
Policy log std Std           0.3398196
Policy log std Max           -0.06713654
Policy log std Min           -2.2132566
Z mean eval                  2.1066844
Z variance eval              0.016813211
total_rewards                [6496.52623913 6591.85177837 6569.42270709 6098.36901669 6464.48388517
 6701.31683893 6480.2497233  6434.90569056 6448.79880998 6390.03749129]
total_rewards_mean           6467.5962180509505
total_rewards_std            150.068732970856
total_rewards_max            6701.316838927655
total_rewards_min            6098.369016687215
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               31.142293139360845
(Previous) Eval Time (s)     28.417192582972348
Sample Time (s)              22.83404496172443
Epoch Time (s)               82.39353068405762
Total Train Time (s)         6447.94673908269
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:26.978911 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #77 | Epoch Duration: 80.70609283447266
2020-01-11 11:18:26.979288 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1067314
Z variance train             0.016856857
KL Divergence                28.803871
KL Loss                      2.880387
QF Loss                      389.25513
VF Loss                      176.45143
Policy Loss                  -1875.2975
Q Predictions Mean           1872.6464
Q Predictions Std            547.9376
Q Predictions Max            2413.548
Q Predictions Min            161.21803
V Predictions Mean           1871.4536
V Predictions Std            545.42053
V Predictions Max            2427.1062
V Predictions Min            214.08049
Log Pis Mean                 2.3561518
Log Pis Std                  4.365781
Log Pis Max                  15.383451
Log Pis Min                  -8.819117
Policy mu Mean               -0.046467345
Policy mu Std                1.1826154
Policy mu Max                3.1466222
Policy mu Min                -3.6537957
Policy log std Mean          -0.6178339
Policy log std Std           0.35264978
Policy log std Max           0.06282872
Policy log std Min           -2.2314305
Z mean eval                  2.0777872
Z variance eval              0.024229335
total_rewards                [6462.08451885 6486.22193854 6263.60969888 6443.50471603 6422.35798863
 6451.67359546 6474.77611572 6229.02328472 6347.49653079 6426.39904059]
total_rewards_mean           6400.71474282173
total_rewards_std            85.57256835475307
total_rewards_max            6486.22193853989
total_rewards_min            6229.023284715592
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               31.590394223108888
(Previous) Eval Time (s)     26.72938992269337
Sample Time (s)              22.737240285612643
Epoch Time (s)               81.0570244314149
Total Train Time (s)         6530.1892535244115
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:19:49.222828 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #78 | Epoch Duration: 82.2432861328125
2020-01-11 11:19:49.223032 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0770366
Z variance train             0.02424673
KL Divergence                27.59309
KL Loss                      2.759309
QF Loss                      336.47437
VF Loss                      157.20813
Policy Loss                  -1779.4272
Q Predictions Mean           1773.571
Q Predictions Std            651.49774
Q Predictions Max            2512.0935
Q Predictions Min            222.51367
V Predictions Mean           1779.9452
V Predictions Std            647.31744
V Predictions Max            2514.0007
V Predictions Min            217.52129
Log Pis Mean                 2.40904
Log Pis Std                  4.404644
Log Pis Max                  13.6718025
Log Pis Min                  -6.7849283
Policy mu Mean               -0.07350745
Policy mu Std                1.1917588
Policy mu Max                3.254386
Policy mu Min                -2.7481205
Policy log std Mean          -0.6126142
Policy log std Std           0.34092745
Policy log std Max           0.01766634
Policy log std Min           -2.27721
Z mean eval                  2.0973535
Z variance eval              0.02116807
total_rewards                [6485.55220137 6711.74806887 6354.84641704 6560.31175036 6576.22259422
 6551.25041772 6563.85525369 6672.28597527 6444.87322902 6563.53562426]
total_rewards_mean           6548.448153181422
total_rewards_std            97.75121189992925
total_rewards_max            6711.748068870518
total_rewards_min            6354.846417039762
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               32.33784643094987
(Previous) Eval Time (s)     27.915332227014005
Sample Time (s)              22.642516432795674
Epoch Time (s)               82.89569509075955
Total Train Time (s)         6612.682141779456
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:11.717466 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #79 | Epoch Duration: 82.49427723884583
2020-01-11 11:21:11.717661 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0967438
Z variance train             0.021209795
KL Divergence                28.727974
KL Loss                      2.8727975
QF Loss                      518.7213
VF Loss                      130.17665
Policy Loss                  -1846.8888
Q Predictions Mean           1840.259
Q Predictions Std            608.31757
Q Predictions Max            2457.4092
Q Predictions Min            218.85968
V Predictions Mean           1845.5198
V Predictions Std            608.83026
V Predictions Max            2455.9893
V Predictions Min            214.42593
Log Pis Mean                 2.209661
Log Pis Std                  4.5332227
Log Pis Max                  15.467663
Log Pis Min                  -6.444452
Policy mu Mean               -0.08669285
Policy mu Std                1.1741309
Policy mu Max                2.7243667
Policy mu Min                -3.0644083
Policy log std Mean          -0.6135056
Policy log std Std           0.34137842
Policy log std Max           -0.03082177
Policy log std Min           -2.2224193
Z mean eval                  2.1182961
Z variance eval              0.017575603
total_rewards                [6584.50745257 6430.3114182  6506.28525856 6594.6324448  6535.42465627
 6454.55311118 6625.09571204 6532.69686149 6679.12758733 6481.70395329]
total_rewards_mean           6542.433845572608
total_rewards_std            74.46226246962519
total_rewards_max            6679.127587328068
total_rewards_min            6430.311418204361
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               31.64458189206198
(Previous) Eval Time (s)     27.51359796896577
Sample Time (s)              22.06374857062474
Epoch Time (s)               81.22192843165249
Total Train Time (s)         6694.514301301446
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:22:33.552764 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #80 | Epoch Duration: 81.8349404335022
2020-01-11 11:22:33.553001 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1188369
Z variance train             0.017597403
KL Divergence                29.537905
KL Loss                      2.9537904
QF Loss                      401.2291
VF Loss                      179.031
Policy Loss                  -1853.7913
Q Predictions Mean           1852.9116
Q Predictions Std            668.46277
Q Predictions Max            2551.4937
Q Predictions Min            214.47496
V Predictions Mean           1852.5505
V Predictions Std            663.68567
V Predictions Max            2545.7922
V Predictions Min            219.05602
Log Pis Mean                 2.6887329
Log Pis Std                  4.493025
Log Pis Max                  15.113478
Log Pis Min                  -7.182695
Policy mu Mean               -0.052093964
Policy mu Std                1.2008934
Policy mu Max                2.7003493
Policy mu Min                -2.8021836
Policy log std Mean          -0.6244492
Policy log std Std           0.33620277
Policy log std Max           -0.007921994
Policy log std Min           -2.1131406
Z mean eval                  2.1144593
Z variance eval              0.018258236
total_rewards                [6523.77573713 6560.98857927 6468.41986991 6551.11268241 6559.73390812
 6739.11281117 6625.51859199 6325.59097589 6571.0135313  6502.80981734]
total_rewards_mean           6542.807650452154
total_rewards_std            100.76560504299825
total_rewards_max            6739.112811168114
total_rewards_min            6325.590975889167
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               31.75899184588343
(Previous) Eval Time (s)     28.12618798390031
Sample Time (s)              22.837701288051903
Epoch Time (s)               82.72288111783564
Total Train Time (s)         6777.165078229271
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:23:56.205335 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #81 | Epoch Duration: 82.65216112136841
2020-01-11 11:23:56.205542 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.113205
Z variance train             0.0182937
KL Divergence                29.402794
KL Loss                      2.9402795
QF Loss                      677.991
VF Loss                      150.39099
Policy Loss                  -1852.6014
Q Predictions Mean           1848.2668
Q Predictions Std            645.3081
Q Predictions Max            2485.9106
Q Predictions Min            194.89334
V Predictions Mean           1854.8942
V Predictions Std            637.1705
V Predictions Max            2516.4905
V Predictions Min            211.51683
Log Pis Mean                 2.3673987
Log Pis Std                  4.5556006
Log Pis Max                  15.93849
Log Pis Min                  -7.33017
Policy mu Mean               -0.09343714
Policy mu Std                1.2288659
Policy mu Max                3.5613308
Policy mu Min                -3.1131883
Policy log std Mean          -0.62361574
Policy log std Std           0.3313539
Policy log std Max           -0.00787735
Policy log std Min           -2.2958403
Z mean eval                  2.1065998
Z variance eval              0.020310437
total_rewards                [6379.90688631 6643.80982193 6462.67493711 6873.78047488 6897.02683891
 6781.95437331 6875.60188093 7167.73572092 6912.18550762 6491.93771956]
total_rewards_mean           6748.661416147399
total_rewards_std            234.93017350029933
total_rewards_max            7167.73572091989
total_rewards_min            6379.9068863074035
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               31.787185475230217
(Previous) Eval Time (s)     28.055093235801905
Sample Time (s)              23.236125783994794
Epoch Time (s)               83.07840449502692
Total Train Time (s)         6859.8750419127755
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:25:18.915651 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #82 | Epoch Duration: 82.70996618270874
2020-01-11 11:25:18.915823 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #82 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1092575
Z variance train             0.02032469
KL Divergence                28.854057
KL Loss                      2.8854058
QF Loss                      532.5845
VF Loss                      407.4976
Policy Loss                  -1846.4158
Q Predictions Mean           1835.4927
Q Predictions Std            725.7744
Q Predictions Max            2618.6304
Q Predictions Min            207.80984
V Predictions Mean           1829.6224
V Predictions Std            720.9508
V Predictions Max            2602.0237
V Predictions Min            214.03217
Log Pis Mean                 2.4140263
Log Pis Std                  4.3602095
Log Pis Max                  14.18362
Log Pis Min                  -6.7119536
Policy mu Mean               -0.04896359
Policy mu Std                1.1768855
Policy mu Max                3.402853
Policy mu Min                -2.7629507
Policy log std Mean          -0.6067989
Policy log std Std           0.33346012
Policy log std Max           -0.0036138296
Policy log std Min           -2.0050826
Z mean eval                  2.0886703
Z variance eval              0.031356927
total_rewards                [6798.20100136 6671.60454175 6792.0939159  6777.29104147 6715.5205953
 6910.66600738 6829.47753105 6521.86882741 6857.65240796 6633.00851318]
total_rewards_mean           6750.738438275839
total_rewards_std            110.28117892348645
total_rewards_max            6910.666007380107
total_rewards_min            6521.868827412861
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               31.3283561039716
(Previous) Eval Time (s)     27.68636200018227
Sample Time (s)              22.175486393272877
Epoch Time (s)               81.19020449742675
Total Train Time (s)         6939.923338152468
Epoch                        83
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:38.966105 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #83 | Epoch Duration: 80.05014610290527
2020-01-11 11:26:38.966293 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0884247
Z variance train             0.03130274
KL Divergence                28.087553
KL Loss                      2.8087554
QF Loss                      249.94194
VF Loss                      114.77025
Policy Loss                  -1871.5049
Q Predictions Mean           1869.6436
Q Predictions Std            728.095
Q Predictions Max            2617.8857
Q Predictions Min            205.44496
V Predictions Mean           1869.1597
V Predictions Std            726.2737
V Predictions Max            2616.3254
V Predictions Min            210.04489
Log Pis Mean                 2.4130554
Log Pis Std                  4.5925326
Log Pis Max                  15.929441
Log Pis Min                  -6.2246084
Policy mu Mean               -0.080102876
Policy mu Std                1.1873438
Policy mu Max                2.8691845
Policy mu Min                -3.1432986
Policy log std Mean          -0.6100736
Policy log std Std           0.36573324
Policy log std Max           0.012500346
Policy log std Min           -2.3621314
Z mean eval                  2.099985
Z variance eval              0.028327515
total_rewards                [6630.99073372 6538.98417365 6588.57398212 6710.33546421 6432.11691934
 6603.29084294 6576.92622231 6442.99878831 6614.86910876 6377.62436887]
total_rewards_mean           6551.671060422637
total_rewards_std            98.32614657645769
total_rewards_max            6710.335464206322
total_rewards_min            6377.624368867579
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               31.678121712990105
(Previous) Eval Time (s)     26.545996421016753
Sample Time (s)              22.391425173729658
Epoch Time (s)               80.61554330773652
Total Train Time (s)         7021.8484479291365
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:28:00.892404 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #84 | Epoch Duration: 81.92596220970154
2020-01-11 11:28:00.892582 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #84 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1018925
Z variance train             0.028330058
KL Divergence                28.093094
KL Loss                      2.8093095
QF Loss                      1451.8175
VF Loss                      120.89322
Policy Loss                  -1945.1616
Q Predictions Mean           1954.598
Q Predictions Std            637.1124
Q Predictions Max            2620.242
Q Predictions Min            212.45891
V Predictions Mean           1950.2878
V Predictions Std            634.9307
V Predictions Max            2606.7793
V Predictions Min            208.37622
Log Pis Mean                 2.3047783
Log Pis Std                  4.57508
Log Pis Max                  17.197739
Log Pis Min                  -6.2794724
Policy mu Mean               -0.16298713
Policy mu Std                1.1618208
Policy mu Max                2.8657908
Policy mu Min                -3.015986
Policy log std Mean          -0.6190343
Policy log std Std           0.3543062
Policy log std Max           -0.021057993
Policy log std Min           -2.3900938
Z mean eval                  2.1140022
Z variance eval              0.02110885
total_rewards                [6760.27941642 6742.98074972 6707.65063711 6679.25113666 6696.190642
 6855.21397432 6731.10085851 6855.74330612 6789.23215351 6830.71572654]
total_rewards_mean           6764.835860090473
total_rewards_std            61.89605896203413
total_rewards_max            6855.743306124078
total_rewards_min            6679.251136658741
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               31.777977966703475
(Previous) Eval Time (s)     27.85612461809069
Sample Time (s)              22.522625032346696
Epoch Time (s)               82.15672761714086
Total Train Time (s)         7103.869797238149
Epoch                        85
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:22.914260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #85 | Epoch Duration: 82.02155041694641
2020-01-11 11:29:22.914406 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.112228
Z variance train             0.021010736
KL Divergence                28.432049
KL Loss                      2.843205
QF Loss                      362.76715
VF Loss                      262.61792
Policy Loss                  -1937.0385
Q Predictions Mean           1936.4425
Q Predictions Std            690.8804
Q Predictions Max            2690.564
Q Predictions Min            191.97372
V Predictions Mean           1944.2379
V Predictions Std            684.3185
V Predictions Max            2680.6792
V Predictions Min            210.49422
Log Pis Mean                 2.432567
Log Pis Std                  4.0059767
Log Pis Max                  13.010123
Log Pis Min                  -6.674517
Policy mu Mean               -0.081043266
Policy mu Std                1.1618865
Policy mu Max                3.1702826
Policy mu Min                -2.7782154
Policy log std Mean          -0.6273359
Policy log std Std           0.348233
Policy log std Max           0.05909407
Policy log std Min           -2.234322
Z mean eval                  2.1126835
Z variance eval              0.018164866
total_rewards                [6839.03810333 6555.95161584 6741.67534627 6702.73312704 6481.94097652
 6802.65686198 2412.43893181 6631.2685094  6659.46165728 6629.65464334]
total_rewards_mean           6245.681977281837
total_rewards_std            1281.809701347207
total_rewards_max            6839.038103334925
total_rewards_min            2412.438931811393
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               31.26047171698883
(Previous) Eval Time (s)     27.720649952068925
Sample Time (s)              21.086291301529855
Epoch Time (s)               80.06741297058761
Total Train Time (s)         7183.523848954588
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:30:42.573019 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #86 | Epoch Duration: 79.65839886665344
2020-01-11 11:30:42.573401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1122093
Z variance train             0.018192524
KL Divergence                27.948612
KL Loss                      2.7948613
QF Loss                      475.8467
VF Loss                      118.64786
Policy Loss                  -1915.0682
Q Predictions Mean           1908.3127
Q Predictions Std            684.91095
Q Predictions Max            2626.552
Q Predictions Min            194.20831
V Predictions Mean           1911.2839
V Predictions Std            677.7635
V Predictions Max            2614.6887
V Predictions Min            201.56479
Log Pis Mean                 2.7419057
Log Pis Std                  4.2740397
Log Pis Max                  13.172458
Log Pis Min                  -6.4256954
Policy mu Mean               -0.06695369
Policy mu Std                1.2126532
Policy mu Max                2.609532
Policy mu Min                -2.8924427
Policy log std Mean          -0.5986962
Policy log std Std           0.3265152
Policy log std Max           0.03910461
Policy log std Min           -2.280141
Z mean eval                  2.1120822
Z variance eval              0.017669603
total_rewards                [6767.18419889 6949.36941714 6603.08756659 6880.87454639 6818.82063983
 6861.73579043 6695.86394742 7048.37480728 6714.21383405 6784.25004562]
total_rewards_mean           6812.377479363035
total_rewards_std            123.07659902729091
total_rewards_max            7048.374807279032
total_rewards_min            6603.087566592673
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               31.77444492187351
(Previous) Eval Time (s)     27.311299308668822
Sample Time (s)              23.21236277744174
Epoch Time (s)               82.29810700798407
Total Train Time (s)         7266.471374774817
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:05.521085 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #87 | Epoch Duration: 82.94746780395508
2020-01-11 11:32:05.521285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1124923
Z variance train             0.017688561
KL Divergence                28.207996
KL Loss                      2.8207996
QF Loss                      466.57025
VF Loss                      214.30792
Policy Loss                  -1963.8219
Q Predictions Mean           1958.6404
Q Predictions Std            730.1865
Q Predictions Max            2711.2788
Q Predictions Min            196.43704
V Predictions Mean           1954.2266
V Predictions Std            726.26306
V Predictions Max            2697.0273
V Predictions Min            204.41394
Log Pis Mean                 2.8433022
Log Pis Std                  4.665374
Log Pis Max                  15.240866
Log Pis Min                  -6.678838
Policy mu Mean               -0.08147884
Policy mu Std                1.2410358
Policy mu Max                3.1264265
Policy mu Min                -2.8271646
Policy log std Mean          -0.60500544
Policy log std Std           0.3651821
Policy log std Max           0.04102108
Policy log std Min           -2.2579112
Z mean eval                  2.1097808
Z variance eval              0.018948661
total_rewards                [6801.84851859 6812.16330308 6831.3982109  6889.64659081 6770.77880587
 6861.66577564 6805.52559288 6784.80240836 6722.74975077 6558.204185  ]
total_rewards_mean           6783.878314191641
total_rewards_std            87.13523771701067
total_rewards_max            6889.6465908081445
total_rewards_min            6558.204184998341
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               32.00230955518782
(Previous) Eval Time (s)     27.96031287126243
Sample Time (s)              22.048906228970736
Epoch Time (s)               82.01152865542099
Total Train Time (s)         7349.015656871721
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:28.067536 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #88 | Epoch Duration: 82.54603695869446
2020-01-11 11:33:28.067830 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.110106
Z variance train             0.018981364
KL Divergence                27.951036
KL Loss                      2.7951038
QF Loss                      506.87244
VF Loss                      153.84172
Policy Loss                  -2052.2905
Q Predictions Mean           2055.8228
Q Predictions Std            601.44
Q Predictions Max            2659.5276
Q Predictions Min            192.12689
V Predictions Mean           2056.56
V Predictions Std            596.3299
V Predictions Max            2655.185
V Predictions Min            201.69096
Log Pis Mean                 2.9147983
Log Pis Std                  3.9191172
Log Pis Max                  13.768966
Log Pis Min                  -6.5295362
Policy mu Mean               -0.007997685
Policy mu Std                1.2457504
Policy mu Max                3.5480807
Policy mu Min                -2.9732943
Policy log std Mean          -0.6226627
Policy log std Std           0.3603897
Policy log std Max           0.04567063
Policy log std Min           -2.1778457
Z mean eval                  2.1118426
Z variance eval              0.017422507
total_rewards                [6714.87013567 6884.98832926 7042.79497826 6684.55038662 6934.30109752
 6817.73004192 6931.20631787 6745.69504787 6900.6793934  6812.53539134]
total_rewards_mean           6846.93511197147
total_rewards_std            106.54943378546048
total_rewards_max            7042.7949782627975
total_rewards_min            6684.550386618351
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               31.466287653893232
(Previous) Eval Time (s)     28.494518701918423
Sample Time (s)              22.495821324177086
Epoch Time (s)               82.45662767998874
Total Train Time (s)         7431.434999479912
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:34:50.488458 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #89 | Epoch Duration: 82.42046403884888
2020-01-11 11:34:50.488647 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.112128
Z variance train             0.0174337
KL Divergence                28.180244
KL Loss                      2.8180244
QF Loss                      835.49347
VF Loss                      210.00035
Policy Loss                  -2045.658
Q Predictions Mean           2043.8903
Q Predictions Std            622.3102
Q Predictions Max            2718.1814
Q Predictions Min            197.03322
V Predictions Mean           2049.2231
V Predictions Std            617.7603
V Predictions Max            2730.426
V Predictions Min            199.60341
Log Pis Mean                 3.227231
Log Pis Std                  4.425824
Log Pis Max                  16.957983
Log Pis Min                  -6.6081724
Policy mu Mean               -0.055796485
Policy mu Std                1.2466598
Policy mu Max                4.330242
Policy mu Min                -2.9449768
Policy log std Mean          -0.6300986
Policy log std Std           0.3576951
Policy log std Max           0.03934647
Policy log std Min           -2.2321386
Z mean eval                  2.1186893
Z variance eval              0.017611785
total_rewards                [6813.48761313 6888.99163258 6868.36802793 7026.66711728 6733.32457812
 6878.95312789 6578.33334946 7078.17181731 6755.71313242 6867.10103369]
total_rewards_mean           6848.911142980379
total_rewards_std            135.6058052438946
total_rewards_max            7078.1718173113
total_rewards_min            6578.333349457154
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               32.455909995827824
(Previous) Eval Time (s)     28.45807777205482
Sample Time (s)              23.124376366380602
Epoch Time (s)               84.03836413426325
Total Train Time (s)         7513.782491726801
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:12.837426 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #90 | Epoch Duration: 82.34864473342896
2020-01-11 11:36:12.837620 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1175394
Z variance train             0.01759595
KL Divergence                27.9471
KL Loss                      2.79471
QF Loss                      287.48227
VF Loss                      91.46337
Policy Loss                  -2007.4587
Q Predictions Mean           2006.3157
Q Predictions Std            735.9497
Q Predictions Max            2759.633
Q Predictions Min            193.59557
V Predictions Mean           2004.6622
V Predictions Std            732.506
V Predictions Max            2738.8313
V Predictions Min            199.29922
Log Pis Mean                 2.6386476
Log Pis Std                  4.3377843
Log Pis Max                  13.914677
Log Pis Min                  -6.6948643
Policy mu Mean               -0.107962035
Policy mu Std                1.1910582
Policy mu Max                2.5565758
Policy mu Min                -2.6055024
Policy log std Mean          -0.6202526
Policy log std Std           0.35530874
Policy log std Max           0.056209266
Policy log std Min           -2.2930908
Z mean eval                  2.1202505
Z variance eval              0.013820967
total_rewards                [6779.09597663 7175.07871727 7330.15553361 7034.34727864 7026.51673566
 7067.17853818 7008.28033393 7209.93594539 6747.74496621 7007.16710751]
total_rewards_mean           7038.550113303012
total_rewards_std            169.6508686120331
total_rewards_max            7330.155533606854
total_rewards_min            6747.744966214429
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               32.23511420702562
(Previous) Eval Time (s)     26.76800780603662
Sample Time (s)              22.1454661404714
Epoch Time (s)               81.14858815353364
Total Train Time (s)         7596.685723581351
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:37:35.742533 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #91 | Epoch Duration: 82.90476846694946
2020-01-11 11:37:35.742737 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1204176
Z variance train             0.013808973
KL Divergence                28.360386
KL Loss                      2.8360386
QF Loss                      288.9018
VF Loss                      175.24768
Policy Loss                  -2019.5417
Q Predictions Mean           2013.7673
Q Predictions Std            714.5852
Q Predictions Max            2774.7124
Q Predictions Min            197.85751
V Predictions Mean           2011.8303
V Predictions Std            711.487
V Predictions Max            2777.704
V Predictions Min            192.47272
Log Pis Mean                 2.6169648
Log Pis Std                  4.2280393
Log Pis Max                  14.41494
Log Pis Min                  -6.1153097
Policy mu Mean               -0.06642738
Policy mu Std                1.1828641
Policy mu Max                3.0285776
Policy mu Min                -3.0315902
Policy log std Mean          -0.62903917
Policy log std Std           0.35726207
Policy log std Max           0.021601051
Policy log std Min           -2.2929173
Z mean eval                  2.1172786
Z variance eval              0.011871544
total_rewards                [6983.63347062 6778.27900534 6912.16333077 6863.20215314 6803.55488877
 6912.60340925 6486.79388735 7045.45568998 6738.74531046 6868.63059816]
total_rewards_mean           6839.306174385197
total_rewards_std            146.56720314263478
total_rewards_max            7045.455689981259
total_rewards_min            6486.793887354033
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               31.687888253014535
(Previous) Eval Time (s)     28.52386320894584
Sample Time (s)              23.23496784735471
Epoch Time (s)               83.44671930931509
Total Train Time (s)         7679.566983580124
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:38:58.625772 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #92 | Epoch Duration: 82.88286972045898
2020-01-11 11:38:58.626028 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1174304
Z variance train             0.011867834
KL Divergence                28.786076
KL Loss                      2.8786075
QF Loss                      445.09286
VF Loss                      276.53772
Policy Loss                  -2063.1572
Q Predictions Mean           2056.5977
Q Predictions Std            654.83716
Q Predictions Max            2736.2563
Q Predictions Min            178.22464
V Predictions Mean           2055.3574
V Predictions Std            651.06537
V Predictions Max            2759.9446
V Predictions Min            183.11778
Log Pis Mean                 2.8057919
Log Pis Std                  4.4714513
Log Pis Max                  16.774456
Log Pis Min                  -7.1423755
Policy mu Mean               -0.13472456
Policy mu Std                1.2428132
Policy mu Max                2.738569
Policy mu Min                -2.9618506
Policy log std Mean          -0.6322445
Policy log std Std           0.3479886
Policy log std Max           0.0012553483
Policy log std Min           -2.2436156
Z mean eval                  2.1072001
Z variance eval              0.008850307
total_rewards                [6715.22586402 6805.25555951 7102.4767276  6865.50750782 4256.57998419
 6900.19411248 7139.03480449 6662.16356179 7095.34320911 6910.89199455]
total_rewards_mean           6645.267332557145
total_rewards_std            810.9295937733664
total_rewards_max            7139.034804488825
total_rewards_min            4256.579984193225
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               32.32762238429859
(Previous) Eval Time (s)     27.95968560082838
Sample Time (s)              22.991132081951946
Epoch Time (s)               83.27844006707892
Total Train Time (s)         7761.746618331876
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:40:20.807412 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #93 | Epoch Duration: 82.18122458457947
2020-01-11 11:40:20.807636 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1078668
Z variance train             0.008865264
KL Divergence                29.469751
KL Loss                      2.9469752
QF Loss                      327.32654
VF Loss                      123.76684
Policy Loss                  -2007.035
Q Predictions Mean           2007.781
Q Predictions Std            749.353
Q Predictions Max            2741.1887
Q Predictions Min            186.55022
V Predictions Mean           2003.5571
V Predictions Std            746.2945
V Predictions Max            2705.4775
V Predictions Min            188.93533
Log Pis Mean                 2.8261132
Log Pis Std                  4.3259068
Log Pis Max                  15.593731
Log Pis Min                  -4.9157553
Policy mu Mean               -0.043644857
Policy mu Std                1.2247381
Policy mu Max                2.8771842
Policy mu Min                -3.3189218
Policy log std Mean          -0.6332294
Policy log std Std           0.36702898
Policy log std Max           -0.033600748
Policy log std Min           -2.2837336
Z mean eval                  2.1191444
Z variance eval              0.008026131
total_rewards                [6835.60011343 6733.46879938 7050.80796047 6929.79503593 6789.21743635
 6838.60736755 6934.29373986 6970.26275832 6822.22251711 6962.67082431]
total_rewards_mean           6886.69465527071
total_rewards_std            92.66723578910506
total_rewards_max            7050.807960468956
total_rewards_min            6733.468799378648
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               31.791734471917152
(Previous) Eval Time (s)     26.862084524706006
Sample Time (s)              21.60929848300293
Epoch Time (s)               80.26311747962609
Total Train Time (s)         7843.161450934596
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:41:42.224575 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #94 | Epoch Duration: 81.41675305366516
2020-01-11 11:41:42.224886 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1192627
Z variance train             0.008038575
KL Divergence                29.807312
KL Loss                      2.9807312
QF Loss                      320.82248
VF Loss                      251.53008
Policy Loss                  -2085.5803
Q Predictions Mean           2078.0361
Q Predictions Std            716.219
Q Predictions Max            2795.3025
Q Predictions Min            188.09776
V Predictions Mean           2075.9353
V Predictions Std            711.064
V Predictions Max            2792.8374
V Predictions Min            194.62733
Log Pis Mean                 2.8077197
Log Pis Std                  4.5463023
Log Pis Max                  16.072325
Log Pis Min                  -5.6628838
Policy mu Mean               -0.05699371
Policy mu Std                1.2296203
Policy mu Max                2.7341442
Policy mu Min                -2.5883276
Policy log std Mean          -0.64061135
Policy log std Std           0.37037396
Policy log std Max           -0.038245022
Policy log std Min           -2.4186273
Z mean eval                  2.1186175
Z variance eval              0.0071749003
total_rewards                [6851.31883071 7091.39425214 7224.73847447 7278.1994485  6995.87540857
 7378.25215714 7171.23371735 6852.40175692 7170.36554699 6838.76571899]
total_rewards_mean           7085.254531176998
total_rewards_std            183.0018607944202
total_rewards_max            7378.252157136382
total_rewards_min            6838.76571898508
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               31.90249383635819
(Previous) Eval Time (s)     28.01534418016672
Sample Time (s)              22.91089844563976
Epoch Time (s)               82.82873646216467
Total Train Time (s)         7925.049193513114
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:43:04.113324 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #95 | Epoch Duration: 81.8882155418396
2020-01-11 11:43:04.113497 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1162438
Z variance train             0.0071644313
KL Divergence                30.30085
KL Loss                      3.030085
QF Loss                      464.3106
VF Loss                      220.29218
Policy Loss                  -2092.5344
Q Predictions Mean           2091.3926
Q Predictions Std            669.70264
Q Predictions Max            2793.803
Q Predictions Min            181.58452
V Predictions Mean           2097.6978
V Predictions Std            669.6082
V Predictions Max            2777.4092
V Predictions Min            181.1402
Log Pis Mean                 2.2486963
Log Pis Std                  4.134164
Log Pis Max                  13.612854
Log Pis Min                  -5.9579945
Policy mu Mean               0.0090423245
Policy mu Std                1.1739162
Policy mu Max                2.730339
Policy mu Min                -2.6667879
Policy log std Mean          -0.6431652
Policy log std Std           0.3598806
Policy log std Max           -0.054006934
Policy log std Min           -2.2048943
Z mean eval                  2.134063
Z variance eval              0.005682435
total_rewards                [7055.40523255 7177.82566413 5143.05560085 7145.24726666 6993.00954606
 3477.99877738 7009.16716847 6717.94774776 6931.86664131 6934.35264699]
total_rewards_mean           6458.587629214582
total_rewards_std            1143.0611594456557
total_rewards_max            7177.825664131643
total_rewards_min            3477.99877737707
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               31.849084697198123
(Previous) Eval Time (s)     27.07452030479908
Sample Time (s)              22.555999418720603
Epoch Time (s)               81.4796044207178
Total Train Time (s)         8006.473046441097
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:44:25.539054 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #96 | Epoch Duration: 81.42540836334229
2020-01-11 11:44:25.539260 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1371675
Z variance train             0.00568719
KL Divergence                31.357662
KL Loss                      3.1357663
QF Loss                      280.57385
VF Loss                      356.23404
Policy Loss                  -2116.6597
Q Predictions Mean           2110.7603
Q Predictions Std            686.72235
Q Predictions Max            2871.4963
Q Predictions Min            197.71082
V Predictions Mean           2101.2236
V Predictions Std            682.7245
V Predictions Max            2860.786
V Predictions Min            195.21568
Log Pis Mean                 3.4897428
Log Pis Std                  4.1962047
Log Pis Max                  14.266742
Log Pis Min                  -5.5196714
Policy mu Mean               -0.09966087
Policy mu Std                1.268674
Policy mu Max                2.8053565
Policy mu Min                -3.0533977
Policy log std Mean          -0.65864867
Policy log std Std           0.3691005
Policy log std Max           0.033157796
Policy log std Min           -2.35281
Z mean eval                  2.1503696
Z variance eval              0.0053493693
total_rewards                [7078.17292316 7240.5019635  7238.84420118 7232.5832005  7460.92613744
 6996.14090442 7006.86617906 7327.31194015 7107.67501884 7109.62599625]
total_rewards_mean           7179.864846450076
total_rewards_std            139.58505800344452
total_rewards_max            7460.926137436067
total_rewards_min            6996.140904420887
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               31.98550223885104
(Previous) Eval Time (s)     27.020043678116053
Sample Time (s)              22.074924333952367
Epoch Time (s)               81.08047025091946
Total Train Time (s)         8088.1016197912395
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:47.169939 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #97 | Epoch Duration: 81.63052868843079
2020-01-11 11:45:47.170121 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.148963
Z variance train             0.0053339778
KL Divergence                31.565243
KL Loss                      3.1565244
QF Loss                      380.07614
VF Loss                      212.30496
Policy Loss                  -2134.048
Q Predictions Mean           2134.5652
Q Predictions Std            677.5153
Q Predictions Max            2860.344
Q Predictions Min            187.1003
V Predictions Mean           2143.7783
V Predictions Std            674.9054
V Predictions Max            2829.2566
V Predictions Min            184.64319
Log Pis Mean                 3.5662358
Log Pis Std                  4.3476176
Log Pis Max                  13.570621
Log Pis Min                  -7.1309032
Policy mu Mean               -0.1348129
Policy mu Std                1.2938145
Policy mu Max                3.1469343
Policy mu Min                -3.1639054
Policy log std Mean          -0.65423644
Policy log std Std           0.35299584
Policy log std Max           -0.06714463
Policy log std Min           -2.2436695
Z mean eval                  2.1320581
Z variance eval              0.004439346
total_rewards                [6892.44296666 7117.78435908 7267.55180856 6926.61496555 7159.47947329
 7104.77421176 7233.85590234 7052.7586227  6946.87606007 7134.1111035 ]
total_rewards_mean           7083.62494735283
total_rewards_std            121.31406359957607
total_rewards_max            7267.551808563098
total_rewards_min            6892.442966662097
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               31.792365617584437
(Previous) Eval Time (s)     27.569824036676437
Sample Time (s)              23.15028202859685
Epoch Time (s)               82.51247168285772
Total Train Time (s)         8170.449477254413
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:09.520762 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #98 | Epoch Duration: 82.35050177574158
2020-01-11 11:47:09.520954 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1291676
Z variance train             0.004429465
KL Divergence                32.194828
KL Loss                      3.219483
QF Loss                      450.18982
VF Loss                      631.0471
Policy Loss                  -2177.9539
Q Predictions Mean           2184.2803
Q Predictions Std            685.8927
Q Predictions Max            2875.6655
Q Predictions Min            175.13774
V Predictions Mean           2199.931
V Predictions Std            685.0158
V Predictions Max            2887.877
V Predictions Min            186.33867
Log Pis Mean                 3.176488
Log Pis Std                  4.6382437
Log Pis Max                  17.059273
Log Pis Min                  -9.317337
Policy mu Mean               -0.13251558
Policy mu Std                1.2626597
Policy mu Max                3.1459513
Policy mu Min                -2.9884877
Policy log std Mean          -0.64590496
Policy log std Std           0.3594624
Policy log std Max           -0.0053099394
Policy log std Min           -2.370951
Z mean eval                  2.131353
Z variance eval              0.0036839545
total_rewards                [6899.71682717 7320.73298889 7199.8930073  7163.88799184 6998.40959845
 7250.86717397 7302.9521925  7171.56097303 7046.77989204 7050.13059071]
total_rewards_mean           7140.493123590006
total_rewards_std            130.84768877513184
total_rewards_max            7320.732988893716
total_rewards_min            6899.716827168728
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               31.881872869096696
(Previous) Eval Time (s)     27.407501507084817
Sample Time (s)              23.42759629059583
Epoch Time (s)               82.71697066677734
Total Train Time (s)         8253.326687164139
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:32.399009 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #99 | Epoch Duration: 82.87791419029236
2020-01-11 11:48:32.399222 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.131139
Z variance train             0.0036748268
KL Divergence                32.50668
KL Loss                      3.250668
QF Loss                      574.34094
VF Loss                      239.89857
Policy Loss                  -2051.0068
Q Predictions Mean           2049.7236
Q Predictions Std            790.1528
Q Predictions Max            2877.0508
Q Predictions Min            177.79305
V Predictions Mean           2058.7808
V Predictions Std            785.891
V Predictions Max            2881.9502
V Predictions Min            181.6676
Log Pis Mean                 3.212482
Log Pis Std                  4.598144
Log Pis Max                  15.460869
Log Pis Min                  -9.032459
Policy mu Mean               -0.047839742
Policy mu Std                1.2521594
Policy mu Max                3.6966214
Policy mu Min                -5.0537553
Policy log std Mean          -0.6386722
Policy log std Std           0.35279524
Policy log std Max           0.016781896
Policy log std Min           -2.2599518
Z mean eval                  2.140799
Z variance eval              0.0036377453
total_rewards                [7227.34234386 7124.43252943 7157.90265136 7008.05203563 7132.55745653
 7211.51122127 7382.11657567 7156.16241376 7208.88108197 7139.78598931]
total_rewards_mean           7174.874429879261
total_rewards_std            90.6835696865784
total_rewards_max            7382.116575672344
total_rewards_min            7008.052035634384
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               32.35200693504885
(Previous) Eval Time (s)     27.5681062489748
Sample Time (s)              22.080661674495786
Epoch Time (s)               82.00077485851943
Total Train Time (s)         8335.207479867619
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:49:54.281880 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #100 | Epoch Duration: 81.88250160217285
2020-01-11 11:49:54.282112 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.137263
Z variance train             0.0036380868
KL Divergence                32.16594
KL Loss                      3.216594
QF Loss                      489.71283
VF Loss                      490.662
Policy Loss                  -2134.3386
Q Predictions Mean           2138.532
Q Predictions Std            714.7278
Q Predictions Max            2896.4895
Q Predictions Min            166.85074
V Predictions Mean           2152.772
V Predictions Std            714.1172
V Predictions Max            2901.6553
V Predictions Min            176.99907
Log Pis Mean                 3.1143703
Log Pis Std                  4.2532215
Log Pis Max                  13.659947
Log Pis Min                  -7.444617
Policy mu Mean               -0.073867775
Policy mu Std                1.2631724
Policy mu Max                2.997128
Policy mu Min                -2.9464452
Policy log std Mean          -0.6527584
Policy log std Std           0.36855367
Policy log std Max           0.0048601627
Policy log std Min           -2.3027902
Z mean eval                  2.1204114
Z variance eval              0.0051975
total_rewards                [7096.07603631 7304.90372859 7211.44010684 7172.73403248 7417.0705852
 7473.29884131 7046.34190952 7204.8240059  7351.21975079 7043.59483481]
total_rewards_mean           7232.150383176342
total_rewards_std            143.21968590248912
total_rewards_max            7473.298841310296
total_rewards_min            7043.594834810469
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               33.35786796268076
(Previous) Eval Time (s)     27.449537944048643
Sample Time (s)              22.00178477121517
Epoch Time (s)               82.80919067794457
Total Train Time (s)         8419.313698085956
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:18.390385 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #101 | Epoch Duration: 84.10811448097229
2020-01-11 11:51:18.390611 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1169312
Z variance train             0.0052031027
KL Divergence                31.4827
KL Loss                      3.1482701
QF Loss                      346.35223
VF Loss                      169.10416
Policy Loss                  -2219.5642
Q Predictions Mean           2219.6973
Q Predictions Std            636.3301
Q Predictions Max            2940.0
Q Predictions Min            171.89912
V Predictions Mean           2226.9697
V Predictions Std            631.1763
V Predictions Max            2926.5706
V Predictions Min            182.79803
Log Pis Mean                 3.003573
Log Pis Std                  4.415983
Log Pis Max                  15.49664
Log Pis Min                  -5.2680445
Policy mu Mean               -0.07170412
Policy mu Std                1.235413
Policy mu Max                2.7958124
Policy mu Min                -2.86961
Policy log std Mean          -0.6550223
Policy log std Std           0.36406028
Policy log std Max           0.0028227568
Policy log std Min           -2.1966865
Z mean eval                  2.1211767
Z variance eval              0.010084364
total_rewards                [7037.67945928 7430.45699401 7147.78068049 7077.46946984 7320.24929776
 7245.54356773 6999.79319027 7265.97780183 7075.99664207 7047.62483679]
total_rewards_mean           7164.857194007325
total_rewards_std            135.7990332650425
total_rewards_max            7430.456994005418
total_rewards_min            6999.79319026626
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               34.44724034098908
(Previous) Eval Time (s)     28.74812363088131
Sample Time (s)              23.831363868899643
Epoch Time (s)               87.02672784077004
Total Train Time (s)         8507.310651890468
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:52:46.389833 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #102 | Epoch Duration: 87.99907684326172
2020-01-11 11:52:46.390024 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #102 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1185086
Z variance train             0.010065323
KL Divergence                30.537508
KL Loss                      3.0537508
QF Loss                      363.68954
VF Loss                      117.62398
Policy Loss                  -2229.6921
Q Predictions Mean           2229.7937
Q Predictions Std            675.51654
Q Predictions Max            2885.7068
Q Predictions Min            178.32274
V Predictions Mean           2228.5193
V Predictions Std            674.758
V Predictions Max            2880.8413
V Predictions Min            173.64786
Log Pis Mean                 3.4511132
Log Pis Std                  4.364775
Log Pis Max                  14.622446
Log Pis Min                  -7.099739
Policy mu Mean               -0.09909111
Policy mu Std                1.2671685
Policy mu Max                2.7829292
Policy mu Min                -2.7473803
Policy log std Mean          -0.6473047
Policy log std Std           0.34630036
Policy log std Max           -0.07612109
Policy log std Min           -2.4121976
Z mean eval                  2.106296
Z variance eval              0.009802744
total_rewards                [7113.18753162 7426.62367965 7141.4547043  7345.4977043  7170.6601782
 7537.61384165 7426.6493299  7343.14136494 7083.99668239 7193.90916856]
total_rewards_mean           7278.273418551548
total_rewards_std            149.13809646831518
total_rewards_max            7537.613841654994
total_rewards_min            7083.996682387271
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               34.00727264303714
(Previous) Eval Time (s)     29.720013650134206
Sample Time (s)              24.55756931938231
Epoch Time (s)               88.28485561255366
Total Train Time (s)         8594.27070953697
Epoch                        103
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:54:13.351756 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #103 | Epoch Duration: 86.96158695220947
2020-01-11 11:54:13.351952 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #103 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1070285
Z variance train             0.009765396
KL Divergence                29.947784
KL Loss                      2.9947784
QF Loss                      338.114
VF Loss                      286.04062
Policy Loss                  -2113.373
Q Predictions Mean           2116.8232
Q Predictions Std            822.12726
Q Predictions Max            2933.0005
Q Predictions Min            185.27792
V Predictions Mean           2100.2634
V Predictions Std            818.3948
V Predictions Max            2890.8237
V Predictions Min            172.71957
Log Pis Mean                 2.7631838
Log Pis Std                  4.3388033
Log Pis Max                  14.716442
Log Pis Min                  -5.554622
Policy mu Mean               0.0071986
Policy mu Std                1.1983473
Policy mu Max                3.0830958
Policy mu Min                -2.8514168
Policy log std Mean          -0.6178236
Policy log std Std           0.36823186
Policy log std Max           -0.033277005
Policy log std Min           -2.2644005
Z mean eval                  2.1128974
Z variance eval              0.011359483
total_rewards                [7059.20889698 7427.5308194  7397.09379276 7350.16945831 7342.9628902
 7149.64614178 7305.72909953 7141.38206092 7490.09662668 7046.60521533]
total_rewards_mean           7271.042500187781
total_rewards_std            150.92828977607954
total_rewards_max            7490.0966266828955
total_rewards_min            7046.605215329578
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               34.184664546046406
(Previous) Eval Time (s)     28.39627891406417
Sample Time (s)              23.08108240040019
Epoch Time (s)               85.66202586051077
Total Train Time (s)         8680.394489575643
Epoch                        104
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:55:39.476173 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #104 | Epoch Duration: 86.12408566474915
2020-01-11 11:55:39.476320 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1126962
Z variance train             0.011354087
KL Divergence                29.984858
KL Loss                      2.9984858
QF Loss                      401.4806
VF Loss                      167.92606
Policy Loss                  -2196.6252
Q Predictions Mean           2197.8784
Q Predictions Std            753.9764
Q Predictions Max            2891.858
Q Predictions Min            169.8377
V Predictions Mean           2199.7842
V Predictions Std            751.18396
V Predictions Max            2887.9424
V Predictions Min            164.96953
Log Pis Mean                 3.0556073
Log Pis Std                  4.4909596
Log Pis Max                  15.20136
Log Pis Min                  -5.9642563
Policy mu Mean               -0.077390276
Policy mu Std                1.260786
Policy mu Max                3.2304842
Policy mu Min                -3.1529126
Policy log std Mean          -0.64260054
Policy log std Std           0.3673946
Policy log std Max           0.016211003
Policy log std Min           -2.4225721
Z mean eval                  2.1097214
Z variance eval              0.0081944475
total_rewards                [7495.04495877 7485.4193152  7699.20669265 7660.93403681 7601.81081139
 7453.04068446 7411.19260523 7635.50219021 7639.55123677 7627.52508351]
total_rewards_mean           7570.922761499535
total_rewards_std            94.90798099970795
total_rewards_max            7699.206692649361
total_rewards_min            7411.192605227635
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               34.14707150636241
(Previous) Eval Time (s)     28.857904695905745
Sample Time (s)              23.630060674156994
Epoch Time (s)               86.63503687642515
Total Train Time (s)         8766.770439348184
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:05.856328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #105 | Epoch Duration: 86.37984776496887
2020-01-11 11:57:05.856644 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1101084
Z variance train             0.008187551
KL Divergence                30.295332
KL Loss                      3.0295331
QF Loss                      388.31555
VF Loss                      164.54356
Policy Loss                  -2255.5042
Q Predictions Mean           2246.1108
Q Predictions Std            695.3236
Q Predictions Max            2916.2031
Q Predictions Min            172.19154
V Predictions Mean           2247.1262
V Predictions Std            694.957
V Predictions Max            2906.462
V Predictions Min            163.66127
Log Pis Mean                 3.3098376
Log Pis Std                  4.6179943
Log Pis Max                  16.971157
Log Pis Min                  -6.105455
Policy mu Mean               -0.14203691
Policy mu Std                1.245393
Policy mu Max                3.0177863
Policy mu Min                -2.7432668
Policy log std Mean          -0.63918823
Policy log std Std           0.3502886
Policy log std Max           0.008238822
Policy log std Min           -2.283938
Z mean eval                  2.095262
Z variance eval              0.04059807
total_rewards                [7266.99168518 7534.22600104 7335.08284463 7265.61446801 7158.20934963
 7239.09743025 7397.50628294 7381.47335685 7208.09847981 7203.70352608]
total_rewards_mean           7299.00034244197
total_rewards_std            107.71840185543418
total_rewards_max            7534.226001044297
total_rewards_min            7158.209349632185
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               33.779819475952536
(Previous) Eval Time (s)     28.602082048077136
Sample Time (s)              23.058954121544957
Epoch Time (s)               85.44085564557463
Total Train Time (s)         8852.270060225856
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:58:31.357175 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #106 | Epoch Duration: 85.50035738945007
2020-01-11 11:58:31.357383 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.096887
Z variance train             0.041200936
KL Divergence                29.510897
KL Loss                      2.9510896
QF Loss                      435.24957
VF Loss                      130.59377
Policy Loss                  -2267.9514
Q Predictions Mean           2270.836
Q Predictions Std            673.9038
Q Predictions Max            2933.276
Q Predictions Min            166.89392
V Predictions Mean           2270.0464
V Predictions Std            668.8757
V Predictions Max            2933.5588
V Predictions Min            173.94849
Log Pis Mean                 2.9219365
Log Pis Std                  4.3837347
Log Pis Max                  14.883076
Log Pis Min                  -8.072243
Policy mu Mean               -0.06263662
Policy mu Std                1.2403475
Policy mu Max                2.7912946
Policy mu Min                -2.7753944
Policy log std Mean          -0.66427964
Policy log std Std           0.3657315
Policy log std Max           -0.023473322
Policy log std Min           -2.4917445
Z mean eval                  2.110065
Z variance eval              0.03850005
total_rewards                [7042.28089531 7199.36306973 7487.29894194 7083.1903505  7061.10726149
 7106.20028341 7036.08925792 7064.27313291 7184.57379157 6957.45550965]
total_rewards_mean           7122.183249442574
total_rewards_std            138.9065593898401
total_rewards_max            7487.29894193724
total_rewards_min            6957.455509649512
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               34.783489307854325
(Previous) Eval Time (s)     28.66121829301119
Sample Time (s)              23.639052606653422
Epoch Time (s)               87.08376020751894
Total Train Time (s)         8940.213014943525
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:59.302917 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #107 | Epoch Duration: 87.94535422325134
2020-01-11 11:59:59.303284 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1122518
Z variance train             0.03854538
KL Divergence                29.685438
KL Loss                      2.9685438
QF Loss                      419.8003
VF Loss                      327.24115
Policy Loss                  -2178.456
Q Predictions Mean           2167.748
Q Predictions Std            699.14777
Q Predictions Max            2931.8936
Q Predictions Min            149.54788
V Predictions Mean           2165.563
V Predictions Std            691.4845
V Predictions Max            2930.138
V Predictions Min            158.81248
Log Pis Mean                 3.1352925
Log Pis Std                  4.456382
Log Pis Max                  13.170013
Log Pis Min                  -6.8989496
Policy mu Mean               -0.12077254
Policy mu Std                1.2631902
Policy mu Max                2.842502
Policy mu Min                -2.6692502
Policy log std Mean          -0.64496577
Policy log std Std           0.34558335
Policy log std Max           -0.045044303
Policy log std Min           -2.1963277
Z mean eval                  2.149693
Z variance eval              0.009720111
total_rewards                [7269.0269355  7511.68337783 7780.37946299 7560.96827885 7305.55452067
 7276.84506873 7554.11541697 7557.26837466 7306.04288581 7138.77855381]
total_rewards_mean           7426.066287582199
total_rewards_std            185.22108465979085
total_rewards_max            7780.3794629942095
total_rewards_min            7138.77855380896
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               34.006360894069076
(Previous) Eval Time (s)     29.522449960932136
Sample Time (s)              24.776930660475045
Epoch Time (s)               88.30574151547626
Total Train Time (s)         9026.360802510288
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:01:25.452563 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #108 | Epoch Duration: 86.1490683555603
2020-01-11 12:01:25.452815 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1500878
Z variance train             0.009722221
KL Divergence                31.468628
KL Loss                      3.1468627
QF Loss                      542.267
VF Loss                      113.64594
Policy Loss                  -2191.5027
Q Predictions Mean           2190.2854
Q Predictions Std            824.22015
Q Predictions Max            2988.3794
Q Predictions Min            154.43639
V Predictions Mean           2191.1694
V Predictions Std            820.74585
V Predictions Max            2977.3582
V Predictions Min            160.19589
Log Pis Mean                 3.163113
Log Pis Std                  4.3687115
Log Pis Max                  12.804199
Log Pis Min                  -6.0463285
Policy mu Mean               -0.059833843
Policy mu Std                1.2605726
Policy mu Max                2.8894713
Policy mu Min                -2.8688948
Policy log std Mean          -0.62063426
Policy log std Std           0.34014478
Policy log std Max           0.01679194
Policy log std Min           -2.195249
Z mean eval                  2.1309724
Z variance eval              0.010476066
total_rewards                [7110.2740164  7188.31157362 6942.48972325 6696.87810133 7015.37067782
 7332.66010995 7481.70183404 7248.71863941 7324.07205204 7324.38506716]
total_rewards_mean           7166.486179501716
total_rewards_std            219.24425577304612
total_rewards_max            7481.701834044574
total_rewards_min            6696.878101333877
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               34.381796058733016
(Previous) Eval Time (s)     27.365319018252194
Sample Time (s)              23.458883432671428
Epoch Time (s)               85.20599850965664
Total Train Time (s)         9113.569654759485
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:52.664361 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #109 | Epoch Duration: 87.21135258674622
2020-01-11 12:02:52.664716 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1322606
Z variance train             0.0104754735
KL Divergence                30.337208
KL Loss                      3.0337207
QF Loss                      436.74054
VF Loss                      321.33188
Policy Loss                  -2320.1653
Q Predictions Mean           2311.6775
Q Predictions Std            680.76337
Q Predictions Max            2949.6042
Q Predictions Min            168.14175
V Predictions Mean           2317.2646
V Predictions Std            676.6763
V Predictions Max            2954.089
V Predictions Min            162.77443
Log Pis Mean                 3.1494603
Log Pis Std                  4.399215
Log Pis Max                  15.787262
Log Pis Min                  -8.497261
Policy mu Mean               -0.08499023
Policy mu Std                1.2471751
Policy mu Max                3.7374082
Policy mu Min                -3.1960382
Policy log std Mean          -0.64397174
Policy log std Std           0.3569181
Policy log std Max           0.04184243
Policy log std Min           -2.2648249
Z mean eval                  2.1494312
Z variance eval              0.009230427
total_rewards                [7410.94248404 7901.22444622 7581.64811442 7649.40208446 7391.39969899
 7486.57584616 7548.10861527 7515.72745003 7557.45377383 7329.71765727]
total_rewards_mean           7537.22001706827
total_rewards_std            151.9471734932087
total_rewards_max            7901.224446224628
total_rewards_min            7329.717657268471
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               33.58071416430175
(Previous) Eval Time (s)     29.370236618909985
Sample Time (s)              23.790479606948793
Epoch Time (s)               86.74143039016053
Total Train Time (s)         9199.382819779217
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:04:18.479294 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #110 | Epoch Duration: 85.81439399719238
2020-01-11 12:04:18.479504 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1509123
Z variance train             0.009226255
KL Divergence                30.31403
KL Loss                      3.031403
QF Loss                      475.03714
VF Loss                      116.80836
Policy Loss                  -2306.9548
Q Predictions Mean           2305.411
Q Predictions Std            779.14246
Q Predictions Max            3042.805
Q Predictions Min            159.17107
V Predictions Mean           2307.392
V Predictions Std            778.1978
V Predictions Max            3060.7253
V Predictions Min            167.01123
Log Pis Mean                 4.106906
Log Pis Std                  4.8126283
Log Pis Max                  15.842436
Log Pis Min                  -5.982725
Policy mu Mean               -0.093729
Policy mu Std                1.3142086
Policy mu Max                2.9010594
Policy mu Min                -2.9167616
Policy log std Mean          -0.64378065
Policy log std Std           0.3620565
Policy log std Max           -0.025357336
Policy log std Min           -2.3988056
Z mean eval                  2.1385007
Z variance eval              0.018369805
total_rewards                [7338.56976998 7593.3225492  7557.56389928 7307.87774659 7256.93559413
 7641.40468065 7175.28000583 7472.94346339 7408.10199588 7366.28167047]
total_rewards_mean           7411.8281375407805
total_rewards_std            144.50853314756424
total_rewards_max            7641.404680651087
total_rewards_min            7175.280005828779
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               31.93513130908832
(Previous) Eval Time (s)     28.4428558209911
Sample Time (s)              21.790069838054478
Epoch Time (s)               82.1680569681339
Total Train Time (s)         9282.141971101053
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:41.255237 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #111 | Epoch Duration: 82.77557325363159
2020-01-11 12:05:41.255420 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1355731
Z variance train             0.01845999
KL Divergence                28.22334
KL Loss                      2.822334
QF Loss                      698.6847
VF Loss                      235.12639
Policy Loss                  -2323.7397
Q Predictions Mean           2320.0369
Q Predictions Std            701.5083
Q Predictions Max            3060.404
Q Predictions Min            156.99994
V Predictions Mean           2332.276
V Predictions Std            700.72266
V Predictions Max            3081.8171
V Predictions Min            163.65865
Log Pis Mean                 3.5314102
Log Pis Std                  4.146191
Log Pis Max                  12.478049
Log Pis Min                  -5.905792
Policy mu Mean               -0.087601684
Policy mu Std                1.2884964
Policy mu Max                3.0241313
Policy mu Min                -2.5319161
Policy log std Mean          -0.6545729
Policy log std Std           0.36815608
Policy log std Max           -0.10518041
Policy log std Min           -2.4717531
Z mean eval                  2.1263278
Z variance eval              0.07237793
total_rewards                [7508.97389381 7683.48736609 7668.00839604 7656.18637422 7702.22575994
 7610.4003947  7411.93828888 7421.20731451 7485.01578733 7839.43160801]
total_rewards_mean           7598.687518353663
total_rewards_std            130.94345598847494
total_rewards_max            7839.431608013015
total_rewards_min            7411.938288878392
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               32.07003004895523
(Previous) Eval Time (s)     29.05005435924977
Sample Time (s)              22.26452341163531
Epoch Time (s)               83.38460781984031
Total Train Time (s)         9364.94206942711
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:07:04.041928 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #112 | Epoch Duration: 82.78637194633484
2020-01-11 12:07:04.042115 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1255012
Z variance train             0.07253233
KL Divergence                27.594051
KL Loss                      2.7594051
QF Loss                      722.95123
VF Loss                      323.3188
Policy Loss                  -2295.397
Q Predictions Mean           2288.9878
Q Predictions Std            766.8266
Q Predictions Max            3029.2751
Q Predictions Min            144.04811
V Predictions Mean           2285.996
V Predictions Std            762.952
V Predictions Max            3003.464
V Predictions Min            150.39314
Log Pis Mean                 3.8741899
Log Pis Std                  4.423392
Log Pis Max                  16.436085
Log Pis Min                  -6.2528644
Policy mu Mean               -0.19308896
Policy mu Std                1.3314401
Policy mu Max                3.2212152
Policy mu Min                -3.2202108
Policy log std Mean          -0.64146364
Policy log std Std           0.35202777
Policy log std Max           0.007009983
Policy log std Min           -2.2213311
Z mean eval                  2.1594284
Z variance eval              0.03528331
total_rewards                [7526.59799172 7420.83608399 7026.77649788 7600.56338907  784.91780135
 7516.07841832 7561.65901374 7433.14114581 7321.06056313 7565.60694412]
total_rewards_mean           6775.723784914667
total_rewards_std            2003.308525494748
total_rewards_max            7600.563389073999
total_rewards_min            784.9178013546275
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               31.73837530054152
(Previous) Eval Time (s)     28.45150250289589
Sample Time (s)              22.683589450083673
Epoch Time (s)               82.87346725352108
Total Train Time (s)         9446.612814343069
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:08:25.713277 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #113 | Epoch Duration: 81.67098832130432
2020-01-11 12:08:25.713423 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1590898
Z variance train             0.035337083
KL Divergence                28.689764
KL Loss                      2.8689764
QF Loss                      352.23053
VF Loss                      223.04655
Policy Loss                  -2406.429
Q Predictions Mean           2409.4817
Q Predictions Std            708.21387
Q Predictions Max            3114.1982
Q Predictions Min            165.5045
V Predictions Mean           2405.2268
V Predictions Std            705.40735
V Predictions Max            3107.8748
V Predictions Min            170.6744
Log Pis Mean                 3.5988455
Log Pis Std                  4.2451525
Log Pis Max                  14.981598
Log Pis Min                  -7.4913607
Policy mu Mean               -0.009034869
Policy mu Std                1.2759578
Policy mu Max                3.0347803
Policy mu Min                -2.726309
Policy log std Mean          -0.65901405
Policy log std Std           0.36898822
Policy log std Max           0.0045678318
Policy log std Min           -2.2644408
Z mean eval                  2.144406
Z variance eval              0.026352052
total_rewards                [7456.91857808 7611.25785799 7394.77075579 7704.47061088 7683.77381022
 7902.03192819 7458.48265036 7898.24934662 7520.51377    7858.62842472]
total_rewards_mean           7648.909773285304
total_rewards_std            181.6971153914399
total_rewards_max            7902.031928187303
total_rewards_min            7394.770755794435
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               32.58432270120829
(Previous) Eval Time (s)     27.248720303643495
Sample Time (s)              21.70526448637247
Epoch Time (s)               81.53830749122426
Total Train Time (s)         9529.647103800438
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:09:48.750664 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #114 | Epoch Duration: 83.03710699081421
2020-01-11 12:09:48.750881 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #114 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1429608
Z variance train             0.026342865
KL Divergence                28.007057
KL Loss                      2.8007057
QF Loss                      529.9026
VF Loss                      222.46034
Policy Loss                  -2315.4573
Q Predictions Mean           2317.126
Q Predictions Std            748.0376
Q Predictions Max            3078.0469
Q Predictions Min            155.15051
V Predictions Mean           2319.1604
V Predictions Std            746.3554
V Predictions Max            3033.578
V Predictions Min            156.50874
Log Pis Mean                 3.3010983
Log Pis Std                  4.543342
Log Pis Max                  14.195842
Log Pis Min                  -7.350049
Policy mu Mean               -0.1349045
Policy mu Std                1.2720443
Policy mu Max                3.7773933
Policy mu Min                -2.8201857
Policy log std Mean          -0.6450735
Policy log std Std           0.351397
Policy log std Max           -0.018994838
Policy log std Min           -2.329298
Z mean eval                  2.1672196
Z variance eval              0.030491525
total_rewards                [7389.10326874 7377.48118158 7722.08784378 7679.9598871  7735.5752469
 7947.98033704 7663.10609671 7268.07788803 7576.92504352 7545.03130575]
total_rewards_mean           7590.532809915579
total_rewards_std            192.76266376691282
total_rewards_max            7947.9803370390355
total_rewards_min            7268.0778880336775
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               32.1136109828949
(Previous) Eval Time (s)     28.747202422935516
Sample Time (s)              22.124507736880332
Epoch Time (s)               82.98532114271075
Total Train Time (s)         9610.944065124262
Epoch                        115
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:10.064147 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #115 | Epoch Duration: 81.31309604644775
2020-01-11 12:11:10.064427 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.166699
Z variance train             0.030564994
KL Divergence                28.413616
KL Loss                      2.8413618
QF Loss                      518.5525
VF Loss                      147.1306
Policy Loss                  -2352.0217
Q Predictions Mean           2343.3271
Q Predictions Std            747.1976
Q Predictions Max            3112.5164
Q Predictions Min            154.86742
V Predictions Mean           2345.8267
V Predictions Std            743.34296
V Predictions Max            3097.377
V Predictions Min            163.76198
Log Pis Mean                 3.3147008
Log Pis Std                  4.5653906
Log Pis Max                  15.8278055
Log Pis Min                  -5.8372893
Policy mu Mean               -0.027875898
Policy mu Std                1.2779633
Policy mu Max                2.9703162
Policy mu Min                -3.1395283
Policy log std Mean          -0.6682063
Policy log std Std           0.3874564
Policy log std Max           0.0154545605
Policy log std Min           -2.7174525
Z mean eval                  2.1401494
Z variance eval              0.023749918
total_rewards                [7373.57146268 7549.53692103 7584.10930499 7647.21837991 7725.99937749
 7490.91287627 7396.47495376 7390.76454638 7576.31709766 7516.29413311]
total_rewards_mean           7525.119905326277
total_rewards_std            109.89700808892283
total_rewards_max            7725.999377489779
total_rewards_min            7373.571462675387
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               32.49827014096081
(Previous) Eval Time (s)     27.074641888961196
Sample Time (s)              22.076462081633508
Epoch Time (s)               81.64937411155552
Total Train Time (s)         9693.638220705092
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:12:32.746686 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #116 | Epoch Duration: 82.68205499649048
2020-01-11 12:12:32.746883 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.140013
Z variance train             0.023713032
KL Divergence                27.795218
KL Loss                      2.7795217
QF Loss                      324.84848
VF Loss                      220.01105
Policy Loss                  -2375.778
Q Predictions Mean           2371.7883
Q Predictions Std            732.4757
Q Predictions Max            3190.255
Q Predictions Min            163.22998
V Predictions Mean           2365.7659
V Predictions Std            731.0529
V Predictions Max            3177.6418
V Predictions Min            146.25775
Log Pis Mean                 3.4242613
Log Pis Std                  4.330859
Log Pis Max                  18.024483
Log Pis Min                  -7.091023
Policy mu Mean               -0.10029149
Policy mu Std                1.2815934
Policy mu Max                3.6735494
Policy mu Min                -2.852701
Policy log std Mean          -0.636404
Policy log std Std           0.3551131
Policy log std Max           0.04967022
Policy log std Min           -2.3966842
Z mean eval                  2.1236436
Z variance eval              0.030370152
total_rewards                [7094.14086389 6956.61885004 7232.70830602 7179.98434034 7210.74068818
 7293.94971708 7298.88162312 7130.27050971 7512.41329858 7263.54324892]
total_rewards_mean           7217.325144588137
total_rewards_std            139.33086411803507
total_rewards_max            7512.41329857616
total_rewards_min            6956.6188500378
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               31.97789427312091
(Previous) Eval Time (s)     28.10699481703341
Sample Time (s)              23.36145328031853
Epoch Time (s)               83.44634237047285
Total Train Time (s)         9776.16332501173
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:13:55.273240 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #117 | Epoch Duration: 82.5262131690979
2020-01-11 12:13:55.273449 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1248085
Z variance train             0.030241128
KL Divergence                27.023613
KL Loss                      2.7023613
QF Loss                      478.9682
VF Loss                      213.45969
Policy Loss                  -2341.7983
Q Predictions Mean           2330.7517
Q Predictions Std            724.29865
Q Predictions Max            3012.2678
Q Predictions Min            152.05907
V Predictions Mean           2335.854
V Predictions Std            723.7485
V Predictions Max            3030.556
V Predictions Min            151.6353
Log Pis Mean                 3.6820002
Log Pis Std                  4.81591
Log Pis Max                  19.693758
Log Pis Min                  -6.324106
Policy mu Mean               -0.0818796
Policy mu Std                1.3036859
Policy mu Max                3.67282
Policy mu Min                -4.4581013
Policy log std Mean          -0.65584546
Policy log std Std           0.35120735
Policy log std Max           0.06569767
Policy log std Min           -2.2111728
Z mean eval                  2.1442418
Z variance eval              0.032032073
total_rewards                [7015.57949991 7584.73680885 7266.17355138 7632.92153587 7353.85207272
 7432.9831967  7528.10498244 7450.22539977 7698.85659955 7299.04190254]
total_rewards_mean           7426.2475549724595
total_rewards_std            192.05161611917384
total_rewards_max            7698.856599548134
total_rewards_min            7015.579499905669
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               31.902583480346948
(Previous) Eval Time (s)     27.186499509960413
Sample Time (s)              22.523742003832012
Epoch Time (s)               81.61282499413937
Total Train Time (s)         9859.202987961471
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:15:18.317425 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #118 | Epoch Duration: 83.04383039474487
2020-01-11 12:15:18.317602 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.142915
Z variance train             0.032176126
KL Divergence                27.232662
KL Loss                      2.7232664
QF Loss                      599.9242
VF Loss                      248.53967
Policy Loss                  -2428.552
Q Predictions Mean           2426.7617
Q Predictions Std            677.93195
Q Predictions Max            3093.9102
Q Predictions Min            137.43947
V Predictions Mean           2431.7217
V Predictions Std            671.9735
V Predictions Max            3100.5488
V Predictions Min            153.88716
Log Pis Mean                 3.638464
Log Pis Std                  4.3956985
Log Pis Max                  14.92223
Log Pis Min                  -8.168527
Policy mu Mean               -0.06799839
Policy mu Std                1.3026059
Policy mu Max                2.9740832
Policy mu Min                -2.7027028
Policy log std Mean          -0.6702903
Policy log std Std           0.36021549
Policy log std Max           -0.020496786
Policy log std Min           -2.1766102
Z mean eval                  2.163973
Z variance eval              0.028902596
total_rewards                [7641.68410075 7894.56245001 7947.85026302 7728.4557448  7771.97416162
 7430.9892206  7772.72463099 8008.85295461 7655.7975318  7771.29311321]
total_rewards_mean           7762.418417142384
total_rewards_std            158.0496284247883
total_rewards_max            8008.852954614325
total_rewards_min            7430.989220600062
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               32.05728844227269
(Previous) Eval Time (s)     28.6171563831158
Sample Time (s)              22.346906901337206
Epoch Time (s)               83.0213517267257
Total Train Time (s)         9942.722405671142
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:41.837914 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #119 | Epoch Duration: 83.52016758918762
2020-01-11 12:16:41.838188 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1602707
Z variance train             0.028858488
KL Divergence                27.296791
KL Loss                      2.729679
QF Loss                      401.2388
VF Loss                      510.7658
Policy Loss                  -2362.0732
Q Predictions Mean           2366.3262
Q Predictions Std            804.5355
Q Predictions Max            3156.0527
Q Predictions Min            112.66487
V Predictions Mean           2380.247
V Predictions Std            807.25476
V Predictions Max            3166.221
V Predictions Min            161.13603
Log Pis Mean                 3.705635
Log Pis Std                  4.6241894
Log Pis Max                  15.8421
Log Pis Min                  -5.207158
Policy mu Mean               -0.08613255
Policy mu Std                1.3001207
Policy mu Max                3.238702
Policy mu Min                -3.1809554
Policy log std Mean          -0.6720298
Policy log std Std           0.37692523
Policy log std Max           0.07308251
Policy log std Min           -2.2911768
Z mean eval                  2.161359
Z variance eval              0.03745121
total_rewards                [1670.06486198 7887.85652497 7838.66724746 7660.85296517 7786.61000705
 7739.99749694 7577.82909044 7823.07193376 7573.41005468 7856.44628089]
total_rewards_mean           7141.480646333126
total_rewards_std            1826.9210227176288
total_rewards_max            7887.856524966769
total_rewards_min            1670.0648619832155
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               32.233737925067544
(Previous) Eval Time (s)     29.11563022620976
Sample Time (s)              22.272349659353495
Epoch Time (s)               83.6217178106308
Total Train Time (s)         10025.5637827022
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:18:04.678007 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #120 | Epoch Duration: 82.83962345123291
2020-01-11 12:18:04.678137 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1615384
Z variance train             0.037366137
KL Divergence                27.223349
KL Loss                      2.7223349
QF Loss                      493.4255
VF Loss                      116.13165
Policy Loss                  -2399.9343
Q Predictions Mean           2400.5347
Q Predictions Std            717.86743
Q Predictions Max            3130.753
Q Predictions Min            142.47969
V Predictions Mean           2403.6807
V Predictions Std            714.3444
V Predictions Max            3133.4565
V Predictions Min            147.08215
Log Pis Mean                 3.5403497
Log Pis Std                  4.5292826
Log Pis Max                  13.945557
Log Pis Min                  -7.399075
Policy mu Mean               -0.10427099
Policy mu Std                1.2915564
Policy mu Max                3.1460598
Policy mu Min                -2.8937132
Policy log std Mean          -0.6493683
Policy log std Std           0.360737
Policy log std Max           0.023186922
Policy log std Min           -2.4276505
Z mean eval                  2.166556
Z variance eval              0.028832573
total_rewards                [7768.19847141 7747.50659594 7668.43532834 7374.96079382 7875.80072032
 7588.43056421 7576.55682443 7521.63314238 7827.77809117 7818.90093491]
total_rewards_mean           7676.820146693162
total_rewards_std            151.34494536750242
total_rewards_max            7875.800720319751
total_rewards_min            7374.960793822822
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               31.633822922129184
(Previous) Eval Time (s)     28.333247672766447
Sample Time (s)              22.70806915126741
Epoch Time (s)               82.67513974616304
Total Train Time (s)         10108.172321683262
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:27.288362 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #121 | Epoch Duration: 82.61009097099304
2020-01-11 12:19:27.288658 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1669364
Z variance train             0.028765962
KL Divergence                27.72247
KL Loss                      2.772247
QF Loss                      483.68976
VF Loss                      260.29395
Policy Loss                  -2445.991
Q Predictions Mean           2449.4014
Q Predictions Std            650.5726
Q Predictions Max            3113.2083
Q Predictions Min            163.05203
V Predictions Mean           2438.819
V Predictions Std            648.2336
V Predictions Max            3088.8696
V Predictions Min            141.6081
Log Pis Mean                 3.9256926
Log Pis Std                  4.2858915
Log Pis Max                  14.054834
Log Pis Min                  -5.445697
Policy mu Mean               -0.08777684
Policy mu Std                1.3004625
Policy mu Max                3.1136425
Policy mu Min                -2.83485
Policy log std Mean          -0.6886563
Policy log std Std           0.37058768
Policy log std Max           0.026530385
Policy log std Min           -2.567794
Z mean eval                  2.1651862
Z variance eval              0.022629252
total_rewards                [7641.04870339 7881.64989157 7788.48949085 7700.76540655 7869.69252472
 7797.97736464 7750.3407883  7908.42127357 7963.95271762 7801.34298356]
total_rewards_mean           7810.368114476305
total_rewards_std            93.16752868474026
total_rewards_max            7963.952717622465
total_rewards_min            7641.048703387032
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               31.718963470775634
(Previous) Eval Time (s)     28.267850168980658
Sample Time (s)              21.725071489810944
Epoch Time (s)               81.71188512956724
Total Train Time (s)         10189.474520849064
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:20:48.591644 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #122 | Epoch Duration: 81.30278396606445
2020-01-11 12:20:48.591789 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1675887
Z variance train             0.022673242
KL Divergence                27.969124
KL Loss                      2.7969124
QF Loss                      343.4251
VF Loss                      232.29019
Policy Loss                  -2507.861
Q Predictions Mean           2502.7715
Q Predictions Std            729.1567
Q Predictions Max            3235.6135
Q Predictions Min            144.80428
V Predictions Mean           2495.6082
V Predictions Std            721.66144
V Predictions Max            3201.9722
V Predictions Min            151.91975
Log Pis Mean                 3.9773197
Log Pis Std                  4.1661787
Log Pis Max                  14.810989
Log Pis Min                  -5.9714284
Policy mu Mean               -0.060611084
Policy mu Std                1.3432254
Policy mu Max                2.8210905
Policy mu Min                -3.023932
Policy log std Mean          -0.6700917
Policy log std Std           0.38071197
Policy log std Max           0.018575013
Policy log std Min           -2.4792962
Z mean eval                  2.158179
Z variance eval              0.022369374
total_rewards                [7569.42945748 7521.61936796 7662.41411332 7605.22178639 7673.95936073
 7539.21259328 7713.16769686 7389.85814552 7572.85418923 7618.50869766]
total_rewards_mean           7586.62454084272
total_rewards_std            87.42020960175738
total_rewards_max            7713.167696860186
total_rewards_min            7389.858145524164
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               31.900997004006058
(Previous) Eval Time (s)     27.858421981334686
Sample Time (s)              23.19695779355243
Epoch Time (s)               82.95637677889317
Total Train Time (s)         10272.593683172483
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:11.714766 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #123 | Epoch Duration: 83.12278199195862
2020-01-11 12:22:11.715079 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1583824
Z variance train             0.022367457
KL Divergence                28.011662
KL Loss                      2.8011663
QF Loss                      379.68927
VF Loss                      152.9073
Policy Loss                  -2477.808
Q Predictions Mean           2475.121
Q Predictions Std            757.524
Q Predictions Max            3194.2378
Q Predictions Min            146.45087
V Predictions Mean           2482.6062
V Predictions Std            755.21204
V Predictions Max            3197.0005
V Predictions Min            149.76118
Log Pis Mean                 3.753213
Log Pis Std                  4.49923
Log Pis Max                  14.227472
Log Pis Min                  -8.425393
Policy mu Mean               -0.08532071
Policy mu Std                1.3291787
Policy mu Max                2.9437695
Policy mu Min                -3.0960083
Policy log std Mean          -0.66863745
Policy log std Std           0.38493922
Policy log std Max           -0.019096792
Policy log std Min           -2.5060906
Z mean eval                  2.1611867
Z variance eval              0.022162767
total_rewards                [7506.01897348 7785.45865677 7848.43541352 7670.12277356 7976.60466923
 7832.07810446 7630.69376134 7733.10958317 7787.92228522 7860.19480731]
total_rewards_mean           7763.0639028051755
total_rewards_std            127.01734346316492
total_rewards_max            7976.604669227559
total_rewards_min            7506.018973476086
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               32.02152909198776
(Previous) Eval Time (s)     28.024450284894556
Sample Time (s)              22.444499496836215
Epoch Time (s)               82.49047887371853
Total Train Time (s)         10354.931254369672
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:23:34.053872 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #124 | Epoch Duration: 82.33848881721497
2020-01-11 12:23:34.054080 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1608572
Z variance train             0.022153946
KL Divergence                28.166801
KL Loss                      2.8166802
QF Loss                      363.5307
VF Loss                      164.76459
Policy Loss                  -2548.734
Q Predictions Mean           2549.0957
Q Predictions Std            724.4027
Q Predictions Max            3276.55
Q Predictions Min            147.92834
V Predictions Mean           2548.504
V Predictions Std            720.96655
V Predictions Max            3263.4514
V Predictions Min            155.44008
Log Pis Mean                 3.6401284
Log Pis Std                  4.2937927
Log Pis Max                  16.123154
Log Pis Min                  -5.25014
Policy mu Mean               -0.10102471
Policy mu Std                1.3115661
Policy mu Max                3.5708656
Policy mu Min                -2.7394338
Policy log std Mean          -0.6572583
Policy log std Std           0.36736044
Policy log std Max           0.07411778
Policy log std Min           -2.595261
Z mean eval                  2.1855383
Z variance eval              0.017542686
total_rewards                [7900.35309413 7638.18243217 7950.30773248 7682.0755332  7651.15239274
 7767.43930253 7836.05726565 7736.93384004 7946.70313695 7638.91278255]
total_rewards_mean           7774.811751244479
total_rewards_std            119.3205608777489
total_rewards_max            7950.307732476468
total_rewards_min            7638.182432166923
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               32.161142848897725
(Previous) Eval Time (s)     27.872199334204197
Sample Time (s)              22.375892338808626
Epoch Time (s)               82.40923452191055
Total Train Time (s)         10437.237067535985
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:24:56.362875 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #125 | Epoch Duration: 82.30854797363281
2020-01-11 12:24:56.363318 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1862042
Z variance train             0.017526515
KL Divergence                28.95858
KL Loss                      2.895858
QF Loss                      472.78363
VF Loss                      195.39989
Policy Loss                  -2495.0303
Q Predictions Mean           2497.3833
Q Predictions Std            757.35474
Q Predictions Max            3268.611
Q Predictions Min            140.42471
V Predictions Mean           2502.8516
V Predictions Std            757.9763
V Predictions Max            3247.23
V Predictions Min            141.71968
Log Pis Mean                 3.786283
Log Pis Std                  4.1812944
Log Pis Max                  15.40319
Log Pis Min                  -6.0013056
Policy mu Mean               -0.13535248
Policy mu Std                1.2990096
Policy mu Max                2.8774095
Policy mu Min                -3.786364
Policy log std Mean          -0.6798355
Policy log std Std           0.38679394
Policy log std Max           0.04966098
Policy log std Min           -2.416494
Z mean eval                  2.158931
Z variance eval              0.019582726
total_rewards                [7183.76126148 7534.87593825 7377.10301487 7974.69601064 7523.60203838
 7750.1305903  7701.22382803 7604.6092168  7563.93823029 7590.9114624 ]
total_rewards_mean           7580.485159144186
total_rewards_std            200.94628903415756
total_rewards_max            7974.696010637538
total_rewards_min            7183.761261483706
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               31.755634099710733
(Previous) Eval Time (s)     27.77115014800802
Sample Time (s)              20.634361669886857
Epoch Time (s)               80.16114591760561
Total Train Time (s)         10517.300397719722
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:26:16.426055 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #126 | Epoch Duration: 80.0624623298645
2020-01-11 12:26:16.426191 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1568856
Z variance train             0.019552493
KL Divergence                28.229713
KL Loss                      2.8229713
QF Loss                      616.3839
VF Loss                      487.9043
Policy Loss                  -2451.4524
Q Predictions Mean           2450.3145
Q Predictions Std            766.3673
Q Predictions Max            3219.5278
Q Predictions Min            139.47939
V Predictions Mean           2462.5503
V Predictions Std            760.4519
V Predictions Max            3219.7705
V Predictions Min            152.21211
Log Pis Mean                 3.4882557
Log Pis Std                  4.645358
Log Pis Max                  16.348852
Log Pis Min                  -6.896637
Policy mu Mean               -0.15351354
Policy mu Std                1.2808789
Policy mu Max                3.5147452
Policy mu Min                -3.3616762
Policy log std Mean          -0.6643668
Policy log std Std           0.3720756
Policy log std Max           -0.021333754
Policy log std Min           -2.6209126
Z mean eval                  2.1848404
Z variance eval              0.0146914525
total_rewards                [7665.51673957 7996.26428224 7917.98592376 7785.54545286 7956.04141808
 7726.39150836 7549.55906913 7840.61620286 7929.07260121 7789.35055474]
total_rewards_mean           7815.63437528122
total_rewards_std            133.8660928336053
total_rewards_max            7996.264282237264
total_rewards_min            7549.559069130345
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               32.06702484516427
(Previous) Eval Time (s)     27.67221516976133
Sample Time (s)              23.030520821455866
Epoch Time (s)               82.76976083638147
Total Train Time (s)         10599.788477720227
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:38.918540 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #127 | Epoch Duration: 82.4921522140503
2020-01-11 12:27:38.918878 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.186056
Z variance train             0.014709538
KL Divergence                29.431313
KL Loss                      2.9431312
QF Loss                      347.77133
VF Loss                      105.075
Policy Loss                  -2509.9248
Q Predictions Mean           2510.8784
Q Predictions Std            730.0727
Q Predictions Max            3281.5493
Q Predictions Min            135.64326
V Predictions Mean           2508.6826
V Predictions Std            725.0124
V Predictions Max            3267.8672
V Predictions Min            140.59537
Log Pis Mean                 3.5548878
Log Pis Std                  4.439563
Log Pis Max                  16.564537
Log Pis Min                  -6.9519835
Policy mu Mean               -0.11658005
Policy mu Std                1.2975591
Policy mu Max                3.1982803
Policy mu Min                -2.8408027
Policy log std Mean          -0.678245
Policy log std Std           0.38412327
Policy log std Max           0.012543142
Policy log std Min           -2.3966534
Z mean eval                  2.1987805
Z variance eval              0.010929668
total_rewards                [7971.61194829 8250.10267551 7994.21648406 7941.97234983 8022.69116697
 8020.94085041 7942.53201428 8024.63327984 7943.2123199  8082.61037518]
total_rewards_mean           8019.452346427235
total_rewards_std            88.25306795480223
total_rewards_max            8250.102675513604
total_rewards_min            7941.972349832387
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               31.83170649362728
(Previous) Eval Time (s)     27.394187772180885
Sample Time (s)              22.11462298920378
Epoch Time (s)               81.34051725501195
Total Train Time (s)         10680.922513339669
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:29:00.055331 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #128 | Epoch Duration: 81.13625645637512
2020-01-11 12:29:00.055576 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1981645
Z variance train             0.0109062465
KL Divergence                30.459705
KL Loss                      3.0459707
QF Loss                      508.8352
VF Loss                      167.3658
Policy Loss                  -2480.093
Q Predictions Mean           2471.5469
Q Predictions Std            789.5917
Q Predictions Max            3215.9558
Q Predictions Min            111.80424
V Predictions Mean           2480.1736
V Predictions Std            778.1357
V Predictions Max            3210.1396
V Predictions Min            144.80128
Log Pis Mean                 3.9257646
Log Pis Std                  4.7665505
Log Pis Max                  17.98684
Log Pis Min                  -5.703204
Policy mu Mean               -0.17822695
Policy mu Std                1.3045448
Policy mu Max                3.0189474
Policy mu Min                -2.8363128
Policy log std Mean          -0.6788616
Policy log std Std           0.3771828
Policy log std Max           -0.03958553
Policy log std Min           -2.5687318
Z mean eval                  2.1800232
Z variance eval              0.012905789
total_rewards                [7435.02148792 7985.90044128 7693.62373194 7300.79498894 7911.70031642
 7621.12642823 8008.40533427 7757.86631593 3686.14073356 8016.91313735]
total_rewards_mean           7341.749291583762
total_rewards_std            1240.5209729568464
total_rewards_max            8016.913137353257
total_rewards_min            3686.1407335605672
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               31.91690224967897
(Previous) Eval Time (s)     27.189595696050674
Sample Time (s)              22.414226626977324
Epoch Time (s)               81.52072457270697
Total Train Time (s)         10763.46572679421
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:22.601328 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #129 | Epoch Duration: 82.54552626609802
2020-01-11 12:30:22.601599 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1816583
Z variance train             0.012899275
KL Divergence                30.08772
KL Loss                      3.0087721
QF Loss                      563.63745
VF Loss                      255.33463
Policy Loss                  -2592.8206
Q Predictions Mean           2598.5361
Q Predictions Std            718.49274
Q Predictions Max            3345.5615
Q Predictions Min            149.24925
V Predictions Mean           2602.4749
V Predictions Std            718.4068
V Predictions Max            3330.0022
V Predictions Min            149.19011
Log Pis Mean                 4.0616083
Log Pis Std                  4.535389
Log Pis Max                  14.117641
Log Pis Min                  -6.478543
Policy mu Mean               -0.11300554
Policy mu Std                1.3381039
Policy mu Max                2.8607955
Policy mu Min                -3.3548527
Policy log std Mean          -0.66918564
Policy log std Std           0.35371384
Policy log std Max           -0.107973665
Policy log std Min           -2.4231956
Z mean eval                  2.1868505
Z variance eval              0.010797994
total_rewards                [7787.50632432 7787.63517445 8000.95543005 8014.95406301 8078.08116443
 7897.90390285 7824.36309574 7802.32746202 7925.1775027  7889.43005443]
total_rewards_mean           7900.833417399372
total_rewards_std            98.18551919732603
total_rewards_max            8078.081164428279
total_rewards_min            7787.506324324556
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               32.30447591515258
(Previous) Eval Time (s)     28.214088364038616
Sample Time (s)              21.972522630356252
Epoch Time (s)               82.49108690954745
Total Train Time (s)         10846.639206974767
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:31:45.777665 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #130 | Epoch Duration: 83.17590975761414
2020-01-11 12:31:45.777851 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1872587
Z variance train             0.010801589
KL Divergence                30.666052
KL Loss                      3.0666053
QF Loss                      368.12326
VF Loss                      166.74309
Policy Loss                  -2549.8804
Q Predictions Mean           2546.2996
Q Predictions Std            749.80695
Q Predictions Max            3337.5823
Q Predictions Min            145.52222
V Predictions Mean           2546.1174
V Predictions Std            750.222
V Predictions Max            3331.3303
V Predictions Min            139.57898
Log Pis Mean                 3.378889
Log Pis Std                  4.169176
Log Pis Max                  14.205139
Log Pis Min                  -5.038956
Policy mu Mean               -0.10830248
Policy mu Std                1.2843491
Policy mu Max                2.6152368
Policy mu Min                -2.7718062
Policy log std Mean          -0.6588785
Policy log std Std           0.37039933
Policy log std Max           -0.00889504
Policy log std Min           -2.4257443
Z mean eval                  2.1947482
Z variance eval              0.009609329
total_rewards                [7664.53587769 7756.44508608 7518.92684882 7783.85920457 7476.20986128
 7745.09483413 7918.33713711 7631.31959376 7860.38310331 7439.93364179]
total_rewards_mean           7679.504518854861
total_rewards_std            154.2478138918197
total_rewards_max            7918.337137107134
total_rewards_min            7439.933641793547
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               31.84923062985763
(Previous) Eval Time (s)     28.898611365351826
Sample Time (s)              22.945441315881908
Epoch Time (s)               83.69328331109136
Total Train Time (s)         10929.035116858315
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:08.174147 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #131 | Epoch Duration: 82.39614343643188
2020-01-11 12:33:08.174333 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1953063
Z variance train             0.0096020745
KL Divergence                31.206398
KL Loss                      3.1206398
QF Loss                      764.90674
VF Loss                      264.12103
Policy Loss                  -2453.4915
Q Predictions Mean           2450.1814
Q Predictions Std            850.0971
Q Predictions Max            3249.1733
Q Predictions Min            129.88243
V Predictions Mean           2451.913
V Predictions Std            843.2255
V Predictions Max            3234.3718
V Predictions Min            135.44153
Log Pis Mean                 3.5663114
Log Pis Std                  4.3955283
Log Pis Max                  13.736706
Log Pis Min                  -6.5514946
Policy mu Mean               -0.117340714
Policy mu Std                1.3064028
Policy mu Max                4.5757027
Policy mu Min                -2.8674254
Policy log std Mean          -0.6696584
Policy log std Std           0.36769778
Policy log std Max           0.024642467
Policy log std Min           -2.4179523
Z mean eval                  2.1784477
Z variance eval              0.009002568
total_rewards                [7740.67960258 8174.96788707 7613.4121651  7793.82885911 8179.02302141
 7895.67492717 7764.59842428 7971.63741703 8064.91000879 7996.04592701]
total_rewards_mean           7919.477823953368
total_rewards_std            181.20694247679668
total_rewards_max            8179.023021407733
total_rewards_min            7613.412165099122
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               32.590766195673496
(Previous) Eval Time (s)     27.60115135787055
Sample Time (s)              23.093001856468618
Epoch Time (s)               83.28491941001266
Total Train Time (s)         11012.056824208237
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:34:31.198488 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #132 | Epoch Duration: 83.0240089893341
2020-01-11 12:34:31.198701 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1782072
Z variance train             0.009007083
KL Divergence                30.950039
KL Loss                      3.0950038
QF Loss                      304.92255
VF Loss                      260.78442
Policy Loss                  -2475.579
Q Predictions Mean           2473.23
Q Predictions Std            842.1723
Q Predictions Max            3345.2468
Q Predictions Min            127.501785
V Predictions Mean           2479.293
V Predictions Std            841.7808
V Predictions Max            3348.9192
V Predictions Min            129.70471
Log Pis Mean                 3.9319239
Log Pis Std                  4.7513337
Log Pis Max                  14.667539
Log Pis Min                  -9.062307
Policy mu Mean               -0.07101205
Policy mu Std                1.321804
Policy mu Max                3.1458182
Policy mu Min                -3.2162943
Policy log std Mean          -0.6699941
Policy log std Std           0.3905936
Policy log std Max           -0.057042032
Policy log std Min           -2.4933712
Z mean eval                  2.1946511
Z variance eval              0.008420995
total_rewards                [7814.75901599 8259.06453777 8131.9097698  7892.20625793 7729.84299654
 7881.58627853 8047.34195834 7690.24782842 7976.16346751 7825.01462485]
total_rewards_mean           7924.813673568475
total_rewards_std            170.382171845127
total_rewards_max            8259.064537772898
total_rewards_min            7690.247828419931
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               31.581646645907313
(Previous) Eval Time (s)     27.339926719665527
Sample Time (s)              22.493171635549515
Epoch Time (s)               81.41474500112236
Total Train Time (s)         11094.26396752568
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:35:53.407650 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #133 | Epoch Duration: 82.20880246162415
2020-01-11 12:35:53.407844 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.194228
Z variance train             0.008444454
KL Divergence                31.737072
KL Loss                      3.1737072
QF Loss                      575.3832
VF Loss                      245.72696
Policy Loss                  -2461.962
Q Predictions Mean           2456.9783
Q Predictions Std            851.7289
Q Predictions Max            3322.598
Q Predictions Min            124.58693
V Predictions Mean           2460.1719
V Predictions Std            845.2321
V Predictions Max            3314.071
V Predictions Min            133.74403
Log Pis Mean                 3.8720582
Log Pis Std                  4.597559
Log Pis Max                  19.540956
Log Pis Min                  -5.172459
Policy mu Mean               -0.14549999
Policy mu Std                1.3062592
Policy mu Max                3.9423015
Policy mu Min                -3.1065602
Policy log std Mean          -0.693693
Policy log std Std           0.4019579
Policy log std Max           0.046117842
Policy log std Min           -2.5365105
Z mean eval                  2.170587
Z variance eval              0.008513495
total_rewards                [7900.81288572 7826.53268408 8180.6190086  7720.02396701 8056.56363928
 7861.60039003 7886.94731271 7989.39418172 7719.36049426 7625.51845332]
total_rewards_mean           7876.737301672389
total_rewards_std            159.13645794017913
total_rewards_max            8180.619008599673
total_rewards_min            7625.518453322919
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               32.62761056935415
(Previous) Eval Time (s)     28.133608389180154
Sample Time (s)              22.803111080545932
Epoch Time (s)               83.56433003908023
Total Train Time (s)         11178.46212478634
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:37:17.608549 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #134 | Epoch Duration: 84.20055484771729
2020-01-11 12:37:17.608779 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1691406
Z variance train             0.008511709
KL Divergence                31.255707
KL Loss                      3.1255708
QF Loss                      356.83652
VF Loss                      227.43079
Policy Loss                  -2597.9646
Q Predictions Mean           2596.4102
Q Predictions Std            745.4515
Q Predictions Max            3326.816
Q Predictions Min            86.734665
V Predictions Mean           2604.976
V Predictions Std            745.75995
V Predictions Max            3340.791
V Predictions Min            132.43741
Log Pis Mean                 4.0929856
Log Pis Std                  4.4637647
Log Pis Max                  14.87507
Log Pis Min                  -5.2626367
Policy mu Mean               -0.121877335
Policy mu Std                1.3337426
Policy mu Max                2.689363
Policy mu Min                -2.609521
Policy log std Mean          -0.6783728
Policy log std Std           0.37448117
Policy log std Max           -0.09960866
Policy log std Min           -2.5533023
Z mean eval                  2.1662872
Z variance eval              0.009902049
total_rewards                [7734.26545797 7779.41310245 7428.82489516 7563.46061131 7589.20453299
 7675.10086838 7552.14661881 7495.63497881 7714.55281585 7716.43740051]
total_rewards_mean           7624.904128223044
total_rewards_std            109.66716194364625
total_rewards_max            7779.413102449878
total_rewards_min            7428.824895161483
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               32.46828634524718
(Previous) Eval Time (s)     28.769483662676066
Sample Time (s)              20.518734690267593
Epoch Time (s)               81.75650469819084
Total Train Time (s)         11260.075653527398
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:38:39.224876 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #135 | Epoch Duration: 81.61592054367065
2020-01-11 12:38:39.225214 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1645577
Z variance train             0.00991799
KL Divergence                31.33941
KL Loss                      3.1339412
QF Loss                      464.33734
VF Loss                      231.79546
Policy Loss                  -2599.4653
Q Predictions Mean           2591.939
Q Predictions Std            685.3346
Q Predictions Max            3265.1226
Q Predictions Min            129.29195
V Predictions Mean           2595.9097
V Predictions Std            679.0578
V Predictions Max            3233.5815
V Predictions Min            126.45525
Log Pis Mean                 4.0028033
Log Pis Std                  4.3124266
Log Pis Max                  15.100565
Log Pis Min                  -5.8274956
Policy mu Mean               -0.047028277
Policy mu Std                1.3377188
Policy mu Max                2.8694193
Policy mu Min                -2.84863
Policy log std Mean          -0.68946195
Policy log std Std           0.36810452
Policy log std Max           -0.1146452
Policy log std Min           -2.463295
Z mean eval                  2.1688435
Z variance eval              0.010434966
total_rewards                [7631.89988614 7783.75768456 7906.87818033 7699.05729174 7691.17588854
 8078.31481877 7744.44184311 7587.49605666 7751.56027143 7897.64156454]
total_rewards_mean           7777.222348581898
total_rewards_std            139.4174901420211
total_rewards_max            8078.314818770149
total_rewards_min            7587.496056660684
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               32.053010005969554
(Previous) Eval Time (s)     28.628570897039026
Sample Time (s)              22.618344428483397
Epoch Time (s)               83.29992533149198
Total Train Time (s)         11342.216952871531
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:40:01.367864 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #136 | Epoch Duration: 82.14245319366455
2020-01-11 12:40:01.368073 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1700578
Z variance train             0.010450147
KL Divergence                31.384525
KL Loss                      3.1384525
QF Loss                      545.8311
VF Loss                      363.88025
Policy Loss                  -2518.2847
Q Predictions Mean           2514.3198
Q Predictions Std            824.2324
Q Predictions Max            3342.3564
Q Predictions Min            149.10762
V Predictions Mean           2510.5654
V Predictions Std            821.0022
V Predictions Max            3308.6917
V Predictions Min            125.96727
Log Pis Mean                 3.7103674
Log Pis Std                  4.316576
Log Pis Max                  12.878366
Log Pis Min                  -4.743309
Policy mu Mean               -0.15159865
Policy mu Std                1.3097025
Policy mu Max                3.0037315
Policy mu Min                -3.2773986
Policy log std Mean          -0.67722726
Policy log std Std           0.3609604
Policy log std Max           -0.0942049
Policy log std Min           -2.5852575
Z mean eval                  2.1694674
Z variance eval              0.01302254
total_rewards                [7530.97688146 7930.48783672 8120.51402197 8051.80425762 7982.69071741
 7964.84816224 7704.37279383 8211.41470652 7909.246295   7928.45900895]
total_rewards_mean           7933.481468172604
total_rewards_std            185.67606762757083
total_rewards_max            8211.414706517406
total_rewards_min            7530.976881458233
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               31.881814050022513
(Previous) Eval Time (s)     27.4707824960351
Sample Time (s)              22.23274060478434
Epoch Time (s)               81.58533715084195
Total Train Time (s)         11424.664784220047
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:23.817584 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #137 | Epoch Duration: 82.44936895370483
2020-01-11 12:41:23.817782 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1717608
Z variance train             0.013005422
KL Divergence                31.558426
KL Loss                      3.1558425
QF Loss                      497.1909
VF Loss                      141.47517
Policy Loss                  -2610.3813
Q Predictions Mean           2617.7014
Q Predictions Std            720.5717
Q Predictions Max            3351.514
Q Predictions Min            133.32135
V Predictions Mean           2609.4756
V Predictions Std            715.0963
V Predictions Max            3328.3123
V Predictions Min            129.00397
Log Pis Mean                 3.9014273
Log Pis Std                  4.8802414
Log Pis Max                  15.700635
Log Pis Min                  -9.054565
Policy mu Mean               -0.09679934
Policy mu Std                1.337877
Policy mu Max                3.1095595
Policy mu Min                -2.867675
Policy log std Mean          -0.6752781
Policy log std Std           0.35143888
Policy log std Max           -0.115986645
Policy log std Min           -2.5342627
Z mean eval                  2.1736605
Z variance eval              0.018814351
total_rewards                [7583.62525472 8087.00515764 7531.96793574 8145.37703754 8018.93940978
 7729.49165194 7726.7120938  7630.51892102 7775.76307073 7831.83781866]
total_rewards_mean           7806.123835156967
total_rewards_std            202.12456157828697
total_rewards_max            8145.377037540081
total_rewards_min            7531.967935738024
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               32.1892668409273
(Previous) Eval Time (s)     28.33451888570562
Sample Time (s)              21.83393588894978
Epoch Time (s)               82.3577216155827
Total Train Time (s)         11506.432054608129
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:42:45.587930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #138 | Epoch Duration: 81.77000689506531
2020-01-11 12:42:45.588108 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1734264
Z variance train             0.018801466
KL Divergence                30.747011
KL Loss                      3.074701
QF Loss                      357.63638
VF Loss                      175.34703
Policy Loss                  -2591.5713
Q Predictions Mean           2591.9336
Q Predictions Std            773.8418
Q Predictions Max            3330.319
Q Predictions Min            121.60279
V Predictions Mean           2597.9827
V Predictions Std            770.2079
V Predictions Max            3325.821
V Predictions Min            127.1102
Log Pis Mean                 3.804027
Log Pis Std                  4.5094495
Log Pis Max                  15.664596
Log Pis Min                  -5.623625
Policy mu Mean               -0.14805211
Policy mu Std                1.3263484
Policy mu Max                2.905786
Policy mu Min                -2.7753088
Policy log std Mean          -0.6772725
Policy log std Std           0.3831285
Policy log std Max           0.06172514
Policy log std Min           -2.6847196
Z mean eval                  2.1771522
Z variance eval              0.017222885
total_rewards                [7948.15398444 7988.2427815  8208.21735297 8153.77991273 8126.46806001
 8208.79029926 8108.12746054 7977.36512071 8288.16614913 8161.4410863 ]
total_rewards_mean           8116.875220759303
total_rewards_std            106.82939458890603
total_rewards_max            8288.166149132394
total_rewards_min            7948.1539844448625
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               33.040467496961355
(Previous) Eval Time (s)     27.746446553617716
Sample Time (s)              22.628484062850475
Epoch Time (s)               83.41539811342955
Total Train Time (s)         11590.021434172057
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:09.178769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #139 | Epoch Duration: 83.59053564071655
2020-01-11 12:44:09.178953 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.179197
Z variance train             0.01725789
KL Divergence                30.884186
KL Loss                      3.0884187
QF Loss                      318.04926
VF Loss                      220.39583
Policy Loss                  -2655.1084
Q Predictions Mean           2649.4658
Q Predictions Std            703.5291
Q Predictions Max            3429.0725
Q Predictions Min            122.69882
V Predictions Mean           2647.2856
V Predictions Std            701.20966
V Predictions Max            3400.4062
V Predictions Min            125.45416
Log Pis Mean                 3.889709
Log Pis Std                  4.0291147
Log Pis Max                  13.977915
Log Pis Min                  -5.899637
Policy mu Mean               -0.14719062
Policy mu Std                1.3344375
Policy mu Max                3.190541
Policy mu Min                -2.9124854
Policy log std Mean          -0.6896093
Policy log std Std           0.35330197
Policy log std Max           -0.12744164
Policy log std Min           -2.495167
Z mean eval                  2.1696541
Z variance eval              0.01736121
total_rewards                [7242.57301035 7647.56048482 7436.55393542 7432.65070625 7832.84630897
 7723.54543414 7689.47545919 7963.73261145 7704.43797415 7655.2221715 ]
total_rewards_mean           7632.859809625103
total_rewards_std            199.4200869767306
total_rewards_max            7963.732611446228
total_rewards_min            7242.573010354453
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               31.62743871100247
(Previous) Eval Time (s)     27.921318877954036
Sample Time (s)              20.935219258069992
Epoch Time (s)               80.4839768470265
Total Train Time (s)         11670.938934384845
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:45:30.099178 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #140 | Epoch Duration: 80.92007946968079
2020-01-11 12:45:30.099440 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1721935
Z variance train             0.017292937
KL Divergence                30.738293
KL Loss                      3.0738294
QF Loss                      344.6336
VF Loss                      266.31494
Policy Loss                  -2577.519
Q Predictions Mean           2575.3867
Q Predictions Std            696.39294
Q Predictions Max            3326.9248
Q Predictions Min            131.18968
V Predictions Mean           2573.9587
V Predictions Std            691.5307
V Predictions Max            3290.102
V Predictions Min            128.30995
Log Pis Mean                 4.476345
Log Pis Std                  4.6452665
Log Pis Max                  15.229158
Log Pis Min                  -6.2366066
Policy mu Mean               -0.12382728
Policy mu Std                1.366121
Policy mu Max                3.094192
Policy mu Min                -2.8068967
Policy log std Mean          -0.69165134
Policy log std Std           0.35674566
Policy log std Max           0.048240602
Policy log std Min           -2.4141808
Z mean eval                  2.186639
Z variance eval              0.016912075
total_rewards                [7909.08287681 7728.80028692 7993.70263423 8189.40397069 7854.07741244
 8184.13862291 7954.08298718 7900.05607335 7934.25290456 8067.4427184 ]
total_rewards_mean           7971.504048750644
total_rewards_std            136.30015832211308
total_rewards_max            8189.403970690679
total_rewards_min            7728.800286924179
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               33.996261787135154
(Previous) Eval Time (s)     28.357096292078495
Sample Time (s)              22.524886657949537
Epoch Time (s)               84.87824473716319
Total Train Time (s)         11756.10625736788
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:46:55.268509 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #141 | Epoch Duration: 85.16890907287598
2020-01-11 12:46:55.268730 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1857333
Z variance train             0.016904306
KL Divergence                30.963089
KL Loss                      3.096309
QF Loss                      930.1045
VF Loss                      295.70374
Policy Loss                  -2606.9036
Q Predictions Mean           2606.8584
Q Predictions Std            717.6201
Q Predictions Max            3346.1487
Q Predictions Min            117.75682
V Predictions Mean           2619.331
V Predictions Std            715.3399
V Predictions Max            3372.2458
V Predictions Min            120.90672
Log Pis Mean                 3.4072404
Log Pis Std                  4.3985085
Log Pis Max                  13.635675
Log Pis Min                  -6.324918
Policy mu Mean               -0.11801449
Policy mu Std                1.286422
Policy mu Max                3.292681
Policy mu Min                -2.820134
Policy log std Mean          -0.6730531
Policy log std Std           0.359619
Policy log std Max           -0.011057854
Policy log std Min           -2.5227983
Z mean eval                  2.1801398
Z variance eval              0.016105149
total_rewards                [8033.81073301 7964.38257423 8201.90262438 8112.31099287 8310.37864266
 8165.95527967 7848.13128244 8158.99906105 8020.12560538 7962.91015347]
total_rewards_mean           8077.890694915724
total_rewards_std            130.04697388189726
total_rewards_max            8310.378642661153
total_rewards_min            7848.1312824400875
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               35.16356502985582
(Previous) Eval Time (s)     28.647387025877833
Sample Time (s)              23.160227664746344
Epoch Time (s)               86.97117972048
Total Train Time (s)         11842.536763054319
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:48:21.701083 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #142 | Epoch Duration: 86.43218851089478
2020-01-11 12:48:21.701297 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #142 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1836553
Z variance train             0.0160135
KL Divergence                31.08053
KL Loss                      3.108053
QF Loss                      317.73132
VF Loss                      292.46588
Policy Loss                  -2680.1714
Q Predictions Mean           2679.3403
Q Predictions Std            755.68567
Q Predictions Max            3416.0098
Q Predictions Min            131.14708
V Predictions Mean           2666.5222
V Predictions Std            751.3525
V Predictions Max            3361.236
V Predictions Min            132.65543
Log Pis Mean                 4.181818
Log Pis Std                  4.624046
Log Pis Max                  15.526642
Log Pis Min                  -6.7618465
Policy mu Mean               -0.15324421
Policy mu Std                1.3386686
Policy mu Max                2.8726826
Policy mu Min                -2.7971344
Policy log std Mean          -0.67837715
Policy log std Std           0.36563018
Policy log std Max           -0.036978126
Policy log std Min           -2.5403833
Z mean eval                  2.1807866
Z variance eval              0.017010735
total_rewards                [5127.01521167 3293.08600206 3299.60015781 7883.69967112 7736.4225393
 7796.21186622 8084.58621526 7653.32259114 8299.13702327 7886.71832898]
total_rewards_mean           6705.979960682655
total_rewards_std            1900.3195844377187
total_rewards_max            8299.137023269337
total_rewards_min            3293.086002055934
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               34.73040391411632
(Previous) Eval Time (s)     28.108037685975432
Sample Time (s)              23.37034860998392
Epoch Time (s)               86.20879021007568
Total Train Time (s)         11929.39017646201
Epoch                        143
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:49:48.556513 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #143 | Epoch Duration: 86.85507416725159
2020-01-11 12:49:48.556696 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.17959
Z variance train             0.017060356
KL Divergence                30.284977
KL Loss                      3.0284977
QF Loss                      642.35925
VF Loss                      162.909
Policy Loss                  -2703.3018
Q Predictions Mean           2697.425
Q Predictions Std            748.1061
Q Predictions Max            3415.1638
Q Predictions Min            128.95009
V Predictions Mean           2704.9482
V Predictions Std            746.3405
V Predictions Max            3412.483
V Predictions Min            129.41751
Log Pis Mean                 4.3424025
Log Pis Std                  4.4791617
Log Pis Max                  17.391302
Log Pis Min                  -5.875
Policy mu Mean               -0.13399671
Policy mu Std                1.3571267
Policy mu Max                3.2493262
Policy mu Min                -3.1954772
Policy log std Mean          -0.6900994
Policy log std Std           0.37775344
Policy log std Max           -0.02314198
Policy log std Min           -2.587591
Z mean eval                  2.1846442
Z variance eval              0.015598996
total_rewards                [7685.51772389 8275.19315731 7988.67088554 8050.90535399 8056.87854443
 8076.49097113 7848.18197943 7804.51505356 8121.40137335 8161.21998545]
total_rewards_mean           8006.8975028084005
total_rewards_std            169.69196049372056
total_rewards_max            8275.193157313277
total_rewards_min            7685.517723889621
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               34.528948449064046
(Previous) Eval Time (s)     28.753930575214326
Sample Time (s)              23.264798528980464
Epoch Time (s)               86.54767755325884
Total Train Time (s)         12015.596650345717
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:14.769681 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #144 | Epoch Duration: 86.21283221244812
2020-01-11 12:51:14.769919 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1853175
Z variance train             0.015634859
KL Divergence                30.286522
KL Loss                      3.0286522
QF Loss                      449.727
VF Loss                      299.0274
Policy Loss                  -2595.171
Q Predictions Mean           2599.7405
Q Predictions Std            808.89655
Q Predictions Max            3334.3555
Q Predictions Min            121.14121
V Predictions Mean           2593.8706
V Predictions Std            801.99554
V Predictions Max            3319.1917
V Predictions Min            125.518456
Log Pis Mean                 3.90182
Log Pis Std                  4.8812914
Log Pis Max                  22.247377
Log Pis Min                  -8.107687
Policy mu Mean               -0.10241414
Policy mu Std                1.3309243
Policy mu Max                3.750727
Policy mu Min                -3.9114876
Policy log std Mean          -0.67686707
Policy log std Std           0.37682548
Policy log std Max           0.036878407
Policy log std Min           -2.6026204
Z mean eval                  2.1740806
Z variance eval              0.016438363
total_rewards                [7712.14947511 8181.83242656 8130.48160333 8066.40997955 8216.40211491
 7977.84527479 8219.38489484 8177.84966531 8333.89454116 7864.0805901 ]
total_rewards_mean           8088.0330565667855
total_rewards_std            178.0165983998801
total_rewards_max            8333.894541157872
total_rewards_min            7712.149475109668
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               34.99804446985945
(Previous) Eval Time (s)     28.418695447966456
Sample Time (s)              23.615481947548687
Epoch Time (s)               87.0322218653746
Total Train Time (s)         12101.873331838753
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:41.044777 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #145 | Epoch Duration: 86.27470970153809
2020-01-11 12:52:41.044982 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #145 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1735835
Z variance train             0.016437728
KL Divergence                29.721806
KL Loss                      2.9721806
QF Loss                      1034.8977
VF Loss                      182.78183
Policy Loss                  -2619.8757
Q Predictions Mean           2619.969
Q Predictions Std            763.30774
Q Predictions Max            3350.7356
Q Predictions Min            118.724556
V Predictions Mean           2620.9067
V Predictions Std            759.81506
V Predictions Max            3337.7368
V Predictions Min            119.12189
Log Pis Mean                 3.963673
Log Pis Std                  4.4745493
Log Pis Max                  16.105885
Log Pis Min                  -5.3274183
Policy mu Mean               -0.10852497
Policy mu Std                1.3160682
Policy mu Max                3.2577121
Policy mu Min                -3.0110087
Policy log std Mean          -0.6866922
Policy log std Std           0.35968587
Policy log std Max           -0.067824304
Policy log std Min           -2.4720795
Z mean eval                  2.1812978
Z variance eval              0.022588765
total_rewards                [7980.81079794 8193.6396807  8076.71733921 7982.66283382 8068.2812653
 8113.7116349  8252.75263329 8170.15344308 7871.15815388 8128.67557722]
total_rewards_mean           8083.856335933054
total_rewards_std            108.31353033417643
total_rewards_max            8252.752633288334
total_rewards_min            7871.158153882301
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               33.70450932113454
(Previous) Eval Time (s)     27.660793066956103
Sample Time (s)              22.86515737976879
Epoch Time (s)               84.23045976785943
Total Train Time (s)         12187.383306235075
Epoch                        146
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:06.556877 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #146 | Epoch Duration: 85.51174211502075
2020-01-11 12:54:06.557076 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1807172
Z variance train             0.022455912
KL Divergence                29.49115
KL Loss                      2.949115
QF Loss                      291.25793
VF Loss                      208.53003
Policy Loss                  -2717.308
Q Predictions Mean           2725.7637
Q Predictions Std            721.9104
Q Predictions Max            3425.8545
Q Predictions Min            123.27343
V Predictions Mean           2727.772
V Predictions Std            719.3412
V Predictions Max            3418.2422
V Predictions Min            126.74532
Log Pis Mean                 4.4831676
Log Pis Std                  4.7297
Log Pis Max                  14.873716
Log Pis Min                  -5.2306604
Policy mu Mean               -0.14083825
Policy mu Std                1.3717936
Policy mu Max                3.0902903
Policy mu Min                -2.7745898
Policy log std Mean          -0.6773295
Policy log std Std           0.37763205
Policy log std Max           -0.033352077
Policy log std Min           -2.6110125
Z mean eval                  2.1739573
Z variance eval              0.017666081
total_rewards                [8394.79184065 8358.00932333 8061.50860468 8057.27440619 8317.16755266
 8288.77152348 3193.82498633 8372.93169551 8029.84168581 8226.63076156]
total_rewards_mean           7730.075238019733
total_rewards_std            1517.7988587692978
total_rewards_max            8394.791840650349
total_rewards_min            3193.8249863346878
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               34.97083742078394
(Previous) Eval Time (s)     28.941618971992284
Sample Time (s)              23.519856427330524
Epoch Time (s)               87.43231282010674
Total Train Time (s)         12275.292817876674
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:34.468686 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #147 | Epoch Duration: 87.91145873069763
2020-01-11 12:55:34.468893 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1750267
Z variance train             0.017659504
KL Divergence                29.713604
KL Loss                      2.9713604
QF Loss                      413.0855
VF Loss                      145.6702
Policy Loss                  -2620.3179
Q Predictions Mean           2622.8274
Q Predictions Std            799.8625
Q Predictions Max            3436.7678
Q Predictions Min            121.347305
V Predictions Mean           2616.065
V Predictions Std            799.17957
V Predictions Max            3416.8428
V Predictions Min            109.27268
Log Pis Mean                 4.2571335
Log Pis Std                  4.6509295
Log Pis Max                  15.542897
Log Pis Min                  -6.7210274
Policy mu Mean               -0.09779634
Policy mu Std                1.3570921
Policy mu Max                3.2355702
Policy mu Min                -3.032516
Policy log std Mean          -0.6882505
Policy log std Std           0.38621438
Policy log std Max           -0.06733291
Policy log std Min           -2.6815994
Z mean eval                  2.1841197
Z variance eval              0.015552203
total_rewards                [8222.6328539  8018.87966435 8021.27024279 8278.94598326 8257.77411458
 8558.47921906 7901.6260407  8191.04965231 8543.33674246 8318.70878135]
total_rewards_mean           8231.270329476069
total_rewards_std            203.62698790077326
total_rewards_max            8558.479219061168
total_rewards_min            7901.626040698002
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               34.14721919596195
(Previous) Eval Time (s)     29.420342409051955
Sample Time (s)              24.362708696629852
Epoch Time (s)               87.93027030164376
Total Train Time (s)         12362.16829444142
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:01.346354 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #148 | Epoch Duration: 86.87731623649597
2020-01-11 12:57:01.346544 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1828792
Z variance train             0.015567553
KL Divergence                29.988707
KL Loss                      2.9988706
QF Loss                      573.16455
VF Loss                      253.85223
Policy Loss                  -2721.856
Q Predictions Mean           2729.6812
Q Predictions Std            855.5803
Q Predictions Max            3466.3062
Q Predictions Min            120.05811
V Predictions Mean           2732.308
V Predictions Std            852.2054
V Predictions Max            3463.9976
V Predictions Min            125.69478
Log Pis Mean                 3.9435625
Log Pis Std                  4.4639707
Log Pis Max                  14.112034
Log Pis Min                  -6.8253584
Policy mu Mean               -0.07139673
Policy mu Std                1.3211466
Policy mu Max                2.85628
Policy mu Min                -3.0030997
Policy log std Mean          -0.68580467
Policy log std Std           0.3820334
Policy log std Max           0.3560654
Policy log std Min           -2.5760899
Z mean eval                  2.1996827
Z variance eval              0.015123211
total_rewards                [8032.85102045 8067.88808157 8138.11705652 8040.87570091 4945.60939462
 8251.79756987 8294.31315824 8261.84623656 8105.66090459 7986.16986662]
total_rewards_mean           7812.512898996198
total_rewards_std            960.9455846948803
total_rewards_max            8294.313158236917
total_rewards_min            4945.609394621281
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               34.255717772990465
(Previous) Eval Time (s)     28.366993669886142
Sample Time (s)              23.12407329166308
Epoch Time (s)               85.74678473453969
Total Train Time (s)         12447.836281966884
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:27.016953 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #149 | Epoch Duration: 85.6702573299408
2020-01-11 12:58:27.017206 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #149 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2008262
Z variance train             0.015152323
KL Divergence                30.459185
KL Loss                      3.0459185
QF Loss                      648.2738
VF Loss                      226.78369
Policy Loss                  -2753.8606
Q Predictions Mean           2746.866
Q Predictions Std            732.07446
Q Predictions Max            3473.1675
Q Predictions Min            108.01375
V Predictions Mean           2748.4917
V Predictions Std            729.0113
V Predictions Max            3466.8237
V Predictions Min            108.59829
Log Pis Mean                 4.319524
Log Pis Std                  4.410352
Log Pis Max                  18.854507
Log Pis Min                  -4.972476
Policy mu Mean               -0.15832445
Policy mu Std                1.3493961
Policy mu Max                3.336906
Policy mu Min                -3.5219538
Policy log std Mean          -0.6980637
Policy log std Std           0.37110224
Policy log std Max           -0.0024894178
Policy log std Min           -2.4434958
Z mean eval                  2.1964366
Z variance eval              0.012359759
total_rewards                [8107.79827767 8174.99926671 8104.74283201 8307.2220705  7963.7253753
 8076.08363864 8158.69306914 3722.51059333 7800.00738274 7893.78239253]
total_rewards_mean           7630.956489857871
total_rewards_std            1310.1966821664262
total_rewards_max            8307.222070501075
total_rewards_min            3722.510593332787
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               34.64345977129415
(Previous) Eval Time (s)     28.290116680320352
Sample Time (s)              23.027602296322584
Epoch Time (s)               85.96117874793708
Total Train Time (s)         12533.656794335693
Epoch                        150
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:59:52.838898 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #150 | Epoch Duration: 85.82153677940369
2020-01-11 12:59:52.839060 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.194336
Z variance train             0.012364132
KL Divergence                31.15099
KL Loss                      3.115099
QF Loss                      483.41174
VF Loss                      232.22438
Policy Loss                  -2661.7856
Q Predictions Mean           2672.4243
Q Predictions Std            829.24634
Q Predictions Max            3479.3608
Q Predictions Min            124.254745
V Predictions Mean           2669.0884
V Predictions Std            830.9873
V Predictions Max            3468.9172
V Predictions Min            117.09113
Log Pis Mean                 3.9629035
Log Pis Std                  4.8691263
Log Pis Max                  18.926704
Log Pis Min                  -7.02364
Policy mu Mean               -0.068377644
Policy mu Std                1.3277528
Policy mu Max                2.835916
Policy mu Min                -3.0173485
Policy log std Mean          -0.6776502
Policy log std Std           0.38649938
Policy log std Max           -0.01805988
Policy log std Min           -2.725581
Z mean eval                  2.1913269
Z variance eval              0.012306685
total_rewards                [8055.88837829 8134.17530672 8328.58114563 8032.46381218 7961.75675681
 8237.8845128  8118.17592875 8205.17021746 7993.80224986 8162.36254457]
total_rewards_mean           8123.026085307305
total_rewards_std            109.2262691869434
total_rewards_max            8328.58114563489
total_rewards_min            7961.756756807744
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               32.203697175718844
(Previous) Eval Time (s)     28.150103885680437
Sample Time (s)              21.049227268900722
Epoch Time (s)               81.4030283303
Total Train Time (s)         12614.784143243916
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:01:13.968694 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #151 | Epoch Duration: 81.12951445579529
2020-01-11 13:01:13.968868 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.190844
Z variance train             0.012286754
KL Divergence                31.179657
KL Loss                      3.1179657
QF Loss                      503.67444
VF Loss                      238.56946
Policy Loss                  -2651.4604
Q Predictions Mean           2646.427
Q Predictions Std            856.5455
Q Predictions Max            3398.7092
Q Predictions Min            103.810715
V Predictions Mean           2654.853
V Predictions Std            856.7348
V Predictions Max            3401.4172
V Predictions Min            110.66564
Log Pis Mean                 3.8171098
Log Pis Std                  4.448261
Log Pis Max                  16.70994
Log Pis Min                  -5.0599794
Policy mu Mean               -0.101178326
Policy mu Std                1.3052834
Policy mu Max                2.9918728
Policy mu Min                -2.8971944
Policy log std Mean          -0.67693776
Policy log std Std           0.35865656
Policy log std Max           -0.06218344
Policy log std Min           -2.5735424
Z mean eval                  2.1782012
Z variance eval              0.015002829
total_rewards                [7106.10241674 8395.75549472 8335.61862581 8294.1673385  8258.29546361
 8330.44749481 8350.11028251 8251.23925161 8372.49300861 8382.056169  ]
total_rewards_mean           8207.628554592182
total_rewards_std            370.14616595589683
total_rewards_max            8395.755494715408
total_rewards_min            7106.102416741076
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               32.59887999901548
(Previous) Eval Time (s)     27.876289496663958
Sample Time (s)              21.899822616018355
Epoch Time (s)               82.3749921116978
Total Train Time (s)         12697.619671269786
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:02:36.807329 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #152 | Epoch Duration: 82.83830714225769
2020-01-11 13:02:36.807637 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.177626
Z variance train             0.014954132
KL Divergence                30.536848
KL Loss                      3.053685
QF Loss                      455.80273
VF Loss                      738.08167
Policy Loss                  -2645.9907
Q Predictions Mean           2653.5332
Q Predictions Std            812.8927
Q Predictions Max            3439.4792
Q Predictions Min            96.710434
V Predictions Mean           2664.6445
V Predictions Std            808.546
V Predictions Max            3432.751
V Predictions Min            101.68033
Log Pis Mean                 4.3382387
Log Pis Std                  4.6633787
Log Pis Max                  15.353985
Log Pis Min                  -4.4617596
Policy mu Mean               -0.17368758
Policy mu Std                1.3622711
Policy mu Max                4.3207726
Policy mu Min                -3.463114
Policy log std Mean          -0.6966862
Policy log std Std           0.37037534
Policy log std Max           0.000228405
Policy log std Min           -2.5500858
Z mean eval                  2.1709118
Z variance eval              0.011536563
total_rewards                [8163.43378296 8168.49902448 8336.31668977 8362.42540092 8231.52786885
 8321.64787705 8292.29924114 8307.82509966 8056.59220911 8242.03378643]
total_rewards_mean           8248.260098036659
total_rewards_std            90.7047562483921
total_rewards_max            8362.425400918017
total_rewards_min            8056.592209113478
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               32.66214693989605
(Previous) Eval Time (s)     28.339242266025394
Sample Time (s)              21.866661607753485
Epoch Time (s)               82.86805081367493
Total Train Time (s)         12779.527209723834
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:58.717091 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #153 | Epoch Duration: 81.90924620628357
2020-01-11 13:03:58.717281 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1705556
Z variance train             0.011510333
KL Divergence                31.016249
KL Loss                      3.101625
QF Loss                      1170.7958
VF Loss                      287.6662
Policy Loss                  -2654.2622
Q Predictions Mean           2649.7964
Q Predictions Std            778.9335
Q Predictions Max            3390.7097
Q Predictions Min            93.25692
V Predictions Mean           2658.3733
V Predictions Std            773.1238
V Predictions Max            3398.9512
V Predictions Min            107.267426
Log Pis Mean                 3.7786884
Log Pis Std                  4.5174794
Log Pis Max                  17.774292
Log Pis Min                  -9.257866
Policy mu Mean               -0.1434378
Policy mu Std                1.3272784
Policy mu Max                4.925196
Policy mu Min                -3.50671
Policy log std Mean          -0.671478
Policy log std Std           0.3794885
Policy log std Max           0.096235275
Policy log std Min           -2.6341438
Z mean eval                  2.161058
Z variance eval              0.014749801
total_rewards                [8215.01055933 8330.75159695 7745.54277876 8080.68800786 8082.39573593
 8410.17716879 8398.83377979 7816.26723659 8031.50441315 7846.26812753]
total_rewards_mean           8095.743940467682
total_rewards_std            229.71779778780964
total_rewards_max            8410.177168792185
total_rewards_min            7745.542778761427
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               32.28870747704059
(Previous) Eval Time (s)     27.380124324001372
Sample Time (s)              22.83941999077797
Epoch Time (s)               82.50825179181993
Total Train Time (s)         12861.902644032147
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:05:21.094753 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #154 | Epoch Duration: 82.3773398399353
2020-01-11 13:05:21.094929 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1608405
Z variance train             0.01472949
KL Divergence                30.228409
KL Loss                      3.022841
QF Loss                      767.4296
VF Loss                      260.09085
Policy Loss                  -2772.9883
Q Predictions Mean           2761.1082
Q Predictions Std            766.8192
Q Predictions Max            3497.7207
Q Predictions Min            121.39891
V Predictions Mean           2763.059
V Predictions Std            766.21356
V Predictions Max            3495.3843
V Predictions Min            116.19682
Log Pis Mean                 4.207266
Log Pis Std                  4.755133
Log Pis Max                  17.509733
Log Pis Min                  -7.431881
Policy mu Mean               -0.1649101
Policy mu Std                1.3376147
Policy mu Max                2.8905327
Policy mu Min                -2.811872
Policy log std Mean          -0.7073922
Policy log std Std           0.3705382
Policy log std Max           -0.0059678555
Policy log std Min           -2.6800046
Z mean eval                  2.1682675
Z variance eval              0.016317654
total_rewards                [8338.93478303 8203.07022355 8495.69068551 8431.92074674 8250.21987105
 8231.88062433 8207.3651958  8436.64316631 8536.3160995  8416.22993162]
total_rewards_mean           8354.827132744622
total_rewards_std            118.43759967844558
total_rewards_max            8536.316099497728
total_rewards_min            8203.07022354993
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               32.21453553903848
(Previous) Eval Time (s)     27.248861314263195
Sample Time (s)              22.44150106003508
Epoch Time (s)               81.90489791333675
Total Train Time (s)         12944.035590780899
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:43.228786 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #155 | Epoch Duration: 82.13373041152954
2020-01-11 13:06:43.228930 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1670048
Z variance train             0.016318586
KL Divergence                30.233809
KL Loss                      3.023381
QF Loss                      308.20233
VF Loss                      278.70557
Policy Loss                  -2789.9438
Q Predictions Mean           2789.7783
Q Predictions Std            584.7291
Q Predictions Max            3480.3813
Q Predictions Min            110.83753
V Predictions Mean           2777.259
V Predictions Std            579.1333
V Predictions Max            3456.7659
V Predictions Min            109.43785
Log Pis Mean                 4.4722176
Log Pis Std                  4.191602
Log Pis Max                  16.762405
Log Pis Min                  -5.4968224
Policy mu Mean               -0.08120951
Policy mu Std                1.3496226
Policy mu Max                3.0048628
Policy mu Min                -3.1860738
Policy log std Mean          -0.7209366
Policy log std Std           0.39630088
Policy log std Max           -0.025103152
Policy log std Min           -2.6640217
Z mean eval                  2.1600013
Z variance eval              0.018863175
total_rewards                [8175.03825279 8228.27016256 8110.70689738 8580.78345492 8145.94168623
 7906.9830663  8498.81926087 8025.16689448 5754.96525512 8309.44694516]
total_rewards_mean           7973.612187581084
total_rewards_std            764.2441691084034
total_rewards_max            8580.783454918585
total_rewards_min            5754.965255118916
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               32.166706276126206
(Previous) Eval Time (s)     27.477429253980517
Sample Time (s)              21.959417109843343
Epoch Time (s)               81.60355263995007
Total Train Time (s)         13025.608002073597
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:08:04.804701 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #156 | Epoch Duration: 81.57559752464294
2020-01-11 13:08:04.804971 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #156 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1603985
Z variance train             0.018761765
KL Divergence                29.376331
KL Loss                      2.9376333
QF Loss                      748.91034
VF Loss                      405.7658
Policy Loss                  -2666.9695
Q Predictions Mean           2673.156
Q Predictions Std            849.9787
Q Predictions Max            3464.2207
Q Predictions Min            104.91224
V Predictions Mean           2666.674
V Predictions Std            838.42084
V Predictions Max            3455.7625
V Predictions Min            104.79795
Log Pis Mean                 3.990968
Log Pis Std                  4.812022
Log Pis Max                  16.991848
Log Pis Min                  -7.0292025
Policy mu Mean               -0.051224858
Policy mu Std                1.3403344
Policy mu Max                3.0802205
Policy mu Min                -3.431369
Policy log std Mean          -0.71091604
Policy log std Std           0.3801864
Policy log std Max           -0.08791202
Policy log std Min           -2.4887362
Z mean eval                  2.183313
Z variance eval              0.01875658
total_rewards                [8138.68112638 8196.13400562 8213.06151692 8237.17980699 8454.8290708
 8534.52496643 8380.31321311 8294.39988887 8179.81607736 8314.77694257]
total_rewards_mean           8294.371661504787
total_rewards_std            121.70370828532121
total_rewards_max            8534.524966427543
total_rewards_min            8138.681126384749
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               32.091468083206564
(Previous) Eval Time (s)     27.449103095103055
Sample Time (s)              22.977306901477277
Epoch Time (s)               82.5178780797869
Total Train Time (s)         13108.380205229856
Epoch                        157
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:27.578169 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #157 | Epoch Duration: 82.7729697227478
2020-01-11 13:09:27.578561 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1843288
Z variance train             0.018695083
KL Divergence                30.225536
KL Loss                      3.0225537
QF Loss                      367.27243
VF Loss                      351.9325
Policy Loss                  -2822.964
Q Predictions Mean           2816.8745
Q Predictions Std            642.86456
Q Predictions Max            3483.8079
Q Predictions Min            102.616066
V Predictions Mean           2812.8052
V Predictions Std            635.41565
V Predictions Max            3483.7883
V Predictions Min            111.241615
Log Pis Mean                 4.645456
Log Pis Std                  4.122541
Log Pis Max                  16.314152
Log Pis Min                  -5.810479
Policy mu Mean               -0.18458688
Policy mu Std                1.3911924
Policy mu Max                2.7579005
Policy mu Min                -2.8049376
Policy log std Mean          -0.6953148
Policy log std Std           0.3670618
Policy log std Max           0.06722808
Policy log std Min           -2.5413923
Z mean eval                  2.1707952
Z variance eval              0.019570205
total_rewards                [8394.50978013 8120.94966761 8669.24955646 8390.04871691 8453.33751742
 8504.02741007 8410.53904979 8550.78493647 8614.40231324 8380.45046641]
total_rewards_mean           8448.829941449583
total_rewards_std            144.74607007570927
total_rewards_max            8669.24955646147
total_rewards_min            8120.949667608857
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               32.64221241977066
(Previous) Eval Time (s)     27.70375945419073
Sample Time (s)              21.9531758450903
Epoch Time (s)               82.29914771905169
Total Train Time (s)         13191.177050733007
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:10:50.377829 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #158 | Epoch Duration: 82.79907631874084
2020-01-11 13:10:50.378028 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1709785
Z variance train             0.019532867
KL Divergence                30.5111
KL Loss                      3.05111
QF Loss                      367.93744
VF Loss                      123.40687
Policy Loss                  -2731.0935
Q Predictions Mean           2728.9363
Q Predictions Std            767.4172
Q Predictions Max            3515.9114
Q Predictions Min            111.92651
V Predictions Mean           2728.6538
V Predictions Std            757.54144
V Predictions Max            3508.8982
V Predictions Min            115.1222
Log Pis Mean                 3.9842062
Log Pis Std                  4.6791973
Log Pis Max                  23.34141
Log Pis Min                  -6.2911525
Policy mu Mean               -0.09305751
Policy mu Std                1.3617815
Policy mu Max                3.7388265
Policy mu Min                -4.3848176
Policy log std Mean          -0.6909594
Policy log std Std           0.37988663
Policy log std Max           -0.07103239
Policy log std Min           -2.6738527
Z mean eval                  2.179823
Z variance eval              0.021304952
total_rewards                [8040.88230212 8000.54138174 7739.20669464 7983.2984479  7891.42486316
 7870.22842351 7491.67943965 7717.56880705 8082.19005766 7622.84153616]
total_rewards_mean           7843.986195359427
total_rewards_std            185.02723554931686
total_rewards_max            8082.190057659273
total_rewards_min            7491.67943965178
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               32.54895751923323
(Previous) Eval Time (s)     28.203358255326748
Sample Time (s)              21.93366146320477
Epoch Time (s)               82.68597723776475
Total Train Time (s)         13273.291741450317
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:12.496401 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #159 | Epoch Duration: 82.11813831329346
2020-01-11 13:12:12.496714 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.178524
Z variance train             0.02129187
KL Divergence                29.961823
KL Loss                      2.9961822
QF Loss                      361.32373
VF Loss                      339.13947
Policy Loss                  -2718.0022
Q Predictions Mean           2723.6282
Q Predictions Std            785.4607
Q Predictions Max            3500.926
Q Predictions Min            94.73536
V Predictions Mean           2733.1675
V Predictions Std            781.8608
V Predictions Max            3499.9858
V Predictions Min            114.96151
Log Pis Mean                 4.367237
Log Pis Std                  4.5824003
Log Pis Max                  14.5554085
Log Pis Min                  -5.6210938
Policy mu Mean               -0.10741816
Policy mu Std                1.3480103
Policy mu Max                2.8335993
Policy mu Min                -2.894303
Policy log std Mean          -0.70940137
Policy log std Std           0.41077542
Policy log std Max           -0.006300628
Policy log std Min           -2.6367137
Z mean eval                  2.1694179
Z variance eval              0.013005981
total_rewards                [8202.60558273 8158.5091134  8544.70470801 8257.17946169 8325.70968888
 8605.8972472  8344.57999227 8370.27727219 8254.70665527 8340.48546391]
total_rewards_mean           8340.4655185557
total_rewards_std            134.05062428784456
total_rewards_max            8605.897247204748
total_rewards_min            8158.5091133999595
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               32.4697908628732
(Previous) Eval Time (s)     27.63518008682877
Sample Time (s)              21.437140248250216
Epoch Time (s)               81.54211119795218
Total Train Time (s)         13355.745125736576
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:13:34.951727 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #160 | Epoch Duration: 82.45482444763184
2020-01-11 13:13:34.951957 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1710582
Z variance train             0.012960616
KL Divergence                30.515244
KL Loss                      3.0515244
QF Loss                      541.72076
VF Loss                      391.02557
Policy Loss                  -2659.5867
Q Predictions Mean           2664.122
Q Predictions Std            880.4134
Q Predictions Max            3469.4194
Q Predictions Min            121.6832
V Predictions Mean           2644.1023
V Predictions Std            876.82654
V Predictions Max            3442.1982
V Predictions Min            105.4444
Log Pis Mean                 3.4008212
Log Pis Std                  4.78595
Log Pis Max                  16.434406
Log Pis Min                  -6.613274
Policy mu Mean               -0.13765144
Policy mu Std                1.2866412
Policy mu Max                3.2824528
Policy mu Min                -2.7179706
Policy log std Mean          -0.6652009
Policy log std Std           0.3941817
Policy log std Max           -0.05624205
Policy log std Min           -2.7297373
Z mean eval                  2.1655755
Z variance eval              0.014214613
total_rewards                [8099.94006133 8167.32459464 8257.26241321 8303.75253973 8254.84442949
 8046.39010227 8099.02356375 8160.19886168 8092.15345837 8211.39967521]
total_rewards_mean           8169.228969966609
total_rewards_std            81.11707377019452
total_rewards_max            8303.75253972667
total_rewards_min            8046.390102265963
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               31.936776144895703
(Previous) Eval Time (s)     28.54758922290057
Sample Time (s)              22.604899014811963
Epoch Time (s)               83.08926438260823
Total Train Time (s)         13438.980610733852
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:14:58.191410 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #161 | Epoch Duration: 83.2392737865448
2020-01-11 13:14:58.191658 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1669714
Z variance train             0.014210914
KL Divergence                30.007301
KL Loss                      3.0007303
QF Loss                      3509.3289
VF Loss                      518.5312
Policy Loss                  -2796.788
Q Predictions Mean           2806.7036
Q Predictions Std            711.47784
Q Predictions Max            3504.0176
Q Predictions Min            97.70087
V Predictions Mean           2812.1353
V Predictions Std            709.28094
V Predictions Max            3527.7708
V Predictions Min            115.684845
Log Pis Mean                 4.4185305
Log Pis Std                  4.6406803
Log Pis Max                  17.608948
Log Pis Min                  -5.0928106
Policy mu Mean               -0.16481362
Policy mu Std                1.343435
Policy mu Max                2.6524968
Policy mu Min                -3.396403
Policy log std Mean          -0.7074659
Policy log std Std           0.39325824
Policy log std Max           0.03947586
Policy log std Min           -2.5490289
Z mean eval                  2.1748815
Z variance eval              0.010858184
total_rewards                [8476.36278425 8253.97637014 8284.96491802 8442.04014319 8239.25395211
 8248.08684507 3271.24051223 8147.87642314 8439.1778131  8654.72169791]
total_rewards_mean           7845.770145915629
total_rewards_std            1531.4542902685248
total_rewards_max            8654.72169791136
total_rewards_min            3271.240512230066
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               32.199974542018026
(Previous) Eval Time (s)     28.697162138298154
Sample Time (s)              21.68065315578133
Epoch Time (s)               82.57778983609751
Total Train Time (s)         13520.847769537475
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:16:20.059058 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #162 | Epoch Duration: 81.86723279953003
2020-01-11 13:16:20.059304 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.174609
Z variance train             0.010878979
KL Divergence                30.90638
KL Loss                      3.090638
QF Loss                      419.08328
VF Loss                      159.76161
Policy Loss                  -2783.644
Q Predictions Mean           2779.6377
Q Predictions Std            804.0906
Q Predictions Max            3529.5251
Q Predictions Min            78.02862
V Predictions Mean           2783.2769
V Predictions Std            798.8961
V Predictions Max            3514.6987
V Predictions Min            110.62862
Log Pis Mean                 4.13972
Log Pis Std                  4.448639
Log Pis Max                  17.953396
Log Pis Min                  -6.615619
Policy mu Mean               -0.09892393
Policy mu Std                1.3380995
Policy mu Max                3.1350775
Policy mu Min                -2.9906292
Policy log std Mean          -0.71696645
Policy log std Std           0.3966439
Policy log std Max           -0.05039394
Policy log std Min           -2.65165
Z mean eval                  2.16568
Z variance eval              0.022873867
total_rewards                [8229.81716236 8244.07644588 8257.51512198 8269.64558066 8361.15359317
 8201.39307414 8364.60204365 8539.99478251 8293.10329527 8648.9653141 ]
total_rewards_mean           8341.026641371334
total_rewards_std            138.20489848700578
total_rewards_max            8648.96531409905
total_rewards_min            8201.393074135114
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               32.98062768206
(Previous) Eval Time (s)     27.986317292321473
Sample Time (s)              22.74931017216295
Epoch Time (s)               83.71625514654443
Total Train Time (s)         13605.065778617747
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:17:44.279285 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #163 | Epoch Duration: 84.21983814239502
2020-01-11 13:17:44.279473 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.166281
Z variance train             0.022862151
KL Divergence                29.473824
KL Loss                      2.9473825
QF Loss                      629.7709
VF Loss                      130.5994
Policy Loss                  -2846.6323
Q Predictions Mean           2842.9453
Q Predictions Std            700.7001
Q Predictions Max            3543.0557
Q Predictions Min            94.47828
V Predictions Mean           2844.417
V Predictions Std            694.47406
V Predictions Max            3554.136
V Predictions Min            108.022484
Log Pis Mean                 4.157975
Log Pis Std                  4.6733356
Log Pis Max                  16.821898
Log Pis Min                  -6.384578
Policy mu Mean               -0.15417977
Policy mu Std                1.331062
Policy mu Max                2.7439165
Policy mu Min                -2.7177057
Policy log std Mean          -0.7120936
Policy log std Std           0.38676226
Policy log std Max           0.0086301565
Policy log std Min           -2.576136
Z mean eval                  2.1748798
Z variance eval              0.018965434
total_rewards                [8219.58300013 8420.37895809 8320.75910237 8303.12013761 7954.93734154
 8173.32211931 8153.44788183 8310.52779949 7908.68044639 8359.98127498]
total_rewards_mean           8212.473806174095
total_rewards_std            160.69316879055128
total_rewards_max            8420.378958091467
total_rewards_min            7908.68044639193
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               32.18664012989029
(Previous) Eval Time (s)     28.489611845929176
Sample Time (s)              22.754182788543403
Epoch Time (s)               83.43043476436287
Total Train Time (s)         13687.096014835406
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:19:06.312846 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #164 | Epoch Duration: 82.0332293510437
2020-01-11 13:19:06.313032 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.175464
Z variance train             0.019055964
KL Divergence                29.775196
KL Loss                      2.9775198
QF Loss                      601.7307
VF Loss                      303.30115
Policy Loss                  -2773.6519
Q Predictions Mean           2775.8154
Q Predictions Std            713.75635
Q Predictions Max            3498.1023
Q Predictions Min            98.72823
V Predictions Mean           2766.0005
V Predictions Std            709.13
V Predictions Max            3512.482
V Predictions Min            99.84457
Log Pis Mean                 4.1663322
Log Pis Std                  4.0161157
Log Pis Max                  14.012211
Log Pis Min                  -5.0645766
Policy mu Mean               -0.12358788
Policy mu Std                1.3212898
Policy mu Max                2.8414638
Policy mu Min                -3.0020294
Policy log std Mean          -0.70111674
Policy log std Std           0.38520968
Policy log std Max           0.14287704
Policy log std Min           -2.4891844
Z mean eval                  2.151649
Z variance eval              0.015551589
total_rewards                [8039.96656793 8464.42623389 8406.18784284 8472.74279395 8259.00237781
 8638.71358436 8424.51548038 8422.75466618 8441.11466642 8637.81456213]
total_rewards_mean           8420.72387758888
total_rewards_std            164.63271074116298
total_rewards_max            8638.713584356521
total_rewards_min            8039.966567929045
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               32.4438710231334
(Previous) Eval Time (s)     27.092116343788803
Sample Time (s)              22.196449742652476
Epoch Time (s)               81.73243710957468
Total Train Time (s)         13768.84188422421
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:20:28.060929 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #165 | Epoch Duration: 81.7477376461029
2020-01-11 13:20:28.061255 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1522832
Z variance train             0.015551744
KL Divergence                29.543638
KL Loss                      2.9543638
QF Loss                      861.64166
VF Loss                      415.15454
Policy Loss                  -2632.791
Q Predictions Mean           2632.8745
Q Predictions Std            800.7468
Q Predictions Max            3398.1582
Q Predictions Min            91.48517
V Predictions Mean           2640.9004
V Predictions Std            796.5296
V Predictions Max            3406.344
V Predictions Min            93.33141
Log Pis Mean                 4.0421505
Log Pis Std                  4.9423714
Log Pis Max                  36.666397
Log Pis Min                  -5.789901
Policy mu Mean               -0.08218036
Policy mu Std                1.3369756
Policy mu Max                6.289949
Policy mu Min                -5.6987963
Policy log std Mean          -0.7073717
Policy log std Std           0.38669866
Policy log std Max           0.65917134
Policy log std Min           -2.4734476
Z mean eval                  2.1688173
Z variance eval              0.016570847
total_rewards                [8259.4340206  8629.87727786 8579.09681932 8556.82068386 8395.30840031
 8548.68858561 8906.00811868 8399.48046464 8720.79725734 8439.29390349]
total_rewards_mean           8543.480553170908
total_rewards_std            174.93820265544375
total_rewards_max            8906.008118675029
total_rewards_min            8259.434020604913
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               32.31722186226398
(Previous) Eval Time (s)     27.107090051751584
Sample Time (s)              22.316013004630804
Epoch Time (s)               81.74032491864637
Total Train Time (s)         13851.967588198837
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:21:51.188908 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #166 | Epoch Duration: 83.12745714187622
2020-01-11 13:21:51.189113 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.169198
Z variance train             0.01651583
KL Divergence                30.049644
KL Loss                      3.0049646
QF Loss                      302.8443
VF Loss                      136.39145
Policy Loss                  -2713.68
Q Predictions Mean           2711.9937
Q Predictions Std            842.2739
Q Predictions Max            3482.4666
Q Predictions Min            99.43801
V Predictions Mean           2708.212
V Predictions Std            838.00885
V Predictions Max            3464.1143
V Predictions Min            98.93197
Log Pis Mean                 4.215662
Log Pis Std                  4.1973977
Log Pis Max                  13.698294
Log Pis Min                  -4.776114
Policy mu Mean               -0.11331111
Policy mu Std                1.3591719
Policy mu Max                2.8281724
Policy mu Min                -2.8064005
Policy log std Mean          -0.6884372
Policy log std Std           0.38625476
Policy log std Max           0.07525736
Policy log std Min           -2.6204925
Z mean eval                  2.1605563
Z variance eval              0.011455504
total_rewards                [8382.97185551 8195.44935824 8339.59833157 8324.23237442 8262.85107056
 8352.30952772 8333.13939758 8271.54119936 8123.42673695 8240.80464055]
total_rewards_mean           8282.632449246874
total_rewards_std            75.93467165878499
total_rewards_max            8382.971855505491
total_rewards_min            8123.4267369468
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               32.253836817108095
(Previous) Eval Time (s)     28.49390060873702
Sample Time (s)              22.184308847412467
Epoch Time (s)               82.93204627325758
Total Train Time (s)         13933.113986016251
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:23:12.336385 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #167 | Epoch Duration: 81.14712333679199
2020-01-11 13:23:12.336591 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1631608
Z variance train             0.011473628
KL Divergence                30.803967
KL Loss                      3.0803967
QF Loss                      579.1387
VF Loss                      166.38017
Policy Loss                  -2803.6963
Q Predictions Mean           2802.982
Q Predictions Std            724.9704
Q Predictions Max            3490.7314
Q Predictions Min            120.048256
V Predictions Mean           2802.4062
V Predictions Std            725.3629
V Predictions Max            3466.6233
V Predictions Min            108.59888
Log Pis Mean                 4.529895
Log Pis Std                  4.411736
Log Pis Max                  16.078285
Log Pis Min                  -5.445009
Policy mu Mean               -0.15306813
Policy mu Std                1.3663051
Policy mu Max                2.6738825
Policy mu Min                -3.2899528
Policy log std Mean          -0.70974034
Policy log std Std           0.38388225
Policy log std Max           -0.03130266
Policy log std Min           -2.7281032
Z mean eval                  2.1685703
Z variance eval              0.007972
total_rewards                [8406.69938312 8582.78047879 8339.85780719 8681.12512202 8639.57270943
 8774.80129471 8526.57793607 8653.86389717 8495.99998097 8739.25267889]
total_rewards_mean           8584.053128834974
total_rewards_std            134.16213425986922
total_rewards_max            8774.80129470524
total_rewards_min            8339.857807186525
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               32.5951568428427
(Previous) Eval Time (s)     26.708627664018422
Sample Time (s)              22.599341060500592
Epoch Time (s)               81.90312556736171
Total Train Time (s)         14016.030942118261
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:24:35.254572 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #168 | Epoch Duration: 82.9178307056427
2020-01-11 13:24:35.254718 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1667483
Z variance train             0.007983036
KL Divergence                31.342255
KL Loss                      3.1342256
QF Loss                      882.99713
VF Loss                      459.3475
Policy Loss                  -2766.6726
Q Predictions Mean           2763.5461
Q Predictions Std            794.5885
Q Predictions Max            3512.4114
Q Predictions Min            104.48339
V Predictions Mean           2768.1936
V Predictions Std            792.9538
V Predictions Max            3483.6084
V Predictions Min            105.471085
Log Pis Mean                 4.704301
Log Pis Std                  4.863737
Log Pis Max                  15.959921
Log Pis Min                  -4.7189775
Policy mu Mean               -0.14056568
Policy mu Std                1.3779981
Policy mu Max                4.727532
Policy mu Min                -2.7378557
Policy log std Mean          -0.7103374
Policy log std Std           0.39875862
Policy log std Max           -0.052495778
Policy log std Min           -2.851142
Z mean eval                  2.2038207
Z variance eval              0.009045398
total_rewards                [8413.73125389 8070.50420539 4568.65701964 8314.92877818 8051.53928728
 8029.45772827 8512.82419425 8199.88311927 7978.88521857 1267.89955853]
total_rewards_mean           7140.8310363274095
total_rewards_std            2242.6728307029566
total_rewards_max            8512.824194245835
total_rewards_min            1267.8995585296811
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               32.320627447683364
(Previous) Eval Time (s)     27.722990276291966
Sample Time (s)              21.704000238329172
Epoch Time (s)               81.7476179623045
Total Train Time (s)         14097.59427313134
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:25:56.821142 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #169 | Epoch Duration: 81.56631064414978
2020-01-11 13:25:56.821322 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2026305
Z variance train             0.009038573
KL Divergence                31.4452
KL Loss                      3.14452
QF Loss                      534.20526
VF Loss                      258.1293
Policy Loss                  -2828.897
Q Predictions Mean           2831.3408
Q Predictions Std            679.627
Q Predictions Max            3493.1575
Q Predictions Min            88.73053
V Predictions Mean           2830.5688
V Predictions Std            676.93195
V Predictions Max            3499.0598
V Predictions Min            102.54018
Log Pis Mean                 4.383283
Log Pis Std                  4.4419017
Log Pis Max                  16.450771
Log Pis Min                  -7.1141253
Policy mu Mean               -0.08657404
Policy mu Std                1.3680065
Policy mu Max                3.9902823
Policy mu Min                -2.8494825
Policy log std Mean          -0.699058
Policy log std Std           0.36272112
Policy log std Max           0.031098366
Policy log std Min           -2.6377742
Z mean eval                  2.1612115
Z variance eval              0.00840072
total_rewards                [8290.14506568 8630.34966887 8508.26635439 8453.53908703 8557.12844672
 8613.60960602 8537.36778551 8303.8388728  8441.50181925 8255.97944083]
total_rewards_mean           8459.17261470964
total_rewards_std            128.68672676502723
total_rewards_max            8630.349668870773
total_rewards_min            8255.979440834235
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               32.161389937624335
(Previous) Eval Time (s)     27.541303574107587
Sample Time (s)              22.56612768024206
Epoch Time (s)               82.26882119197398
Total Train Time (s)         14180.810064418707
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:27:20.040601 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #170 | Epoch Duration: 83.21915698051453
2020-01-11 13:27:20.040802 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1610477
Z variance train             0.008403895
KL Divergence                31.234488
KL Loss                      3.1234488
QF Loss                      558.047
VF Loss                      285.93826
Policy Loss                  -2784.5137
Q Predictions Mean           2795.9312
Q Predictions Std            797.0648
Q Predictions Max            3580.4355
Q Predictions Min            102.12215
V Predictions Mean           2797.5898
V Predictions Std            793.1001
V Predictions Max            3567.28
V Predictions Min            105.9998
Log Pis Mean                 3.9836402
Log Pis Std                  4.316862
Log Pis Max                  13.378947
Log Pis Min                  -5.7061806
Policy mu Mean               -0.072469026
Policy mu Std                1.3339747
Policy mu Max                2.8003051
Policy mu Min                -2.863253
Policy log std Mean          -0.68844557
Policy log std Std           0.3778439
Policy log std Max           0.14966619
Policy log std Min           -2.4936337
Z mean eval                  2.1902947
Z variance eval              0.0108958855
total_rewards                [8264.20879001 8288.82005058 8459.09039862 8387.04577643 8370.18232368
 8566.39719559 8231.9561798  8263.19556451 8372.29962103 8142.08023893]
total_rewards_mean           8334.527613917437
total_rewards_std            115.9373112219732
total_rewards_max            8566.39719559325
total_rewards_min            8142.080238930463
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               32.19271402899176
(Previous) Eval Time (s)     28.491293444298208
Sample Time (s)              22.75798770133406
Epoch Time (s)               83.44199517462403
Total Train Time (s)         14263.511980766896
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:28:42.744769 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #171 | Epoch Duration: 82.70381116867065
2020-01-11 13:28:42.744977 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.192122
Z variance train             0.010868586
KL Divergence                31.347183
KL Loss                      3.1347184
QF Loss                      868.23676
VF Loss                      161.67984
Policy Loss                  -2865.65
Q Predictions Mean           2866.3337
Q Predictions Std            661.33044
Q Predictions Max            3537.289
Q Predictions Min            94.92277
V Predictions Mean           2862.4402
V Predictions Std            651.7874
V Predictions Max            3522.557
V Predictions Min            98.013504
Log Pis Mean                 4.538002
Log Pis Std                  4.4060307
Log Pis Max                  14.86231
Log Pis Min                  -6.5945315
Policy mu Mean               -0.026469626
Policy mu Std                1.3883978
Policy mu Max                3.7622716
Policy mu Min                -3.2624235
Policy log std Mean          -0.68867683
Policy log std Std           0.35682368
Policy log std Max           0.08361256
Policy log std Min           -2.8073144
Z mean eval                  2.1598158
Z variance eval              0.010527335
total_rewards                [8535.07867381 8708.7372515  8596.75905993 8553.08074658 8735.29591357
 8451.72357209 8675.34937832 8496.20711341 8645.41239634 8761.59180427]
total_rewards_mean           8615.923590982367
total_rewards_std            100.31473140288021
total_rewards_max            8761.591804266818
total_rewards_min            8451.723572087574
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               32.202936307061464
(Previous) Eval Time (s)     27.752759610768408
Sample Time (s)              22.724454111419618
Epoch Time (s)               82.68015002924949
Total Train Time (s)         14347.33307537809
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:30:06.567909 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #172 | Epoch Duration: 83.8227813243866
2020-01-11 13:30:06.568117 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1600502
Z variance train             0.010540567
KL Divergence                31.090147
KL Loss                      3.1090147
QF Loss                      594.60254
VF Loss                      164.14493
Policy Loss                  -2892.645
Q Predictions Mean           2891.8071
Q Predictions Std            668.01166
Q Predictions Max            3515.6978
Q Predictions Min            99.55593
V Predictions Mean           2896.0654
V Predictions Std            664.8419
V Predictions Max            3502.2524
V Predictions Min            96.603455
Log Pis Mean                 4.936455
Log Pis Std                  5.019488
Log Pis Max                  20.221407
Log Pis Min                  -6.756613
Policy mu Mean               -0.16185905
Policy mu Std                1.4103508
Policy mu Max                3.297838
Policy mu Min                -2.754206
Policy log std Mean          -0.71321255
Policy log std Std           0.38029778
Policy log std Max           -0.03395334
Policy log std Min           -2.5858603
Z mean eval                  2.1648152
Z variance eval              0.008551662
total_rewards                [8253.70767244 8351.71341665 8230.09456064 8234.58328714 8350.06397107
 8135.84320851 8214.77210547 8273.71028071 8144.26533834 8315.63639373]
total_rewards_mean           8250.43902347096
total_rewards_std            71.64289795135831
total_rewards_max            8351.71341665464
total_rewards_min            8135.8432085146915
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               32.477429947815835
(Previous) Eval Time (s)     28.895091965794563
Sample Time (s)              22.85416153864935
Epoch Time (s)               84.22668345225975
Total Train Time (s)         14430.384973485488
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:31:29.622122 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #173 | Epoch Duration: 83.05386662483215
2020-01-11 13:31:29.622310 UTC | [2020_01_10_11_46_20] [2020_01_11_00_02_43] [2020_01_11_09_30_58] Iteration #173 | Started Training: True
