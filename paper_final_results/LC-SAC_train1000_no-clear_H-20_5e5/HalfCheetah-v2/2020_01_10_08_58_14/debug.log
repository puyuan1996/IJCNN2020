---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.001665857
Z variance train             0.6939996
KL Divergence                0.14821959
KL Loss                      0.014821959
QF Loss                      31.229198
VF Loss                      16.272526
Policy Loss                  -4.001113
Q Predictions Mean           -0.002410819
Q Predictions Std            0.0023329558
Q Predictions Max            0.0028117641
Q Predictions Min            -0.011669379
V Predictions Mean           -0.0015952892
V Predictions Std            0.0011524304
V Predictions Max            0.002049731
V Predictions Min            -0.0048056818
Log Pis Mean                 -4.0268764
Log Pis Std                  0.5006648
Log Pis Max                  -2.7188148
Log Pis Min                  -5.6398134
Policy mu Mean               -0.00012204088
Policy mu Std                0.0013571002
Policy mu Max                0.0038402323
Policy mu Min                -0.004229544
Policy log std Mean          -0.0006187927
Policy log std Std           0.0009721947
Policy log std Max           0.0019530763
Policy log std Min           -0.003607768
Z mean eval                  0.2500392
Z variance eval              0.2317594
total_rewards                [-345.35164555 -276.42860605 -151.9919622  -112.35588913 -221.30061761
 -162.64833275 -216.84819637 -226.95232064 -131.347171   -109.1431411 ]
total_rewards_mean           -195.43678823859432
total_rewards_std            72.50779126419594
total_rewards_max            -109.14314110087382
total_rewards_min            -345.3516455473914
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               28.912174249067903
(Previous) Eval Time (s)     0
Sample Time (s)              24.202132397331297
Epoch Time (s)               53.1143066463992
Total Train Time (s)         75.90670800721273
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 08:59:30.118924 UTC | [2020_01_10_08_58_14] Iteration #0 | Epoch Duration: 75.91028571128845
2020-01-10 08:59:30.119178 UTC | [2020_01_10_08_58_14] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.2584095
Z variance train             0.22655296
KL Divergence                2.0280619
KL Loss                      0.20280619
QF Loss                      32.598515
VF Loss                      4.1254067
Policy Loss                  -14.125619
Q Predictions Mean           10.657736
Q Predictions Std            6.2672834
Q Predictions Max            28.54066
Q Predictions Min            -5.5720744
V Predictions Mean           15.166788
V Predictions Std            5.9617443
V Predictions Max            35.61169
V Predictions Min            -1.7345933
Log Pis Mean                 -3.215521
Log Pis Std                  1.1229734
Log Pis Max                  1.0562754
Log Pis Min                  -6.509409
Policy mu Mean               0.23953362
Policy mu Std                0.35334957
Policy mu Max                1.2890923
Policy mu Min                -1.4874307
Policy log std Mean          -0.17423888
Policy log std Std           0.06579379
Policy log std Max           -0.0600947
Policy log std Min           -0.5082317
Z mean eval                  0.76779044
Z variance eval              0.07120937
total_rewards                [-244.8449505  -246.8485069  -258.2177133  -257.88058263 -268.96799138
 -269.02550857 -257.41356666 -245.6907868  -259.90685789 -255.70959385]
total_rewards_mean           -256.4506058475844
total_rewards_std            8.222335058941663
total_rewards_max            -244.844950500084
total_rewards_min            -269.02550856734047
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               25.015362475067377
(Previous) Eval Time (s)     22.795449460390955
Sample Time (s)              17.105559880379587
Epoch Time (s)               64.91637181583792
Total Train Time (s)         141.8576587899588
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:00:36.075705 UTC | [2020_01_10_08_58_14] Iteration #1 | Epoch Duration: 65.95632886886597
2020-01-10 09:00:36.076044 UTC | [2020_01_10_08_58_14] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.73022014
Z variance train             0.08230704
KL Divergence                6.2726183
KL Loss                      0.6272618
QF Loss                      28.951212
VF Loss                      14.91595
Policy Loss                  -36.212456
Q Predictions Mean           32.041233
Q Predictions Std            11.31773
Q Predictions Max            57.72696
Q Predictions Min            3.0220046
V Predictions Mean           37.743874
V Predictions Std            11.4701805
V Predictions Max            63.42405
V Predictions Min            5.948652
Log Pis Mean                 -2.5249045
Log Pis Std                  1.58495
Log Pis Max                  1.4697204
Log Pis Min                  -7.3834753
Policy mu Mean               -0.048745196
Policy mu Std                0.58880854
Policy mu Max                1.3650094
Policy mu Min                -1.9288692
Policy log std Mean          -0.274916
Policy log std Std           0.10187235
Policy log std Max           -0.10612653
Policy log std Min           -0.59819645
Z mean eval                  0.8613607
Z variance eval              0.054599874
total_rewards                [-234.80139505 -215.44165587 -243.23095477 -255.10600625 -219.48325597
 -202.19853086 -220.64196282 -194.40695711 -229.92614918 -190.64550141]
total_rewards_mean           -220.58823693042933
total_rewards_std            19.8527046456169
total_rewards_max            -190.64550141270408
total_rewards_min            -255.10600625174854
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               30.352718795184046
(Previous) Eval Time (s)     23.834975086152554
Sample Time (s)              16.202683757059276
Epoch Time (s)               70.39037763839588
Total Train Time (s)         210.9711889945902
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:01:45.190681 UTC | [2020_01_10_08_58_14] Iteration #2 | Epoch Duration: 69.11436223983765
2020-01-10 09:01:45.190961 UTC | [2020_01_10_08_58_14] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87617147
Z variance train             0.053652644
KL Divergence                8.757435
KL Loss                      0.8757435
QF Loss                      37.24514
VF Loss                      10.991609
Policy Loss                  -54.366447
Q Predictions Mean           48.942993
Q Predictions Std            13.197094
Q Predictions Max            90.43529
Q Predictions Min            9.003035
V Predictions Mean           52.22738
V Predictions Std            12.499101
V Predictions Max            89.873085
V Predictions Min            14.694919
Log Pis Mean                 -3.106771
Log Pis Std                  1.3789892
Log Pis Max                  3.3778067
Log Pis Min                  -6.168265
Policy mu Mean               0.13170184
Policy mu Std                0.43849668
Policy mu Max                1.563726
Policy mu Min                -1.1457798
Policy log std Mean          -0.23340265
Policy log std Std           0.09567691
Policy log std Max           -0.11125434
Policy log std Min           -0.6035615
Z mean eval                  0.9681695
Z variance eval              0.031237686
total_rewards                [-243.8138945  -220.73074904 -228.79540831 -301.82006741 -264.29019691
 -241.49784676 -234.88376313 -293.1485918  -255.98815439 -281.79160239]
total_rewards_mean           -256.6760274640572
total_rewards_std            26.452938446343854
total_rewards_max            -220.73074904375005
total_rewards_min            -301.8200674054877
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               26.968679851852357
(Previous) Eval Time (s)     22.558592678047717
Sample Time (s)              16.76494185999036
Epoch Time (s)               66.29221438989043
Total Train Time (s)         277.4475782010704
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:02:51.666186 UTC | [2020_01_10_08_58_14] Iteration #3 | Epoch Duration: 66.47504472732544
2020-01-10 09:02:51.666336 UTC | [2020_01_10_08_58_14] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9644313
Z variance train             0.031315338
KL Divergence                11.165116
KL Loss                      1.1165117
QF Loss                      40.417988
VF Loss                      8.043112
Policy Loss                  -73.75308
Q Predictions Mean           68.6167
Q Predictions Std            14.940545
Q Predictions Max            106.48848
Q Predictions Min            18.075294
V Predictions Mean           72.49098
V Predictions Std            14.389882
V Predictions Max            110.15829
V Predictions Min            19.450941
Log Pis Mean                 -2.8300414
Log Pis Std                  1.5669785
Log Pis Max                  4.5037374
Log Pis Min                  -7.2117395
Policy mu Mean               0.11812254
Policy mu Std                0.5250913
Policy mu Max                1.8268335
Policy mu Min                -1.3045956
Policy log std Mean          -0.25556037
Policy log std Std           0.11302785
Policy log std Max           -0.04225508
Policy log std Min           -0.6481705
Z mean eval                  1.1074857
Z variance eval              0.037572898
total_rewards                [-156.57903813 -222.1649407  -202.05462275 -144.76117661 -142.72811604
 -185.37576979 -207.70565001 -149.00447408 -227.0859067  -133.78156774]
total_rewards_mean           -177.12412625622733
total_rewards_std            33.86966524112742
total_rewards_max            -133.7815677425766
total_rewards_min            -227.0859067044404
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               27.62200221279636
(Previous) Eval Time (s)     22.741137630771846
Sample Time (s)              16.59162740316242
Epoch Time (s)               66.95476724673063
Total Train Time (s)         344.4202074864879
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:03:58.642304 UTC | [2020_01_10_08_58_14] Iteration #4 | Epoch Duration: 66.97580766677856
2020-01-10 09:03:58.642576 UTC | [2020_01_10_08_58_14] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1074494
Z variance train             0.03758136
KL Divergence                12.398289
KL Loss                      1.239829
QF Loss                      36.610634
VF Loss                      9.135693
Policy Loss                  -91.10844
Q Predictions Mean           87.51501
Q Predictions Std            11.999767
Q Predictions Max            135.76172
Q Predictions Min            57.960766
V Predictions Mean           89.55633
V Predictions Std            12.24617
V Predictions Max            133.3336
V Predictions Min            58.327454
Log Pis Mean                 -3.0210814
Log Pis Std                  1.9394618
Log Pis Max                  8.242103
Log Pis Min                  -7.169951
Policy mu Mean               0.087795146
Policy mu Std                0.49196282
Policy mu Max                2.0592828
Policy mu Min                -1.2366812
Policy log std Mean          -0.22818428
Policy log std Std           0.122394495
Policy log std Max           -0.026782276
Policy log std Min           -0.6744095
Z mean eval                  1.1895984
Z variance eval              0.041566294
total_rewards                [-135.77991738 -121.24739257 -141.82801663 -128.05092992  -85.84635171
 -151.90815451 -105.10051931 -162.18124005 -144.26250514 -117.09002961]
total_rewards_mean           -129.3295056827299
total_rewards_std            21.689710546959507
total_rewards_max            -85.84635171408698
total_rewards_min            -162.18124005067887
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               27.569878790993243
(Previous) Eval Time (s)     22.761839393060654
Sample Time (s)              16.464582772925496
Epoch Time (s)               66.7963009569794
Total Train Time (s)         411.9269326431677
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:05:06.151066 UTC | [2020_01_10_08_58_14] Iteration #5 | Epoch Duration: 67.50825548171997
2020-01-10 09:05:06.151379 UTC | [2020_01_10_08_58_14] Iteration #5 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1914191
Z variance train             0.04162691
KL Divergence                13.026811
KL Loss                      1.3026811
QF Loss                      36.76512
VF Loss                      9.854804
Policy Loss                  -104.52787
Q Predictions Mean           99.67949
Q Predictions Std            17.991692
Q Predictions Max            172.4487
Q Predictions Min            54.753017
V Predictions Mean           102.70514
V Predictions Std            17.30235
V Predictions Max            171.05553
V Predictions Min            67.19478
Log Pis Mean                 -3.2687614
Log Pis Std                  1.541667
Log Pis Max                  2.1750355
Log Pis Min                  -7.186391
Policy mu Mean               0.055035517
Policy mu Std                0.42713413
Policy mu Max                1.6889753
Policy mu Min                -1.5590165
Policy log std Mean          -0.22162051
Policy log std Std           0.12139466
Policy log std Max           -0.030637786
Policy log std Min           -0.6720606
Z mean eval                  1.238487
Z variance eval              0.044732947
total_rewards                [ -21.3573892  -212.66832744 -159.50352332 -200.44689451 -163.2565694
 -172.37928879  -58.8155511  -162.75264375 -122.64630074 -170.04018426]
total_rewards_mean           -144.3866672503752
total_rewards_std            57.53258932441645
total_rewards_max            -21.357389199491656
total_rewards_min            -212.66832743897893
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               30.13869318459183
(Previous) Eval Time (s)     23.47348156105727
Sample Time (s)              15.979176774155349
Epoch Time (s)               69.59135151980445
Total Train Time (s)         481.5414353925735
Epoch                        6
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:06:15.764428 UTC | [2020_01_10_08_58_14] Iteration #6 | Epoch Duration: 69.61284828186035
2020-01-10 09:06:15.764571 UTC | [2020_01_10_08_58_14] Iteration #6 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.24082
Z variance train             0.04459249
KL Divergence                13.468488
KL Loss                      1.3468488
QF Loss                      34.71776
VF Loss                      7.118634
Policy Loss                  -115.77089
Q Predictions Mean           110.76785
Q Predictions Std            19.158892
Q Predictions Max            172.5671
Q Predictions Min            82.75499
V Predictions Mean           114.302155
V Predictions Std            18.575354
V Predictions Max            175.72145
V Predictions Min            86.15467
Log Pis Mean                 -3.3854795
Log Pis Std                  1.2990154
Log Pis Max                  2.4499497
Log Pis Min                  -7.327654
Policy mu Mean               0.038119834
Policy mu Std                0.38509446
Policy mu Max                1.5966052
Policy mu Min                -1.5318449
Policy log std Mean          -0.22619432
Policy log std Std           0.09939245
Policy log std Max           -0.05066881
Policy log std Min           -0.59896773
Z mean eval                  1.2630955
Z variance eval              0.04017728
total_rewards                [-119.61153626 -114.62112251 -164.39081431 -149.41086776 -118.23505942
 -122.07337507 -161.08257981 -139.40912875 -114.11131812 -163.48286802]
total_rewards_mean           -136.64286700264876
total_rewards_std            20.22898779239888
total_rewards_max            -114.11131811950037
total_rewards_min            -164.39081430526915
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               26.728347764350474
(Previous) Eval Time (s)     23.494682004209608
Sample Time (s)              17.773656600154936
Epoch Time (s)               67.99668636871502
Total Train Time (s)         548.7009574314579
Epoch                        7
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:07:22.925909 UTC | [2020_01_10_08_58_14] Iteration #7 | Epoch Duration: 67.16121482849121
2020-01-10 09:07:22.926099 UTC | [2020_01_10_08_58_14] Iteration #7 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2584902
Z variance train             0.040543783
KL Divergence                14.394935
KL Loss                      1.4394935
QF Loss                      29.3838
VF Loss                      16.69632
Policy Loss                  -129.14491
Q Predictions Mean           126.384964
Q Predictions Std            23.088644
Q Predictions Max            204.37271
Q Predictions Min            88.34249
V Predictions Mean           131.62328
V Predictions Std            24.63975
V Predictions Max            210.31795
V Predictions Min            101.012924
Log Pis Mean                 -3.2649994
Log Pis Std                  1.4958988
Log Pis Max                  3.6072178
Log Pis Min                  -6.500685
Policy mu Mean               0.0664019
Policy mu Std                0.43504944
Policy mu Max                1.9382229
Policy mu Min                -1.3684496
Policy log std Mean          -0.24296062
Policy log std Std           0.11671688
Policy log std Max           -0.018879961
Policy log std Min           -0.7294214
Z mean eval                  1.2697594
Z variance eval              0.04526194
total_rewards                [-109.58487721  -92.98266521  -45.01056306  -53.1065239   -58.10348006
  -65.11141471  -46.35244003 -111.73166636  -73.22638698  -75.8130974 ]
total_rewards_mean           -73.10231149069855
total_rewards_std            23.279067267269404
total_rewards_max            -45.01056305688335
total_rewards_min            -111.73166635982119
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               29.305201631970704
(Previous) Eval Time (s)     22.658879712689668
Sample Time (s)              16.326672579627484
Epoch Time (s)               68.29075392428786
Total Train Time (s)         617.4715425926261
Epoch                        8
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:08:31.697194 UTC | [2020_01_10_08_58_14] Iteration #8 | Epoch Duration: 68.77095198631287
2020-01-10 09:08:31.697377 UTC | [2020_01_10_08_58_14] Iteration #8 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2688892
Z variance train             0.045183294
KL Divergence                13.829837
KL Loss                      1.3829837
QF Loss                      38.508415
VF Loss                      8.174326
Policy Loss                  -137.60152
Q Predictions Mean           131.63199
Q Predictions Std            26.269693
Q Predictions Max            210.90208
Q Predictions Min            93.3929
V Predictions Mean           138.37006
V Predictions Std            26.779297
V Predictions Max            221.74205
V Predictions Min            103.71865
Log Pis Mean                 -3.1480002
Log Pis Std                  1.5331771
Log Pis Max                  2.5442562
Log Pis Min                  -6.3734326
Policy mu Mean               0.023635365
Policy mu Std                0.4469214
Policy mu Max                1.8232647
Policy mu Min                -1.8776144
Policy log std Mean          -0.2448324
Policy log std Std           0.111863226
Policy log std Max           -0.043803222
Policy log std Min           -0.68790275
Z mean eval                  1.3355565
Z variance eval              0.054635514
total_rewards                [ -81.40493453 -108.65444317 -101.65792444 -106.10454808 -106.46491403
  -47.99758442  -46.75633695  -60.71028109  -26.22120057  -78.49271826]
total_rewards_mean           -76.44648855421863
total_rewards_std            28.18421805236621
total_rewards_max            -26.22120057165059
total_rewards_min            -108.65444316871466
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               29.624113699886948
(Previous) Eval Time (s)     23.138796237763017
Sample Time (s)              16.64257454359904
Epoch Time (s)               69.405484481249
Total Train Time (s)         686.7242401363328
Epoch                        9
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:09:40.952928 UTC | [2020_01_10_08_58_14] Iteration #9 | Epoch Duration: 69.25535130500793
2020-01-10 09:09:40.953225 UTC | [2020_01_10_08_58_14] Iteration #9 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3298116
Z variance train             0.05541997
KL Divergence                14.6108055
KL Loss                      1.4610806
QF Loss                      34.249428
VF Loss                      21.563831
Policy Loss                  -144.43108
Q Predictions Mean           141.75906
Q Predictions Std            27.5981
Q Predictions Max            236.98068
Q Predictions Min            113.690994
V Predictions Mean           147.55087
V Predictions Std            29.244297
V Predictions Max            247.33115
V Predictions Min            115.64328
Log Pis Mean                 -3.4067235
Log Pis Std                  1.2781014
Log Pis Max                  3.4445632
Log Pis Min                  -6.6683025
Policy mu Mean               0.020752005
Policy mu Std                0.3988706
Policy mu Max                1.4941078
Policy mu Min                -1.7744583
Policy log std Mean          -0.22887546
Policy log std Std           0.09441464
Policy log std Max           -0.03661461
Policy log std Min           -0.6218989
Z mean eval                  1.341332
Z variance eval              0.054147877
total_rewards                [ -52.09810035 -105.81478434  -49.22742826  -50.75482935  -92.01757009
  -73.32828396  -45.60725238  -16.13210616  -33.44188837  -82.75794359]
total_rewards_mean           -60.118018686276784
total_rewards_std            26.306625045760935
total_rewards_max            -16.132106158890515
total_rewards_min            -105.81478434323111
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               27.821842147037387
(Previous) Eval Time (s)     22.988336682785302
Sample Time (s)              16.05850871698931
Epoch Time (s)               66.868687546812
Total Train Time (s)         752.8921759752557
Epoch                        10
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:10:47.120676 UTC | [2020_01_10_08_58_14] Iteration #10 | Epoch Duration: 66.16724848747253
2020-01-10 09:10:47.120905 UTC | [2020_01_10_08_58_14] Iteration #10 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3388059
Z variance train             0.05425678
KL Divergence                15.756594
KL Loss                      1.5756594
QF Loss                      38.530468
VF Loss                      11.671496
Policy Loss                  -156.4435
Q Predictions Mean           154.36275
Q Predictions Std            33.807194
Q Predictions Max            255.47499
Q Predictions Min            113.88743
V Predictions Mean           157.93347
V Predictions Std            32.94472
V Predictions Max            254.62448
V Predictions Min            117.49571
Log Pis Mean                 -3.3676362
Log Pis Std                  1.3508728
Log Pis Max                  1.6465929
Log Pis Min                  -5.999426
Policy mu Mean               0.016679427
Policy mu Std                0.42989436
Policy mu Max                2.0023031
Policy mu Min                -1.817901
Policy log std Mean          -0.22640543
Policy log std Std           0.10395036
Policy log std Max           0.01256761
Policy log std Min           -0.7458792
Z mean eval                  1.338485
Z variance eval              0.05236743
total_rewards                [ -72.87262109  -57.3612086   -22.35212117  -27.89533435 -122.31462837
    3.05022485   -1.07940869  -50.76762998 -114.37861475  -41.57956158]
total_rewards_mean           -50.75509037205235
total_rewards_std            40.59275696699277
total_rewards_max            3.050224848283441
total_rewards_min            -122.31462836602336
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               26.652983963955194
(Previous) Eval Time (s)     22.28665327001363
Sample Time (s)              16.078812999650836
Epoch Time (s)               65.01845023361966
Total Train Time (s)         817.7885047672316
Epoch                        11
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:11:52.018479 UTC | [2020_01_10_08_58_14] Iteration #11 | Epoch Duration: 64.89743423461914
2020-01-10 09:11:52.018692 UTC | [2020_01_10_08_58_14] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3393333
Z variance train             0.052370477
KL Divergence                14.829732
KL Loss                      1.4829732
QF Loss                      29.346996
VF Loss                      10.429394
Policy Loss                  -164.31314
Q Predictions Mean           159.5739
Q Predictions Std            35.39204
Q Predictions Max            271.8816
Q Predictions Min            121.14737
V Predictions Mean           164.80771
V Predictions Std            35.66229
V Predictions Max            279.04425
V Predictions Min            124.34101
Log Pis Mean                 -3.3596048
Log Pis Std                  1.4450405
Log Pis Max                  4.0754666
Log Pis Min                  -7.3084598
Policy mu Mean               0.020655261
Policy mu Std                0.39494506
Policy mu Max                1.7916652
Policy mu Min                -1.6015257
Policy log std Mean          -0.2266864
Policy log std Std           0.10134603
Policy log std Max           0.09751405
Policy log std Min           -0.7236108
Z mean eval                  1.3507457
Z variance eval              0.050966393
total_rewards                [ 22.18802775  27.44173124  35.68635263 -23.24753889  21.44328132
 -22.91914797 -26.74776213  10.74365621 -34.6613517  -43.63884057]
total_rewards_mean           -3.3711592095559744
total_rewards_std            28.04888975914192
total_rewards_max            35.68635263293135
total_rewards_min            -43.63884057083568
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               30.778122550807893
(Previous) Eval Time (s)     22.165343713015318
Sample Time (s)              16.40451293392107
Epoch Time (s)               69.34797919774428
Total Train Time (s)         888.0502441278659
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:13:02.282852 UTC | [2020_01_10_08_58_14] Iteration #12 | Epoch Duration: 70.26396465301514
2020-01-10 09:13:02.283120 UTC | [2020_01_10_08_58_14] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.349337
Z variance train             0.05093645
KL Divergence                14.963692
KL Loss                      1.4963692
QF Loss                      39.66178
VF Loss                      6.8575892
Policy Loss                  -167.57986
Q Predictions Mean           162.09573
Q Predictions Std            32.26766
Q Predictions Max            268.11072
Q Predictions Min            118.936485
V Predictions Mean           167.16733
V Predictions Std            32.586643
V Predictions Max            267.63388
V Predictions Min            126.19645
Log Pis Mean                 -3.4022422
Log Pis Std                  1.4168874
Log Pis Max                  2.2191088
Log Pis Min                  -7.2571287
Policy mu Mean               0.029371
Policy mu Std                0.41868755
Policy mu Max                1.897032
Policy mu Min                -1.6452887
Policy log std Mean          -0.240511
Policy log std Std           0.1008204
Policy log std Max           -0.0016448162
Policy log std Min           -0.82051295
Z mean eval                  1.3602806
Z variance eval              0.053330373
total_rewards                [ 59.08040129  35.85168319  18.0773164   29.61382178 -48.34763529
  21.43788118  58.21635088  63.35151826  81.13755408  46.16151272]
total_rewards_mean           36.458040448518226
total_rewards_std            34.06103430763381
total_rewards_max            81.13755407989548
total_rewards_min            -48.34763529243333
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               31.191093089058995
(Previous) Eval Time (s)     23.0810627900064
Sample Time (s)              16.238376502413303
Epoch Time (s)               70.5105323814787
Total Train Time (s)         957.8343920987099
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:14:12.066971 UTC | [2020_01_10_08_58_14] Iteration #13 | Epoch Duration: 69.78365302085876
2020-01-10 09:14:12.067170 UTC | [2020_01_10_08_58_14] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3579353
Z variance train             0.053294934
KL Divergence                15.192989
KL Loss                      1.5192989
QF Loss                      28.884651
VF Loss                      9.861789
Policy Loss                  -178.45207
Q Predictions Mean           174.79361
Q Predictions Std            37.845856
Q Predictions Max            294.45734
Q Predictions Min            134.49997
V Predictions Mean           180.4472
V Predictions Std            38.67458
V Predictions Max            318.15802
V Predictions Min            140.24011
Log Pis Mean                 -3.1988869
Log Pis Std                  1.3812234
Log Pis Max                  3.4417315
Log Pis Min                  -7.183751
Policy mu Mean               -0.018358095
Policy mu Std                0.43576577
Policy mu Max                1.5387626
Policy mu Min                -1.6244751
Policy log std Mean          -0.2391283
Policy log std Std           0.09769699
Policy log std Max           0.02647404
Policy log std Min           -0.7520043
Z mean eval                  1.3632636
Z variance eval              0.05165456
total_rewards                [ 57.44481162 109.75535552 112.71713449 184.89243101 115.64446701
 -13.4268478   41.66388139  89.64629165  47.16131931 119.30454367]
total_rewards_mean           86.48033878782192
total_rewards_std            52.18432879980672
total_rewards_max            184.89243100858167
total_rewards_min            -13.426847800942063
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               27.368074972648174
(Previous) Eval Time (s)     22.35386873781681
Sample Time (s)              16.273652233183384
Epoch Time (s)               65.99559594364837
Total Train Time (s)         1024.4250091244467
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:15:18.660393 UTC | [2020_01_10_08_58_14] Iteration #14 | Epoch Duration: 66.59302926063538
2020-01-10 09:15:18.660705 UTC | [2020_01_10_08_58_14] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3616979
Z variance train             0.051629853
KL Divergence                15.180935
KL Loss                      1.5180935
QF Loss                      26.030746
VF Loss                      8.3677
Policy Loss                  -189.50537
Q Predictions Mean           186.9696
Q Predictions Std            44.67382
Q Predictions Max            321.09662
Q Predictions Min            134.81766
V Predictions Mean           190.76181
V Predictions Std            44.629265
V Predictions Max            325.50983
V Predictions Min            139.3955
Log Pis Mean                 -3.3510866
Log Pis Std                  1.3653328
Log Pis Max                  2.147286
Log Pis Min                  -7.34464
Policy mu Mean               -0.018473795
Policy mu Std                0.43150753
Policy mu Max                1.6150354
Policy mu Min                -1.6775374
Policy log std Mean          -0.23651028
Policy log std Std           0.0943367
Policy log std Max           0.07544537
Policy log std Min           -0.6971697
Z mean eval                  1.3678644
Z variance eval              0.05560407
total_rewards                [145.4310602  116.78650509 142.20064557  55.46250232  20.56252576
  68.34472409 406.48903281 160.54746526  73.07245247  73.66555903]
total_rewards_mean           126.25624726094217
total_rewards_std            102.73696177997559
total_rewards_max            406.48903281484013
total_rewards_min            20.56252576035972
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               30.972772788722068
(Previous) Eval Time (s)     22.95100673381239
Sample Time (s)              16.225226307753474
Epoch Time (s)               70.14900583028793
Total Train Time (s)         1094.2856797557324
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:16:28.520370 UTC | [2020_01_10_08_58_14] Iteration #15 | Epoch Duration: 69.85946989059448
2020-01-10 09:16:28.520526 UTC | [2020_01_10_08_58_14] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.368826
Z variance train             0.055578552
KL Divergence                14.594182
KL Loss                      1.4594182
QF Loss                      30.515007
VF Loss                      5.540756
Policy Loss                  -207.37778
Q Predictions Mean           202.60287
Q Predictions Std            48.03139
Q Predictions Max            343.4773
Q Predictions Min            149.44371
V Predictions Mean           207.28383
V Predictions Std            48.24414
V Predictions Max            349.18842
V Predictions Min            154.0463
Log Pis Mean                 -2.940332
Log Pis Std                  1.6684824
Log Pis Max                  5.6392665
Log Pis Min                  -5.915621
Policy mu Mean               -0.011873444
Policy mu Std                0.47626218
Policy mu Max                1.9600726
Policy mu Min                -2.037665
Policy log std Mean          -0.25664994
Policy log std Std           0.107790135
Policy log std Max           1.2695789e-05
Policy log std Min           -0.8728063
Z mean eval                  1.4117057
Z variance eval              0.06335743
total_rewards                [ 716.67020375  655.18133616  888.49258382  280.51860205  187.32847659
  661.1548109   347.70588192 1148.70738724   29.93197841  340.24304394]
total_rewards_mean           525.5934304786687
total_rewards_std            328.30030709791674
total_rewards_max            1148.7073872442525
total_rewards_min            29.931978411191047
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               28.078612059354782
(Previous) Eval Time (s)     22.661152076907456
Sample Time (s)              16.049647158011794
Epoch Time (s)               66.78941129427403
Total Train Time (s)         1160.6804401502013
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:17:34.918019 UTC | [2020_01_10_08_58_14] Iteration #16 | Epoch Duration: 66.39734101295471
2020-01-10 09:17:34.918280 UTC | [2020_01_10_08_58_14] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4148588
Z variance train             0.06350456
KL Divergence                14.985838
KL Loss                      1.4985838
QF Loss                      34.29374
VF Loss                      15.740132
Policy Loss                  -220.6397
Q Predictions Mean           215.20065
Q Predictions Std            56.800777
Q Predictions Max            366.782
Q Predictions Min            154.55336
V Predictions Mean           218.46924
V Predictions Std            55.988342
V Predictions Max            365.19354
V Predictions Min            159.1959
Log Pis Mean                 -2.9114769
Log Pis Std                  1.7245406
Log Pis Max                  2.3899846
Log Pis Min                  -7.0454803
Policy mu Mean               -0.013931911
Policy mu Std                0.5074996
Policy mu Max                1.8460524
Policy mu Min                -1.9324524
Policy log std Mean          -0.27190498
Policy log std Std           0.12573183
Policy log std Max           0.11941996
Policy log std Min           -0.95828116
Z mean eval                  1.4427022
Z variance eval              0.049232222
total_rewards                [ 473.04608539  447.13202606  650.2899209  1521.38712823 1308.92001778
 1501.55825137 1392.7377108   573.8660208   540.76658337  851.59386859]
total_rewards_mean           926.1297613290935
total_rewards_std            428.7962249627232
total_rewards_max            1521.3871282271912
total_rewards_min            447.1320260602939
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               28.6939555038698
(Previous) Eval Time (s)     22.268815016839653
Sample Time (s)              16.02442718250677
Epoch Time (s)               66.98719770321622
Total Train Time (s)         1227.3749654078856
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:18:41.612433 UTC | [2020_01_10_08_58_14] Iteration #17 | Epoch Duration: 66.69394040107727
2020-01-10 09:18:41.612613 UTC | [2020_01_10_08_58_14] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4434454
Z variance train             0.04911513
KL Divergence                15.521735
KL Loss                      1.5521735
QF Loss                      39.671627
VF Loss                      13.253595
Policy Loss                  -229.35216
Q Predictions Mean           225.40355
Q Predictions Std            66.60614
Q Predictions Max            402.95944
Q Predictions Min            158.47415
V Predictions Mean           230.35286
V Predictions Std            66.781075
V Predictions Max            402.5468
V Predictions Min            158.53864
Log Pis Mean                 -2.6138296
Log Pis Std                  1.8436525
Log Pis Max                  3.8593302
Log Pis Min                  -6.6388597
Policy mu Mean               0.025438426
Policy mu Std                0.5474955
Policy mu Max                2.1256187
Policy mu Min                -2.0899675
Policy log std Mean          -0.2798957
Policy log std Std           0.12447015
Policy log std Max           0.02961266
Policy log std Min           -0.86361057
Z mean eval                  1.4386106
Z variance eval              0.054712135
total_rewards                [1528.09484254  581.58138522 1749.10683796 1619.19126671  361.25781822
 1592.19571191 1600.98216837 1597.32981821 1618.95128736 1612.16781793]
total_rewards_mean           1386.0858954447813
total_rewards_std            462.8621760953883
total_rewards_max            1749.1068379649655
total_rewards_min            361.257818223714
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               26.297491281293333
(Previous) Eval Time (s)     21.975287347100675
Sample Time (s)              15.47502439422533
Epoch Time (s)               63.74780302261934
Total Train Time (s)         1290.9735192433
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:19:45.213515 UTC | [2020_01_10_08_58_14] Iteration #18 | Epoch Duration: 63.600762128829956
2020-01-10 09:19:45.213747 UTC | [2020_01_10_08_58_14] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4361755
Z variance train             0.054926384
KL Divergence                14.471532
KL Loss                      1.4471532
QF Loss                      62.009632
VF Loss                      19.887506
Policy Loss                  -259.16272
Q Predictions Mean           253.45831
Q Predictions Std            81.58938
Q Predictions Max            456.8606
Q Predictions Min            168.54282
V Predictions Mean           261.6284
V Predictions Std            83.4431
V Predictions Max            458.9207
V Predictions Min            181.60513
Log Pis Mean                 -2.5168977
Log Pis Std                  1.9962412
Log Pis Max                  6.231604
Log Pis Min                  -7.405641
Policy mu Mean               0.02349218
Policy mu Std                0.5685663
Policy mu Max                1.855428
Policy mu Min                -1.98312
Policy log std Mean          -0.28822657
Policy log std Std           0.14073783
Policy log std Max           -0.014794685
Policy log std Min           -0.95383924
Z mean eval                  1.4825163
Z variance eval              0.04882956
total_rewards                [ 632.78140495  828.32750969  963.8439593  1824.76729252 1923.92965633
 1701.03013194  231.10770747 1885.35530161 1971.83997599 1898.49390412]
total_rewards_mean           1386.147684391173
total_rewards_std            618.6009863375946
total_rewards_max            1971.8399759915885
total_rewards_min            231.10770746610982
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               28.150450004264712
(Previous) Eval Time (s)     21.827947173267603
Sample Time (s)              15.791387790814042
Epoch Time (s)               65.76978496834636
Total Train Time (s)         1357.0631368658505
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:20:51.302939 UTC | [2020_01_10_08_58_14] Iteration #19 | Epoch Duration: 66.08902883529663
2020-01-10 09:20:51.303106 UTC | [2020_01_10_08_58_14] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4827216
Z variance train             0.04879787
KL Divergence                15.364416
KL Loss                      1.5364417
QF Loss                      58.229813
VF Loss                      10.814358
Policy Loss                  -268.74893
Q Predictions Mean           266.42963
Q Predictions Std            91.17774
Q Predictions Max            484.0761
Q Predictions Min            167.50897
V Predictions Mean           269.7
V Predictions Std            90.34575
V Predictions Max            482.35056
V Predictions Min            175.5118
Log Pis Mean                 -2.4222057
Log Pis Std                  2.4204304
Log Pis Max                  6.10633
Log Pis Min                  -10.242884
Policy mu Mean               0.09968353
Policy mu Std                0.61826164
Policy mu Max                2.3130836
Policy mu Min                -2.3494084
Policy log std Mean          -0.30286503
Policy log std Std           0.14024046
Policy log std Max           0.006987095
Policy log std Min           -0.9612775
Z mean eval                  1.5195705
Z variance eval              0.04832103
total_rewards                [2175.83545243 2192.76206653 2157.21949819  399.44300296 2222.35014015
 2135.38860743 2066.16020303 2166.36203514 1687.06031184 2013.26018319]
total_rewards_mean           1921.5841500895935
total_rewards_std            528.30065084003
total_rewards_max            2222.3501401504213
total_rewards_min            399.4430029578137
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               28.315960990730673
(Previous) Eval Time (s)     22.146837471984327
Sample Time (s)              16.19330202974379
Epoch Time (s)               66.65610049245879
Total Train Time (s)         1424.183803750202
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:21:58.426917 UTC | [2020_01_10_08_58_14] Iteration #20 | Epoch Duration: 67.12363982200623
2020-01-10 09:21:58.427224 UTC | [2020_01_10_08_58_14] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5187978
Z variance train             0.048082676
KL Divergence                15.986994
KL Loss                      1.5986995
QF Loss                      43.730835
VF Loss                      14.440946
Policy Loss                  -297.28638
Q Predictions Mean           294.05792
Q Predictions Std            107.53288
Q Predictions Max            530.1075
Q Predictions Min            186.14252
V Predictions Mean           297.79053
V Predictions Std            107.17625
V Predictions Max            529.86633
V Predictions Min            191.03038
Log Pis Mean                 -2.0423706
Log Pis Std                  2.4730155
Log Pis Max                  6.923841
Log Pis Min                  -10.566769
Policy mu Mean               0.032393057
Policy mu Std                0.6598798
Policy mu Max                2.153496
Policy mu Min                -2.0611026
Policy log std Mean          -0.3185254
Policy log std Std           0.15893103
Policy log std Max           -0.001284562
Policy log std Min           -1.0701594
Z mean eval                  1.4832432
Z variance eval              0.10710778
total_rewards                [2188.45146762 2206.88856105 2212.20919143 2191.13624987 1243.01303281
 2205.31518489 2277.37170024 1436.83965825 2251.09991971 2312.69348168]
total_rewards_mean           2052.501844754843
total_rewards_std            360.8898460306595
total_rewards_max            2312.6934816818202
total_rewards_min            1243.0130328070618
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               26.80492542218417
(Previous) Eval Time (s)     22.614077031146735
Sample Time (s)              16.45404898514971
Epoch Time (s)               65.87305143848062
Total Train Time (s)         1489.445537991356
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:23:03.688900 UTC | [2020_01_10_08_58_14] Iteration #21 | Epoch Duration: 65.26146245002747
2020-01-10 09:23:03.689092 UTC | [2020_01_10_08_58_14] Iteration #21 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4838425
Z variance train             0.10701698
KL Divergence                12.902444
KL Loss                      1.2902445
QF Loss                      62.52436
VF Loss                      35.6306
Policy Loss                  -318.76532
Q Predictions Mean           315.20694
Q Predictions Std            120.01755
Q Predictions Max            560.94135
Q Predictions Min            181.22081
V Predictions Mean           314.35376
V Predictions Std            117.76739
V Predictions Max            561.1993
V Predictions Min            177.87514
Log Pis Mean                 -2.043479
Log Pis Std                  2.247228
Log Pis Max                  5.711392
Log Pis Min                  -8.395915
Policy mu Mean               0.063279934
Policy mu Std                0.6837533
Policy mu Max                2.3069663
Policy mu Min                -2.338267
Policy log std Mean          -0.32996243
Policy log std Std           0.15822105
Policy log std Max           0.059148967
Policy log std Min           -1.1395257
Z mean eval                  1.5600299
Z variance eval              0.10822584
total_rewards                [2472.71177421 2584.2182683  2454.22876345 2510.58552484 2521.37713237
 2481.3668215  2536.25958068 2453.46216826 2540.6253245   911.31961361]
total_rewards_mean           2346.6154971708374
total_rewards_std            480.0642516906315
total_rewards_max            2584.2182682990697
total_rewards_min            911.3196136143785
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               28.959247200284153
(Previous) Eval Time (s)     22.002201843075454
Sample Time (s)              16.016811061650515
Epoch Time (s)               66.97826010501012
Total Train Time (s)         1558.1153779840097
Epoch                        22
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:24:12.360100 UTC | [2020_01_10_08_58_14] Iteration #22 | Epoch Duration: 68.67084836959839
2020-01-10 09:24:12.360354 UTC | [2020_01_10_08_58_14] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5568591
Z variance train             0.10813043
KL Divergence                13.352594
KL Loss                      1.3352594
QF Loss                      43.66804
VF Loss                      35.40522
Policy Loss                  -328.53876
Q Predictions Mean           324.31262
Q Predictions Std            136.36893
Q Predictions Max            594.1367
Q Predictions Min            181.6906
V Predictions Mean           331.6316
V Predictions Std            137.91145
V Predictions Max            595.18335
V Predictions Min            181.42847
Log Pis Mean                 -1.8639766
Log Pis Std                  2.6466064
Log Pis Max                  8.333873
Log Pis Min                  -7.312137
Policy mu Mean               0.082403205
Policy mu Std                0.6803605
Policy mu Max                2.1401062
Policy mu Min                -2.2691731
Policy log std Mean          -0.31016836
Policy log std Std           0.17666866
Policy log std Max           0.10581775
Policy log std Min           -1.2843846
Z mean eval                  1.6583481
Z variance eval              0.066273905
total_rewards                [2527.66825576 2792.25732993 2655.81337288 1247.10449916 2573.19688443
 2706.60438753 2724.34884101 2663.50070658 2838.23388042 2788.47977958]
total_rewards_mean           2551.720793729007
total_rewards_std            444.54304615911946
total_rewards_max            2838.233880424803
total_rewards_min            1247.1044991565332
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               27.61191732669249
(Previous) Eval Time (s)     23.694514967035502
Sample Time (s)              16.018624786753207
Epoch Time (s)               67.3250570804812
Total Train Time (s)         1624.0656474991702
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:25:18.311664 UTC | [2020_01_10_08_58_14] Iteration #23 | Epoch Duration: 65.95109367370605
2020-01-10 09:25:18.311892 UTC | [2020_01_10_08_58_14] Iteration #23 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6611115
Z variance train             0.06611637
KL Divergence                15.499967
KL Loss                      1.5499967
QF Loss                      84.87639
VF Loss                      23.15952
Policy Loss                  -393.234
Q Predictions Mean           387.4912
Q Predictions Std            163.78798
Q Predictions Max            683.3673
Q Predictions Min            212.90576
V Predictions Mean           391.58047
V Predictions Std            163.52663
V Predictions Max            684.2572
V Predictions Min            216.399
Log Pis Mean                 -1.7390635
Log Pis Std                  2.7548182
Log Pis Max                  6.82985
Log Pis Min                  -7.1836796
Policy mu Mean               0.08971212
Policy mu Std                0.7297535
Policy mu Max                2.1128647
Policy mu Min                -2.4546034
Policy log std Mean          -0.3422923
Policy log std Std           0.18839097
Policy log std Max           0.0015754849
Policy log std Min           -1.2253186
Z mean eval                  1.7240565
Z variance eval              0.056604803
total_rewards                [2728.79517901 2817.80712078 2821.27936658 2904.3992682  2829.7715087
 2933.3078837  2784.96905501 2837.71365758 2847.84482558 2890.98669227]
total_rewards_mean           2839.6874557413366
total_rewards_std            56.44606864959166
total_rewards_max            2933.307883699859
total_rewards_min            2728.7951790134025
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               26.618423345964402
(Previous) Eval Time (s)     22.320293894037604
Sample Time (s)              16.25462553743273
Epoch Time (s)               65.19334277743474
Total Train Time (s)         1689.5327594811097
Epoch                        24
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:26:23.779153 UTC | [2020_01_10_08_58_14] Iteration #24 | Epoch Duration: 65.46710991859436
2020-01-10 09:26:23.779302 UTC | [2020_01_10_08_58_14] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7251298
Z variance train             0.056702893
KL Divergence                16.749405
KL Loss                      1.6749405
QF Loss                      73.31208
VF Loss                      19.821447
Policy Loss                  -433.6012
Q Predictions Mean           427.52344
Q Predictions Std            175.32468
Q Predictions Max            732.19403
Q Predictions Min            218.28592
V Predictions Mean           431.9159
V Predictions Std            173.66504
V Predictions Max            730.6746
V Predictions Min            224.97192
Log Pis Mean                 -1.4667845
Log Pis Std                  2.9586337
Log Pis Max                  8.143282
Log Pis Min                  -7.4215
Policy mu Mean               0.08583475
Policy mu Std                0.7519276
Policy mu Max                2.2242825
Policy mu Min                -2.056168
Policy log std Mean          -0.36440787
Policy log std Std           0.18975943
Policy log std Max           0.005574934
Policy log std Min           -1.3073376
Z mean eval                  1.7677181
Z variance eval              0.055457704
total_rewards                [2869.65805047 2899.43698414 2911.91809793 2912.91592367 3083.75069866
 2980.3468346  2967.78486446 3002.8809309  2881.6684924  3004.08119257]
total_rewards_mean           2951.4442069790903
total_rewards_std            64.29066371712322
total_rewards_max            3083.750698655112
total_rewards_min            2869.6580504657672
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               27.6957350759767
(Previous) Eval Time (s)     22.59378492925316
Sample Time (s)              16.206768203526735
Epoch Time (s)               66.4962882087566
Total Train Time (s)         1756.0060336110182
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:27:30.253599 UTC | [2020_01_10_08_58_14] Iteration #25 | Epoch Duration: 66.4741690158844
2020-01-10 09:27:30.253794 UTC | [2020_01_10_08_58_14] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7632818
Z variance train             0.055555202
KL Divergence                17.45072
KL Loss                      1.745072
QF Loss                      67.89743
VF Loss                      78.75885
Policy Loss                  -433.11606
Q Predictions Mean           433.00977
Q Predictions Std            195.28377
Q Predictions Max            804.33356
Q Predictions Min            224.29585
V Predictions Mean           440.0614
V Predictions Std            195.7169
V Predictions Max            808.1615
V Predictions Min            231.48831
Log Pis Mean                 -1.7165639
Log Pis Std                  2.6992767
Log Pis Max                  10.120739
Log Pis Min                  -6.1618295
Policy mu Mean               0.13762666
Policy mu Std                0.701082
Policy mu Max                2.622099
Policy mu Min                -2.1818562
Policy log std Mean          -0.34811687
Policy log std Std           0.18397479
Policy log std Max           -0.004484743
Policy log std Min           -1.2351441
Z mean eval                  1.8075176
Z variance eval              0.043641157
total_rewards                [2986.44385998 3189.33488652 3157.89023802 3196.81427581 3157.37617476
 3087.2266861  3091.00702828 3102.15131488 3089.97292038 3132.90915379]
total_rewards_mean           3119.1126538512244
total_rewards_std            58.88234588919262
total_rewards_max            3196.8142758051126
total_rewards_min            2986.443859977343
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               28.50314894411713
(Previous) Eval Time (s)     22.571376109030098
Sample Time (s)              15.510265401564538
Epoch Time (s)               66.58479045471177
Total Train Time (s)         1821.9868737198412
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:28:36.235420 UTC | [2020_01_10_08_58_14] Iteration #26 | Epoch Duration: 65.98145914077759
2020-01-10 09:28:36.235607 UTC | [2020_01_10_08_58_14] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8067461
Z variance train             0.04363607
KL Divergence                18.611275
KL Loss                      1.8611275
QF Loss                      92.17583
VF Loss                      16.304008
Policy Loss                  -487.97092
Q Predictions Mean           480.84778
Q Predictions Std            201.62112
Q Predictions Max            837.5042
Q Predictions Min            239.71747
V Predictions Mean           486.40942
V Predictions Std            201.71603
V Predictions Max            837.8961
V Predictions Min            246.22034
Log Pis Mean                 -1.316767
Log Pis Std                  2.7619727
Log Pis Max                  5.3234453
Log Pis Min                  -5.948625
Policy mu Mean               0.16016372
Policy mu Std                0.76538444
Policy mu Max                2.316772
Policy mu Min                -2.224917
Policy log std Mean          -0.37301156
Policy log std Std           0.1966177
Policy log std Max           0.061077803
Policy log std Min           -1.3725488
Z mean eval                  1.8386726
Z variance eval              0.040285956
total_rewards                [3163.60907471 3215.07997171 3134.33279648 3216.04431131 3240.23689873
 3037.80501106 3259.83382542 3005.29602596 3175.18664864 3037.37510579]
total_rewards_mean           3148.4799669794916
total_rewards_std            87.21047744297393
total_rewards_max            3259.833825418369
total_rewards_min            3005.2960259616325
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               27.96821085596457
(Previous) Eval Time (s)     21.967745196074247
Sample Time (s)              15.620564933400601
Epoch Time (s)               65.55652098543942
Total Train Time (s)         1888.6121071227826
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:29:42.863738 UTC | [2020_01_10_08_58_14] Iteration #27 | Epoch Duration: 66.6279399394989
2020-01-10 09:29:42.864051 UTC | [2020_01_10_08_58_14] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8393562
Z variance train             0.04023735
KL Divergence                19.321632
KL Loss                      1.9321632
QF Loss                      80.09233
VF Loss                      21.664032
Policy Loss                  -484.25104
Q Predictions Mean           480.42233
Q Predictions Std            207.08948
Q Predictions Max            826.8084
Q Predictions Min            222.463
V Predictions Mean           484.78308
V Predictions Std            205.53456
V Predictions Max            827.8086
V Predictions Min            228.5642
Log Pis Mean                 -1.3908325
Log Pis Std                  3.1018631
Log Pis Max                  9.881323
Log Pis Min                  -6.9599447
Policy mu Mean               0.08931148
Policy mu Std                0.78964126
Policy mu Max                2.4505153
Policy mu Min                -2.4254735
Policy log std Mean          -0.39966598
Policy log std Std           0.19949171
Policy log std Max           0.103759825
Policy log std Min           -1.4374921
Z mean eval                  1.8331101
Z variance eval              0.033811346
total_rewards                [3054.58973721 3055.97151218  218.91812435 3232.83668266 3141.13789429
 3164.2033855  3206.16271223 3081.35823754  715.67080918 3214.43430059]
total_rewards_mean           2608.5283395713836
total_rewards_std            1078.0718141801956
total_rewards_max            3232.8366826576025
total_rewards_min            218.91812434983004
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               28.339651802089065
(Previous) Eval Time (s)     23.038875340949744
Sample Time (s)              15.848177155479789
Epoch Time (s)               67.2267042985186
Total Train Time (s)         1955.0708510372788
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:30:49.322303 UTC | [2020_01_10_08_58_14] Iteration #28 | Epoch Duration: 66.45801210403442
2020-01-10 09:30:49.322492 UTC | [2020_01_10_08_58_14] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8351705
Z variance train             0.03379629
KL Divergence                19.372463
KL Loss                      1.9372463
QF Loss                      90.49422
VF Loss                      21.16184
Policy Loss                  -530.52673
Q Predictions Mean           525.20715
Q Predictions Std            236.72913
Q Predictions Max            942.1767
Q Predictions Min            248.83192
V Predictions Mean           530.67645
V Predictions Std            235.91669
V Predictions Max            938.61536
V Predictions Min            251.98021
Log Pis Mean                 -1.004894
Log Pis Std                  3.054758
Log Pis Max                  10.522933
Log Pis Min                  -6.4285707
Policy mu Mean               0.12901565
Policy mu Std                0.8170345
Policy mu Max                2.2951488
Policy mu Min                -2.5285132
Policy log std Mean          -0.34324548
Policy log std Std           0.19607009
Policy log std Max           0.015881836
Policy log std Min           -1.4010153
Z mean eval                  1.9140838
Z variance eval              0.03501693
total_rewards                [3256.64410646 3555.55885423 3454.35277585 3523.64745739 3539.47080698
 3346.26171953 3405.26497773 3371.62619044 3398.80469819 3494.99177022]
total_rewards_mean           3434.662335702024
total_rewards_std            91.20042716303507
total_rewards_max            3555.55885423374
total_rewards_min            3256.644106455726
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               29.141587594989687
(Previous) Eval Time (s)     22.269937223754823
Sample Time (s)              16.018115155398846
Epoch Time (s)               67.42963997414336
Total Train Time (s)         2022.5990283605643
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:31:56.851583 UTC | [2020_01_10_08_58_14] Iteration #29 | Epoch Duration: 67.52894306182861
2020-01-10 09:31:56.851774 UTC | [2020_01_10_08_58_14] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9133514
Z variance train             0.034980066
KL Divergence                21.192535
KL Loss                      2.1192536
QF Loss                      115.68473
VF Loss                      23.255482
Policy Loss                  -586.7274
Q Predictions Mean           582.991
Q Predictions Std            256.3417
Q Predictions Max            977.3705
Q Predictions Min            250.5645
V Predictions Mean           587.43884
V Predictions Std            255.52664
V Predictions Max            977.37286
V Predictions Min            251.84581
Log Pis Mean                 -0.76342064
Log Pis Std                  3.318446
Log Pis Max                  9.70471
Log Pis Min                  -7.0435314
Policy mu Mean               0.14776187
Policy mu Std                0.85507596
Policy mu Max                2.2929432
Policy mu Min                -2.696264
Policy log std Mean          -0.37777564
Policy log std Std           0.21738453
Policy log std Max           0.0059520677
Policy log std Min           -1.4144914
Z mean eval                  1.933801
Z variance eval              0.024815626
total_rewards                [3383.65051957 3396.8731717  3445.25951524 3392.0483398  3479.96961788
 3368.18781791 3507.54104848 3431.73595563 3464.3618432  3474.96511938]
total_rewards_mean           3434.459294878196
total_rewards_std            45.00658155638015
total_rewards_max            3507.5410484771755
total_rewards_min            3368.187817906133
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               27.88116299500689
(Previous) Eval Time (s)     22.3689689761959
Sample Time (s)              15.51847127545625
Epoch Time (s)               65.76860324665904
Total Train Time (s)         2088.834751418326
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:33:03.090267 UTC | [2020_01_10_08_58_14] Iteration #30 | Epoch Duration: 66.238276720047
2020-01-10 09:33:03.090535 UTC | [2020_01_10_08_58_14] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9331388
Z variance train             0.02487035
KL Divergence                22.589933
KL Loss                      2.2589934
QF Loss                      82.979935
VF Loss                      46.0946
Policy Loss                  -598.674
Q Predictions Mean           593.2546
Q Predictions Std            270.41776
Q Predictions Max            1015.7528
Q Predictions Min            245.91135
V Predictions Mean           602.0584
V Predictions Std            270.4029
V Predictions Max            1028.7938
V Predictions Min            246.44269
Log Pis Mean                 -0.681167
Log Pis Std                  3.113177
Log Pis Max                  8.44382
Log Pis Min                  -9.168212
Policy mu Mean               0.13498384
Policy mu Std                0.85195714
Policy mu Max                2.4057784
Policy mu Min                -2.201835
Policy log std Mean          -0.378045
Policy log std Std           0.20974058
Policy log std Max           0.1275717
Policy log std Min           -1.2338848
Z mean eval                  1.9369841
Z variance eval              0.025507271
total_rewards                [3452.02790512 3469.27460377 3493.39563627 3510.95868626 3528.49700977
 3324.76954859 3508.56371436 3478.19459048 3513.87447654 3590.96215993]
total_rewards_mean           3487.051833110222
total_rewards_std            65.01211534825303
total_rewards_max            3590.962159933778
total_rewards_min            3324.769548594225
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               27.28053299197927
(Previous) Eval Time (s)     22.838367308024317
Sample Time (s)              15.82539192168042
Epoch Time (s)               65.94429222168401
Total Train Time (s)         2153.7553832479753
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:34:08.010840 UTC | [2020_01_10_08_58_14] Iteration #31 | Epoch Duration: 64.92011332511902
2020-01-10 09:34:08.010990 UTC | [2020_01_10_08_58_14] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9410118
Z variance train             0.025396273
KL Divergence                23.647491
KL Loss                      2.3647492
QF Loss                      113.040436
VF Loss                      51.419643
Policy Loss                  -656.2552
Q Predictions Mean           650.1813
Q Predictions Std            280.1175
Q Predictions Max            1054.0038
Q Predictions Min            256.17032
V Predictions Mean           651.14844
V Predictions Std            277.1677
V Predictions Max            1044.2677
V Predictions Min            261.78415
Log Pis Mean                 -0.63953197
Log Pis Std                  2.9599373
Log Pis Max                  8.233843
Log Pis Min                  -6.119487
Policy mu Mean               0.090335034
Policy mu Std                0.8526456
Policy mu Max                2.3153715
Policy mu Min                -2.222443
Policy log std Mean          -0.39805532
Policy log std Std           0.2214295
Policy log std Max           0.009832174
Policy log std Min           -1.5470722
Z mean eval                  1.9781643
Z variance eval              0.024200302
total_rewards                [3751.30377963 3590.95663667 3705.47128476 3570.14164481 3534.96334247
 3743.35274879 3629.48218504 3705.19293539 3659.89361543 3650.44516724]
total_rewards_mean           3654.120334023994
total_rewards_std            69.67547219272026
total_rewards_max            3751.3037796299086
total_rewards_min            3534.9633424727267
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               26.32701347908005
(Previous) Eval Time (s)     21.813912746030837
Sample Time (s)              15.66695167357102
Epoch Time (s)               63.80787789868191
Total Train Time (s)         2218.2004046258517
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:35:12.456980 UTC | [2020_01_10_08_58_14] Iteration #32 | Epoch Duration: 64.44585585594177
2020-01-10 09:35:12.457180 UTC | [2020_01_10_08_58_14] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9793822
Z variance train             0.02455769
KL Divergence                25.048025
KL Loss                      2.5048025
QF Loss                      101.45342
VF Loss                      66.84456
Policy Loss                  -649.1308
Q Predictions Mean           640.42474
Q Predictions Std            282.4152
Q Predictions Max            1070.584
Q Predictions Min            249.12491
V Predictions Mean           642.9218
V Predictions Std            280.7347
V Predictions Max            1069.285
V Predictions Min            254.06723
Log Pis Mean                 -0.39655146
Log Pis Std                  3.4247737
Log Pis Max                  9.206639
Log Pis Min                  -6.1492705
Policy mu Mean               0.1419452
Policy mu Std                0.8790044
Policy mu Max                2.3061595
Policy mu Min                -2.313272
Policy log std Mean          -0.41599306
Policy log std Std           0.22356544
Policy log std Max           0.099457204
Policy log std Min           -1.3337299
Z mean eval                  1.9899786
Z variance eval              0.018825715
total_rewards                [3725.36732189 3623.65841525 3704.15731931 3718.31125787 3649.71826702
 3817.99358487 3654.72495277 3702.64398691 3715.99398357 3776.91638954]
total_rewards_mean           3708.948547901299
total_rewards_std            55.41015859798426
total_rewards_max            3817.9935848748337
total_rewards_min            3623.658415246333
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               26.721964608877897
(Previous) Eval Time (s)     22.451610025949776
Sample Time (s)              16.323658537119627
Epoch Time (s)               65.4972331719473
Total Train Time (s)         2283.966703333892
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:36:18.226315 UTC | [2020_01_10_08_58_14] Iteration #33 | Epoch Duration: 65.7689619064331
2020-01-10 09:36:18.226577 UTC | [2020_01_10_08_58_14] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9889438
Z variance train             0.018807035
KL Divergence                24.904741
KL Loss                      2.4904742
QF Loss                      114.65716
VF Loss                      29.409992
Policy Loss                  -686.703
Q Predictions Mean           681.6296
Q Predictions Std            297.6037
Q Predictions Max            1088.4595
Q Predictions Min            248.63272
V Predictions Mean           687.8897
V Predictions Std            297.1977
V Predictions Max            1092.1924
V Predictions Min            256.60327
Log Pis Mean                 -0.48112643
Log Pis Std                  3.2707174
Log Pis Max                  8.2701
Log Pis Min                  -7.007002
Policy mu Mean               0.06185733
Policy mu Std                0.8841088
Policy mu Max                2.3340826
Policy mu Min                -2.5465455
Policy log std Mean          -0.42877626
Policy log std Std           0.2205171
Policy log std Max           0.024610579
Policy log std Min           -1.4522672
Z mean eval                  2.0000937
Z variance eval              0.015610263
total_rewards                [3507.95174176 3660.52796742 3601.90104273 3644.02652773 3751.68216688
 3697.31791626 3747.99421283 3747.67031593 3698.53772028 3671.79076011]
total_rewards_mean           3672.9400371932525
total_rewards_std            72.0601393990337
total_rewards_max            3751.682166877952
total_rewards_min            3507.951741763532
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               28.898598772007972
(Previous) Eval Time (s)     22.723038400989026
Sample Time (s)              16.09125150879845
Epoch Time (s)               67.71288868179545
Total Train Time (s)         2351.9277281905524
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:37:26.187913 UTC | [2020_01_10_08_58_14] Iteration #34 | Epoch Duration: 67.96114373207092
2020-01-10 09:37:26.188066 UTC | [2020_01_10_08_58_14] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.999884
Z variance train             0.015624834
KL Divergence                25.307457
KL Loss                      2.5307457
QF Loss                      95.913795
VF Loss                      32.242767
Policy Loss                  -704.9866
Q Predictions Mean           700.9295
Q Predictions Std            320.49918
Q Predictions Max            1168.2848
Q Predictions Min            262.71048
V Predictions Mean           706.2556
V Predictions Std            319.17407
V Predictions Max            1155.1959
V Predictions Min            271.26562
Log Pis Mean                 -0.43252838
Log Pis Std                  3.3587916
Log Pis Max                  8.455084
Log Pis Min                  -7.488994
Policy mu Mean               0.116464354
Policy mu Std                0.8708958
Policy mu Max                2.4151936
Policy mu Min                -2.0726748
Policy log std Mean          -0.43497634
Policy log std Std           0.23919222
Policy log std Max           0.029966623
Policy log std Min           -1.5464952
Z mean eval                  1.9956448
Z variance eval              0.014174959
total_rewards                [3625.69964954 3804.44915164 3805.89747807 3809.47781698 3892.11064776
 3965.67845969 3817.71871305 3765.75474253 3826.13031767 3878.70524121]
total_rewards_mean           3819.162221814261
total_rewards_std            84.35095216693486
total_rewards_max            3965.67845968612
total_rewards_min            3625.699649542238
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               25.43867430323735
(Previous) Eval Time (s)     22.97100357990712
Sample Time (s)              15.77104260865599
Epoch Time (s)               64.18072049180046
Total Train Time (s)         2415.90303284768
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:38:30.167617 UTC | [2020_01_10_08_58_14] Iteration #35 | Epoch Duration: 63.979387283325195
2020-01-10 09:38:30.167945 UTC | [2020_01_10_08_58_14] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.9962895
Z variance train             0.014176717
KL Divergence                25.551311
KL Loss                      2.5551312
QF Loss                      160.20706
VF Loss                      54.853844
Policy Loss                  -737.58276
Q Predictions Mean           730.0334
Q Predictions Std            344.70367
Q Predictions Max            1210.08
Q Predictions Min            258.96252
V Predictions Mean           734.13806
V Predictions Std            342.36783
V Predictions Max            1197.9359
V Predictions Min            262.98148
Log Pis Mean                 -0.007944845
Log Pis Std                  3.6376326
Log Pis Max                  8.768114
Log Pis Min                  -6.105397
Policy mu Mean               0.113705255
Policy mu Std                0.9133246
Policy mu Max                2.2772899
Policy mu Min                -2.3522305
Policy log std Mean          -0.42447773
Policy log std Std           0.2392546
Policy log std Max           0.049551502
Policy log std Min           -1.8308126
Z mean eval                  2.0254693
Z variance eval              0.014954147
total_rewards                [3868.91093894 3809.72530198 4011.2277281  3891.22332466 3951.38686653
 3711.40351933 4017.28204885 3915.31705069 3886.65479092 3847.39571713]
total_rewards_mean           3891.052728714157
total_rewards_std            87.12542137379073
total_rewards_max            4017.282048854673
total_rewards_min            3711.4035193273367
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               27.754362327046692
(Previous) Eval Time (s)     22.769355564843863
Sample Time (s)              15.904805683530867
Epoch Time (s)               66.42852357542142
Total Train Time (s)         2482.1150384135544
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:39:36.379395 UTC | [2020_01_10_08_58_14] Iteration #36 | Epoch Duration: 66.21120429039001
2020-01-10 09:39:36.379663 UTC | [2020_01_10_08_58_14] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0222652
Z variance train             0.014938292
KL Divergence                26.149265
KL Loss                      2.6149266
QF Loss                      129.30084
VF Loss                      62.244072
Policy Loss                  -747.2761
Q Predictions Mean           742.636
Q Predictions Std            348.09027
Q Predictions Max            1231.1868
Q Predictions Min            260.5898
V Predictions Mean           752.5763
V Predictions Std            349.20682
V Predictions Max            1238.402
V Predictions Min            261.82184
Log Pis Mean                 -0.5872511
Log Pis Std                  3.3581247
Log Pis Max                  8.719984
Log Pis Min                  -7.8314013
Policy mu Mean               0.068614885
Policy mu Std                0.8602909
Policy mu Max                2.5046196
Policy mu Min                -2.0591958
Policy log std Mean          -0.43994907
Policy log std Std           0.253918
Policy log std Max           0.02125714
Policy log std Min           -1.6462209
Z mean eval                  2.0372427
Z variance eval              0.010381939
total_rewards                [3809.59946048 4063.1762528  4046.43087827 3929.04915412 3997.05703039
 3913.22545506 3953.16087801 3874.87137585 3979.6728617  4033.20182409]
total_rewards_mean           3959.944517075883
total_rewards_std            76.35060481806711
total_rewards_max            4063.1762528004374
total_rewards_min            3809.599460475774
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               28.212173890788108
(Previous) Eval Time (s)     22.551769454032183
Sample Time (s)              16.334469395689666
Epoch Time (s)               67.09841274050996
Total Train Time (s)         2549.2967842547223
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:40:43.561305 UTC | [2020_01_10_08_58_14] Iteration #37 | Epoch Duration: 67.18144941329956
2020-01-10 09:40:43.561468 UTC | [2020_01_10_08_58_14] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0376668
Z variance train             0.010384082
KL Divergence                27.580515
KL Loss                      2.7580516
QF Loss                      156.79962
VF Loss                      64.16387
Policy Loss                  -816.3296
Q Predictions Mean           809.1854
Q Predictions Std            359.58182
Q Predictions Max            1277.7036
Q Predictions Min            267.2426
V Predictions Mean           810.4526
V Predictions Std            357.5573
V Predictions Max            1274.9233
V Predictions Min            270.8685
Log Pis Mean                 -0.18745911
Log Pis Std                  3.5794623
Log Pis Max                  10.26491
Log Pis Min                  -6.5528164
Policy mu Mean               0.04327181
Policy mu Std                0.91884476
Policy mu Max                2.3338103
Policy mu Min                -2.4425423
Policy log std Mean          -0.47072306
Policy log std Std           0.26841822
Policy log std Max           0.09140874
Policy log std Min           -1.8285644
Z mean eval                  2.0406675
Z variance eval              0.0086707845
total_rewards                [3903.89597394 3925.732859   3898.72783698 3986.64808839 4122.94797864
 3962.43878303 4074.01517086 4103.41301057 4001.30881022 3855.57255091]
total_rewards_mean           3983.4701062537597
total_rewards_std            87.18605995802474
total_rewards_max            4122.947978637651
total_rewards_min            3855.5725509083445
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               24.440243729390204
(Previous) Eval Time (s)     22.634559251833707
Sample Time (s)              15.59053468843922
Epoch Time (s)               62.66533766966313
Total Train Time (s)         2612.327938602306
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:41:46.592995 UTC | [2020_01_10_08_58_14] Iteration #38 | Epoch Duration: 63.031412839889526
2020-01-10 09:41:46.593135 UTC | [2020_01_10_08_58_14] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0392606
Z variance train             0.008651867
KL Divergence                27.503452
KL Loss                      2.7503452
QF Loss                      195.47385
VF Loss                      86.10314
Policy Loss                  -842.30804
Q Predictions Mean           839.18384
Q Predictions Std            374.54877
Q Predictions Max            1318.2146
Q Predictions Min            270.21014
V Predictions Mean           845.1013
V Predictions Std            373.0083
V Predictions Max            1325.0212
V Predictions Min            275.4543
Log Pis Mean                 -0.15244702
Log Pis Std                  3.6004994
Log Pis Max                  11.928468
Log Pis Min                  -8.440696
Policy mu Mean               0.0870203
Policy mu Std                0.93573415
Policy mu Max                2.4552674
Policy mu Min                -2.3103998
Policy log std Mean          -0.471128
Policy log std Std           0.26589176
Policy log std Max           0.016542964
Policy log std Min           -1.9623544
Z mean eval                  2.0453484
Z variance eval              0.01992746
total_rewards                [3831.57625935 4143.51297519 4135.6193972  3956.20485771 4223.99172475
 4158.73715502 3995.06413023 3926.5222235  4244.58705043 3985.45882294]
total_rewards_mean           4060.12745963168
total_rewards_std            131.88913772183884
total_rewards_max            4244.587050426898
total_rewards_min            3831.5762593471027
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               29.446651691105217
(Previous) Eval Time (s)     23.000334543641657
Sample Time (s)              15.710584997665137
Epoch Time (s)               68.15757123241201
Total Train Time (s)         2679.7724676528014
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:42:54.039766 UTC | [2020_01_10_08_58_14] Iteration #39 | Epoch Duration: 67.44647479057312
2020-01-10 09:42:54.039991 UTC | [2020_01_10_08_58_14] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0455656
Z variance train             0.019899188
KL Divergence                25.587757
KL Loss                      2.5587757
QF Loss                      131.83589
VF Loss                      53.313007
Policy Loss                  -879.8375
Q Predictions Mean           878.1909
Q Predictions Std            379.1237
Q Predictions Max            1343.2874
Q Predictions Min            272.71063
V Predictions Mean           883.1447
V Predictions Std            375.95322
V Predictions Max            1342.248
V Predictions Min            280.25354
Log Pis Mean                 0.12942198
Log Pis Std                  3.4607422
Log Pis Max                  12.6495495
Log Pis Min                  -7.182494
Policy mu Mean               0.14437436
Policy mu Std                0.94477624
Policy mu Max                2.5041964
Policy mu Min                -2.3454263
Policy log std Mean          -0.47115406
Policy log std Std           0.25729856
Policy log std Max           0.05642757
Policy log std Min           -1.7897848
Z mean eval                  2.048224
Z variance eval              0.025054907
total_rewards                [3975.31134588 3957.81173536 4022.01184342 4139.61607464 3872.81205179
 3983.83091252 3939.20244851 3995.57875118 4168.5504626  4000.27329836]
total_rewards_mean           4005.499892427194
total_rewards_std            84.04016724133207
total_rewards_max            4168.550462600054
total_rewards_min            3872.8120517948473
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               27.906577652320266
(Previous) Eval Time (s)     22.288954923395067
Sample Time (s)              16.734744125045836
Epoch Time (s)               66.93027670076117
Total Train Time (s)         2747.2998518124223
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:44:01.569752 UTC | [2020_01_10_08_58_14] Iteration #40 | Epoch Duration: 67.5295820236206
2020-01-10 09:44:01.570021 UTC | [2020_01_10_08_58_14] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0504346
Z variance train             0.02495693
KL Divergence                25.631868
KL Loss                      2.563187
QF Loss                      183.90497
VF Loss                      99.69215
Policy Loss                  -833.2242
Q Predictions Mean           826.0198
Q Predictions Std            395.86078
Q Predictions Max            1337.2766
Q Predictions Min            252.17787
V Predictions Mean           825.7629
V Predictions Std            390.99774
V Predictions Max            1326.443
V Predictions Min            255.96143
Log Pis Mean                 -0.38186562
Log Pis Std                  3.2305849
Log Pis Max                  11.272553
Log Pis Min                  -7.491398
Policy mu Mean               0.08487186
Policy mu Std                0.88650537
Policy mu Max                2.3331082
Policy mu Min                -2.2255135
Policy log std Mean          -0.45637894
Policy log std Std           0.26178193
Policy log std Max           0.0587582
Policy log std Min           -1.6079462
Z mean eval                  2.053388
Z variance eval              0.027690291
total_rewards                [4269.98288049 4260.02463332 4322.93928374 4264.94113777 4314.95536688
 4143.34719711 4185.66108942 4287.93054784 4275.93210761 4153.07672735]
total_rewards_mean           4247.879097153582
total_rewards_std            61.02216000842988
total_rewards_max            4322.939283739856
total_rewards_min            4143.347197106285
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               26.296439577825367
(Previous) Eval Time (s)     22.88794346805662
Sample Time (s)              16.74041207972914
Epoch Time (s)               65.92479512561113
Total Train Time (s)         2813.0299232057296
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:45:07.306770 UTC | [2020_01_10_08_58_14] Iteration #41 | Epoch Duration: 65.73652696609497
2020-01-10 09:45:07.307046 UTC | [2020_01_10_08_58_14] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0541291
Z variance train             0.027713919
KL Divergence                24.351143
KL Loss                      2.4351144
QF Loss                      198.10603
VF Loss                      135.35455
Policy Loss                  -948.6125
Q Predictions Mean           945.59753
Q Predictions Std            419.89612
Q Predictions Max            1455.4657
Q Predictions Min            294.25333
V Predictions Mean           945.85956
V Predictions Std            416.41498
V Predictions Max            1454.5726
V Predictions Min            296.2527
Log Pis Mean                 0.18394051
Log Pis Std                  3.8554738
Log Pis Max                  11.832893
Log Pis Min                  -7.679039
Policy mu Mean               0.018970696
Policy mu Std                0.9713155
Policy mu Max                2.7820725
Policy mu Min                -2.4755144
Policy log std Mean          -0.4863921
Policy log std Std           0.27781656
Policy log std Max           0.043310612
Policy log std Min           -1.8415496
Z mean eval                  2.0462968
Z variance eval              0.05549674
total_rewards                [4083.69583659 4132.89683774 4035.40019955 4153.30225818 4051.86075177
 4197.80048719 4074.15910909 4107.23514141 4251.20911388 4227.33259394]
total_rewards_mean           4131.489232933095
total_rewards_std            70.8002695923251
total_rewards_max            4251.209113878263
total_rewards_min            4035.4001995511567
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               27.704692858736962
(Previous) Eval Time (s)     22.69938770402223
Sample Time (s)              17.114649686496705
Epoch Time (s)               67.5187302492559
Total Train Time (s)         2880.8118191529065
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:46:15.085768 UTC | [2020_01_10_08_58_14] Iteration #42 | Epoch Duration: 67.77850008010864
2020-01-10 09:46:15.086036 UTC | [2020_01_10_08_58_14] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0457926
Z variance train             0.055553127
KL Divergence                23.787455
KL Loss                      2.3787456
QF Loss                      177.4521
VF Loss                      57.06107
Policy Loss                  -946.5457
Q Predictions Mean           942.3128
Q Predictions Std            385.01807
Q Predictions Max            1375.7223
Q Predictions Min            252.16931
V Predictions Mean           948.8134
V Predictions Std            381.75873
V Predictions Max            1384.8975
V Predictions Min            258.73694
Log Pis Mean                 0.580922
Log Pis Std                  3.6713336
Log Pis Max                  11.569271
Log Pis Min                  -5.8098145
Policy mu Mean               0.01583012
Policy mu Std                0.98220605
Policy mu Max                2.3416104
Policy mu Min                -2.4510822
Policy log std Mean          -0.5031076
Policy log std Std           0.2767612
Policy log std Max           0.15742053
Policy log std Min           -1.7559636
Z mean eval                  2.086059
Z variance eval              0.033132352
total_rewards                [4076.28872674 4330.74591419 4199.06325812 4276.91521019 4370.26858228
 4179.25354864 4329.64123936 4132.364673   4262.15634134 4210.9649021 ]
total_rewards_mean           4236.7662395938405
total_rewards_std            89.2104646980127
total_rewards_max            4370.268582275108
total_rewards_min            4076.2887267381266
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               29.724055350292474
(Previous) Eval Time (s)     22.958858207799494
Sample Time (s)              16.542908802162856
Epoch Time (s)               69.22582236025482
Total Train Time (s)         2949.2749719750136
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:47:23.548427 UTC | [2020_01_10_08_58_14] Iteration #43 | Epoch Duration: 68.46221733093262
2020-01-10 09:47:23.548568 UTC | [2020_01_10_08_58_14] Iteration #43 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.0881085
Z variance train             0.033150606
KL Divergence                24.705877
KL Loss                      2.4705877
QF Loss                      134.31488
VF Loss                      62.344215
Policy Loss                  -981.22784
Q Predictions Mean           976.182
Q Predictions Std            426.7464
Q Predictions Max            1511.5209
Q Predictions Min            277.55106
V Predictions Mean           979.5959
V Predictions Std            422.55325
V Predictions Max            1503.7561
V Predictions Min            278.95404
Log Pis Mean                 0.33317685
Log Pis Std                  3.7493954
Log Pis Max                  12.098333
Log Pis Min                  -7.812261
Policy mu Mean               0.053611416
Policy mu Std                1.0024458
Policy mu Max                2.8045697
Policy mu Min                -2.741197
Policy log std Mean          -0.49547789
Policy log std Std           0.27624735
Policy log std Max           0.024255812
Policy log std Min           -1.8141724
Z mean eval                  2.1010005
Z variance eval              0.029840171
total_rewards                [4479.64009161 4296.05515128 4228.19819165 4299.16906104 4223.22184145
 4274.0118718  4295.4508417  4326.57138885 4331.28639983 4298.17903525]
total_rewards_mean           4305.178387446527
total_rewards_std            67.41907314012657
total_rewards_max            4479.640091605355
total_rewards_min            4223.221841451278
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               25.43929618783295
(Previous) Eval Time (s)     22.194926586933434
Sample Time (s)              16.05491616204381
Epoch Time (s)               63.689138936810195
Total Train Time (s)         3013.033344789408
Epoch                        44
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:48:27.309989 UTC | [2020_01_10_08_58_14] Iteration #44 | Epoch Duration: 63.761263608932495
2020-01-10 09:48:27.310244 UTC | [2020_01_10_08_58_14] Iteration #44 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1000812
Z variance train             0.029936701
KL Divergence                24.92834
KL Loss                      2.492834
QF Loss                      175.02548
VF Loss                      46.76394
Policy Loss                  -984.6316
Q Predictions Mean           983.02106
Q Predictions Std            422.8547
Q Predictions Max            1491.554
Q Predictions Min            276.65326
V Predictions Mean           985.1504
V Predictions Std            418.90305
V Predictions Max            1485.9357
V Predictions Min            277.3623
Log Pis Mean                 0.8222937
Log Pis Std                  3.9174464
Log Pis Max                  11.384855
Log Pis Min                  -7.909763
Policy mu Mean               0.075107224
Policy mu Std                1.0147723
Policy mu Max                2.7429013
Policy mu Min                -2.5085886
Policy log std Mean          -0.4934951
Policy log std Std           0.2779565
Policy log std Max           0.016674384
Policy log std Min           -1.9369934
Z mean eval                  2.1264906
Z variance eval              0.022342514
total_rewards                [4355.68504145 4370.55504017 4445.7817896  4317.31198628 4301.77295981
 4325.18025757 4410.17328992 4269.52284723 4433.06199733 4319.16877067]
total_rewards_mean           4354.821398003247
total_rewards_std            55.99477841996608
total_rewards_max            4445.781789595701
total_rewards_min            4269.522847233366
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               27.46145349415019
(Previous) Eval Time (s)     22.26672383118421
Sample Time (s)              16.602129423525184
Epoch Time (s)               66.33030674885958
Total Train Time (s)         3079.408623044379
Epoch                        45
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:49:33.685769 UTC | [2020_01_10_08_58_14] Iteration #45 | Epoch Duration: 66.3753297328949
2020-01-10 09:49:33.685972 UTC | [2020_01_10_08_58_14] Iteration #45 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1301188
Z variance train             0.022317437
KL Divergence                26.17172
KL Loss                      2.617172
QF Loss                      222.9974
VF Loss                      87.75199
Policy Loss                  -1017.4686
Q Predictions Mean           1015.5178
Q Predictions Std            435.16702
Q Predictions Max            1546.89
Q Predictions Min            282.549
V Predictions Mean           1011.86774
V Predictions Std            429.50726
V Predictions Max            1523.3859
V Predictions Min            281.94724
Log Pis Mean                 0.8476795
Log Pis Std                  3.900459
Log Pis Max                  10.147274
Log Pis Min                  -5.804442
Policy mu Mean               0.03897598
Policy mu Std                1.0110931
Policy mu Max                2.4756563
Policy mu Min                -2.779111
Policy log std Mean          -0.4793278
Policy log std Std           0.2680859
Policy log std Max           0.07450464
Policy log std Min           -1.8702809
Z mean eval                  2.1272397
Z variance eval              0.022338662
total_rewards                [4571.54549171 4343.20213341 4502.02512448 4370.80159432 4425.23311415
 4324.32256648 4502.93958841 4579.04108874 4413.63137517 4493.54695185]
total_rewards_mean           4452.62890287155
total_rewards_std            86.12224626717534
total_rewards_max            4579.041088743773
total_rewards_min            4324.322566484303
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               26.353817192837596
(Previous) Eval Time (s)     22.311450297944248
Sample Time (s)              16.085520916152745
Epoch Time (s)               64.75078840693459
Total Train Time (s)         3144.333852495067
Epoch                        46
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:50:38.611792 UTC | [2020_01_10_08_58_14] Iteration #46 | Epoch Duration: 64.92567086219788
2020-01-10 09:50:38.611958 UTC | [2020_01_10_08_58_14] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.126141
Z variance train             0.022313666
KL Divergence                26.177753
KL Loss                      2.6177754
QF Loss                      211.05756
VF Loss                      80.59354
Policy Loss                  -1018.2055
Q Predictions Mean           1014.4154
Q Predictions Std            435.4477
Q Predictions Max            1516.7955
Q Predictions Min            268.3331
V Predictions Mean           1020.0255
V Predictions Std            431.95984
V Predictions Max            1507.6406
V Predictions Min            268.61038
Log Pis Mean                 0.76780057
Log Pis Std                  3.9148278
Log Pis Max                  10.787515
Log Pis Min                  -7.6783447
Policy mu Mean               0.083042584
Policy mu Std                1.0189993
Policy mu Max                2.5984356
Policy mu Min                -2.5795217
Policy log std Mean          -0.51413417
Policy log std Std           0.274344
Policy log std Max           0.05479765
Policy log std Min           -1.836594
Z mean eval                  2.121661
Z variance eval              0.026906908
total_rewards                [4636.03368878 4402.33097083 4398.446036   4536.60938895 4591.19538638
 4545.64141124 4484.87205002 4492.32150098 4473.81930832 4535.97587124]
total_rewards_mean           4509.72456127367
total_rewards_std            71.70734331149335
total_rewards_max            4636.033688777564
total_rewards_min            4398.446036004112
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               29.98449706006795
(Previous) Eval Time (s)     22.486026105936617
Sample Time (s)              15.88414908759296
Epoch Time (s)               68.35467225359753
Total Train Time (s)         3212.3215234703384
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:51:46.602877 UTC | [2020_01_10_08_58_14] Iteration #47 | Epoch Duration: 67.99076414108276
2020-01-10 09:51:46.603180 UTC | [2020_01_10_08_58_14] Iteration #47 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1191783
Z variance train             0.02683309
KL Divergence                25.87651
KL Loss                      2.587651
QF Loss                      209.19008
VF Loss                      67.11596
Policy Loss                  -1041.8019
Q Predictions Mean           1042.1499
Q Predictions Std            447.702
Q Predictions Max            1553.2404
Q Predictions Min            263.86978
V Predictions Mean           1044.2441
V Predictions Std            445.257
V Predictions Max            1560.6057
V Predictions Min            263.41965
Log Pis Mean                 0.46041286
Log Pis Std                  3.839721
Log Pis Max                  10.7257595
Log Pis Min                  -9.574056
Policy mu Mean               0.017285373
Policy mu Std                1.0164703
Policy mu Max                2.6140437
Policy mu Min                -2.6042354
Policy log std Mean          -0.5005331
Policy log std Std           0.28194675
Policy log std Max           0.06844501
Policy log std Min           -2.0186276
Z mean eval                  2.1225348
Z variance eval              0.027680222
total_rewards                [4357.86261646 4441.77659997 4491.52097614 4531.65946641 4340.5901546
 4469.38074319 4327.6140202  4463.86624528 4508.82695599 4437.4229424 ]
total_rewards_mean           4437.052072064753
total_rewards_std            68.12357499803964
total_rewards_max            4531.659466413131
total_rewards_min            4327.614020202819
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               23.69293281296268
(Previous) Eval Time (s)     22.121818816289306
Sample Time (s)              16.47172246221453
Epoch Time (s)               62.286474091466516
Total Train Time (s)         3274.8908523176797
Epoch                        48
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:52:49.173629 UTC | [2020_01_10_08_58_14] Iteration #48 | Epoch Duration: 62.570218563079834
2020-01-10 09:52:49.173861 UTC | [2020_01_10_08_58_14] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.119637
Z variance train             0.02780051
KL Divergence                26.45278
KL Loss                      2.645278
QF Loss                      224.189
VF Loss                      62.84319
Policy Loss                  -1068.6063
Q Predictions Mean           1064.5261
Q Predictions Std            460.93115
Q Predictions Max            1616.111
Q Predictions Min            275.3942
V Predictions Mean           1069.1516
V Predictions Std            458.49597
V Predictions Max            1613.2701
V Predictions Min            279.3457
Log Pis Mean                 0.61385286
Log Pis Std                  3.704827
Log Pis Max                  11.525656
Log Pis Min                  -6.4507093
Policy mu Mean               0.092277706
Policy mu Std                1.0200356
Policy mu Max                2.8760443
Policy mu Min                -2.770108
Policy log std Mean          -0.4911909
Policy log std Std           0.273818
Policy log std Max           0.14678559
Policy log std Min           -1.8583503
Z mean eval                  2.1405072
Z variance eval              0.020863976
total_rewards                [4673.09388589 4833.01349512 4715.18051683 4590.95786092 4604.54178397
 4790.21805009 4814.35984904 4678.57453994 4691.65001664 4688.78851994]
total_rewards_mean           4708.037851838866
total_rewards_std            78.02262935282286
total_rewards_max            4833.013495119708
total_rewards_min            4590.957860922846
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               27.563315930776298
(Previous) Eval Time (s)     22.405264942906797
Sample Time (s)              16.27816766081378
Epoch Time (s)               66.24674853449687
Total Train Time (s)         3340.6057570446283
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:53:54.890047 UTC | [2020_01_10_08_58_14] Iteration #49 | Epoch Duration: 65.71600198745728
2020-01-10 09:53:54.890271 UTC | [2020_01_10_08_58_14] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1411037
Z variance train             0.020793919
KL Divergence                27.058323
KL Loss                      2.7058322
QF Loss                      206.65492
VF Loss                      86.68347
Policy Loss                  -1190.6519
Q Predictions Mean           1190.6799
Q Predictions Std            421.26663
Q Predictions Max            1662.1384
Q Predictions Min            278.92142
V Predictions Mean           1195.4263
V Predictions Std            418.33755
V Predictions Max            1674.0677
V Predictions Min            285.62103
Log Pis Mean                 0.8051975
Log Pis Std                  3.6342943
Log Pis Max                  9.25308
Log Pis Min                  -7.0340776
Policy mu Mean               0.10112962
Policy mu Std                1.0136087
Policy mu Max                3.268585
Policy mu Min                -2.6093419
Policy log std Mean          -0.54472023
Policy log std Std           0.29131895
Policy log std Max           0.08738145
Policy log std Min           -2.1096659
Z mean eval                  2.1522732
Z variance eval              0.015967887
total_rewards                [4693.90199533 4567.66767637 4755.62122404 4696.59424256 4665.82410727
 4888.7283031  4762.7334344  4643.44760201 4730.84348837 4861.19911233]
total_rewards_mean           4726.6561185774535
total_rewards_std            91.87238913086729
total_rewards_max            4888.728303100411
total_rewards_min            4567.667676372081
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               29.043338095303625
(Previous) Eval Time (s)     21.874234673101455
Sample Time (s)              16.4793212111108
Epoch Time (s)               67.39689397951588
Total Train Time (s)         3408.373261708766
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:55:02.657768 UTC | [2020_01_10_08_58_14] Iteration #50 | Epoch Duration: 67.76734828948975
2020-01-10 09:55:02.657954 UTC | [2020_01_10_08_58_14] Iteration #50 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1532521
Z variance train             0.015988082
KL Divergence                27.637327
KL Loss                      2.7637327
QF Loss                      214.83138
VF Loss                      66.69902
Policy Loss                  -1172.785
Q Predictions Mean           1172.0869
Q Predictions Std            468.6788
Q Predictions Max            1710.0144
Q Predictions Min            280.52682
V Predictions Mean           1173.7274
V Predictions Std            463.08536
V Predictions Max            1702.5961
V Predictions Min            287.74048
Log Pis Mean                 1.0430014
Log Pis Std                  3.6566255
Log Pis Max                  13.346527
Log Pis Min                  -5.510718
Policy mu Mean               0.08637595
Policy mu Std                1.0299166
Policy mu Max                2.6171126
Policy mu Min                -2.4257457
Policy log std Mean          -0.5469968
Policy log std Std           0.29897058
Policy log std Max           0.09589529
Policy log std Min           -1.8838621
Z mean eval                  2.1471922
Z variance eval              0.013898915
total_rewards                [4828.61119636 5028.73720325 4828.95923913 4866.34663684 4906.97954752
 4849.65176098 4736.03628651 4709.71452609 4769.16763628 4673.3988579 ]
total_rewards_mean           4819.760289085358
total_rewards_std            98.79593131396967
total_rewards_max            5028.73720324908
total_rewards_min            4673.398857900504
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               27.996774517931044
(Previous) Eval Time (s)     22.24443212337792
Sample Time (s)              16.814101301133633
Epoch Time (s)               67.0553079424426
Total Train Time (s)         3475.7285906672478
Epoch                        51
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:56:10.016541 UTC | [2020_01_10_08_58_14] Iteration #51 | Epoch Duration: 67.35842323303223
2020-01-10 09:56:10.016829 UTC | [2020_01_10_08_58_14] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1498723
Z variance train             0.013895673
KL Divergence                27.92063
KL Loss                      2.792063
QF Loss                      124.08157
VF Loss                      43.204987
Policy Loss                  -1161.5754
Q Predictions Mean           1160.4299
Q Predictions Std            492.01584
Q Predictions Max            1709.1194
Q Predictions Min            278.93204
V Predictions Mean           1159.6365
V Predictions Std            489.1912
V Predictions Max            1705.4851
V Predictions Min            278.91788
Log Pis Mean                 0.75126874
Log Pis Std                  3.786168
Log Pis Max                  11.366135
Log Pis Min                  -6.7052574
Policy mu Mean               0.07108375
Policy mu Std                1.0104451
Policy mu Max                2.5715582
Policy mu Min                -2.5238087
Policy log std Mean          -0.5008267
Policy log std Std           0.29417717
Policy log std Max           0.07722296
Policy log std Min           -2.0028195
Z mean eval                  2.1479485
Z variance eval              0.021831397
total_rewards                [4686.04851688 4934.12329456 4711.7038615  4656.71969861 4785.93703142
 4802.57699859 4765.70143692 4742.96221931 4632.53842812 4771.04257633]
total_rewards_mean           4748.935406224916
total_rewards_std            81.69427300549488
total_rewards_max            4934.123294563511
total_rewards_min            4632.538428123723
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               29.297382920980453
(Previous) Eval Time (s)     22.547238213941455
Sample Time (s)              16.386990804225206
Epoch Time (s)               68.23161193914711
Total Train Time (s)         3544.1100624636747
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:57:18.400710 UTC | [2020_01_10_08_58_14] Iteration #52 | Epoch Duration: 68.38363671302795
2020-01-10 09:57:18.401031 UTC | [2020_01_10_08_58_14] Iteration #52 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1464698
Z variance train             0.021860877
KL Divergence                27.401854
KL Loss                      2.7401855
QF Loss                      227.52007
VF Loss                      154.1873
Policy Loss                  -1140.2036
Q Predictions Mean           1138.6318
Q Predictions Std            510.42896
Q Predictions Max            1747.6907
Q Predictions Min            278.87396
V Predictions Mean           1147.9197
V Predictions Std            510.0006
V Predictions Max            1755.1171
V Predictions Min            283.55194
Log Pis Mean                 1.1298103
Log Pis Std                  4.1509285
Log Pis Max                  12.25401
Log Pis Min                  -8.432697
Policy mu Mean               0.018251965
Policy mu Std                1.0393896
Policy mu Max                2.9078038
Policy mu Min                -2.9016125
Policy log std Mean          -0.5393663
Policy log std Std           0.31646538
Policy log std Max           0.13413514
Policy log std Min           -1.9704129
Z mean eval                  2.1576886
Z variance eval              0.016526518
total_rewards                [4814.68806556 5116.63781789 5005.74388883 5084.97789749 4867.4475951
 4930.86945822 5011.07949395 4925.18151171 4894.75414231 5014.21864961]
total_rewards_mean           4966.559852066985
total_rewards_std            91.30459340894929
total_rewards_max            5116.637817893796
total_rewards_min            4814.688065564488
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               28.743721374776214
(Previous) Eval Time (s)     22.6989908083342
Sample Time (s)              15.540579491760582
Epoch Time (s)               66.983291674871
Total Train Time (s)         3610.4416154106148
Epoch                        53
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:58:24.732608 UTC | [2020_01_10_08_58_14] Iteration #53 | Epoch Duration: 66.33135294914246
2020-01-10 09:58:24.732828 UTC | [2020_01_10_08_58_14] Iteration #53 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1603787
Z variance train             0.016472513
KL Divergence                27.993887
KL Loss                      2.7993886
QF Loss                      331.46283
VF Loss                      75.064644
Policy Loss                  -1239.5278
Q Predictions Mean           1243.1077
Q Predictions Std            472.5319
Q Predictions Max            1823.4314
Q Predictions Min            280.20386
V Predictions Mean           1240.4646
V Predictions Std            470.01688
V Predictions Max            1814.9421
V Predictions Min            278.46173
Log Pis Mean                 0.61956275
Log Pis Std                  3.6876793
Log Pis Max                  11.207886
Log Pis Min                  -7.692503
Policy mu Mean               0.1125764
Policy mu Std                1.0080928
Policy mu Max                2.5804763
Policy mu Min                -3.0077872
Policy log std Mean          -0.53433543
Policy log std Std           0.29906544
Policy log std Max           0.09298791
Policy log std Min           -1.9521215
Z mean eval                  2.1571002
Z variance eval              0.016607586
total_rewards                [4915.9796662  5117.5246441  4951.88404797 5030.49451718 4995.98437793
 5045.71172075 5189.79192828 5113.8684303  5039.16332388 5096.31802438]
total_rewards_mean           5049.672068096111
total_rewards_std            78.32431630330025
total_rewards_max            5189.791928278139
total_rewards_min            4915.979666197123
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               28.116698038298637
(Previous) Eval Time (s)     22.046774137299508
Sample Time (s)              16.59848445141688
Epoch Time (s)               66.76195662701502
Total Train Time (s)         3678.1711453259923
Epoch                        54
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 09:59:32.462715 UTC | [2020_01_10_08_58_14] Iteration #54 | Epoch Duration: 67.729736328125
2020-01-10 09:59:32.462917 UTC | [2020_01_10_08_58_14] Iteration #54 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.156401
Z variance train             0.016688507
KL Divergence                27.685112
KL Loss                      2.7685113
QF Loss                      372.48502
VF Loss                      67.853745
Policy Loss                  -1254.586
Q Predictions Mean           1249.8497
Q Predictions Std            509.01636
Q Predictions Max            1797.0879
Q Predictions Min            280.5266
V Predictions Mean           1255.606
V Predictions Std            509.12186
V Predictions Max            1808.667
V Predictions Min            281.6099
Log Pis Mean                 0.97791934
Log Pis Std                  3.6209571
Log Pis Max                  11.513164
Log Pis Min                  -6.636366
Policy mu Mean               -0.034018237
Policy mu Std                1.0322316
Policy mu Max                2.7389958
Policy mu Min                -2.3857944
Policy log std Mean          -0.5497138
Policy log std Std           0.3075993
Policy log std Max           0.06537323
Policy log std Min           -2.0434272
Z mean eval                  2.1776555
Z variance eval              0.01442835
total_rewards                [4861.65939158 5298.7605653  5243.27539817 5012.31995153 4903.94761823
 5023.04737036 5147.50386319 5003.2698495  5090.69125778 4854.97813427]
total_rewards_mean           5043.945339990376
total_rewards_std            144.6375952108468
total_rewards_max            5298.760565300198
total_rewards_min            4854.978134268064
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               29.01065932586789
(Previous) Eval Time (s)     23.01422127801925
Sample Time (s)              16.257479179184884
Epoch Time (s)               68.28235978307202
Total Train Time (s)         3745.8951328741387
Epoch                        55
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:00:40.187581 UTC | [2020_01_10_08_58_14] Iteration #55 | Epoch Duration: 67.72453236579895
2020-01-10 10:00:40.187738 UTC | [2020_01_10_08_58_14] Iteration #55 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1766326
Z variance train             0.014350548
KL Divergence                28.207872
KL Loss                      2.8207872
QF Loss                      212.75253
VF Loss                      136.91937
Policy Loss                  -1211.5421
Q Predictions Mean           1210.4037
Q Predictions Std            538.4638
Q Predictions Max            1858.1759
Q Predictions Min            265.25812
V Predictions Mean           1219.9967
V Predictions Std            538.1432
V Predictions Max            1869.7498
V Predictions Min            278.1071
Log Pis Mean                 1.2996805
Log Pis Std                  3.9128423
Log Pis Max                  11.885009
Log Pis Min                  -6.2985096
Policy mu Mean               0.04579444
Policy mu Std                1.0619004
Policy mu Max                3.1747997
Policy mu Min                -2.750522
Policy log std Mean          -0.5529494
Policy log std Std           0.3141411
Policy log std Max           0.1124323
Policy log std Min           -2.351337
Z mean eval                  2.157022
Z variance eval              0.014458373
total_rewards                [5038.01132805 5176.71128815 5172.75465735 5103.19181687 5127.06899257
 5352.22733433 4902.63706277 5095.54096203 5273.86017001 5232.45678465]
total_rewards_mean           5147.446039677317
total_rewards_std            119.83943729054718
total_rewards_max            5352.227334330295
total_rewards_min            4902.637062767506
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               29.986031678970903
(Previous) Eval Time (s)     22.456083330325782
Sample Time (s)              16.433484188281
Epoch Time (s)               68.87559919757769
Total Train Time (s)         3815.5106793940067
Epoch                        56
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:01:49.807608 UTC | [2020_01_10_08_58_14] Iteration #56 | Epoch Duration: 69.61971640586853
2020-01-10 10:01:49.807769 UTC | [2020_01_10_08_58_14] Iteration #56 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.154494
Z variance train             0.014395928
KL Divergence                28.088839
KL Loss                      2.808884
QF Loss                      312.89722
VF Loss                      106.86331
Policy Loss                  -1273.2511
Q Predictions Mean           1262.6233
Q Predictions Std            555.6076
Q Predictions Max            1899.1953
Q Predictions Min            268.6878
V Predictions Mean           1274.2411
V Predictions Std            554.9174
V Predictions Max            1921.2427
V Predictions Min            274.3459
Log Pis Mean                 1.3242491
Log Pis Std                  4.360898
Log Pis Max                  14.469998
Log Pis Min                  -7.4635124
Policy mu Mean               0.046896398
Policy mu Std                1.0653657
Policy mu Max                2.656083
Policy mu Min                -2.5746746
Policy log std Mean          -0.5676707
Policy log std Std           0.33208764
Policy log std Max           0.19676909
Policy log std Min           -2.1932936
Z mean eval                  2.163675
Z variance eval              0.02167516
total_rewards                [5368.06857246 4885.0249354  5231.39974843 5351.27099534 5252.89175674
 5229.05831436 5138.1812003  5401.77135491 5646.57401339 5292.8834117 ]
total_rewards_mean           5279.712430302323
total_rewards_std            185.4765009342179
total_rewards_max            5646.5740133943855
total_rewards_min            4885.024935396439
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               25.64781589899212
(Previous) Eval Time (s)     23.199913348071277
Sample Time (s)              15.880479500629008
Epoch Time (s)               64.7282087476924
Total Train Time (s)         3879.902026824653
Epoch                        57
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:02:54.198000 UTC | [2020_01_10_08_58_14] Iteration #57 | Epoch Duration: 64.39006900787354
2020-01-10 10:02:54.198202 UTC | [2020_01_10_08_58_14] Iteration #57 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1635165
Z variance train             0.0216234
KL Divergence                27.384888
KL Loss                      2.738489
QF Loss                      423.2975
VF Loss                      101.64133
Policy Loss                  -1254.2589
Q Predictions Mean           1247.9575
Q Predictions Std            560.70856
Q Predictions Max            1885.271
Q Predictions Min            273.4272
V Predictions Mean           1248.615
V Predictions Std            556.0822
V Predictions Max            1879.5563
V Predictions Min            279.71866
Log Pis Mean                 1.3935702
Log Pis Std                  4.208958
Log Pis Max                  13.658209
Log Pis Min                  -5.8657713
Policy mu Mean               0.027685262
Policy mu Std                1.0653001
Policy mu Max                2.855216
Policy mu Min                -2.7767131
Policy log std Mean          -0.5399261
Policy log std Std           0.3259776
Policy log std Max           0.11919689
Policy log std Min           -2.1647058
Z mean eval                  2.1599095
Z variance eval              0.036056057
total_rewards                [5103.68657042 5394.84055985 5148.16649762 5248.29872485 5224.48268856
 5142.05897759 5336.09855885 5201.26279426 5170.12251225 5148.63749767]
total_rewards_mean           5211.765538191491
total_rewards_std            87.68470093889198
total_rewards_max            5394.840559851676
total_rewards_min            5103.686570421813
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               28.714400267228484
(Previous) Eval Time (s)     22.861488942988217
Sample Time (s)              15.927468350622803
Epoch Time (s)               67.5033575608395
Total Train Time (s)         3947.155075466726
Epoch                        58
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:04:01.453978 UTC | [2020_01_10_08_58_14] Iteration #58 | Epoch Duration: 67.25559902191162
2020-01-10 10:04:01.454246 UTC | [2020_01_10_08_58_14] Iteration #58 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.157208
Z variance train             0.036334403
KL Divergence                26.439394
KL Loss                      2.6439395
QF Loss                      224.11626
VF Loss                      150.48628
Policy Loss                  -1373.16
Q Predictions Mean           1372.8546
Q Predictions Std            533.79376
Q Predictions Max            1983.343
Q Predictions Min            263.7381
V Predictions Mean           1382.6073
V Predictions Std            531.7222
V Predictions Max            1990.299
V Predictions Min            270.09683
Log Pis Mean                 1.4738374
Log Pis Std                  4.219463
Log Pis Max                  15.685078
Log Pis Min                  -7.3827486
Policy mu Mean               0.02406882
Policy mu Std                1.0951855
Policy mu Max                3.0321827
Policy mu Min                -2.5580084
Policy log std Mean          -0.5657545
Policy log std Std           0.3317151
Policy log std Max           0.16633883
Policy log std Min           -2.0725574
Z mean eval                  2.1738136
Z variance eval              0.037639566
total_rewards                [5573.34290974 5305.66762236 5463.79972581 5281.71596979 5546.90398367
 5578.54739967 5312.00278308 5281.97470139 5276.64939672 5323.01847646]
total_rewards_mean           5394.362296869179
total_rewards_std            123.67902150973339
total_rewards_max            5578.547399669198
total_rewards_min            5276.649396721426
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               28.059525463264436
(Previous) Eval Time (s)     22.613432260695845
Sample Time (s)              16.66878179088235
Epoch Time (s)               67.34173951484263
Total Train Time (s)         4014.653559321072
Epoch                        59
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:05:08.954764 UTC | [2020_01_10_08_58_14] Iteration #59 | Epoch Duration: 67.50028991699219
2020-01-10 10:05:08.955043 UTC | [2020_01_10_08_58_14] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1710272
Z variance train             0.037596084
KL Divergence                25.993141
KL Loss                      2.5993142
QF Loss                      237.45671
VF Loss                      183.58635
Policy Loss                  -1382.5194
Q Predictions Mean           1381.6482
Q Predictions Std            518.20276
Q Predictions Max            1947.9818
Q Predictions Min            279.7223
V Predictions Mean           1388.2229
V Predictions Std            516.19226
V Predictions Max            1937.2926
V Predictions Min            275.15494
Log Pis Mean                 1.2150263
Log Pis Std                  4.2055593
Log Pis Max                  17.144629
Log Pis Min                  -7.4127736
Policy mu Mean               0.019231938
Policy mu Std                1.0738664
Policy mu Max                3.040068
Policy mu Min                -2.7983172
Policy log std Mean          -0.5450362
Policy log std Std           0.2899925
Policy log std Max           0.07630496
Policy log std Min           -1.8832818
Z mean eval                  2.1847174
Z variance eval              0.041246805
total_rewards                [5422.53558027 5517.44771147 5326.58897953 5445.48677043 5378.46105296
 5501.22216832 5374.71381604 5336.42505525 5576.64101883 5316.66907383]
total_rewards_mean           5419.619122692279
total_rewards_std            84.52695005397018
total_rewards_max            5576.641018833275
total_rewards_min            5316.669073828739
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               28.798608478158712
(Previous) Eval Time (s)     22.77168391039595
Sample Time (s)              15.821746984031051
Epoch Time (s)               67.39203937258571
Total Train Time (s)         4081.810121672228
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:06:16.111116 UTC | [2020_01_10_08_58_14] Iteration #60 | Epoch Duration: 67.15588879585266
2020-01-10 10:06:16.111300 UTC | [2020_01_10_08_58_14] Iteration #60 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.1853395
Z variance train             0.04122432
KL Divergence                26.1654
KL Loss                      2.61654
QF Loss                      183.99957
VF Loss                      68.06395
Policy Loss                  -1333.3866
Q Predictions Mean           1329.2505
Q Predictions Std            536.12665
Q Predictions Max            1895.0265
Q Predictions Min            258.76624
V Predictions Mean           1330.9144
V Predictions Std            533.29846
V Predictions Max            1894.4792
V Predictions Min            260.8636
Log Pis Mean                 1.2756338
Log Pis Std                  3.909967
Log Pis Max                  13.668436
Log Pis Min                  -7.6690354
Policy mu Mean               0.027185017
Policy mu Std                1.0877012
Policy mu Max                2.888382
Policy mu Min                -2.9187188
Policy log std Mean          -0.57518715
Policy log std Std           0.3162999
Policy log std Max           0.12051977
Policy log std Min           -2.1816723
Z mean eval                  2.2164588
Z variance eval              0.026687121
total_rewards                [5545.54652917 5468.47036606 5355.13078436 5639.44557335 5506.50818401
 5335.31376884 5625.08188824 5434.11602178 5567.38835116 5478.25736374]
total_rewards_mean           5495.525883070428
total_rewards_std            97.70599015781846
total_rewards_max            5639.445573347716
total_rewards_min            5335.313768836012
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               28.665246568154544
(Previous) Eval Time (s)     22.53527554916218
Sample Time (s)              16.216667213011533
Epoch Time (s)               67.41718933032826
Total Train Time (s)         4149.5903581036255
Epoch                        61
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:07:23.892141 UTC | [2020_01_10_08_58_14] Iteration #61 | Epoch Duration: 67.78072690963745
2020-01-10 10:07:23.892284 UTC | [2020_01_10_08_58_14] Iteration #61 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2159078
Z variance train             0.026724195
KL Divergence                27.48811
KL Loss                      2.748811
QF Loss                      256.20337
VF Loss                      91.25507
Policy Loss                  -1393.2661
Q Predictions Mean           1389.7888
Q Predictions Std            546.4987
Q Predictions Max            1994.6167
Q Predictions Min            266.69238
V Predictions Mean           1398.968
V Predictions Std            545.0363
V Predictions Max            1987.7555
V Predictions Min            271.01028
Log Pis Mean                 1.857357
Log Pis Std                  4.004011
Log Pis Max                  16.08826
Log Pis Min                  -6.4125223
Policy mu Mean               0.06932331
Policy mu Std                1.1176256
Policy mu Max                2.876937
Policy mu Min                -2.4791496
Policy log std Mean          -0.5686187
Policy log std Std           0.3229329
Policy log std Max           0.08119503
Policy log std Min           -2.0132105
Z mean eval                  2.2153623
Z variance eval              0.027330205
total_rewards                [5609.64773473 5509.30219608 5654.32675281 5832.13907114 5721.7628922
 5596.4540547  5497.91713503 5604.5502777  5514.00848642 5683.00967381]
total_rewards_mean           5622.31182746284
total_rewards_std            99.87315792562623
total_rewards_max            5832.139071141743
total_rewards_min            5497.917135032415
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               25.962604022119194
(Previous) Eval Time (s)     22.898528148885816
Sample Time (s)              15.796521494165063
Epoch Time (s)               64.65765366517007
Total Train Time (s)         4214.203434229363
Epoch                        62
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:08:28.506388 UTC | [2020_01_10_08_58_14] Iteration #62 | Epoch Duration: 64.61399292945862
2020-01-10 10:08:28.506532 UTC | [2020_01_10_08_58_14] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.216539
Z variance train             0.02722558
KL Divergence                27.451303
KL Loss                      2.7451303
QF Loss                      197.80794
VF Loss                      80.62813
Policy Loss                  -1422.148
Q Predictions Mean           1418.4105
Q Predictions Std            559.632
Q Predictions Max            2037.1532
Q Predictions Min            279.66174
V Predictions Mean           1422.6593
V Predictions Std            559.8704
V Predictions Max            2030.8849
V Predictions Min            279.10284
Log Pis Mean                 1.5507205
Log Pis Std                  4.325054
Log Pis Max                  14.717589
Log Pis Min                  -8.19854
Policy mu Mean               -0.03990108
Policy mu Std                1.0941179
Policy mu Max                2.5435934
Policy mu Min                -3.3241124
Policy log std Mean          -0.5804058
Policy log std Std           0.3399306
Policy log std Max           0.08821705
Policy log std Min           -2.4765446
Z mean eval                  2.2274537
Z variance eval              0.025715131
total_rewards                [5498.40602242 5419.73176997 5575.82982769 5600.81590093 5613.53825836
 5570.40548689 5650.07257108 5690.00297174 5627.47196255 5637.52213288]
total_rewards_mean           5588.37969045024
total_rewards_std            74.75430030997265
total_rewards_max            5690.00297174394
total_rewards_min            5419.731769967422
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               29.706852270755917
(Previous) Eval Time (s)     22.854609187226743
Sample Time (s)              16.313621713779867
Epoch Time (s)               68.87508317176253
Total Train Time (s)         4283.465723580215
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:09:37.772194 UTC | [2020_01_10_08_58_14] Iteration #63 | Epoch Duration: 69.2655029296875
2020-01-10 10:09:37.772453 UTC | [2020_01_10_08_58_14] Iteration #63 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2267547
Z variance train             0.02581277
KL Divergence                28.073614
KL Loss                      2.8073614
QF Loss                      252.6203
VF Loss                      112.21701
Policy Loss                  -1493.0704
Q Predictions Mean           1494.7164
Q Predictions Std            567.79913
Q Predictions Max            2072.3855
Q Predictions Min            272.64032
V Predictions Mean           1499.4954
V Predictions Std            564.6845
V Predictions Max            2074.1448
V Predictions Min            282.8979
Log Pis Mean                 1.2897487
Log Pis Std                  3.8496914
Log Pis Max                  13.10647
Log Pis Min                  -6.4517994
Policy mu Mean               -0.0013171533
Policy mu Std                1.064518
Policy mu Max                2.7192717
Policy mu Min                -2.8677335
Policy log std Mean          -0.56766826
Policy log std Std           0.3253201
Policy log std Max           0.10996112
Policy log std Min           -2.1122935
Z mean eval                  2.2383764
Z variance eval              0.022625372
total_rewards                [5639.18110359 5624.74045767 5550.93071333 5666.89663612 5922.6424952
 5866.54652143 5951.96662868 5751.57087112 5479.5136064  5730.81466734]
total_rewards_mean           5718.480370087525
total_rewards_std            149.091628097081
total_rewards_max            5951.96662867611
total_rewards_min            5479.513606397585
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               27.592247622087598
(Previous) Eval Time (s)     23.244746710173786
Sample Time (s)              15.838213903829455
Epoch Time (s)               66.67520823609084
Total Train Time (s)         4349.618539026007
Epoch                        64
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:10:43.925017 UTC | [2020_01_10_08_58_14] Iteration #64 | Epoch Duration: 66.15238904953003
2020-01-10 10:10:43.925169 UTC | [2020_01_10_08_58_14] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.239267
Z variance train             0.022619307
KL Divergence                28.135584
KL Loss                      2.8135583
QF Loss                      233.1328
VF Loss                      75.19256
Policy Loss                  -1418.5502
Q Predictions Mean           1418.0255
Q Predictions Std            609.00714
Q Predictions Max            2081.2266
Q Predictions Min            263.79648
V Predictions Mean           1418.9055
V Predictions Std            605.6203
V Predictions Max            2079.2766
V Predictions Min            265.32065
Log Pis Mean                 1.4565258
Log Pis Std                  4.3225126
Log Pis Max                  12.785413
Log Pis Min                  -7.0794697
Policy mu Mean               0.039886054
Policy mu Std                1.10286
Policy mu Max                3.705659
Policy mu Min                -2.6886399
Policy log std Mean          -0.57394725
Policy log std Std           0.34807998
Policy log std Max           0.11543791
Policy log std Min           -2.2609015
Z mean eval                  2.2408588
Z variance eval              0.019407531
total_rewards                [5612.65883037 5688.21649115 5678.11449862 5780.99824322 5788.26074576
 5313.97554733 5880.90426127 5890.91491252 5927.24252649 5547.20289785]
total_rewards_mean           5710.848895457718
total_rewards_std            177.36850041036402
total_rewards_max            5927.242526491318
total_rewards_min            5313.975547332382
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               28.473638371098787
(Previous) Eval Time (s)     22.72164755500853
Sample Time (s)              15.94589205365628
Epoch Time (s)               67.1411779797636
Total Train Time (s)         4416.941939482
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:11:51.252350 UTC | [2020_01_10_08_58_14] Iteration #65 | Epoch Duration: 67.32702231407166
2020-01-10 10:11:51.252643 UTC | [2020_01_10_08_58_14] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2405422
Z variance train             0.019456798
KL Divergence                28.717232
KL Loss                      2.8717232
QF Loss                      174.88054
VF Loss                      129.67403
Policy Loss                  -1517.5938
Q Predictions Mean           1515.2675
Q Predictions Std            542.39453
Q Predictions Max            2097.254
Q Predictions Min            261.33636
V Predictions Mean           1523.1772
V Predictions Std            543.4656
V Predictions Max            2107.356
V Predictions Min            263.92264
Log Pis Mean                 1.6639533
Log Pis Std                  4.0792637
Log Pis Max                  11.956464
Log Pis Min                  -11.030262
Policy mu Mean               0.0039316495
Policy mu Std                1.0984235
Policy mu Max                2.8081381
Policy mu Min                -2.6095471
Policy log std Mean          -0.59303576
Policy log std Std           0.3462114
Policy log std Max           0.062485233
Policy log std Min           -2.2656937
Z mean eval                  2.2325244
Z variance eval              0.015580031
total_rewards                [5633.44728723 5779.76263923 5766.55496118 5765.92902074 5791.53811869
 5601.79057899 5860.38734342 5756.26930703 5908.5394106  5586.72389403]
total_rewards_mean           5745.094256114426
total_rewards_std            101.2262000821766
total_rewards_max            5908.539410603193
total_rewards_min            5586.7238940344505
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               27.13104876410216
(Previous) Eval Time (s)     22.907192735932767
Sample Time (s)              16.254329037386924
Epoch Time (s)               66.29257053742185
Total Train Time (s)         4483.365499861538
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:12:57.675748 UTC | [2020_01_10_08_58_14] Iteration #66 | Epoch Duration: 66.42289686203003
2020-01-10 10:12:57.675914 UTC | [2020_01_10_08_58_14] Iteration #66 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.234289
Z variance train             0.01557674
KL Divergence                29.213108
KL Loss                      2.921311
QF Loss                      304.13806
VF Loss                      120.74315
Policy Loss                  -1456.2968
Q Predictions Mean           1451.0908
Q Predictions Std            611.5598
Q Predictions Max            2137.5173
Q Predictions Min            264.55496
V Predictions Mean           1449.7458
V Predictions Std            608.6491
V Predictions Max            2124.574
V Predictions Min            266.30328
Log Pis Mean                 1.5059783
Log Pis Std                  4.277072
Log Pis Max                  16.627491
Log Pis Min                  -9.468849
Policy mu Mean               -0.005573718
Policy mu Std                1.0916823
Policy mu Max                2.6064975
Policy mu Min                -2.801099
Policy log std Mean          -0.5700469
Policy log std Std           0.33533755
Policy log std Max           0.13953587
Policy log std Min           -2.4257107
Z mean eval                  2.2467487
Z variance eval              0.014244762
total_rewards                [5743.95362301 6006.03680018 5717.66908705 5777.47076139 5882.5559109
 5861.61436218 5790.67753582 5663.45097604 5744.32916459 5752.82288474]
total_rewards_mean           5794.058110590784
total_rewards_std            93.37800553649208
total_rewards_max            6006.036800183913
total_rewards_min            5663.450976038116
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               27.881647622212768
(Previous) Eval Time (s)     23.037232376635075
Sample Time (s)              15.59590611467138
Epoch Time (s)               66.51478611351922
Total Train Time (s)         4550.062918268144
Epoch                        67
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:14:04.376587 UTC | [2020_01_10_08_58_14] Iteration #67 | Epoch Duration: 66.70051646232605
2020-01-10 10:14:04.376881 UTC | [2020_01_10_08_58_14] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.244554
Z variance train             0.014295442
KL Divergence                29.83005
KL Loss                      2.983005
QF Loss                      291.8429
VF Loss                      151.09856
Policy Loss                  -1546.9542
Q Predictions Mean           1547.1805
Q Predictions Std            577.2845
Q Predictions Max            2182.4412
Q Predictions Min            272.84033
V Predictions Mean           1555.3318
V Predictions Std            578.6166
V Predictions Max            2193.0217
V Predictions Min            272.11707
Log Pis Mean                 1.7763579
Log Pis Std                  4.213126
Log Pis Max                  12.624418
Log Pis Min                  -6.8263683
Policy mu Mean               -0.010476082
Policy mu Std                1.1528243
Policy mu Max                2.7860746
Policy mu Min                -3.1935494
Policy log std Mean          -0.58795536
Policy log std Std           0.33247343
Policy log std Max           0.05715795
Policy log std Min           -2.2475934
Z mean eval                  2.2449698
Z variance eval              0.015174148
total_rewards                [5884.61130352 5824.85983736 5686.23781403 5851.08915203 5803.96401286
 5799.42588619 5857.12722931 5749.44039317 5690.61411154 5942.99063305]
total_rewards_mean           5809.036037306008
total_rewards_std            77.94867017336199
total_rewards_max            5942.990633053152
total_rewards_min            5686.237814034303
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               28.225604658015072
(Previous) Eval Time (s)     23.22264959802851
Sample Time (s)              15.344678015913814
Epoch Time (s)               66.7929322719574
Total Train Time (s)         4616.711619934067
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:15:11.027490 UTC | [2020_01_10_08_58_14] Iteration #68 | Epoch Duration: 66.65038752555847
2020-01-10 10:15:11.027737 UTC | [2020_01_10_08_58_14] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2431238
Z variance train             0.01517714
KL Divergence                29.808151
KL Loss                      2.9808152
QF Loss                      257.12518
VF Loss                      126.24698
Policy Loss                  -1559.0018
Q Predictions Mean           1557.2781
Q Predictions Std            598.46924
Q Predictions Max            2198.6943
Q Predictions Min            261.0261
V Predictions Mean           1562.282
V Predictions Std            594.344
V Predictions Max            2188.6895
V Predictions Min            262.9598
Log Pis Mean                 1.9153699
Log Pis Std                  4.420315
Log Pis Max                  13.063719
Log Pis Min                  -6.00876
Policy mu Mean               -0.024595158
Policy mu Std                1.1002859
Policy mu Max                2.9912164
Policy mu Min                -2.9387407
Policy log std Mean          -0.59539074
Policy log std Std           0.34326923
Policy log std Max           0.10558671
Policy log std Min           -1.9848714
Z mean eval                  2.243568
Z variance eval              0.01585183
total_rewards                [5845.02602892 5798.34092672 5960.56307152 5856.6983394  5849.70669847
 5889.20136792 6035.28539079 5995.25546065 6117.00488562 6007.86262613]
total_rewards_mean           5935.494479613996
total_rewards_std            97.4927054532195
total_rewards_max            6117.004885621736
total_rewards_min            5798.340926715494
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               30.192461161874235
(Previous) Eval Time (s)     23.07985095307231
Sample Time (s)              17.12240140605718
Epoch Time (s)               70.39471352100372
Total Train Time (s)         4686.4522265335545
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:16:20.770774 UTC | [2020_01_10_08_58_14] Iteration #69 | Epoch Duration: 69.7427933216095
2020-01-10 10:16:20.771097 UTC | [2020_01_10_08_58_14] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2438097
Z variance train             0.015827803
KL Divergence                29.894247
KL Loss                      2.9894247
QF Loss                      212.76106
VF Loss                      106.062325
Policy Loss                  -1505.774
Q Predictions Mean           1505.4156
Q Predictions Std            626.4822
Q Predictions Max            2256.4802
Q Predictions Min            260.2918
V Predictions Mean           1510.6849
V Predictions Std            624.75195
V Predictions Max            2237.5918
V Predictions Min            262.8462
Log Pis Mean                 1.9542941
Log Pis Std                  4.4189906
Log Pis Max                  14.188113
Log Pis Min                  -7.4324675
Policy mu Mean               -0.008129419
Policy mu Std                1.155053
Policy mu Max                3.1565177
Policy mu Min                -2.5830512
Policy log std Mean          -0.57891446
Policy log std Std           0.34365338
Policy log std Max           0.13579443
Policy log std Min           -2.2943025
Z mean eval                  2.2314525
Z variance eval              0.019454297
total_rewards                [5342.45179321 5656.65171739 5755.46492228 5631.34130699 5721.39402225
 5623.01321819 5643.30539581 5670.64985564 5753.78902182 5709.66846726]
total_rewards_mean           5650.772972083795
total_rewards_std            112.57187959118525
total_rewards_max            5755.464922280066
total_rewards_min            5342.451793208454
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               24.05762762017548
(Previous) Eval Time (s)     22.42762533482164
Sample Time (s)              17.100347451400012
Epoch Time (s)               63.585600406397134
Total Train Time (s)         4750.114553696942
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:17:24.435809 UTC | [2020_01_10_08_58_14] Iteration #70 | Epoch Duration: 63.66435432434082
2020-01-10 10:17:24.436167 UTC | [2020_01_10_08_58_14] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.231877
Z variance train             0.019489124
KL Divergence                29.196991
KL Loss                      2.9196992
QF Loss                      426.65042
VF Loss                      222.53818
Policy Loss                  -1611.2755
Q Predictions Mean           1609.3157
Q Predictions Std            595.24286
Q Predictions Max            2237.491
Q Predictions Min            264.23175
V Predictions Mean           1614.0955
V Predictions Std            592.3027
V Predictions Max            2240.6414
V Predictions Min            267.53995
Log Pis Mean                 1.7889988
Log Pis Std                  4.3091183
Log Pis Max                  15.898474
Log Pis Min                  -7.912061
Policy mu Mean               -0.039513808
Policy mu Std                1.133737
Policy mu Max                3.2430654
Policy mu Min                -3.2857268
Policy log std Mean          -0.5910416
Policy log std Std           0.3319734
Policy log std Max           0.080301866
Policy log std Min           -2.3143148
Z mean eval                  2.2359774
Z variance eval              0.017304871
total_rewards                [5703.13600573 6095.78834503 5865.73957936 6059.48573587 6069.55043516
 5950.44184501 6110.17994632 6113.36921387 5779.42367633 6003.47969764]
total_rewards_mean           5975.059448032372
total_rewards_std            139.13994249655096
total_rewards_max            6113.369213870907
total_rewards_min            5703.13600572925
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               26.345388703979552
(Previous) Eval Time (s)     22.506022218614817
Sample Time (s)              15.598165704403073
Epoch Time (s)               64.44957662699744
Total Train Time (s)         4813.991562654264
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:18:28.313828 UTC | [2020_01_10_08_58_14] Iteration #71 | Epoch Duration: 63.87748122215271
2020-01-10 10:18:28.314038 UTC | [2020_01_10_08_58_14] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.237416
Z variance train             0.01732101
KL Divergence                29.869488
KL Loss                      2.9869487
QF Loss                      350.40085
VF Loss                      105.79764
Policy Loss                  -1684.8926
Q Predictions Mean           1685.0479
Q Predictions Std            577.4562
Q Predictions Max            2340.4414
Q Predictions Min            269.31073
V Predictions Mean           1681.4065
V Predictions Std            573.18317
V Predictions Max            2312.3386
V Predictions Min            269.30206
Log Pis Mean                 2.3969023
Log Pis Std                  4.5789905
Log Pis Max                  14.963171
Log Pis Min                  -5.6750984
Policy mu Mean               -0.017729962
Policy mu Std                1.2141942
Policy mu Max                3.1750405
Policy mu Min                -2.7449949
Policy log std Mean          -0.61126333
Policy log std Std           0.3342
Policy log std Max           0.13249423
Policy log std Min           -2.2604914
Z mean eval                  2.2535396
Z variance eval              0.016750837
total_rewards                [5862.00221728 6027.13094897 6116.36678395 5963.03194489 6041.36519949
 6018.07642405 6035.78930937 6100.90709768 6132.43479855 5840.93930502]
total_rewards_mean           6013.80440292538
total_rewards_std            94.40442836496433
total_rewards_max            6132.434798547869
total_rewards_min            5840.939305017816
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               27.190148942172527
(Previous) Eval Time (s)     21.933678578119725
Sample Time (s)              16.381439307238907
Epoch Time (s)               65.50526682753116
Total Train Time (s)         4880.193934451789
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:19:34.519454 UTC | [2020_01_10_08_58_14] Iteration #72 | Epoch Duration: 66.2051932811737
2020-01-10 10:19:34.519636 UTC | [2020_01_10_08_58_14] Iteration #72 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2531865
Z variance train             0.016838297
KL Divergence                30.580555
KL Loss                      3.0580556
QF Loss                      330.22357
VF Loss                      79.87677
Policy Loss                  -1689.786
Q Predictions Mean           1687.0577
Q Predictions Std            575.80756
Q Predictions Max            2273.276
Q Predictions Min            259.89337
V Predictions Mean           1688.8429
V Predictions Std            571.5423
V Predictions Max            2267.2993
V Predictions Min            259.71536
Log Pis Mean                 2.477123
Log Pis Std                  4.0407214
Log Pis Max                  12.522458
Log Pis Min                  -5.6366997
Policy mu Mean               -0.007823271
Policy mu Std                1.1842219
Policy mu Max                3.1638465
Policy mu Min                -3.033378
Policy log std Mean          -0.62750906
Policy log std Std           0.34202743
Policy log std Max           0.12123451
Policy log std Min           -2.227547
Z mean eval                  2.2632713
Z variance eval              0.011996684
total_rewards                [5926.21800943 6114.43427184 6036.042075   6036.69474304 6142.13806635
 5930.77294682 5916.71742781 5975.97575561 6041.33544287 5830.21947676]
total_rewards_mean           5995.054821554205
total_rewards_std            91.64212077353814
total_rewards_max            6142.138066348196
total_rewards_min            5830.219476760379
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               26.697003195993602
(Previous) Eval Time (s)     22.633330373093486
Sample Time (s)              15.936823655851185
Epoch Time (s)               65.26715722493827
Total Train Time (s)         4945.5509967501275
Epoch                        73
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:20:39.875155 UTC | [2020_01_10_08_58_14] Iteration #73 | Epoch Duration: 65.35538983345032
2020-01-10 10:20:39.875323 UTC | [2020_01_10_08_58_14] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2615018
Z variance train             0.01200618
KL Divergence                31.23601
KL Loss                      3.123601
QF Loss                      295.98016
VF Loss                      230.22955
Policy Loss                  -1691.864
Q Predictions Mean           1686.5302
Q Predictions Std            645.359
Q Predictions Max            2341.3748
Q Predictions Min            257.3714
V Predictions Mean           1693.9749
V Predictions Std            642.0473
V Predictions Max            2351.2893
V Predictions Min            260.77344
Log Pis Mean                 2.2221725
Log Pis Std                  4.4890614
Log Pis Max                  16.139341
Log Pis Min                  -8.377981
Policy mu Mean               -0.046468467
Policy mu Std                1.2054896
Policy mu Max                2.9288821
Policy mu Min                -3.101257
Policy log std Mean          -0.60211307
Policy log std Std           0.35040832
Policy log std Max           0.08323455
Policy log std Min           -2.1193779
Z mean eval                  2.267532
Z variance eval              0.0126733985
total_rewards                [5828.91912492 5949.22858443 6092.92537688 5947.84204813 6025.93900103
 5836.45540373 5964.01912129 5850.51740545 6194.65377106 5972.17709578]
total_rewards_mean           5966.267693269408
total_rewards_std            110.24828158849503
total_rewards_max            6194.6537710585635
total_rewards_min            5828.919124920098
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               27.61726621678099
(Previous) Eval Time (s)     22.721262925770134
Sample Time (s)              15.787298705428839
Epoch Time (s)               66.12582784797996
Total Train Time (s)         5011.013685061131
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:21:45.338971 UTC | [2020_01_10_08_58_14] Iteration #74 | Epoch Duration: 65.46353387832642
2020-01-10 10:21:45.339116 UTC | [2020_01_10_08_58_14] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2674882
Z variance train             0.012717731
KL Divergence                31.676544
KL Loss                      3.1676545
QF Loss                      231.79428
VF Loss                      148.20653
Policy Loss                  -1667.3517
Q Predictions Mean           1657.3855
Q Predictions Std            675.35065
Q Predictions Max            2391.8633
Q Predictions Min            253.98347
V Predictions Mean           1659.1521
V Predictions Std            669.0535
V Predictions Max            2379.3733
V Predictions Min            263.22006
Log Pis Mean                 2.2393222
Log Pis Std                  4.347248
Log Pis Max                  16.316181
Log Pis Min                  -5.578687
Policy mu Mean               0.004475907
Policy mu Std                1.1816175
Policy mu Max                2.8462641
Policy mu Min                -3.112198
Policy log std Mean          -0.58726937
Policy log std Std           0.3564908
Policy log std Max           0.15134183
Policy log std Min           -2.3802807
Z mean eval                  2.2580998
Z variance eval              0.016180042
total_rewards                [6349.84136757 6199.86311817 6291.67144181 6461.95309616 6240.18638966
 6387.3582035  5961.66999114 6260.17433762 6295.45305683 6130.41944821]
total_rewards_mean           6257.859045067946
total_rewards_std            133.0758305078162
total_rewards_max            6461.95309616401
total_rewards_min            5961.669991143135
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               27.328404418192804
(Previous) Eval Time (s)     22.05869257869199
Sample Time (s)              16.45880224974826
Epoch Time (s)               65.84589924663305
Total Train Time (s)         5077.936808428261
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:22:52.265175 UTC | [2020_01_10_08_58_14] Iteration #75 | Epoch Duration: 66.92588353157043
2020-01-10 10:22:52.265391 UTC | [2020_01_10_08_58_14] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2584333
Z variance train             0.01612547
KL Divergence                31.709023
KL Loss                      3.1709023
QF Loss                      258.4661
VF Loss                      132.96793
Policy Loss                  -1663.0801
Q Predictions Mean           1662.6516
Q Predictions Std            685.7758
Q Predictions Max            2454.8035
Q Predictions Min            261.2763
V Predictions Mean           1660.0935
V Predictions Std            678.9741
V Predictions Max            2445.7046
V Predictions Min            266.76685
Log Pis Mean                 1.8483958
Log Pis Std                  4.208205
Log Pis Max                  13.369088
Log Pis Min                  -7.2001905
Policy mu Mean               -0.051572636
Policy mu Std                1.1367376
Policy mu Max                2.451997
Policy mu Min                -2.9182374
Policy log std Mean          -0.5944487
Policy log std Std           0.34492975
Policy log std Max           0.096387476
Policy log std Min           -2.2352166
Z mean eval                  2.2752593
Z variance eval              0.013850316
total_rewards                [6127.7157334  6356.76647288 6306.85395826 6266.28695515 6453.79443438
 6473.46214678 6322.07194601 6248.08951126 6178.03230323 6094.96101923]
total_rewards_mean           6282.8034480586375
total_rewards_std            120.40409040256756
total_rewards_max            6473.462146784341
total_rewards_min            6094.961019233895
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               28.969949843361974
(Previous) Eval Time (s)     23.138352741952986
Sample Time (s)              15.77708907192573
Epoch Time (s)               67.88539165724069
Total Train Time (s)         5144.639739291742
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:23:58.968308 UTC | [2020_01_10_08_58_14] Iteration #76 | Epoch Duration: 66.70273995399475
2020-01-10 10:23:58.968475 UTC | [2020_01_10_08_58_14] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.273987
Z variance train             0.013780209
KL Divergence                32.168953
KL Loss                      3.2168953
QF Loss                      416.3128
VF Loss                      196.99783
Policy Loss                  -1723.7803
Q Predictions Mean           1727.7533
Q Predictions Std            638.6991
Q Predictions Max            2441.0598
Q Predictions Min            260.0241
V Predictions Mean           1729.5735
V Predictions Std            635.6902
V Predictions Max            2429.3003
V Predictions Min            262.13367
Log Pis Mean                 2.86229
Log Pis Std                  4.4336314
Log Pis Max                  14.111221
Log Pis Min                  -6.441245
Policy mu Mean               0.03483693
Policy mu Std                1.2133044
Policy mu Max                2.9032578
Policy mu Min                -3.0790453
Policy log std Mean          -0.63479865
Policy log std Std           0.33986646
Policy log std Max           0.11648592
Policy log std Min           -2.3438416
Z mean eval                  2.2697656
Z variance eval              0.012219466
total_rewards                [6170.89896452 6042.22545399 6525.36532002 6258.85131459 6152.22717085
 6270.03089288 6433.75925997 6217.6137327  6408.74808538 6291.79271613]
total_rewards_mean           6277.15129110259
total_rewards_std            137.72595956962417
total_rewards_max            6525.3653200162
total_rewards_min            6042.225453990269
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               31.22896077297628
(Previous) Eval Time (s)     21.955455855000764
Sample Time (s)              15.488335248082876
Epoch Time (s)               68.67275187605992
Total Train Time (s)         5213.636100472417
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:25:07.966041 UTC | [2020_01_10_08_58_14] Iteration #77 | Epoch Duration: 68.99744892120361
2020-01-10 10:25:07.966211 UTC | [2020_01_10_08_58_14] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2693532
Z variance train             0.0121843945
KL Divergence                32.137394
KL Loss                      3.2137394
QF Loss                      443.92926
VF Loss                      118.96536
Policy Loss                  -1688.4404
Q Predictions Mean           1684.8903
Q Predictions Std            694.3766
Q Predictions Max            2451.8687
Q Predictions Min            252.66138
V Predictions Mean           1686.9983
V Predictions Std            689.55457
V Predictions Max            2440.6462
V Predictions Min            255.23573
Log Pis Mean                 2.5381768
Log Pis Std                  4.3002996
Log Pis Max                  13.390251
Log Pis Min                  -6.5440416
Policy mu Mean               -0.07199847
Policy mu Std                1.1779908
Policy mu Max                2.7567647
Policy mu Min                -2.8919394
Policy log std Mean          -0.61722684
Policy log std Std           0.35296115
Policy log std Max           0.033169657
Policy log std Min           -2.3937316
Z mean eval                  2.283277
Z variance eval              0.015284223
total_rewards                [6142.55423017 6314.60386407 6462.22421655 6461.21891641 6537.51801745
 6199.05160499 6331.32564578 6499.58075848 6275.08825201 6437.19972284]
total_rewards_mean           6366.036522874922
total_rewards_std            126.71463081819088
total_rewards_max            6537.518017448757
total_rewards_min            6142.554230169518
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               29.41091575892642
(Previous) Eval Time (s)     22.279858875088394
Sample Time (s)              16.521166143007576
Epoch Time (s)               68.21194077702239
Total Train Time (s)         5283.2307352647185
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:26:17.561563 UTC | [2020_01_10_08_58_14] Iteration #78 | Epoch Duration: 69.59523892402649
2020-01-10 10:26:17.561701 UTC | [2020_01_10_08_58_14] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2850718
Z variance train             0.01515791
KL Divergence                32.32817
KL Loss                      3.2328172
QF Loss                      277.07382
VF Loss                      80.78453
Policy Loss                  -1820.3684
Q Predictions Mean           1816.9131
Q Predictions Std            655.3901
Q Predictions Max            2550.9883
Q Predictions Min            250.00868
V Predictions Mean           1819.283
V Predictions Std            649.7151
V Predictions Max            2544.6152
V Predictions Min            259.66577
Log Pis Mean                 2.3284533
Log Pis Std                  4.168053
Log Pis Max                  15.727142
Log Pis Min                  -5.825165
Policy mu Mean               0.0061693243
Policy mu Std                1.1590054
Policy mu Max                3.1543167
Policy mu Min                -2.621958
Policy log std Mean          -0.62649995
Policy log std Std           0.36251512
Policy log std Max           0.17365226
Policy log std Min           -2.3815613
Z mean eval                  2.2660413
Z variance eval              0.027134895
total_rewards                [6456.53000799 6389.5013026  6581.74551109 6499.30240824 6476.14446614
 6451.4241206  6521.09250325 6587.69101036 6535.83470252 6437.78134251]
total_rewards_mean           6493.70473753127
total_rewards_std            60.50182728291073
total_rewards_max            6587.691010363741
total_rewards_min            6389.501302602179
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               29.200498436111957
(Previous) Eval Time (s)     23.66284326603636
Sample Time (s)              17.450670848134905
Epoch Time (s)               70.31401255028322
Total Train Time (s)         5352.22955786949
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:27:26.561655 UTC | [2020_01_10_08_58_14] Iteration #79 | Epoch Duration: 68.99984645843506
2020-01-10 10:27:26.561794 UTC | [2020_01_10_08_58_14] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2654545
Z variance train             0.027175242
KL Divergence                30.885681
KL Loss                      3.0885682
QF Loss                      264.52618
VF Loss                      101.14026
Policy Loss                  -1805.4872
Q Predictions Mean           1803.7179
Q Predictions Std            630.1296
Q Predictions Max            2540.384
Q Predictions Min            260.43604
V Predictions Mean           1804.665
V Predictions Std            628.36444
V Predictions Max            2555.0374
V Predictions Min            256.97913
Log Pis Mean                 2.2273736
Log Pis Std                  4.4071074
Log Pis Max                  23.832932
Log Pis Min                  -6.457244
Policy mu Mean               -0.047571182
Policy mu Std                1.1801437
Policy mu Max                3.8954582
Policy mu Min                -3.5815427
Policy log std Mean          -0.604552
Policy log std Std           0.32223713
Policy log std Max           0.027885646
Policy log std Min           -2.1352477
Z mean eval                  2.27827
Z variance eval              0.029076885
total_rewards                [6435.14913972 6443.75376195 6522.16862863 6335.13163085 6591.26163648
 6431.04836939 6385.29300669 6356.81890302 6528.4902238  6544.64759323]
total_rewards_mean           6457.376289376158
total_rewards_std            81.49915857283416
total_rewards_max            6591.261636481592
total_rewards_min            6335.13163084629
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               29.399903771933168
(Previous) Eval Time (s)     22.348303198814392
Sample Time (s)              16.5880635692738
Epoch Time (s)               68.33627054002136
Total Train Time (s)         5420.484012040775
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:28:34.818795 UTC | [2020_01_10_08_58_14] Iteration #80 | Epoch Duration: 68.25684332847595
2020-01-10 10:28:34.818994 UTC | [2020_01_10_08_58_14] Iteration #80 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2780435
Z variance train             0.029056132
KL Divergence                29.813395
KL Loss                      2.9813395
QF Loss                      278.53436
VF Loss                      90.87255
Policy Loss                  -1899.003
Q Predictions Mean           1895.1296
Q Predictions Std            623.9688
Q Predictions Max            2522.9856
Q Predictions Min            249.13875
V Predictions Mean           1901.4519
V Predictions Std            618.471
V Predictions Max            2514.9421
V Predictions Min            260.79755
Log Pis Mean                 2.399744
Log Pis Std                  4.2947726
Log Pis Max                  14.265427
Log Pis Min                  -6.8887877
Policy mu Mean               -0.07155944
Policy mu Std                1.1839238
Policy mu Max                3.2674057
Policy mu Min                -2.7028549
Policy log std Mean          -0.6348443
Policy log std Std           0.34942642
Policy log std Max           0.075927645
Policy log std Min           -2.2761612
Z mean eval                  2.275161
Z variance eval              0.028506566
total_rewards                [6244.34191667 6490.99988586 6358.41876623 6241.70741423 6393.7913706
 6224.56524179 6131.21231417 6209.87946459 6319.53279071 6353.82004818]
total_rewards_mean           6296.826921303866
total_rewards_std            100.3320573841908
total_rewards_max            6490.999885857408
total_rewards_min            6131.212314172843
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               31.01826954819262
(Previous) Eval Time (s)     22.26861345395446
Sample Time (s)              16.260544400662184
Epoch Time (s)               69.54742740280926
Total Train Time (s)         5490.474242995027
Epoch                        81
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:29:44.809977 UTC | [2020_01_10_08_58_14] Iteration #81 | Epoch Duration: 69.9908356666565
2020-01-10 10:29:44.810142 UTC | [2020_01_10_08_58_14] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2744887
Z variance train             0.028454447
KL Divergence                29.730556
KL Loss                      2.9730556
QF Loss                      326.2724
VF Loss                      146.85364
Policy Loss                  -1754.9172
Q Predictions Mean           1750.7002
Q Predictions Std            656.03107
Q Predictions Max            2462.8936
Q Predictions Min            239.34874
V Predictions Mean           1751.1445
V Predictions Std            652.772
V Predictions Max            2460.4653
V Predictions Min            232.67601
Log Pis Mean                 2.3644686
Log Pis Std                  4.5984917
Log Pis Max                  14.107142
Log Pis Min                  -7.008932
Policy mu Mean               -0.012066242
Policy mu Std                1.1791964
Policy mu Max                2.757736
Policy mu Min                -2.8495853
Policy log std Mean          -0.6220978
Policy log std Std           0.36627436
Policy log std Max           0.09918699
Policy log std Min           -2.3738265
Z mean eval                  2.28914
Z variance eval              0.028013308
total_rewards                [6218.68750654 6520.82802849 6438.97724414 6569.30121068 6311.30596639
 6335.79261055 6398.50185319 6319.19018777 6260.3230464  6429.851264  ]
total_rewards_mean           6380.27589181416
total_rewards_std            106.15450711098592
total_rewards_max            6569.301210677189
total_rewards_min            6218.687506535498
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               27.684350925963372
(Previous) Eval Time (s)     22.71171963820234
Sample Time (s)              15.643952501937747
Epoch Time (s)               66.04002306610346
Total Train Time (s)         5556.981122131459
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:30:51.320810 UTC | [2020_01_10_08_58_14] Iteration #82 | Epoch Duration: 66.51051068305969
2020-01-10 10:30:51.321060 UTC | [2020_01_10_08_58_14] Iteration #82 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.289915
Z variance train             0.027942037
KL Divergence                29.819796
KL Loss                      2.9819796
QF Loss                      326.00702
VF Loss                      131.05812
Policy Loss                  -1861.8217
Q Predictions Mean           1863.342
Q Predictions Std            619.91113
Q Predictions Max            2592.9287
Q Predictions Min            245.41107
V Predictions Mean           1860.4135
V Predictions Std            615.102
V Predictions Max            2588.3738
V Predictions Min            248.4164
Log Pis Mean                 2.607862
Log Pis Std                  3.9892826
Log Pis Max                  14.361042
Log Pis Min                  -6.564497
Policy mu Mean               -0.059286237
Policy mu Std                1.1934718
Policy mu Max                3.030998
Policy mu Min                -2.8025844
Policy log std Mean          -0.6423654
Policy log std Std           0.33687854
Policy log std Max           0.020286113
Policy log std Min           -2.3628094
Z mean eval                  2.3008113
Z variance eval              0.032446213
total_rewards                [6007.17866162 6221.25549907 6382.67812661 6087.07890688 6231.3156657
 6275.30081633 6239.04728302 6312.12029642 6536.14854583 6154.92266279]
total_rewards_mean           6244.704646428488
total_rewards_std            141.25991225380707
total_rewards_max            6536.14854583315
total_rewards_min            6007.178661622505
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               28.686509402934462
(Previous) Eval Time (s)     23.18189493799582
Sample Time (s)              15.935527128633112
Epoch Time (s)               67.8039314695634
Total Train Time (s)         5623.770706330426
Epoch                        83
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:31:58.112673 UTC | [2020_01_10_08_58_14] Iteration #83 | Epoch Duration: 66.79139351844788
2020-01-10 10:31:58.112956 UTC | [2020_01_10_08_58_14] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.304588
Z variance train             0.03259256
KL Divergence                30.712646
KL Loss                      3.0712647
QF Loss                      401.78796
VF Loss                      305.55923
Policy Loss                  -1930.2075
Q Predictions Mean           1930.033
Q Predictions Std            605.6231
Q Predictions Max            2574.5579
Q Predictions Min            257.8191
V Predictions Mean           1916.6682
V Predictions Std            597.9633
V Predictions Max            2547.6716
V Predictions Min            250.60396
Log Pis Mean                 2.5202541
Log Pis Std                  4.438736
Log Pis Max                  13.61389
Log Pis Min                  -5.802577
Policy mu Mean               -0.014373754
Policy mu Std                1.2035382
Policy mu Max                2.9184666
Policy mu Min                -3.2957873
Policy log std Mean          -0.6495541
Policy log std Std           0.36629704
Policy log std Max           0.22973862
Policy log std Min           -2.2171793
Z mean eval                  2.3060002
Z variance eval              0.031152045
total_rewards                [6499.43465563 6725.69022841 6580.59914817 6512.19383821 6522.10646645
 6459.66310307 6476.51119445 6760.61204636 6622.28887125 6614.64785327]
total_rewards_mean           6577.374740527887
total_rewards_std            98.18229401172913
total_rewards_max            6760.612046361333
total_rewards_min            6459.663103068671
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               27.44032218772918
(Previous) Eval Time (s)     22.169059986248612
Sample Time (s)              17.17770242271945
Epoch Time (s)               66.78708459669724
Total Train Time (s)         5690.748176207766
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:33:05.090245 UTC | [2020_01_10_08_58_14] Iteration #84 | Epoch Duration: 66.97709369659424
2020-01-10 10:33:05.090428 UTC | [2020_01_10_08_58_14] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3061972
Z variance train             0.030791992
KL Divergence                30.980064
KL Loss                      3.0980065
QF Loss                      230.62257
VF Loss                      103.477646
Policy Loss                  -1821.9149
Q Predictions Mean           1818.3802
Q Predictions Std            686.02313
Q Predictions Max            2539.3604
Q Predictions Min            241.7249
V Predictions Mean           1819.5459
V Predictions Std            684.5769
V Predictions Max            2534.9749
V Predictions Min            242.16466
Log Pis Mean                 2.5895708
Log Pis Std                  4.437112
Log Pis Max                  14.467643
Log Pis Min                  -6.722234
Policy mu Mean               -0.10273284
Policy mu Std                1.1961485
Policy mu Max                2.8181875
Policy mu Min                -2.8146849
Policy log std Mean          -0.64380497
Policy log std Std           0.37856683
Policy log std Max           0.10235196
Policy log std Min           -2.4540691
Z mean eval                  2.309624
Z variance eval              0.032089505
total_rewards                [6560.31992902 6386.34957494 6532.94369679 6563.85517121 6540.57215175
 6335.79430837 6459.10306568 6192.27891214 6399.05609177 6490.62457304]
total_rewards_mean           6446.0897474713365
total_rewards_std            113.0957721488543
total_rewards_max            6563.855171212488
total_rewards_min            6192.278912136976
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               28.44337068591267
(Previous) Eval Time (s)     22.35880007315427
Sample Time (s)              15.296638174913824
Epoch Time (s)               66.09880893398076
Total Train Time (s)         5757.565131159965
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:34:11.911252 UTC | [2020_01_10_08_58_14] Iteration #85 | Epoch Duration: 66.82067060470581
2020-01-10 10:34:11.911520 UTC | [2020_01_10_08_58_14] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3085237
Z variance train             0.031934924
KL Divergence                31.32882
KL Loss                      3.1328819
QF Loss                      397.6361
VF Loss                      97.149445
Policy Loss                  -1945.4766
Q Predictions Mean           1936.8284
Q Predictions Std            685.4218
Q Predictions Max            2635.03
Q Predictions Min            243.37027
V Predictions Mean           1942.3816
V Predictions Std            683.6897
V Predictions Max            2631.0308
V Predictions Min            255.18042
Log Pis Mean                 2.9482884
Log Pis Std                  4.2065597
Log Pis Max                  14.773022
Log Pis Min                  -7.944811
Policy mu Mean               0.010505132
Policy mu Std                1.2144148
Policy mu Max                2.7105036
Policy mu Min                -3.264991
Policy log std Mean          -0.63046396
Policy log std Std           0.33831072
Policy log std Max           0.08058393
Policy log std Min           -2.4361777
Z mean eval                  2.3146508
Z variance eval              0.039520603
total_rewards                [6454.67120427 6673.80661387 6380.79640989 6513.38755957 6337.73949904
 6419.20007353 6545.83006029 6446.36837425 6468.41440463 6570.29447818]
total_rewards_mean           6481.050867752918
total_rewards_std            93.18490905567185
total_rewards_max            6673.806613869521
total_rewards_min            6337.739499035504
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               29.17531004315242
(Previous) Eval Time (s)     23.080382572021335
Sample Time (s)              15.873034514021128
Epoch Time (s)               68.12872712919489
Total Train Time (s)         5824.692171816248
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:35:19.040222 UTC | [2020_01_10_08_58_14] Iteration #86 | Epoch Duration: 67.12848424911499
2020-01-10 10:35:19.040481 UTC | [2020_01_10_08_58_14] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3147
Z variance train             0.039644107
KL Divergence                31.103745
KL Loss                      3.1103745
QF Loss                      294.37595
VF Loss                      148.22038
Policy Loss                  -1871.248
Q Predictions Mean           1862.3047
Q Predictions Std            668.4212
Q Predictions Max            2532.6965
Q Predictions Min            234.29779
V Predictions Mean           1866.5457
V Predictions Std            664.77954
V Predictions Max            2535.9688
V Predictions Min            233.11354
Log Pis Mean                 2.9651124
Log Pis Std                  4.255197
Log Pis Max                  12.80669
Log Pis Min                  -6.325706
Policy mu Mean               -0.008736645
Policy mu Std                1.2355636
Policy mu Max                2.900698
Policy mu Min                -2.7830563
Policy log std Mean          -0.60919917
Policy log std Std           0.32666788
Policy log std Max           0.09376952
Policy log std Min           -2.2125227
Z mean eval                  2.3212192
Z variance eval              0.031857945
total_rewards                [6447.59707946 6649.68682365 6519.08461041 6520.43307869 6689.89301973
 6827.13988174 6575.00458337 6490.26837146 3770.4143118  6644.33336716]
total_rewards_mean           6313.385512747051
total_rewards_std            854.2806727999525
total_rewards_max            6827.13988174444
total_rewards_min            3770.4143117967633
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               29.379946088884026
(Previous) Eval Time (s)     22.07986283209175
Sample Time (s)              15.99030597973615
Epoch Time (s)               67.45011490071192
Total Train Time (s)         5892.552352119237
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:36:26.901308 UTC | [2020_01_10_08_58_14] Iteration #87 | Epoch Duration: 67.8606436252594
2020-01-10 10:36:26.901478 UTC | [2020_01_10_08_58_14] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3211687
Z variance train             0.03175325
KL Divergence                31.822819
KL Loss                      3.182282
QF Loss                      319.96667
VF Loss                      176.11435
Policy Loss                  -1824.0219
Q Predictions Mean           1827.6056
Q Predictions Std            752.38904
Q Predictions Max            2653.613
Q Predictions Min            243.91814
V Predictions Mean           1830.2129
V Predictions Std            750.8889
V Predictions Max            2643.035
V Predictions Min            246.21088
Log Pis Mean                 2.4117289
Log Pis Std                  4.5408635
Log Pis Max                  19.322609
Log Pis Min                  -6.1752057
Policy mu Mean               -0.03527015
Policy mu Std                1.2065268
Policy mu Max                3.8194723
Policy mu Min                -2.857562
Policy log std Mean          -0.6142821
Policy log std Std           0.36240163
Policy log std Max           0.19305784
Policy log std Min           -2.4450169
Z mean eval                  2.3429177
Z variance eval              0.025246227
total_rewards                [6812.77887661 6702.49289871 6606.49304864 6813.79089336 6942.52989144
 6859.67048494 6804.96486812 6587.86476694 6883.75611444 6497.94806265]
total_rewards_mean           6751.228990585287
total_rewards_std            138.08394300859408
total_rewards_max            6942.529891437521
total_rewards_min            6497.948062650457
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               28.515117041766644
(Previous) Eval Time (s)     22.49013440310955
Sample Time (s)              16.369372403249145
Epoch Time (s)               67.37462384812534
Total Train Time (s)         5959.770283011254
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:37:34.120031 UTC | [2020_01_10_08_58_14] Iteration #88 | Epoch Duration: 67.2183997631073
2020-01-10 10:37:34.120257 UTC | [2020_01_10_08_58_14] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3391476
Z variance train             0.025278807
KL Divergence                32.564068
KL Loss                      3.2564068
QF Loss                      453.76862
VF Loss                      90.62661
Policy Loss                  -1884.5735
Q Predictions Mean           1876.5852
Q Predictions Std            717.4537
Q Predictions Max            2621.2908
Q Predictions Min            234.71234
V Predictions Mean           1883.416
V Predictions Std            713.6743
V Predictions Max            2611.8816
V Predictions Min            241.81693
Log Pis Mean                 2.6190896
Log Pis Std                  4.58164
Log Pis Max                  19.116158
Log Pis Min                  -5.829254
Policy mu Mean               -0.051277503
Policy mu Std                1.1865513
Policy mu Max                3.277909
Policy mu Min                -2.9665499
Policy log std Mean          -0.63633084
Policy log std Std           0.3560029
Policy log std Max           0.04352042
Policy log std Min           -2.483859
Z mean eval                  2.3343372
Z variance eval              0.02280263
total_rewards                [6679.0872821  6666.32412691 6693.15073346 6761.54907876 6672.59815914
 6816.02859573 6546.67176348 6597.67317372 6671.05879043 6693.67677703]
total_rewards_mean           6679.781848076425
total_rewards_std            70.98610514478365
total_rewards_max            6816.028595733844
total_rewards_min            6546.671763479801
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               25.076559614855796
(Previous) Eval Time (s)     22.333624521270394
Sample Time (s)              16.254260644782335
Epoch Time (s)               63.664444780908525
Total Train Time (s)         6023.104594335891
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:38:37.457231 UTC | [2020_01_10_08_58_14] Iteration #89 | Epoch Duration: 63.33681344985962
2020-01-10 10:38:37.457492 UTC | [2020_01_10_08_58_14] Iteration #89 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3326583
Z variance train             0.022768812
KL Divergence                32.832363
KL Loss                      3.2832363
QF Loss                      333.40106
VF Loss                      141.20938
Policy Loss                  -1889.4646
Q Predictions Mean           1877.8364
Q Predictions Std            776.66345
Q Predictions Max            2647.5745
Q Predictions Min            232.96307
V Predictions Mean           1883.1602
V Predictions Std            771.1982
V Predictions Max            2647.7925
V Predictions Min            244.01468
Log Pis Mean                 2.7101917
Log Pis Std                  4.4574733
Log Pis Max                  14.786833
Log Pis Min                  -5.409944
Policy mu Mean               -0.018188374
Policy mu Std                1.2088472
Policy mu Max                3.1054235
Policy mu Min                -3.217559
Policy log std Mean          -0.62741894
Policy log std Std           0.35107803
Policy log std Max           0.122436374
Policy log std Min           -2.3995395
Z mean eval                  2.3472567
Z variance eval              0.021562893
total_rewards                [6670.15614115 6659.80716589 6660.60819412 6687.7573302  6745.9123497
 6703.56573041 6589.55312447 6647.47218902 6516.10166664 6695.40349154]
total_rewards_mean           6657.633738315983
total_rewards_std            60.972766297068084
total_rewards_max            6745.912349702432
total_rewards_min            6516.101666639569
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               28.015787957701832
(Previous) Eval Time (s)     22.005683389957994
Sample Time (s)              15.622771767899394
Epoch Time (s)               65.64424311555922
Total Train Time (s)         6090.03832204733
Epoch                        90
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:39:44.391829 UTC | [2020_01_10_08_58_14] Iteration #90 | Epoch Duration: 66.93416166305542
2020-01-10 10:39:44.391990 UTC | [2020_01_10_08_58_14] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3456273
Z variance train             0.021529969
KL Divergence                33.199177
KL Loss                      3.3199177
QF Loss                      326.30066
VF Loss                      88.93281
Policy Loss                  -2035.1902
Q Predictions Mean           2027.5763
Q Predictions Std            623.8755
Q Predictions Max            2741.612
Q Predictions Min            221.7853
V Predictions Mean           2035.6865
V Predictions Std            620.4575
V Predictions Max            2739.252
V Predictions Min            231.61975
Log Pis Mean                 3.132391
Log Pis Std                  4.2099066
Log Pis Max                  13.4738865
Log Pis Min                  -6.2365313
Policy mu Mean               -0.046335455
Policy mu Std                1.2398995
Policy mu Max                3.1675537
Policy mu Min                -2.9372013
Policy log std Mean          -0.6613964
Policy log std Std           0.35352483
Policy log std Max           0.04774627
Policy log std Min           -2.262518
Z mean eval                  2.3230426
Z variance eval              0.02158868
total_rewards                [6652.20847019 6937.21185116 6635.98584333 6753.74249937 6884.73805191
 6575.17918699 6673.47637842 6451.40186898 6894.92566099 6616.23496474]
total_rewards_mean           6707.510477608431
total_rewards_std            149.06407993926018
total_rewards_max            6937.211851157464
total_rewards_min            6451.401868981375
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               27.857400631997734
(Previous) Eval Time (s)     23.295334958005697
Sample Time (s)              16.0382347763516
Epoch Time (s)               67.19097036635503
Total Train Time (s)         6156.471748010721
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:40:50.826721 UTC | [2020_01_10_08_58_14] Iteration #91 | Epoch Duration: 66.43460965156555
2020-01-10 10:40:50.826873 UTC | [2020_01_10_08_58_14] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3247027
Z variance train             0.021461736
KL Divergence                33.411224
KL Loss                      3.3411224
QF Loss                      213.89754
VF Loss                      217.54509
Policy Loss                  -2013.2855
Q Predictions Mean           2003.9448
Q Predictions Std            663.729
Q Predictions Max            2701.529
Q Predictions Min            238.918
V Predictions Mean           2003.4827
V Predictions Std            660.4727
V Predictions Max            2701.0378
V Predictions Min            240.57826
Log Pis Mean                 3.1147327
Log Pis Std                  4.1564813
Log Pis Max                  13.064125
Log Pis Min                  -5.618572
Policy mu Mean               -0.050016433
Policy mu Std                1.2288998
Policy mu Max                3.0629117
Policy mu Min                -2.9772131
Policy log std Mean          -0.6449609
Policy log std Std           0.35890943
Policy log std Max           0.06491852
Policy log std Min           -2.5720026
Z mean eval                  2.3326054
Z variance eval              0.019510273
total_rewards                [6747.15618409 6972.954499   6870.3665201  6907.50042994 6598.82779577
 6630.56688416 6653.85615504 6789.94139017 6813.42115665 6780.78188589]
total_rewards_mean           6776.537290081105
total_rewards_std            116.14431907382983
total_rewards_max            6972.954498995617
total_rewards_min            6598.827795765493
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               30.81008875509724
(Previous) Eval Time (s)     22.538702144753188
Sample Time (s)              16.351682054344565
Epoch Time (s)               69.70047295419499
Total Train Time (s)         6226.07520536473
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:42:00.433825 UTC | [2020_01_10_08_58_14] Iteration #92 | Epoch Duration: 69.60679388046265
2020-01-10 10:42:00.434110 UTC | [2020_01_10_08_58_14] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3296933
Z variance train             0.019533867
KL Divergence                33.66477
KL Loss                      3.3664768
QF Loss                      338.28714
VF Loss                      149.45984
Policy Loss                  -2048.7275
Q Predictions Mean           2041.7021
Q Predictions Std            631.17456
Q Predictions Max            2685.534
Q Predictions Min            227.75919
V Predictions Mean           2053.332
V Predictions Std            630.2796
V Predictions Max            2685.592
V Predictions Min            232.1842
Log Pis Mean                 3.3445435
Log Pis Std                  4.3199105
Log Pis Max                  13.911871
Log Pis Min                  -6.4695926
Policy mu Mean               -0.022832714
Policy mu Std                1.2602392
Policy mu Max                2.9272575
Policy mu Min                -3.159759
Policy log std Mean          -0.65748554
Policy log std Std           0.35938182
Policy log std Max           0.032520384
Policy log std Min           -2.3260524
Z mean eval                  2.3273668
Z variance eval              0.01618798
total_rewards                [6789.2131516  6560.082581   6750.77568358 6798.4643998  6984.23051095
 7049.43558896 6943.68884395 7152.57072461 6956.28411116 7088.66107389]
total_rewards_mean           6907.340666949518
total_rewards_std            171.38945724013766
total_rewards_max            7152.570724607078
total_rewards_min            6560.0825809982425
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               26.780794459860772
(Previous) Eval Time (s)     22.444702153094113
Sample Time (s)              16.043933435343206
Epoch Time (s)               65.26943004829809
Total Train Time (s)         6291.043141108472
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:43:05.402904 UTC | [2020_01_10_08_58_14] Iteration #93 | Epoch Duration: 64.96858787536621
2020-01-10 10:43:05.403101 UTC | [2020_01_10_08_58_14] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3258834
Z variance train             0.01620361
KL Divergence                33.96117
KL Loss                      3.396117
QF Loss                      400.89923
VF Loss                      124.48654
Policy Loss                  -2002.5658
Q Predictions Mean           1996.3286
Q Predictions Std            723.3408
Q Predictions Max            2734.3823
Q Predictions Min            216.82864
V Predictions Mean           2002.274
V Predictions Std            717.75616
V Predictions Max            2718.644
V Predictions Min            233.59845
Log Pis Mean                 2.8818579
Log Pis Std                  4.3889346
Log Pis Max                  15.259434
Log Pis Min                  -8.240607
Policy mu Mean               -0.039937753
Policy mu Std                1.1979666
Policy mu Max                2.6486669
Policy mu Min                -3.0157945
Policy log std Mean          -0.66724426
Policy log std Std           0.37713426
Policy log std Max           0.062452942
Policy log std Min           -2.4963446
Z mean eval                  2.327971
Z variance eval              0.014590274
total_rewards                [6861.73454901 6868.20766609 6804.59328022 7072.47044503 6796.36581535
 6940.28150391 6909.80213174 6832.52389891 6873.91068394 6837.10389735]
total_rewards_mean           6879.699387156205
total_rewards_std            76.71418834617836
total_rewards_max            7072.470445030849
total_rewards_min            6796.36581534528
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               29.561877228785306
(Previous) Eval Time (s)     22.143593668937683
Sample Time (s)              16.53512380924076
Epoch Time (s)               68.24059470696375
Total Train Time (s)         6359.542746115476
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:44:13.903790 UTC | [2020_01_10_08_58_14] Iteration #94 | Epoch Duration: 68.50054049491882
2020-01-10 10:44:13.904003 UTC | [2020_01_10_08_58_14] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3290055
Z variance train             0.014562289
KL Divergence                34.66037
KL Loss                      3.466037
QF Loss                      284.0926
VF Loss                      92.692276
Policy Loss                  -1991.3735
Q Predictions Mean           1991.1556
Q Predictions Std            754.48395
Q Predictions Max            2737.7544
Q Predictions Min            233.7213
V Predictions Mean           1994.1686
V Predictions Std            751.69824
V Predictions Max            2731.8916
V Predictions Min            231.4945
Log Pis Mean                 2.4899044
Log Pis Std                  4.48295
Log Pis Max                  13.774622
Log Pis Min                  -6.136931
Policy mu Mean               -0.037058245
Policy mu Std                1.1894155
Policy mu Max                2.6945128
Policy mu Min                -2.8419147
Policy log std Mean          -0.6210141
Policy log std Std           0.3600087
Policy log std Max           0.09976542
Policy log std Min           -2.4281783
Z mean eval                  2.3331244
Z variance eval              0.017550591
total_rewards                [6823.63375293 7132.42808315 7144.06226363 6820.30928214 7098.18574119
 6991.51615872 6822.40270171 6761.13886704 7214.05757661 6968.37596951]
total_rewards_mean           6977.611039662408
total_rewards_std            155.49947481907537
total_rewards_max            7214.0575766119855
total_rewards_min            6761.138867037638
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               28.498519076034427
(Previous) Eval Time (s)     22.40325109194964
Sample Time (s)              16.26834304444492
Epoch Time (s)               67.17011321242899
Total Train Time (s)         6427.1095722964965
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:45:21.471516 UTC | [2020_01_10_08_58_14] Iteration #95 | Epoch Duration: 67.56738591194153
2020-01-10 10:45:21.471673 UTC | [2020_01_10_08_58_14] Iteration #95 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3331127
Z variance train             0.017593285
KL Divergence                34.299217
KL Loss                      3.4299219
QF Loss                      299.0172
VF Loss                      99.97858
Policy Loss                  -2016.7317
Q Predictions Mean           2009.5365
Q Predictions Std            730.4027
Q Predictions Max            2818.35
Q Predictions Min            232.03185
V Predictions Mean           2013.3129
V Predictions Std            726.6376
V Predictions Max            2809.7449
V Predictions Min            234.82558
Log Pis Mean                 3.1287427
Log Pis Std                  4.4614534
Log Pis Max                  14.65264
Log Pis Min                  -5.2973022
Policy mu Mean               -0.016994813
Policy mu Std                1.2140418
Policy mu Max                2.7441757
Policy mu Min                -3.3499753
Policy log std Mean          -0.657943
Policy log std Std           0.35936168
Policy log std Max           0.19573617
Policy log std Min           -2.4207382
Z mean eval                  2.3333657
Z variance eval              0.01277755
total_rewards                [6879.8370901  6907.85209851 6926.40466466 7040.44720416 6999.8731621
 6695.97467964 6786.88434391 6799.92299017 6984.24326497 6969.94839667]
total_rewards_mean           6899.138789488083
total_rewards_std            103.57830386616425
total_rewards_max            7040.447204157796
total_rewards_min            6695.974679642019
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               28.240579013712704
(Previous) Eval Time (s)     22.800243484787643
Sample Time (s)              15.648755519185215
Epoch Time (s)               66.68957801768556
Total Train Time (s)         6493.344771685544
Epoch                        96
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:46:27.711207 UTC | [2020_01_10_08_58_14] Iteration #96 | Epoch Duration: 66.23935317993164
2020-01-10 10:46:27.711508 UTC | [2020_01_10_08_58_14] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.33522
Z variance train             0.012772533
KL Divergence                34.637676
KL Loss                      3.4637678
QF Loss                      412.91833
VF Loss                      158.94482
Policy Loss                  -2086.7937
Q Predictions Mean           2086.41
Q Predictions Std            711.13434
Q Predictions Max            2828.7988
Q Predictions Min            229.50735
V Predictions Mean           2085.0596
V Predictions Std            706.5887
V Predictions Max            2815.2515
V Predictions Min            231.21649
Log Pis Mean                 3.0488157
Log Pis Std                  4.4993167
Log Pis Max                  17.936756
Log Pis Min                  -5.00313
Policy mu Mean               -0.019570796
Policy mu Std                1.2527966
Policy mu Max                2.9526076
Policy mu Min                -2.694577
Policy log std Mean          -0.6581955
Policy log std Std           0.3736914
Policy log std Max           0.12706146
Policy log std Min           -2.4317055
Z mean eval                  2.3339305
Z variance eval              0.011682227
total_rewards                [6778.03667079 6829.9476906  6867.70942535 6819.30846489 6818.79029322
 7223.32868473 6813.98740335 6912.69083524 6931.3633121  6886.72898738]
total_rewards_mean           6888.189176762835
total_rewards_std            120.746298231944
total_rewards_max            7223.328684728485
total_rewards_min            6778.0366707891035
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               29.3665588805452
(Previous) Eval Time (s)     22.349727627821267
Sample Time (s)              15.767576568294317
Epoch Time (s)               67.48386307666078
Total Train Time (s)         6561.3951208228245
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:47:35.764548 UTC | [2020_01_10_08_58_14] Iteration #97 | Epoch Duration: 68.05279278755188
2020-01-10 10:47:35.764867 UTC | [2020_01_10_08_58_14] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.332569
Z variance train             0.011669248
KL Divergence                35.002213
KL Loss                      3.5002213
QF Loss                      313.5664
VF Loss                      154.9036
Policy Loss                  -1999.4474
Q Predictions Mean           1991.6913
Q Predictions Std            749.2524
Q Predictions Max            2810.6292
Q Predictions Min            225.85486
V Predictions Mean           1999.5052
V Predictions Std            742.9848
V Predictions Max            2809.13
V Predictions Min            231.41414
Log Pis Mean                 2.6966543
Log Pis Std                  4.731953
Log Pis Max                  23.32095
Log Pis Min                  -6.516657
Policy mu Mean               0.0394726
Policy mu Std                1.2274178
Policy mu Max                3.704877
Policy mu Min                -3.3614087
Policy log std Mean          -0.6407483
Policy log std Std           0.36498043
Policy log std Max           0.13741714
Policy log std Min           -2.4794595
Z mean eval                  2.3344111
Z variance eval              0.01163839
total_rewards                [6810.27631344 7076.60022175 7212.60378389 6925.78330924 7247.38088807
 6945.45425066 7158.16919639 7020.28234218 7086.22628544 6823.94998952]
total_rewards_mean           7030.6726580573495
total_rewards_std            145.32481788662966
total_rewards_max            7247.380888065587
total_rewards_min            6810.276313436513
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               27.65799287101254
(Previous) Eval Time (s)     22.918402594979852
Sample Time (s)              16.008505039848387
Epoch Time (s)               66.58490050584078
Total Train Time (s)         6627.6238136678
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:48:41.994328 UTC | [2020_01_10_08_58_14] Iteration #98 | Epoch Duration: 66.22923135757446
2020-01-10 10:48:41.994551 UTC | [2020_01_10_08_58_14] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3342595
Z variance train             0.011668137
KL Divergence                34.91645
KL Loss                      3.491645
QF Loss                      303.61203
VF Loss                      162.15973
Policy Loss                  -2131.2957
Q Predictions Mean           2126.4714
Q Predictions Std            707.97675
Q Predictions Max            2811.9155
Q Predictions Min            231.58313
V Predictions Mean           2130.1323
V Predictions Std            707.5923
V Predictions Max            2810.4895
V Predictions Min            234.35272
Log Pis Mean                 2.7856522
Log Pis Std                  4.364344
Log Pis Max                  17.886408
Log Pis Min                  -5.317835
Policy mu Mean               -0.040474024
Policy mu Std                1.215826
Policy mu Max                2.658367
Policy mu Min                -3.3443472
Policy log std Mean          -0.6594374
Policy log std Std           0.37341174
Policy log std Max           0.17936522
Policy log std Min           -2.344109
Z mean eval                  2.3298478
Z variance eval              0.010787776
total_rewards                [7074.13205852 7039.99109642 7265.00724911 7210.68375784 7237.66482456
 7045.02298083 7161.39078383 6873.56332308 7268.17927813 7025.23180343]
total_rewards_mean           7120.086715573258
total_rewards_std            122.72113524135558
total_rewards_max            7268.17927812641
total_rewards_min            6873.5633230764415
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               30.911553266923875
(Previous) Eval Time (s)     22.562415774911642
Sample Time (s)              15.870018503628671
Epoch Time (s)               69.34398754546419
Total Train Time (s)         6696.63690890139
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:49:51.009089 UTC | [2020_01_10_08_58_14] Iteration #99 | Epoch Duration: 69.01436591148376
2020-01-10 10:49:51.009283 UTC | [2020_01_10_08_58_14] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.330768
Z variance train             0.010813906
KL Divergence                34.650543
KL Loss                      3.4650543
QF Loss                      308.44296
VF Loss                      127.38273
Policy Loss                  -2061.5632
Q Predictions Mean           2058.5188
Q Predictions Std            767.7696
Q Predictions Max            2875.5315
Q Predictions Min            228.19478
V Predictions Mean           2060.1016
V Predictions Std            763.159
V Predictions Max            2865.2822
V Predictions Min            232.02577
Log Pis Mean                 3.4973357
Log Pis Std                  4.3110485
Log Pis Max                  13.9969635
Log Pis Min                  -5.79321
Policy mu Mean               -0.015642894
Policy mu Std                1.2712111
Policy mu Max                3.4691954
Policy mu Min                -2.9132838
Policy log std Mean          -0.65924007
Policy log std Std           0.36408722
Policy log std Max           0.14273372
Policy log std Min           -2.5329568
Z mean eval                  2.3349972
Z variance eval              0.011146419
total_rewards                [6889.49870887 7107.49525527 6947.54460673 7152.31806909 6996.19306089
 6940.21438201 7026.33898604 7180.09212429 4130.10181477 7229.54133163]
total_rewards_mean           6759.93383395837
total_rewards_std            883.126323452716
total_rewards_max            7229.5413316270015
total_rewards_min            4130.101814771208
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               27.696486365050077
(Previous) Eval Time (s)     22.232533977832645
Sample Time (s)              15.961403138469905
Epoch Time (s)               65.89042348135263
Total Train Time (s)         6763.040227197111
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:50:57.414616 UTC | [2020_01_10_08_58_14] Iteration #100 | Epoch Duration: 66.4051764011383
2020-01-10 10:50:57.414830 UTC | [2020_01_10_08_58_14] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.331606
Z variance train             0.010959188
KL Divergence                34.29002
KL Loss                      3.429002
QF Loss                      699.80066
VF Loss                      354.85928
Policy Loss                  -2085.1184
Q Predictions Mean           2081.5415
Q Predictions Std            736.65625
Q Predictions Max            2841.086
Q Predictions Min            218.89525
V Predictions Mean           2097.0894
V Predictions Std            734.36676
V Predictions Max            2847.0176
V Predictions Min            221.85793
Log Pis Mean                 2.889368
Log Pis Std                  4.6971364
Log Pis Max                  17.019436
Log Pis Min                  -7.4576607
Policy mu Mean               -0.06847765
Policy mu Std                1.2579436
Policy mu Max                3.1290913
Policy mu Min                -3.1521661
Policy log std Mean          -0.65477246
Policy log std Std           0.35622856
Policy log std Max           0.17436913
Policy log std Min           -2.5862544
Z mean eval                  2.3317902
Z variance eval              0.013180355
total_rewards                [7078.0975111  7147.91974532 6801.67680392 7089.64949673 7087.03983843
 6822.52336646 7088.98506097 6942.67961388 7163.09509162 6739.08849142]
total_rewards_mean           6996.075501986442
total_rewards_std            148.37360233689265
total_rewards_max            7163.095091624284
total_rewards_min            6739.088491419161
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               29.425697006750852
(Previous) Eval Time (s)     22.747029618360102
Sample Time (s)              16.858961990568787
Epoch Time (s)               69.03168861567974
Total Train Time (s)         6832.040315801278
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:52:06.419290 UTC | [2020_01_10_08_58_14] Iteration #101 | Epoch Duration: 69.0042655467987
2020-01-10 10:52:06.419566 UTC | [2020_01_10_08_58_14] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3325577
Z variance train             0.013248822
KL Divergence                32.469296
KL Loss                      3.2469296
QF Loss                      281.88986
VF Loss                      103.47418
Policy Loss                  -2113.7612
Q Predictions Mean           2107.8801
Q Predictions Std            753.26355
Q Predictions Max            2943.1997
Q Predictions Min            220.86443
V Predictions Mean           2112.758
V Predictions Std            748.1441
V Predictions Max            2937.5212
V Predictions Min            226.79747
Log Pis Mean                 3.2671578
Log Pis Std                  4.3937697
Log Pis Max                  14.5894785
Log Pis Min                  -6.133767
Policy mu Mean               -0.030618003
Policy mu Std                1.224073
Policy mu Max                3.172194
Policy mu Min                -2.9219878
Policy log std Mean          -0.6672518
Policy log std Std           0.37956637
Policy log std Max           0.113428146
Policy log std Min           -2.4584846
Z mean eval                  2.3343225
Z variance eval              0.013459308
total_rewards                [6937.20753533 7098.87907065 7184.23011452 7055.35683983 7279.54565774
 7089.89263554 7127.92377074 7165.44299255 7343.11449673 7368.68624004]
total_rewards_mean           7165.02793536604
total_rewards_std            127.28013261268799
total_rewards_max            7368.68624003887
total_rewards_min            6937.207535332239
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               30.283712124917656
(Previous) Eval Time (s)     22.719303658697754
Sample Time (s)              16.641201872378588
Epoch Time (s)               69.644217655994
Total Train Time (s)         6901.494770905003
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:53:15.873948 UTC | [2020_01_10_08_58_14] Iteration #102 | Epoch Duration: 69.45415306091309
2020-01-10 10:53:15.874238 UTC | [2020_01_10_08_58_14] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3350894
Z variance train             0.013533577
KL Divergence                32.91461
KL Loss                      3.2914612
QF Loss                      305.30212
VF Loss                      165.98178
Policy Loss                  -2153.6453
Q Predictions Mean           2148.7722
Q Predictions Std            688.4134
Q Predictions Max            2924.12
Q Predictions Min            217.30385
V Predictions Mean           2146.2861
V Predictions Std            685.7637
V Predictions Max            2898.728
V Predictions Min            222.65807
Log Pis Mean                 3.4747667
Log Pis Std                  4.3106446
Log Pis Max                  15.109179
Log Pis Min                  -6.430733
Policy mu Mean               -0.0505476
Policy mu Std                1.260068
Policy mu Max                2.6280117
Policy mu Min                -2.9210484
Policy log std Mean          -0.6719777
Policy log std Std           0.3582389
Policy log std Max           0.14950058
Policy log std Min           -2.3303466
Z mean eval                  2.3336647
Z variance eval              0.02404447
total_rewards                [6957.00809055 7251.74223727 7315.62590133 7018.51990375 7107.31260898
 6911.72907884 7095.25993176 7064.91151245 7224.00061146 7101.65514977]
total_rewards_mean           7104.776502615756
total_rewards_std            121.86457801719772
total_rewards_max            7315.6259013328245
total_rewards_min            6911.729078835674
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               29.41310025099665
(Previous) Eval Time (s)     22.528889825101942
Sample Time (s)              16.64951252192259
Epoch Time (s)               68.59150259802118
Total Train Time (s)         6969.350243696477
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:54:23.731064 UTC | [2020_01_10_08_58_14] Iteration #103 | Epoch Duration: 67.85661745071411
2020-01-10 10:54:23.731278 UTC | [2020_01_10_08_58_14] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3332942
Z variance train             0.023995472
KL Divergence                32.325935
KL Loss                      3.2325935
QF Loss                      481.1673
VF Loss                      308.13385
Policy Loss                  -2086.7224
Q Predictions Mean           2078.4885
Q Predictions Std            730.8697
Q Predictions Max            2836.8066
Q Predictions Min            208.01523
V Predictions Mean           2087.898
V Predictions Std            723.08984
V Predictions Max            2852.3372
V Predictions Min            209.68587
Log Pis Mean                 2.782857
Log Pis Std                  4.036821
Log Pis Max                  12.1361885
Log Pis Min                  -5.0195613
Policy mu Mean               -0.05054913
Policy mu Std                1.225755
Policy mu Max                2.7345693
Policy mu Min                -2.8456032
Policy log std Mean          -0.64449596
Policy log std Std           0.34197828
Policy log std Max           0.14203957
Policy log std Min           -2.1853962
Z mean eval                  2.327583
Z variance eval              0.02192826
total_rewards                [6971.82735755 7037.64346877 6994.76732151 6934.88939036 7057.84769525
 6795.39204267 7086.21620907 7035.90277785 6946.89917687 6858.51735863]
total_rewards_mean           6971.990279852644
total_rewards_std            86.8343872827785
total_rewards_max            7086.216209072986
total_rewards_min            6795.392042668226
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               26.905497601255774
(Previous) Eval Time (s)     21.7937268470414
Sample Time (s)              16.279374286532402
Epoch Time (s)               64.97859873482957
Total Train Time (s)         7034.795385220554
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:55:29.177147 UTC | [2020_01_10_08_58_14] Iteration #104 | Epoch Duration: 65.44572114944458
2020-01-10 10:55:29.177301 UTC | [2020_01_10_08_58_14] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.329514
Z variance train             0.021944977
KL Divergence                31.223896
KL Loss                      3.1223896
QF Loss                      248.09377
VF Loss                      164.52576
Policy Loss                  -2201.8923
Q Predictions Mean           2198.3162
Q Predictions Std            722.821
Q Predictions Max            2900.6892
Q Predictions Min            216.12198
V Predictions Mean           2195.5266
V Predictions Std            718.52606
V Predictions Max            2898.8071
V Predictions Min            219.7099
Log Pis Mean                 3.27127
Log Pis Std                  4.493578
Log Pis Max                  13.639198
Log Pis Min                  -6.23918
Policy mu Mean               -0.091941334
Policy mu Std                1.2388061
Policy mu Max                2.5175922
Policy mu Min                -3.3004088
Policy log std Mean          -0.6580606
Policy log std Std           0.36535713
Policy log std Max           0.2300987
Policy log std Min           -2.5016215
Z mean eval                  2.322956
Z variance eval              0.021592116
total_rewards                [6918.72535481 6995.45597008 6942.39188312 6980.11555758 6849.33115249
 6903.66469247 6957.22453668 7030.79802878 7062.3940172  6932.4678405 ]
total_rewards_mean           6957.256903371987
total_rewards_std            59.40036794383811
total_rewards_max            7062.394017196861
total_rewards_min            6849.3311524913925
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               28.697584526147693
(Previous) Eval Time (s)     22.260549413971603
Sample Time (s)              16.414800690021366
Epoch Time (s)               67.37293463014066
Total Train Time (s)         7102.002445465419
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:56:36.386741 UTC | [2020_01_10_08_58_14] Iteration #105 | Epoch Duration: 67.2092866897583
2020-01-10 10:56:36.387022 UTC | [2020_01_10_08_58_14] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3187466
Z variance train             0.021516394
KL Divergence                30.978954
KL Loss                      3.0978954
QF Loss                      348.80637
VF Loss                      206.79105
Policy Loss                  -2079.6848
Q Predictions Mean           2075.1008
Q Predictions Std            781.3211
Q Predictions Max            2855.8076
Q Predictions Min            199.18327
V Predictions Mean           2086.626
V Predictions Std            781.0145
V Predictions Max            2850.0361
V Predictions Min            208.64111
Log Pis Mean                 3.0218005
Log Pis Std                  4.6353455
Log Pis Max                  15.347176
Log Pis Min                  -8.802137
Policy mu Mean               -0.0396926
Policy mu Std                1.234759
Policy mu Max                3.285968
Policy mu Min                -3.0901208
Policy log std Mean          -0.64096504
Policy log std Std           0.35455093
Policy log std Max           0.26583883
Policy log std Min           -2.2661169
Z mean eval                  2.3178225
Z variance eval              0.013793483
total_rewards                [6868.1195253  6876.39893048 6815.35431656 6924.5008174  6924.38378222
 6766.65823815 6698.20001091 6850.36149207 6926.77307011 5173.69391924]
total_rewards_mean           6682.444410243859
total_rewards_std            507.7839603324988
total_rewards_max            6926.773070112471
total_rewards_min            5173.693919235204
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               30.033800702076405
(Previous) Eval Time (s)     22.09660766227171
Sample Time (s)              15.845339018851519
Epoch Time (s)               67.97574738319963
Total Train Time (s)         7170.056768653914
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:57:44.444010 UTC | [2020_01_10_08_58_14] Iteration #106 | Epoch Duration: 68.05640172958374
2020-01-10 10:57:44.444297 UTC | [2020_01_10_08_58_14] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3154864
Z variance train             0.013779822
KL Divergence                31.825708
KL Loss                      3.182571
QF Loss                      602.6083
VF Loss                      294.78967
Policy Loss                  -2153.9011
Q Predictions Mean           2139.9878
Q Predictions Std            760.63855
Q Predictions Max            2892.9185
Q Predictions Min            208.77313
V Predictions Mean           2142.6245
V Predictions Std            751.7154
V Predictions Max            2884.1428
V Predictions Min            215.73663
Log Pis Mean                 3.5215907
Log Pis Std                  4.767141
Log Pis Max                  18.874592
Log Pis Min                  -5.800565
Policy mu Mean               -0.040295646
Policy mu Std                1.3137413
Policy mu Max                3.4793572
Policy mu Min                -3.460413
Policy log std Mean          -0.6499879
Policy log std Std           0.35436243
Policy log std Max           0.12534145
Policy log std Min           -2.4254582
Z mean eval                  2.3115902
Z variance eval              0.037403353
total_rewards                [6996.99498977 7227.78962646 7219.47602327 7199.08960968 7321.62253219
 7267.62898626 7142.66657801 7295.24482742 7365.99074278 7013.63786701]
total_rewards_mean           7205.0141782835535
total_rewards_std            116.67056690367947
total_rewards_max            7365.990742775984
total_rewards_min            6996.994989771264
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               28.72118192212656
(Previous) Eval Time (s)     22.176978114061058
Sample Time (s)              15.466126395389438
Epoch Time (s)               66.36428643157706
Total Train Time (s)         7236.640708129853
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 10:58:51.031245 UTC | [2020_01_10_08_58_14] Iteration #107 | Epoch Duration: 66.58660554885864
2020-01-10 10:58:51.031646 UTC | [2020_01_10_08_58_14] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3121006
Z variance train             0.037450112
KL Divergence                29.956432
KL Loss                      2.9956434
QF Loss                      280.98944
VF Loss                      189.106
Policy Loss                  -2280.1711
Q Predictions Mean           2273.9038
Q Predictions Std            853.8097
Q Predictions Max            3105.3513
Q Predictions Min            240.28448
V Predictions Mean           2274.0894
V Predictions Std            849.4556
V Predictions Max            3093.067
V Predictions Min            239.1613
Log Pis Mean                 3.3482842
Log Pis Std                  4.7041516
Log Pis Max                  14.824354
Log Pis Min                  -6.9977245
Policy mu Mean               -0.03482197
Policy mu Std                1.2974721
Policy mu Max                4.2874737
Policy mu Min                -3.227198
Policy log std Mean          -0.6560076
Policy log std Std           0.38133645
Policy log std Max           0.052164376
Policy log std Min           -2.6691585
Z mean eval                  2.295034
Z variance eval              0.115174875
total_rewards                [6840.60343498 6710.35893555 6961.65590601 7037.42873424 6990.28473608
 6970.00554801 6936.57611709 6960.12191063 7005.69151923 6898.75091153]
total_rewards_mean           6931.147775335065
total_rewards_std            90.36303346777434
total_rewards_max            7037.428734235286
total_rewards_min            6710.358935554967
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               30.33799640694633
(Previous) Eval Time (s)     22.39904228411615
Sample Time (s)              16.348140727262944
Epoch Time (s)               69.08517941832542
Total Train Time (s)         7306.558449430391
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:00:00.949961 UTC | [2020_01_10_08_58_14] Iteration #108 | Epoch Duration: 69.91807222366333
2020-01-10 11:00:00.950158 UTC | [2020_01_10_08_58_14] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.2950568
Z variance train             0.11514411
KL Divergence                27.283596
KL Loss                      2.7283597
QF Loss                      711.2904
VF Loss                      154.05125
Policy Loss                  -2054.0796
Q Predictions Mean           2055.8503
Q Predictions Std            776.5325
Q Predictions Max            2869.8555
Q Predictions Min            180.2066
V Predictions Mean           2056.8694
V Predictions Std            772.2907
V Predictions Max            2843.8745
V Predictions Min            203.70425
Log Pis Mean                 3.022589
Log Pis Std                  4.5249233
Log Pis Max                  14.6075325
Log Pis Min                  -6.1948376
Policy mu Mean               -0.07526959
Policy mu Std                1.2329688
Policy mu Max                2.9656506
Policy mu Min                -3.2944188
Policy log std Mean          -0.64443845
Policy log std Std           0.34956658
Policy log std Max           0.1042254
Policy log std Min           -2.3188713
Z mean eval                  2.3420897
Z variance eval              0.04318573
total_rewards                [7178.90958979 7540.81352048 7542.43476775 7393.08950173 7532.46314069
 7557.62780673 7588.80799202 7602.50014826 7128.59967956 7226.25318236]
total_rewards_mean           7429.149932936077
total_rewards_std            174.19572806332798
total_rewards_max            7602.50014825813
total_rewards_min            7128.599679555105
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               28.0436271969229
(Previous) Eval Time (s)     23.23164183087647
Sample Time (s)              16.579781553708017
Epoch Time (s)               67.85505058150738
Total Train Time (s)         7374.640542265028
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:01:09.034917 UTC | [2020_01_10_08_58_14] Iteration #109 | Epoch Duration: 68.08457970619202
2020-01-10 11:01:09.035192 UTC | [2020_01_10_08_58_14] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3421593
Z variance train             0.043175098
KL Divergence                29.394424
KL Loss                      2.9394424
QF Loss                      345.02032
VF Loss                      156.76637
Policy Loss                  -2250.8801
Q Predictions Mean           2244.0337
Q Predictions Std            789.9138
Q Predictions Max            3027.0369
Q Predictions Min            220.11238
V Predictions Mean           2250.3818
V Predictions Std            780.2624
V Predictions Max            3022.541
V Predictions Min            223.69945
Log Pis Mean                 3.4342723
Log Pis Std                  4.5538626
Log Pis Max                  15.118064
Log Pis Min                  -6.125473
Policy mu Mean               -0.06795976
Policy mu Std                1.2777706
Policy mu Max                3.5449092
Policy mu Min                -3.078361
Policy log std Mean          -0.6553419
Policy log std Std           0.36176237
Policy log std Max           0.16060126
Policy log std Min           -2.4969227
Z mean eval                  2.3700569
Z variance eval              0.026535552
total_rewards                [6993.75293171 7166.4957608  7282.2852687  7286.06844101 7467.33010638
 7310.10645928 7105.23516339 7134.98782906 7194.44370562 7155.37577919]
total_rewards_mean           7209.608144513439
total_rewards_std            124.7933624305068
total_rewards_max            7467.330106379938
total_rewards_min            6993.752931707964
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               30.222231943160295
(Previous) Eval Time (s)     23.460897725075483
Sample Time (s)              16.294687174260616
Epoch Time (s)               69.9778168424964
Total Train Time (s)         7444.103475462645
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:02:18.501932 UTC | [2020_01_10_08_58_14] Iteration #110 | Epoch Duration: 69.46639227867126
2020-01-10 11:02:18.502363 UTC | [2020_01_10_08_58_14] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.369689
Z variance train             0.02644842
KL Divergence                30.959589
KL Loss                      3.095959
QF Loss                      355.05817
VF Loss                      149.56458
Policy Loss                  -2106.8635
Q Predictions Mean           2111.9893
Q Predictions Std            825.0288
Q Predictions Max            2989.1467
Q Predictions Min            201.57524
V Predictions Mean           2106.9285
V Predictions Std            818.7157
V Predictions Max            2977.8767
V Predictions Min            210.04744
Log Pis Mean                 2.8759608
Log Pis Std                  4.3687205
Log Pis Max                  14.617677
Log Pis Min                  -6.709334
Policy mu Mean               0.006489443
Policy mu Std                1.2366906
Policy mu Max                2.7031224
Policy mu Min                -2.8608544
Policy log std Mean          -0.6204379
Policy log std Std           0.35072863
Policy log std Max           0.15422437
Policy log std Min           -2.3347247
Z mean eval                  2.3547473
Z variance eval              0.025210794
total_rewards                [7150.60705553 7297.36815641 7275.16717215 7278.19549915 7130.95879754
 7131.78236944 6985.68156585 7180.61990337 7256.27393707 7365.82558788]
total_rewards_mean           7205.2480044384865
total_rewards_std            104.78675436547098
total_rewards_max            7365.8255878837845
total_rewards_min            6985.681565850855
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               27.97246651817113
(Previous) Eval Time (s)     22.949159814044833
Sample Time (s)              15.308092432562262
Epoch Time (s)               66.22971876477823
Total Train Time (s)         7510.558310181834
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:03:24.956594 UTC | [2020_01_10_08_58_14] Iteration #111 | Epoch Duration: 66.45400857925415
2020-01-10 11:03:24.956763 UTC | [2020_01_10_08_58_14] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3546443
Z variance train             0.02524069
KL Divergence                31.363058
KL Loss                      3.1363058
QF Loss                      353.76355
VF Loss                      217.10947
Policy Loss                  -2365.4006
Q Predictions Mean           2359.0298
Q Predictions Std            750.693
Q Predictions Max            3104.2168
Q Predictions Min            227.61765
V Predictions Mean           2365.6174
V Predictions Std            746.74634
V Predictions Max            3103.2053
V Predictions Min            226.05336
Log Pis Mean                 3.8465362
Log Pis Std                  4.821111
Log Pis Max                  18.50194
Log Pis Min                  -10.152378
Policy mu Mean               -0.09242582
Policy mu Std                1.3069272
Policy mu Max                2.8958585
Policy mu Min                -3.206314
Policy log std Mean          -0.6461256
Policy log std Std           0.34111705
Policy log std Max           -0.014371663
Policy log std Min           -2.2064633
Z mean eval                  2.3711302
Z variance eval              0.01679557
total_rewards                [7105.66501898 7450.64279825 7138.11058326 7209.20628855 7382.90599297
 7216.31217353 7524.70944458 7446.1617895  7407.27051324 7205.4067871 ]
total_rewards_mean           7308.63913899599
total_rewards_std            141.54651874155286
total_rewards_max            7524.70944457827
total_rewards_min            7105.665018984013
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               30.05978924781084
(Previous) Eval Time (s)     23.17320442898199
Sample Time (s)              16.453939460683614
Epoch Time (s)               69.68693313747644
Total Train Time (s)         7579.301160784904
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:04:33.700535 UTC | [2020_01_10_08_58_14] Iteration #112 | Epoch Duration: 68.74364733695984
2020-01-10 11:04:33.700719 UTC | [2020_01_10_08_58_14] Iteration #112 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3680017
Z variance train             0.01678052
KL Divergence                32.48476
KL Loss                      3.248476
QF Loss                      315.62354
VF Loss                      259.06036
Policy Loss                  -2375.207
Q Predictions Mean           2374.0479
Q Predictions Std            736.304
Q Predictions Max            3045.2712
Q Predictions Min            223.21188
V Predictions Mean           2383.311
V Predictions Std            734.773
V Predictions Max            3029.3323
V Predictions Min            219.77843
Log Pis Mean                 3.7156749
Log Pis Std                  4.3641505
Log Pis Max                  18.359169
Log Pis Min                  -4.9608197
Policy mu Mean               -0.076375335
Policy mu Std                1.2957238
Policy mu Max                3.0565927
Policy mu Min                -3.4119034
Policy log std Mean          -0.65910447
Policy log std Std           0.3500844
Policy log std Max           0.11375803
Policy log std Min           -2.3385038
Z mean eval                  2.365444
Z variance eval              0.01664331
total_rewards                [6589.71637734 6850.41905875 7213.00452447 7025.63505568 6911.5259543
 6802.85939465 7283.65990205 7184.83176447 6850.9901919  7031.02693158]
total_rewards_mean           6974.366915519658
total_rewards_std            203.62932793636205
total_rewards_max            7283.6599020547055
total_rewards_min            6589.716377339568
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               28.377579510211945
(Previous) Eval Time (s)     22.229650133289397
Sample Time (s)              15.903596448712051
Epoch Time (s)               66.51082609221339
Total Train Time (s)         7647.168107330799
Epoch                        113
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:05:41.568916 UTC | [2020_01_10_08_58_14] Iteration #113 | Epoch Duration: 67.86807990074158
2020-01-10 11:05:41.569080 UTC | [2020_01_10_08_58_14] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3629441
Z variance train             0.016683122
KL Divergence                32.12697
KL Loss                      3.2126968
QF Loss                      464.54108
VF Loss                      146.14867
Policy Loss                  -2420.1323
Q Predictions Mean           2416.4934
Q Predictions Std            714.0043
Q Predictions Max            3070.536
Q Predictions Min            210.45836
V Predictions Mean           2425.2915
V Predictions Std            713.35645
V Predictions Max            3073.3406
V Predictions Min            220.3014
Log Pis Mean                 3.563927
Log Pis Std                  4.468678
Log Pis Max                  18.15915
Log Pis Min                  -6.386961
Policy mu Mean               -0.06032601
Policy mu Std                1.3181027
Policy mu Max                2.9007046
Policy mu Min                -2.809592
Policy log std Mean          -0.66053325
Policy log std Std           0.37235
Policy log std Max           0.04347396
Policy log std Min           -2.2511194
Z mean eval                  2.3753774
Z variance eval              0.016624201
total_rewards                [7344.68003575 7180.73561497 7346.16018035 7214.65849544 7154.46326913
 7433.58076825 7387.06681272 7357.03838761 7252.27175663 7405.45340312]
total_rewards_mean           7307.610872397403
total_rewards_std            93.97454690353653
total_rewards_max            7433.580768246616
total_rewards_min            7154.463269127769
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               25.874833528883755
(Previous) Eval Time (s)     23.58663692418486
Sample Time (s)              15.846685971133411
Epoch Time (s)               65.30815642420202
Total Train Time (s)         7711.593460796867
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:06:45.996955 UTC | [2020_01_10_08_58_14] Iteration #114 | Epoch Duration: 64.42773723602295
2020-01-10 11:06:45.997165 UTC | [2020_01_10_08_58_14] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3780515
Z variance train             0.016551185
KL Divergence                32.459
KL Loss                      3.2459
QF Loss                      299.2384
VF Loss                      210.49869
Policy Loss                  -2356.7253
Q Predictions Mean           2352.3276
Q Predictions Std            734.9349
Q Predictions Max            3021.2625
Q Predictions Min            178.20377
V Predictions Mean           2345.7583
V Predictions Std            728.7535
V Predictions Max            3016.3665
V Predictions Min            195.94112
Log Pis Mean                 3.480372
Log Pis Std                  4.654593
Log Pis Max                  16.128769
Log Pis Min                  -8.150468
Policy mu Mean               -0.07157307
Policy mu Std                1.276339
Policy mu Max                2.716411
Policy mu Min                -3.0691702
Policy log std Mean          -0.67604256
Policy log std Std           0.35993713
Policy log std Max           0.21904609
Policy log std Min           -2.459852
Z mean eval                  2.39167
Z variance eval              0.012519364
total_rewards                [7549.20961137 7366.28179927 7050.55255529 7563.05876062 7405.51302811
 7717.95404108 7384.48930472 7647.80447358 7165.69153054 7596.40760706]
total_rewards_mean           7444.696271163329
total_rewards_std            202.08259354391396
total_rewards_max            7717.9540410757845
total_rewards_min            7050.552555290814
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               28.04245232185349
(Previous) Eval Time (s)     22.70595230301842
Sample Time (s)              15.95788106508553
Epoch Time (s)               66.70628568995744
Total Train Time (s)         7778.493211681023
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:07:52.900141 UTC | [2020_01_10_08_58_14] Iteration #115 | Epoch Duration: 66.90270781517029
2020-01-10 11:07:52.900508 UTC | [2020_01_10_08_58_14] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3896117
Z variance train             0.012536159
KL Divergence                34.090614
KL Loss                      3.4090614
QF Loss                      531.31384
VF Loss                      321.5001
Policy Loss                  -2397.028
Q Predictions Mean           2399.6165
Q Predictions Std            641.5148
Q Predictions Max            3069.8389
Q Predictions Min            211.27766
V Predictions Mean           2406.8535
V Predictions Std            634.6091
V Predictions Max            3062.8174
V Predictions Min            211.7643
Log Pis Mean                 3.2851
Log Pis Std                  3.9199245
Log Pis Max                  13.680043
Log Pis Min                  -5.2993727
Policy mu Mean               -0.10149307
Policy mu Std                1.2757914
Policy mu Max                3.291796
Policy mu Min                -2.9478369
Policy log std Mean          -0.6534052
Policy log std Std           0.34907043
Policy log std Max           0.12952739
Policy log std Min           -2.4038439
Z mean eval                  2.3920317
Z variance eval              0.011426018
total_rewards                [7268.51220718 7608.71763371 7380.77624774 7475.10578744 7177.10426113
 7430.94644144 7492.59657659 7458.02724149 7510.13285548 7472.11981963]
total_rewards_mean           7427.403907181202
total_rewards_std            118.01049724028894
total_rewards_max            7608.717633713061
total_rewards_min            7177.10426112562
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               27.838759128935635
(Previous) Eval Time (s)     22.902090809307992
Sample Time (s)              17.362295484170318
Epoch Time (s)               68.10314542241395
Total Train Time (s)         7846.077057862654
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:09:00.486563 UTC | [2020_01_10_08_58_14] Iteration #116 | Epoch Duration: 67.5858302116394
2020-01-10 11:09:00.486846 UTC | [2020_01_10_08_58_14] Iteration #116 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.392573
Z variance train             0.011434401
KL Divergence                33.97615
KL Loss                      3.3976152
QF Loss                      285.20786
VF Loss                      150.70203
Policy Loss                  -2321.01
Q Predictions Mean           2313.7432
Q Predictions Std            782.5333
Q Predictions Max            3021.5955
Q Predictions Min            201.95825
V Predictions Mean           2318.2378
V Predictions Std            776.4454
V Predictions Max            3044.2922
V Predictions Min            210.91446
Log Pis Mean                 2.6026502
Log Pis Std                  4.2487917
Log Pis Max                  14.110975
Log Pis Min                  -5.338454
Policy mu Mean               -0.047953054
Policy mu Std                1.2339883
Policy mu Max                3.338352
Policy mu Min                -2.8237662
Policy log std Mean          -0.65082896
Policy log std Std           0.37573296
Policy log std Max           0.2565003
Policy log std Min           -2.53472
Z mean eval                  2.3669813
Z variance eval              0.010998194
total_rewards                [7516.51665132 7548.31942903 7497.85049098 7528.72642721 7170.3768703
 7507.98518513 7596.49726567 7248.35256396 3674.55488472 7103.25732469]
total_rewards_mean           7039.243709299507
total_rewards_std            1133.7222854993865
total_rewards_max            7596.49726566742
total_rewards_min            3674.554884722219
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               27.2873158804141
(Previous) Eval Time (s)     22.384507526177913
Sample Time (s)              16.07268913788721
Epoch Time (s)               65.74451254447922
Total Train Time (s)         7912.085247109178
Epoch                        117
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:10:06.495785 UTC | [2020_01_10_08_58_14] Iteration #117 | Epoch Duration: 66.00868368148804
2020-01-10 11:10:06.496015 UTC | [2020_01_10_08_58_14] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.367464
Z variance train             0.011007973
KL Divergence                33.8124
KL Loss                      3.3812401
QF Loss                      471.2071
VF Loss                      216.06639
Policy Loss                  -2356.3442
Q Predictions Mean           2355.8584
Q Predictions Std            709.4645
Q Predictions Max            3082.6526
Q Predictions Min            200.06447
V Predictions Mean           2354.0225
V Predictions Std            703.3398
V Predictions Max            3070.0232
V Predictions Min            203.71706
Log Pis Mean                 3.946211
Log Pis Std                  4.407213
Log Pis Max                  17.614904
Log Pis Min                  -6.1432433
Policy mu Mean               -0.033154324
Policy mu Std                1.3178419
Policy mu Max                3.0508192
Policy mu Min                -3.2838812
Policy log std Mean          -0.6651733
Policy log std Std           0.35171017
Policy log std Max           0.11731079
Policy log std Min           -2.5601053
Z mean eval                  2.3538423
Z variance eval              0.015144234
total_rewards                [7530.96609524 7532.66278472 7419.76674673 7564.71429209 7648.95306919
 7629.5229611  7397.97908999 7558.7815015  7400.35261225 7436.10446703]
total_rewards_mean           7511.980361984306
total_rewards_std            88.3486087317
total_rewards_max            7648.953069190739
total_rewards_min            7397.979089986153
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               27.32657361542806
(Previous) Eval Time (s)     22.648395816795528
Sample Time (s)              15.823290040716529
Epoch Time (s)               65.79825947294012
Total Train Time (s)         7978.4188815280795
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:11:12.832810 UTC | [2020_01_10_08_58_14] Iteration #118 | Epoch Duration: 66.33662295341492
2020-01-10 11:11:12.833088 UTC | [2020_01_10_08_58_14] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.354518
Z variance train             0.015164921
KL Divergence                32.79725
KL Loss                      3.2797248
QF Loss                      400.24326
VF Loss                      190.71928
Policy Loss                  -2332.7039
Q Predictions Mean           2322.5845
Q Predictions Std            689.406
Q Predictions Max            3042.0764
Q Predictions Min            201.06691
V Predictions Mean           2323.2405
V Predictions Std            686.9264
V Predictions Max            3025.8997
V Predictions Min            198.04625
Log Pis Mean                 3.2849374
Log Pis Std                  4.3765926
Log Pis Max                  14.262779
Log Pis Min                  -6.8674994
Policy mu Mean               -0.03931621
Policy mu Std                1.2937268
Policy mu Max                3.299911
Policy mu Min                -3.3288114
Policy log std Mean          -0.65894943
Policy log std Std           0.35235566
Policy log std Max           0.16289946
Policy log std Min           -2.3282318
Z mean eval                  2.3630393
Z variance eval              0.010303283
total_rewards                [7165.18783488 7640.34400653 7543.10018808 7352.62456106 7531.12038568
 7671.42434125 7601.17277431 7382.54998918 7325.48356573 7304.42825339]
total_rewards_mean           7451.743590008734
total_rewards_std            159.7421277015551
total_rewards_max            7671.424341248978
total_rewards_min            7165.187834882838
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               28.965525585692376
(Previous) Eval Time (s)     23.186472933273762
Sample Time (s)              16.999496333301067
Epoch Time (s)               69.1514948522672
Total Train Time (s)         8047.232555939816
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:12:21.649175 UTC | [2020_01_10_08_58_14] Iteration #119 | Epoch Duration: 68.81587171554565
2020-01-10 11:12:21.649450 UTC | [2020_01_10_08_58_14] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3630047
Z variance train             0.010318485
KL Divergence                33.937805
KL Loss                      3.3937805
QF Loss                      399.09674
VF Loss                      160.0117
Policy Loss                  -2344.3022
Q Predictions Mean           2342.358
Q Predictions Std            815.53766
Q Predictions Max            3121.568
Q Predictions Min            195.75145
V Predictions Mean           2346.023
V Predictions Std            814.3888
V Predictions Max            3112.2214
V Predictions Min            196.32318
Log Pis Mean                 3.239869
Log Pis Std                  4.354531
Log Pis Max                  13.709664
Log Pis Min                  -7.3668413
Policy mu Mean               -0.05634894
Policy mu Std                1.2590191
Policy mu Max                2.836591
Policy mu Min                -3.585264
Policy log std Mean          -0.64240366
Policy log std Std           0.34881023
Policy log std Max           0.01867053
Policy log std Min           -2.3541403
Z mean eval                  2.3570561
Z variance eval              0.009126529
total_rewards                [7130.72743976 7332.0239981  7134.89125777 7127.15276246 7567.35786611
 7103.50755414 7145.98109398 7282.39611052 7576.76810824 7422.49252337]
total_rewards_mean           7282.329871444408
total_rewards_std            175.9032973448434
total_rewards_max            7576.768108244945
total_rewards_min            7103.507554139001
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               28.967743250075728
(Previous) Eval Time (s)     22.850539625622332
Sample Time (s)              16.007727507967502
Epoch Time (s)               67.82601038366556
Total Train Time (s)         8115.0675767916255
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:13:29.484524 UTC | [2020_01_10_08_58_14] Iteration #120 | Epoch Duration: 67.83488774299622
2020-01-10 11:13:29.484690 UTC | [2020_01_10_08_58_14] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.359483
Z variance train             0.009114313
KL Divergence                34.558716
KL Loss                      3.4558716
QF Loss                      648.3947
VF Loss                      249.26721
Policy Loss                  -2302.397
Q Predictions Mean           2300.7578
Q Predictions Std            791.85645
Q Predictions Max            3092.814
Q Predictions Min            189.8064
V Predictions Mean           2293.7441
V Predictions Std            788.33057
V Predictions Max            3079.6252
V Predictions Min            200.1723
Log Pis Mean                 3.1822138
Log Pis Std                  4.338873
Log Pis Max                  18.03253
Log Pis Min                  -5.879836
Policy mu Mean               -0.0025328633
Policy mu Std                1.26691
Policy mu Max                3.0033224
Policy mu Min                -3.750629
Policy log std Mean          -0.6665788
Policy log std Std           0.36445314
Policy log std Max           0.14120382
Policy log std Min           -2.4158177
Z mean eval                  2.343955
Z variance eval              0.010731819
total_rewards                [7521.68538493 7317.46622255 7550.53760114 7255.21698675 7670.99745172
 7404.29670098 7795.76261542 7447.17719911 7549.57877495 7351.28032218]
total_rewards_mean           7486.399925970091
total_rewards_std            157.36982201487518
total_rewards_max            7795.762615417808
total_rewards_min            7255.216986746019
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               31.497700648382306
(Previous) Eval Time (s)     22.859132301062346
Sample Time (s)              15.832311158068478
Epoch Time (s)               70.18914410751313
Total Train Time (s)         8184.876846851781
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:14:39.298492 UTC | [2020_01_10_08_58_14] Iteration #121 | Epoch Duration: 69.81363892555237
2020-01-10 11:14:39.298805 UTC | [2020_01_10_08_58_14] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.343473
Z variance train             0.010743147
KL Divergence                33.473732
KL Loss                      3.3473732
QF Loss                      451.64905
VF Loss                      212.76779
Policy Loss                  -2333.8894
Q Predictions Mean           2329.0396
Q Predictions Std            784.893
Q Predictions Max            3063.518
Q Predictions Min            184.97562
V Predictions Mean           2337.6873
V Predictions Std            785.7874
V Predictions Max            3061.2449
V Predictions Min            195.64949
Log Pis Mean                 3.2980938
Log Pis Std                  4.50981
Log Pis Max                  15.276808
Log Pis Min                  -6.225539
Policy mu Mean               -0.09600975
Policy mu Std                1.2903593
Policy mu Max                3.2107592
Policy mu Min                -3.1065652
Policy log std Mean          -0.6611127
Policy log std Std           0.3549814
Policy log std Max           0.13070464
Policy log std Min           -2.4441965
Z mean eval                  2.3393185
Z variance eval              0.012120716
total_rewards                [7424.59161222 7665.80827929 7699.77716433 7420.95239713 7341.25501312
 7584.15069842 7241.35574234 7667.60430055 7527.36924209 7366.08941673]
total_rewards_mean           7493.895386622967
total_rewards_std            149.97202089186356
total_rewards_max            7699.777164333562
total_rewards_min            7241.355742337842
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               28.89450855087489
(Previous) Eval Time (s)     22.483338973019272
Sample Time (s)              16.07916634855792
Epoch Time (s)               67.45701387245208
Total Train Time (s)         8252.617708808277
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:15:47.039898 UTC | [2020_01_10_08_58_14] Iteration #122 | Epoch Duration: 67.74088263511658
2020-01-10 11:15:47.040077 UTC | [2020_01_10_08_58_14] Iteration #122 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.339787
Z variance train             0.012140095
KL Divergence                32.783173
KL Loss                      3.2783172
QF Loss                      646.1846
VF Loss                      567.73004
Policy Loss                  -2364.1074
Q Predictions Mean           2358.7974
Q Predictions Std            709.28546
Q Predictions Max            3092.936
Q Predictions Min            196.57605
V Predictions Mean           2363.4387
V Predictions Std            709.49664
V Predictions Max            3082.4954
V Predictions Min            194.0584
Log Pis Mean                 3.794732
Log Pis Std                  4.3207893
Log Pis Max                  14.666452
Log Pis Min                  -6.229109
Policy mu Mean               -0.04315898
Policy mu Std                1.3222631
Policy mu Max                3.0179513
Policy mu Min                -3.0896814
Policy log std Mean          -0.65716535
Policy log std Std           0.35184658
Policy log std Max           0.12971133
Policy log std Min           -2.472544
Z mean eval                  2.3481874
Z variance eval              0.007617797
total_rewards                [7574.88126442 7543.43852917 7387.19125513 7368.84651941 7546.8974423
 7459.7739142  7484.26772293 7423.59081229 7660.66432986 7489.8228264 ]
total_rewards_mean           7493.937461609751
total_rewards_std            85.3660310568464
total_rewards_max            7660.664329861735
total_rewards_min            7368.84651940808
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               27.639523120131344
(Previous) Eval Time (s)     22.766959961038083
Sample Time (s)              15.9618482561782
Epoch Time (s)               66.36833133734763
Total Train Time (s)         8318.474949718453
Epoch                        123
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:16:52.898569 UTC | [2020_01_10_08_58_14] Iteration #123 | Epoch Duration: 65.85833311080933
2020-01-10 11:16:52.898748 UTC | [2020_01_10_08_58_14] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3463082
Z variance train             0.007622124
KL Divergence                34.079784
KL Loss                      3.4079785
QF Loss                      319.52814
VF Loss                      153.54271
Policy Loss                  -2390.5935
Q Predictions Mean           2388.0325
Q Predictions Std            711.6852
Q Predictions Max            3117.2498
Q Predictions Min            181.11531
V Predictions Mean           2386.7615
V Predictions Std            710.77637
V Predictions Max            3120.8767
V Predictions Min            180.75179
Log Pis Mean                 3.277217
Log Pis Std                  4.0813036
Log Pis Max                  12.963061
Log Pis Min                  -8.060282
Policy mu Mean               -0.058349773
Policy mu Std                1.258294
Policy mu Max                2.6222234
Policy mu Min                -2.8260937
Policy log std Mean          -0.68012667
Policy log std Std           0.37500218
Policy log std Max           0.15774402
Policy log std Min           -2.466742
Z mean eval                  2.3648384
Z variance eval              0.012412925
total_rewards                [7471.66214497 7506.7967357  7879.29358838 7625.08155652 7491.36361576
 7309.64428168 7182.60337455 7416.2808497  7746.74056288 7364.94872853]
total_rewards_mean           7499.441543868675
total_rewards_std            195.84031372035696
total_rewards_max            7879.293588383395
total_rewards_min            7182.603374550495
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               28.146666147746146
(Previous) Eval Time (s)     22.256681436207145
Sample Time (s)              15.2283754972741
Epoch Time (s)               65.63172308122739
Total Train Time (s)         8384.317477057688
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:17:58.742483 UTC | [2020_01_10_08_58_14] Iteration #124 | Epoch Duration: 65.84361624717712
2020-01-10 11:17:58.742632 UTC | [2020_01_10_08_58_14] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3652873
Z variance train             0.01244211
KL Divergence                33.937546
KL Loss                      3.3937547
QF Loss                      353.71655
VF Loss                      167.5745
Policy Loss                  -2408.0803
Q Predictions Mean           2408.6074
Q Predictions Std            802.88855
Q Predictions Max            3128.3142
Q Predictions Min            174.59831
V Predictions Mean           2413.0635
V Predictions Std            796.50494
V Predictions Max            3124.137
V Predictions Min            194.25012
Log Pis Mean                 3.928545
Log Pis Std                  4.266259
Log Pis Max                  14.674685
Log Pis Min                  -7.8820043
Policy mu Mean               -0.055866122
Policy mu Std                1.3071839
Policy mu Max                2.7847345
Policy mu Min                -2.8376796
Policy log std Mean          -0.6724696
Policy log std Std           0.3630183
Policy log std Max           0.09437382
Policy log std Min           -2.4889913
Z mean eval                  2.3442507
Z variance eval              0.010257854
total_rewards                [7719.29780786 7377.17235474 7092.71917612 7793.75550748 7548.57129148
 7193.22177737 7511.79377627 7635.34035237 7393.71146929 7185.42618434]
total_rewards_mean           7445.100969730733
total_rewards_std            225.91838814933664
total_rewards_max            7793.755507476389
total_rewards_min            7092.719176117313
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               27.609023766126484
(Previous) Eval Time (s)     22.468326895032078
Sample Time (s)              15.741448033135384
Epoch Time (s)               65.81879869429395
Total Train Time (s)         8450.475417025853
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:19:04.903433 UTC | [2020_01_10_08_58_14] Iteration #125 | Epoch Duration: 66.16067171096802
2020-01-10 11:19:04.903634 UTC | [2020_01_10_08_58_14] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3435705
Z variance train             0.010294436
KL Divergence                33.368248
KL Loss                      3.336825
QF Loss                      281.08423
VF Loss                      91.24039
Policy Loss                  -2358.0022
Q Predictions Mean           2358.011
Q Predictions Std            756.46106
Q Predictions Max            3138.1348
Q Predictions Min            187.30635
V Predictions Mean           2358.3145
V Predictions Std            753.5956
V Predictions Max            3111.8057
V Predictions Min            187.5176
Log Pis Mean                 3.918003
Log Pis Std                  4.4549084
Log Pis Max                  16.080227
Log Pis Min                  -7.0900416
Policy mu Mean               -0.058707017
Policy mu Std                1.2996475
Policy mu Max                2.9027357
Policy mu Min                -2.9474933
Policy log std Mean          -0.6805833
Policy log std Std           0.36324218
Policy log std Max           0.19933224
Policy log std Min           -2.5039115
Z mean eval                  2.34427
Z variance eval              0.009899529
total_rewards                [7452.83003206 7664.38973079 7886.047616   7682.50443268 7785.63618203
 7445.4906748  7648.25774295 7762.95019796 7081.95302846 7873.87494717]
total_rewards_mean           7628.393458489363
total_rewards_std            231.72592084288726
total_rewards_max            7886.047616000501
total_rewards_min            7081.953028462832
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               25.85311547992751
(Previous) Eval Time (s)     22.80993939982727
Sample Time (s)              16.752909497357905
Epoch Time (s)               65.41596437711269
Total Train Time (s)         8515.148918645456
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:20:09.577793 UTC | [2020_01_10_08_58_14] Iteration #126 | Epoch Duration: 64.67401695251465
2020-01-10 11:20:09.577946 UTC | [2020_01_10_08_58_14] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3443856
Z variance train             0.009899594
KL Divergence                33.11109
KL Loss                      3.3111093
QF Loss                      484.74506
VF Loss                      173.27582
Policy Loss                  -2461.6943
Q Predictions Mean           2456.0486
Q Predictions Std            734.421
Q Predictions Max            3185.657
Q Predictions Min            187.77428
V Predictions Mean           2459.5413
V Predictions Std            728.0429
V Predictions Max            3170.9158
V Predictions Min            186.66716
Log Pis Mean                 3.8604465
Log Pis Std                  4.1732054
Log Pis Max                  14.227401
Log Pis Min                  -5.312501
Policy mu Mean               -0.16067936
Policy mu Std                1.3076199
Policy mu Max                2.7751288
Policy mu Min                -3.3358195
Policy log std Mean          -0.6943204
Policy log std Std           0.3606206
Policy log std Max           -0.00073719025
Policy log std Min           -2.2815857
Z mean eval                  2.3542314
Z variance eval              0.012394065
total_rewards                [7491.76513324 7471.0190132  7641.28638425 7265.78759742 7692.28902545
 7820.52003842 7685.84469194 7543.45396403 7547.78854749 7671.52143797]
total_rewards_mean           7583.1275833401105
total_rewards_std            146.44489107077237
total_rewards_max            7820.520038420562
total_rewards_min            7265.787597416109
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               28.063644093926996
(Previous) Eval Time (s)     22.06771785300225
Sample Time (s)              16.14999813074246
Epoch Time (s)               66.2813600776717
Total Train Time (s)         8582.123396792915
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:21:16.555564 UTC | [2020_01_10_08_58_14] Iteration #127 | Epoch Duration: 66.97746992111206
2020-01-10 11:21:16.555793 UTC | [2020_01_10_08_58_14] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3547618
Z variance train             0.012404884
KL Divergence                32.613228
KL Loss                      3.2613227
QF Loss                      618.3461
VF Loss                      169.1536
Policy Loss                  -2386.423
Q Predictions Mean           2379.02
Q Predictions Std            780.4323
Q Predictions Max            3156.2144
Q Predictions Min            166.82498
V Predictions Mean           2382.0942
V Predictions Std            777.43317
V Predictions Max            3126.7854
V Predictions Min            174.99553
Log Pis Mean                 3.4843845
Log Pis Std                  4.479846
Log Pis Max                  16.748047
Log Pis Min                  -9.899748
Policy mu Mean               -0.01041909
Policy mu Std                1.2847981
Policy mu Max                2.7212362
Policy mu Min                -3.5664043
Policy log std Mean          -0.6876145
Policy log std Std           0.39339042
Policy log std Max           0.15832627
Policy log std Min           -2.3916905
Z mean eval                  2.358971
Z variance eval              0.015501578
total_rewards                [7177.13171496 7409.0473915  7300.03575369 7306.05560296 7793.66021066
 7520.79238179 7293.91840965 7654.59484271 7434.34272718 7637.98728089]
total_rewards_mean           7452.756631599606
total_rewards_std            185.52257915012422
total_rewards_max            7793.660210656925
total_rewards_min            7177.131714957899
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               25.89342888398096
(Previous) Eval Time (s)     22.763562853913754
Sample Time (s)              16.143529346678406
Epoch Time (s)               64.80052108457312
Total Train Time (s)         8646.566978938878
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:22:21.002332 UTC | [2020_01_10_08_58_14] Iteration #128 | Epoch Duration: 64.44632649421692
2020-01-10 11:22:21.002580 UTC | [2020_01_10_08_58_14] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3571491
Z variance train             0.015515393
KL Divergence                32.193634
KL Loss                      3.2193635
QF Loss                      397.3767
VF Loss                      125.55012
Policy Loss                  -2321.8435
Q Predictions Mean           2313.5388
Q Predictions Std            861.8233
Q Predictions Max            3192.5059
Q Predictions Min            168.21448
V Predictions Mean           2320.1362
V Predictions Std            856.58105
V Predictions Max            3196.65
V Predictions Min            183.21336
Log Pis Mean                 3.8313932
Log Pis Std                  4.9230847
Log Pis Max                  17.812954
Log Pis Min                  -9.599682
Policy mu Mean               -0.07419351
Policy mu Std                1.3144047
Policy mu Max                2.936073
Policy mu Min                -3.5444946
Policy log std Mean          -0.65838677
Policy log std Std           0.36801952
Policy log std Max           0.07161534
Policy log std Min           -2.4673104
Z mean eval                  2.353791
Z variance eval              0.013505203
total_rewards                [7246.87722736 7331.63922725 7578.4153387  7679.50355081 7457.13716638
 7394.23051497 7619.00415597 7660.60633129 7307.08807471 7560.42571432]
total_rewards_mean           7483.492730175871
total_rewards_std            148.96615235808588
total_rewards_max            7679.5035508089995
total_rewards_min            7246.877227359766
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               28.17355337087065
(Previous) Eval Time (s)     22.409091120120138
Sample Time (s)              16.105473512783647
Epoch Time (s)               66.68811800377443
Total Train Time (s)         8713.17276211502
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:23:27.610914 UTC | [2020_01_10_08_58_14] Iteration #129 | Epoch Duration: 66.60804629325867
2020-01-10 11:23:27.611276 UTC | [2020_01_10_08_58_14] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3540885
Z variance train             0.013514182
KL Divergence                32.734688
KL Loss                      3.2734687
QF Loss                      276.87854
VF Loss                      170.64473
Policy Loss                  -2531.6091
Q Predictions Mean           2531.825
Q Predictions Std            677.9164
Q Predictions Max            3194.4568
Q Predictions Min            193.44968
V Predictions Mean           2531.704
V Predictions Std            675.88477
V Predictions Max            3197.447
V Predictions Min            186.28203
Log Pis Mean                 3.097585
Log Pis Std                  4.3524327
Log Pis Max                  15.439422
Log Pis Min                  -5.652442
Policy mu Mean               -0.074032955
Policy mu Std                1.2576393
Policy mu Max                3.2190738
Policy mu Min                -3.3880515
Policy log std Mean          -0.6747287
Policy log std Std           0.37556684
Policy log std Max           0.059528828
Policy log std Min           -2.54696
Z mean eval                  2.331602
Z variance eval              0.018674724
total_rewards                [7476.22708549 7402.1430379  7771.12227034 7731.53095191 7687.92788086
 7624.53537387 7534.52923984 7606.29513023 7596.86707026 7471.94833038]
total_rewards_mean           7590.312637108259
total_rewards_std            113.65662135596472
total_rewards_max            7771.122270339034
total_rewards_min            7402.143037901008
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               27.620631045196205
(Previous) Eval Time (s)     22.328761818818748
Sample Time (s)              17.020311717875302
Epoch Time (s)               66.96970458189026
Total Train Time (s)         8780.293371790554
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:24:34.732777 UTC | [2020_01_10_08_58_14] Iteration #130 | Epoch Duration: 67.12130308151245
2020-01-10 11:24:34.732945 UTC | [2020_01_10_08_58_14] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.33348
Z variance train             0.018823361
KL Divergence                32.22466
KL Loss                      3.222466
QF Loss                      390.97006
VF Loss                      232.11942
Policy Loss                  -2395.4917
Q Predictions Mean           2395.739
Q Predictions Std            736.4679
Q Predictions Max            3183.2578
Q Predictions Min            184.59978
V Predictions Mean           2399.85
V Predictions Std            734.8948
V Predictions Max            3164.6038
V Predictions Min            174.26376
Log Pis Mean                 3.4749577
Log Pis Std                  4.1786814
Log Pis Max                  13.635954
Log Pis Min                  -5.5893106
Policy mu Mean               -0.030426815
Policy mu Std                1.2853616
Policy mu Max                2.9050958
Policy mu Min                -2.8493629
Policy log std Mean          -0.6735003
Policy log std Std           0.35528228
Policy log std Max           0.124537945
Policy log std Min           -2.391005
Z mean eval                  2.3519542
Z variance eval              0.014428912
total_rewards                [7570.88633064 7710.80632428 7425.03159293 7383.25082618 7714.27014005
 7457.85370413 7558.65216289 7668.32238683 7541.34419743 7292.20470508]
total_rewards_mean           7532.262237043568
total_rewards_std            135.14992527907893
total_rewards_max            7714.27014004866
total_rewards_min            7292.204705077266
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               27.84762853011489
(Previous) Eval Time (s)     22.480099571868777
Sample Time (s)              16.082670953590423
Epoch Time (s)               66.41039905557409
Total Train Time (s)         8847.630083467346
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:25:42.077076 UTC | [2020_01_10_08_58_14] Iteration #131 | Epoch Duration: 67.34381771087646
2020-01-10 11:25:42.077590 UTC | [2020_01_10_08_58_14] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3509667
Z variance train             0.014402656
KL Divergence                32.962044
KL Loss                      3.2962043
QF Loss                      559.10333
VF Loss                      184.45322
Policy Loss                  -2494.8345
Q Predictions Mean           2494.694
Q Predictions Std            695.8705
Q Predictions Max            3185.982
Q Predictions Min            171.51894
V Predictions Mean           2500.593
V Predictions Std            688.87354
V Predictions Max            3177.4045
V Predictions Min            176.81566
Log Pis Mean                 3.1523428
Log Pis Std                  4.1808248
Log Pis Max                  15.173909
Log Pis Min                  -6.3803473
Policy mu Mean               -0.042755436
Policy mu Std                1.273473
Policy mu Max                2.95969
Policy mu Min                -2.637175
Policy log std Mean          -0.6664641
Policy log std Std           0.35862088
Policy log std Max           0.16574264
Policy log std Min           -2.4153562
Z mean eval                  2.3612962
Z variance eval              0.011324398
total_rewards                [7575.25652161 7664.75300442 7619.96764202 7632.01933567 7683.37423026
 7759.47086663 7673.60858501 7690.73471541 7473.48224142 7666.56377153]
total_rewards_mean           7643.923091398072
total_rewards_std            73.08041267404965
total_rewards_max            7759.470866626861
total_rewards_min            7473.482241423142
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               28.460108384955674
(Previous) Eval Time (s)     23.413152784109116
Sample Time (s)              16.07956998096779
Epoch Time (s)               67.95283115003258
Total Train Time (s)         8914.60221176641
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:26:49.047487 UTC | [2020_01_10_08_58_14] Iteration #132 | Epoch Duration: 66.96964120864868
2020-01-10 11:26:49.047636 UTC | [2020_01_10_08_58_14] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3623338
Z variance train             0.011360556
KL Divergence                33.318867
KL Loss                      3.3318868
QF Loss                      540.802
VF Loss                      205.10222
Policy Loss                  -2423.9604
Q Predictions Mean           2416.15
Q Predictions Std            781.67975
Q Predictions Max            3280.152
Q Predictions Min            178.274
V Predictions Mean           2418.4927
V Predictions Std            779.1441
V Predictions Max            3252.499
V Predictions Min            171.81601
Log Pis Mean                 3.5122085
Log Pis Std                  4.195201
Log Pis Max                  16.238567
Log Pis Min                  -5.8446026
Policy mu Mean               -0.069867216
Policy mu Std                1.2705134
Policy mu Max                2.921992
Policy mu Min                -3.3104417
Policy log std Mean          -0.6763921
Policy log std Std           0.37433445
Policy log std Max           0.116062135
Policy log std Min           -2.5209339
Z mean eval                  2.3568132
Z variance eval              0.014438691
total_rewards                [7418.68735684 7357.69447962 7584.15096824 7652.36050985 7455.36187488
 7381.07151493 7563.58970004 7662.44584964 7544.25867684 7475.86896879]
total_rewards_mean           7509.548989965451
total_rewards_std            102.64300917481461
total_rewards_max            7662.445849638349
total_rewards_min            7357.6944796218295
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               28.938487085979432
(Previous) Eval Time (s)     22.429715547244996
Sample Time (s)              15.332299607805908
Epoch Time (s)               66.70050224103034
Total Train Time (s)         8981.883098055143
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:27:56.333066 UTC | [2020_01_10_08_58_14] Iteration #133 | Epoch Duration: 67.28523969650269
2020-01-10 11:27:56.333404 UTC | [2020_01_10_08_58_14] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3573823
Z variance train             0.014436695
KL Divergence                32.85403
KL Loss                      3.285403
QF Loss                      407.98987
VF Loss                      210.98029
Policy Loss                  -2440.827
Q Predictions Mean           2441.437
Q Predictions Std            839.5589
Q Predictions Max            3254.5642
Q Predictions Min            167.18256
V Predictions Mean           2439.0288
V Predictions Std            830.45953
V Predictions Max            3250.1565
V Predictions Min            168.97668
Log Pis Mean                 3.6924725
Log Pis Std                  4.6519966
Log Pis Max                  19.081406
Log Pis Min                  -8.717175
Policy mu Mean               -0.08543119
Policy mu Std                1.3112439
Policy mu Max                3.345456
Policy mu Min                -2.9006088
Policy log std Mean          -0.64755726
Policy log std Std           0.35006973
Policy log std Max           0.21168971
Policy log std Min           -2.518421
Z mean eval                  2.3713157
Z variance eval              0.010265833
total_rewards                [7594.63907857 7487.87327022 7536.96140687 7658.26717952 7524.63491223
 7549.90995657 7778.85226647 7703.31975115 7677.5922861  7555.99400505]
total_rewards_mean           7606.804411276209
total_rewards_std            88.49642641023021
total_rewards_max            7778.85226647251
total_rewards_min            7487.873270223711
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               29.326037266291678
(Previous) Eval Time (s)     23.014166720211506
Sample Time (s)              16.057413197122514
Epoch Time (s)               68.3976171836257
Total Train Time (s)         9050.119825425558
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:29:04.570486 UTC | [2020_01_10_08_58_14] Iteration #134 | Epoch Duration: 68.2368552684784
2020-01-10 11:29:04.570653 UTC | [2020_01_10_08_58_14] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3720329
Z variance train             0.010250598
KL Divergence                34.25701
KL Loss                      3.4257011
QF Loss                      569.3895
VF Loss                      378.03946
Policy Loss                  -2548.1865
Q Predictions Mean           2543.853
Q Predictions Std            727.5051
Q Predictions Max            3228.4204
Q Predictions Min            163.69408
V Predictions Mean           2555.1973
V Predictions Std            718.5619
V Predictions Max            3245.6406
V Predictions Min            171.54591
Log Pis Mean                 4.351884
Log Pis Std                  4.2832704
Log Pis Max                  13.649332
Log Pis Min                  -5.900216
Policy mu Mean               -0.03194532
Policy mu Std                1.3380944
Policy mu Max                2.978449
Policy mu Min                -3.1185472
Policy log std Mean          -0.7017541
Policy log std Std           0.3831174
Policy log std Max           0.12573138
Policy log std Min           -2.5452936
Z mean eval                  2.3490407
Z variance eval              0.035404455
total_rewards                [7635.62336573 7900.91346607 7637.86028941 7658.66479542 7328.51251069
 7589.22991174 7573.13430316 7650.82009894 7860.87190056 7704.23726933]
total_rewards_mean           7653.986791106266
total_rewards_std            149.53013691048395
total_rewards_max            7900.913466072923
total_rewards_min            7328.512510690695
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               26.99519395502284
(Previous) Eval Time (s)     22.853096563834697
Sample Time (s)              15.850469300989062
Epoch Time (s)               65.6987598198466
Total Train Time (s)         9115.814804359805
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:30:10.267079 UTC | [2020_01_10_08_58_14] Iteration #135 | Epoch Duration: 65.69630074501038
2020-01-10 11:30:10.267240 UTC | [2020_01_10_08_58_14] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3471437
Z variance train             0.035494056
KL Divergence                33.23885
KL Loss                      3.323885
QF Loss                      371.9387
VF Loss                      219.57819
Policy Loss                  -2410.446
Q Predictions Mean           2411.4214
Q Predictions Std            771.69543
Q Predictions Max            3216.5652
Q Predictions Min            149.92752
V Predictions Mean           2414.573
V Predictions Std            766.469
V Predictions Max            3215.3735
V Predictions Min            166.41237
Log Pis Mean                 3.9866536
Log Pis Std                  4.95089
Log Pis Max                  21.171198
Log Pis Min                  -8.794984
Policy mu Mean               -0.049285244
Policy mu Std                1.3172259
Policy mu Max                3.1385381
Policy mu Min                -3.0099614
Policy log std Mean          -0.66574615
Policy log std Std           0.3701375
Policy log std Max           0.07397428
Policy log std Min           -2.5952125
Z mean eval                  2.3794005
Z variance eval              0.021887554
total_rewards                [7518.26244204 7813.00206688 7827.51135187 7845.32518618 7560.07255345
 7815.51669312 7623.88783695 7758.05727211 7754.6857691  7902.55409328]
total_rewards_mean           7741.887526496687
total_rewards_std            123.18161870432654
total_rewards_max            7902.554093276072
total_rewards_min            7518.262442039441
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               26.838126925751567
(Previous) Eval Time (s)     22.850362805183977
Sample Time (s)              16.099777933675796
Epoch Time (s)               65.78826766461134
Total Train Time (s)         9181.11889102403
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:31:15.574597 UTC | [2020_01_10_08_58_14] Iteration #136 | Epoch Duration: 65.30721712112427
2020-01-10 11:31:15.574847 UTC | [2020_01_10_08_58_14] Iteration #136 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.379169
Z variance train             0.021881595
KL Divergence                33.755226
KL Loss                      3.3755226
QF Loss                      334.78833
VF Loss                      670.5333
Policy Loss                  -2493.9583
Q Predictions Mean           2483.9863
Q Predictions Std            784.1368
Q Predictions Max            3201.4448
Q Predictions Min            169.33115
V Predictions Mean           2472.618
V Predictions Std            775.8713
V Predictions Max            3182.315
V Predictions Min            165.18813
Log Pis Mean                 3.7727242
Log Pis Std                  4.5563054
Log Pis Max                  17.586664
Log Pis Min                  -5.368014
Policy mu Mean               -0.07195846
Policy mu Std                1.304542
Policy mu Max                3.0406792
Policy mu Min                -3.3340175
Policy log std Mean          -0.6868167
Policy log std Std           0.38178352
Policy log std Max           0.2777904
Policy log std Min           -2.483268
Z mean eval                  2.3722491
Z variance eval              0.014403966
total_rewards                [7223.82315566 7196.9468822  7436.70532816 7192.91996007 7222.7939548
 7179.62020755 7147.48941398 7260.56591091 7412.74587304 7195.02576041]
total_rewards_mean           7246.863644676826
total_rewards_std            93.45610347644198
total_rewards_max            7436.705328155902
total_rewards_min            7147.489413979444
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               27.53652087599039
(Previous) Eval Time (s)     22.369038756005466
Sample Time (s)              16.988279111217707
Epoch Time (s)               66.89383874321356
Total Train Time (s)         9248.439934565686
Epoch                        137
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:32:22.896737 UTC | [2020_01_10_08_58_14] Iteration #137 | Epoch Duration: 67.32171678543091
2020-01-10 11:32:22.896928 UTC | [2020_01_10_08_58_14] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3735197
Z variance train             0.014415598
KL Divergence                34.304268
KL Loss                      3.4304268
QF Loss                      359.7909
VF Loss                      121.64762
Policy Loss                  -2582.755
Q Predictions Mean           2575.4854
Q Predictions Std            631.72296
Q Predictions Max            3201.0342
Q Predictions Min            166.1083
V Predictions Mean           2581.356
V Predictions Std            630.51184
V Predictions Max            3198.9255
V Predictions Min            159.98286
Log Pis Mean                 3.6090946
Log Pis Std                  4.2621922
Log Pis Max                  15.414307
Log Pis Min                  -5.7025976
Policy mu Mean               -0.02305563
Policy mu Std                1.3210405
Policy mu Max                3.0742538
Policy mu Min                -2.9409556
Policy log std Mean          -0.66847795
Policy log std Std           0.363191
Policy log std Max           0.22904468
Policy log std Min           -2.484034
Z mean eval                  2.3676612
Z variance eval              0.01746639
total_rewards                [7494.11986251 7578.66086213 7788.21627436 7810.07546959 7753.94058482
 7557.1725932  7773.40894983 7717.07691496 7622.38882241 7569.57040066]
total_rewards_mean           7666.463073448604
total_rewards_std            108.52944672674647
total_rewards_max            7810.075469593876
total_rewards_min            7494.119862508222
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               29.90430594002828
(Previous) Eval Time (s)     22.796656579244882
Sample Time (s)              15.8279973231256
Epoch Time (s)               68.52895984239876
Total Train Time (s)         9316.173935461324
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:33:30.632030 UTC | [2020_01_10_08_58_14] Iteration #138 | Epoch Duration: 67.73498034477234
2020-01-10 11:33:30.632247 UTC | [2020_01_10_08_58_14] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3686006
Z variance train             0.017506778
KL Divergence                34.167446
KL Loss                      3.4167447
QF Loss                      362.37787
VF Loss                      268.98965
Policy Loss                  -2531.6465
Q Predictions Mean           2528.086
Q Predictions Std            798.26416
Q Predictions Max            3265.625
Q Predictions Min            167.81519
V Predictions Mean           2522.1895
V Predictions Std            794.8168
V Predictions Max            3238.1448
V Predictions Min            171.6687
Log Pis Mean                 3.7790275
Log Pis Std                  4.2935314
Log Pis Max                  14.52281
Log Pis Min                  -8.802569
Policy mu Mean               0.0050434857
Policy mu Std                1.3212423
Policy mu Max                3.6731374
Policy mu Min                -3.0146189
Policy log std Mean          -0.6625907
Policy log std Std           0.36727333
Policy log std Max           0.035965383
Policy log std Min           -2.5343087
Z mean eval                  2.3707552
Z variance eval              0.01599003
total_rewards                [7536.81647998 7822.40800258 7540.73380784 7844.6189824  7662.77134411
 7916.26088249 7552.63132904 7680.85106337 7771.4130509  7589.22888429]
total_rewards_mean           7691.77338269844
total_rewards_std            132.22147745210134
total_rewards_max            7916.26088248774
total_rewards_min            7536.81647997965
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               27.46246193163097
(Previous) Eval Time (s)     22.00236941780895
Sample Time (s)              15.943274333141744
Epoch Time (s)               65.40810568258166
Total Train Time (s)         9381.566753796767
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:34:36.029690 UTC | [2020_01_10_08_58_14] Iteration #139 | Epoch Duration: 65.39731168746948
2020-01-10 11:34:36.029899 UTC | [2020_01_10_08_58_14] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3629687
Z variance train             0.016094819
KL Divergence                33.776543
KL Loss                      3.3776543
QF Loss                      935.80634
VF Loss                      751.7842
Policy Loss                  -2476.5442
Q Predictions Mean           2466.8794
Q Predictions Std            800.39514
Q Predictions Max            3195.5283
Q Predictions Min            156.546
V Predictions Mean           2500.2717
V Predictions Std            802.7902
V Predictions Max            3215.1663
V Predictions Min            168.87634
Log Pis Mean                 3.1982536
Log Pis Std                  4.067283
Log Pis Max                  18.49606
Log Pis Min                  -6.0186234
Policy mu Mean               0.02911987
Policy mu Std                1.2737745
Policy mu Max                3.3743362
Policy mu Min                -3.6690528
Policy log std Mean          -0.65324646
Policy log std Std           0.3579044
Policy log std Max           0.07085389
Policy log std Min           -2.5005183
Z mean eval                  2.3774617
Z variance eval              0.014525324
total_rewards                [7626.44472627 7824.79572463 7579.0364062  7631.07978492 7744.59608448
 7736.11967372 7815.43993888 7856.06409716 7696.83031306 7709.83028409]
total_rewards_mean           7722.023703340521
total_rewards_std            87.5206307413913
total_rewards_max            7856.064097161055
total_rewards_min            7579.036406199613
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               29.689665182027966
(Previous) Eval Time (s)     21.991291920188814
Sample Time (s)              16.41317804949358
Epoch Time (s)               68.09413515171036
Total Train Time (s)         9449.84397318773
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:35:44.308336 UTC | [2020_01_10_08_58_14] Iteration #140 | Epoch Duration: 68.27828335762024
2020-01-10 11:35:44.308506 UTC | [2020_01_10_08_58_14] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3794768
Z variance train             0.014626485
KL Divergence                34.27313
KL Loss                      3.4273129
QF Loss                      438.40442
VF Loss                      277.9895
Policy Loss                  -2472.314
Q Predictions Mean           2475.1118
Q Predictions Std            857.196
Q Predictions Max            3295.0317
Q Predictions Min            163.11296
V Predictions Mean           2468.855
V Predictions Std            850.18036
V Predictions Max            3283.8777
V Predictions Min            162.8577
Log Pis Mean                 3.5220733
Log Pis Std                  4.488461
Log Pis Max                  16.209358
Log Pis Min                  -7.656253
Policy mu Mean               -0.04173079
Policy mu Std                1.271153
Policy mu Max                3.221513
Policy mu Min                -3.3665862
Policy log std Mean          -0.66641
Policy log std Std           0.3813543
Policy log std Max           0.12789372
Policy log std Min           -2.4833884
Z mean eval                  2.3534036
Z variance eval              0.018396888
total_rewards                [7566.77203265 7575.89998503 7624.04624274 7762.93543947 7575.13968602
 7785.54806779 7628.52323621 7668.24750461 7504.47885438 7742.11065999]
total_rewards_mean           7643.3701708883145
total_rewards_std            89.35240177817829
total_rewards_max            7785.548067790268
total_rewards_min            7504.478854381956
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               28.53752917610109
(Previous) Eval Time (s)     22.175154201686382
Sample Time (s)              15.540347384754568
Epoch Time (s)               66.25303076254204
Total Train Time (s)         9515.813295820262
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:36:50.281134 UTC | [2020_01_10_08_58_14] Iteration #141 | Epoch Duration: 65.97246980667114
2020-01-10 11:36:50.281388 UTC | [2020_01_10_08_58_14] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.352406
Z variance train             0.018482992
KL Divergence                33.690735
KL Loss                      3.3690736
QF Loss                      388.21906
VF Loss                      138.23126
Policy Loss                  -2491.8403
Q Predictions Mean           2491.216
Q Predictions Std            824.9187
Q Predictions Max            3288.549
Q Predictions Min            161.0942
V Predictions Mean           2492.9578
V Predictions Std            819.5737
V Predictions Max            3320.8416
V Predictions Min            165.47772
Log Pis Mean                 4.1988573
Log Pis Std                  4.8458047
Log Pis Max                  19.876574
Log Pis Min                  -6.1321
Policy mu Mean               -0.10969325
Policy mu Std                1.3390727
Policy mu Max                3.2183883
Policy mu Min                -3.6395373
Policy log std Mean          -0.65951526
Policy log std Std           0.34522387
Policy log std Max           0.013739109
Policy log std Min           -2.4670882
Z mean eval                  2.3697555
Z variance eval              0.017794494
total_rewards                [7450.28175335 7566.15811216 7641.15134871 8037.29741282 7689.93750314
 7182.12072033 7592.87460664 7547.33340989 7351.55045742 7574.34520651]
total_rewards_mean           7563.30505309755
total_rewards_std            212.3534383203649
total_rewards_max            8037.297412824752
total_rewards_min            7182.120720331185
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               27.702194854151458
(Previous) Eval Time (s)     21.894290707074106
Sample Time (s)              15.70801335759461
Epoch Time (s)               65.30449891882017
Total Train Time (s)         9581.890828749165
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:37:56.361745 UTC | [2020_01_10_08_58_14] Iteration #142 | Epoch Duration: 66.08014440536499
2020-01-10 11:37:56.362008 UTC | [2020_01_10_08_58_14] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3714082
Z variance train             0.017778894
KL Divergence                33.919228
KL Loss                      3.3919227
QF Loss                      545.54724
VF Loss                      232.85352
Policy Loss                  -2591.502
Q Predictions Mean           2591.6438
Q Predictions Std            709.3589
Q Predictions Max            3357.446
Q Predictions Min            161.67798
V Predictions Mean           2598.2883
V Predictions Std            706.78925
V Predictions Max            3344.2502
V Predictions Min            163.73318
Log Pis Mean                 3.8641276
Log Pis Std                  4.3955197
Log Pis Max                  16.243069
Log Pis Min                  -6.612167
Policy mu Mean               -0.064781964
Policy mu Std                1.3087337
Policy mu Max                3.3162773
Policy mu Min                -3.209524
Policy log std Mean          -0.689531
Policy log std Std           0.3655456
Policy log std Max           0.030254751
Policy log std Min           -2.3682187
Z mean eval                  2.3534987
Z variance eval              0.020216297
total_rewards                [7776.49704948 7672.36752335 7653.85012644 7385.67935459 7821.39923304
 7680.17268481 7726.93633796 7846.47099283 7996.71563749 8024.52466722]
total_rewards_mean           7758.461360721109
total_rewards_std            174.36512488068516
total_rewards_max            8024.524667219673
total_rewards_min            7385.67935459133
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               27.104935518000275
(Previous) Eval Time (s)     22.66964572109282
Sample Time (s)              15.83807664597407
Epoch Time (s)               65.61265788506716
Total Train Time (s)         9647.463708273135
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:39:01.939390 UTC | [2020_01_10_08_58_14] Iteration #143 | Epoch Duration: 65.57716965675354
2020-01-10 11:39:01.939670 UTC | [2020_01_10_08_58_14] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3505921
Z variance train             0.020240549
KL Divergence                33.515915
KL Loss                      3.3515916
QF Loss                      363.79437
VF Loss                      177.5751
Policy Loss                  -2488.6724
Q Predictions Mean           2488.1592
Q Predictions Std            828.20514
Q Predictions Max            3302.6238
Q Predictions Min            142.16148
V Predictions Mean           2497.5278
V Predictions Std            825.7776
V Predictions Max            3308.7751
V Predictions Min            158.12344
Log Pis Mean                 3.947012
Log Pis Std                  4.3154025
Log Pis Max                  15.014191
Log Pis Min                  -6.023462
Policy mu Mean               -0.0022205673
Policy mu Std                1.317122
Policy mu Max                2.6619859
Policy mu Min                -3.0248723
Policy log std Mean          -0.676727
Policy log std Std           0.37198582
Policy log std Max           0.08731884
Policy log std Min           -2.4622571
Z mean eval                  2.35212
Z variance eval              0.018002737
total_rewards                [7696.34926692 7839.63342195 7669.1235421  7717.818854   7905.98194148
 7439.50442135 7838.49070985 7506.6183843  7507.50739721 7584.37795915]
total_rewards_mean           7670.5405898304525
total_rewards_std            151.4554754013067
total_rewards_max            7905.98194148157
total_rewards_min            7439.504421348071
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               26.468358352780342
(Previous) Eval Time (s)     22.63379789283499
Sample Time (s)              15.675679514650255
Epoch Time (s)               64.77783576026559
Total Train Time (s)         9712.74811189482
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:40:07.222677 UTC | [2020_01_10_08_58_14] Iteration #144 | Epoch Duration: 65.28278851509094
2020-01-10 11:40:07.222818 UTC | [2020_01_10_08_58_14] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3495831
Z variance train             0.018058252
KL Divergence                34.413605
KL Loss                      3.4413605
QF Loss                      381.7276
VF Loss                      183.9079
Policy Loss                  -2483.693
Q Predictions Mean           2483.9175
Q Predictions Std            854.9183
Q Predictions Max            3286.996
Q Predictions Min            146.95952
V Predictions Mean           2489.0303
V Predictions Std            851.9186
V Predictions Max            3271.6067
V Predictions Min            155.5147
Log Pis Mean                 3.3597906
Log Pis Std                  4.300857
Log Pis Max                  16.117363
Log Pis Min                  -6.0482187
Policy mu Mean               -0.028599814
Policy mu Std                1.2995147
Policy mu Max                2.7595212
Policy mu Min                -2.8361104
Policy log std Mean          -0.6519871
Policy log std Std           0.3587047
Policy log std Max           0.09725091
Policy log std Min           -2.338194
Z mean eval                  2.3675885
Z variance eval              0.013797429
total_rewards                [7749.17834233 7860.63453139 7797.90260097 7668.65392408 7640.29088258
 7786.37060574 7675.80766653 7898.90006    7551.94727028 7865.33141397]
total_rewards_mean           7749.501729785456
total_rewards_std            107.10317249889135
total_rewards_max            7898.900059998474
total_rewards_min            7551.947270278597
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               27.335553913842887
(Previous) Eval Time (s)     23.138522415887564
Sample Time (s)              15.66196752898395
Epoch Time (s)               66.1360438587144
Total Train Time (s)         9778.499989949632
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:41:12.976477 UTC | [2020_01_10_08_58_14] Iteration #145 | Epoch Duration: 65.75354504585266
2020-01-10 11:41:12.976631 UTC | [2020_01_10_08_58_14] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3683686
Z variance train             0.01381743
KL Divergence                35.41754
KL Loss                      3.5417542
QF Loss                      361.87302
VF Loss                      192.76904
Policy Loss                  -2534.883
Q Predictions Mean           2527.5574
Q Predictions Std            815.88666
Q Predictions Max            3326.703
Q Predictions Min            153.17409
V Predictions Mean           2527.7837
V Predictions Std            808.5133
V Predictions Max            3318.029
V Predictions Min            166.11023
Log Pis Mean                 3.2214808
Log Pis Std                  4.1316476
Log Pis Max                  15.329296
Log Pis Min                  -5.246334
Policy mu Mean               -0.013793026
Policy mu Std                1.2605771
Policy mu Max                3.0070374
Policy mu Min                -2.6098416
Policy log std Mean          -0.6900999
Policy log std Std           0.3855136
Policy log std Max           0.1401869
Policy log std Min           -2.646574
Z mean eval                  2.356852
Z variance eval              0.012074817
total_rewards                [7844.14232714 7663.2602573  7748.26624987 7623.61165343 1708.03065432
 7865.55204914 7812.65924331 7700.43697409 7618.19093404 7460.27329142]
total_rewards_mean           7104.442363404751
total_rewards_std            1802.5360101568274
total_rewards_max            7865.5520491380785
total_rewards_min            1708.0306543213835
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               29.586608138866723
(Previous) Eval Time (s)     22.755688144359738
Sample Time (s)              15.95298687973991
Epoch Time (s)               68.29528316296637
Total Train Time (s)         9846.580479038414
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:42:21.060134 UTC | [2020_01_10_08_58_14] Iteration #146 | Epoch Duration: 68.0833649635315
2020-01-10 11:42:21.060368 UTC | [2020_01_10_08_58_14] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3612711
Z variance train             0.01212264
KL Divergence                35.84778
KL Loss                      3.5847778
QF Loss                      375.52722
VF Loss                      525.03955
Policy Loss                  -2660.145
Q Predictions Mean           2652.488
Q Predictions Std            723.04553
Q Predictions Max            3318.5405
Q Predictions Min            137.42133
V Predictions Mean           2641.0532
V Predictions Std            716.96564
V Predictions Max            3311.9363
V Predictions Min            146.65953
Log Pis Mean                 3.736633
Log Pis Std                  4.3489995
Log Pis Max                  13.497067
Log Pis Min                  -7.781666
Policy mu Mean               -0.06909728
Policy mu Std                1.3060838
Policy mu Max                2.751536
Policy mu Min                -2.6615212
Policy log std Mean          -0.69799995
Policy log std Std           0.39411885
Policy log std Max           0.18508887
Policy log std Min           -2.5821302
Z mean eval                  2.351206
Z variance eval              0.0084372265
total_rewards                [7737.11931559 7930.48617775 8122.17564172 8051.19099706 7855.45146869
 7858.36071827 7937.61497633 7938.35124297 8001.88707938 7797.50196614]
total_rewards_mean           7923.013958389737
total_rewards_std            110.39690418760658
total_rewards_max            8122.175641720876
total_rewards_min            7737.119315587471
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               25.952989108860493
(Previous) Eval Time (s)     22.543507845140994
Sample Time (s)              15.261098912451416
Epoch Time (s)               63.7575958664529
Total Train Time (s)         9910.364642953034
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:43:24.845817 UTC | [2020_01_10_08_58_14] Iteration #147 | Epoch Duration: 63.785279989242554
2020-01-10 11:43:24.846001 UTC | [2020_01_10_08_58_14] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3519793
Z variance train             0.00842781
KL Divergence                35.658455
KL Loss                      3.5658455
QF Loss                      337.8619
VF Loss                      282.5167
Policy Loss                  -2574.0981
Q Predictions Mean           2572.4595
Q Predictions Std            799.4775
Q Predictions Max            3302.2705
Q Predictions Min            159.60887
V Predictions Mean           2562.5312
V Predictions Std            792.9266
V Predictions Max            3275.9792
V Predictions Min            153.75581
Log Pis Mean                 3.7777333
Log Pis Std                  4.2026105
Log Pis Max                  13.621044
Log Pis Min                  -5.0852823
Policy mu Mean               -0.017190063
Policy mu Std                1.314871
Policy mu Max                3.7931595
Policy mu Min                -2.5683594
Policy log std Mean          -0.69065076
Policy log std Std           0.38082635
Policy log std Max           0.05696839
Policy log std Min           -2.6456473
Z mean eval                  2.35772
Z variance eval              0.007641998
total_rewards                [7366.19546434 7824.35257051 7709.68430997 7970.96255159 7656.82692917
 8046.39324768 7592.18269251 7805.9022802  7814.67575141 8071.96347466]
total_rewards_mean           7785.913927203941
total_rewards_std            205.61879934338188
total_rewards_max            8071.9634746605025
total_rewards_min            7366.195464343022
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               26.732381804846227
(Previous) Eval Time (s)     22.570944752078503
Sample Time (s)              15.991922833025455
Epoch Time (s)               65.29524938995019
Total Train Time (s)         9975.929065968841
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:44:30.412183 UTC | [2020_01_10_08_58_14] Iteration #148 | Epoch Duration: 65.5660457611084
2020-01-10 11:44:30.412356 UTC | [2020_01_10_08_58_14] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.359982
Z variance train             0.00765235
KL Divergence                36.20342
KL Loss                      3.620342
QF Loss                      339.74872
VF Loss                      242.7617
Policy Loss                  -2561.9197
Q Predictions Mean           2556.8396
Q Predictions Std            797.71826
Q Predictions Max            3336.302
Q Predictions Min            140.48213
V Predictions Mean           2552.3752
V Predictions Std            788.27954
V Predictions Max            3315.615
V Predictions Min            153.54308
Log Pis Mean                 4.2064333
Log Pis Std                  4.3153143
Log Pis Max                  19.677103
Log Pis Min                  -4.870758
Policy mu Mean               -0.09018763
Policy mu Std                1.3413861
Policy mu Max                4.4898
Policy mu Min                -2.908699
Policy log std Mean          -0.6970766
Policy log std Std           0.380811
Policy log std Max           0.020547807
Policy log std Min           -2.45538
Z mean eval                  2.3647027
Z variance eval              0.0060618343
total_rewards                [7717.42005899 7974.65182602 7845.4168167  7817.26725096 7987.03457913
 7905.91482652 8013.09497773 7906.81104689 7919.26171067 7857.69854683]
total_rewards_mean           7894.45716404406
total_rewards_std            84.28073639468192
total_rewards_max            8013.0949777321375
total_rewards_min            7717.420058987582
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               28.44381340406835
(Previous) Eval Time (s)     22.841503575909883
Sample Time (s)              15.677740898448974
Epoch Time (s)               66.96305787842721
Total Train Time (s)         10042.45556642674
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:45:36.942352 UTC | [2020_01_10_08_58_14] Iteration #149 | Epoch Duration: 66.52984142303467
2020-01-10 11:45:36.942579 UTC | [2020_01_10_08_58_14] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3653097
Z variance train             0.0060509695
KL Divergence                36.527893
KL Loss                      3.6527894
QF Loss                      456.28107
VF Loss                      318.2154
Policy Loss                  -2648.0366
Q Predictions Mean           2643.9539
Q Predictions Std            717.48816
Q Predictions Max            3425.256
Q Predictions Min            149.08873
V Predictions Mean           2641.8674
V Predictions Std            711.4309
V Predictions Max            3418.922
V Predictions Min            158.16722
Log Pis Mean                 4.1217422
Log Pis Std                  4.2523336
Log Pis Max                  15.3688545
Log Pis Min                  -5.7030773
Policy mu Mean               -0.12307543
Policy mu Std                1.3203318
Policy mu Max                2.9861434
Policy mu Min                -2.851243
Policy log std Mean          -0.6937871
Policy log std Std           0.35900554
Policy log std Max           0.25641197
Policy log std Min           -2.5109918
Z mean eval                  2.3608665
Z variance eval              0.0038936771
total_rewards                [7772.24303041 7931.37939727 7879.71749038 7828.72953481 7903.12556706
 8114.30698508 7983.01107097 7903.22010638 7877.54917121 8117.48280168]
total_rewards_mean           7931.076515522892
total_rewards_std            106.66824262028013
total_rewards_max            8117.482801678135
total_rewards_min            7772.243030406371
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               27.594276323914528
(Previous) Eval Time (s)     22.408015087246895
Sample Time (s)              16.072329625487328
Epoch Time (s)               66.07462103664875
Total Train Time (s)         10108.710003626999
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:46:43.198394 UTC | [2020_01_10_08_58_14] Iteration #150 | Epoch Duration: 66.25563740730286
2020-01-10 11:46:43.198604 UTC | [2020_01_10_08_58_14] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.358037
Z variance train             0.0038935244
KL Divergence                37.643887
KL Loss                      3.7643888
QF Loss                      406.35043
VF Loss                      198.00351
Policy Loss                  -2623.936
Q Predictions Mean           2620.9329
Q Predictions Std            746.83167
Q Predictions Max            3379.0442
Q Predictions Min            146.21579
V Predictions Mean           2618.577
V Predictions Std            740.4314
V Predictions Max            3361.3835
V Predictions Min            153.03322
Log Pis Mean                 4.320281
Log Pis Std                  4.6671996
Log Pis Max                  18.071516
Log Pis Min                  -5.4322248
Policy mu Mean               -0.046179965
Policy mu Std                1.3434569
Policy mu Max                3.672518
Policy mu Min                -3.0475922
Policy log std Mean          -0.69778186
Policy log std Std           0.3803971
Policy log std Max           0.011082649
Policy log std Min           -2.7224984
Z mean eval                  2.3459709
Z variance eval              0.0038796372
total_rewards                [7622.03913583 7845.3028548  7876.47531129 7803.26275009 7632.52935306
 7883.87424259 7499.18016249 7751.25434228 7591.48724301 7854.14127274]
total_rewards_mean           7735.954666817782
total_rewards_std            131.4999455381668
total_rewards_max            7883.874242590997
total_rewards_min            7499.180162486819
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               28.17082042619586
(Previous) Eval Time (s)     22.588720494881272
Sample Time (s)              16.415438903030008
Epoch Time (s)               67.17497982410714
Total Train Time (s)         10176.088833104353
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:47:50.578304 UTC | [2020_01_10_08_58_14] Iteration #151 | Epoch Duration: 67.37955641746521
2020-01-10 11:47:50.578451 UTC | [2020_01_10_08_58_14] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3445385
Z variance train             0.0038792186
KL Divergence                38.176933
KL Loss                      3.8176935
QF Loss                      278.96088
VF Loss                      159.26166
Policy Loss                  -2672.6445
Q Predictions Mean           2670.5386
Q Predictions Std            669.7321
Q Predictions Max            3366.389
Q Predictions Min            149.92523
V Predictions Mean           2674.3525
V Predictions Std            668.8089
V Predictions Max            3384.374
V Predictions Min            145.66646
Log Pis Mean                 3.9584394
Log Pis Std                  4.1870046
Log Pis Max                  13.9321375
Log Pis Min                  -4.843155
Policy mu Mean               -0.106165506
Policy mu Std                1.2944365
Policy mu Max                2.8753035
Policy mu Min                -2.8592684
Policy log std Mean          -0.7104661
Policy log std Std           0.37413678
Policy log std Max           0.0723837
Policy log std Min           -2.6720839
Z mean eval                  2.3738596
Z variance eval              0.0032171197
total_rewards                [7793.32576065 7661.87182505 8095.133387   7860.35465349 8011.67169243
 7672.54480157 7905.73572422 7966.7082576  7983.16749906 7992.72691537]
total_rewards_mean           7894.324051644025
total_rewards_std            138.42524605550895
total_rewards_max            8095.133387004586
total_rewards_min            7661.8718250483
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               26.295626581646502
(Previous) Eval Time (s)     22.793048691004515
Sample Time (s)              16.329024645034224
Epoch Time (s)               65.41769991768524
Total Train Time (s)         10241.59024747461
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:48:56.084785 UTC | [2020_01_10_08_58_14] Iteration #152 | Epoch Duration: 65.50618386268616
2020-01-10 11:48:56.085001 UTC | [2020_01_10_08_58_14] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3725297
Z variance train             0.0032199926
KL Divergence                38.75029
KL Loss                      3.875029
QF Loss                      372.0602
VF Loss                      145.9006
Policy Loss                  -2547.8281
Q Predictions Mean           2548.5317
Q Predictions Std            899.6096
Q Predictions Max            3377.9568
Q Predictions Min            136.72012
V Predictions Mean           2546.5142
V Predictions Std            893.9004
V Predictions Max            3369.6597
V Predictions Min            152.06703
Log Pis Mean                 3.3391783
Log Pis Std                  4.567377
Log Pis Max                  14.721909
Log Pis Min                  -5.6299715
Policy mu Mean               -0.08891206
Policy mu Std                1.2995625
Policy mu Max                2.7240493
Policy mu Min                -3.4665256
Policy log std Mean          -0.6521483
Policy log std Std           0.36566547
Policy log std Max           0.038033783
Policy log std Min           -2.5551686
Z mean eval                  2.3661416
Z variance eval              0.003508179
total_rewards                [7909.60037445 7840.33601578 7976.43741039 7766.80543198 7947.74884368
 8038.33178017 7812.03352833 7734.40476472 8015.84553817 8103.16512319]
total_rewards_mean           7914.47088108686
total_rewards_std            116.79603435967229
total_rewards_max            8103.165123185001
total_rewards_min            7734.404764720765
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               27.620657728984952
(Previous) Eval Time (s)     22.88123789988458
Sample Time (s)              16.255261078011245
Epoch Time (s)               66.75715670688078
Total Train Time (s)         10308.426727257669
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:50:02.923591 UTC | [2020_01_10_08_58_14] Iteration #153 | Epoch Duration: 66.83831739425659
2020-01-10 11:50:02.923963 UTC | [2020_01_10_08_58_14] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3657963
Z variance train             0.003527231
KL Divergence                39.134655
KL Loss                      3.9134655
QF Loss                      792.3804
VF Loss                      244.74602
Policy Loss                  -2640.891
Q Predictions Mean           2643.7256
Q Predictions Std            770.054
Q Predictions Max            3400.4475
Q Predictions Min            151.22316
V Predictions Mean           2633.9956
V Predictions Std            767.7977
V Predictions Max            3380.848
V Predictions Min            142.5368
Log Pis Mean                 4.0658026
Log Pis Std                  4.295861
Log Pis Max                  16.346096
Log Pis Min                  -7.5680466
Policy mu Mean               -0.0022592347
Policy mu Std                1.3201284
Policy mu Max                3.1306725
Policy mu Min                -2.75193
Policy log std Mean          -0.7010978
Policy log std Std           0.3797771
Policy log std Max           0.09251088
Policy log std Min           -2.5562153
Z mean eval                  2.3748767
Z variance eval              0.003716626
total_rewards                [7857.4252941  7917.50994519 7887.17332827 7981.05577928 8219.60296401
 7723.7416619  7976.48542292 8203.73540918 7946.25707925 8049.57010004]
total_rewards_mean           7976.2556984129815
total_rewards_std            143.71278944066032
total_rewards_max            8219.602964006905
total_rewards_min            7723.741661900715
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               25.696551093365997
(Previous) Eval Time (s)     22.96203846577555
Sample Time (s)              16.02084766048938
Epoch Time (s)               64.67943721963093
Total Train Time (s)         10372.806605089922
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:51:07.303427 UTC | [2020_01_10_08_58_14] Iteration #154 | Epoch Duration: 64.37926244735718
2020-01-10 11:51:07.303623 UTC | [2020_01_10_08_58_14] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3753376
Z variance train             0.0036890742
KL Divergence                39.573856
KL Loss                      3.9573858
QF Loss                      539.4979
VF Loss                      417.47107
Policy Loss                  -2626.7236
Q Predictions Mean           2615.1921
Q Predictions Std            808.18713
Q Predictions Max            3331.8928
Q Predictions Min            135.65794
V Predictions Mean           2615.7827
V Predictions Std            799.82874
V Predictions Max            3330.2146
V Predictions Min            148.70067
Log Pis Mean                 3.9899805
Log Pis Std                  4.435411
Log Pis Max                  17.03676
Log Pis Min                  -5.002206
Policy mu Mean               -0.09448103
Policy mu Std                1.3150506
Policy mu Max                3.4779956
Policy mu Min                -3.3997574
Policy log std Mean          -0.6953723
Policy log std Std           0.39114207
Policy log std Max           0.10441291
Policy log std Min           -2.6137438
Z mean eval                  2.3665407
Z variance eval              0.005082269
total_rewards                [8070.7671198  8090.60797918 7911.41327824 8124.42065042 8179.09346302
 8107.23556831 8171.52669664 7975.16672992 8073.11664171 7964.94339711]
total_rewards_mean           8066.829152434817
total_rewards_std            84.89498440858956
total_rewards_max            8179.093463015811
total_rewards_min            7911.413278240924
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               25.977785668801516
(Previous) Eval Time (s)     22.66160412179306
Sample Time (s)              15.47467144113034
Epoch Time (s)               64.11406123172492
Total Train Time (s)         10437.041530320887
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:52:11.543096 UTC | [2020_01_10_08_58_14] Iteration #155 | Epoch Duration: 64.2391984462738
2020-01-10 11:52:11.543472 UTC | [2020_01_10_08_58_14] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3661196
Z variance train             0.005081037
KL Divergence                39.543922
KL Loss                      3.9543922
QF Loss                      719.88086
VF Loss                      160.33739
Policy Loss                  -2590.0603
Q Predictions Mean           2590.5234
Q Predictions Std            833.6015
Q Predictions Max            3342.5215
Q Predictions Min            148.01167
V Predictions Mean           2597.875
V Predictions Std            832.243
V Predictions Max            3326.4443
V Predictions Min            148.07733
Log Pis Mean                 3.3619478
Log Pis Std                  4.294505
Log Pis Max                  14.049069
Log Pis Min                  -5.7763057
Policy mu Mean               -0.0487037
Policy mu Std                1.2834122
Policy mu Max                2.7453923
Policy mu Min                -2.6012492
Policy log std Mean          -0.67231685
Policy log std Std           0.37678942
Policy log std Max           0.09378344
Policy log std Min           -2.6405509
Z mean eval                  2.3644803
Z variance eval              0.005274892
total_rewards                [7588.21228983 7740.87236494 8054.18373677 7854.51972395 7472.86643022
 7890.05414156 7750.88588253 7702.3660268  7860.73342502 7939.92563522]
total_rewards_mean           7785.461965685487
total_rewards_std            162.52900718852763
total_rewards_max            8054.183736774699
total_rewards_min            7472.866430224444
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               31.42624791804701
(Previous) Eval Time (s)     22.786455913912505
Sample Time (s)              16.134790384676307
Epoch Time (s)               70.34749421663582
Total Train Time (s)         10507.554848253727
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:53:22.056952 UTC | [2020_01_10_08_58_14] Iteration #156 | Epoch Duration: 70.51327419281006
2020-01-10 11:53:22.057149 UTC | [2020_01_10_08_58_14] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.363715
Z variance train             0.0052762157
KL Divergence                39.31315
KL Loss                      3.931315
QF Loss                      472.25955
VF Loss                      139.58693
Policy Loss                  -2600.4373
Q Predictions Mean           2597.1921
Q Predictions Std            808.62195
Q Predictions Max            3347.1714
Q Predictions Min            138.38017
V Predictions Mean           2595.6953
V Predictions Std            804.94653
V Predictions Max            3343.625
V Predictions Min            147.02827
Log Pis Mean                 3.6289277
Log Pis Std                  4.4838896
Log Pis Max                  14.135889
Log Pis Min                  -6.2315006
Policy mu Mean               -0.04422586
Policy mu Std                1.2989532
Policy mu Max                2.853569
Policy mu Min                -2.6642036
Policy log std Mean          -0.67605823
Policy log std Std           0.3749365
Policy log std Max           0.1203683
Policy log std Min           -2.5239956
Z mean eval                  2.3498623
Z variance eval              0.00412291
total_rewards                [7953.10072627 7980.49758715 7889.21222528 8131.33097534 7941.12180343
 8219.978044   7985.19396237 8072.29702622 7935.73246335 7984.20089716]
total_rewards_mean           8009.266571057922
total_rewards_std            96.39810021102534
total_rewards_max            8219.97804399909
total_rewards_min            7889.212225279667
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               28.59803510410711
(Previous) Eval Time (s)     22.95197108294815
Sample Time (s)              17.005555417388678
Epoch Time (s)               68.55556160444394
Total Train Time (s)         10576.328213311266
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:54:30.832964 UTC | [2020_01_10_08_58_14] Iteration #157 | Epoch Duration: 68.77567958831787
2020-01-10 11:54:30.833172 UTC | [2020_01_10_08_58_14] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3497224
Z variance train             0.004130972
KL Divergence                38.414833
KL Loss                      3.8414834
QF Loss                      577.1879
VF Loss                      279.75024
Policy Loss                  -2667.743
Q Predictions Mean           2670.2078
Q Predictions Std            744.1886
Q Predictions Max            3364.871
Q Predictions Min            140.09837
V Predictions Mean           2672.134
V Predictions Std            739.7715
V Predictions Max            3353.6604
V Predictions Min            146.0873
Log Pis Mean                 4.277619
Log Pis Std                  4.3591447
Log Pis Max                  24.613453
Log Pis Min                  -5.216541
Policy mu Mean               -0.103540935
Policy mu Std                1.347726
Policy mu Max                3.912316
Policy mu Min                -3.7000868
Policy log std Mean          -0.68496424
Policy log std Std           0.36971086
Policy log std Max           0.20564562
Policy log std Min           -2.5673294
Z mean eval                  2.375556
Z variance eval              0.0040228143
total_rewards                [8005.34306269 8321.54564955 7795.68678278 8147.4040017  8024.43672378
 8125.02333209 8053.36392854 7855.56542651 8168.99746676 8089.54647884]
total_rewards_mean           8058.691285323587
total_rewards_std            144.55485856609982
total_rewards_max            8321.545649554371
total_rewards_min            7795.686782782381
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               28.667591216042638
(Previous) Eval Time (s)     23.17174415104091
Sample Time (s)              16.23537730658427
Epoch Time (s)               68.07471267366782
Total Train Time (s)         10643.901572789531
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:55:38.409464 UTC | [2020_01_10_08_58_14] Iteration #158 | Epoch Duration: 67.57612204551697
2020-01-10 11:55:38.409686 UTC | [2020_01_10_08_58_14] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3764496
Z variance train             0.0040056356
KL Divergence                38.803024
KL Loss                      3.8803024
QF Loss                      364.47342
VF Loss                      125.075424
Policy Loss                  -2759.7744
Q Predictions Mean           2760.3882
Q Predictions Std            663.52716
Q Predictions Max            3419.6975
Q Predictions Min            137.47719
V Predictions Mean           2757.5818
V Predictions Std            659.08417
V Predictions Max            3402.2695
V Predictions Min            141.39558
Log Pis Mean                 4.3305182
Log Pis Std                  4.404399
Log Pis Max                  17.573887
Log Pis Min                  -5.9692516
Policy mu Mean               -0.10438452
Policy mu Std                1.3547529
Policy mu Max                2.8507996
Policy mu Min                -2.7723105
Policy log std Mean          -0.69636846
Policy log std Std           0.37019604
Policy log std Max           0.18163377
Policy log std Min           -2.458726
Z mean eval                  2.370455
Z variance eval              0.0028184992
total_rewards                [7801.15360163 7880.09371877 8075.71437918 8072.33341785 7767.32326873
 7724.58231257 8015.05534507 7763.79346475 7993.53517492 7662.24304008]
total_rewards_mean           7875.582772354227
total_rewards_std            144.9899458930341
total_rewards_max            8075.714379175467
total_rewards_min            7662.243040076315
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               25.164689457975328
(Previous) Eval Time (s)     22.672875902149826
Sample Time (s)              15.58932197932154
Epoch Time (s)               63.426887339446694
Total Train Time (s)         10707.146840252448
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:56:41.656341 UTC | [2020_01_10_08_58_14] Iteration #159 | Epoch Duration: 63.24649477005005
2020-01-10 11:56:41.656512 UTC | [2020_01_10_08_58_14] Iteration #159 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3705773
Z variance train             0.0028176517
KL Divergence                38.842796
KL Loss                      3.8842797
QF Loss                      539.75854
VF Loss                      189.17996
Policy Loss                  -2656.371
Q Predictions Mean           2658.7415
Q Predictions Std            784.7812
Q Predictions Max            3375.021
Q Predictions Min            142.30959
V Predictions Mean           2660.2603
V Predictions Std            779.8667
V Predictions Max            3370.2676
V Predictions Min            145.69254
Log Pis Mean                 3.845583
Log Pis Std                  4.0737224
Log Pis Max                  16.650375
Log Pis Min                  -5.000793
Policy mu Mean               -0.0038049903
Policy mu Std                1.2995666
Policy mu Max                3.2588477
Policy mu Min                -2.7246735
Policy log std Mean          -0.691446
Policy log std Std           0.3594824
Policy log std Max           0.09843242
Policy log std Min           -2.7314012
Z mean eval                  2.3627844
Z variance eval              0.004099877
total_rewards                [8105.81139482 7848.22573576 7985.60131935 7997.50275561 7962.8869168
 8060.91767366 7827.66121745 8349.42074089 8165.70367435 8316.17803048]
total_rewards_mean           8061.990945918161
total_rewards_std            167.42949911325968
total_rewards_max            8349.420740893898
total_rewards_min            7827.661217446736
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               29.504458078183234
(Previous) Eval Time (s)     22.49219594709575
Sample Time (s)              15.947701662313193
Epoch Time (s)               67.94435568759218
Total Train Time (s)         10774.933043524157
Epoch                        160
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:57:49.444315 UTC | [2020_01_10_08_58_14] Iteration #160 | Epoch Duration: 67.78766679763794
2020-01-10 11:57:49.444490 UTC | [2020_01_10_08_58_14] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3638592
Z variance train             0.0041118865
KL Divergence                38.86872
KL Loss                      3.886872
QF Loss                      429.61438
VF Loss                      418.99777
Policy Loss                  -2686.2769
Q Predictions Mean           2686.0366
Q Predictions Std            755.43665
Q Predictions Max            3439.3652
Q Predictions Min            132.09355
V Predictions Mean           2691.1677
V Predictions Std            755.8093
V Predictions Max            3427.024
V Predictions Min            141.9632
Log Pis Mean                 4.1491046
Log Pis Std                  4.456931
Log Pis Max                  13.758124
Log Pis Min                  -5.48617
Policy mu Mean               -0.06325855
Policy mu Std                1.3271449
Policy mu Max                3.2115138
Policy mu Min                -2.570344
Policy log std Mean          -0.70585066
Policy log std Std           0.3765419
Policy log std Max           0.12786478
Policy log std Min           -2.6318333
Z mean eval                  2.3445659
Z variance eval              0.0035805
total_rewards                [7942.26989677 7973.81746386 8020.67004718 7926.0555587  7899.11881948
 8048.77021235 7963.40384934 7969.33792554 7956.71499061 7787.55680031]
total_rewards_mean           7948.771556415227
total_rewards_std            67.46145516281885
total_rewards_max            8048.77021235435
total_rewards_min            7787.556800309944
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               28.92413700511679
(Previous) Eval Time (s)     22.335256837774068
Sample Time (s)              16.18961591925472
Epoch Time (s)               67.44900976214558
Total Train Time (s)         10842.507446193136
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 11:58:57.021282 UTC | [2020_01_10_08_58_14] Iteration #161 | Epoch Duration: 67.5766487121582
2020-01-10 11:58:57.021462 UTC | [2020_01_10_08_58_14] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3441932
Z variance train             0.0035885149
KL Divergence                38.54676
KL Loss                      3.854676
QF Loss                      443.7578
VF Loss                      186.63466
Policy Loss                  -2615.1113
Q Predictions Mean           2613.207
Q Predictions Std            832.475
Q Predictions Max            3346.0105
Q Predictions Min            132.09474
V Predictions Mean           2609.517
V Predictions Std            827.3858
V Predictions Max            3351.571
V Predictions Min            137.76665
Log Pis Mean                 3.763092
Log Pis Std                  4.3396463
Log Pis Max                  14.298933
Log Pis Min                  -5.553614
Policy mu Mean               -0.07271898
Policy mu Std                1.3051214
Policy mu Max                2.907889
Policy mu Min                -2.8291938
Policy log std Mean          -0.6976323
Policy log std Std           0.38119498
Policy log std Max           0.07040745
Policy log std Min           -2.589765
Z mean eval                  2.3585076
Z variance eval              0.002748107
total_rewards                [7435.42197401 7902.14220097 7833.05424795 7825.69145921 7443.61798974
 7743.13673131 8051.32674901 7672.23624624 7813.22565173 7955.5890399 ]
total_rewards_mean           7767.544229006914
total_rewards_std            192.01098334158846
total_rewards_max            8051.326749005664
total_rewards_min            7435.421974009349
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               27.563841791823506
(Previous) Eval Time (s)     22.462610800750554
Sample Time (s)              16.036589191295207
Epoch Time (s)               66.06304178386927
Total Train Time (s)         10908.78573988052
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:00:03.301218 UTC | [2020_01_10_08_58_14] Iteration #162 | Epoch Duration: 66.27961659431458
2020-01-10 12:00:03.301385 UTC | [2020_01_10_08_58_14] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3591182
Z variance train             0.0027593493
KL Divergence                38.749287
KL Loss                      3.8749287
QF Loss                      361.6709
VF Loss                      126.842865
Policy Loss                  -2732.8643
Q Predictions Mean           2732.0212
Q Predictions Std            685.8279
Q Predictions Max            3425.1462
Q Predictions Min            155.87416
V Predictions Mean           2731.207
V Predictions Std            688.28644
V Predictions Max            3417.6782
V Predictions Min            136.80237
Log Pis Mean                 3.7080493
Log Pis Std                  4.4930296
Log Pis Max                  17.215712
Log Pis Min                  -4.9596996
Policy mu Mean               -0.061913546
Policy mu Std                1.3131502
Policy mu Max                3.2035375
Policy mu Min                -3.666284
Policy log std Mean          -0.6934249
Policy log std Std           0.39032158
Policy log std Max           0.117106915
Policy log std Min           -2.5480757
Z mean eval                  2.3617358
Z variance eval              0.002155585
total_rewards                [7919.01090013 7873.99650146 8149.12633105 7918.99293159 8055.72707057
 8193.39912514 7810.32845897 8065.82097253 8180.39438391 7962.72467338]
total_rewards_mean           8012.952134873803
total_rewards_std            128.18242911203077
total_rewards_max            8193.39912514074
total_rewards_min            7810.328458965001
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               25.879599241074175
(Previous) Eval Time (s)     22.6789230001159
Sample Time (s)              16.236212782096118
Epoch Time (s)               64.7947350232862
Total Train Time (s)         10973.12504917616
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:01:07.643411 UTC | [2020_01_10_08_58_14] Iteration #163 | Epoch Duration: 64.34187650680542
2020-01-10 12:01:07.643620 UTC | [2020_01_10_08_58_14] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3605983
Z variance train             0.002155558
KL Divergence                39.054466
KL Loss                      3.9054468
QF Loss                      379.7832
VF Loss                      182.02686
Policy Loss                  -2677.3474
Q Predictions Mean           2678.6213
Q Predictions Std            770.1057
Q Predictions Max            3377.4966
Q Predictions Min            132.49648
V Predictions Mean           2685.9976
V Predictions Std            764.1934
V Predictions Max            3388.5466
V Predictions Min            133.08752
Log Pis Mean                 3.290561
Log Pis Std                  4.3507915
Log Pis Max                  23.04925
Log Pis Min                  -5.2720366
Policy mu Mean               -0.054747786
Policy mu Std                1.2342355
Policy mu Max                3.382121
Policy mu Min                -4.4075675
Policy log std Mean          -0.69815093
Policy log std Std           0.39462712
Policy log std Max           0.0512442
Policy log std Min           -2.6164823
Z mean eval                  2.3609862
Z variance eval              0.0021365378
total_rewards                [7962.15231985 7902.30993639 8181.473927   8283.38133019 8096.08256727
 7881.45422817 7963.99643907 7970.63025    8025.1867595  8187.93161337]
total_rewards_mean           8045.459937080121
total_rewards_std            128.4305118072084
total_rewards_max            8283.381330185026
total_rewards_min            7881.454228169216
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               27.417948776856065
(Previous) Eval Time (s)     22.225758735090494
Sample Time (s)              15.735911433119327
Epoch Time (s)               65.37961894506589
Total Train Time (s)         11039.654456933029
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:02:14.177688 UTC | [2020_01_10_08_58_14] Iteration #164 | Epoch Duration: 66.53387522697449
2020-01-10 12:02:14.177965 UTC | [2020_01_10_08_58_14] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3599386
Z variance train             0.0021445125
KL Divergence                39.737892
KL Loss                      3.9737892
QF Loss                      320.38727
VF Loss                      109.12714
Policy Loss                  -2663.8862
Q Predictions Mean           2659.9487
Q Predictions Std            802.35046
Q Predictions Max            3418.5022
Q Predictions Min            127.16883
V Predictions Mean           2662.0571
V Predictions Std            797.96875
V Predictions Max            3421.3564
V Predictions Min            129.49573
Log Pis Mean                 4.1376643
Log Pis Std                  4.7277145
Log Pis Max                  14.468799
Log Pis Min                  -8.825014
Policy mu Mean               -0.043224093
Policy mu Std                1.3248633
Policy mu Max                2.9886591
Policy mu Min                -2.7823262
Policy log std Mean          -0.6996234
Policy log std Std           0.38690934
Policy log std Max           -0.050143123
Policy log std Min           -2.641809
Z mean eval                  2.3885984
Z variance eval              0.0041884864
total_rewards                [8313.53812009 8311.80386183 8311.25382252 8311.24956837 8093.87879828
 8198.70829866 8282.50700389 8226.41186546 8130.52021894 7939.96027947]
total_rewards_mean           8211.983183751358
total_rewards_std            118.29006183808833
total_rewards_max            8313.538120092297
total_rewards_min            7939.960279473615
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               29.881969343870878
(Previous) Eval Time (s)     23.37970834830776
Sample Time (s)              16.066891623660922
Epoch Time (s)               69.32856931583956
Total Train Time (s)         11108.476990949363
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:03:23.000411 UTC | [2020_01_10_08_58_14] Iteration #165 | Epoch Duration: 68.8222587108612
2020-01-10 12:03:23.000563 UTC | [2020_01_10_08_58_14] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.389753
Z variance train             0.004184147
KL Divergence                39.612236
KL Loss                      3.9612236
QF Loss                      320.98645
VF Loss                      158.94608
Policy Loss                  -2707.927
Q Predictions Mean           2699.7764
Q Predictions Std            783.70087
Q Predictions Max            3413.1155
Q Predictions Min            132.02231
V Predictions Mean           2703.2812
V Predictions Std            781.7411
V Predictions Max            3402.1094
V Predictions Min            131.17657
Log Pis Mean                 4.2280035
Log Pis Std                  4.2381835
Log Pis Max                  13.694489
Log Pis Min                  -5.56076
Policy mu Mean               -0.088212065
Policy mu Std                1.3260261
Policy mu Max                2.9408243
Policy mu Min                -3.0632846
Policy log std Mean          -0.71545714
Policy log std Std           0.39711836
Policy log std Max           0.13842463
Policy log std Min           -2.6885645
Z mean eval                  2.3638368
Z variance eval              0.007163188
total_rewards                [8241.87374347 8089.85918654 8435.71189333 7978.85768147 8347.92208677
 8273.250272   8265.60596075 8297.52315645 8260.6477272  8319.49033322]
total_rewards_mean           8251.074204120645
total_rewards_std            122.99602773884831
total_rewards_max            8435.71189332528
total_rewards_min            7978.857681472986
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               27.22876883484423
(Previous) Eval Time (s)     22.873133999295533
Sample Time (s)              14.907338391058147
Epoch Time (s)               65.00924122519791
Total Train Time (s)         11173.100452100392
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:04:27.626049 UTC | [2020_01_10_08_58_14] Iteration #166 | Epoch Duration: 64.62536239624023
2020-01-10 12:04:27.626220 UTC | [2020_01_10_08_58_14] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.362139
Z variance train             0.007207936
KL Divergence                38.439095
KL Loss                      3.8439095
QF Loss                      406.09192
VF Loss                      340.68762
Policy Loss                  -2700.3984
Q Predictions Mean           2700.663
Q Predictions Std            838.1613
Q Predictions Max            3512.5396
Q Predictions Min            118.09505
V Predictions Mean           2712.7957
V Predictions Std            835.5096
V Predictions Max            3517.7937
V Predictions Min            125.74511
Log Pis Mean                 3.4955494
Log Pis Std                  4.3191204
Log Pis Max                  13.368547
Log Pis Min                  -5.8163843
Policy mu Mean               -0.05715057
Policy mu Std                1.3111691
Policy mu Max                2.8003354
Policy mu Min                -2.7689989
Policy log std Mean          -0.68455935
Policy log std Std           0.37144288
Policy log std Max           0.08169997
Policy log std Min           -2.3680425
Z mean eval                  2.3775055
Z variance eval              0.008192751
total_rewards                [8150.00702677 8049.35055991 8125.14685606 8028.28566013 7854.22348379
 8313.61571537 8239.54623829 8160.11487676 7983.55147418 7929.45971778]
total_rewards_mean           8083.33016090499
total_rewards_std            134.1012721395875
total_rewards_max            8313.615715374508
total_rewards_min            7854.223483792512
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               30.30609546136111
(Previous) Eval Time (s)     22.48900702316314
Sample Time (s)              15.28779677581042
Epoch Time (s)               68.08289926033467
Total Train Time (s)         11240.852712288499
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:05:35.381528 UTC | [2020_01_10_08_58_14] Iteration #167 | Epoch Duration: 67.75516247749329
2020-01-10 12:05:35.381732 UTC | [2020_01_10_08_58_14] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3754742
Z variance train             0.008177047
KL Divergence                39.302177
KL Loss                      3.9302177
QF Loss                      599.49243
VF Loss                      228.98788
Policy Loss                  -2716.3833
Q Predictions Mean           2717.788
Q Predictions Std            715.41266
Q Predictions Max            3486.8855
Q Predictions Min            141.65605
V Predictions Mean           2727.1313
V Predictions Std            712.0136
V Predictions Max            3477.114
V Predictions Min            128.6187
Log Pis Mean                 3.822863
Log Pis Std                  4.5519624
Log Pis Max                  25.066229
Log Pis Min                  -10.239998
Policy mu Mean               -0.06353625
Policy mu Std                1.3242921
Policy mu Max                3.616348
Policy mu Min                -3.3783317
Policy log std Mean          -0.6863472
Policy log std Std           0.36175832
Policy log std Max           -0.055122733
Policy log std Min           -2.4593575
Z mean eval                  2.3789353
Z variance eval              0.005837332
total_rewards                [7920.88657726 8267.31222175 8072.67320351 8358.63713036 8169.50865291
 8066.36990217 8225.91858796 8171.33236639 8325.87483234 8177.59744921]
total_rewards_mean           8175.611092386983
total_rewards_std            124.29464246088324
total_rewards_max            8358.637130359226
total_rewards_min            7920.886577263021
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               27.237348245922476
(Previous) Eval Time (s)     22.160980154760182
Sample Time (s)              16.27591606043279
Epoch Time (s)               65.67424446111545
Total Train Time (s)         11306.934651621152
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:06:41.464987 UTC | [2020_01_10_08_58_14] Iteration #168 | Epoch Duration: 66.08307957649231
2020-01-10 12:06:41.465170 UTC | [2020_01_10_08_58_14] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3806117
Z variance train             0.00585213
KL Divergence                39.77066
KL Loss                      3.977066
QF Loss                      370.75824
VF Loss                      132.54872
Policy Loss                  -2677.75
Q Predictions Mean           2672.7085
Q Predictions Std            829.00696
Q Predictions Max            3480.9126
Q Predictions Min            115.7489
V Predictions Mean           2677.9624
V Predictions Std            819.962
V Predictions Max            3482.827
V Predictions Min            126.3283
Log Pis Mean                 3.8448915
Log Pis Std                  4.4064236
Log Pis Max                  14.616622
Log Pis Min                  -5.0212574
Policy mu Mean               -0.084602274
Policy mu Std                1.3117205
Policy mu Max                2.9009595
Policy mu Min                -4.0127454
Policy log std Mean          -0.68456817
Policy log std Std           0.3907017
Policy log std Max           0.09499532
Policy log std Min           -2.5765526
Z mean eval                  2.3755717
Z variance eval              0.0057141883
total_rewards                [7652.84656238 7991.3788166  8038.48735156 8129.99198664 8126.01759457
 8134.27542038 8119.18777661 8137.56040681 8128.72068972 8041.34549719]
total_rewards_mean           8049.98121024707
total_rewards_std            141.1754913129148
total_rewards_max            8137.5604068148805
total_rewards_min            7652.846562378385
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               27.444100013002753
(Previous) Eval Time (s)     22.569554526824504
Sample Time (s)              16.081630619242787
Epoch Time (s)               66.09528515907004
Total Train Time (s)         11372.771997628734
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:07:47.306655 UTC | [2020_01_10_08_58_14] Iteration #169 | Epoch Duration: 65.84130764007568
2020-01-10 12:07:47.306964 UTC | [2020_01_10_08_58_14] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3762734
Z variance train             0.005724023
KL Divergence                40.28428
KL Loss                      4.028428
QF Loss                      414.35785
VF Loss                      205.72357
Policy Loss                  -2640.5273
Q Predictions Mean           2632.683
Q Predictions Std            888.43134
Q Predictions Max            3438.6855
Q Predictions Min            121.91645
V Predictions Mean           2632.1685
V Predictions Std            883.5973
V Predictions Max            3429.8887
V Predictions Min            126.20822
Log Pis Mean                 3.8443625
Log Pis Std                  4.7241054
Log Pis Max                  26.618835
Log Pis Min                  -6.2988844
Policy mu Mean               -0.040444
Policy mu Std                1.307291
Policy mu Max                3.0746672
Policy mu Min                -3.4344134
Policy log std Mean          -0.6902335
Policy log std Std           0.36211222
Policy log std Max           -0.04587245
Policy log std Min           -2.5266674
Z mean eval                  2.3683038
Z variance eval              0.0050873854
total_rewards                [7973.23994628 8085.47323466 8013.48087687 7892.34479049 7816.66171941
 7909.5371827  7728.27277241 7915.70583121 8032.85667482 7944.686862  ]
total_rewards_mean           7931.2259890849145
total_rewards_std            99.68512957855242
total_rewards_max            8085.473234664232
total_rewards_min            7728.272772405468
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               29.910005996003747
(Previous) Eval Time (s)     22.31526028504595
Sample Time (s)              15.69769938243553
Epoch Time (s)               67.92296566348523
Total Train Time (s)         11441.385874887928
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:08:55.924095 UTC | [2020_01_10_08_58_14] Iteration #170 | Epoch Duration: 68.61690950393677
2020-01-10 12:08:55.924386 UTC | [2020_01_10_08_58_14] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3706193
Z variance train             0.0050971415
KL Divergence                39.475872
KL Loss                      3.9475873
QF Loss                      535.5232
VF Loss                      212.25392
Policy Loss                  -2681.047
Q Predictions Mean           2680.8037
Q Predictions Std            827.58276
Q Predictions Max            3509.3325
Q Predictions Min            124.7924
V Predictions Mean           2670.6245
V Predictions Std            821.2572
V Predictions Max            3491.368
V Predictions Min            124.74665
Log Pis Mean                 3.6231003
Log Pis Std                  4.4175296
Log Pis Max                  14.79576
Log Pis Min                  -6.250531
Policy mu Mean               -0.061905723
Policy mu Std                1.3062869
Policy mu Max                2.755628
Policy mu Min                -2.775071
Policy log std Mean          -0.66857696
Policy log std Std           0.36860695
Policy log std Max           0.08113003
Policy log std Min           -2.4954653
Z mean eval                  2.3495505
Z variance eval              0.009623107
total_rewards                [8019.89333128 8087.73527658 7935.4535096  7870.35273781 8113.35004849
 8247.13928964 8139.68655159 7836.44989485 7969.94595834 8189.23206068]
total_rewards_mean           8040.923865886567
total_rewards_std            130.0843215706274
total_rewards_max            8247.13928963947
total_rewards_min            7836.4498948508535
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               29.610487627331167
(Previous) Eval Time (s)     23.008919657208025
Sample Time (s)              15.817071503959596
Epoch Time (s)               68.43647878849879
Total Train Time (s)         11509.842014060821
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:10:04.383704 UTC | [2020_01_10_08_58_14] Iteration #171 | Epoch Duration: 68.45910835266113
2020-01-10 12:10:04.383989 UTC | [2020_01_10_08_58_14] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3463054
Z variance train             0.009519816
KL Divergence                37.37598
KL Loss                      3.7375982
QF Loss                      538.49774
VF Loss                      319.63907
Policy Loss                  -2866.2341
Q Predictions Mean           2861.2966
Q Predictions Std            625.97516
Q Predictions Max            3482.8247
Q Predictions Min            112.38704
V Predictions Mean           2856.1582
V Predictions Std            612.38916
V Predictions Max            3451.8706
V Predictions Min            133.3188
Log Pis Mean                 4.714526
Log Pis Std                  4.2227464
Log Pis Max                  19.009933
Log Pis Min                  -4.96539
Policy mu Mean               -0.12290543
Policy mu Std                1.38262
Policy mu Max                2.9212072
Policy mu Min                -3.7857947
Policy log std Mean          -0.7322996
Policy log std Std           0.3725754
Policy log std Max           0.010382175
Policy log std Min           -2.5010948
Z mean eval                  2.353951
Z variance eval              0.019104844
total_rewards                [8042.70962209 7921.96693747 8120.21190731 8014.63164492 8004.13017186
 8186.06018799 8320.2884572  8271.3949493  8075.72332553 8459.70698244]
total_rewards_mean           8141.682418610209
total_rewards_std            158.04400616802783
total_rewards_max            8459.706982442582
total_rewards_min            7921.96693747074
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               29.603944597765803
(Previous) Eval Time (s)     23.03125819005072
Sample Time (s)              15.6563885435462
Epoch Time (s)               68.29159133136272
Total Train Time (s)         11578.015062767547
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:11:12.557724 UTC | [2020_01_10_08_58_14] Iteration #172 | Epoch Duration: 68.17354726791382
2020-01-10 12:11:12.557872 UTC | [2020_01_10_08_58_14] Iteration #172 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3536355
Z variance train             0.018948851
KL Divergence                36.436836
KL Loss                      3.6436837
QF Loss                      464.50763
VF Loss                      357.42633
Policy Loss                  -2724.7566
Q Predictions Mean           2716.6113
Q Predictions Std            738.7359
Q Predictions Max            3495.6536
Q Predictions Min            115.251724
V Predictions Mean           2709.9485
V Predictions Std            732.4814
V Predictions Max            3470.0684
V Predictions Min            116.993835
Log Pis Mean                 3.8375516
Log Pis Std                  4.2989244
Log Pis Max                  21.295317
Log Pis Min                  -5.4023533
Policy mu Mean               -0.052223105
Policy mu Std                1.3196051
Policy mu Max                3.789427
Policy mu Min                -4.0271955
Policy log std Mean          -0.69931173
Policy log std Std           0.36823413
Policy log std Max           0.055600762
Policy log std Min           -2.4651115
Z mean eval                  2.3398147
Z variance eval              0.010502556
total_rewards                [8328.1051476  7892.12399037 8445.29059209 8302.41326914 8287.1419288
 8272.7680579  8011.28694552 8142.77773652 8131.64264271 8051.31154215]
total_rewards_mean           8186.486185281899
total_rewards_std            160.80584028303238
total_rewards_max            8445.290592092555
total_rewards_min            7892.123990374722
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               28.598049668129534
(Previous) Eval Time (s)     22.912919333204627
Sample Time (s)              16.11251869937405
Epoch Time (s)               67.62348770070821
Total Train Time (s)         11645.48374842899
Epoch                        173
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:12:20.029047 UTC | [2020_01_10_08_58_14] Iteration #173 | Epoch Duration: 67.47104525566101
2020-01-10 12:12:20.029247 UTC | [2020_01_10_08_58_14] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3394177
Z variance train             0.010507509
KL Divergence                35.70379
KL Loss                      3.570379
QF Loss                      494.37103
VF Loss                      196.67197
Policy Loss                  -2747.5244
Q Predictions Mean           2744.9995
Q Predictions Std            752.92645
Q Predictions Max            3478.3892
Q Predictions Min            119.45859
V Predictions Mean           2739.1484
V Predictions Std            749.2141
V Predictions Max            3460.6511
V Predictions Min            119.10777
Log Pis Mean                 3.6581922
Log Pis Std                  4.1226134
Log Pis Max                  13.16282
Log Pis Min                  -8.127169
Policy mu Mean               -0.11760205
Policy mu Std                1.285546
Policy mu Max                2.9382732
Policy mu Min                -3.0676355
Policy log std Mean          -0.6976889
Policy log std Std           0.38811922
Policy log std Max           0.016699791
Policy log std Min           -2.6612399
Z mean eval                  2.3480268
Z variance eval              0.013183624
total_rewards                [8117.81802077 8083.68487408 8514.50964551 8253.57910872 8089.65952932
 8312.40914024 8216.43659592 8242.02461437 8401.40559503 7727.67480388]
total_rewards_mean           8195.920192784248
total_rewards_std            203.07782861443283
total_rewards_max            8514.509645508504
total_rewards_min            7727.674803875749
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               27.59294940205291
(Previous) Eval Time (s)     22.760189435910434
Sample Time (s)              16.47448103968054
Epoch Time (s)               66.82761987764388
Total Train Time (s)         11711.858965623658
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:13:26.405597 UTC | [2020_01_10_08_58_14] Iteration #174 | Epoch Duration: 66.37621402740479
2020-01-10 12:13:26.405766 UTC | [2020_01_10_08_58_14] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3476691
Z variance train             0.013021715
KL Divergence                35.223076
KL Loss                      3.5223076
QF Loss                      354.83734
VF Loss                      389.8113
Policy Loss                  -2737.8735
Q Predictions Mean           2741.804
Q Predictions Std            789.7214
Q Predictions Max            3457.4167
Q Predictions Min            122.10795
V Predictions Mean           2753.1992
V Predictions Std            786.40216
V Predictions Max            3465.4844
V Predictions Min            124.711655
Log Pis Mean                 4.11209
Log Pis Std                  4.4289784
Log Pis Max                  15.8481
Log Pis Min                  -7.78237
Policy mu Mean               -0.09291131
Policy mu Std                1.3446887
Policy mu Max                3.0666046
Policy mu Min                -3.459922
Policy log std Mean          -0.69443005
Policy log std Std           0.3672824
Policy log std Max           0.04732859
Policy log std Min           -2.5984116
Z mean eval                  2.3714044
Z variance eval              0.010905153
total_rewards                [8066.95784443 8405.5606138  8073.06707622 8094.03928683 8326.06860673
 7847.66994024 8163.70559343 8278.00513633 7877.17438336 8064.47191523]
total_rewards_mean           8119.6720396611
total_rewards_std            171.1097014289136
total_rewards_max            8405.560613800348
total_rewards_min            7847.669940241557
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               28.799665874801576
(Previous) Eval Time (s)     22.30850210180506
Sample Time (s)              15.946464435663074
Epoch Time (s)               67.05463241226971
Total Train Time (s)         11778.8892761725
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:14:33.440858 UTC | [2020_01_10_08_58_14] Iteration #175 | Epoch Duration: 67.03494381904602
2020-01-10 12:14:33.441110 UTC | [2020_01_10_08_58_14] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3737874
Z variance train             0.010894231
KL Divergence                36.688408
KL Loss                      3.668841
QF Loss                      746.08154
VF Loss                      266.29648
Policy Loss                  -2804.8853
Q Predictions Mean           2799.9937
Q Predictions Std            765.22565
Q Predictions Max            3486.1685
Q Predictions Min            124.62641
V Predictions Mean           2797.024
V Predictions Std            761.7303
V Predictions Max            3473.1611
V Predictions Min            120.58132
Log Pis Mean                 4.497215
Log Pis Std                  4.435368
Log Pis Max                  15.340824
Log Pis Min                  -6.0340776
Policy mu Mean               -0.052712824
Policy mu Std                1.3735901
Policy mu Max                2.8512013
Policy mu Min                -2.9229007
Policy log std Mean          -0.6948156
Policy log std Std           0.39042798
Policy log std Max           0.058813393
Policy log std Min           -2.659328
Z mean eval                  2.3670926
Z variance eval              0.010380248
total_rewards                [8355.38404539 8166.45253901 8200.34226895 8461.71485977 8279.72600644
 8300.55418062 8245.19084681 7971.70392157 8016.33416204 8297.91594465]
total_rewards_mean           8229.5318775239
total_rewards_std            141.06468885676233
total_rewards_max            8461.714859766602
total_rewards_min            7971.703921573578
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               27.839480529073626
(Previous) Eval Time (s)     22.288551018107682
Sample Time (s)              16.215853397734463
Epoch Time (s)               66.34388494491577
Total Train Time (s)         11845.990018387325
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:15:40.541950 UTC | [2020_01_10_08_58_14] Iteration #176 | Epoch Duration: 67.10066866874695
2020-01-10 12:15:40.542089 UTC | [2020_01_10_08_58_14] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3690388
Z variance train             0.0103483135
KL Divergence                36.57321
KL Loss                      3.6573212
QF Loss                      339.9077
VF Loss                      242.69371
Policy Loss                  -2731.612
Q Predictions Mean           2728.6042
Q Predictions Std            853.0742
Q Predictions Max            3525.2834
Q Predictions Min            100.395035
V Predictions Mean           2723.4956
V Predictions Std            845.6241
V Predictions Max            3511.2139
V Predictions Min            118.53947
Log Pis Mean                 3.6232145
Log Pis Std                  4.5110483
Log Pis Max                  14.535629
Log Pis Min                  -6.547654
Policy mu Mean               -0.040296894
Policy mu Std                1.3192674
Policy mu Max                2.9501
Policy mu Min                -2.914481
Policy log std Mean          -0.676601
Policy log std Std           0.38541925
Policy log std Max           0.0388512
Policy log std Min           -2.6951265
Z mean eval                  2.3550467
Z variance eval              0.0163592
total_rewards                [8024.45677273 8145.31018005 8045.797473   7841.8322599  8239.17037425
 8058.3067228  8081.24243117 8012.40628193 7953.52257522 8313.82484516]
total_rewards_mean           8071.58699162171
total_rewards_std            128.6791458469138
total_rewards_max            8313.82484516419
total_rewards_min            7841.832259902977
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               27.314416811801493
(Previous) Eval Time (s)     23.04506273707375
Sample Time (s)              15.26866895193234
Epoch Time (s)               65.62814850080758
Total Train Time (s)         11911.575199014973
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:16:46.128956 UTC | [2020_01_10_08_58_14] Iteration #177 | Epoch Duration: 65.58673810958862
2020-01-10 12:16:46.129135 UTC | [2020_01_10_08_58_14] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.355407
Z variance train             0.016358811
KL Divergence                35.158188
KL Loss                      3.5158188
QF Loss                      266.71692
VF Loss                      112.07573
Policy Loss                  -2728.2915
Q Predictions Mean           2726.04
Q Predictions Std            833.81085
Q Predictions Max            3444.5286
Q Predictions Min            105.241554
V Predictions Mean           2726.2844
V Predictions Std            829.33984
V Predictions Max            3439.418
V Predictions Min            115.82523
Log Pis Mean                 3.7674947
Log Pis Std                  4.5150104
Log Pis Max                  13.924345
Log Pis Min                  -6.1910796
Policy mu Mean               -0.078934185
Policy mu Std                1.2928286
Policy mu Max                2.7383616
Policy mu Min                -3.0267406
Policy log std Mean          -0.7077419
Policy log std Std           0.38578278
Policy log std Max           0.06462312
Policy log std Min           -2.492026
Z mean eval                  2.3402307
Z variance eval              0.015590837
total_rewards                [8159.3424178  8270.72853628 8077.46723088 8108.70600668 8289.93253183
 8250.36666968 8242.65871381 8242.48197057 8368.86793834 8247.94124912]
total_rewards_mean           8225.84932649861
total_rewards_std            82.696100334279
total_rewards_max            8368.867938343401
total_rewards_min            8077.467230880388
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               27.59607815463096
(Previous) Eval Time (s)     23.00339455064386
Sample Time (s)              16.043729626573622
Epoch Time (s)               66.64320233184844
Total Train Time (s)         11977.97730301693
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:17:52.536017 UTC | [2020_01_10_08_58_14] Iteration #178 | Epoch Duration: 66.40672779083252
2020-01-10 12:17:52.536287 UTC | [2020_01_10_08_58_14] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3382492
Z variance train             0.015634103
KL Divergence                34.84415
KL Loss                      3.484415
QF Loss                      513.1726
VF Loss                      140.58894
Policy Loss                  -2818.0557
Q Predictions Mean           2809.585
Q Predictions Std            668.2796
Q Predictions Max            3460.2334
Q Predictions Min            101.76325
V Predictions Mean           2818.3079
V Predictions Std            664.0265
V Predictions Max            3456.9197
V Predictions Min            115.46533
Log Pis Mean                 3.8632426
Log Pis Std                  4.2994223
Log Pis Max                  15.211669
Log Pis Min                  -6.610586
Policy mu Mean               -0.1040166
Policy mu Std                1.3151609
Policy mu Max                2.8834195
Policy mu Min                -3.2192597
Policy log std Mean          -0.6830995
Policy log std Std           0.3590572
Policy log std Max           -0.015191138
Policy log std Min           -2.407276
Z mean eval                  2.343805
Z variance eval              0.018626343
total_rewards                [8266.13302824 8537.15763944 8273.70758961 8515.01196793 8228.80186776
 8314.86154229 8172.84597987 8363.49718657 8329.05346585 8385.73910483]
total_rewards_mean           8338.680937238274
total_rewards_std            110.92131483543703
total_rewards_max            8537.157639441772
total_rewards_min            8172.8459798726535
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               28.842515176162124
(Previous) Eval Time (s)     22.76665024133399
Sample Time (s)              16.515967646613717
Epoch Time (s)               68.12513306410983
Total Train Time (s)         12046.009028550703
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:19:00.569099 UTC | [2020_01_10_08_58_14] Iteration #179 | Epoch Duration: 68.03261613845825
2020-01-10 12:19:00.569281 UTC | [2020_01_10_08_58_14] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3438747
Z variance train             0.018666822
KL Divergence                34.627235
KL Loss                      3.4627235
QF Loss                      446.28497
VF Loss                      300.85657
Policy Loss                  -2849.0662
Q Predictions Mean           2855.017
Q Predictions Std            701.0948
Q Predictions Max            3555.042
Q Predictions Min            116.544464
V Predictions Mean           2861.5742
V Predictions Std            694.14703
V Predictions Max            3543.2576
V Predictions Min            120.3166
Log Pis Mean                 4.721884
Log Pis Std                  4.418485
Log Pis Max                  16.11799
Log Pis Min                  -6.7156296
Policy mu Mean               -0.027547682
Policy mu Std                1.3962018
Policy mu Max                3.046452
Policy mu Min                -3.3935225
Policy log std Mean          -0.7102409
Policy log std Std           0.37705812
Policy log std Max           0.5843122
Policy log std Min           -2.430995
Z mean eval                  2.3592439
Z variance eval              0.012755361
total_rewards                [1470.60092789 8290.3149148  8007.29177526 8261.70342863 8019.12366326
 8437.0410051  8104.73638071 8444.97504517 8482.2586661  8048.74520446]
total_rewards_mean           7556.679101138706
total_rewards_std            2036.0706084123951
total_rewards_max            8482.258666099064
total_rewards_min            1470.6009278886277
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               30.004587133880705
(Previous) Eval Time (s)     22.673855890054256
Sample Time (s)              17.593385187909007
Epoch Time (s)               70.27182821184397
Total Train Time (s)         12116.901391362771
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:20:11.465504 UTC | [2020_01_10_08_58_14] Iteration #180 | Epoch Duration: 70.89605855941772
2020-01-10 12:20:11.465742 UTC | [2020_01_10_08_58_14] Iteration #180 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3612685
Z variance train             0.012689831
KL Divergence                35.80018
KL Loss                      3.5800178
QF Loss                      801.62524
VF Loss                      266.31287
Policy Loss                  -2719.5063
Q Predictions Mean           2714.9214
Q Predictions Std            829.1586
Q Predictions Max            3485.9998
Q Predictions Min            111.69441
V Predictions Mean           2712.9019
V Predictions Std            820.5905
V Predictions Max            3464.6443
V Predictions Min            117.80335
Log Pis Mean                 4.155003
Log Pis Std                  4.543378
Log Pis Max                  21.189611
Log Pis Min                  -7.098732
Policy mu Mean               -0.082045294
Policy mu Std                1.2987859
Policy mu Max                3.2384818
Policy mu Min                -4.3864155
Policy log std Mean          -0.7222171
Policy log std Std           0.4035813
Policy log std Max           0.1634587
Policy log std Min           -2.5860167
Z mean eval                  2.3532596
Z variance eval              0.017523607
total_rewards                [8174.44065867 8793.08789371 8638.95773658 8642.45581959 8410.3097133
 8341.17942    8427.05084275 8309.23890496 8614.61568208 8348.22693208]
total_rewards_mean           8469.956360373082
total_rewards_std            182.65202606149245
total_rewards_max            8793.087893711452
total_rewards_min            8174.440658672134
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               28.305686097126454
(Previous) Eval Time (s)     23.29776380304247
Sample Time (s)              15.701717385556549
Epoch Time (s)               67.30516728572547
Total Train Time (s)         12184.23078850098
Epoch                        181
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:21:18.795713 UTC | [2020_01_10_08_58_14] Iteration #181 | Epoch Duration: 67.32980012893677
2020-01-10 12:21:18.795908 UTC | [2020_01_10_08_58_14] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3531168
Z variance train             0.017572783
KL Divergence                34.269646
KL Loss                      3.4269645
QF Loss                      307.1776
VF Loss                      122.49331
Policy Loss                  -2846.4072
Q Predictions Mean           2849.5967
Q Predictions Std            708.6318
Q Predictions Max            3535.384
Q Predictions Min            112.86714
V Predictions Mean           2849.2856
V Predictions Std            705.18134
V Predictions Max            3526.212
V Predictions Min            122.253555
Log Pis Mean                 4.645713
Log Pis Std                  4.304357
Log Pis Max                  14.711721
Log Pis Min                  -5.350936
Policy mu Mean               -0.02569948
Policy mu Std                1.3894877
Policy mu Max                3.6086392
Policy mu Min                -2.7404685
Policy log std Mean          -0.719718
Policy log std Std           0.37473294
Policy log std Max           -0.081300795
Policy log std Min           -2.60906
Z mean eval                  2.337797
Z variance eval              0.026293006
total_rewards                [8206.20988087 8407.83810712 8252.30671605 8421.59361553 8081.10391254
 8505.75057581 8615.43599531 8324.77193919 8344.41754183 8207.25087698]
total_rewards_mean           8336.66791612322
total_rewards_std            149.9925232263231
total_rewards_max            8615.435995312631
total_rewards_min            8081.103912541352
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               29.027023615315557
(Previous) Eval Time (s)     23.32213311130181
Sample Time (s)              15.71312591060996
Epoch Time (s)               68.06228263722733
Total Train Time (s)         12251.614356490318
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:22:26.181990 UTC | [2020_01_10_08_58_14] Iteration #182 | Epoch Duration: 67.38595128059387
2020-01-10 12:22:26.182175 UTC | [2020_01_10_08_58_14] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.338679
Z variance train             0.026159918
KL Divergence                33.58356
KL Loss                      3.3583562
QF Loss                      332.2221
VF Loss                      129.81963
Policy Loss                  -2732.4395
Q Predictions Mean           2731.392
Q Predictions Std            775.90076
Q Predictions Max            3535.386
Q Predictions Min            97.5764
V Predictions Mean           2730.5952
V Predictions Std            768.70435
V Predictions Max            3537.5176
V Predictions Min            114.43588
Log Pis Mean                 4.10938
Log Pis Std                  4.379561
Log Pis Max                  17.060081
Log Pis Min                  -7.214545
Policy mu Mean               -0.036692057
Policy mu Std                1.3383073
Policy mu Max                3.3380702
Policy mu Min                -3.200109
Policy log std Mean          -0.7169644
Policy log std Std           0.39045718
Policy log std Max           0.015862048
Policy log std Min           -2.4283864
Z mean eval                  2.3428006
Z variance eval              0.026897782
total_rewards                [8085.67772218 7907.32398498 8328.31519374 8433.21634492 8355.37871622
 8512.3404857  8555.97852008 8462.3572305  8312.79002398 8610.16771002]
total_rewards_mean           8356.354593233233
total_rewards_std            205.74892093953045
total_rewards_max            8610.16771002129
total_rewards_min            7907.3239849821875
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               25.38850832125172
(Previous) Eval Time (s)     22.645506819244474
Sample Time (s)              15.798879466485232
Epoch Time (s)               63.83289460698143
Total Train Time (s)         12315.200235783122
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:23:29.771435 UTC | [2020_01_10_08_58_14] Iteration #183 | Epoch Duration: 63.58910012245178
2020-01-10 12:23:29.771669 UTC | [2020_01_10_08_58_14] Iteration #183 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3425398
Z variance train             0.026950452
KL Divergence                32.970135
KL Loss                      3.2970135
QF Loss                      588.9669
VF Loss                      241.66273
Policy Loss                  -2835.1826
Q Predictions Mean           2837.7615
Q Predictions Std            773.4684
Q Predictions Max            3577.5916
Q Predictions Min            123.345856
V Predictions Mean           2841.9478
V Predictions Std            765.82306
V Predictions Max            3578.313
V Predictions Min            119.88875
Log Pis Mean                 4.544669
Log Pis Std                  4.225125
Log Pis Max                  16.357437
Log Pis Min                  -5.98034
Policy mu Mean               -0.1186325
Policy mu Std                1.3640813
Policy mu Max                3.538537
Policy mu Min                -3.4607203
Policy log std Mean          -0.68559915
Policy log std Std           0.3614249
Policy log std Max           0.02812922
Policy log std Min           -2.4928927
Z mean eval                  2.367221
Z variance eval              0.017998975
total_rewards                [8019.20787519 8324.08451876 8370.3001053  8142.08663582 8013.1453049
 8153.88826257 8240.12575396 7975.69380199 8354.99567185 8218.51424422]
total_rewards_mean           8181.204217454821
total_rewards_std            137.92635024859212
total_rewards_max            8370.300105295273
total_rewards_min            7975.6938019873805
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               28.62343558995053
(Previous) Eval Time (s)     22.401432157028466
Sample Time (s)              16.621490370482206
Epoch Time (s)               67.6463581174612
Total Train Time (s)         12382.809754298069
Epoch                        184
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:24:37.384712 UTC | [2020_01_10_08_58_14] Iteration #184 | Epoch Duration: 67.61282539367676
2020-01-10 12:24:37.384979 UTC | [2020_01_10_08_58_14] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3668714
Z variance train             0.017933507
KL Divergence                33.673157
KL Loss                      3.3673158
QF Loss                      266.91122
VF Loss                      131.49672
Policy Loss                  -2770.5862
Q Predictions Mean           2774.973
Q Predictions Std            880.64703
Q Predictions Max            3608.2256
Q Predictions Min            102.37547
V Predictions Mean           2773.6265
V Predictions Std            875.5791
V Predictions Max            3616.2417
V Predictions Min            111.946335
Log Pis Mean                 3.7640383
Log Pis Std                  4.2104893
Log Pis Max                  14.296782
Log Pis Min                  -5.037868
Policy mu Mean               -0.06537602
Policy mu Std                1.295316
Policy mu Max                2.761601
Policy mu Min                -3.318014
Policy log std Mean          -0.7098512
Policy log std Std           0.39920485
Policy log std Max           0.10537928
Policy log std Min           -2.4772482
Z mean eval                  2.3670478
Z variance eval              0.01827152
total_rewards                [7932.53498624 8055.83950252 8277.72368402 7985.5032298  8072.75536059
 8152.7073878  8047.73151768 8047.06719089 8145.32050443 8100.59576708]
total_rewards_mean           8081.7779131044545
total_rewards_std            90.8173842380111
total_rewards_max            8277.72368401744
total_rewards_min            7932.534986244292
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               28.83962767617777
(Previous) Eval Time (s)     22.367593730799854
Sample Time (s)              16.641535589005798
Epoch Time (s)               67.84875699598342
Total Train Time (s)         12450.679117191117
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:25:45.254734 UTC | [2020_01_10_08_58_14] Iteration #185 | Epoch Duration: 67.86955094337463
2020-01-10 12:25:45.254916 UTC | [2020_01_10_08_58_14] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3643453
Z variance train             0.018212954
KL Divergence                33.49977
KL Loss                      3.3499773
QF Loss                      342.83276
VF Loss                      119.653885
Policy Loss                  -2882.5146
Q Predictions Mean           2877.1162
Q Predictions Std            767.5002
Q Predictions Max            3551.132
Q Predictions Min            93.718025
V Predictions Mean           2883.133
V Predictions Std            763.2686
V Predictions Max            3552.4705
V Predictions Min            118.53064
Log Pis Mean                 4.3796635
Log Pis Std                  4.3665776
Log Pis Max                  14.1147175
Log Pis Min                  -7.0452724
Policy mu Mean               -0.12021065
Policy mu Std                1.3438246
Policy mu Max                3.125594
Policy mu Min                -2.9799743
Policy log std Mean          -0.70549244
Policy log std Std           0.38039273
Policy log std Max           -0.039223373
Policy log std Min           -2.6009407
Z mean eval                  2.3789654
Z variance eval              0.013854021
total_rewards                [8177.52349054 8182.78532944 8097.22563328 8151.43965553 8123.09662234
 8106.54785996 8457.81660839 8048.6155321  8147.29796318 8044.70972004]
total_rewards_mean           8153.705841479462
total_rewards_std            111.0033301904193
total_rewards_max            8457.816608394118
total_rewards_min            8044.70972004049
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               29.54607294406742
(Previous) Eval Time (s)     22.38812611391768
Sample Time (s)              15.46668448112905
Epoch Time (s)               67.40088353911415
Total Train Time (s)         12517.705911655445
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:26:52.284417 UTC | [2020_01_10_08_58_14] Iteration #186 | Epoch Duration: 67.02933621406555
2020-01-10 12:26:52.284693 UTC | [2020_01_10_08_58_14] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3773367
Z variance train             0.013856593
KL Divergence                34.32803
KL Loss                      3.432803
QF Loss                      370.33636
VF Loss                      269.62277
Policy Loss                  -2852.1338
Q Predictions Mean           2853.686
Q Predictions Std            755.1449
Q Predictions Max            3642.043
Q Predictions Min            98.76319
V Predictions Mean           2861.3403
V Predictions Std            750.9246
V Predictions Max            3650.4148
V Predictions Min            118.04523
Log Pis Mean                 3.8488667
Log Pis Std                  4.026566
Log Pis Max                  14.119224
Log Pis Min                  -7.0617704
Policy mu Mean               -0.075856216
Policy mu Std                1.2846128
Policy mu Max                2.7327046
Policy mu Min                -3.3068326
Policy log std Mean          -0.6958502
Policy log std Std           0.37915096
Policy log std Max           -0.042572185
Policy log std Min           -2.5449066
Z mean eval                  2.3653417
Z variance eval              0.014017656
total_rewards                [8157.4021699  3128.21053649 8378.6703468  8216.38522828 8142.38062194
 8090.92196841 8397.49389857 8552.49193896 2263.75071691 8400.01502065]
total_rewards_mean           7172.772244690491
total_rewards_std            2250.8358418428033
total_rewards_max            8552.491938958186
total_rewards_min            2263.7507169121754
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               30.33101263921708
(Previous) Eval Time (s)     22.016249229665846
Sample Time (s)              16.08586373226717
Epoch Time (s)               68.4331256011501
Total Train Time (s)         12586.557631164324
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:28:01.136827 UTC | [2020_01_10_08_58_14] Iteration #187 | Epoch Duration: 68.85194110870361
2020-01-10 12:28:01.137006 UTC | [2020_01_10_08_58_14] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3616083
Z variance train             0.013978349
KL Divergence                33.948177
KL Loss                      3.3948178
QF Loss                      516.1022
VF Loss                      237.31787
Policy Loss                  -2805.0635
Q Predictions Mean           2802.8376
Q Predictions Std            747.6467
Q Predictions Max            3517.8738
Q Predictions Min            117.51848
V Predictions Mean           2805.6362
V Predictions Std            748.48096
V Predictions Max            3502.89
V Predictions Min            106.07525
Log Pis Mean                 4.186929
Log Pis Std                  4.489901
Log Pis Max                  19.827301
Log Pis Min                  -7.927186
Policy mu Mean               -0.05973017
Policy mu Std                1.3593855
Policy mu Max                3.8718734
Policy mu Min                -3.2278297
Policy log std Mean          -0.7141037
Policy log std Std           0.39319903
Policy log std Max           -0.056179345
Policy log std Min           -2.5266325
Z mean eval                  2.3456333
Z variance eval              0.020315107
total_rewards                [8248.59024477 8191.99399039 7856.24488502 8159.17167838 8326.53596725
 8260.15212652 8250.82222121 7541.63908954 8109.59178259 8178.816496  ]
total_rewards_mean           8112.355848166752
total_rewards_std            225.7694992766938
total_rewards_max            8326.535967250615
total_rewards_min            7541.639089538368
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               30.139611105900258
(Previous) Eval Time (s)     22.43478052224964
Sample Time (s)              15.76309385150671
Epoch Time (s)               68.3374854796566
Total Train Time (s)         12654.92543437332
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:29:09.508499 UTC | [2020_01_10_08_58_14] Iteration #188 | Epoch Duration: 68.37135457992554
2020-01-10 12:29:09.508718 UTC | [2020_01_10_08_58_14] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3467927
Z variance train             0.020413091
KL Divergence                32.556034
KL Loss                      3.2556036
QF Loss                      562.2727
VF Loss                      164.56027
Policy Loss                  -2722.0986
Q Predictions Mean           2720.8862
Q Predictions Std            854.99414
Q Predictions Max            3519.947
Q Predictions Min            119.619316
V Predictions Mean           2726.1338
V Predictions Std            854.5757
V Predictions Max            3507.116
V Predictions Min            110.60487
Log Pis Mean                 4.1062956
Log Pis Std                  4.2775335
Log Pis Max                  14.781002
Log Pis Min                  -5.2727203
Policy mu Mean               -0.06351287
Policy mu Std                1.3285813
Policy mu Max                2.9090025
Policy mu Min                -3.4098186
Policy log std Mean          -0.707849
Policy log std Std           0.41513193
Policy log std Max           0.05485761
Policy log std Min           -2.680775
Z mean eval                  2.3317332
Z variance eval              0.02698344
total_rewards                [8319.56607985 8123.45482795 8513.42731195 8322.94891665 8358.76928417
 8244.56174929 8375.81809433 8359.82712585 8057.15476191 8470.55656793]
total_rewards_mean           8314.608471987878
total_rewards_std            133.94516576836588
total_rewards_max            8513.427311950789
total_rewards_min            8057.154761906863
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               29.544053588062525
(Previous) Eval Time (s)     22.468376378994435
Sample Time (s)              16.387347556184977
Epoch Time (s)               68.39977752324194
Total Train Time (s)         12724.509593629278
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:30:19.093495 UTC | [2020_01_10_08_58_14] Iteration #189 | Epoch Duration: 69.58461952209473
2020-01-10 12:30:19.093649 UTC | [2020_01_10_08_58_14] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3335934
Z variance train             0.02695244
KL Divergence                31.301605
KL Loss                      3.1301606
QF Loss                      397.0543
VF Loss                      146.8046
Policy Loss                  -2767.4
Q Predictions Mean           2764.754
Q Predictions Std            794.071
Q Predictions Max            3515.6123
Q Predictions Min            109.812004
V Predictions Mean           2765.3457
V Predictions Std            791.90375
V Predictions Max            3509.7395
V Predictions Min            103.40322
Log Pis Mean                 3.9775217
Log Pis Std                  4.2820215
Log Pis Max                  14.322052
Log Pis Min                  -4.64402
Policy mu Mean               -0.11683782
Policy mu Std                1.3234988
Policy mu Max                2.8343866
Policy mu Min                -2.925865
Policy log std Mean          -0.71628016
Policy log std Std           0.3965344
Policy log std Max           0.050075054
Policy log std Min           -2.4810512
Z mean eval                  2.3391442
Z variance eval              0.041885473
total_rewards                [8327.12941636 8290.4072115  8473.63122203 8161.97332176 8559.80582311
 8386.10017227 8283.12868537 8332.35983624 8382.26589211 8473.41930014]
total_rewards_mean           8367.02208808868
total_rewards_std            108.71689168899319
total_rewards_max            8559.805823105464
total_rewards_min            8161.973321757022
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               26.9271873482503
(Previous) Eval Time (s)     23.65294193290174
Sample Time (s)              16.40759752318263
Epoch Time (s)               66.98772680433467
Total Train Time (s)         12791.024229587056
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:31:25.611817 UTC | [2020_01_10_08_58_14] Iteration #190 | Epoch Duration: 66.51802206039429
2020-01-10 12:31:25.612041 UTC | [2020_01_10_08_58_14] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3420525
Z variance train             0.04198535
KL Divergence                30.691883
KL Loss                      3.0691884
QF Loss                      392.90268
VF Loss                      220.44702
Policy Loss                  -2798.0078
Q Predictions Mean           2797.1519
Q Predictions Std            766.671
Q Predictions Max            3503.524
Q Predictions Min            105.78399
V Predictions Mean           2788.2935
V Predictions Std            762.53784
V Predictions Max            3483.2798
V Predictions Min            112.361084
Log Pis Mean                 4.136414
Log Pis Std                  4.237482
Log Pis Max                  15.605159
Log Pis Min                  -5.312605
Policy mu Mean               -0.11394793
Policy mu Std                1.3161156
Policy mu Max                2.7726686
Policy mu Min                -2.6509938
Policy log std Mean          -0.71292526
Policy log std Std           0.39260742
Policy log std Max           0.014297187
Policy log std Min           -2.6155086
Z mean eval                  2.355573
Z variance eval              0.049863257
total_rewards                [8099.57267924 8214.45748714 7966.43550788 8082.52007403 8170.33253646
 8235.26017926 8250.57590891 7926.71242667 8214.49531815 8273.18456188]
total_rewards_mean           8143.354667963688
total_rewards_std            114.67135105780947
total_rewards_max            8273.184561881351
total_rewards_min            7926.712426674151
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               26.899563420098275
(Previous) Eval Time (s)     23.182923197280616
Sample Time (s)              16.85676376754418
Epoch Time (s)               66.93925038492307
Total Train Time (s)         12857.471658656374
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:32:32.062303 UTC | [2020_01_10_08_58_14] Iteration #191 | Epoch Duration: 66.45007634162903
2020-01-10 12:32:32.062526 UTC | [2020_01_10_08_58_14] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3555634
Z variance train             0.04989576
KL Divergence                30.492027
KL Loss                      3.0492027
QF Loss                      318.51575
VF Loss                      83.94673
Policy Loss                  -2832.0337
Q Predictions Mean           2834.507
Q Predictions Std            785.7704
Q Predictions Max            3509.8013
Q Predictions Min            105.35854
V Predictions Mean           2831.027
V Predictions Std            783.2084
V Predictions Max            3493.9165
V Predictions Min            101.412735
Log Pis Mean                 4.134137
Log Pis Std                  4.5627303
Log Pis Max                  14.725544
Log Pis Min                  -6.757422
Policy mu Mean               -0.06384354
Policy mu Std                1.3579818
Policy mu Max                3.554637
Policy mu Min                -3.0006456
Policy log std Mean          -0.68851566
Policy log std Std           0.36745703
Policy log std Max           -0.08129874
Policy log std Min           -2.6037788
Z mean eval                  2.3610835
Z variance eval              0.043438673
total_rewards                [8030.83057704 8277.7167919  8148.0745208  8226.26117832 8314.18712838
 8390.91853949 8551.7529571  8117.29283041 8417.3891864  8329.79958929]
total_rewards_mean           8280.422329912402
total_rewards_std            147.48958820219391
total_rewards_max            8551.752957095154
total_rewards_min            8030.8305770377565
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               28.70394949382171
(Previous) Eval Time (s)     22.693435894325376
Sample Time (s)              15.718983478844166
Epoch Time (s)               67.11636886699125
Total Train Time (s)         12924.612419375684
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:33:39.207168 UTC | [2020_01_10_08_58_14] Iteration #192 | Epoch Duration: 67.14442300796509
2020-01-10 12:33:39.207443 UTC | [2020_01_10_08_58_14] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.361282
Z variance train             0.043428563
KL Divergence                30.62951
KL Loss                      3.062951
QF Loss                      581.0431
VF Loss                      131.57083
Policy Loss                  -2907.5876
Q Predictions Mean           2908.5835
Q Predictions Std            706.37695
Q Predictions Max            3646.8076
Q Predictions Min            93.03048
V Predictions Mean           2908.2476
V Predictions Std            701.2901
V Predictions Max            3661.7502
V Predictions Min            108.80224
Log Pis Mean                 4.680018
Log Pis Std                  4.0462503
Log Pis Max                  14.902395
Log Pis Min                  -5.9639144
Policy mu Mean               -0.047136825
Policy mu Std                1.367411
Policy mu Max                2.6600358
Policy mu Min                -2.727437
Policy log std Mean          -0.71884793
Policy log std Std           0.38044173
Policy log std Max           -0.058597326
Policy log std Min           -2.5590215
Z mean eval                  2.3756957
Z variance eval              0.030840289
total_rewards                [8390.81021702 8416.72256169 8481.69160565 8391.8061274  8362.25575112
 8459.99804383 8333.32433048 8423.08769181 8432.71218887 8074.34109167]
total_rewards_mean           8376.67496095465
total_rewards_std            108.99131689252502
total_rewards_max            8481.69160565397
total_rewards_min            8074.341091669013
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               27.28396455384791
(Previous) Eval Time (s)     22.72121734591201
Sample Time (s)              16.092718666419387
Epoch Time (s)               66.0979005661793
Total Train Time (s)         12991.02291196445
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:34:45.625919 UTC | [2020_01_10_08_58_14] Iteration #193 | Epoch Duration: 66.41824460029602
2020-01-10 12:34:45.626219 UTC | [2020_01_10_08_58_14] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3731353
Z variance train             0.030856302
KL Divergence                31.508198
KL Loss                      3.1508198
QF Loss                      309.92734
VF Loss                      222.17981
Policy Loss                  -2874.254
Q Predictions Mean           2876.5898
Q Predictions Std            719.14526
Q Predictions Max            3597.288
Q Predictions Min            95.64089
V Predictions Mean           2878.9097
V Predictions Std            716.75366
V Predictions Max            3595.4866
V Predictions Min            98.931015
Log Pis Mean                 4.2714243
Log Pis Std                  4.0346866
Log Pis Max                  16.312372
Log Pis Min                  -5.3997293
Policy mu Mean               -0.0202733
Policy mu Std                1.3568051
Policy mu Max                3.4008112
Policy mu Min                -3.1235092
Policy log std Mean          -0.71472025
Policy log std Std           0.40442154
Policy log std Max           -0.02037847
Policy log std Min           -2.624393
Z mean eval                  2.375939
Z variance eval              0.040511426
total_rewards                [8369.39457952 8400.78463361 8255.99631639 8551.91007522 8407.07367618
 6664.81304868 8396.28478815 8616.62717954 8434.95315839 8477.85643272]
total_rewards_mean           8257.569388838736
total_rewards_std            539.1692245814261
total_rewards_max            8616.62717954368
total_rewards_min            6664.81304867581
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               27.233883357141167
(Previous) Eval Time (s)     23.041231692302972
Sample Time (s)              15.69589197775349
Epoch Time (s)               65.97100702719763
Total Train Time (s)         13056.416371818632
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:35:51.020627 UTC | [2020_01_10_08_58_14] Iteration #194 | Epoch Duration: 65.39421892166138
2020-01-10 12:35:51.020800 UTC | [2020_01_10_08_58_14] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.377821
Z variance train             0.040584497
KL Divergence                30.674217
KL Loss                      3.0674217
QF Loss                      477.97842
VF Loss                      248.90215
Policy Loss                  -2967.0967
Q Predictions Mean           2969.9548
Q Predictions Std            700.9061
Q Predictions Max            3640.173
Q Predictions Min            106.01153
V Predictions Mean           2970.3433
V Predictions Std            693.76935
V Predictions Max            3644.1233
V Predictions Min            113.31803
Log Pis Mean                 4.484356
Log Pis Std                  4.4963193
Log Pis Max                  21.09056
Log Pis Min                  -6.5144005
Policy mu Mean               -0.08157747
Policy mu Std                1.3593086
Policy mu Max                3.3670635
Policy mu Min                -3.3246386
Policy log std Mean          -0.72843105
Policy log std Std           0.39735743
Policy log std Max           -0.051305473
Policy log std Min           -2.5267127
Z mean eval                  2.3447092
Z variance eval              0.06469049
total_rewards                [8113.22419281 8298.93009001 8390.85199067 8108.72288159 8463.69807911
 8113.41960342 8148.82689605 8235.27411206 8068.99373932 8359.77198083]
total_rewards_mean           8230.171356586621
total_rewards_std            132.8742293581832
total_rewards_max            8463.698079114994
total_rewards_min            8068.993739316273
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               28.446982834953815
(Previous) Eval Time (s)     22.46417522476986
Sample Time (s)              16.713842916302383
Epoch Time (s)               67.62500097602606
Total Train Time (s)         13124.138616885059
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:36:58.744731 UTC | [2020_01_10_08_58_14] Iteration #195 | Epoch Duration: 67.72380781173706
2020-01-10 12:36:58.744933 UTC | [2020_01_10_08_58_14] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.343614
Z variance train             0.06465931
KL Divergence                29.227604
KL Loss                      2.9227605
QF Loss                      559.39856
VF Loss                      530.5008
Policy Loss                  -2871.3433
Q Predictions Mean           2867.4697
Q Predictions Std            864.4531
Q Predictions Max            3664.0247
Q Predictions Min            86.202736
V Predictions Mean           2876.3582
V Predictions Std            857.1169
V Predictions Max            3684.0012
V Predictions Min            103.13432
Log Pis Mean                 4.0492954
Log Pis Std                  4.469695
Log Pis Max                  22.744265
Log Pis Min                  -5.6342077
Policy mu Mean               -0.056634262
Policy mu Std                1.3388158
Policy mu Max                3.8655927
Policy mu Min                -3.4484012
Policy log std Mean          -0.6826528
Policy log std Std           0.3819618
Policy log std Max           -0.027342439
Policy log std Min           -2.5858228
Z mean eval                  2.3513677
Z variance eval              0.05778972
total_rewards                [8128.88043663 8562.24921846 8513.68037408 8673.26121751 8608.30267293
 8655.68766265 8649.75262218 8677.34645187 8769.62571386 8675.31815379]
total_rewards_mean           8591.410452396327
total_rewards_std            167.78939159076708
total_rewards_max            8769.625713864401
total_rewards_min            8128.880436626904
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               26.723139551933855
(Previous) Eval Time (s)     22.562683107797056
Sample Time (s)              16.136234586592764
Epoch Time (s)               65.42205724632367
Total Train Time (s)         13188.99335677037
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:38:03.604110 UTC | [2020_01_10_08_58_14] Iteration #196 | Epoch Duration: 64.85900926589966
2020-01-10 12:38:03.604385 UTC | [2020_01_10_08_58_14] Iteration #196 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.35211
Z variance train             0.057826452
KL Divergence                29.235855
KL Loss                      2.9235857
QF Loss                      407.37433
VF Loss                      199.4093
Policy Loss                  -2959.453
Q Predictions Mean           2961.4736
Q Predictions Std            748.25366
Q Predictions Max            3746.8044
Q Predictions Min            119.63585
V Predictions Mean           2953.2852
V Predictions Std            746.0738
V Predictions Max            3707.423
V Predictions Min            109.03193
Log Pis Mean                 3.9285011
Log Pis Std                  4.1120677
Log Pis Max                  14.241347
Log Pis Min                  -6.2069893
Policy mu Mean               -0.021411607
Policy mu Std                1.3202115
Policy mu Max                2.8186176
Policy mu Min                -2.946213
Policy log std Mean          -0.69529766
Policy log std Std           0.37896517
Policy log std Max           -0.056745946
Policy log std Min           -2.4215958
Z mean eval                  2.3628733
Z variance eval              0.06110841
total_rewards                [8547.98385423 8519.83680214 8358.82157883 8577.32304219 8519.3271783
 8395.22377037 8522.71745622 8157.50197553 8506.94899419 8542.54363468]
total_rewards_mean           8464.82282866699
total_rewards_std            121.35181979889573
total_rewards_max            8577.323042186032
total_rewards_min            8157.501975530957
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               29.866797507274896
(Previous) Eval Time (s)     21.99935041088611
Sample Time (s)              17.326571948826313
Epoch Time (s)               69.19271986698732
Total Train Time (s)         13259.001276470255
Epoch                        197
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:39:13.616213 UTC | [2020_01_10_08_58_14] Iteration #197 | Epoch Duration: 70.01159238815308
2020-01-10 12:39:13.616510 UTC | [2020_01_10_08_58_14] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3667655
Z variance train             0.061110146
KL Divergence                29.403805
KL Loss                      2.9403806
QF Loss                      452.85272
VF Loss                      189.52054
Policy Loss                  -2865.725
Q Predictions Mean           2872.045
Q Predictions Std            786.5595
Q Predictions Max            3658.6868
Q Predictions Min            113.28818
V Predictions Mean           2872.3428
V Predictions Std            785.60675
V Predictions Max            3642.9915
V Predictions Min            105.516914
Log Pis Mean                 4.3255005
Log Pis Std                  3.988707
Log Pis Max                  13.51125
Log Pis Min                  -6.5084295
Policy mu Mean               -0.09598418
Policy mu Std                1.342511
Policy mu Max                3.1201108
Policy mu Min                -3.2296264
Policy log std Mean          -0.72274786
Policy log std Std           0.38159773
Policy log std Max           -0.008291423
Policy log std Min           -2.537974
Z mean eval                  2.4041224
Z variance eval              0.043267682
total_rewards                [8660.81688462 8462.83086093 8491.3652004  8448.30515326 8468.74444099
 8385.09947594 8746.87469991 8460.41591774 8612.53661231 8772.12501777]
total_rewards_mean           8550.91142638595
total_rewards_std            129.4142073649466
total_rewards_max            8772.125017767265
total_rewards_min            8385.0994759445
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               27.592720602173358
(Previous) Eval Time (s)     22.817944996990263
Sample Time (s)              16.023209740407765
Epoch Time (s)               66.43387533957139
Total Train Time (s)         13324.722154915798
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:40:19.337290 UTC | [2020_01_10_08_58_14] Iteration #198 | Epoch Duration: 65.7205867767334
2020-01-10 12:40:19.337430 UTC | [2020_01_10_08_58_14] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.406162
Z variance train             0.04331636
KL Divergence                30.740326
KL Loss                      3.0740325
QF Loss                      350.43378
VF Loss                      443.659
Policy Loss                  -2746.8606
Q Predictions Mean           2741.7217
Q Predictions Std            793.8596
Q Predictions Max            3518.9927
Q Predictions Min            49.981876
V Predictions Mean           2730.4988
V Predictions Std            782.63196
V Predictions Max            3491.8152
V Predictions Min            99.13592
Log Pis Mean                 3.9140034
Log Pis Std                  4.230079
Log Pis Max                  13.608828
Log Pis Min                  -4.283388
Policy mu Mean               -0.04701802
Policy mu Std                1.316208
Policy mu Max                2.9409063
Policy mu Min                -2.8454802
Policy log std Mean          -0.7146632
Policy log std Std           0.39109313
Policy log std Max           0.025602877
Policy log std Min           -2.5596206
Z mean eval                  2.3980181
Z variance eval              0.027684068
total_rewards                [8003.16625828 8320.70698559 8328.27819649 8156.32114188 8396.61043157
 8216.88345933 8174.82945286 8553.19449644 8231.93310058 8353.09407448]
total_rewards_mean           8273.501759749424
total_rewards_std            143.67668218682218
total_rewards_max            8553.194496440878
total_rewards_min            8003.1662582754
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               27.88447435060516
(Previous) Eval Time (s)     22.10437497217208
Sample Time (s)              15.646603694651276
Epoch Time (s)               65.63545301742852
Total Train Time (s)         13390.852456714027
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:41:25.472669 UTC | [2020_01_10_08_58_14] Iteration #199 | Epoch Duration: 66.13506436347961
2020-01-10 12:41:25.472949 UTC | [2020_01_10_08_58_14] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3970854
Z variance train             0.02767999
KL Divergence                31.716162
KL Loss                      3.1716163
QF Loss                      421.9938
VF Loss                      159.77199
Policy Loss                  -2905.4353
Q Predictions Mean           2905.4019
Q Predictions Std            789.52045
Q Predictions Max            3682.362
Q Predictions Min            85.51595
V Predictions Mean           2903.4712
V Predictions Std            783.93933
V Predictions Max            3667.155
V Predictions Min            99.77877
Log Pis Mean                 4.3148375
Log Pis Std                  3.9629524
Log Pis Max                  12.756016
Log Pis Min                  -5.198099
Policy mu Mean               -0.054020345
Policy mu Std                1.3508743
Policy mu Max                2.8317287
Policy mu Min                -2.6720061
Policy log std Mean          -0.7140953
Policy log std Std           0.39971307
Policy log std Max           0.025058687
Policy log std Min           -2.4912148
Z mean eval                  2.3824162
Z variance eval              0.027053824
total_rewards                [8292.6735954  8458.35602967 8444.98861152 8431.51729997 8395.70228513
 8566.40907866 8534.77780741 8265.49023895 8608.87557444 8290.8858025 ]
total_rewards_mean           8428.96763236612
total_rewards_std            113.6018310292215
total_rewards_max            8608.875574443904
total_rewards_min            8265.490238952565
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               28.72838112199679
(Previous) Eval Time (s)     22.603704610839486
Sample Time (s)              16.677743518259376
Epoch Time (s)               68.00982925109565
Total Train Time (s)         13458.556258856319
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:42:33.178025 UTC | [2020_01_10_08_58_14] Iteration #200 | Epoch Duration: 67.70488715171814
2020-01-10 12:42:33.178188 UTC | [2020_01_10_08_58_14] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.382988
Z variance train             0.027119432
KL Divergence                31.66888
KL Loss                      3.166888
QF Loss                      251.26291
VF Loss                      161.86124
Policy Loss                  -2840.194
Q Predictions Mean           2839.8638
Q Predictions Std            906.51495
Q Predictions Max            3637.368
Q Predictions Min            107.13115
V Predictions Mean           2838.7295
V Predictions Std            905.6398
V Predictions Max            3622.4436
V Predictions Min            105.802826
Log Pis Mean                 4.5463567
Log Pis Std                  4.296585
Log Pis Max                  16.706587
Log Pis Min                  -6.324287
Policy mu Mean               -0.0116716
Policy mu Std                1.3761412
Policy mu Max                3.7296743
Policy mu Min                -4.0726223
Policy log std Mean          -0.6973246
Policy log std Std           0.39800212
Policy log std Max           0.11307824
Policy log std Min           -2.4962265
Z mean eval                  2.4265037
Z variance eval              0.017468961
total_rewards                [8960.68245234 8596.89912754 8581.99961726 8670.61298628 8551.32536917
 8926.26578761 8698.7427633  8670.93724969 8788.17784257 8596.92426957]
total_rewards_mean           8704.256746535559
total_rewards_std            136.2857782638167
total_rewards_max            8960.68245234278
total_rewards_min            8551.325369171915
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               28.947098749224097
(Previous) Eval Time (s)     22.298468528781086
Sample Time (s)              15.211020766757429
Epoch Time (s)               66.45658804476261
Total Train Time (s)         13525.45623600157
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:43:40.079045 UTC | [2020_01_10_08_58_14] Iteration #201 | Epoch Duration: 66.90073013305664
2020-01-10 12:43:40.079201 UTC | [2020_01_10_08_58_14] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4253361
Z variance train             0.017443065
KL Divergence                33.132805
KL Loss                      3.3132806
QF Loss                      301.32574
VF Loss                      220.18684
Policy Loss                  -2990.7266
Q Predictions Mean           2991.8232
Q Predictions Std            682.4229
Q Predictions Max            3628.192
Q Predictions Min            99.23203
V Predictions Mean           2996.3796
V Predictions Std            682.0445
V Predictions Max            3611.1917
V Predictions Min            98.1215
Log Pis Mean                 4.9181633
Log Pis Std                  4.20244
Log Pis Max                  15.800909
Log Pis Min                  -5.4461107
Policy mu Mean               -0.08937695
Policy mu Std                1.3883078
Policy mu Max                3.450163
Policy mu Min                -3.383181
Policy log std Mean          -0.7212308
Policy log std Std           0.40086257
Policy log std Max           0.07827985
Policy log std Min           -2.5896678
Z mean eval                  2.404757
Z variance eval              0.012981494
total_rewards                [8578.62888989 8363.77634913 8835.21668703 8528.10709864 8551.67145564
 8734.88492267 8811.001207   8351.42098012 8586.62565918 8661.41359961]
total_rewards_mean           8600.27468489022
total_rewards_std            157.33600809574907
total_rewards_max            8835.216687027985
total_rewards_min            8351.420980120243
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               27.45307666109875
(Previous) Eval Time (s)     22.742354582063854
Sample Time (s)              15.67579838912934
Epoch Time (s)               65.87122963229194
Total Train Time (s)         13591.036290837452
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:44:45.662342 UTC | [2020_01_10_08_58_14] Iteration #202 | Epoch Duration: 65.5829963684082
2020-01-10 12:44:45.662582 UTC | [2020_01_10_08_58_14] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4045665
Z variance train             0.012946715
KL Divergence                33.808304
KL Loss                      3.3808305
QF Loss                      306.7464
VF Loss                      202.74586
Policy Loss                  -2935.1912
Q Predictions Mean           2934.5454
Q Predictions Std            742.7476
Q Predictions Max            3652.0525
Q Predictions Min            103.88329
V Predictions Mean           2928.045
V Predictions Std            737.9934
V Predictions Max            3651.8865
V Predictions Min            99.5002
Log Pis Mean                 4.5214596
Log Pis Std                  4.266151
Log Pis Max                  15.861709
Log Pis Min                  -5.082247
Policy mu Mean               -0.032246668
Policy mu Std                1.3861208
Policy mu Max                3.04034
Policy mu Min                -2.7590194
Policy log std Mean          -0.726309
Policy log std Std           0.40044916
Policy log std Max           0.045541227
Policy log std Min           -2.5124664
Z mean eval                  2.3834229
Z variance eval              0.011389143
total_rewards                [8121.75879594 8530.19182245 8379.00253654 3985.44528584 8551.11753147
 8417.77902016 8341.05893182 8522.29032992 7918.89411024 8152.9528785 ]
total_rewards_mean           7892.049124289219
total_rewards_std            1316.7018686202207
total_rewards_max            8551.117531471955
total_rewards_min            3985.4452858408335
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               29.848671582061797
(Previous) Eval Time (s)     22.453832416795194
Sample Time (s)              15.907044124789536
Epoch Time (s)               68.20954812364653
Total Train Time (s)         13659.228977226652
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:45:53.855560 UTC | [2020_01_10_08_58_14] Iteration #203 | Epoch Duration: 68.19281053543091
2020-01-10 12:45:53.855714 UTC | [2020_01_10_08_58_14] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3824868
Z variance train             0.011384684
KL Divergence                33.83483
KL Loss                      3.3834832
QF Loss                      321.4516
VF Loss                      186.5463
Policy Loss                  -2983.83
Q Predictions Mean           2981.3228
Q Predictions Std            679.91956
Q Predictions Max            3690.056
Q Predictions Min            100.77748
V Predictions Mean           2985.0322
V Predictions Std            679.6521
V Predictions Max            3676.2166
V Predictions Min            99.78773
Log Pis Mean                 4.402855
Log Pis Std                  4.1735277
Log Pis Max                  15.395082
Log Pis Min                  -6.3720207
Policy mu Mean               -0.06313164
Policy mu Std                1.3659942
Policy mu Max                2.9238737
Policy mu Min                -2.852354
Policy log std Mean          -0.73340917
Policy log std Std           0.40594113
Policy log std Max           0.13000536
Policy log std Min           -2.5935678
Z mean eval                  2.3812127
Z variance eval              0.015264278
total_rewards                [8458.24245954 8675.51237373 8577.42454786 8679.79678696 8683.30695777
 8688.53327045 8598.13142845 8799.22059893 8475.76430853 8509.6894722 ]
total_rewards_mean           8614.562220440883
total_rewards_std            104.21849198760775
total_rewards_max            8799.22059893033
total_rewards_min            8458.242459542498
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               29.004547358956188
(Previous) Eval Time (s)     22.43685028096661
Sample Time (s)              16.17820713110268
Epoch Time (s)               67.61960477102548
Total Train Time (s)         13726.85858551599
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:47:01.489393 UTC | [2020_01_10_08_58_14] Iteration #204 | Epoch Duration: 67.63355541229248
2020-01-10 12:47:01.489571 UTC | [2020_01_10_08_58_14] Iteration #204 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.384077
Z variance train             0.015267688
KL Divergence                33.21787
KL Loss                      3.3217869
QF Loss                      508.2172
VF Loss                      254.0551
Policy Loss                  -2951.1687
Q Predictions Mean           2953.0603
Q Predictions Std            629.2523
Q Predictions Max            3573.1743
Q Predictions Min            105.82445
V Predictions Mean           2941.874
V Predictions Std            623.95966
V Predictions Max            3581.8086
V Predictions Min            98.9976
Log Pis Mean                 4.424465
Log Pis Std                  4.058816
Log Pis Max                  13.538147
Log Pis Min                  -8.635189
Policy mu Mean               -0.070910946
Policy mu Std                1.3536534
Policy mu Max                3.030992
Policy mu Min                -3.2175937
Policy log std Mean          -0.7430186
Policy log std Std           0.39154518
Policy log std Max           -0.07529318
Policy log std Min           -2.5897012
Z mean eval                  2.381453
Z variance eval              0.019001087
total_rewards                [8600.2179578  8724.84744725 8763.38068178 8636.85457777 8914.4436775
 8769.15484176 8742.42551765 8662.4874666  8802.90068443 9083.04391617]
total_rewards_mean           8769.975676871018
total_rewards_std            134.49875220796716
total_rewards_max            9083.043916167622
total_rewards_min            8600.217957802268
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               26.95965844159946
(Previous) Eval Time (s)     22.450479903724045
Sample Time (s)              15.855599089991301
Epoch Time (s)               65.2657374353148
Total Train Time (s)         13791.561653727666
Epoch                        205
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:48:06.196331 UTC | [2020_01_10_08_58_14] Iteration #205 | Epoch Duration: 64.70659875869751
2020-01-10 12:48:06.196584 UTC | [2020_01_10_08_58_14] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3806405
Z variance train             0.019005362
KL Divergence                32.578644
KL Loss                      3.2578645
QF Loss                      349.4648
VF Loss                      106.14363
Policy Loss                  -3009.8398
Q Predictions Mean           3006.4653
Q Predictions Std            652.38464
Q Predictions Max            3645.2273
Q Predictions Min            81.57622
V Predictions Mean           3012.112
V Predictions Std            647.35876
V Predictions Max            3645.808
V Predictions Min            102.89305
Log Pis Mean                 4.7423134
Log Pis Std                  4.1198545
Log Pis Max                  15.794085
Log Pis Min                  -6.114236
Policy mu Mean               -0.07095737
Policy mu Std                1.368751
Policy mu Max                3.0530064
Policy mu Min                -3.202915
Policy log std Mean          -0.7276295
Policy log std Std           0.3929312
Policy log std Max           -0.034632802
Policy log std Min           -2.5108113
Z mean eval                  2.372077
Z variance eval              0.021476675
total_rewards                [8296.89796851 8246.35971278 8446.69549897 8338.39807879 8176.12026338
 8641.0656776  8484.03900572 8754.4749945  8445.79238536 8272.00641677]
total_rewards_mean           8410.185000238307
total_rewards_std            172.80117600258103
total_rewards_max            8754.474994503715
total_rewards_min            8176.1202633829425
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               26.369542963802814
(Previous) Eval Time (s)     21.891075102146715
Sample Time (s)              16.46683622011915
Epoch Time (s)               64.72745428606868
Total Train Time (s)         13856.391363230068
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:49:11.029284 UTC | [2020_01_10_08_58_14] Iteration #206 | Epoch Duration: 64.83249735832214
2020-01-10 12:49:11.029550 UTC | [2020_01_10_08_58_14] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3704445
Z variance train             0.021515787
KL Divergence                31.950314
KL Loss                      3.1950314
QF Loss                      408.59186
VF Loss                      193.03644
Policy Loss                  -3008.0212
Q Predictions Mean           3013.278
Q Predictions Std            551.7405
Q Predictions Max            3611.663
Q Predictions Min            102.436195
V Predictions Mean           3014.5505
V Predictions Std            549.98254
V Predictions Max            3624.4565
V Predictions Min            99.99178
Log Pis Mean                 3.885549
Log Pis Std                  3.6802087
Log Pis Max                  12.886637
Log Pis Min                  -7.775446
Policy mu Mean               -0.06885907
Policy mu Std                1.3212495
Policy mu Max                2.8701186
Policy mu Min                -2.530568
Policy log std Mean          -0.7500976
Policy log std Std           0.36538613
Policy log std Max           -0.11946556
Policy log std Min           -2.4911058
Z mean eval                  2.3757699
Z variance eval              0.03015678
total_rewards                [8449.31813208 8715.20015724 8839.12244683 8619.12069943 8660.51327634
 8679.60340193 8592.44084808 8358.10204557 8632.79696254 8674.4174585 ]
total_rewards_mean           8622.063542854432
total_rewards_std            127.99889307009127
total_rewards_max            8839.122446832469
total_rewards_min            8358.102045567546
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               26.89233466098085
(Previous) Eval Time (s)     21.99581816419959
Sample Time (s)              16.092163702938706
Epoch Time (s)               64.98031652811915
Total Train Time (s)         13921.866004684009
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:50:16.507408 UTC | [2020_01_10_08_58_14] Iteration #207 | Epoch Duration: 65.47763204574585
2020-01-10 12:50:16.507689 UTC | [2020_01_10_08_58_14] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3760118
Z variance train             0.030171072
KL Divergence                31.776787
KL Loss                      3.1776788
QF Loss                      275.5224
VF Loss                      116.56048
Policy Loss                  -3191.7275
Q Predictions Mean           3191.9695
Q Predictions Std            448.37515
Q Predictions Max            3747.7788
Q Predictions Min            104.056145
V Predictions Mean           3194.0847
V Predictions Std            443.47052
V Predictions Max            3753.6797
V Predictions Min            107.86368
Log Pis Mean                 4.536038
Log Pis Std                  3.7410502
Log Pis Max                  12.980545
Log Pis Min                  -3.9804254
Policy mu Mean               -0.066894166
Policy mu Std                1.3494023
Policy mu Max                2.999574
Policy mu Min                -2.5585067
Policy log std Mean          -0.7565155
Policy log std Std           0.40076384
Policy log std Max           -0.11246914
Policy log std Min           -2.544021
Z mean eval                  2.3754954
Z variance eval              0.02472738
total_rewards                [8487.38732787 8741.98299494 8336.85366668 8303.36978707 8488.4389277
 8564.92809625 8759.42387522 8496.1342012  8417.7114387  8463.22118996]
total_rewards_mean           8505.945150558862
total_rewards_std            142.62912171031041
total_rewards_max            8759.423875217184
total_rewards_min            8303.36978706529
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               28.63780190004036
(Previous) Eval Time (s)     22.492847017012537
Sample Time (s)              15.740093887783587
Epoch Time (s)               66.87074280483648
Total Train Time (s)         13988.747669422999
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:51:23.390640 UTC | [2020_01_10_08_58_14] Iteration #208 | Epoch Duration: 66.88271021842957
2020-01-10 12:51:23.390846 UTC | [2020_01_10_08_58_14] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3750033
Z variance train             0.024678579
KL Divergence                31.953074
KL Loss                      3.1953075
QF Loss                      353.40796
VF Loss                      201.34883
Policy Loss                  -3057.6038
Q Predictions Mean           3059.3105
Q Predictions Std            692.3723
Q Predictions Max            3738.1294
Q Predictions Min            97.60411
V Predictions Mean           3062.9192
V Predictions Std            687.80914
V Predictions Max            3738.7156
V Predictions Min            98.725555
Log Pis Mean                 4.5157394
Log Pis Std                  4.30589
Log Pis Max                  26.669094
Log Pis Min                  -6.5157347
Policy mu Mean               -0.06340352
Policy mu Std                1.3834782
Policy mu Max                4.7568207
Policy mu Min                -3.7553525
Policy log std Mean          -0.7475002
Policy log std Std           0.40916333
Policy log std Max           -0.041282296
Policy log std Min           -2.6974747
Z mean eval                  2.3783164
Z variance eval              0.022580016
total_rewards                [8835.66763297 8641.77410716 8733.04291362 8896.06285095 8904.87040046
 8738.90607379 8774.5917362  8890.67958783 8750.99546873 8589.76040742]
total_rewards_mean           8775.63511791226
total_rewards_std            102.11915969623267
total_rewards_max            8904.870400458882
total_rewards_min            8589.760407415868
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               25.779497555922717
(Previous) Eval Time (s)     22.504516707267612
Sample Time (s)              15.43374517839402
Epoch Time (s)               63.71775944158435
Total Train Time (s)         14052.58085425105
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:52:27.228075 UTC | [2020_01_10_08_58_14] Iteration #209 | Epoch Duration: 63.83704209327698
2020-01-10 12:52:27.228715 UTC | [2020_01_10_08_58_14] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3800464
Z variance train             0.02256682
KL Divergence                32.163776
KL Loss                      3.2163777
QF Loss                      376.57208
VF Loss                      89.48132
Policy Loss                  -3115.6626
Q Predictions Mean           3121.1594
Q Predictions Std            501.79373
Q Predictions Max            3705.3425
Q Predictions Min            111.11049
V Predictions Mean           3115.8115
V Predictions Std            497.95798
V Predictions Max            3693.3894
V Predictions Min            106.55752
Log Pis Mean                 4.640293
Log Pis Std                  3.8764863
Log Pis Max                  13.867203
Log Pis Min                  -4.5108624
Policy mu Mean               -0.07438538
Policy mu Std                1.377432
Policy mu Max                2.8956623
Policy mu Min                -2.701076
Policy log std Mean          -0.7156842
Policy log std Std           0.3821967
Policy log std Max           0.010691911
Policy log std Min           -2.6953385
Z mean eval                  2.3549864
Z variance eval              0.030612629
total_rewards                [8772.89863732 8785.40393286 8795.04691403 8782.49702143 8757.80202985
 8921.70209686 8755.31508774 8774.311611   8518.99974264 8798.38855531]
total_rewards_mean           8766.236562903508
total_rewards_std            93.85689355556536
total_rewards_max            8921.702096857134
total_rewards_min            8518.99974263538
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               24.489833471830934
(Previous) Eval Time (s)     22.623523021116853
Sample Time (s)              15.487511342857033
Epoch Time (s)               62.60086783580482
Total Train Time (s)         14114.6877151886
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:53:29.336561 UTC | [2020_01_10_08_58_14] Iteration #210 | Epoch Duration: 62.107544898986816
2020-01-10 12:53:29.336730 UTC | [2020_01_10_08_58_14] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3558168
Z variance train             0.030610248
KL Divergence                31.13786
KL Loss                      3.113786
QF Loss                      236.79596
VF Loss                      243.3261
Policy Loss                  -3036.849
Q Predictions Mean           3040.3828
Q Predictions Std            528.5657
Q Predictions Max            3625.0994
Q Predictions Min            79.216095
V Predictions Mean           3046.8774
V Predictions Std            528.1869
V Predictions Max            3620.1802
V Predictions Min            87.6882
Log Pis Mean                 4.6486855
Log Pis Std                  3.4616485
Log Pis Max                  13.306471
Log Pis Min                  -4.3390465
Policy mu Mean               -0.04250367
Policy mu Std                1.3546666
Policy mu Max                3.0942318
Policy mu Min                -2.7318864
Policy log std Mean          -0.7479599
Policy log std Std           0.40790844
Policy log std Max           0.004997909
Policy log std Min           -2.5293572
Z mean eval                  2.4018831
Z variance eval              0.020049233
total_rewards                [8544.91573025 8788.92216856 8716.72671994 8680.54768552 8830.53993965
 8674.89705356 8793.70265404 8928.81595363 8725.24996052 8998.03793207]
total_rewards_mean           8768.235579774042
total_rewards_std            124.22859825556421
total_rewards_max            8998.037932069361
total_rewards_min            8544.915730254623
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               27.27446846710518
(Previous) Eval Time (s)     22.129955056123435
Sample Time (s)              15.30106051499024
Epoch Time (s)               64.70548403821886
Total Train Time (s)         14179.348494844045
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:54:34.001991 UTC | [2020_01_10_08_58_14] Iteration #211 | Epoch Duration: 64.66510319709778
2020-01-10 12:54:34.002253 UTC | [2020_01_10_08_58_14] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.402392
Z variance train             0.020180423
KL Divergence                32.838177
KL Loss                      3.2838178
QF Loss                      483.04007
VF Loss                      286.26218
Policy Loss                  -3092.3718
Q Predictions Mean           3088.7483
Q Predictions Std            447.75027
Q Predictions Max            3637.7642
Q Predictions Min            120.94449
V Predictions Mean           3093.2312
V Predictions Std            441.78223
V Predictions Max            3635.1707
V Predictions Min            114.97541
Log Pis Mean                 5.1084156
Log Pis Std                  3.9736753
Log Pis Max                  15.584871
Log Pis Min                  -5.104475
Policy mu Mean               -0.046930403
Policy mu Std                1.3925914
Policy mu Max                2.9800758
Policy mu Min                -2.9072964
Policy log std Mean          -0.7622916
Policy log std Std           0.3987185
Policy log std Max           -0.14297204
Policy log std Min           -2.6032977
Z mean eval                  2.4010649
Z variance eval              0.025654677
total_rewards                [8690.80184516 8787.07509943 8984.06058839 9023.02829533 8519.04893471
  609.93176223 8735.61707925 8699.11913342 8935.78545162 9023.30621581]
total_rewards_mean           8000.777440535067
total_rewards_std            2468.7430186271936
total_rewards_max            9023.306215807388
total_rewards_min            609.9317622326682
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               27.133620756212622
(Previous) Eval Time (s)     22.08927520783618
Sample Time (s)              15.896963622421026
Epoch Time (s)               65.11985958646983
Total Train Time (s)         14244.988617054187
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:55:39.645023 UTC | [2020_01_10_08_58_14] Iteration #212 | Epoch Duration: 65.6425621509552
2020-01-10 12:55:39.645263 UTC | [2020_01_10_08_58_14] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4012148
Z variance train             0.025707256
KL Divergence                32.806488
KL Loss                      3.280649
QF Loss                      1029.0596
VF Loss                      214.35889
Policy Loss                  -3091.021
Q Predictions Mean           3096.2617
Q Predictions Std            573.81995
Q Predictions Max            3671.4543
Q Predictions Min            99.114525
V Predictions Mean           3100.5308
V Predictions Std            571.36505
V Predictions Max            3664.0999
V Predictions Min            98.56006
Log Pis Mean                 4.6512423
Log Pis Std                  3.6965082
Log Pis Max                  15.332117
Log Pis Min                  -3.7704198
Policy mu Mean               -0.04668984
Policy mu Std                1.3598185
Policy mu Max                3.2366245
Policy mu Min                -3.3629434
Policy log std Mean          -0.73765534
Policy log std Std           0.3754353
Policy log std Max           -0.043423593
Policy log std Min           -2.565921
Z mean eval                  2.3989916
Z variance eval              0.016317867
total_rewards                [8643.13724679 8672.11673921 8712.74149565 8865.21993221 8960.83995611
 8912.82009718 8867.81600736 8691.35628219 8713.86426272 8997.91044434]
total_rewards_mean           8803.782246377341
total_rewards_std            124.20665332189759
total_rewards_max            8997.910444339794
total_rewards_min            8643.137246793216
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               28.84483715193346
(Previous) Eval Time (s)     22.611720220651478
Sample Time (s)              16.43895466485992
Epoch Time (s)               67.89551203744486
Total Train Time (s)         14312.677885415964
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:56:47.335398 UTC | [2020_01_10_08_58_14] Iteration #213 | Epoch Duration: 67.6899619102478
2020-01-10 12:56:47.335547 UTC | [2020_01_10_08_58_14] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.3974798
Z variance train             0.016354349
KL Divergence                33.675846
KL Loss                      3.3675847
QF Loss                      373.46848
VF Loss                      118.95739
Policy Loss                  -3172.291
Q Predictions Mean           3170.298
Q Predictions Std            398.79388
Q Predictions Max            3662.4814
Q Predictions Min            84.09947
V Predictions Mean           3172.6926
V Predictions Std            393.17883
V Predictions Max            3657.574
V Predictions Min            104.4032
Log Pis Mean                 4.850882
Log Pis Std                  4.085786
Log Pis Max                  14.977909
Log Pis Min                  -6.31851
Policy mu Mean               -0.019732162
Policy mu Std                1.3996043
Policy mu Max                3.1654804
Policy mu Min                -2.7330742
Policy log std Mean          -0.76452494
Policy log std Std           0.4036779
Policy log std Max           -0.023335412
Policy log std Min           -2.550396
Z mean eval                  2.411513
Z variance eval              0.01844395
total_rewards                [8452.03422499 8253.35764683 8578.87354644 8758.81805181 8469.24024872
 8813.05678696 8583.94814432 8741.95227958 8993.86457646 8741.412324  ]
total_rewards_mean           8638.655783011469
total_rewards_std            202.68393260231417
total_rewards_max            8993.86457646148
total_rewards_min            8253.357646829256
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               27.288555515930057
(Previous) Eval Time (s)     22.40586311975494
Sample Time (s)              15.328563487157226
Epoch Time (s)               65.02298212284222
Total Train Time (s)         14377.33396814391
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:57:51.994527 UTC | [2020_01_10_08_58_14] Iteration #214 | Epoch Duration: 64.65885186195374
2020-01-10 12:57:51.994730 UTC | [2020_01_10_08_58_14] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4121697
Z variance train             0.018415498
KL Divergence                34.26426
KL Loss                      3.426426
QF Loss                      371.37366
VF Loss                      105.130295
Policy Loss                  -3196.7222
Q Predictions Mean           3200.6257
Q Predictions Std            367.51117
Q Predictions Max            3824.0913
Q Predictions Min            2398.3328
V Predictions Mean           3195.9187
V Predictions Std            362.73785
V Predictions Max            3815.5276
V Predictions Min            2410.5486
Log Pis Mean                 4.4786777
Log Pis Std                  3.9519725
Log Pis Max                  16.693327
Log Pis Min                  -5.806325
Policy mu Mean               -0.090308465
Policy mu Std                1.3640891
Policy mu Max                2.9418697
Policy mu Min                -2.6939073
Policy log std Mean          -0.7346456
Policy log std Std           0.38108155
Policy log std Max           -0.061723173
Policy log std Min           -2.6631718
Z mean eval                  2.4129844
Z variance eval              0.014142427
total_rewards                [8567.70911716 9189.31977477 8912.26764892 8944.1323021  8748.19225155
 8926.07220737 9030.27436601 8965.35853041 9027.24312847 8965.61055442]
total_rewards_mean           8927.617988117505
total_rewards_std            159.3919209174821
total_rewards_max            9189.31977477414
total_rewards_min            8567.709117155138
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               29.227550104260445
(Previous) Eval Time (s)     22.041456369683146
Sample Time (s)              16.334491519723088
Epoch Time (s)               67.60349799366668
Total Train Time (s)         14445.00402546674
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 12:58:59.667929 UTC | [2020_01_10_08_58_14] Iteration #215 | Epoch Duration: 67.67304754257202
2020-01-10 12:58:59.668161 UTC | [2020_01_10_08_58_14] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4130292
Z variance train             0.014117028
KL Divergence                35.04625
KL Loss                      3.504625
QF Loss                      344.78253
VF Loss                      181.24129
Policy Loss                  -3189.1277
Q Predictions Mean           3193.4126
Q Predictions Std            385.34967
Q Predictions Max            3747.4358
Q Predictions Min            132.60358
V Predictions Mean           3192.4807
V Predictions Std            382.65533
V Predictions Max            3758.0442
V Predictions Min            139.20396
Log Pis Mean                 5.060122
Log Pis Std                  3.6683092
Log Pis Max                  12.726234
Log Pis Min                  -3.557163
Policy mu Mean               -0.023621982
Policy mu Std                1.4182512
Policy mu Max                2.9194825
Policy mu Min                -2.6378896
Policy log std Mean          -0.76861745
Policy log std Std           0.4020728
Policy log std Max           -0.13920802
Policy log std Min           -2.697979
Z mean eval                  2.423393
Z variance eval              0.018231181
total_rewards                [8824.21539157 8922.82724149 9074.458611   8950.95118914 8710.64858099
 8742.81777528 9225.42713736 9038.07972338 8740.79196669 8909.99984925]
total_rewards_mean           8914.021746615563
total_rewards_std            157.5773984155736
total_rewards_max            9225.427137357228
total_rewards_min            8710.648580992261
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               28.861756169237196
(Previous) Eval Time (s)     22.110711350105703
Sample Time (s)              17.199348282068968
Epoch Time (s)               68.17181580141187
Total Train Time (s)         14513.477588983718
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:00:08.144240 UTC | [2020_01_10_08_58_14] Iteration #216 | Epoch Duration: 68.4759042263031
2020-01-10 13:00:08.144433 UTC | [2020_01_10_08_58_14] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4240086
Z variance train             0.018315244
KL Divergence                34.634396
KL Loss                      3.4634397
QF Loss                      344.67874
VF Loss                      111.783195
Policy Loss                  -3185.9424
Q Predictions Mean           3192.6782
Q Predictions Std            316.01315
Q Predictions Max            3704.171
Q Predictions Min            2349.7566
V Predictions Mean           3184.3389
V Predictions Std            311.7502
V Predictions Max            3697.0168
V Predictions Min            2343.8691
Log Pis Mean                 5.2776403
Log Pis Std                  4.1740823
Log Pis Max                  18.209854
Log Pis Min                  -7.602289
Policy mu Mean               -0.052956063
Policy mu Std                1.4307626
Policy mu Max                2.8173378
Policy mu Min                -2.57211
Policy log std Mean          -0.77563125
Policy log std Std           0.40999827
Policy log std Max           -0.01156649
Policy log std Min           -2.6626863
Z mean eval                  2.4443307
Z variance eval              0.017968984
total_rewards                [8773.06603261 8594.63669575 8827.62235382 8893.09796107 8930.75016275
 9050.76286689 8916.23173038 8945.34462859 9023.21271532 9027.5870652 ]
total_rewards_mean           8898.231221236098
total_rewards_std            131.1748097247799
total_rewards_max            9050.762866888479
total_rewards_min            8594.636695749261
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               28.170570365618914
(Previous) Eval Time (s)     22.414492845069617
Sample Time (s)              16.303924622479826
Epoch Time (s)               66.88898783316836
Total Train Time (s)         14580.66519923415
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:01:15.333594 UTC | [2020_01_10_08_58_14] Iteration #217 | Epoch Duration: 67.18902158737183
2020-01-10 13:01:15.333787 UTC | [2020_01_10_08_58_14] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4436142
Z variance train             0.01801819
KL Divergence                34.926315
KL Loss                      3.4926317
QF Loss                      350.81525
VF Loss                      133.91576
Policy Loss                  -3162.4934
Q Predictions Mean           3165.719
Q Predictions Std            331.43552
Q Predictions Max            3750.9512
Q Predictions Min            2293.271
V Predictions Mean           3163.85
V Predictions Std            325.68777
V Predictions Max            3753.5813
V Predictions Min            2307.3079
Log Pis Mean                 5.1556263
Log Pis Std                  3.8360543
Log Pis Max                  14.677621
Log Pis Min                  -4.0565486
Policy mu Mean               -0.08587983
Policy mu Std                1.396738
Policy mu Max                2.817372
Policy mu Min                -2.8785186
Policy log std Mean          -0.7757737
Policy log std Std           0.4026741
Policy log std Max           -0.068706095
Policy log std Min           -2.5171185
Z mean eval                  2.432714
Z variance eval              0.017158512
total_rewards                [8643.69755672 8979.30349427 8969.88585248 8620.31877969 8834.83681807
 8951.47495051 8955.00361553 8889.4288462  8690.68264016 8637.76989036]
total_rewards_mean           8817.240244398441
total_rewards_std            144.63930236770815
total_rewards_max            8979.303494270627
total_rewards_min            8620.318779689274
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               28.76811518613249
(Previous) Eval Time (s)     22.714206502772868
Sample Time (s)              16.23183964798227
Epoch Time (s)               67.71416133688763
Total Train Time (s)         14648.508134705946
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:02:23.178060 UTC | [2020_01_10_08_58_14] Iteration #218 | Epoch Duration: 67.84415054321289
2020-01-10 13:02:23.178207 UTC | [2020_01_10_08_58_14] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4327664
Z variance train             0.017191853
KL Divergence                35.5382
KL Loss                      3.5538201
QF Loss                      323.38586
VF Loss                      203.80621
Policy Loss                  -3155.7654
Q Predictions Mean           3153.302
Q Predictions Std            394.88254
Q Predictions Max            3783.105
Q Predictions Min            133.6777
V Predictions Mean           3155.2188
V Predictions Std            393.44214
V Predictions Max            3762.4585
V Predictions Min            106.198296
Log Pis Mean                 5.0100718
Log Pis Std                  3.979333
Log Pis Max                  15.128082
Log Pis Min                  -11.413556
Policy mu Mean               -0.07617355
Policy mu Std                1.3736794
Policy mu Max                2.9259028
Policy mu Min                -2.7514217
Policy log std Mean          -0.7605769
Policy log std Std           0.39953083
Policy log std Max           -0.09329885
Policy log std Min           -2.6148572
Z mean eval                  2.4357967
Z variance eval              0.015991112
total_rewards                [8743.2405886  8847.66092262 8883.9854783  8832.06003269 8919.52424344
 8787.13151164 8822.81108756 8741.19873055 8717.77057024 8875.44936033]
total_rewards_mean           8817.083252598126
total_rewards_std            64.45160064497523
total_rewards_max            8919.524243442589
total_rewards_min            8717.770570240053
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               28.466046548914164
(Previous) Eval Time (s)     22.843914790078998
Sample Time (s)              15.79811120359227
Epoch Time (s)               67.10807254258543
Total Train Time (s)         14714.904650238808
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:03:29.577839 UTC | [2020_01_10_08_58_14] Iteration #219 | Epoch Duration: 66.39949917793274
2020-01-10 13:03:29.578020 UTC | [2020_01_10_08_58_14] Iteration #219 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4350286
Z variance train             0.01593579
KL Divergence                35.746563
KL Loss                      3.5746562
QF Loss                      278.81317
VF Loss                      113.47397
Policy Loss                  -3201.0916
Q Predictions Mean           3203.5417
Q Predictions Std            322.05457
Q Predictions Max            3714.8005
Q Predictions Min            2383.4783
V Predictions Mean           3202.0303
V Predictions Std            319.63025
V Predictions Max            3708.9053
V Predictions Min            2387.6921
Log Pis Mean                 4.5423136
Log Pis Std                  3.6760926
Log Pis Max                  13.883003
Log Pis Min                  -5.5275536
Policy mu Mean               -0.080798
Policy mu Std                1.3493271
Policy mu Max                2.8092053
Policy mu Min                -3.1841779
Policy log std Mean          -0.7692836
Policy log std Std           0.38869652
Policy log std Max           -0.13675304
Policy log std Min           -2.5484757
Z mean eval                  2.440671
Z variance eval              0.013489358
total_rewards                [8640.32305974 9060.41456568 8966.53452017 9201.89437346 8869.9682099
 8925.380819   9015.70792782 8952.81283832 8920.59172752 9004.20808589]
total_rewards_mean           8955.783612749101
total_rewards_std            136.60924054452278
total_rewards_max            9201.894373457468
total_rewards_min            8640.323059736402
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               25.926099581178278
(Previous) Eval Time (s)     22.13505965517834
Sample Time (s)              16.015792726539075
Epoch Time (s)               64.07695196289569
Total Train Time (s)         14779.581335462164
Epoch                        220
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:04:34.257027 UTC | [2020_01_10_08_58_14] Iteration #220 | Epoch Duration: 64.67887282371521
2020-01-10 13:04:34.257194 UTC | [2020_01_10_08_58_14] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4399018
Z variance train             0.013480504
KL Divergence                36.48345
KL Loss                      3.6483452
QF Loss                      438.23532
VF Loss                      216.14783
Policy Loss                  -3273.6455
Q Predictions Mean           3273.6118
Q Predictions Std            325.45328
Q Predictions Max            3782.9734
Q Predictions Min            2358.138
V Predictions Mean           3275.6387
V Predictions Std            323.09692
V Predictions Max            3781.6633
V Predictions Min            2375.3354
Log Pis Mean                 5.30546
Log Pis Std                  3.9182937
Log Pis Max                  20.891209
Log Pis Min                  -4.1155987
Policy mu Mean               -0.0055530407
Policy mu Std                1.4227412
Policy mu Max                3.6379402
Policy mu Min                -3.1499007
Policy log std Mean          -0.7664831
Policy log std Std           0.39279372
Policy log std Max           -0.12917608
Policy log std Min           -2.7778647
Z mean eval                  2.4338105
Z variance eval              0.018734604
total_rewards                [8860.4568675  8701.89976753 9025.84955306 8904.67653714 8829.19197585
 9041.92769501 8746.38230247 8984.00190454 8772.39515903 8945.86159032]
total_rewards_mean           8881.264335245223
total_rewards_std            112.85182092639292
total_rewards_max            9041.927695006647
total_rewards_min            8701.899767525925
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               28.101227906066924
(Previous) Eval Time (s)     22.736679413821548
Sample Time (s)              15.95568541297689
Epoch Time (s)               66.79359273286536
Total Train Time (s)         14845.745825511403
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:05:40.422234 UTC | [2020_01_10_08_58_14] Iteration #221 | Epoch Duration: 66.16492462158203
2020-01-10 13:05:40.422415 UTC | [2020_01_10_08_58_14] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.430953
Z variance train             0.018757822
KL Divergence                34.55751
KL Loss                      3.4557512
QF Loss                      459.8542
VF Loss                      192.17392
Policy Loss                  -3173.5544
Q Predictions Mean           3171.461
Q Predictions Std            335.46722
Q Predictions Max            3717.9622
Q Predictions Min            2299.7156
V Predictions Mean           3171.1946
V Predictions Std            330.4094
V Predictions Max            3710.762
V Predictions Min            2305.9854
Log Pis Mean                 4.9451256
Log Pis Std                  3.514859
Log Pis Max                  13.295029
Log Pis Min                  -3.553591
Policy mu Mean               -0.049077984
Policy mu Std                1.407298
Policy mu Max                2.960416
Policy mu Min                -2.988064
Policy log std Mean          -0.7506976
Policy log std Std           0.37196416
Policy log std Max           -0.07858202
Policy log std Min           -2.5517666
Z mean eval                  2.4352303
Z variance eval              0.022222992
total_rewards                [8995.98863041 8948.68218522 8810.0525965  9232.74409571 8966.55507963
 8895.87075896 8981.34251103 8928.75761559 8941.29098762 8908.83976501]
total_rewards_mean           8961.012422566977
total_rewards_std            103.36397089399762
total_rewards_max            9232.744095710097
total_rewards_min            8810.05259650481
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               27.44369839411229
(Previous) Eval Time (s)     22.10775351105258
Sample Time (s)              15.857172385789454
Epoch Time (s)               65.40862429095432
Total Train Time (s)         14911.515408505686
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:06:46.196476 UTC | [2020_01_10_08_58_14] Iteration #222 | Epoch Duration: 65.77390909194946
2020-01-10 13:06:46.196720 UTC | [2020_01_10_08_58_14] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.434147
Z variance train             0.02223447
KL Divergence                34.861397
KL Loss                      3.4861398
QF Loss                      368.61322
VF Loss                      113.23906
Policy Loss                  -3249.5696
Q Predictions Mean           3255.046
Q Predictions Std            303.1628
Q Predictions Max            3769.6025
Q Predictions Min            2458.064
V Predictions Mean           3247.4731
V Predictions Std            300.06268
V Predictions Max            3764.669
V Predictions Min            2452.8035
Log Pis Mean                 4.9205885
Log Pis Std                  3.7891624
Log Pis Max                  14.138113
Log Pis Min                  -4.547742
Policy mu Mean               -0.008489166
Policy mu Std                1.3914965
Policy mu Max                3.0200546
Policy mu Min                -2.789126
Policy log std Mean          -0.767196
Policy log std Std           0.38580787
Policy log std Max           -0.083889455
Policy log std Min           -2.6149535
Z mean eval                  2.440395
Z variance eval              0.019587379
total_rewards                [8899.12949453 8974.47321245 9195.60734979 9111.72644379 8941.16460845
 8986.54681327 9111.91065425 9042.63434533 8978.98851562 8926.14087833]
total_rewards_mean           9016.832231581619
total_rewards_std            90.89510156713479
total_rewards_max            9195.607349791637
total_rewards_min            8899.129494529636
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               30.452235268894583
(Previous) Eval Time (s)     22.47277530701831
Sample Time (s)              15.421199884731323
Epoch Time (s)               68.34621046064422
Total Train Time (s)         14979.217865653336
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:07:53.902029 UTC | [2020_01_10_08_58_14] Iteration #223 | Epoch Duration: 67.70511746406555
2020-01-10 13:07:53.902261 UTC | [2020_01_10_08_58_14] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4396636
Z variance train             0.019536503
KL Divergence                35.26702
KL Loss                      3.5267022
QF Loss                      338.39438
VF Loss                      145.33893
Policy Loss                  -3291.3137
Q Predictions Mean           3291.8042
Q Predictions Std            322.2479
Q Predictions Max            3843.5735
Q Predictions Min            2439.787
V Predictions Mean           3286.2886
V Predictions Std            318.1956
V Predictions Max            3823.2476
V Predictions Min            2440.2043
Log Pis Mean                 5.005883
Log Pis Std                  3.8186903
Log Pis Max                  14.113873
Log Pis Min                  -3.857206
Policy mu Mean               -0.0116277365
Policy mu Std                1.3728887
Policy mu Max                3.4043105
Policy mu Min                -2.5793798
Policy log std Mean          -0.7584881
Policy log std Std           0.4044487
Policy log std Max           -0.03779033
Policy log std Min           -2.7388718
Z mean eval                  2.4317167
Z variance eval              0.022850629
total_rewards                [8280.58491734 8622.23514727 8794.75672897 8839.47252972 8881.04999825
 8980.41093476 8728.84183314 8838.1546641  8924.40596986 8952.03172859]
total_rewards_mean           8784.194445199893
total_rewards_std            196.1394275414125
total_rewards_max            8980.410934761137
total_rewards_min            8280.584917340351
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               27.184783281758428
(Previous) Eval Time (s)     21.831431740894914
Sample Time (s)              15.458335253410041
Epoch Time (s)               64.47455027606338
Total Train Time (s)         15044.537643965334
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:08:59.226423 UTC | [2020_01_10_08_58_14] Iteration #224 | Epoch Duration: 65.32395029067993
2020-01-10 13:08:59.226711 UTC | [2020_01_10_08_58_14] Iteration #224 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.432566
Z variance train             0.02289808
KL Divergence                34.649498
KL Loss                      3.4649498
QF Loss                      260.85928
VF Loss                      155.25705
Policy Loss                  -3202.784
Q Predictions Mean           3201.8726
Q Predictions Std            329.8152
Q Predictions Max            3765.372
Q Predictions Min            2336.2292
V Predictions Mean           3193.3481
V Predictions Std            326.74274
V Predictions Max            3751.4094
V Predictions Min            2328.3098
Log Pis Mean                 4.774117
Log Pis Std                  3.8923998
Log Pis Max                  13.44014
Log Pis Min                  -6.6495357
Policy mu Mean               -0.108728856
Policy mu Std                1.3577564
Policy mu Max                2.7044141
Policy mu Min                -2.7916627
Policy log std Mean          -0.78230524
Policy log std Std           0.40655178
Policy log std Max           -0.110126734
Policy log std Min           -2.6829047
Z mean eval                  2.4287944
Z variance eval              0.023381952
total_rewards                [8891.74927258 9069.30003431 8897.54766424 9049.38625973 8896.5123548
 9214.25910884 9120.76389694 8780.75125658 9124.11310645 9127.69070272]
total_rewards_mean           9017.20736571714
total_rewards_std            133.21968008733649
total_rewards_max            9214.259108840253
total_rewards_min            8780.751256577763
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               26.8060272927396
(Previous) Eval Time (s)     22.680556882638484
Sample Time (s)              15.921683142427355
Epoch Time (s)               65.40826731780544
Total Train Time (s)         15110.161920579616
Epoch                        225
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:10:04.855857 UTC | [2020_01_10_08_58_14] Iteration #225 | Epoch Duration: 65.6288948059082
2020-01-10 13:10:04.856165 UTC | [2020_01_10_08_58_14] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4278479
Z variance train             0.0233668
KL Divergence                34.658546
KL Loss                      3.4658546
QF Loss                      254.30417
VF Loss                      180.40038
Policy Loss                  -3237.9094
Q Predictions Mean           3243.3247
Q Predictions Std            306.29507
Q Predictions Max            3788.6687
Q Predictions Min            2387.386
V Predictions Mean           3240.5293
V Predictions Std            302.82138
V Predictions Max            3784.771
V Predictions Min            2388.2183
Log Pis Mean                 4.619756
Log Pis Std                  3.6688716
Log Pis Max                  15.475124
Log Pis Min                  -5.9026256
Policy mu Mean               -0.060585428
Policy mu Std                1.3860298
Policy mu Max                2.783687
Policy mu Min                -3.0699053
Policy log std Mean          -0.76128834
Policy log std Std           0.40330407
Policy log std Max           -0.060236007
Policy log std Min           -2.6439414
Z mean eval                  2.4336934
Z variance eval              0.02025423
total_rewards                [8838.24580578 9203.43590224 9265.69047485 9096.04008874 9143.36142784
 8895.84230584 9238.15063916 9146.78446513 9139.99798725 9438.65845066]
total_rewards_mean           9140.620754750773
total_rewards_std            164.714039847315
total_rewards_max            9438.658450664361
total_rewards_min            8838.245805780954
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               28.202026849612594
(Previous) Eval Time (s)     22.900904660578817
Sample Time (s)              17.11516499053687
Epoch Time (s)               68.21809650072828
Total Train Time (s)         15177.689361922443
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:11:12.384035 UTC | [2020_01_10_08_58_14] Iteration #226 | Epoch Duration: 67.52766966819763
2020-01-10 13:11:12.384204 UTC | [2020_01_10_08_58_14] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4347775
Z variance train             0.020300563
KL Divergence                34.453434
KL Loss                      3.4453435
QF Loss                      344.86102
VF Loss                      258.06058
Policy Loss                  -3252.1975
Q Predictions Mean           3255.6333
Q Predictions Std            319.38025
Q Predictions Max            3867.841
Q Predictions Min            2383.5269
V Predictions Mean           3252.823
V Predictions Std            315.72473
V Predictions Max            3839.449
V Predictions Min            2390.443
Log Pis Mean                 4.7807026
Log Pis Std                  3.760461
Log Pis Max                  13.39128
Log Pis Min                  -4.8592787
Policy mu Mean               -0.074844174
Policy mu Std                1.3671923
Policy mu Max                3.0587823
Policy mu Min                -2.681941
Policy log std Mean          -0.7698503
Policy log std Std           0.39017817
Policy log std Max           -0.15418252
Policy log std Min           -2.719029
Z mean eval                  2.4315715
Z variance eval              0.022880156
total_rewards                [8850.23268035 9194.27876207 9101.62993701 9198.1930702  9188.22609972
 9105.21104055 9150.64816665 9112.74860434 9019.81857296 9034.25261534]
total_rewards_mean           9095.523954920036
total_rewards_std            100.99847920625133
total_rewards_max            9198.193070197114
total_rewards_min            8850.232680350591
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               27.540202033240348
(Previous) Eval Time (s)     22.210143344011158
Sample Time (s)              15.321427606511861
Epoch Time (s)               65.07177298376337
Total Train Time (s)         15243.009013959207
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:12:17.706775 UTC | [2020_01_10_08_58_14] Iteration #227 | Epoch Duration: 65.32243728637695
2020-01-10 13:12:17.706980 UTC | [2020_01_10_08_58_14] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4310858
Z variance train             0.02287437
KL Divergence                34.098373
KL Loss                      3.4098375
QF Loss                      278.9428
VF Loss                      146.94241
Policy Loss                  -3250.4773
Q Predictions Mean           3250.6714
Q Predictions Std            320.97745
Q Predictions Max            3789.2058
Q Predictions Min            2371.0815
V Predictions Mean           3250.8018
V Predictions Std            318.2285
V Predictions Max            3788.3062
V Predictions Min            2373.444
Log Pis Mean                 4.5529003
Log Pis Std                  3.9299455
Log Pis Max                  14.195494
Log Pis Min                  -6.2764244
Policy mu Mean               -0.03246129
Policy mu Std                1.377224
Policy mu Max                2.8736138
Policy mu Min                -2.9498947
Policy log std Mean          -0.7735448
Policy log std Std           0.40175822
Policy log std Max           -0.14157575
Policy log std Min           -2.6840215
Z mean eval                  2.423816
Z variance eval              0.02018649
total_rewards                [9119.53633352 9085.42097276 8844.81225731 9127.03939102 9269.12384718
 6503.7949658  9223.25375176 9171.96286277 9120.54998292 9350.62192375]
total_rewards_mean           8881.61162887813
total_rewards_std            802.6206183078835
total_rewards_max            9350.62192375162
total_rewards_min            6503.794965799898
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               26.741426202002913
(Previous) Eval Time (s)     22.46055772388354
Sample Time (s)              16.634721957612783
Epoch Time (s)               65.83670588349923
Total Train Time (s)         15308.601136547979
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:13:23.300494 UTC | [2020_01_10_08_58_14] Iteration #228 | Epoch Duration: 65.59336972236633
2020-01-10 13:13:23.300659 UTC | [2020_01_10_08_58_14] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4234908
Z variance train             0.020186733
KL Divergence                33.958107
KL Loss                      3.3958108
QF Loss                      342.23853
VF Loss                      135.92738
Policy Loss                  -3294.022
Q Predictions Mean           3297.2073
Q Predictions Std            335.04642
Q Predictions Max            3829.2273
Q Predictions Min            2425.0781
V Predictions Mean           3299.683
V Predictions Std            332.49652
V Predictions Max            3829.1555
V Predictions Min            2423.314
Log Pis Mean                 4.520278
Log Pis Std                  3.8018885
Log Pis Max                  13.340269
Log Pis Min                  -4.9729586
Policy mu Mean               -0.11457544
Policy mu Std                1.3856701
Policy mu Max                2.7483165
Policy mu Min                -2.9950614
Policy log std Mean          -0.76041937
Policy log std Std           0.3920573
Policy log std Max           -0.10161501
Policy log std Min           -2.6429708
Z mean eval                  2.4348094
Z variance eval              0.014517861
total_rewards                [9095.89806553 9251.30801298 9315.16358389 9207.57062764 9123.09185861
 9133.01535684 9136.51837027 9378.03617871 9308.94346163 9260.08132284]
total_rewards_mean           9220.962683894257
total_rewards_std            91.65282063820783
total_rewards_max            9378.036178708853
total_rewards_min            9095.898065532017
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               25.876936174929142
(Previous) Eval Time (s)     22.216920244973153
Sample Time (s)              15.394510369747877
Epoch Time (s)               63.48836678965017
Total Train Time (s)         15372.472973269876
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:14:27.175919 UTC | [2020_01_10_08_58_14] Iteration #229 | Epoch Duration: 63.87513303756714
2020-01-10 13:14:27.176125 UTC | [2020_01_10_08_58_14] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4338853
Z variance train             0.014526004
KL Divergence                34.96475
KL Loss                      3.496475
QF Loss                      431.54626
VF Loss                      87.70108
Policy Loss                  -3264.3926
Q Predictions Mean           3261.8179
Q Predictions Std            324.98154
Q Predictions Max            3713.4678
Q Predictions Min            2327.5188
V Predictions Mean           3266.9238
V Predictions Std            323.5172
V Predictions Max            3723.2144
V Predictions Min            2335.609
Log Pis Mean                 5.1636186
Log Pis Std                  3.769231
Log Pis Max                  15.065946
Log Pis Min                  -5.997489
Policy mu Mean               -0.07179114
Policy mu Std                1.4031605
Policy mu Max                3.0568151
Policy mu Min                -3.4200726
Policy log std Mean          -0.7713442
Policy log std Std           0.40589303
Policy log std Max           -0.12622657
Policy log std Min           -2.6049113
Z mean eval                  2.4458687
Z variance eval              0.013688895
total_rewards                [7916.72006205 8124.60469274 8689.80351611 8237.71109754 8645.26191812
 8442.19484842 8349.61678269 8503.91052641 7895.10121148 8108.21899084]
total_rewards_mean           8291.314364639391
total_rewards_std            267.7552595044242
total_rewards_max            8689.80351611427
total_rewards_min            7895.10121147603
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               27.77514027385041
(Previous) Eval Time (s)     22.603393303696066
Sample Time (s)              16.536022970452905
Epoch Time (s)               66.91455654799938
Total Train Time (s)         15440.307733493391
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:15:35.014753 UTC | [2020_01_10_08_58_14] Iteration #230 | Epoch Duration: 67.83848357200623
2020-01-10 13:15:35.014962 UTC | [2020_01_10_08_58_14] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4469001
Z variance train             0.013673961
KL Divergence                35.21027
KL Loss                      3.521027
QF Loss                      406.6024
VF Loss                      330.31833
Policy Loss                  -3291.7268
Q Predictions Mean           3290.0488
Q Predictions Std            318.66812
Q Predictions Max            3818.4736
Q Predictions Min            2394.3198
V Predictions Mean           3280.0671
V Predictions Std            315.6516
V Predictions Max            3788.1924
V Predictions Min            2379.925
Log Pis Mean                 5.0036173
Log Pis Std                  3.7995338
Log Pis Max                  14.187521
Log Pis Min                  -2.934983
Policy mu Mean               -0.09314104
Policy mu Std                1.3961893
Policy mu Max                2.7767684
Policy mu Min                -2.5916166
Policy log std Mean          -0.7857418
Policy log std Std           0.40698493
Policy log std Max           -0.14635392
Policy log std Min           -2.651497
Z mean eval                  2.4260926
Z variance eval              0.0150444405
total_rewards                [9258.27320519 9195.3491682  9245.68058698 9306.70746653 9321.12137169
 9203.21938674 9275.39140274 9242.11987643 9318.18534462 9217.29500068]
total_rewards_mean           9258.334280981784
total_rewards_std            43.894537478205734
total_rewards_max            9321.121371689032
total_rewards_min            9195.349168202765
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               27.86188072292134
(Previous) Eval Time (s)     23.527004212141037
Sample Time (s)              15.617115641012788
Epoch Time (s)               67.00600057607517
Total Train Time (s)         15505.88282634411
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:16:40.588940 UTC | [2020_01_10_08_58_14] Iteration #231 | Epoch Duration: 65.57386255264282
2020-01-10 13:16:40.589123 UTC | [2020_01_10_08_58_14] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.426251
Z variance train             0.01500628
KL Divergence                34.424324
KL Loss                      3.4424324
QF Loss                      270.51947
VF Loss                      106.25564
Policy Loss                  -3273.03
Q Predictions Mean           3279.1787
Q Predictions Std            340.65646
Q Predictions Max            3790.0818
Q Predictions Min            2412.22
V Predictions Mean           3270.5251
V Predictions Std            336.636
V Predictions Max            3768.9014
V Predictions Min            2414.5388
Log Pis Mean                 4.9408135
Log Pis Std                  3.9285097
Log Pis Max                  14.962421
Log Pis Min                  -6.433802
Policy mu Mean               -0.063309826
Policy mu Std                1.3829206
Policy mu Max                2.6758766
Policy mu Min                -2.7397892
Policy log std Mean          -0.7725857
Policy log std Std           0.4003422
Policy log std Max           -0.095277935
Policy log std Min           -2.5600364
Z mean eval                  2.4560707
Z variance eval              0.017916799
total_rewards                [8662.6292143  8924.97832662 8656.04496803 8960.28730629 8809.04582871
 8884.32413689 8665.51726397 8726.74965638 8812.10498397 8851.04603363]
total_rewards_mean           8795.27277187992
total_rewards_std            106.80718806145835
total_rewards_max            8960.287306293641
total_rewards_min            8656.044968026075
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               27.030431357678026
(Previous) Eval Time (s)     22.09459384297952
Sample Time (s)              15.862333404831588
Epoch Time (s)               64.98735860548913
Total Train Time (s)         15571.212342116982
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:17:45.920904 UTC | [2020_01_10_08_58_14] Iteration #232 | Epoch Duration: 65.3316662311554
2020-01-10 13:17:45.921105 UTC | [2020_01_10_08_58_14] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4568782
Z variance train             0.017947523
KL Divergence                34.91071
KL Loss                      3.491071
QF Loss                      369.8512
VF Loss                      86.87157
Policy Loss                  -3355.1372
Q Predictions Mean           3362.3435
Q Predictions Std            321.03253
Q Predictions Max            3954.175
Q Predictions Min            2447.4233
V Predictions Mean           3355.6062
V Predictions Std            319.04266
V Predictions Max            3929.9668
V Predictions Min            2456.1936
Log Pis Mean                 4.9341784
Log Pis Std                  4.117825
Log Pis Max                  14.939064
Log Pis Min                  -5.030966
Policy mu Mean               -0.074990384
Policy mu Std                1.3882059
Policy mu Max                2.8298795
Policy mu Min                -2.932429
Policy log std Mean          -0.77350205
Policy log std Std           0.40319934
Policy log std Max           -0.07128574
Policy log std Min           -2.6528745
Z mean eval                  2.4677453
Z variance eval              0.016641133
total_rewards                [8906.95694487 9168.22587314 9121.18851603 9123.15959792 9080.73401399
 8838.55286622 9013.9303339  9012.85032151 8813.59879413 8674.92794658]
total_rewards_mean           8975.412520829565
total_rewards_std            153.01178013791534
total_rewards_max            9168.225873141
total_rewards_min            8674.927946580185
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               29.737765330821276
(Previous) Eval Time (s)     22.438620949629694
Sample Time (s)              15.475911255925894
Epoch Time (s)               67.65229753637686
Total Train Time (s)         15638.211875290144
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:18:52.925502 UTC | [2020_01_10_08_58_14] Iteration #233 | Epoch Duration: 67.00424313545227
2020-01-10 13:18:52.925757 UTC | [2020_01_10_08_58_14] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4647043
Z variance train             0.016635284
KL Divergence                34.896458
KL Loss                      3.4896457
QF Loss                      336.69
VF Loss                      229.13882
Policy Loss                  -3359.3403
Q Predictions Mean           3362.7168
Q Predictions Std            334.27042
Q Predictions Max            3940.9648
Q Predictions Min            2500.801
V Predictions Mean           3369.4841
V Predictions Std            333.46716
V Predictions Max            3948.9512
V Predictions Min            2498.9
Log Pis Mean                 4.8790236
Log Pis Std                  3.9158695
Log Pis Max                  15.490427
Log Pis Min                  -4.9069886
Policy mu Mean               -0.08198511
Policy mu Std                1.3914363
Policy mu Max                2.7778094
Policy mu Min                -3.2133203
Policy log std Mean          -0.73812276
Policy log std Std           0.38639516
Policy log std Max           -0.046643883
Policy log std Min           -2.6773767
Z mean eval                  2.4548402
Z variance eval              0.020700183
total_rewards                [8817.56718653 9069.25651168 9029.4394069  9082.52706799 8833.88744433
 9078.19493063 9143.36998659 9157.65133622 8986.96307493 9211.77977195]
total_rewards_mean           9041.063671776448
total_rewards_std            123.70557727420714
total_rewards_max            9211.77977194844
total_rewards_min            8817.567186534228
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               27.737394171301275
(Previous) Eval Time (s)     21.79029506025836
Sample Time (s)              16.52497066790238
Epoch Time (s)               66.05265989946201
Total Train Time (s)         15704.899623282254
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:19:59.616494 UTC | [2020_01_10_08_58_14] Iteration #234 | Epoch Duration: 66.69052147865295
2020-01-10 13:19:59.616761 UTC | [2020_01_10_08_58_14] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.455969
Z variance train             0.020678956
KL Divergence                33.933186
KL Loss                      3.3933187
QF Loss                      260.44174
VF Loss                      132.82953
Policy Loss                  -3337.9697
Q Predictions Mean           3341.4548
Q Predictions Std            321.08524
Q Predictions Max            3878.9397
Q Predictions Min            2421.8616
V Predictions Mean           3334.5476
V Predictions Std            319.45084
V Predictions Max            3863.239
V Predictions Min            2433.034
Log Pis Mean                 4.890129
Log Pis Std                  3.7498987
Log Pis Max                  14.572328
Log Pis Min                  -3.397203
Policy mu Mean               -0.06288842
Policy mu Std                1.3648573
Policy mu Max                2.7577858
Policy mu Min                -2.879756
Policy log std Mean          -0.7878037
Policy log std Std           0.4137003
Policy log std Max           -0.08270785
Policy log std Min           -2.605126
Z mean eval                  2.4845188
Z variance eval              0.015854148
total_rewards                [9042.54923169 9121.82047833 9443.20334578 9526.28706077 9285.01441108
 9512.37856066 9066.9693694  9311.10738852 9352.20833693 9337.39531655]
total_rewards_mean           9299.893349971047
total_rewards_std            165.4151590231782
total_rewards_max            9526.287060768766
total_rewards_min            9042.549231690455
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               27.59239391889423
(Previous) Eval Time (s)     22.427846091333777
Sample Time (s)              16.136831181123853
Epoch Time (s)               66.15707119135186
Total Train Time (s)         15770.578044378664
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:21:05.296335 UTC | [2020_01_10_08_58_14] Iteration #235 | Epoch Duration: 65.67939734458923
2020-01-10 13:21:05.296484 UTC | [2020_01_10_08_58_14] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.48633
Z variance train             0.01582357
KL Divergence                35.46286
KL Loss                      3.546286
QF Loss                      334.78442
VF Loss                      110.28736
Policy Loss                  -3348.4832
Q Predictions Mean           3351.8948
Q Predictions Std            311.98297
Q Predictions Max            3857.8308
Q Predictions Min            2449.7183
V Predictions Mean           3345.0444
V Predictions Std            310.5886
V Predictions Max            3857.2622
V Predictions Min            2438.849
Log Pis Mean                 4.5809793
Log Pis Std                  3.8869543
Log Pis Max                  14.959402
Log Pis Min                  -4.154245
Policy mu Mean               -0.02573572
Policy mu Std                1.372026
Policy mu Max                2.8830698
Policy mu Min                -3.0328481
Policy log std Mean          -0.77871794
Policy log std Std           0.4048108
Policy log std Max           -0.16198196
Policy log std Min           -2.6458929
Z mean eval                  2.4685225
Z variance eval              0.015364924
total_rewards                [9348.42231903 9034.96296525 9145.95784122 9436.43081605 9285.36316456
 9447.2850124  9135.08102729 9282.063951   9382.30912599 9283.42547179]
total_rewards_mean           9278.130169457692
total_rewards_std            129.08346082710668
total_rewards_max            9447.285012398022
total_rewards_min            9034.96296525
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               26.293075433000922
(Previous) Eval Time (s)     21.94987366301939
Sample Time (s)              15.799820411484689
Epoch Time (s)               64.042769507505
Total Train Time (s)         15834.704687823076
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:22:09.428239 UTC | [2020_01_10_08_58_14] Iteration #236 | Epoch Duration: 64.13160395622253
2020-01-10 13:22:09.428496 UTC | [2020_01_10_08_58_14] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4682412
Z variance train             0.015407629
KL Divergence                35.20282
KL Loss                      3.520282
QF Loss                      788.1826
VF Loss                      359.6964
Policy Loss                  -3315.3213
Q Predictions Mean           3314.6465
Q Predictions Std            385.5907
Q Predictions Max            3832.3428
Q Predictions Min            233.20233
V Predictions Mean           3313.905
V Predictions Std            391.97757
V Predictions Max            3843.2522
V Predictions Min            2.662176
Log Pis Mean                 5.2031965
Log Pis Std                  4.1495333
Log Pis Max                  14.615349
Log Pis Min                  -4.665393
Policy mu Mean               -0.061356828
Policy mu Std                1.3978364
Policy mu Max                2.8364887
Policy mu Min                -3.0408957
Policy log std Mean          -0.7706879
Policy log std Std           0.39890718
Policy log std Max           0.3356037
Policy log std Min           -2.822729
Z mean eval                  2.4677022
Z variance eval              0.013853466
total_rewards                [9128.86579876 9417.05679893 9555.42369093 9296.95747464 3426.19392933
 9305.19589981 9532.48516878 9439.58698371 9241.33937316 8933.54420223]
total_rewards_mean           8727.66493202915
total_rewards_std            1776.1040223309346
total_rewards_max            9555.423690931562
total_rewards_min            3426.193929326676
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               27.709870452061296
(Previous) Eval Time (s)     22.038414811715484
Sample Time (s)              16.022317071910948
Epoch Time (s)               65.77060233568773
Total Train Time (s)         15900.84236415755
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:23:15.566825 UTC | [2020_01_10_08_58_14] Iteration #237 | Epoch Duration: 66.13815331459045
2020-01-10 13:23:15.566975 UTC | [2020_01_10_08_58_14] Iteration #237 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4671397
Z variance train             0.013874332
KL Divergence                35.487873
KL Loss                      3.5487874
QF Loss                      443.59393
VF Loss                      243.60881
Policy Loss                  -3347.061
Q Predictions Mean           3345.353
Q Predictions Std            318.9128
Q Predictions Max            3880.2227
Q Predictions Min            2485.0518
V Predictions Mean           3335.934
V Predictions Std            315.454
V Predictions Max            3858.056
V Predictions Min            2478.0083
Log Pis Mean                 5.192699
Log Pis Std                  3.9459338
Log Pis Max                  15.999884
Log Pis Min                  -5.409955
Policy mu Mean               -0.105753064
Policy mu Std                1.4326538
Policy mu Max                3.342345
Policy mu Min                -3.7887714
Policy log std Mean          -0.7803895
Policy log std Std           0.3997501
Policy log std Max           -0.07117826
Policy log std Min           -2.6445484
Z mean eval                  2.4660301
Z variance eval              0.014522022
total_rewards                [9033.12667254 9402.01321414 9363.61603173 9255.22564138 9249.3016772
 9475.92666681 9237.05672583 9373.38330007 9534.07412547 9242.93684618]
total_rewards_mean           9316.666090132805
total_rewards_std            136.31456345871288
total_rewards_max            9534.074125465984
total_rewards_min            9033.126672536842
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               27.638337542768568
(Previous) Eval Time (s)     22.405717025976628
Sample Time (s)              15.091077847406268
Epoch Time (s)               65.13513241615146
Total Train Time (s)         15966.277170836926
Epoch                        238
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:24:21.007150 UTC | [2020_01_10_08_58_14] Iteration #238 | Epoch Duration: 65.43999457359314
2020-01-10 13:24:21.007469 UTC | [2020_01_10_08_58_14] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4655414
Z variance train             0.014520216
KL Divergence                35.09641
KL Loss                      3.509641
QF Loss                      564.62946
VF Loss                      169.68915
Policy Loss                  -3295.452
Q Predictions Mean           3303.6865
Q Predictions Std            392.4732
Q Predictions Max            3816.1833
Q Predictions Min            27.528929
V Predictions Mean           3303.753
V Predictions Std            390.85638
V Predictions Max            3803.7017
V Predictions Min            2.6000504
Log Pis Mean                 5.476551
Log Pis Std                  3.9727805
Log Pis Max                  13.68364
Log Pis Min                  -4.6447105
Policy mu Mean               -0.06322926
Policy mu Std                1.4036089
Policy mu Max                2.716901
Policy mu Min                -3.2714095
Policy log std Mean          -0.77920985
Policy log std Std           0.4138512
Policy log std Max           0.27692938
Policy log std Min           -2.7954862
Z mean eval                  2.4448466
Z variance eval              0.020279879
total_rewards                [8874.87958074 9513.15842009 9245.70911637 9334.28092384 9311.12116607
 9242.9454528  9216.77129964 9102.18752701 9402.88316106 9156.45124215]
total_rewards_mean           9240.038788976643
total_rewards_std            165.81917255623537
total_rewards_max            9513.158420086278
total_rewards_min            8874.879580739933
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               26.088987688999623
(Previous) Eval Time (s)     22.710334822069854
Sample Time (s)              15.984071301762015
Epoch Time (s)               64.78339381283149
Total Train Time (s)         16030.477818190586
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:25:25.209226 UTC | [2020_01_10_08_58_14] Iteration #239 | Epoch Duration: 64.20154285430908
2020-01-10 13:25:25.209379 UTC | [2020_01_10_08_58_14] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4449923
Z variance train             0.020263689
KL Divergence                34.07295
KL Loss                      3.407295
QF Loss                      473.78708
VF Loss                      79.2743
Policy Loss                  -3384.795
Q Predictions Mean           3388.529
Q Predictions Std            330.7658
Q Predictions Max            3906.1646
Q Predictions Min            2462.4062
V Predictions Mean           3383.004
V Predictions Std            328.16183
V Predictions Max            3904.7908
V Predictions Min            2457.2078
Log Pis Mean                 5.225031
Log Pis Std                  3.7245529
Log Pis Max                  12.607132
Log Pis Min                  -7.208746
Policy mu Mean               -0.06379819
Policy mu Std                1.3756844
Policy mu Max                2.8760219
Policy mu Min                -2.6276832
Policy log std Mean          -0.7985174
Policy log std Std           0.4221732
Policy log std Max           -0.050695643
Policy log std Min           -2.7064419
Z mean eval                  2.427737
Z variance eval              0.028515328
total_rewards                [9000.38153079 9371.24062536 9473.63648105 9072.94503855 9194.54166964
 9127.96278485 9358.50802479 9118.06522838 9192.44005556 9280.14691746]
total_rewards_mean           9218.986835643176
total_rewards_std            141.46508697751472
total_rewards_max            9473.636481050617
total_rewards_min            9000.381530791443
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               24.658088537864387
(Previous) Eval Time (s)     22.128206911031157
Sample Time (s)              15.67509415699169
Epoch Time (s)               62.461389605887234
Total Train Time (s)         16092.809968130197
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:26:27.543350 UTC | [2020_01_10_08_58_14] Iteration #240 | Epoch Duration: 62.33385515213013
2020-01-10 13:26:27.543507 UTC | [2020_01_10_08_58_14] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4296606
Z variance train             0.028654069
KL Divergence                33.24256
KL Loss                      3.3242562
QF Loss                      398.1411
VF Loss                      522.617
Policy Loss                  -3354.893
Q Predictions Mean           3353.2754
Q Predictions Std            325.29538
Q Predictions Max            3898.4045
Q Predictions Min            2446.704
V Predictions Mean           3335.6968
V Predictions Std            320.39694
V Predictions Max            3866.6064
V Predictions Min            2447.7515
Log Pis Mean                 5.191515
Log Pis Std                  3.8902473
Log Pis Max                  13.444643
Log Pis Min                  -6.413644
Policy mu Mean               -0.020202523
Policy mu Std                1.4145366
Policy mu Max                2.720109
Policy mu Min                -2.6068516
Policy log std Mean          -0.78576857
Policy log std Std           0.42924875
Policy log std Max           -0.10719548
Policy log std Min           -2.6597736
Z mean eval                  2.4490454
Z variance eval              0.025661986
total_rewards                [8976.73143483 9348.48746396 9192.79684868 9225.60137148 9075.58619899
 9051.07092267 9006.27569229 9205.48444776 9086.67300251 9025.73752717]
total_rewards_mean           9119.444491034177
total_rewards_std            112.31253840359565
total_rewards_max            9348.487463959462
total_rewards_min            8976.731434829502
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               27.448333198204637
(Previous) Eval Time (s)     22.00037556188181
Sample Time (s)              15.529810282867402
Epoch Time (s)               64.97851904295385
Total Train Time (s)         16158.007322903723
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:27:32.745496 UTC | [2020_01_10_08_58_14] Iteration #241 | Epoch Duration: 65.20182776451111
2020-01-10 13:27:32.745768 UTC | [2020_01_10_08_58_14] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4498687
Z variance train             0.025576383
KL Divergence                33.879784
KL Loss                      3.3879783
QF Loss                      421.08667
VF Loss                      105.29665
Policy Loss                  -3425.4236
Q Predictions Mean           3432.4666
Q Predictions Std            338.78494
Q Predictions Max            3999.3088
Q Predictions Min            2590.3984
V Predictions Mean           3424.2139
V Predictions Std            333.31503
V Predictions Max            3986.336
V Predictions Min            2580.6584
Log Pis Mean                 4.988656
Log Pis Std                  3.9302948
Log Pis Max                  14.620833
Log Pis Min                  -8.383842
Policy mu Mean               -0.023267688
Policy mu Std                1.3968129
Policy mu Max                2.9356563
Policy mu Min                -2.4946508
Policy log std Mean          -0.78214264
Policy log std Std           0.42455298
Policy log std Max           -0.043636218
Policy log std Min           -2.7129848
Z mean eval                  2.467583
Z variance eval              0.018093314
total_rewards                [9361.2345954  9433.66377449 9713.2013457  9649.51240298 9374.18983061
 9202.13255716 9319.70951185 9226.46205741 9564.33013917 9649.28453457]
total_rewards_mean           9449.372074934709
total_rewards_std            174.39562903515142
total_rewards_max            9713.20134570386
total_rewards_min            9202.132557162264
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               27.08968031220138
(Previous) Eval Time (s)     22.22340047871694
Sample Time (s)              16.05196959991008
Epoch Time (s)               65.3650503908284
Total Train Time (s)         16223.22411715705
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:28:37.964153 UTC | [2020_01_10_08_58_14] Iteration #242 | Epoch Duration: 65.21818137168884
2020-01-10 13:28:37.964344 UTC | [2020_01_10_08_58_14] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4688468
Z variance train             0.018110288
KL Divergence                35.066998
KL Loss                      3.5066998
QF Loss                      509.45444
VF Loss                      163.57666
Policy Loss                  -3365.9521
Q Predictions Mean           3374.3145
Q Predictions Std            339.8881
Q Predictions Max            3963.9463
Q Predictions Min            2441.6655
V Predictions Mean           3364.0142
V Predictions Std            337.4294
V Predictions Max            3955.785
V Predictions Min            2446.482
Log Pis Mean                 5.0443983
Log Pis Std                  3.7039268
Log Pis Max                  16.66373
Log Pis Min                  -4.178314
Policy mu Mean               -0.06445781
Policy mu Std                1.3845018
Policy mu Max                2.7383196
Policy mu Min                -2.903079
Policy log std Mean          -0.78203416
Policy log std Std           0.4115367
Policy log std Max           -0.15029068
Policy log std Min           -2.6359215
Z mean eval                  2.465767
Z variance eval              0.013456377
total_rewards                [9364.2231396  9381.82675686 9158.82713117 9299.49485734 9149.19103113
 9565.61230436 9408.94530379 9318.8507454  9380.27644614 9301.93589596]
total_rewards_mean           9332.918361175047
total_rewards_std            114.83893306482264
total_rewards_max            9565.612304358136
total_rewards_min            9149.191031126358
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               26.517262562178075
(Previous) Eval Time (s)     22.076255464926362
Sample Time (s)              16.097209279425442
Epoch Time (s)               64.69072730652988
Total Train Time (s)         16288.337305134162
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:29:43.080477 UTC | [2020_01_10_08_58_14] Iteration #243 | Epoch Duration: 65.1159439086914
2020-01-10 13:29:43.080813 UTC | [2020_01_10_08_58_14] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4661014
Z variance train             0.013425464
KL Divergence                35.517174
KL Loss                      3.5517175
QF Loss                      390.07126
VF Loss                      176.4855
Policy Loss                  -3365.2327
Q Predictions Mean           3366.7295
Q Predictions Std            316.95856
Q Predictions Max            3880.4214
Q Predictions Min            2415.2102
V Predictions Mean           3371.6663
V Predictions Std            315.20142
V Predictions Max            3879.0186
V Predictions Min            2421.2473
Log Pis Mean                 5.077138
Log Pis Std                  3.5596588
Log Pis Max                  15.432539
Log Pis Min                  -4.4951954
Policy mu Mean               -0.065716505
Policy mu Std                1.394677
Policy mu Max                2.9167795
Policy mu Min                -2.9799438
Policy log std Mean          -0.7668395
Policy log std Std           0.3968304
Policy log std Max           -0.0829255
Policy log std Min           -2.724809
Z mean eval                  2.4667053
Z variance eval              0.014016822
total_rewards                [8678.58196724 9402.12448466 9351.33012156 9470.02673258 9326.46862603
 9466.72413827 9252.81485808 9555.04869438 9476.27999903 9418.75822032]
total_rewards_mean           9339.815784214268
total_rewards_std            235.20897937126276
total_rewards_max            9555.048694375904
total_rewards_min            8678.581967238326
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               28.347023638896644
(Previous) Eval Time (s)     22.501175220124424
Sample Time (s)              16.300993462093174
Epoch Time (s)               67.14919232111424
Total Train Time (s)         16355.619754459243
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:30:50.366208 UTC | [2020_01_10_08_58_14] Iteration #244 | Epoch Duration: 67.28514552116394
2020-01-10 13:30:50.366416 UTC | [2020_01_10_08_58_14] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4659314
Z variance train             0.01395109
KL Divergence                35.412025
KL Loss                      3.5412025
QF Loss                      294.4271
VF Loss                      202.09059
Policy Loss                  -3391.5283
Q Predictions Mean           3397.8613
Q Predictions Std            358.16547
Q Predictions Max            3941.779
Q Predictions Min            2445.0354
V Predictions Mean           3398.4673
V Predictions Std            357.0277
V Predictions Max            3949.0227
V Predictions Min            2453.4233
Log Pis Mean                 5.340603
Log Pis Std                  3.6225603
Log Pis Max                  15.2114315
Log Pis Min                  -2.8939028
Policy mu Mean               -0.056966934
Policy mu Std                1.4337362
Policy mu Max                3.0717673
Policy mu Min                -2.6328065
Policy log std Mean          -0.77033776
Policy log std Std           0.40439582
Policy log std Max           -0.15566465
Policy log std Min           -2.6307802
Z mean eval                  2.4765832
Z variance eval              0.016855262
total_rewards                [9366.91054887 9413.63507574 9581.28752745 9263.25953423 9654.04133451
 9363.72491844 9552.76756856 9584.4993799  9380.14244938 9533.24711971]
total_rewards_mean           9469.351545678164
total_rewards_std            120.88322065931007
total_rewards_max            9654.041334505906
total_rewards_min            9263.25953423057
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               31.755182622931898
(Previous) Eval Time (s)     22.636860174126923
Sample Time (s)              15.78937695082277
Epoch Time (s)               70.18141974788159
Total Train Time (s)         16425.22863140935
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:31:59.980359 UTC | [2020_01_10_08_58_14] Iteration #245 | Epoch Duration: 69.61373710632324
2020-01-10 13:31:59.980696 UTC | [2020_01_10_08_58_14] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4777634
Z variance train             0.016828043
KL Divergence                34.766846
KL Loss                      3.4766846
QF Loss                      361.2253
VF Loss                      122.11963
Policy Loss                  -3439.625
Q Predictions Mean           3442.891
Q Predictions Std            310.55103
Q Predictions Max            3981.9763
Q Predictions Min            2536.8416
V Predictions Mean           3435.354
V Predictions Std            309.6831
V Predictions Max            3975.3308
V Predictions Min            2538.3015
Log Pis Mean                 5.169666
Log Pis Std                  3.9456775
Log Pis Max                  16.773462
Log Pis Min                  -4.721921
Policy mu Mean               -0.09047967
Policy mu Std                1.3939952
Policy mu Max                2.7733808
Policy mu Min                -2.9108396
Policy log std Mean          -0.7751148
Policy log std Std           0.4181839
Policy log std Max           -0.13766839
Policy log std Min           -2.690671
Z mean eval                  2.473908
Z variance eval              0.014027774
total_rewards                [9034.15335935 9397.09226628 9551.17656525 9271.43407274 9434.44913912
 9484.76261802 9286.67896877 9327.36214687 9241.5264114  9497.60411734]
total_rewards_mean           9352.623966514175
total_rewards_std            145.57495865168454
total_rewards_max            9551.176565251595
total_rewards_min            9034.153359351738
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               28.58997920807451
(Previous) Eval Time (s)     22.068849140778184
Sample Time (s)              16.268041067756712
Epoch Time (s)               66.9268694166094
Total Train Time (s)         16492.243550867774
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:33:06.997384 UTC | [2020_01_10_08_58_14] Iteration #246 | Epoch Duration: 67.01644659042358
2020-01-10 13:33:06.997575 UTC | [2020_01_10_08_58_14] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.478651
Z variance train             0.014021221
KL Divergence                35.499237
KL Loss                      3.5499237
QF Loss                      370.5912
VF Loss                      690.8534
Policy Loss                  -3458.649
Q Predictions Mean           3464.9429
Q Predictions Std            343.4697
Q Predictions Max            3985.7861
Q Predictions Min            2511.656
V Predictions Mean           3438.1255
V Predictions Std            339.5591
V Predictions Max            3956.934
V Predictions Min            2497.6885
Log Pis Mean                 4.953218
Log Pis Std                  3.7273092
Log Pis Max                  14.607747
Log Pis Min                  -5.749009
Policy mu Mean               -0.067636915
Policy mu Std                1.4105016
Policy mu Max                2.856996
Policy mu Min                -2.624221
Policy log std Mean          -0.7833478
Policy log std Std           0.39193326
Policy log std Max           -0.11599788
Policy log std Min           -2.7162907
Z mean eval                  2.4901645
Z variance eval              0.0113197
total_rewards                [9234.23159044 9332.62165117 9526.64462317 9406.67553552 9447.24558429
 9414.51619074 9582.95811943 9302.81639343 9283.9658357  9417.24322143]
total_rewards_mean           9394.891874530364
total_rewards_std            103.4233770683882
total_rewards_max            9582.958119428098
total_rewards_min            9234.231590437035
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               28.654903028160334
(Previous) Eval Time (s)     22.158149210736156
Sample Time (s)              16.49339490197599
Epoch Time (s)               67.30644714087248
Total Train Time (s)         16560.034566391725
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:34:14.794746 UTC | [2020_01_10_08_58_14] Iteration #247 | Epoch Duration: 67.79698896408081
2020-01-10 13:34:14.795050 UTC | [2020_01_10_08_58_14] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.490649
Z variance train             0.011333374
KL Divergence                36.270805
KL Loss                      3.6270807
QF Loss                      275.22272
VF Loss                      177.7955
Policy Loss                  -3469.1284
Q Predictions Mean           3473.0452
Q Predictions Std            331.31238
Q Predictions Max            3947.7256
Q Predictions Min            2518.9673
V Predictions Mean           3461.918
V Predictions Std            328.9895
V Predictions Max            3943.7751
V Predictions Min            2510.106
Log Pis Mean                 5.4798136
Log Pis Std                  3.9901009
Log Pis Max                  13.620435
Log Pis Min                  -6.1197824
Policy mu Mean               -0.07779352
Policy mu Std                1.4298513
Policy mu Max                2.9573019
Policy mu Min                -3.3621063
Policy log std Mean          -0.78282213
Policy log std Std           0.417804
Policy log std Max           -0.103748456
Policy log std Min           -2.6992679
Z mean eval                  2.4625719
Z variance eval              0.014698649
total_rewards                [4817.58974932 9555.85845015 9459.85590223 9446.19244358 9421.44461314
 9496.95510785 9355.18128555 9289.2689412  9351.19083358 9302.5815568 ]
total_rewards_mean           8949.611888340534
total_rewards_std            1379.7101310922878
total_rewards_max            9555.85845015351
total_rewards_min            4817.589749319062
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               29.645949441939592
(Previous) Eval Time (s)     22.64838218782097
Sample Time (s)              15.661639638710767
Epoch Time (s)               67.95597126847133
Total Train Time (s)         16627.43664634507
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:35:22.198664 UTC | [2020_01_10_08_58_14] Iteration #248 | Epoch Duration: 67.40339684486389
2020-01-10 13:35:22.198880 UTC | [2020_01_10_08_58_14] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4630759
Z variance train             0.014706368
KL Divergence                35.26212
KL Loss                      3.526212
QF Loss                      391.93118
VF Loss                      143.70189
Policy Loss                  -3426.9207
Q Predictions Mean           3425.7432
Q Predictions Std            401.09094
Q Predictions Max            4029.3958
Q Predictions Min            -42.867702
V Predictions Mean           3432.7744
V Predictions Std            398.34897
V Predictions Max            4015.6794
V Predictions Min            16.036354
Log Pis Mean                 4.8410416
Log Pis Std                  3.6532996
Log Pis Max                  14.911734
Log Pis Min                  -3.5563936
Policy mu Mean               -0.08554617
Policy mu Std                1.3883239
Policy mu Max                2.856723
Policy mu Min                -2.719601
Policy log std Mean          -0.77729195
Policy log std Std           0.41939062
Policy log std Max           -0.13857448
Policy log std Min           -2.7172313
Z mean eval                  2.4584303
Z variance eval              0.01645558
total_rewards                [9082.379969   9440.2749499  9218.87090102 9342.5511753  9317.99253313
 9450.27710558 9340.25733341 9401.85045021 9548.3622001  9407.2078574 ]
total_rewards_mean           9355.002447507735
total_rewards_std            123.79571652742364
total_rewards_max            9548.362200104131
total_rewards_min            9082.379969002082
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               28.65459135733545
(Previous) Eval Time (s)     22.09553774399683
Sample Time (s)              15.888994297478348
Epoch Time (s)               66.63912339881063
Total Train Time (s)         16694.139517428353
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:36:28.904949 UTC | [2020_01_10_08_58_14] Iteration #249 | Epoch Duration: 66.705885887146
2020-01-10 13:36:28.905196 UTC | [2020_01_10_08_58_14] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4586303
Z variance train             0.016347859
KL Divergence                35.229595
KL Loss                      3.5229595
QF Loss                      296.57617
VF Loss                      135.72585
Policy Loss                  -3427.3738
Q Predictions Mean           3427.0654
Q Predictions Std            333.26315
Q Predictions Max            3986.6956
Q Predictions Min            2499.9329
V Predictions Mean           3422.7568
V Predictions Std            332.33765
V Predictions Max            3970.3074
V Predictions Min            2498.769
Log Pis Mean                 5.106841
Log Pis Std                  3.9516716
Log Pis Max                  15.10293
Log Pis Min                  -4.7681503
Policy mu Mean               -0.043314844
Policy mu Std                1.3956101
Policy mu Max                3.0051355
Policy mu Min                -2.590301
Policy log std Mean          -0.78465825
Policy log std Std           0.4258205
Policy log std Max           -0.14668337
Policy log std Min           -2.7671087
Z mean eval                  2.4725282
Z variance eval              0.014731851
total_rewards                [9327.52738294 9621.88995082 9481.38517529 9295.44022664 9321.84960881
 9319.71985847 9344.10950048 8979.27339031 9499.27900465 9191.58336654]
total_rewards_mean           9338.205746494383
total_rewards_std            167.2839658987241
total_rewards_max            9621.889950816647
total_rewards_min            8979.273390312042
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               25.223244092892855
(Previous) Eval Time (s)     22.162032613065094
Sample Time (s)              16.301853433717042
Epoch Time (s)               63.68713013967499
Total Train Time (s)         16758.45086610224
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:37:33.217838 UTC | [2020_01_10_08_58_14] Iteration #250 | Epoch Duration: 64.31246995925903
2020-01-10 13:37:33.217988 UTC | [2020_01_10_08_58_14] Iteration #250 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4728365
Z variance train             0.014769912
KL Divergence                35.779724
KL Loss                      3.5779724
QF Loss                      247.76434
VF Loss                      120.85123
Policy Loss                  -3408.9749
Q Predictions Mean           3407.5972
Q Predictions Std            356.93237
Q Predictions Max            3949.7576
Q Predictions Min            2468.2703
V Predictions Mean           3404.3462
V Predictions Std            355.7282
V Predictions Max            3939.4775
V Predictions Min            2474.6558
Log Pis Mean                 5.2623086
Log Pis Std                  4.1031785
Log Pis Max                  13.77189
Log Pis Min                  -3.9844437
Policy mu Mean               -0.07240066
Policy mu Std                1.4099386
Policy mu Max                2.904542
Policy mu Min                -2.9248714
Policy log std Mean          -0.7773997
Policy log std Std           0.40834773
Policy log std Max           -0.1339677
Policy log std Min           -2.693717
Z mean eval                  2.46868
Z variance eval              0.020663416
total_rewards                [9386.88763872 9333.79785071 9669.97142736 7703.07392143 9547.2527027
 9399.28084454 7000.45942533 9409.89109511 9342.06815011 9454.39121451]
total_rewards_mean           9024.707427052148
total_rewards_std            856.4136486267687
total_rewards_max            9669.971427357663
total_rewards_min            7000.459425332919
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               26.945599160157144
(Previous) Eval Time (s)     22.787105534691364
Sample Time (s)              15.875152424909174
Epoch Time (s)               65.60785711975768
Total Train Time (s)         16823.32061068574
Epoch                        251
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:38:38.091639 UTC | [2020_01_10_08_58_14] Iteration #251 | Epoch Duration: 64.87349772453308
2020-01-10 13:38:38.091896 UTC | [2020_01_10_08_58_14] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4685955
Z variance train             0.02068246
KL Divergence                34.302734
KL Loss                      3.4302735
QF Loss                      339.49902
VF Loss                      304.94583
Policy Loss                  -3448.4636
Q Predictions Mean           3449.1875
Q Predictions Std            311.50055
Q Predictions Max            3977.7788
Q Predictions Min            2479.5427
V Predictions Mean           3455.126
V Predictions Std            311.57297
V Predictions Max            3976.4697
V Predictions Min            2485.1907
Log Pis Mean                 4.820969
Log Pis Std                  3.7774804
Log Pis Max                  15.647408
Log Pis Min                  -6.4514585
Policy mu Mean               -0.019800752
Policy mu Std                1.3800199
Policy mu Max                2.9229846
Policy mu Min                -2.5389004
Policy log std Mean          -0.773694
Policy log std Std           0.42138445
Policy log std Max           0.023630202
Policy log std Min           -2.6263504
Z mean eval                  2.470662
Z variance eval              0.02047191
total_rewards                [9059.23738012 9343.5189289  9205.49284073 9173.98589705 9351.1296892
 9288.8318205  9231.72913884 9219.54690501 9232.51877179 9194.63631414]
total_rewards_mean           9230.062768627718
total_rewards_std            80.8005798672066
total_rewards_max            9351.129689204714
total_rewards_min            9059.237380120401
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               29.238204833120108
(Previous) Eval Time (s)     22.052466886118054
Sample Time (s)              15.237378825433552
Epoch Time (s)               66.52805054467171
Total Train Time (s)         16889.703401763458
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:39:44.479142 UTC | [2020_01_10_08_58_14] Iteration #252 | Epoch Duration: 66.38703536987305
2020-01-10 13:39:44.479427 UTC | [2020_01_10_08_58_14] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.473449
Z variance train             0.020517793
KL Divergence                34.455883
KL Loss                      3.4455884
QF Loss                      883.96094
VF Loss                      199.24765
Policy Loss                  -3408.9827
Q Predictions Mean           3412.7327
Q Predictions Std            336.91595
Q Predictions Max            3975.4644
Q Predictions Min            2463.884
V Predictions Mean           3401.247
V Predictions Std            333.32077
V Predictions Max            3956.2925
V Predictions Min            2453.149
Log Pis Mean                 5.496291
Log Pis Std                  3.9101825
Log Pis Max                  16.579536
Log Pis Min                  -3.5601919
Policy mu Mean               -0.045875553
Policy mu Std                1.430098
Policy mu Max                2.9274645
Policy mu Min                -2.5500553
Policy log std Mean          -0.78489715
Policy log std Std           0.42892376
Policy log std Max           -0.117716104
Policy log std Min           -2.6085005
Z mean eval                  2.4672365
Z variance eval              0.020684162
total_rewards                [8979.25059719 8827.45780612 9281.7142788  9093.30832904 9182.44783954
 8946.10437967 8921.87420954 9072.65922562 9142.45114297 9153.82586319]
total_rewards_mean           9060.109367168634
total_rewards_std            131.78355128430863
total_rewards_max            9281.714278804571
total_rewards_min            8827.457806121247
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               28.596024880185723
(Previous) Eval Time (s)     21.91116934735328
Sample Time (s)              15.912490876857191
Epoch Time (s)               66.4196851043962
Total Train Time (s)         16956.270139248576
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:40:51.050376 UTC | [2020_01_10_08_58_14] Iteration #253 | Epoch Duration: 66.57071471214294
2020-01-10 13:40:51.050649 UTC | [2020_01_10_08_58_14] Iteration #253 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4662213
Z variance train             0.020734083
KL Divergence                34.73078
KL Loss                      3.4730783
QF Loss                      433.4879
VF Loss                      133.39647
Policy Loss                  -3510.615
Q Predictions Mean           3516.999
Q Predictions Std            315.8448
Q Predictions Max            4001.117
Q Predictions Min            2507.344
V Predictions Mean           3513.1543
V Predictions Std            312.35388
V Predictions Max            3982.7607
V Predictions Min            2516.448
Log Pis Mean                 5.6415663
Log Pis Std                  3.7683978
Log Pis Max                  13.989529
Log Pis Min                  -3.7531972
Policy mu Mean               -0.004156254
Policy mu Std                1.4368562
Policy mu Max                2.9600828
Policy mu Min                -2.593809
Policy log std Mean          -0.77934295
Policy log std Std           0.422471
Policy log std Max           -0.084427774
Policy log std Min           -2.7433405
Z mean eval                  2.4793632
Z variance eval              0.01637083
total_rewards                [9380.49606301 9311.92185231 9383.60739843 9324.3666982  9482.7144749
 9646.81719416 9758.22765945 9525.69127642 9714.24733508 9870.70893489]
total_rewards_mean           9539.879888686066
total_rewards_std            187.26118082669294
total_rewards_max            9870.708934893575
total_rewards_min            9311.921852308267
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               24.925032451283187
(Previous) Eval Time (s)     22.061911911703646
Sample Time (s)              15.401604088023305
Epoch Time (s)               62.38854845101014
Total Train Time (s)         17019.659417434596
Epoch                        254
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:41:54.444512 UTC | [2020_01_10_08_58_14] Iteration #254 | Epoch Duration: 63.39364767074585
2020-01-10 13:41:54.444778 UTC | [2020_01_10_08_58_14] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4782543
Z variance train             0.01637331
KL Divergence                35.63232
KL Loss                      3.5632322
QF Loss                      278.97192
VF Loss                      197.5564
Policy Loss                  -3492.8655
Q Predictions Mean           3496.4607
Q Predictions Std            317.9619
Q Predictions Max            4010.8877
Q Predictions Min            2505.8784
V Predictions Mean           3489.7876
V Predictions Std            314.76172
V Predictions Max            4017.1633
V Predictions Min            2489.677
Log Pis Mean                 4.979179
Log Pis Std                  3.7031417
Log Pis Max                  15.499738
Log Pis Min                  -4.5640397
Policy mu Mean               -0.12042835
Policy mu Std                1.3932878
Policy mu Max                3.0429862
Policy mu Min                -2.803538
Policy log std Mean          -0.77651435
Policy log std Std           0.4232488
Policy log std Max           -0.033355117
Policy log std Min           -2.7843442
Z mean eval                  2.501741
Z variance eval              0.013082797
total_rewards                [9239.32357257 9516.27788615 9367.70286635 9527.49491261 9391.42482352
 9365.60281186 9241.14429297 9416.93160458 9377.49557015 9518.44303732]
total_rewards_mean           9396.184137806535
total_rewards_std            98.89571690674669
total_rewards_max            9527.494912605449
total_rewards_min            9239.323572571608
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               26.48849427420646
(Previous) Eval Time (s)     23.06678387382999
Sample Time (s)              15.788658564910293
Epoch Time (s)               65.34393671294674
Total Train Time (s)         17084.38076373376
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:42:59.169712 UTC | [2020_01_10_08_58_14] Iteration #255 | Epoch Duration: 64.72472643852234
2020-01-10 13:42:59.169912 UTC | [2020_01_10_08_58_14] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5017505
Z variance train             0.01306133
KL Divergence                36.8525
KL Loss                      3.68525
QF Loss                      319.57037
VF Loss                      375.66125
Policy Loss                  -3516.7646
Q Predictions Mean           3521.2886
Q Predictions Std            338.98215
Q Predictions Max            4054.742
Q Predictions Min            2573.2708
V Predictions Mean           3514.2568
V Predictions Std            337.6306
V Predictions Max            4050.9355
V Predictions Min            2567.7354
Log Pis Mean                 5.494975
Log Pis Std                  4.029083
Log Pis Max                  15.842237
Log Pis Min                  -3.5394628
Policy mu Mean               -0.1222164
Policy mu Std                1.423489
Policy mu Max                2.7392948
Policy mu Min                -2.9533212
Policy log std Mean          -0.7746063
Policy log std Std           0.40213755
Policy log std Max           0.0379678
Policy log std Min           -2.889021
Z mean eval                  2.499804
Z variance eval              0.012129197
total_rewards                [9380.52151542 9545.84362777 9376.47656526 9561.34050337 9574.32104162
 9640.36925706 9673.58525018 9611.80119674 9672.27262382 9560.9734279 ]
total_rewards_mean           9559.75050091373
total_rewards_std            100.47404004501637
total_rewards_max            9673.585250178303
total_rewards_min            9376.476565263236
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               28.211649202741683
(Previous) Eval Time (s)     22.447273097001016
Sample Time (s)              15.54455758119002
Epoch Time (s)               66.20347988093272
Total Train Time (s)         17150.441501846537
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:44:05.232392 UTC | [2020_01_10_08_58_14] Iteration #256 | Epoch Duration: 66.06233358383179
2020-01-10 13:44:05.232548 UTC | [2020_01_10_08_58_14] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4993672
Z variance train             0.012132829
KL Divergence                36.956566
KL Loss                      3.6956565
QF Loss                      495.33905
VF Loss                      213.66835
Policy Loss                  -3517.5059
Q Predictions Mean           3522.3606
Q Predictions Std            309.8868
Q Predictions Max            4004.7915
Q Predictions Min            2531.9185
V Predictions Mean           3524.1128
V Predictions Std            310.2146
V Predictions Max            4002.864
V Predictions Min            2531.3474
Log Pis Mean                 5.085293
Log Pis Std                  3.8231442
Log Pis Max                  15.856743
Log Pis Min                  -5.5855207
Policy mu Mean               -0.10500097
Policy mu Std                1.4158355
Policy mu Max                3.004804
Policy mu Min                -2.7246854
Policy log std Mean          -0.78573227
Policy log std Std           0.42837408
Policy log std Max           -0.092968404
Policy log std Min           -2.6246753
Z mean eval                  2.5064058
Z variance eval              0.010475062
total_rewards                [9048.72227641 9074.55557903 9386.33620394 9338.12849054 9431.52051049
 9398.95328954 9559.15414891 9496.72046377 9791.09833627 9283.26795243]
total_rewards_mean           9380.845725132811
total_rewards_std            207.82681245599326
total_rewards_max            9791.098336270757
total_rewards_min            9048.722276408336
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               29.385557901114225
(Previous) Eval Time (s)     22.30585444578901
Sample Time (s)              15.338594178669155
Epoch Time (s)               67.03000652557239
Total Train Time (s)         17217.41822483111
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:45:12.213429 UTC | [2020_01_10_08_58_14] Iteration #257 | Epoch Duration: 66.98072481155396
2020-01-10 13:45:12.213695 UTC | [2020_01_10_08_58_14] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.506143
Z variance train             0.010471967
KL Divergence                38.050987
KL Loss                      3.8050988
QF Loss                      407.5766
VF Loss                      151.27827
Policy Loss                  -3545.4856
Q Predictions Mean           3549.8125
Q Predictions Std            323.25705
Q Predictions Max            4062.696
Q Predictions Min            2572.2441
V Predictions Mean           3547.1587
V Predictions Std            320.07278
V Predictions Max            4072.4358
V Predictions Min            2567.3625
Log Pis Mean                 5.032259
Log Pis Std                  3.9637492
Log Pis Max                  14.136015
Log Pis Min                  -7.1709642
Policy mu Mean               -0.052463263
Policy mu Std                1.4234797
Policy mu Max                2.9694571
Policy mu Min                -2.9393096
Policy log std Mean          -0.78979945
Policy log std Std           0.4309885
Policy log std Max           -0.105801776
Policy log std Min           -2.7405596
Z mean eval                  2.5168648
Z variance eval              0.013699147
total_rewards                [9397.42702916 9729.36312214 9524.40864909 9762.38899054 9511.46883756
 9384.67531397 9508.93777608 9839.63199555 9637.42576522 9374.69873053]
total_rewards_mean           9567.042620984776
total_rewards_std            158.4527163324353
total_rewards_max            9839.631995550337
total_rewards_min            9374.698730534952
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               29.255415054038167
(Previous) Eval Time (s)     22.25629436597228
Sample Time (s)              15.857421375345439
Epoch Time (s)               67.36913079535589
Total Train Time (s)         17284.76111861551
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:46:19.559779 UTC | [2020_01_10_08_58_14] Iteration #258 | Epoch Duration: 67.34587979316711
2020-01-10 13:46:19.560020 UTC | [2020_01_10_08_58_14] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.518126
Z variance train             0.01375133
KL Divergence                38.374466
KL Loss                      3.8374467
QF Loss                      275.61368
VF Loss                      228.36404
Policy Loss                  -3523.0273
Q Predictions Mean           3520.7014
Q Predictions Std            341.2163
Q Predictions Max            4149.8384
Q Predictions Min            2497.0566
V Predictions Mean           3512.773
V Predictions Std            339.9112
V Predictions Max            4141.6196
V Predictions Min            2495.871
Log Pis Mean                 5.2598963
Log Pis Std                  3.6061463
Log Pis Max                  13.861946
Log Pis Min                  -4.1434555
Policy mu Mean               -0.098764904
Policy mu Std                1.4159166
Policy mu Max                2.7836344
Policy mu Min                -2.7980282
Policy log std Mean          -0.7818478
Policy log std Std           0.4195908
Policy log std Max           -0.09223385
Policy log std Min           -2.831644
Z mean eval                  2.500422
Z variance eval              0.012097322
total_rewards                [9162.55328435 9921.46141893 9487.38050285 9550.00952135 9634.95873617
 9381.90657485 9328.81054831 9419.53798038 9497.27176209 9450.84375559]
total_rewards_mean           9483.473408488146
total_rewards_std            190.2084638925181
total_rewards_max            9921.461418929974
total_rewards_min            9162.553284346906
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               26.881455457303673
(Previous) Eval Time (s)     22.23277970775962
Sample Time (s)              15.856401128694415
Epoch Time (s)               64.9706362937577
Total Train Time (s)         17349.952791113406
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:47:24.756103 UTC | [2020_01_10_08_58_14] Iteration #259 | Epoch Duration: 65.1958920955658
2020-01-10 13:47:24.756336 UTC | [2020_01_10_08_58_14] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5010026
Z variance train             0.012137659
KL Divergence                38.20325
KL Loss                      3.8203251
QF Loss                      302.21408
VF Loss                      90.97374
Policy Loss                  -3500.1572
Q Predictions Mean           3507.865
Q Predictions Std            341.82544
Q Predictions Max            4071.7588
Q Predictions Min            2541.4607
V Predictions Mean           3497.98
V Predictions Std            338.76068
V Predictions Max            4056.9807
V Predictions Min            2546.266
Log Pis Mean                 4.775812
Log Pis Std                  3.8805215
Log Pis Max                  15.10273
Log Pis Min                  -4.8486342
Policy mu Mean               -0.04581368
Policy mu Std                1.3722167
Policy mu Max                3.0948582
Policy mu Min                -2.8624208
Policy log std Mean          -0.7594938
Policy log std Std           0.40602386
Policy log std Max           0.19088364
Policy log std Min           -2.7741284
Z mean eval                  2.5004122
Z variance eval              0.011899279
total_rewards                [9386.09775653 9488.61131153 9450.76271822 9656.88317261 9608.20586799
 9735.84631373 9309.35176002 9429.74485728 9454.54146668 9498.24188575]
total_rewards_mean           9501.828711034063
total_rewards_std            122.7968731225696
total_rewards_max            9735.846313729677
total_rewards_min            9309.351760022848
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               28.71880059875548
(Previous) Eval Time (s)     22.457777192350477
Sample Time (s)              16.250462263356894
Epoch Time (s)               67.42704005446285
Total Train Time (s)         17416.88712054584
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:48:31.694534 UTC | [2020_01_10_08_58_14] Iteration #260 | Epoch Duration: 66.93800020217896
2020-01-10 13:48:31.694807 UTC | [2020_01_10_08_58_14] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4982314
Z variance train             0.01193257
KL Divergence                38.35999
KL Loss                      3.835999
QF Loss                      330.8781
VF Loss                      174.42287
Policy Loss                  -3491.0044
Q Predictions Mean           3494.8745
Q Predictions Std            333.38406
Q Predictions Max            4062.407
Q Predictions Min            2484.2493
V Predictions Mean           3494.4106
V Predictions Std            331.0336
V Predictions Max            4055.3716
V Predictions Min            2493.4614
Log Pis Mean                 5.4311256
Log Pis Std                  4.111704
Log Pis Max                  17.34014
Log Pis Min                  -5.7827272
Policy mu Mean               -0.024853742
Policy mu Std                1.4228053
Policy mu Max                3.1747873
Policy mu Min                -3.635155
Policy log std Mean          -0.79478407
Policy log std Std           0.44554794
Policy log std Max           -0.12079346
Policy log std Min           -2.8250327
Z mean eval                  2.501109
Z variance eval              0.011943623
total_rewards                [9252.0481627  9721.51718742 9741.18540415 9558.24913361 9612.77386211
 9415.56315359 9509.82515237 9576.92089735 9526.72721139 9688.21289422]
total_rewards_mean           9560.302305891964
total_rewards_std            140.6232477867431
total_rewards_max            9741.185404154667
total_rewards_min            9252.048162701956
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               28.188045384828
(Previous) Eval Time (s)     21.968449838925153
Sample Time (s)              16.64218126423657
Epoch Time (s)               66.79867648798972
Total Train Time (s)         17483.74469618406
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:49:38.557226 UTC | [2020_01_10_08_58_14] Iteration #261 | Epoch Duration: 66.86209559440613
2020-01-10 13:49:38.557606 UTC | [2020_01_10_08_58_14] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.501591
Z variance train             0.011946778
KL Divergence                37.923088
KL Loss                      3.7923088
QF Loss                      1792.5239
VF Loss                      311.40298
Policy Loss                  -3492.3684
Q Predictions Mean           3502.6592
Q Predictions Std            326.63858
Q Predictions Max            4009.7395
Q Predictions Min            2568.8953
V Predictions Mean           3502.8608
V Predictions Std            325.33755
V Predictions Max            4006.638
V Predictions Min            2575.927
Log Pis Mean                 4.963224
Log Pis Std                  3.520859
Log Pis Max                  14.450459
Log Pis Min                  -4.5979033
Policy mu Mean               -0.07290057
Policy mu Std                1.3830789
Policy mu Max                3.2278259
Policy mu Min                -3.0190642
Policy log std Mean          -0.79563123
Policy log std Std           0.416267
Policy log std Max           -0.06813313
Policy log std Min           -2.7573729
Z mean eval                  2.508956
Z variance eval              0.008857837
total_rewards                [9555.75134434 9273.38041577 9430.01428012 9579.85840922 9523.52234782
 9616.45073187 9546.09110032 9550.07213284 9483.39554414 9593.17683405]
total_rewards_mean           9515.171314048854
total_rewards_std            95.46813046026593
total_rewards_max            9616.450731866784
total_rewards_min            9273.380415772603
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               28.320549212861806
(Previous) Eval Time (s)     22.03157447418198
Sample Time (s)              15.691436090506613
Epoch Time (s)               66.0435597775504
Total Train Time (s)         17550.437132263556
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:50:45.256708 UTC | [2020_01_10_08_58_14] Iteration #262 | Epoch Duration: 66.6988513469696
2020-01-10 13:50:45.257027 UTC | [2020_01_10_08_58_14] Iteration #262 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5083365
Z variance train             0.008854045
KL Divergence                39.205425
KL Loss                      3.9205425
QF Loss                      264.61743
VF Loss                      118.00003
Policy Loss                  -3555.1418
Q Predictions Mean           3565.1475
Q Predictions Std            337.8158
Q Predictions Max            4106.5205
Q Predictions Min            2540.4492
V Predictions Mean           3559.5754
V Predictions Std            335.13812
V Predictions Max            4090.2473
V Predictions Min            2544.7378
Log Pis Mean                 5.4338493
Log Pis Std                  3.5925584
Log Pis Max                  12.341946
Log Pis Min                  -5.5860596
Policy mu Mean               -0.08217142
Policy mu Std                1.4301934
Policy mu Max                2.8960745
Policy mu Min                -2.712644
Policy log std Mean          -0.78972954
Policy log std Std           0.41750672
Policy log std Max           -0.07230583
Policy log std Min           -2.8483758
Z mean eval                  2.4918427
Z variance eval              0.008209899
total_rewards                [ 9562.45372363  9752.21204208  9913.53583488  9733.85935606
 10013.72709787  9957.91131692  9751.35654762  9663.2411028
  9719.62496706  9736.10597792]
total_rewards_mean           9780.402796684686
total_rewards_std            132.04674131642696
total_rewards_max            10013.727097872008
total_rewards_min            9562.453723626986
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               28.915790025144815
(Previous) Eval Time (s)     22.686589969787747
Sample Time (s)              15.93993676174432
Epoch Time (s)               67.54231675667688
Total Train Time (s)         17617.233163895085
Epoch                        263
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:51:52.052301 UTC | [2020_01_10_08_58_14] Iteration #263 | Epoch Duration: 66.79498314857483
2020-01-10 13:51:52.052556 UTC | [2020_01_10_08_58_14] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4910483
Z variance train             0.008179223
KL Divergence                39.634697
KL Loss                      3.9634697
QF Loss                      303.843
VF Loss                      228.6046
Policy Loss                  -3548.3135
Q Predictions Mean           3556.2422
Q Predictions Std            330.50897
Q Predictions Max            4045.631
Q Predictions Min            2523.443
V Predictions Mean           3558.1433
V Predictions Std            329.3322
V Predictions Max            4060.8472
V Predictions Min            2520.1865
Log Pis Mean                 5.1180305
Log Pis Std                  3.7541935
Log Pis Max                  15.075976
Log Pis Min                  -3.381666
Policy mu Mean               -0.08709664
Policy mu Std                1.4068651
Policy mu Max                3.240147
Policy mu Min                -2.599981
Policy log std Mean          -0.79905176
Policy log std Std           0.43998218
Policy log std Max           -0.13927633
Policy log std Min           -2.782847
Z mean eval                  2.4815924
Z variance eval              0.01061822
total_rewards                [8862.46035434 9144.79396211 8848.41666677 8540.6767384  9015.46885513
 8948.41527155 8819.41360731 9134.66821791 9270.75195454 9221.21467411]
total_rewards_mean           8980.628030217447
total_rewards_std            211.18117240431172
total_rewards_max            9270.751954543844
total_rewards_min            8540.676738402002
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               26.49827214097604
(Previous) Eval Time (s)     21.93896062579006
Sample Time (s)              16.623832662589848
Epoch Time (s)               65.06106542935595
Total Train Time (s)         17683.082834826317
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:52:57.907242 UTC | [2020_01_10_08_58_14] Iteration #264 | Epoch Duration: 65.85448026657104
2020-01-10 13:52:57.907555 UTC | [2020_01_10_08_58_14] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4824796
Z variance train             0.010623224
KL Divergence                39.031197
KL Loss                      3.9031198
QF Loss                      343.59537
VF Loss                      175.96928
Policy Loss                  -3559.6858
Q Predictions Mean           3561.3027
Q Predictions Std            325.47757
Q Predictions Max            4126.4307
Q Predictions Min            2558.521
V Predictions Mean           3562.171
V Predictions Std            324.81458
V Predictions Max            4111.948
V Predictions Min            2559.4192
Log Pis Mean                 5.4480085
Log Pis Std                  3.920609
Log Pis Max                  14.294033
Log Pis Min                  -7.0884266
Policy mu Mean               -0.031626042
Policy mu Std                1.4201599
Policy mu Max                3.1876302
Policy mu Min                -2.8369565
Policy log std Mean          -0.77435684
Policy log std Std           0.4315998
Policy log std Max           0.1934945
Policy log std Min           -2.8153431
Z mean eval                  2.4845862
Z variance eval              0.007117696
total_rewards                [9530.06960456 9729.80151992 9762.31817858 9361.29757291 9750.63422668
 9650.54387428 9691.8756572  9709.84941511 9835.23596627 9898.64073924]
total_rewards_mean           9692.026675474854
total_rewards_std            145.13830624941517
total_rewards_max            9898.640739238303
total_rewards_min            9361.297572906322
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               25.76390657806769
(Previous) Eval Time (s)     22.73209080286324
Sample Time (s)              16.01733196992427
Epoch Time (s)               64.5133293508552
Total Train Time (s)         17747.95776021015
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:54:02.785605 UTC | [2020_01_10_08_58_14] Iteration #265 | Epoch Duration: 64.87783241271973
2020-01-10 13:54:02.785831 UTC | [2020_01_10_08_58_14] Iteration #265 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4848275
Z variance train             0.0071319295
KL Divergence                39.22622
KL Loss                      3.922622
QF Loss                      321.85376
VF Loss                      172.04321
Policy Loss                  -3570.229
Q Predictions Mean           3571.529
Q Predictions Std            336.33762
Q Predictions Max            4143.433
Q Predictions Min            2564.4546
V Predictions Mean           3560.5366
V Predictions Std            334.48184
V Predictions Max            4125.699
V Predictions Min            2561.7544
Log Pis Mean                 5.703955
Log Pis Std                  3.9093313
Log Pis Max                  16.457083
Log Pis Min                  -4.6842937
Policy mu Mean               -0.07720518
Policy mu Std                1.4405918
Policy mu Max                3.1932068
Policy mu Min                -2.715878
Policy log std Mean          -0.8101306
Policy log std Std           0.43944374
Policy log std Max           -0.12079346
Policy log std Min           -2.791734
Z mean eval                  2.4905095
Z variance eval              0.005285921
total_rewards                [ 9653.20917277  9771.19319359  9644.62085132  9829.4520461
  9522.40220476  9780.02159023  9707.80204207 10176.8132968
  5294.67431402  9823.87452588]
total_rewards_mean           9320.40632375265
total_rewards_std            1351.8048847966556
total_rewards_max            10176.81329680202
total_rewards_min            5294.674314016017
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               27.575444663874805
(Previous) Eval Time (s)     23.096317279618233
Sample Time (s)              15.783177167642862
Epoch Time (s)               66.4549391111359
Total Train Time (s)         17814.158013941254
Epoch                        266
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:55:08.991621 UTC | [2020_01_10_08_58_14] Iteration #266 | Epoch Duration: 66.20548343658447
2020-01-10 13:55:08.992018 UTC | [2020_01_10_08_58_14] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4918075
Z variance train             0.005286355
KL Divergence                39.603737
KL Loss                      3.9603736
QF Loss                      327.8189
VF Loss                      214.47942
Policy Loss                  -3562.3457
Q Predictions Mean           3562.3577
Q Predictions Std            308.15366
Q Predictions Max            4056.1892
Q Predictions Min            2529.195
V Predictions Mean           3554.5562
V Predictions Std            306.83115
V Predictions Max            4040.1067
V Predictions Min            2529.116
Log Pis Mean                 5.1750093
Log Pis Std                  3.8593283
Log Pis Max                  16.143482
Log Pis Min                  -4.8613534
Policy mu Mean               -0.13382418
Policy mu Std                1.4264108
Policy mu Max                3.029799
Policy mu Min                -2.771227
Policy log std Mean          -0.7890315
Policy log std Std           0.43780005
Policy log std Max           -0.09148972
Policy log std Min           -2.730476
Z mean eval                  2.497543
Z variance eval              0.0058584465
total_rewards                [9342.16304543 9404.20277313 9526.64328516 9501.45613062 9418.98029512
 9493.38011481 9409.5507416  9574.02661486 9479.65892305 9659.42767552]
total_rewards_mean           9480.948959930472
total_rewards_std            87.90457509738006
total_rewards_max            9659.427675518482
total_rewards_min            9342.163045433483
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               26.047183863818645
(Previous) Eval Time (s)     22.84658263484016
Sample Time (s)              16.079627808649093
Epoch Time (s)               64.9733943073079
Total Train Time (s)         17879.574772819877
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:56:14.408745 UTC | [2020_01_10_08_58_14] Iteration #267 | Epoch Duration: 65.41652154922485
2020-01-10 13:56:14.408907 UTC | [2020_01_10_08_58_14] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.499154
Z variance train             0.005859085
KL Divergence                39.724937
KL Loss                      3.972494
QF Loss                      308.32083
VF Loss                      280.7308
Policy Loss                  -3547.967
Q Predictions Mean           3550.25
Q Predictions Std            335.81296
Q Predictions Max            4118.6904
Q Predictions Min            2543.2112
V Predictions Mean           3537.713
V Predictions Std            334.01218
V Predictions Max            4088.8176
V Predictions Min            2542.4734
Log Pis Mean                 5.245128
Log Pis Std                  3.9691265
Log Pis Max                  14.786417
Log Pis Min                  -5.064313
Policy mu Mean               -0.072154865
Policy mu Std                1.4091789
Policy mu Max                2.9968255
Policy mu Min                -2.7042015
Policy log std Mean          -0.793674
Policy log std Std           0.4238104
Policy log std Max           -0.1305521
Policy log std Min           -2.8044739
Z mean eval                  2.4889724
Z variance eval              0.0080456445
total_rewards                [9176.07448863 9323.27381837 9214.16619569 9139.6235068  9139.54798321
 9228.05294308 9036.43487201 9326.57937901 9292.76588284 9245.83463671]
total_rewards_mean           9212.235370634746
total_rewards_std            87.2017492103176
total_rewards_max            9326.579379011251
total_rewards_min            9036.43487200721
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               27.66349846776575
(Previous) Eval Time (s)     23.289461124688387
Sample Time (s)              16.056048348546028
Epoch Time (s)               67.00900794100016
Total Train Time (s)         17945.45637054881
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:57:20.293132 UTC | [2020_01_10_08_58_14] Iteration #268 | Epoch Duration: 65.88404440879822
2020-01-10 13:57:20.293359 UTC | [2020_01_10_08_58_14] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.490396
Z variance train             0.00802276
KL Divergence                37.98384
KL Loss                      3.7983842
QF Loss                      544.26526
VF Loss                      277.23453
Policy Loss                  -3577.051
Q Predictions Mean           3575.3542
Q Predictions Std            428.15384
Q Predictions Max            4171.2944
Q Predictions Min            -182.79546
V Predictions Mean           3572.298
V Predictions Std            420.39893
V Predictions Max            4152.211
V Predictions Min            -1.0466056
Log Pis Mean                 5.4136195
Log Pis Std                  3.7277765
Log Pis Max                  14.1797
Log Pis Min                  -5.017001
Policy mu Mean               -0.06682534
Policy mu Std                1.4441262
Policy mu Max                2.8257036
Policy mu Min                -2.5801828
Policy log std Mean          -0.7875951
Policy log std Std           0.4365177
Policy log std Max           -0.057859868
Policy log std Min           -2.8186805
Z mean eval                  2.4899993
Z variance eval              0.009835377
total_rewards                [9692.58545839 9916.96556385 9886.63077624 9588.46744637 9727.71951189
 9718.69486734 9800.27205747 9816.19503137 9708.71264973 9918.22470247]
total_rewards_mean           9777.446806509679
total_rewards_std            103.33977034817303
total_rewards_max            9918.22470246605
total_rewards_min            9588.467446366581
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               27.330852154176682
(Previous) Eval Time (s)     22.164191744290292
Sample Time (s)              16.244775971397758
Epoch Time (s)               65.73981986986473
Total Train Time (s)         18011.035270126536
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:58:25.876884 UTC | [2020_01_10_08_58_14] Iteration #269 | Epoch Duration: 65.58336448669434
2020-01-10 13:58:25.877132 UTC | [2020_01_10_08_58_14] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4894633
Z variance train             0.009819252
KL Divergence                37.58381
KL Loss                      3.758381
QF Loss                      583.59283
VF Loss                      236.73582
Policy Loss                  -3541.0442
Q Predictions Mean           3550.0337
Q Predictions Std            350.90216
Q Predictions Max            4059.3003
Q Predictions Min            2534.1755
V Predictions Mean           3550.061
V Predictions Std            350.182
V Predictions Max            4052.6626
V Predictions Min            2529.3882
Log Pis Mean                 5.1218147
Log Pis Std                  3.693845
Log Pis Max                  14.525045
Log Pis Min                  -3.645669
Policy mu Mean               -0.074302584
Policy mu Std                1.385608
Policy mu Max                2.6581447
Policy mu Min                -2.6575227
Policy log std Mean          -0.7906104
Policy log std Std           0.43355182
Policy log std Max           -0.07380059
Policy log std Min           -2.8198736
Z mean eval                  2.501452
Z variance eval              0.008420386
total_rewards                [9533.40674398 9693.96838146 9742.6434755  9654.78125238 9446.61691718
 9566.42221062 9464.06095731 9303.40205962 9593.66139944 9766.00822742]
total_rewards_mean           9576.49716249211
total_rewards_std            137.76485055868852
total_rewards_max            9766.008227423219
total_rewards_min            9303.402059620727
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               28.318398729898036
(Previous) Eval Time (s)     22.00741403689608
Sample Time (s)              16.243258994538337
Epoch Time (s)               66.56907176133245
Total Train Time (s)         18077.784095842857
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 13:59:32.630904 UTC | [2020_01_10_08_58_14] Iteration #270 | Epoch Duration: 66.75355744361877
2020-01-10 13:59:32.631176 UTC | [2020_01_10_08_58_14] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5008924
Z variance train             0.00844256
KL Divergence                37.9236
KL Loss                      3.79236
QF Loss                      332.39697
VF Loss                      98.74129
Policy Loss                  -3544.2046
Q Predictions Mean           3549.164
Q Predictions Std            375.4572
Q Predictions Max            4172.296
Q Predictions Min            2560.3826
V Predictions Mean           3549.1746
V Predictions Std            373.84946
V Predictions Max            4165.688
V Predictions Min            2572.675
Log Pis Mean                 5.0917974
Log Pis Std                  3.7659168
Log Pis Max                  16.716307
Log Pis Min                  -3.8775105
Policy mu Mean               0.007887169
Policy mu Std                1.4007012
Policy mu Max                2.8366418
Policy mu Min                -2.620182
Policy log std Mean          -0.7984295
Policy log std Std           0.44532824
Policy log std Max           -0.10689117
Policy log std Min           -2.7300763
Z mean eval                  2.48671
Z variance eval              0.008188149
total_rewards                [9507.03873547 9628.98600835 9680.5590581  9559.52700994 9677.51219814
 9649.35641498 9574.57555554 9717.93688375 9708.73893875 9530.27070407]
total_rewards_mean           9623.450150709468
total_rewards_std            71.9699614175452
total_rewards_max            9717.936883751738
total_rewards_min            9507.038735470449
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               30.776009526103735
(Previous) Eval Time (s)     22.19162760162726
Sample Time (s)              15.246355686802417
Epoch Time (s)               68.21399281453341
Total Train Time (s)         18146.246292452794
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:00:41.094983 UTC | [2020_01_10_08_58_14] Iteration #271 | Epoch Duration: 68.46361041069031
2020-01-10 14:00:41.095169 UTC | [2020_01_10_08_58_14] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4876208
Z variance train             0.008205396
KL Divergence                37.788456
KL Loss                      3.7788455
QF Loss                      618.8239
VF Loss                      129.01945
Policy Loss                  -3584.7148
Q Predictions Mean           3589.2173
Q Predictions Std            326.57797
Q Predictions Max            4105.871
Q Predictions Min            2613.416
V Predictions Mean           3581.103
V Predictions Std            324.88858
V Predictions Max            4097.351
V Predictions Min            2598.73
Log Pis Mean                 5.3068175
Log Pis Std                  4.092574
Log Pis Max                  14.463301
Log Pis Min                  -5.2609186
Policy mu Mean               -0.041093696
Policy mu Std                1.4500108
Policy mu Max                3.3589482
Policy mu Min                -2.9740343
Policy log std Mean          -0.7898891
Policy log std Std           0.42239872
Policy log std Max           -0.08449492
Policy log std Min           -2.7594638
Z mean eval                  2.5170207
Z variance eval              0.02016339
total_rewards                [ 9637.88492778  9907.73934226  9450.13354675  9971.41837496
  9756.29788919  9579.1325705   9870.23268669 10047.08359842
  9620.16733395  9782.33243508]
total_rewards_mean           9762.24227055842
total_rewards_std            180.2083674501129
total_rewards_max            10047.083598416019
total_rewards_min            9450.133546752
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               28.967819503042847
(Previous) Eval Time (s)     22.440993207972497
Sample Time (s)              16.514297233428806
Epoch Time (s)               67.92310994444415
Total Train Time (s)         18213.719496702775
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:01:48.572815 UTC | [2020_01_10_08_58_14] Iteration #272 | Epoch Duration: 67.47749042510986
2020-01-10 14:01:48.573037 UTC | [2020_01_10_08_58_14] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5154052
Z variance train             0.02014731
KL Divergence                37.516552
KL Loss                      3.7516553
QF Loss                      375.77692
VF Loss                      228.94455
Policy Loss                  -3614.4531
Q Predictions Mean           3613.3545
Q Predictions Std            327.624
Q Predictions Max            4138.435
Q Predictions Min            2579.9973
V Predictions Mean           3610.267
V Predictions Std            324.4269
V Predictions Max            4134.359
V Predictions Min            2582.9229
Log Pis Mean                 5.283478
Log Pis Std                  3.863566
Log Pis Max                  16.12872
Log Pis Min                  -7.901254
Policy mu Mean               -0.09786288
Policy mu Std                1.4217334
Policy mu Max                2.862081
Policy mu Min                -2.800551
Policy log std Mean          -0.8078535
Policy log std Std           0.44673803
Policy log std Max           -0.09141728
Policy log std Min           -2.8280323
Z mean eval                  2.5025434
Z variance eval              0.018266242
total_rewards                [9381.50775414 9578.24135114 9666.39337772 9552.99202007 9563.04462024
 9672.59886928 9776.55080123 9563.834548   9730.61316492 9679.48855921]
total_rewards_mean           9616.526506594011
total_rewards_std            107.04743248944568
total_rewards_max            9776.550801233241
total_rewards_min            9381.507754137463
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               30.454257247969508
(Previous) Eval Time (s)     21.995077603962272
Sample Time (s)              16.04668289422989
Epoch Time (s)               68.49601774616167
Total Train Time (s)         18282.796842803713
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:02:57.651523 UTC | [2020_01_10_08_58_14] Iteration #273 | Epoch Duration: 69.07832884788513
2020-01-10 14:02:57.651705 UTC | [2020_01_10_08_58_14] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.499314
Z variance train             0.01828343
KL Divergence                37.212788
KL Loss                      3.721279
QF Loss                      268.72726
VF Loss                      100.93271
Policy Loss                  -3606.6606
Q Predictions Mean           3610.9978
Q Predictions Std            348.97205
Q Predictions Max            4136.0825
Q Predictions Min            2600.3147
V Predictions Mean           3610.5527
V Predictions Std            347.9396
V Predictions Max            4122.0083
V Predictions Min            2598.0474
Log Pis Mean                 5.1823444
Log Pis Std                  3.5534372
Log Pis Max                  14.06278
Log Pis Min                  -3.7612128
Policy mu Mean               -0.064092815
Policy mu Std                1.4199317
Policy mu Max                3.094933
Policy mu Min                -2.6954374
Policy log std Mean          -0.80069065
Policy log std Std           0.44569933
Policy log std Max           -0.09993911
Policy log std Min           -2.9264672
Z mean eval                  2.5126376
Z variance eval              0.014561271
total_rewards                [9479.64838446 9593.27761493 9633.88408705 9777.62132814 9771.11371378
 9823.30343215 9602.90674163 9808.00511632 9879.08602159 9656.32463565]
total_rewards_mean           9702.517107569394
total_rewards_std            120.6689568161673
total_rewards_max            9879.086021587595
total_rewards_min            9479.648384456852
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               28.83797009428963
(Previous) Eval Time (s)     22.57711594318971
Sample Time (s)              15.203746242914349
Epoch Time (s)               66.61883228039369
Total Train Time (s)         18349.508138632402
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:04:04.368650 UTC | [2020_01_10_08_58_14] Iteration #274 | Epoch Duration: 66.716787815094
2020-01-10 14:04:04.368936 UTC | [2020_01_10_08_58_14] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5118253
Z variance train             0.014520827
KL Divergence                37.12442
KL Loss                      3.7124422
QF Loss                      416.97272
VF Loss                      190.91261
Policy Loss                  -3662.733
Q Predictions Mean           3660.5347
Q Predictions Std            327.06308
Q Predictions Max            4192.7676
Q Predictions Min            2623.2861
V Predictions Mean           3661.7356
V Predictions Std            325.24463
V Predictions Max            4193.7153
V Predictions Min            2631.4058
Log Pis Mean                 5.6131887
Log Pis Std                  3.7068374
Log Pis Max                  15.882017
Log Pis Min                  -3.546495
Policy mu Mean               -0.027106209
Policy mu Std                1.4335166
Policy mu Max                3.0265658
Policy mu Min                -2.7755437
Policy log std Mean          -0.7943614
Policy log std Std           0.4194504
Policy log std Max           0.2198404
Policy log std Min           -2.819974
Z mean eval                  2.5085614
Z variance eval              0.012529282
total_rewards                [9400.43515336 9755.66554999 9570.2719632  9776.04287202 7783.00909031
 9664.18251215 9668.11489081 9888.38748326 6731.03834854 9731.62674107]
total_rewards_mean           9196.877460471052
total_rewards_std            1005.6094578802032
total_rewards_max            9888.387483261198
total_rewards_min            6731.038348544323
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               29.018382018897682
(Previous) Eval Time (s)     22.67480164486915
Sample Time (s)              16.23950729938224
Epoch Time (s)               67.93269096314907
Total Train Time (s)         18417.81394835189
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:05:12.677345 UTC | [2020_01_10_08_58_14] Iteration #275 | Epoch Duration: 68.3082127571106
2020-01-10 14:05:12.677525 UTC | [2020_01_10_08_58_14] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5090706
Z variance train             0.012486378
KL Divergence                37.631203
KL Loss                      3.7631204
QF Loss                      338.56955
VF Loss                      112.453476
Policy Loss                  -3644.5254
Q Predictions Mean           3649.601
Q Predictions Std            344.95068
Q Predictions Max            4185.6455
Q Predictions Min            2596.9624
V Predictions Mean           3648.288
V Predictions Std            344.13293
V Predictions Max            4193.789
V Predictions Min            2591.1318
Log Pis Mean                 5.9957824
Log Pis Std                  3.9715445
Log Pis Max                  16.4944
Log Pis Min                  -5.872306
Policy mu Mean               -0.059847925
Policy mu Std                1.45693
Policy mu Max                3.3223708
Policy mu Min                -3.0465822
Policy log std Mean          -0.8098375
Policy log std Std           0.44617727
Policy log std Max           -0.071859926
Policy log std Min           -2.894158
Z mean eval                  2.5159726
Z variance eval              0.0126999095
total_rewards                [9291.35502945 9319.13979041 9474.24122784 9400.58040638 9639.27459653
 9459.95850333 9377.09870805 9500.52210569 9423.73175552 9262.66585288]
total_rewards_mean           9414.856797608367
total_rewards_std            106.08832985238038
total_rewards_max            9639.274596527695
total_rewards_min            9262.66585288285
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               28.85422458127141
(Previous) Eval Time (s)     23.050086803734303
Sample Time (s)              16.020982371177524
Epoch Time (s)               67.92529375618324
Total Train Time (s)         18485.21359852515
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:06:20.080309 UTC | [2020_01_10_08_58_14] Iteration #276 | Epoch Duration: 67.40262985229492
2020-01-10 14:06:20.080519 UTC | [2020_01_10_08_58_14] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.514936
Z variance train             0.012757714
KL Divergence                37.801605
KL Loss                      3.7801607
QF Loss                      352.35028
VF Loss                      290.3651
Policy Loss                  -3647.4854
Q Predictions Mean           3655.311
Q Predictions Std            324.95905
Q Predictions Max            4189.574
Q Predictions Min            2644.1853
V Predictions Mean           3658.5771
V Predictions Std            325.65167
V Predictions Max            4186.216
V Predictions Min            2653.384
Log Pis Mean                 5.153988
Log Pis Std                  3.6137714
Log Pis Max                  13.863713
Log Pis Min                  -8.346054
Policy mu Mean               -0.032255087
Policy mu Std                1.429395
Policy mu Max                2.9988475
Policy mu Min                -2.8393476
Policy log std Mean          -0.8096535
Policy log std Std           0.4462794
Policy log std Max           -0.07965131
Policy log std Min           -2.8743875
Z mean eval                  2.5170708
Z variance eval              0.015198949
total_rewards                [9601.19670375 9897.60245529 9768.23550552 9811.41561846 9566.88479667
 9569.82201261 9772.30234059 9703.77750789 9650.58724111 9418.54989535]
total_rewards_mean           9676.037407723386
total_rewards_std            134.7961177393484
total_rewards_max            9897.6024552891
total_rewards_min            9418.549895354226
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               29.112769786734134
(Previous) Eval Time (s)     22.527145809028298
Sample Time (s)              17.145306941121817
Epoch Time (s)               68.78522253688425
Total Train Time (s)         18553.833553237375
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:07:28.705970 UTC | [2020_01_10_08_58_14] Iteration #277 | Epoch Duration: 68.62524557113647
2020-01-10 14:07:28.706279 UTC | [2020_01_10_08_58_14] Iteration #277 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.515925
Z variance train             0.015129889
KL Divergence                38.126213
KL Loss                      3.8126214
QF Loss                      403.76007
VF Loss                      112.13507
Policy Loss                  -3605.6775
Q Predictions Mean           3605.4487
Q Predictions Std            332.21252
Q Predictions Max            4134.3667
Q Predictions Min            2567.106
V Predictions Mean           3604.3303
V Predictions Std            330.55188
V Predictions Max            4132.9375
V Predictions Min            2568.3862
Log Pis Mean                 5.3024054
Log Pis Std                  3.8253584
Log Pis Max                  15.658971
Log Pis Min                  -4.386689
Policy mu Mean               -0.030767381
Policy mu Std                1.4198511
Policy mu Max                2.900692
Policy mu Min                -2.9688373
Policy log std Mean          -0.78505534
Policy log std Std           0.42306328
Policy log std Max           -0.019209385
Policy log std Min           -2.8396382
Z mean eval                  2.5117192
Z variance eval              0.0115445815
total_rewards                [ 9697.92199478  9457.76232522  9508.28281125  9937.28553992
  9969.7403336   9330.63169147 10005.47785852  9283.49171968
  9881.07597048  9715.34497434]
total_rewards_mean           9678.70152192653
total_rewards_std            256.1678561570449
total_rewards_max            10005.477858516084
total_rewards_min            9283.491719684125
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               27.873084490187466
(Previous) Eval Time (s)     22.366861209739
Sample Time (s)              15.845338220708072
Epoch Time (s)               66.08528392063454
Total Train Time (s)         18620.5014277203
Epoch                        278
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:08:35.376905 UTC | [2020_01_10_08_58_14] Iteration #278 | Epoch Duration: 66.67041540145874
2020-01-10 14:08:35.377099 UTC | [2020_01_10_08_58_14] Iteration #278 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.510959
Z variance train             0.011505378
KL Divergence                38.72502
KL Loss                      3.872502
QF Loss                      287.5672
VF Loss                      180.84727
Policy Loss                  -3628.787
Q Predictions Mean           3629.5708
Q Predictions Std            337.5036
Q Predictions Max            4175.574
Q Predictions Min            2570.5645
V Predictions Mean           3624.187
V Predictions Std            334.18716
V Predictions Max            4150.0117
V Predictions Min            2578.212
Log Pis Mean                 5.33868
Log Pis Std                  3.637036
Log Pis Max                  14.8460455
Log Pis Min                  -3.4932232
Policy mu Mean               -0.08453836
Policy mu Std                1.4338608
Policy mu Max                2.8832364
Policy mu Min                -2.8526528
Policy log std Mean          -0.7949233
Policy log std Std           0.44370255
Policy log std Max           0.054345608
Policy log std Min           -2.7461462
Z mean eval                  2.4900832
Z variance eval              0.017029133
total_rewards                [ 9550.5789542   9650.81055784  9910.16648483  9647.8105405
  9814.3287274   9609.19778955  9788.0256816  10029.34627233
  9735.58153581  9688.35433041]
total_rewards_mean           9742.420087445646
total_rewards_std            138.77339707152336
total_rewards_max            10029.346272334571
total_rewards_min            9550.578954202643
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               28.642112956382334
(Previous) Eval Time (s)     22.951714066788554
Sample Time (s)              15.791958339046687
Epoch Time (s)               67.38578536221758
Total Train Time (s)         18687.905284040608
Epoch                        279
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:09:42.782722 UTC | [2020_01_10_08_58_14] Iteration #279 | Epoch Duration: 67.40547561645508
2020-01-10 14:09:42.782886 UTC | [2020_01_10_08_58_14] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4904532
Z variance train             0.017045798
KL Divergence                37.34868
KL Loss                      3.7348678
QF Loss                      260.1942
VF Loss                      198.995
Policy Loss                  -3598.472
Q Predictions Mean           3605.4
Q Predictions Std            329.70566
Q Predictions Max            4200.109
Q Predictions Min            2590.099
V Predictions Mean           3600.431
V Predictions Std            328.09232
V Predictions Max            4196.788
V Predictions Min            2592.4084
Log Pis Mean                 5.173721
Log Pis Std                  3.5502439
Log Pis Max                  13.210665
Log Pis Min                  -4.6612024
Policy mu Mean               -0.06353381
Policy mu Std                1.4167069
Policy mu Max                2.8042607
Policy mu Min                -2.6014931
Policy log std Mean          -0.8028919
Policy log std Std           0.435053
Policy log std Max           -0.11685027
Policy log std Min           -2.940973
Z mean eval                  2.5010242
Z variance eval              0.018864494
total_rewards                [9695.77961589 9708.77744421 9761.09868231 9656.29857509 9710.65084515
 9920.75632243 9590.11847957 9840.49421238 9803.73285082 9806.10925867]
total_rewards_mean           9749.38162865276
total_rewards_std            91.66859438263158
total_rewards_max            9920.756322433894
total_rewards_min            9590.11847957169
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               27.538034954108298
(Previous) Eval Time (s)     22.971135153900832
Sample Time (s)              15.429162365850061
Epoch Time (s)               65.93833247385919
Total Train Time (s)         18753.481451843865
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:10:48.361339 UTC | [2020_01_10_08_58_14] Iteration #280 | Epoch Duration: 65.57833480834961
2020-01-10 14:10:48.361489 UTC | [2020_01_10_08_58_14] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5032978
Z variance train             0.018897312
KL Divergence                37.270798
KL Loss                      3.7270799
QF Loss                      319.34558
VF Loss                      202.77576
Policy Loss                  -3672.6777
Q Predictions Mean           3678.4233
Q Predictions Std            358.50308
Q Predictions Max            4248.888
Q Predictions Min            2607.1118
V Predictions Mean           3662.8718
V Predictions Std            355.15234
V Predictions Max            4220.3384
V Predictions Min            2611.8787
Log Pis Mean                 5.4443173
Log Pis Std                  3.9493294
Log Pis Max                  16.165218
Log Pis Min                  -6.5354204
Policy mu Mean               -0.0605808
Policy mu Std                1.4464703
Policy mu Max                3.0161538
Policy mu Min                -2.7121844
Policy log std Mean          -0.8011015
Policy log std Std           0.42629686
Policy log std Max           -0.026995778
Policy log std Min           -2.7746577
Z mean eval                  2.5095646
Z variance eval              0.015416602
total_rewards                [9627.42282972 9405.16455101 9704.0034702  9769.87258311 9596.81140964
 9669.63195329 9619.61327103 9607.59179023 9512.134865   9791.3204613 ]
total_rewards_mean           9630.356718452324
total_rewards_std            108.99351773996521
total_rewards_max            9791.320461297702
total_rewards_min            9405.164551009568
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               26.041220874059945
(Previous) Eval Time (s)     22.61085355374962
Sample Time (s)              16.09164569573477
Epoch Time (s)               64.74372012354434
Total Train Time (s)         18817.84422656987
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:11:52.726184 UTC | [2020_01_10_08_58_14] Iteration #281 | Epoch Duration: 64.36456871032715
2020-01-10 14:11:52.726337 UTC | [2020_01_10_08_58_14] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5083253
Z variance train             0.0154516725
KL Divergence                37.63907
KL Loss                      3.763907
QF Loss                      519.83417
VF Loss                      252.62917
Policy Loss                  -3654.8809
Q Predictions Mean           3654.9673
Q Predictions Std            344.18402
Q Predictions Max            4205.306
Q Predictions Min            2644.1487
V Predictions Mean           3648.3142
V Predictions Std            342.69327
V Predictions Max            4177.875
V Predictions Min            2635.218
Log Pis Mean                 5.6191797
Log Pis Std                  3.84297
Log Pis Max                  14.730608
Log Pis Min                  -4.8254786
Policy mu Mean               -0.07395447
Policy mu Std                1.4281039
Policy mu Max                2.794649
Policy mu Min                -2.9164736
Policy log std Mean          -0.79395336
Policy log std Std           0.4225334
Policy log std Max           -0.053542197
Policy log std Min           -2.9245596
Z mean eval                  2.5094903
Z variance eval              0.011844499
total_rewards                [9835.44638424 9818.37245815 9416.01415374 9563.41958984 9747.57398636
 9485.15258018 9725.02417739 9799.33585184 9728.26530216 9597.86390694]
total_rewards_mean           9671.646839084784
total_rewards_std            139.20062554903103
total_rewards_max            9835.446384236824
total_rewards_min            9416.014153744123
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               29.0499474639073
(Previous) Eval Time (s)     22.23139966232702
Sample Time (s)              16.253925344441086
Epoch Time (s)               67.53527247067541
Total Train Time (s)         18885.426245858427
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:13:00.314048 UTC | [2020_01_10_08_58_14] Iteration #282 | Epoch Duration: 67.58755230903625
2020-01-10 14:13:00.314363 UTC | [2020_01_10_08_58_14] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5076566
Z variance train             0.011904354
KL Divergence                37.8468
KL Loss                      3.7846801
QF Loss                      494.20682
VF Loss                      123.26622
Policy Loss                  -3636.6348
Q Predictions Mean           3644.1309
Q Predictions Std            348.07895
Q Predictions Max            4170.5776
Q Predictions Min            2576.8489
V Predictions Mean           3638.2598
V Predictions Std            345.7906
V Predictions Max            4164.5957
V Predictions Min            2582.3157
Log Pis Mean                 5.5091553
Log Pis Std                  3.6211767
Log Pis Max                  14.769211
Log Pis Min                  -4.1603127
Policy mu Mean               -0.059708457
Policy mu Std                1.4309418
Policy mu Max                2.8215506
Policy mu Min                -2.7816846
Policy log std Mean          -0.8133371
Policy log std Std           0.44886908
Policy log std Max           -0.13269916
Policy log std Min           -2.7542086
Z mean eval                  2.5039713
Z variance eval              0.009633738
total_rewards                [9332.42737411 9408.78952997 9351.54105645 8947.67534326 9208.53853858
 8986.34130835 9564.30975434 9356.354021   9409.12639322 9426.13993161]
total_rewards_mean           9299.124325088744
total_rewards_std            186.35193059042214
total_rewards_max            9564.309754342818
total_rewards_min            8947.675343256067
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               29.748203734867275
(Previous) Eval Time (s)     22.28333935374394
Sample Time (s)              15.755754426121712
Epoch Time (s)               67.78729751473293
Total Train Time (s)         18953.807851580903
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:14:08.701085 UTC | [2020_01_10_08_58_14] Iteration #283 | Epoch Duration: 68.38648200035095
2020-01-10 14:14:08.701357 UTC | [2020_01_10_08_58_14] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5037308
Z variance train             0.009631887
KL Divergence                38.310345
KL Loss                      3.8310344
QF Loss                      303.43286
VF Loss                      108.15842
Policy Loss                  -3626.7366
Q Predictions Mean           3633.5024
Q Predictions Std            372.63358
Q Predictions Max            4181.519
Q Predictions Min            2634.5847
V Predictions Mean           3629.1462
V Predictions Std            372.01556
V Predictions Max            4188.1504
V Predictions Min            2611.8257
Log Pis Mean                 5.3902054
Log Pis Std                  4.054024
Log Pis Max                  15.609568
Log Pis Min                  -5.3872557
Policy mu Mean               -0.05701701
Policy mu Std                1.4218031
Policy mu Max                2.8403869
Policy mu Min                -3.103346
Policy log std Mean          -0.7867904
Policy log std Std           0.4395635
Policy log std Max           -0.07173005
Policy log std Min           -2.829655
Z mean eval                  2.5124679
Z variance eval              0.009337647
total_rewards                [9127.34280488 9622.92617249 9854.69469214 9792.14606153 9757.15834056
 9359.05930171 9780.41177231 9851.80198738 9754.62271958 5125.7449648 ]
total_rewards_mean           9202.590881737613
total_rewards_std            1377.2418078838923
total_rewards_max            9854.694692135665
total_rewards_min            5125.744964799644
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               28.992608169093728
(Previous) Eval Time (s)     22.882255269680172
Sample Time (s)              15.596921176183969
Epoch Time (s)               67.47178461495787
Total Train Time (s)         19021.016806890257
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:15:15.912159 UTC | [2020_01_10_08_58_14] Iteration #284 | Epoch Duration: 67.2105884552002
2020-01-10 14:15:15.912345 UTC | [2020_01_10_08_58_14] Iteration #284 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5111616
Z variance train             0.009294197
KL Divergence                38.917007
KL Loss                      3.8917007
QF Loss                      441.38556
VF Loss                      118.67135
Policy Loss                  -3706.9897
Q Predictions Mean           3710.267
Q Predictions Std            328.7604
Q Predictions Max            4280.96
Q Predictions Min            2642.9607
V Predictions Mean           3709.0212
V Predictions Std            327.83896
V Predictions Max            4271.804
V Predictions Min            2643.559
Log Pis Mean                 5.3913326
Log Pis Std                  3.8417935
Log Pis Max                  16.700985
Log Pis Min                  -5.324664
Policy mu Mean               -0.079344586
Policy mu Std                1.438264
Policy mu Max                2.8438742
Policy mu Min                -3.0640616
Policy log std Mean          -0.8136196
Policy log std Std           0.44217235
Policy log std Max           -0.06607658
Policy log std Min           -2.7418814
Z mean eval                  2.5065935
Z variance eval              0.008319656
total_rewards                [ 9767.18126469  9976.82825004 10064.25763867 10184.59183833
  9680.19348721  9784.36428054  9871.9698963   9983.09869748
  9853.30127049  9979.78556309]
total_rewards_mean           9914.557218685264
total_rewards_std            143.98661984054255
total_rewards_max            10184.591838330387
total_rewards_min            9680.193487213097
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               28.618508032988757
(Previous) Eval Time (s)     22.62082343827933
Sample Time (s)              16.10285784723237
Epoch Time (s)               67.34218931850046
Total Train Time (s)         19088.045224220492
Epoch                        285
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:16:22.945118 UTC | [2020_01_10_08_58_14] Iteration #285 | Epoch Duration: 67.03260469436646
2020-01-10 14:16:22.945366 UTC | [2020_01_10_08_58_14] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5068316
Z variance train             0.008328595
KL Divergence                38.507187
KL Loss                      3.8507187
QF Loss                      212.29738
VF Loss                      150.3384
Policy Loss                  -3706.3962
Q Predictions Mean           3707.3823
Q Predictions Std            337.17734
Q Predictions Max            4242.086
Q Predictions Min            2639.271
V Predictions Mean           3705.7998
V Predictions Std            336.21814
V Predictions Max            4244.9404
V Predictions Min            2637.73
Log Pis Mean                 5.2420163
Log Pis Std                  3.7256687
Log Pis Max                  13.650728
Log Pis Min                  -4.5636015
Policy mu Mean               -0.035660975
Policy mu Std                1.4283414
Policy mu Max                2.9032235
Policy mu Min                -2.7053566
Policy log std Mean          -0.79344887
Policy log std Std           0.43204263
Policy log std Max           -0.071502715
Policy log std Min           -2.8358805
Z mean eval                  2.510175
Z variance eval              0.0075254114
total_rewards                [9120.30083742 9210.29670923 9247.81421571 9363.12437693 9305.67477532
 9428.46442371 9237.75088401 9207.0008443  9211.49603638 9219.97945194]
total_rewards_mean           9255.190255495012
total_rewards_std            83.82286487258942
total_rewards_max            9428.46442371496
total_rewards_min            9120.30083741748
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               25.857380406931043
(Previous) Eval Time (s)     22.310942117124796
Sample Time (s)              16.173887335229665
Epoch Time (s)               64.3422098592855
Total Train Time (s)         19151.783380856737
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:17:26.686772 UTC | [2020_01_10_08_58_14] Iteration #286 | Epoch Duration: 63.74121904373169
2020-01-10 14:17:26.686986 UTC | [2020_01_10_08_58_14] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5102878
Z variance train             0.007517799
KL Divergence                38.890762
KL Loss                      3.8890762
QF Loss                      858.35706
VF Loss                      249.28954
Policy Loss                  -3691.8955
Q Predictions Mean           3698.1243
Q Predictions Std            341.5299
Q Predictions Max            4191.097
Q Predictions Min            2628.03
V Predictions Mean           3686.0874
V Predictions Std            338.98865
V Predictions Max            4175.1616
V Predictions Min            2629.5918
Log Pis Mean                 5.645021
Log Pis Std                  3.7508461
Log Pis Max                  15.47612
Log Pis Min                  -3.5221105
Policy mu Mean               -0.09307576
Policy mu Std                1.4703109
Policy mu Max                2.9681408
Policy mu Min                -2.9649394
Policy log std Mean          -0.7883273
Policy log std Std           0.42822748
Policy log std Max           -0.060285807
Policy log std Min           -2.7855186
Z mean eval                  2.517095
Z variance eval              0.006604144
total_rewards                [ 9784.23074825  9715.46999703  9834.10690148  9591.20285529
  9857.23130046  9925.53070327  9838.61863972  9953.02832572
  9966.82009954 10067.78303756]
total_rewards_mean           9853.402260833564
total_rewards_std            129.27283252416552
total_rewards_max            10067.783037560741
total_rewards_min            9591.202855290976
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               27.875274604652077
(Previous) Eval Time (s)     21.709661914035678
Sample Time (s)              15.79780317703262
Epoch Time (s)               65.38273969572037
Total Train Time (s)         19217.84957104642
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:18:32.759291 UTC | [2020_01_10_08_58_14] Iteration #287 | Epoch Duration: 66.07213973999023
2020-01-10 14:18:32.759454 UTC | [2020_01_10_08_58_14] Iteration #287 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5172107
Z variance train             0.0066071884
KL Divergence                39.166767
KL Loss                      3.9166768
QF Loss                      334.14124
VF Loss                      122.637276
Policy Loss                  -3684.713
Q Predictions Mean           3686.8735
Q Predictions Std            353.68396
Q Predictions Max            4256.25
Q Predictions Min            2613.377
V Predictions Mean           3680.454
V Predictions Std            352.59167
V Predictions Max            4230.934
V Predictions Min            2617.355
Log Pis Mean                 5.757597
Log Pis Std                  3.6471932
Log Pis Max                  13.777101
Log Pis Min                  -3.474226
Policy mu Mean               -0.10834975
Policy mu Std                1.4448526
Policy mu Max                2.805625
Policy mu Min                -2.6439297
Policy log std Mean          -0.8019516
Policy log std Std           0.4335849
Policy log std Max           -0.13002186
Policy log std Min           -2.8642921
Z mean eval                  2.510814
Z variance eval              0.006835942
total_rewards                [ 9824.35219079  9812.99036074  9872.67641737  9901.98993988
  9777.72549535  7309.12658951 10087.69202276  9885.19203946
 10312.1887219  10069.06032471]
total_rewards_mean           9685.299410247457
total_rewards_std            807.1297891064715
total_rewards_max            10312.188721903718
total_rewards_min            7309.126589508138
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               28.46765268780291
(Previous) Eval Time (s)     22.398777205962688
Sample Time (s)              16.922149336431175
Epoch Time (s)               67.78857923019677
Total Train Time (s)         19285.38580597518
Epoch                        288
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:19:40.295927 UTC | [2020_01_10_08_58_14] Iteration #288 | Epoch Duration: 67.53634357452393
2020-01-10 14:19:40.296090 UTC | [2020_01_10_08_58_14] Iteration #288 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5102718
Z variance train             0.0068485932
KL Divergence                38.83071
KL Loss                      3.8830712
QF Loss                      333.39236
VF Loss                      178.48293
Policy Loss                  -3633.0366
Q Predictions Mean           3638.1167
Q Predictions Std            381.8679
Q Predictions Max            4263.027
Q Predictions Min            2617.8806
V Predictions Mean           3639.134
V Predictions Std            381.7307
V Predictions Max            4257.892
V Predictions Min            2618.0708
Log Pis Mean                 5.494921
Log Pis Std                  3.7890162
Log Pis Max                  16.958881
Log Pis Min                  -3.86612
Policy mu Mean               -0.037380937
Policy mu Std                1.434693
Policy mu Max                3.0646489
Policy mu Min                -3.1934128
Policy log std Mean          -0.7980676
Policy log std Std           0.44296092
Policy log std Max           -0.094728574
Policy log std Min           -2.9973445
Z mean eval                  2.5082922
Z variance eval              0.0058689937
total_rewards                [10081.81558212 10304.40107827 10190.79362726 10034.07746878
 10284.37355659 10160.63182665 10050.3255784  10007.5529341
  9695.61545954  9876.4751028 ]
total_rewards_mean           10068.606221451919
total_rewards_std            175.21932386801137
total_rewards_max            10304.401078269218
total_rewards_min            9695.61545954297
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               29.042759203817695
(Previous) Eval Time (s)     22.146259235218167
Sample Time (s)              15.920456275809556
Epoch Time (s)               67.10947471484542
Total Train Time (s)         19352.878221396822
Epoch                        289
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:20:47.792581 UTC | [2020_01_10_08_58_14] Iteration #289 | Epoch Duration: 67.49635481834412
2020-01-10 14:20:47.792806 UTC | [2020_01_10_08_58_14] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5080333
Z variance train             0.0058663334
KL Divergence                38.972054
KL Loss                      3.8972054
QF Loss                      297.21997
VF Loss                      102.566574
Policy Loss                  -3666.5916
Q Predictions Mean           3669.0618
Q Predictions Std            394.6675
Q Predictions Max            4254.6714
Q Predictions Min            2576.4595
V Predictions Mean           3664.2488
V Predictions Std            392.5122
V Predictions Max            4239.5605
V Predictions Min            2631.195
Log Pis Mean                 5.9007974
Log Pis Std                  3.8606381
Log Pis Max                  15.521529
Log Pis Min                  -3.07399
Policy mu Mean               0.011666399
Policy mu Std                1.4681638
Policy mu Max                3.1068656
Policy mu Min                -2.6279123
Policy log std Mean          -0.81602144
Policy log std Std           0.45778072
Policy log std Max           0.064564526
Policy log std Min           -2.9749622
Z mean eval                  2.4961026
Z variance eval              0.005112474
total_rewards                [9437.5932624  9728.53992504 9400.74646115 9469.41164628 9725.31825465
 9471.72710987 9694.53549758 9591.26217256 9669.06285346 9471.8217652 ]
total_rewards_mean           9566.001894819705
total_rewards_std            122.66470025369432
total_rewards_max            9728.539925039078
total_rewards_min            9400.746461152858
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               26.096685418859124
(Previous) Eval Time (s)     22.532852546777576
Sample Time (s)              15.834761435166001
Epoch Time (s)               64.4642994008027
Total Train Time (s)         19416.795916443225
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:21:51.712710 UTC | [2020_01_10_08_58_14] Iteration #290 | Epoch Duration: 63.91973662376404
2020-01-10 14:21:51.712876 UTC | [2020_01_10_08_58_14] Iteration #290 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4949088
Z variance train             0.0050968337
KL Divergence                38.89309
KL Loss                      3.889309
QF Loss                      378.7002
VF Loss                      245.79478
Policy Loss                  -3682.3823
Q Predictions Mean           3682.3208
Q Predictions Std            367.35052
Q Predictions Max            4234.9634
Q Predictions Min            2630.0774
V Predictions Mean           3694.7153
V Predictions Std            367.6477
V Predictions Max            4238.487
V Predictions Min            2631.8843
Log Pis Mean                 5.326967
Log Pis Std                  3.755685
Log Pis Max                  15.341145
Log Pis Min                  -4.1686516
Policy mu Mean               -0.083105035
Policy mu Std                1.4129895
Policy mu Max                3.408339
Policy mu Min                -2.847433
Policy log std Mean          -0.7947469
Policy log std Std           0.42809784
Policy log std Max           -0.061851278
Policy log std Min           -2.7558913
Z mean eval                  2.4759023
Z variance eval              0.005014802
total_rewards                [10071.04411873 10175.58475994 10077.70889201 10322.39396002
 10278.13978798 10272.80569433 10017.50286542 10016.81710519
 10292.70926924 10200.64937337]
total_rewards_mean           10172.535582623135
total_rewards_std            112.46389667249244
total_rewards_max            10322.393960015457
total_rewards_min            10016.817105185397
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               27.45365465665236
(Previous) Eval Time (s)     21.987995245028287
Sample Time (s)              16.483467974700034
Epoch Time (s)               65.92511787638068
Total Train Time (s)         19483.12274842104
Epoch                        291
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:22:58.041866 UTC | [2020_01_10_08_58_14] Iteration #291 | Epoch Duration: 66.32886242866516
2020-01-10 14:22:58.042026 UTC | [2020_01_10_08_58_14] Iteration #291 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4758487
Z variance train             0.005012417
KL Divergence                38.798225
KL Loss                      3.8798225
QF Loss                      5687.6997
VF Loss                      663.6188
Policy Loss                  -3713.5742
Q Predictions Mean           3712.373
Q Predictions Std            454.73334
Q Predictions Max            4299.411
Q Predictions Min            -138.56586
V Predictions Mean           3716.06
V Predictions Std            441.71622
V Predictions Max            4282.018
V Predictions Min            0.3148387
Log Pis Mean                 5.682425
Log Pis Std                  3.8472326
Log Pis Max                  14.625025
Log Pis Min                  -5.4243183
Policy mu Mean               -0.09422644
Policy mu Std                1.4458277
Policy mu Max                2.88395
Policy mu Min                -2.7982779
Policy log std Mean          -0.8235274
Policy log std Std           0.45639992
Policy log std Max           -0.14579958
Policy log std Min           -2.8237376
Z mean eval                  2.475776
Z variance eval              0.007688216
total_rewards                [ 9745.75305005  9992.92222103 10090.85079258  9897.7367268
  9870.19637263  9886.14113038  9523.24700627  9963.49058109
 10181.69193452  9971.04437503]
total_rewards_mean           9912.307419037103
total_rewards_std            172.8562779781777
total_rewards_max            10181.691934517548
total_rewards_min            9523.24700627255
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               28.37327622389421
(Previous) Eval Time (s)     22.39143401104957
Sample Time (s)              16.155037893913686
Epoch Time (s)               66.91974812885746
Total Train Time (s)         19549.888487679884
Epoch                        292
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:24:04.811940 UTC | [2020_01_10_08_58_14] Iteration #292 | Epoch Duration: 66.7696807384491
2020-01-10 14:24:04.812309 UTC | [2020_01_10_08_58_14] Iteration #292 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4743457
Z variance train             0.007666082
KL Divergence                38.413666
KL Loss                      3.8413665
QF Loss                      268.348
VF Loss                      279.4419
Policy Loss                  -3675.5188
Q Predictions Mean           3683.1875
Q Predictions Std            363.6536
Q Predictions Max            4314.7437
Q Predictions Min            2655.4521
V Predictions Mean           3687.6248
V Predictions Std            364.5766
V Predictions Max            4307.869
V Predictions Min            2648.5334
Log Pis Mean                 5.5308075
Log Pis Std                  3.8405228
Log Pis Max                  14.166822
Log Pis Min                  -4.758007
Policy mu Mean               -0.024910303
Policy mu Std                1.4295535
Policy mu Max                2.7758348
Policy mu Min                -2.980933
Policy log std Mean          -0.80563456
Policy log std Std           0.44617236
Policy log std Max           -0.1315811
Policy log std Min           -2.9000206
Z mean eval                  2.4818482
Z variance eval              0.005207865
total_rewards                [ 9781.76821862 10049.14926334 10239.18353067  9986.32026135
  9937.91085733 10090.35531636 10003.49844964  9951.78547034
  9957.02479505 10054.85289013]
total_rewards_mean           10005.184905283013
total_rewards_std            112.41866273162864
total_rewards_max            10239.183530666009
total_rewards_min            9781.768218619989
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               28.434552100952715
(Previous) Eval Time (s)     22.24105925904587
Sample Time (s)              15.600350390654057
Epoch Time (s)               66.27596175065264
Total Train Time (s)         19616.452096039895
Epoch                        293
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:25:11.378358 UTC | [2020_01_10_08_58_14] Iteration #293 | Epoch Duration: 66.56582307815552
2020-01-10 14:25:11.378545 UTC | [2020_01_10_08_58_14] Iteration #293 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4826047
Z variance train             0.0052109594
KL Divergence                38.917416
KL Loss                      3.8917415
QF Loss                      302.2036
VF Loss                      143.17548
Policy Loss                  -3688.4326
Q Predictions Mean           3689.6958
Q Predictions Std            389.79477
Q Predictions Max            4284.457
Q Predictions Min            2610.0278
V Predictions Mean           3683.039
V Predictions Std            388.78912
V Predictions Max            4278.3916
V Predictions Min            2616.8376
Log Pis Mean                 5.5226192
Log Pis Std                  3.6308682
Log Pis Max                  13.698443
Log Pis Min                  -6.346265
Policy mu Mean               -0.04730924
Policy mu Std                1.4362435
Policy mu Max                2.9642615
Policy mu Min                -3.009293
Policy log std Mean          -0.8088921
Policy log std Std           0.4491804
Policy log std Max           -0.02801758
Policy log std Min           -2.9746408
Z mean eval                  2.4731984
Z variance eval              0.009587556
total_rewards                [ 9658.94967154 10060.3329858   9646.62275031 10034.25253569
 10071.50315723 10132.7323549  10028.44229218 10078.96837459
  9909.92323837  9937.3557927 ]
total_rewards_mean           9955.908315330907
total_rewards_std            163.82216374623437
total_rewards_max            10132.732354901473
total_rewards_min            9646.62275030748
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               30.708833385724574
(Previous) Eval Time (s)     22.5306734200567
Sample Time (s)              16.31057715974748
Epoch Time (s)               69.55008396552876
Total Train Time (s)         19685.880796161015
Epoch                        294
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:26:20.812151 UTC | [2020_01_10_08_58_14] Iteration #294 | Epoch Duration: 69.43345141410828
2020-01-10 14:26:20.812445 UTC | [2020_01_10_08_58_14] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4729383
Z variance train             0.009554935
KL Divergence                38.037277
KL Loss                      3.8037279
QF Loss                      352.86212
VF Loss                      197.88736
Policy Loss                  -3729.5933
Q Predictions Mean           3736.709
Q Predictions Std            382.29
Q Predictions Max            4365.4966
Q Predictions Min            2654.6765
V Predictions Mean           3735.1765
V Predictions Std            380.60025
V Predictions Max            4361.0977
V Predictions Min            2687.8389
Log Pis Mean                 5.689893
Log Pis Std                  3.6880927
Log Pis Max                  15.19345
Log Pis Min                  -5.2369633
Policy mu Mean               0.021910852
Policy mu Std                1.4529314
Policy mu Max                2.9314113
Policy mu Min                -2.6071174
Policy log std Mean          -0.80582833
Policy log std Std           0.4399477
Policy log std Max           -0.09779447
Policy log std Min           -2.810524
Z mean eval                  2.4816186
Z variance eval              0.013325502
total_rewards                [5738.74456852 9948.94635544 2240.06023482 6658.52419423 9477.23679187
 9816.67508812 3837.21621448 2262.88820302 1787.19914169 9698.35220149]
total_rewards_mean           6146.584299368011
total_rewards_std            3267.1958328447745
total_rewards_max            9948.946355438684
total_rewards_min            1787.199141690152
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               28.7566246422939
(Previous) Eval Time (s)     22.41370566189289
Sample Time (s)              15.665927059948444
Epoch Time (s)               66.83625736413524
Total Train Time (s)         19752.40872544702
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:27:27.342750 UTC | [2020_01_10_08_58_14] Iteration #295 | Epoch Duration: 66.53008842468262
2020-01-10 14:27:27.342923 UTC | [2020_01_10_08_58_14] Iteration #295 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4823353
Z variance train             0.013305925
KL Divergence                37.612526
KL Loss                      3.7612526
QF Loss                      206.89136
VF Loss                      177.7833
Policy Loss                  -3702.2285
Q Predictions Mean           3704.2817
Q Predictions Std            395.62982
Q Predictions Max            4283.1826
Q Predictions Min            2601.8726
V Predictions Mean           3693.1821
V Predictions Std            393.2469
V Predictions Max            4266.7783
V Predictions Min            2600.0342
Log Pis Mean                 5.310166
Log Pis Std                  3.8073928
Log Pis Max                  14.796101
Log Pis Min                  -6.2373977
Policy mu Mean               -0.078823864
Policy mu Std                1.439358
Policy mu Max                2.855952
Policy mu Min                -2.9101822
Policy log std Mean          -0.78906363
Policy log std Std           0.45352876
Policy log std Max           -0.05862686
Policy log std Min           -2.8468711
Z mean eval                  2.492935
Z variance eval              0.008954255
total_rewards                [ 9931.29477755 10250.65948175 10224.14933825 10266.62039498
  9788.44740643 10081.65007062 10200.06670099 10246.90587007
 10117.25551086 10074.01902123]
total_rewards_mean           10118.106857272487
total_rewards_std            148.66934607280737
total_rewards_max            10266.62039498111
total_rewards_min            9788.447406432017
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               27.30231939209625
(Previous) Eval Time (s)     22.107300444040447
Sample Time (s)              16.633512722328305
Epoch Time (s)               66.043132558465
Total Train Time (s)         19818.342150280252
Epoch                        296
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:28:33.278868 UTC | [2020_01_10_08_58_14] Iteration #296 | Epoch Duration: 65.93581438064575
2020-01-10 14:28:33.279048 UTC | [2020_01_10_08_58_14] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4922767
Z variance train             0.008946508
KL Divergence                38.162476
KL Loss                      3.8162477
QF Loss                      901.2661
VF Loss                      111.552216
Policy Loss                  -3699.9336
Q Predictions Mean           3706.13
Q Predictions Std            392.9047
Q Predictions Max            4251.3804
Q Predictions Min            2632.4883
V Predictions Mean           3703.4932
V Predictions Std            395.05594
V Predictions Max            4261.99
V Predictions Min            2471.3767
Log Pis Mean                 5.707601
Log Pis Std                  3.64984
Log Pis Max                  16.653816
Log Pis Min                  -4.021599
Policy mu Mean               -0.034673806
Policy mu Std                1.4518245
Policy mu Max                3.1294744
Policy mu Min                -3.1175575
Policy log std Mean          -0.8205989
Policy log std Std           0.446525
Policy log std Max           -0.0688857
Policy log std Min           -2.8662536
Z mean eval                  2.5207622
Z variance eval              0.008704713
total_rewards                [9581.08286363 9801.64133546 3341.97094615 9811.46020976 5435.39637872
 9567.65986787 9577.18018646 9888.1067993  9620.10791791 9796.3970366 ]
total_rewards_mean           8642.10035418512
total_rewards_std            2180.376445329553
total_rewards_max            9888.106799303367
total_rewards_min            3341.9709461461666
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               28.433071792591363
(Previous) Eval Time (s)     21.999701066873968
Sample Time (s)              16.037307107355446
Epoch Time (s)               66.47007996682078
Total Train Time (s)         19885.055774626788
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:29:39.995477 UTC | [2020_01_10_08_58_14] Iteration #297 | Epoch Duration: 66.71630120277405
2020-01-10 14:29:39.995659 UTC | [2020_01_10_08_58_14] Iteration #297 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.51757
Z variance train             0.008750817
KL Divergence                39.14721
KL Loss                      3.914721
QF Loss                      574.5469
VF Loss                      838.3773
Policy Loss                  -3737.2378
Q Predictions Mean           3755.5488
Q Predictions Std            362.74893
Q Predictions Max            4339.3574
Q Predictions Min            2705.287
V Predictions Mean           3763.0654
V Predictions Std            363.1332
V Predictions Max            4342.8384
V Predictions Min            2698.6343
Log Pis Mean                 5.6069145
Log Pis Std                  3.8410137
Log Pis Max                  14.858328
Log Pis Min                  -4.567236
Policy mu Mean               -0.045572925
Policy mu Std                1.4510437
Policy mu Max                3.4751606
Policy mu Min                -2.6089573
Policy log std Mean          -0.8107285
Policy log std Std           0.42829302
Policy log std Max           -0.06481092
Policy log std Min           -2.827968
Z mean eval                  2.5049672
Z variance eval              0.012192579
total_rewards                [ 9745.44796296   234.18366204 10201.29506229 10116.72089298
  9157.2972698  10006.75855964  9902.26780347 10020.00582734
  6080.29591104  9764.7876677 ]
total_rewards_mean           8522.906061926016
total_rewards_std            2996.8582600371146
total_rewards_max            10201.295062294119
total_rewards_min            234.18366204283086
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               27.821789520792663
(Previous) Eval Time (s)     22.245608170051128
Sample Time (s)              15.546887572854757
Epoch Time (s)               65.61428526369855
Total Train Time (s)         19950.743373652454
Epoch                        298
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:30:45.688451 UTC | [2020_01_10_08_58_14] Iteration #298 | Epoch Duration: 65.69262647628784
2020-01-10 14:30:45.688713 UTC | [2020_01_10_08_58_14] Iteration #298 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5067227
Z variance train             0.012165306
KL Divergence                38.404606
KL Loss                      3.8404605
QF Loss                      350.66214
VF Loss                      177.6376
Policy Loss                  -3725.0837
Q Predictions Mean           3729.7195
Q Predictions Std            380.26437
Q Predictions Max            4314.5547
Q Predictions Min            2665.3735
V Predictions Mean           3725.6753
V Predictions Std            379.21146
V Predictions Max            4299.9116
V Predictions Min            2676.4268
Log Pis Mean                 5.3739505
Log Pis Std                  4.059398
Log Pis Max                  16.193325
Log Pis Min                  -3.9171612
Policy mu Mean               -0.038918387
Policy mu Std                1.4198698
Policy mu Max                3.0087466
Policy mu Min                -2.4500675
Policy log std Mean          -0.7818578
Policy log std Std           0.41442648
Policy log std Max           -0.09426345
Policy log std Min           -2.6961234
Z mean eval                  2.470752
Z variance eval              0.016780559
total_rewards                [ 9721.24083593  9891.08445564 10056.12682979  8594.98350126
  9907.33281337  9646.59758854  2153.80092128  9934.8021169
  9998.67011728  9820.25127028]
total_rewards_mean           8972.489045028566
total_rewards_std            2307.4203305289816
total_rewards_max            10056.126829794815
total_rewards_min            2153.800921283879
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               28.859648418612778
(Previous) Eval Time (s)     22.323656051419675
Sample Time (s)              15.63037375966087
Epoch Time (s)               66.81367822969332
Total Train Time (s)         20018.442129449453
Epoch                        299
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:31:53.393057 UTC | [2020_01_10_08_58_14] Iteration #299 | Epoch Duration: 67.70411324501038
2020-01-10 14:31:53.393324 UTC | [2020_01_10_08_58_14] Iteration #299 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4713898
Z variance train             0.01674636
KL Divergence                36.77495
KL Loss                      3.6774948
QF Loss                      309.86243
VF Loss                      133.0522
Policy Loss                  -3752.7566
Q Predictions Mean           3755.192
Q Predictions Std            353.44
Q Predictions Max            4244.5654
Q Predictions Min            2666.9841
V Predictions Mean           3750.1072
V Predictions Std            352.8928
V Predictions Max            4232.456
V Predictions Min            2663.7031
Log Pis Mean                 5.3733954
Log Pis Std                  3.808075
Log Pis Max                  13.905802
Log Pis Min                  -8.873127
Policy mu Mean               -0.017620973
Policy mu Std                1.4249017
Policy mu Max                2.7735198
Policy mu Min                -2.8551612
Policy log std Mean          -0.8058114
Policy log std Std           0.43480122
Policy log std Max           -0.056662202
Policy log std Min           -2.8697865
Z mean eval                  2.4824233
Z variance eval              0.019200675
total_rewards                [ 9723.04984055 10080.600577    4218.46416389  6853.13353529
  9825.68844156 10000.44843252 10081.85628128  9904.90508852
  4503.51299251  9975.52052269]
total_rewards_mean           8516.717987579015
total_rewards_std            2273.080830347334
total_rewards_max            10081.856281282786
total_rewards_min            4218.464163885373
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               29.946333786007017
(Previous) Eval Time (s)     23.213829500135034
Sample Time (s)              16.84870494902134
Epoch Time (s)               70.00886823516339
Total Train Time (s)         20087.280896605458
Epoch                        300
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:33:02.233268 UTC | [2020_01_10_08_58_14] Iteration #300 | Epoch Duration: 68.83974885940552
2020-01-10 14:33:02.233420 UTC | [2020_01_10_08_58_14] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4857655
Z variance train             0.01916585
KL Divergence                36.7939
KL Loss                      3.67939
QF Loss                      408.9585
VF Loss                      104.593285
Policy Loss                  -3712.1636
Q Predictions Mean           3710.6064
Q Predictions Std            408.6322
Q Predictions Max            4267.2656
Q Predictions Min            2624.386
V Predictions Mean           3707.5684
V Predictions Std            407.65543
V Predictions Max            4243.252
V Predictions Min            2635.653
Log Pis Mean                 5.019431
Log Pis Std                  3.8636546
Log Pis Max                  21.394821
Log Pis Min                  -3.8071685
Policy mu Mean               -0.046212584
Policy mu Std                1.4037915
Policy mu Max                4.0091896
Policy mu Min                -2.484101
Policy log std Mean          -0.799047
Policy log std Std           0.4437427
Policy log std Max           -0.08165692
Policy log std Min           -2.8779385
Z mean eval                  2.4786766
Z variance eval              0.027099248
total_rewards                [9821.39867215 9607.84910257 9789.94284531 9949.99853183 9712.38376483
 9758.70442213 9792.87037096 9696.82703735 9442.70591582 8038.63467262]
total_rewards_mean           9561.13153355775
total_rewards_std            523.4064801100263
total_rewards_max            9949.998531834211
total_rewards_min            8038.634672615808
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               28.322691679000854
(Previous) Eval Time (s)     22.04442176921293
Sample Time (s)              16.184186986647546
Epoch Time (s)               66.55130043486133
Total Train Time (s)         20153.83699550247
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:34:08.796679 UTC | [2020_01_10_08_58_14] Iteration #301 | Epoch Duration: 66.56309008598328
2020-01-10 14:34:08.796970 UTC | [2020_01_10_08_58_14] Iteration #301 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.478486
Z variance train             0.027137315
KL Divergence                35.583473
KL Loss                      3.5583475
QF Loss                      487.35352
VF Loss                      211.59853
Policy Loss                  -3805.3325
Q Predictions Mean           3808.7896
Q Predictions Std            361.31808
Q Predictions Max            4295.123
Q Predictions Min            2682.4553
V Predictions Mean           3812.802
V Predictions Std            358.07407
V Predictions Max            4296.8135
V Predictions Min            2692.489
Log Pis Mean                 6.0215554
Log Pis Std                  4.077658
Log Pis Max                  15.429595
Log Pis Min                  -6.2579794
Policy mu Mean               -0.016498527
Policy mu Std                1.4920728
Policy mu Max                2.8285565
Policy mu Min                -4.025186
Policy log std Mean          -0.7884083
Policy log std Std           0.430478
Policy log std Max           -0.08261901
Policy log std Min           -2.803137
Z mean eval                  2.475865
Z variance eval              0.023656469
total_rewards                [ 9769.77518021  9873.62468589   278.59777436  9727.8734553
  9823.45232914 10094.11084682  9718.951668    9862.03596289
  9644.97106382  9995.07244858]
total_rewards_mean           8878.846541499635
total_rewards_std            2869.546227193451
total_rewards_max            10094.110846824793
total_rewards_min            278.59777435595714
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               31.475610624998808
(Previous) Eval Time (s)     22.0558919897303
Sample Time (s)              16.115671734325588
Epoch Time (s)               69.6471743490547
Total Train Time (s)         20223.233992510475
Epoch                        302
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:35:18.195232 UTC | [2020_01_10_08_58_14] Iteration #302 | Epoch Duration: 69.39805483818054
2020-01-10 14:35:18.195413 UTC | [2020_01_10_08_58_14] Iteration #302 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4769373
Z variance train             0.023642343
KL Divergence                35.443634
KL Loss                      3.5443635
QF Loss                      450.90903
VF Loss                      113.87649
Policy Loss                  -3718.1797
Q Predictions Mean           3722.228
Q Predictions Std            386.70322
Q Predictions Max            4318.8643
Q Predictions Min            2654.628
V Predictions Mean           3717.9507
V Predictions Std            386.60205
V Predictions Max            4308.5728
V Predictions Min            2654.1465
Log Pis Mean                 5.2581444
Log Pis Std                  3.9523194
Log Pis Max                  17.340988
Log Pis Min                  -3.6650364
Policy mu Mean               -0.041416876
Policy mu Std                1.4284983
Policy mu Max                2.8994923
Policy mu Min                -3.1322849
Policy log std Mean          -0.80303556
Policy log std Std           0.44520858
Policy log std Max           -0.096069336
Policy log std Min           -2.904311
Z mean eval                  2.491301
Z variance eval              0.024764456
total_rewards                [ 9713.28648997 10083.43662229  9850.90788518  9781.94996262
  9885.24683903  9991.14015545  9697.12774705  9723.86559054
   739.03301666  9859.31532702]
total_rewards_mean           8932.530963581443
total_rewards_std            2733.689254273307
total_rewards_max            10083.436622292034
total_rewards_min            739.033016664295
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               27.792420270852745
(Previous) Eval Time (s)     21.806495117023587
Sample Time (s)              15.882001743186265
Epoch Time (s)               65.4809171310626
Total Train Time (s)         20289.134017162956
Epoch                        303
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:36:24.097407 UTC | [2020_01_10_08_58_14] Iteration #303 | Epoch Duration: 65.90185904502869
2020-01-10 14:36:24.097572 UTC | [2020_01_10_08_58_14] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4932976
Z variance train             0.024825156
KL Divergence                34.441048
KL Loss                      3.444105
QF Loss                      449.54468
VF Loss                      207.51797
Policy Loss                  -3743.1096
Q Predictions Mean           3748.1716
Q Predictions Std            377.60205
Q Predictions Max            4295.508
Q Predictions Min            2671.6013
V Predictions Mean           3734.2104
V Predictions Std            376.5537
V Predictions Max            4269.808
V Predictions Min            2653.6052
Log Pis Mean                 5.710636
Log Pis Std                  3.841097
Log Pis Max                  15.45554
Log Pis Min                  -3.4845638
Policy mu Mean               -0.04521509
Policy mu Std                1.4474006
Policy mu Max                2.840461
Policy mu Min                -2.7540386
Policy log std Mean          -0.8072748
Policy log std Std           0.43895122
Policy log std Max           -0.119873196
Policy log std Min           -2.8577266
Z mean eval                  2.4666278
Z variance eval              0.09226404
total_rewards                [9204.308735   9197.06916949 9362.66230192 9437.48655691 9483.65362607
 9293.26146088 9235.09381664 9248.93139427 9301.84759226 9229.94780095]
total_rewards_mean           9299.426245438532
total_rewards_std            93.85254452349464
total_rewards_max            9483.6536260672
total_rewards_min            9197.069169485218
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               29.198813275434077
(Previous) Eval Time (s)     22.22713045589626
Sample Time (s)              15.563622598070651
Epoch Time (s)               66.98956632940099
Total Train Time (s)         20356.51774954563
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:37:31.485733 UTC | [2020_01_10_08_58_14] Iteration #304 | Epoch Duration: 67.38802552223206
2020-01-10 14:37:31.485951 UTC | [2020_01_10_08_58_14] Iteration #304 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4664512
Z variance train             0.09231291
KL Divergence                32.005013
KL Loss                      3.2005012
QF Loss                      278.7747
VF Loss                      238.15016
Policy Loss                  -3796.9917
Q Predictions Mean           3798.7788
Q Predictions Std            383.5617
Q Predictions Max            4362.2007
Q Predictions Min            2704.9258
V Predictions Mean           3803.9824
V Predictions Std            383.1613
V Predictions Max            4365.4473
V Predictions Min            2709.895
Log Pis Mean                 5.8413076
Log Pis Std                  3.689133
Log Pis Max                  13.841305
Log Pis Min                  -6.65307
Policy mu Mean               -0.13875222
Policy mu Std                1.4660113
Policy mu Max                2.8200133
Policy mu Min                -2.9777706
Policy log std Mean          -0.79057854
Policy log std Std           0.411943
Policy log std Max           -0.0861409
Policy log std Min           -2.764427
Z mean eval                  2.4934697
Z variance eval              0.05570925
total_rewards                [9398.52750963 9615.84751574 9865.90900698 9734.7875328  9739.1008541
 9715.39775589 9679.33573129 9563.83709493 9845.07042377 9509.35970461]
total_rewards_mean           9666.717312973404
total_rewards_std            139.19352284185103
total_rewards_max            9865.909006975853
total_rewards_min            9398.52750963011
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               29.415019567590207
(Previous) Eval Time (s)     22.625301096122712
Sample Time (s)              15.18540188902989
Epoch Time (s)               67.22572255274281
Total Train Time (s)         20424.192402830347
Epoch                        305
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:38:39.163735 UTC | [2020_01_10_08_58_14] Iteration #305 | Epoch Duration: 67.67761325836182
2020-01-10 14:38:39.163981 UTC | [2020_01_10_08_58_14] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4921384
Z variance train             0.055673085
KL Divergence                32.69695
KL Loss                      3.269695
QF Loss                      333.41632
VF Loss                      151.31152
Policy Loss                  -3798.9312
Q Predictions Mean           3804.8738
Q Predictions Std            346.4016
Q Predictions Max            4369.6357
Q Predictions Min            2726.5132
V Predictions Mean           3802.782
V Predictions Std            346.07532
V Predictions Max            4361.36
V Predictions Min            2722.42
Log Pis Mean                 6.144142
Log Pis Std                  3.8016896
Log Pis Max                  14.871398
Log Pis Min                  -3.473749
Policy mu Mean               -0.03554917
Policy mu Std                1.5012949
Policy mu Max                2.9827087
Policy mu Min                -2.7476583
Policy log std Mean          -0.79240686
Policy log std Std           0.43686795
Policy log std Max           -0.1532694
Policy log std Min           -2.727006
Z mean eval                  2.4793115
Z variance eval              0.04381119
total_rewards                [ 9879.61008156  9951.41200356 10284.60583686 10246.31095358
 10215.62255589  9752.29735639 10126.44627897 10164.32066107
 10051.08150586 10324.3261905 ]
total_rewards_mean           10099.603342424576
total_rewards_std            178.31215924053657
total_rewards_max            10324.326190496951
total_rewards_min            9752.297356388672
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               30.8308338932693
(Previous) Eval Time (s)     23.076938182581216
Sample Time (s)              16.296183212660253
Epoch Time (s)               70.20395528851077
Total Train Time (s)         20493.326640145388
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:39:48.304195 UTC | [2020_01_10_08_58_14] Iteration #306 | Epoch Duration: 69.14002537727356
2020-01-10 14:39:48.304461 UTC | [2020_01_10_08_58_14] Iteration #306 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4781597
Z variance train             0.04375171
KL Divergence                33.279472
KL Loss                      3.3279474
QF Loss                      505.49164
VF Loss                      316.50488
Policy Loss                  -3697.9517
Q Predictions Mean           3700.1035
Q Predictions Std            352.19125
Q Predictions Max            4228.801
Q Predictions Min            2590.7388
V Predictions Mean           3704.81
V Predictions Std            351.30765
V Predictions Max            4229.2676
V Predictions Min            2595.7568
Log Pis Mean                 5.5504484
Log Pis Std                  3.531967
Log Pis Max                  14.551397
Log Pis Min                  -5.438385
Policy mu Mean               -0.049120415
Policy mu Std                1.4691154
Policy mu Max                3.4489214
Policy mu Min                -3.1753755
Policy log std Mean          -0.7848823
Policy log std Std           0.41850024
Policy log std Max           -0.06374532
Policy log std Min           -2.950303
Z mean eval                  2.4880834
Z variance eval              0.046874393
total_rewards                [ 9878.39609403  9871.66903646 10077.44133975  9827.97648403
  9492.14374632  9971.28184392  9968.53915772  9983.74617551
  9877.77088846 10020.23469494]
total_rewards_mean           9896.919946113796
total_rewards_std            153.60231088429953
total_rewards_max            10077.4413397479
total_rewards_min            9492.143746322434
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               25.249615657608956
(Previous) Eval Time (s)     22.012731302995235
Sample Time (s)              16.77108845161274
Epoch Time (s)               64.03343541221693
Total Train Time (s)         20557.82711954601
Epoch                        307
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:40:52.807962 UTC | [2020_01_10_08_58_14] Iteration #307 | Epoch Duration: 64.50329852104187
2020-01-10 14:40:52.808177 UTC | [2020_01_10_08_58_14] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4876878
Z variance train             0.04684024
KL Divergence                33.589314
KL Loss                      3.3589313
QF Loss                      356.3452
VF Loss                      145.81941
Policy Loss                  -3751.0508
Q Predictions Mean           3753.2952
Q Predictions Std            369.82846
Q Predictions Max            4263.683
Q Predictions Min            2686.8347
V Predictions Mean           3743.901
V Predictions Std            369.0146
V Predictions Max            4258.5166
V Predictions Min            2686.3372
Log Pis Mean                 5.7058506
Log Pis Std                  3.863181
Log Pis Max                  14.351514
Log Pis Min                  -8.09114
Policy mu Mean               -0.08193495
Policy mu Std                1.4613345
Policy mu Max                3.0042431
Policy mu Min                -2.7811267
Policy log std Mean          -0.80687124
Policy log std Std           0.4237969
Policy log std Max           -0.08501123
Policy log std Min           -2.8174334
Z mean eval                  2.5093205
Z variance eval              0.029921493
total_rewards                [1741.38308794  328.22837455 2410.0042417  9973.57864328 7071.03151066
 9826.48645963 1410.91597176 4012.80814308 2642.81011439 1982.43966176]
total_rewards_mean           4139.96862087557
total_rewards_std            3355.507214372902
total_rewards_max            9973.578643281608
total_rewards_min            328.228374548708
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               28.12339196493849
(Previous) Eval Time (s)     22.482300178147852
Sample Time (s)              15.526275715325028
Epoch Time (s)               66.13196785841137
Total Train Time (s)         20623.430535052437
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:41:58.414532 UTC | [2020_01_10_08_58_14] Iteration #308 | Epoch Duration: 65.60620665550232
2020-01-10 14:41:58.414745 UTC | [2020_01_10_08_58_14] Iteration #308 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.50886
Z variance train             0.029951084
KL Divergence                34.74131
KL Loss                      3.474131
QF Loss                      504.24213
VF Loss                      202.08041
Policy Loss                  -3821.1272
Q Predictions Mean           3833.2192
Q Predictions Std            355.0468
Q Predictions Max            4342.103
Q Predictions Min            2800.6257
V Predictions Mean           3827.0312
V Predictions Std            351.86786
V Predictions Max            4328.408
V Predictions Min            2800.1033
Log Pis Mean                 5.825235
Log Pis Std                  3.7408824
Log Pis Max                  13.965242
Log Pis Min                  -3.7621193
Policy mu Mean               -0.07635412
Policy mu Std                1.5053264
Policy mu Max                2.970961
Policy mu Min                -3.3574238
Policy log std Mean          -0.7816326
Policy log std Std           0.412242
Policy log std Max           0.054691672
Policy log std Min           -2.7428577
Z mean eval                  2.4834018
Z variance eval              0.02510271
total_rewards                [ 9701.53816085  3206.51117984 10083.97284034  9890.86770957
  9940.75777317  2278.32729399  9878.50939201  9940.51802954
  2772.54994792   770.91270335]
total_rewards_mean           6846.446503058331
total_rewards_std            3793.002217378452
total_rewards_max            10083.972840341985
total_rewards_min            770.9127033513103
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               29.734508018940687
(Previous) Eval Time (s)     21.956242118030787
Sample Time (s)              15.691081300377846
Epoch Time (s)               67.38183143734932
Total Train Time (s)         20691.511804518756
Epoch                        309
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:43:06.500454 UTC | [2020_01_10_08_58_14] Iteration #309 | Epoch Duration: 68.08554482460022
2020-01-10 14:43:06.500672 UTC | [2020_01_10_08_58_14] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4846282
Z variance train             0.025103992
KL Divergence                34.64432
KL Loss                      3.4644322
QF Loss                      321.73444
VF Loss                      363.3296
Policy Loss                  -3826.7756
Q Predictions Mean           3823.1113
Q Predictions Std            352.1824
Q Predictions Max            4359.901
Q Predictions Min            2716.9854
V Predictions Mean           3814.8943
V Predictions Std            348.25015
V Predictions Max            4336.8623
V Predictions Min            2717.281
Log Pis Mean                 6.051257
Log Pis Std                  3.6862833
Log Pis Max                  14.950093
Log Pis Min                  -4.95656
Policy mu Mean               -0.07257656
Policy mu Std                1.4945244
Policy mu Max                2.823109
Policy mu Min                -2.8965755
Policy log std Mean          -0.79648304
Policy log std Std           0.4380392
Policy log std Max           -0.072034955
Policy log std Min           -2.896954
Z mean eval                  2.4983172
Z variance eval              0.022412684
total_rewards                [ 9677.17850234  9787.43270964  9757.66789619 10039.96601792
 10023.14835398  9945.31182085  9455.86448299  9982.00468191
  9677.2603377   9722.4170764 ]
total_rewards_mean           9806.825187993041
total_rewards_std            178.2421746214091
total_rewards_max            10039.966017919078
total_rewards_min            9455.864482988763
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               27.89047462726012
(Previous) Eval Time (s)     22.65966041898355
Sample Time (s)              15.841135059017688
Epoch Time (s)               66.39127010526136
Total Train Time (s)         20757.433351453394
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:44:12.423709 UTC | [2020_01_10_08_58_14] Iteration #310 | Epoch Duration: 65.92286658287048
2020-01-10 14:44:12.423907 UTC | [2020_01_10_08_58_14] Iteration #310 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4979491
Z variance train             0.02241852
KL Divergence                35.53587
KL Loss                      3.553587
QF Loss                      576.71936
VF Loss                      256.58902
Policy Loss                  -3781.836
Q Predictions Mean           3791.2815
Q Predictions Std            403.44977
Q Predictions Max            4379.0244
Q Predictions Min            371.99966
V Predictions Mean           3791.5293
V Predictions Std            396.94785
V Predictions Max            4368.9404
V Predictions Min            536.0849
Log Pis Mean                 6.0716987
Log Pis Std                  3.6950166
Log Pis Max                  14.424029
Log Pis Min                  -5.9878626
Policy mu Mean               -0.033049572
Policy mu Std                1.4868706
Policy mu Max                2.6037216
Policy mu Min                -2.7357538
Policy log std Mean          -0.8177748
Policy log std Std           0.45633012
Policy log std Max           -0.05166012
Policy log std Min           -2.8200064
Z mean eval                  2.5163872
Z variance eval              0.019046675
total_rewards                [10040.47643901  9957.57118767  9762.24703748  9888.70506988
  9616.92578522  9854.92660653  9917.37297894  7486.03224465
  9982.17312411  9925.80274508]
total_rewards_mean           9643.223321856769
total_rewards_std            728.0063098239767
total_rewards_max            10040.47643900725
total_rewards_min            7486.032244649026
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               28.06425814796239
(Previous) Eval Time (s)     22.191008020658046
Sample Time (s)              15.458874515257776
Epoch Time (s)               65.71414068387821
Total Train Time (s)         20823.31345568644
Epoch                        311
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:45:18.310090 UTC | [2020_01_10_08_58_14] Iteration #311 | Epoch Duration: 65.88600730895996
2020-01-10 14:45:18.310421 UTC | [2020_01_10_08_58_14] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5189583
Z variance train             0.018984541
KL Divergence                36.26352
KL Loss                      3.626352
QF Loss                      323.9389
VF Loss                      223.4559
Policy Loss                  -3811.6755
Q Predictions Mean           3813.4111
Q Predictions Std            381.78427
Q Predictions Max            4361.7383
Q Predictions Min            2700.1243
V Predictions Mean           3800.685
V Predictions Std            379.07758
V Predictions Max            4332.6787
V Predictions Min            2695.6877
Log Pis Mean                 5.9550347
Log Pis Std                  3.752047
Log Pis Max                  13.894209
Log Pis Min                  -3.129672
Policy mu Mean               -0.07410261
Policy mu Std                1.4653476
Policy mu Max                2.8652973
Policy mu Min                -2.6300015
Policy log std Mean          -0.784403
Policy log std Std           0.4316043
Policy log std Max           -0.09679352
Policy log std Min           -2.838587
Z mean eval                  2.5033436
Z variance eval              0.017925587
total_rewards                [10151.20326081  9882.91176431 10198.25639265 10202.98066806
  4527.98520643 10056.18650041  8292.55920094 10035.49119458
 10115.59525128  9913.933377  ]
total_rewards_mean           9337.710281646196
total_rewards_std            1691.5758444792011
total_rewards_max            10202.98066805654
total_rewards_min            4527.985206429787
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               28.19445913983509
(Previous) Eval Time (s)     22.362593181896955
Sample Time (s)              16.15540978498757
Epoch Time (s)               66.71246210671961
Total Train Time (s)         20889.8946438781
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:46:24.896379 UTC | [2020_01_10_08_58_14] Iteration #312 | Epoch Duration: 66.58571314811707
2020-01-10 14:46:24.896640 UTC | [2020_01_10_08_58_14] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5050743
Z variance train             0.017972644
KL Divergence                36.21992
KL Loss                      3.621992
QF Loss                      280.56985
VF Loss                      205.83925
Policy Loss                  -3783.7344
Q Predictions Mean           3788.577
Q Predictions Std            466.84238
Q Predictions Max            4431.1646
Q Predictions Min            -38.247486
V Predictions Mean           3773.4487
V Predictions Std            463.32596
V Predictions Max            4396.16
V Predictions Min            -0.58234763
Log Pis Mean                 5.6982694
Log Pis Std                  3.9305553
Log Pis Max                  16.152
Log Pis Min                  -4.476319
Policy mu Mean               0.02798014
Policy mu Std                1.441014
Policy mu Max                2.7624118
Policy mu Min                -3.1017745
Policy log std Mean          -0.80012035
Policy log std Std           0.43010488
Policy log std Max           -0.05053723
Policy log std Min           -2.8459127
Z mean eval                  2.497156
Z variance eval              0.016631596
total_rewards                [9145.48025758 7292.84408861 9410.12010547 9073.85873974 8573.57753665
 7760.52881276 4687.28524177 5010.06707144 5782.73890306 9245.80302039]
total_rewards_mean           7598.230377747985
total_rewards_std            1735.165844493747
total_rewards_max            9410.12010547224
total_rewards_min            4687.28524177308
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               27.12074962630868
(Previous) Eval Time (s)     22.235550169833004
Sample Time (s)              16.05369709059596
Epoch Time (s)               65.40999688673764
Total Train Time (s)         20955.655298035592
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:47:30.658915 UTC | [2020_01_10_08_58_14] Iteration #313 | Epoch Duration: 65.76209712028503
2020-01-10 14:47:30.659069 UTC | [2020_01_10_08_58_14] Iteration #313 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4986153
Z variance train             0.016709542
KL Divergence                35.959965
KL Loss                      3.5959966
QF Loss                      2514.8423
VF Loss                      267.34705
Policy Loss                  -3838.172
Q Predictions Mean           3834.4233
Q Predictions Std            350.22394
Q Predictions Max            4311.162
Q Predictions Min            2725.0454
V Predictions Mean           3827.4575
V Predictions Std            347.47375
V Predictions Max            4292.976
V Predictions Min            2720.209
Log Pis Mean                 6.0500536
Log Pis Std                  4.115089
Log Pis Max                  13.799025
Log Pis Min                  -4.6678524
Policy mu Mean               -0.0021277654
Policy mu Std                1.5282886
Policy mu Max                3.8609807
Policy mu Min                -3.00753
Policy log std Mean          -0.7846942
Policy log std Std           0.4140956
Policy log std Max           -0.097568914
Policy log std Min           -2.6916165
Z mean eval                  2.479999
Z variance eval              0.0166714
total_rewards                [ 9985.1560794   9720.46769305 10133.51931681  9706.06701285
  9944.84207875 10167.65908265  9802.48052464  5765.3634244
  1865.46809526 10060.89771702]
total_rewards_mean           8715.192102481955
total_rewards_std            2604.839726399993
total_rewards_max            10167.659082652417
total_rewards_min            1865.4680952559033
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               26.964214898180217
(Previous) Eval Time (s)     22.587393776047975
Sample Time (s)              15.584692894015461
Epoch Time (s)               65.13630156824365
Total Train Time (s)         21020.192703468725
Epoch                        314
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:48:35.200652 UTC | [2020_01_10_08_58_14] Iteration #314 | Epoch Duration: 64.54144597053528
2020-01-10 14:48:35.200879 UTC | [2020_01_10_08_58_14] Iteration #314 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4802067
Z variance train             0.016691368
KL Divergence                36.335094
KL Loss                      3.6335094
QF Loss                      438.4104
VF Loss                      115.22372
Policy Loss                  -3819.1738
Q Predictions Mean           3827.206
Q Predictions Std            515.0256
Q Predictions Max            4407.066
Q Predictions Min            14.271996
V Predictions Mean           3814.4668
V Predictions Std            515.4887
V Predictions Max            4396.4307
V Predictions Min            -3.183568
Log Pis Mean                 5.7935505
Log Pis Std                  3.686944
Log Pis Max                  14.463366
Log Pis Min                  -5.4720654
Policy mu Mean               -0.038781606
Policy mu Std                1.4763228
Policy mu Max                2.9814858
Policy mu Min                -2.5129042
Policy log std Mean          -0.7886276
Policy log std Std           0.42761114
Policy log std Max           -0.04569903
Policy log std Min           -2.9739563
Z mean eval                  2.4767992
Z variance eval              0.013248483
total_rewards                [ 9584.96987423  9803.28517287  9775.11375801  9907.42135418
  9817.55390661  9944.17361992  9732.22506865 10069.14820023
 10124.82537965  9801.08319249]
total_rewards_mean           9855.979952683869
total_rewards_std            151.89171688696885
total_rewards_max            10124.82537964683
total_rewards_min            9584.96987423339
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               28.818613283336163
(Previous) Eval Time (s)     21.992242705076933
Sample Time (s)              15.955662083812058
Epoch Time (s)               66.76651807222515
Total Train Time (s)         21087.17196059646
Epoch                        315
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:49:42.184396 UTC | [2020_01_10_08_58_14] Iteration #315 | Epoch Duration: 66.98333787918091
2020-01-10 14:49:42.184631 UTC | [2020_01_10_08_58_14] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.476774
Z variance train             0.01322867
KL Divergence                37.384567
KL Loss                      3.7384567
QF Loss                      590.3574
VF Loss                      112.47087
Policy Loss                  -3814.7625
Q Predictions Mean           3818.8413
Q Predictions Std            497.89822
Q Predictions Max            4356.85
Q Predictions Min            -6.384259
V Predictions Mean           3814.6758
V Predictions Std            497.1464
V Predictions Max            4358.079
V Predictions Min            -4.4228187
Log Pis Mean                 6.045331
Log Pis Std                  3.863567
Log Pis Max                  14.186392
Log Pis Min                  -4.130948
Policy mu Mean               0.0017578701
Policy mu Std                1.4928348
Policy mu Max                3.0905972
Policy mu Min                -2.698084
Policy log std Mean          -0.80255246
Policy log std Std           0.4496758
Policy log std Max           -0.070913374
Policy log std Min           -2.9225318
Z mean eval                  2.4813204
Z variance eval              0.014399467
total_rewards                [9517.58614331 9702.36406772 9681.71777319 9432.01425506 9774.96518847
 9759.72978447 9544.0162725  9369.42254886 9518.03691366 9699.43410885]
total_rewards_mean           9599.928705605838
total_rewards_std            134.61019639436364
total_rewards_max            9774.965188465267
total_rewards_min            9369.422548855851
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               24.345810363069177
(Previous) Eval Time (s)     22.208808104041964
Sample Time (s)              15.447127657942474
Epoch Time (s)               62.001746125053614
Total Train Time (s)         21149.393391895108
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:50:44.409134 UTC | [2020_01_10_08_58_14] Iteration #316 | Epoch Duration: 62.22432827949524
2020-01-10 14:50:44.409359 UTC | [2020_01_10_08_58_14] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4797497
Z variance train             0.0144445
KL Divergence                37.959347
KL Loss                      3.7959347
QF Loss                      357.51532
VF Loss                      149.90327
Policy Loss                  -3811.616
Q Predictions Mean           3814.924
Q Predictions Std            388.1589
Q Predictions Max            4429.4375
Q Predictions Min            2708.2197
V Predictions Mean           3813.898
V Predictions Std            384.50385
V Predictions Max            4403.205
V Predictions Min            2716.3154
Log Pis Mean                 5.896746
Log Pis Std                  3.9548268
Log Pis Max                  15.243633
Log Pis Min                  -3.8985212
Policy mu Mean               0.049214065
Policy mu Std                1.522079
Policy mu Max                2.8419867
Policy mu Min                -2.9606826
Policy log std Mean          -0.78036386
Policy log std Std           0.42428994
Policy log std Max           -0.11171302
Policy log std Min           -2.843052
Z mean eval                  2.4868846
Z variance eval              0.016051259
total_rewards                [9032.45920764 9224.03085954 9158.11481751 9068.73540807 8976.5017604
 9341.49213345 9553.34672414 9453.64674867 1719.28337776 9315.59738044]
total_rewards_mean           8484.320841761686
total_rewards_std            2261.8424257584097
total_rewards_max            9553.346724138954
total_rewards_min            1719.2833777647438
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               29.008442810736597
(Previous) Eval Time (s)     22.43113310309127
Sample Time (s)              15.975723488721997
Epoch Time (s)               67.41529940254986
Total Train Time (s)         21216.457189287525
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:51:51.476964 UTC | [2020_01_10_08_58_14] Iteration #317 | Epoch Duration: 67.06742811203003
2020-01-10 14:51:51.477158 UTC | [2020_01_10_08_58_14] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4853837
Z variance train             0.016044814
KL Divergence                38.392796
KL Loss                      3.8392797
QF Loss                      293.89096
VF Loss                      241.31757
Policy Loss                  -3824.9458
Q Predictions Mean           3837.0461
Q Predictions Std            365.96683
Q Predictions Max            4439.935
Q Predictions Min            2733.0613
V Predictions Mean           3835.5947
V Predictions Std            366.02414
V Predictions Max            4422.13
V Predictions Min            2729.5813
Log Pis Mean                 5.70934
Log Pis Std                  3.5219488
Log Pis Max                  15.72709
Log Pis Min                  -5.830964
Policy mu Mean               0.02117044
Policy mu Std                1.467668
Policy mu Max                3.0089288
Policy mu Min                -2.936075
Policy log std Mean          -0.7910023
Policy log std Std           0.42474127
Policy log std Max           -0.04595408
Policy log std Min           -2.757543
Z mean eval                  2.4773576
Z variance eval              0.013668691
total_rewards                [9502.9794555  5078.12077283 9370.6095604  9236.43932071 9963.97521686
 9355.18305597 9699.89988936 9671.26144962 9716.76546092 9677.38777124]
total_rewards_mean           9127.262195341691
total_rewards_std            1365.0598986712898
total_rewards_max            9963.975216863566
total_rewards_min            5078.120772830731
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               28.514885800890625
(Previous) Eval Time (s)     22.082950077950954
Sample Time (s)              15.128393619321287
Epoch Time (s)               65.72622949816287
Total Train Time (s)         21282.075311922934
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:52:57.099412 UTC | [2020_01_10_08_58_14] Iteration #318 | Epoch Duration: 65.62209129333496
2020-01-10 14:52:57.099644 UTC | [2020_01_10_08_58_14] Iteration #318 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4786656
Z variance train             0.013645789
KL Divergence                38.13817
KL Loss                      3.8138168
QF Loss                      341.36932
VF Loss                      133.72003
Policy Loss                  -3829.672
Q Predictions Mean           3833.1404
Q Predictions Std            387.40186
Q Predictions Max            4397.475
Q Predictions Min            2688.8662
V Predictions Mean           3826.244
V Predictions Std            387.01846
V Predictions Max            4382.828
V Predictions Min            2682.4248
Log Pis Mean                 5.880885
Log Pis Std                  3.6469502
Log Pis Max                  14.851076
Log Pis Min                  -2.549962
Policy mu Mean               -0.05071166
Policy mu Std                1.4915605
Policy mu Max                3.2507918
Policy mu Min                -2.4936974
Policy log std Mean          -0.80832523
Policy log std Std           0.43878463
Policy log std Max           -0.13990617
Policy log std Min           -2.892862
Z mean eval                  2.4717534
Z variance eval              0.013113676
total_rewards                [ 9627.62069118  9829.85136489  9902.61013959 10411.20044653
 10132.99988675 10257.3542917   9896.20320173 10023.83926101
 10092.03871352  9932.37800992]
total_rewards_mean           10010.609600682183
total_rewards_std            212.92440181595563
total_rewards_max            10411.200446528026
total_rewards_min            9627.620691183563
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               29.256340249907225
(Previous) Eval Time (s)     21.9785151546821
Sample Time (s)              15.702791987452656
Epoch Time (s)               66.93764739204198
Total Train Time (s)         21349.187920397148
Epoch                        319
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:54:04.214357 UTC | [2020_01_10_08_58_14] Iteration #319 | Epoch Duration: 67.11454629898071
2020-01-10 14:54:04.214500 UTC | [2020_01_10_08_58_14] Iteration #319 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4712367
Z variance train             0.01314049
KL Divergence                37.957764
KL Loss                      3.7957764
QF Loss                      962.1046
VF Loss                      300.98407
Policy Loss                  -3789.0298
Q Predictions Mean           3804.262
Q Predictions Std            454.4838
Q Predictions Max            4442.682
Q Predictions Min            328.87753
V Predictions Mean           3793.2961
V Predictions Std            462.91376
V Predictions Max            4429.102
V Predictions Min            -1.6809056
Log Pis Mean                 6.0571175
Log Pis Std                  4.1294417
Log Pis Max                  14.85194
Log Pis Min                  -5.194675
Policy mu Mean               -0.079544924
Policy mu Std                1.4843827
Policy mu Max                3.9445276
Policy mu Min                -3.6096694
Policy log std Mean          -0.80888456
Policy log std Std           0.46141273
Policy log std Max           -0.03430283
Policy log std Min           -2.9341908
Z mean eval                  2.4884503
Z variance eval              0.013762049
total_rewards                [ 9839.00790647  1798.24154485  9959.53978014 10148.60231779
 10253.18307847 10142.76320753 10001.63679116 10311.44297816
 10112.66158383  3510.88991373]
total_rewards_mean           8607.796910211702
total_rewards_std            3003.9791978889575
total_rewards_max            10311.442978164101
total_rewards_min            1798.2415448481183
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               27.70592780970037
(Previous) Eval Time (s)     22.155139254871756
Sample Time (s)              15.902615292929113
Epoch Time (s)               65.76368235750124
Total Train Time (s)         21414.801783210598
Epoch                        320
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:55:09.830744 UTC | [2020_01_10_08_58_14] Iteration #320 | Epoch Duration: 65.61609959602356
2020-01-10 14:55:09.830959 UTC | [2020_01_10_08_58_14] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4922614
Z variance train             0.013733002
KL Divergence                38.704002
KL Loss                      3.8704002
QF Loss                      1255.3582
VF Loss                      1249.9106
Policy Loss                  -3881.7334
Q Predictions Mean           3866.9146
Q Predictions Std            377.27292
Q Predictions Max            4421.166
Q Predictions Min            2711.5132
V Predictions Mean           3850.5593
V Predictions Std            376.68674
V Predictions Max            4399.231
V Predictions Min            2704.988
Log Pis Mean                 5.797868
Log Pis Std                  3.7496283
Log Pis Max                  15.002686
Log Pis Min                  -4.4590683
Policy mu Mean               -0.12710917
Policy mu Std                1.4584621
Policy mu Max                2.8053513
Policy mu Min                -3.0360653
Policy log std Mean          -0.82016975
Policy log std Std           0.4315546
Policy log std Max           -0.11938745
Policy log std Min           -2.8393526
Z mean eval                  2.4910483
Z variance eval              0.009888138
total_rewards                [10178.44927167  9941.54022828  9979.44071685 10415.32411322
 10334.38515766 10041.68677075 10087.44133986  9863.95734484
  9959.97355239 10157.99338005]
total_rewards_mean           10096.019187557948
total_rewards_std            168.003120189595
total_rewards_max            10415.324113223514
total_rewards_min            9863.957344839111
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               30.3365862458013
(Previous) Eval Time (s)     22.00728207360953
Sample Time (s)              15.40910497913137
Epoch Time (s)               67.7529732985422
Total Train Time (s)         21483.27441823529
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:56:18.307438 UTC | [2020_01_10_08_58_14] Iteration #321 | Epoch Duration: 68.47633123397827
2020-01-10 14:56:18.307639 UTC | [2020_01_10_08_58_14] Iteration #321 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4893804
Z variance train             0.009881378
KL Divergence                39.678173
KL Loss                      3.9678173
QF Loss                      487.2975
VF Loss                      166.15431
Policy Loss                  -3831.4697
Q Predictions Mean           3839.5078
Q Predictions Std            408.48285
Q Predictions Max            4440.5303
Q Predictions Min            2686.6934
V Predictions Mean           3837.4016
V Predictions Std            407.48615
V Predictions Max            4436.7124
V Predictions Min            2690.953
Log Pis Mean                 5.655048
Log Pis Std                  3.7637227
Log Pis Max                  14.5703
Log Pis Min                  -3.612625
Policy mu Mean               -0.10557479
Policy mu Std                1.4619551
Policy mu Max                3.0255697
Policy mu Min                -2.7910507
Policy log std Mean          -0.79353017
Policy log std Std           0.4300984
Policy log std Max           -0.12631348
Policy log std Min           -2.9027388
Z mean eval                  2.4564643
Z variance eval              0.012098541
total_rewards                [ 9826.24834586 10239.29846396  9889.58938298 10261.65702618
 10188.43423596 10166.72393825  9803.11525915 10028.38821831
  9806.96987283  9954.94568031]
total_rewards_mean           10016.537042379443
total_rewards_std            175.36758676178815
total_rewards_max            10261.657026178853
total_rewards_min            9803.11525915234
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               27.91101704025641
(Previous) Eval Time (s)     22.730346297379583
Sample Time (s)              15.288332731928676
Epoch Time (s)               65.92969606956467
Total Train Time (s)         21548.48368048668
Epoch                        322
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:57:23.518722 UTC | [2020_01_10_08_58_14] Iteration #322 | Epoch Duration: 65.21093964576721
2020-01-10 14:57:23.518862 UTC | [2020_01_10_08_58_14] Iteration #322 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4568021
Z variance train             0.012182809
KL Divergence                38.49379
KL Loss                      3.849379
QF Loss                      472.21597
VF Loss                      225.57314
Policy Loss                  -3749.2612
Q Predictions Mean           3748.7993
Q Predictions Std            483.94153
Q Predictions Max            4357.73
Q Predictions Min            -3.2570972
V Predictions Mean           3740.9927
V Predictions Std            482.41492
V Predictions Max            4352.106
V Predictions Min            -11.787242
Log Pis Mean                 5.564958
Log Pis Std                  3.672625
Log Pis Max                  14.411284
Log Pis Min                  -2.6507797
Policy mu Mean               -0.031971052
Policy mu Std                1.4367993
Policy mu Max                2.7994199
Policy mu Min                -2.7712364
Policy log std Mean          -0.7995475
Policy log std Std           0.4311153
Policy log std Max           -0.08765602
Policy log std Min           -3.0426288
Z mean eval                  2.4700851
Z variance eval              0.016134307
total_rewards                [ 9865.89309441 10093.63137889 10093.83696331 10042.16008693
 10167.15133462  9958.5003415   9873.29214192 10104.56971244
  1959.45748892 10067.57649421]
total_rewards_mean           9222.606903713899
total_rewards_std            2422.921295373806
total_rewards_max            10167.151334624627
total_rewards_min            1959.4574889199203
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               26.746608879882842
(Previous) Eval Time (s)     22.011322180740535
Sample Time (s)              15.328847506083548
Epoch Time (s)               64.08677856670693
Total Train Time (s)         21613.104625901207
Epoch                        323
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:58:28.143226 UTC | [2020_01_10_08_58_14] Iteration #323 | Epoch Duration: 64.62422943115234
2020-01-10 14:58:28.143399 UTC | [2020_01_10_08_58_14] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4689283
Z variance train             0.016053535
KL Divergence                37.544106
KL Loss                      3.7544105
QF Loss                      1071.2924
VF Loss                      887.07025
Policy Loss                  -3838.167
Q Predictions Mean           3851.291
Q Predictions Std            378.74826
Q Predictions Max            4338.057
Q Predictions Min            1999.4673
V Predictions Mean           3850.3286
V Predictions Std            370.00626
V Predictions Max            4373.342
V Predictions Min            2397.2356
Log Pis Mean                 5.603125
Log Pis Std                  3.8182418
Log Pis Max                  14.545763
Log Pis Min                  -3.669076
Policy mu Mean               -0.013236624
Policy mu Std                1.4529569
Policy mu Max                2.8496237
Policy mu Min                -2.7234957
Policy log std Mean          -0.82585305
Policy log std Std           0.45528564
Policy log std Max           -0.12516427
Policy log std Min           -2.9834704
Z mean eval                  2.4435487
Z variance eval              0.016690854
total_rewards                [ 9910.19189719 10158.2656925  10222.20318435 10162.37145983
 10086.94296653 10192.03501107 10142.00350453 10237.62817951
 10035.32675794 10307.89622115]
total_rewards_mean           10145.486487458587
total_rewards_std            106.91390239150392
total_rewards_max            10307.89622114847
total_rewards_min            9910.191897193487
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               28.4823969588615
(Previous) Eval Time (s)     22.548512593843043
Sample Time (s)              15.547130362596363
Epoch Time (s)               66.5780399153009
Total Train Time (s)         21679.154865814373
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 14:59:34.195790 UTC | [2020_01_10_08_58_14] Iteration #324 | Epoch Duration: 66.0522608757019
2020-01-10 14:59:34.195998 UTC | [2020_01_10_08_58_14] Iteration #324 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4435523
Z variance train             0.016676048
KL Divergence                37.10948
KL Loss                      3.7109482
QF Loss                      393.65955
VF Loss                      170.32108
Policy Loss                  -3770.97
Q Predictions Mean           3770.9202
Q Predictions Std            418.65323
Q Predictions Max            4411.141
Q Predictions Min            2669.3186
V Predictions Mean           3763.7925
V Predictions Std            416.87924
V Predictions Max            4391.605
V Predictions Min            2655.5325
Log Pis Mean                 5.9732914
Log Pis Std                  4.006053
Log Pis Max                  19.29858
Log Pis Min                  -6.3032584
Policy mu Mean               0.019246656
Policy mu Std                1.4885997
Policy mu Max                3.0341415
Policy mu Min                -3.7660816
Policy log std Mean          -0.82297945
Policy log std Std           0.46042573
Policy log std Max           -0.01693511
Policy log std Min           -2.937922
Z mean eval                  2.443286
Z variance eval              0.023907177
total_rewards                [ 9623.99642789  9904.10183996  9846.89057328 10099.53226854
 10243.86770164  9911.11908835 10369.36052337  4527.7041588
  9958.54439882 10317.7308894 ]
total_rewards_mean           9480.284787007318
total_rewards_std            1665.3941579509049
total_rewards_max            10369.36052337161
total_rewards_min            4527.704158798354
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               29.166124266106635
(Previous) Eval Time (s)     22.022479655221105
Sample Time (s)              15.149937604088336
Epoch Time (s)               66.33854152541608
Total Train Time (s)         21745.40497628413
Epoch                        325
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:00:40.450122 UTC | [2020_01_10_08_58_14] Iteration #325 | Epoch Duration: 66.25398349761963
2020-01-10 15:00:40.450335 UTC | [2020_01_10_08_58_14] Iteration #325 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4431365
Z variance train             0.02389453
KL Divergence                35.463326
KL Loss                      3.5463326
QF Loss                      964.52203
VF Loss                      279.22714
Policy Loss                  -3882.602
Q Predictions Mean           3899.0044
Q Predictions Std            381.32904
Q Predictions Max            4478.3984
Q Predictions Min            2765.8882
V Predictions Mean           3894.2236
V Predictions Std            380.93445
V Predictions Max            4473.7246
V Predictions Min            2773.0076
Log Pis Mean                 5.870245
Log Pis Std                  3.6333342
Log Pis Max                  15.257599
Log Pis Min                  -4.0765877
Policy mu Mean               -0.114593126
Policy mu Std                1.4849837
Policy mu Max                3.1196265
Policy mu Min                -2.9507966
Policy log std Mean          -0.8029048
Policy log std Std           0.4341702
Policy log std Max           -0.124878705
Policy log std Min           -2.800657
Z mean eval                  2.4286666
Z variance eval              0.029966807
total_rewards                [ 9608.99147971  9974.34527541  9932.7405952   9846.03358271
 10051.87932849  9614.22128556 10098.74603348 10026.7512123
 10105.35036233 10064.17417403]
total_rewards_mean           9932.323332922944
total_rewards_std            176.96726011786302
total_rewards_max            10105.350362333744
total_rewards_min            9608.991479714581
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               25.85866372799501
(Previous) Eval Time (s)     21.937664752826095
Sample Time (s)              15.328818402253091
Epoch Time (s)               63.125146883074194
Total Train Time (s)         21808.938355130143
Epoch                        326
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:01:43.989656 UTC | [2020_01_10_08_58_14] Iteration #326 | Epoch Duration: 63.53912329673767
2020-01-10 15:01:43.989946 UTC | [2020_01_10_08_58_14] Iteration #326 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4286914
Z variance train             0.029929962
KL Divergence                33.828808
KL Loss                      3.382881
QF Loss                      468.02603
VF Loss                      122.18326
Policy Loss                  -3869.6006
Q Predictions Mean           3874.7114
Q Predictions Std            371.33096
Q Predictions Max            4360.0024
Q Predictions Min            2750.7905
V Predictions Mean           3874.5999
V Predictions Std            369.70703
V Predictions Max            4365.6465
V Predictions Min            2758.4058
Log Pis Mean                 5.807262
Log Pis Std                  4.099796
Log Pis Max                  15.693282
Log Pis Min                  -7.6858377
Policy mu Mean               -0.012873031
Policy mu Std                1.4774513
Policy mu Max                3.0641932
Policy mu Min                -2.945552
Policy log std Mean          -0.80688834
Policy log std Std           0.43991137
Policy log std Max           0.025436282
Policy log std Min           -2.7613463
Z mean eval                  2.4347105
Z variance eval              0.026384871
total_rewards                [ 9472.45589278  9556.50465639  9829.89976339  9796.93858288
  9807.55759402  9399.94423604  9823.30097896  9711.09877402
  9814.9164351  10036.97656388]
total_rewards_mean           9724.959347746892
total_rewards_std            183.3292079084489
total_rewards_max            10036.976563875985
total_rewards_min            9399.944236035812
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               27.609412224963307
(Previous) Eval Time (s)     22.35136012500152
Sample Time (s)              15.879030581563711
Epoch Time (s)               65.83980293152854
Total Train Time (s)         21874.529924814124
Epoch                        327
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:02:49.587149 UTC | [2020_01_10_08_58_14] Iteration #327 | Epoch Duration: 65.59698796272278
2020-01-10 15:02:49.587345 UTC | [2020_01_10_08_58_14] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.437556
Z variance train             0.026375076
KL Divergence                34.50656
KL Loss                      3.4506562
QF Loss                      575.8656
VF Loss                      315.4317
Policy Loss                  -3807.725
Q Predictions Mean           3812.4783
Q Predictions Std            452.7256
Q Predictions Max            4412.549
Q Predictions Min            3.9791124
V Predictions Mean           3796.511
V Predictions Std            451.5673
V Predictions Max            4380.7153
V Predictions Min            -20.223778
Log Pis Mean                 5.805424
Log Pis Std                  3.9736288
Log Pis Max                  14.972189
Log Pis Min                  -5.733833
Policy mu Mean               -0.03994643
Policy mu Std                1.4949617
Policy mu Max                3.3021348
Policy mu Min                -2.8297248
Policy log std Mean          -0.7846196
Policy log std Std           0.43297023
Policy log std Max           -0.11193016
Policy log std Min           -2.749099
Z mean eval                  2.4276288
Z variance eval              0.02719538
total_rewards                [6900.18639034 9297.37434133 9393.30118849 9633.85698246 9267.78188328
 9416.24366618 9461.96585699 9337.68915145 9257.03457112 9523.95361657]
total_rewards_mean           9148.938764821312
total_rewards_std            757.9767900370568
total_rewards_max            9633.856982462787
total_rewards_min            6900.186390342703
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               29.423674009740353
(Previous) Eval Time (s)     22.108239143155515
Sample Time (s)              15.245139357633889
Epoch Time (s)               66.77705251052976
Total Train Time (s)         21941.110364929307
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:03:56.167013 UTC | [2020_01_10_08_58_14] Iteration #328 | Epoch Duration: 66.57952404022217
2020-01-10 15:03:56.167161 UTC | [2020_01_10_08_58_14] Iteration #328 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4270234
Z variance train             0.027373016
KL Divergence                34.249405
KL Loss                      3.4249406
QF Loss                      434.8481
VF Loss                      346.82843
Policy Loss                  -3873.6758
Q Predictions Mean           3889.1213
Q Predictions Std            383.61508
Q Predictions Max            4389.428
Q Predictions Min            2668.608
V Predictions Mean           3872.2014
V Predictions Std            380.42334
V Predictions Max            4375.936
V Predictions Min            2674.8423
Log Pis Mean                 5.2839108
Log Pis Std                  3.93546
Log Pis Max                  18.294472
Log Pis Min                  -6.525206
Policy mu Mean               -0.040360335
Policy mu Std                1.4594928
Policy mu Max                3.315151
Policy mu Min                -2.5652986
Policy log std Mean          -0.78737265
Policy log std Std           0.45053533
Policy log std Max           -0.07480593
Policy log std Min           -2.8949313
Z mean eval                  2.43576
Z variance eval              0.028469646
total_rewards                [ 9937.70695657 10255.14507426 10267.78986077 10181.27931377
  9748.14434175 10274.82952402  1355.89963887 10019.2280784
 10260.99351306 10184.93893728]
total_rewards_mean           9248.595523875203
total_rewards_std            2636.0878115198407
total_rewards_max            10274.82952402433
total_rewards_min            1355.8996388704677
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               28.388945614919066
(Previous) Eval Time (s)     21.91045910026878
Sample Time (s)              15.194231847766787
Epoch Time (s)               65.49363656295463
Total Train Time (s)         22008.137314551976
Epoch                        329
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:05:03.199906 UTC | [2020_01_10_08_58_14] Iteration #329 | Epoch Duration: 67.03258275985718
2020-01-10 15:05:03.200226 UTC | [2020_01_10_08_58_14] Iteration #329 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4361603
Z variance train             0.028430467
KL Divergence                34.53568
KL Loss                      3.453568
QF Loss                      426.81165
VF Loss                      144.73256
Policy Loss                  -3892.8804
Q Predictions Mean           3901.2153
Q Predictions Std            402.01614
Q Predictions Max            4417.2256
Q Predictions Min            2589.4023
V Predictions Mean           3887.9766
V Predictions Std            401.4484
V Predictions Max            4405.8716
V Predictions Min            2548.92
Log Pis Mean                 6.0244656
Log Pis Std                  3.894949
Log Pis Max                  18.02016
Log Pis Min                  -4.1738095
Policy mu Mean               -0.016971763
Policy mu Std                1.5059166
Policy mu Max                3.0685585
Policy mu Min                -3.6027713
Policy log std Mean          -0.7927312
Policy log std Std           0.4217668
Policy log std Max           -0.090848684
Policy log std Min           -2.9277925
Z mean eval                  2.4551036
Z variance eval              0.023863416
total_rewards                [ 9985.34936651  9666.02625273  9572.38995857  9905.39035541
  9820.44399815  9807.28963271 10199.20842298  9980.52078368
  9953.01397013 10143.68082695]
total_rewards_mean           9903.331356782393
total_rewards_std            185.04029767667245
total_rewards_max            10199.208422979571
total_rewards_min            9572.389958571055
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               27.444853213150054
(Previous) Eval Time (s)     23.44912320608273
Sample Time (s)              16.174822457134724
Epoch Time (s)               67.06879887636751
Total Train Time (s)         22074.186061426066
Epoch                        330
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:06:09.251146 UTC | [2020_01_10_08_58_14] Iteration #330 | Epoch Duration: 66.05071783065796
2020-01-10 15:06:09.251350 UTC | [2020_01_10_08_58_14] Iteration #330 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4543958
Z variance train             0.02391592
KL Divergence                34.44
KL Loss                      3.444
QF Loss                      361.37442
VF Loss                      131.67046
Policy Loss                  -3892.0408
Q Predictions Mean           3902.724
Q Predictions Std            388.33923
Q Predictions Max            4493.133
Q Predictions Min            2701.2485
V Predictions Mean           3896.024
V Predictions Std            386.5413
V Predictions Max            4476.5464
V Predictions Min            2705.8933
Log Pis Mean                 5.829726
Log Pis Std                  3.7769747
Log Pis Max                  15.383032
Log Pis Min                  -4.3369784
Policy mu Mean               -0.08390144
Policy mu Std                1.4784898
Policy mu Max                2.907939
Policy mu Min                -2.900566
Policy log std Mean          -0.8000445
Policy log std Std           0.41575533
Policy log std Max           -0.12966636
Policy log std Min           -2.7477198
Z mean eval                  2.4381266
Z variance eval              0.102664806
total_rewards                [ 9267.52633587  5992.61276001 10082.85999312   700.59772828
  9367.74182402  9827.47547666  9719.67146207  9869.03714783
  9932.57212732  9325.93434838]
total_rewards_mean           8408.602920355219
total_rewards_std            2806.0672370658926
total_rewards_max            10082.859993116752
total_rewards_min            700.5977282807033
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               27.266361746005714
(Previous) Eval Time (s)     22.430752316024154
Sample Time (s)              15.197476430330426
Epoch Time (s)               64.8945904923603
Total Train Time (s)         22138.758125904016
Epoch                        331
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:07:13.829162 UTC | [2020_01_10_08_58_14] Iteration #331 | Epoch Duration: 64.57763910293579
2020-01-10 15:07:13.829437 UTC | [2020_01_10_08_58_14] Iteration #331 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4380436
Z variance train             0.10203111
KL Divergence                32.767258
KL Loss                      3.2767258
QF Loss                      2126.7805
VF Loss                      233.05923
Policy Loss                  -3794.4177
Q Predictions Mean           3788.8906
Q Predictions Std            383.08444
Q Predictions Max            4321.2563
Q Predictions Min            2634.8528
V Predictions Mean           3786.5195
V Predictions Std            382.02365
V Predictions Max            4300.083
V Predictions Min            2642.8723
Log Pis Mean                 5.9947424
Log Pis Std                  3.7624447
Log Pis Max                  17.946457
Log Pis Min                  -3.3263433
Policy mu Mean               -0.12062669
Policy mu Std                1.4830079
Policy mu Max                3.3643951
Policy mu Min                -2.6587949
Policy log std Mean          -0.8039608
Policy log std Std           0.44506466
Policy log std Max           -0.08924049
Policy log std Min           -2.7777696
Z mean eval                  2.43955
Z variance eval              0.051291984
total_rewards                [ 9990.56836308 10242.51603633 10550.75278266 10303.57533604
 10016.23422377 10081.86802408 10142.13953111 10242.76522244
 10048.96873995 10366.00146961]
total_rewards_mean           10198.538972907825
total_rewards_std            168.12849087820135
total_rewards_max            10550.752782661246
total_rewards_min            9990.56836308128
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               29.17022740188986
(Previous) Eval Time (s)     22.113523073960096
Sample Time (s)              15.734733034856617
Epoch Time (s)               67.01848351070657
Total Train Time (s)         22205.598724005744
Epoch                        332
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:08:20.674243 UTC | [2020_01_10_08_58_14] Iteration #332 | Epoch Duration: 66.84459781646729
2020-01-10 15:08:20.674476 UTC | [2020_01_10_08_58_14] Iteration #332 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4404943
Z variance train             0.051133703
KL Divergence                33.106724
KL Loss                      3.3106725
QF Loss                      1044.7262
VF Loss                      267.01474
Policy Loss                  -3843.5547
Q Predictions Mean           3844.0015
Q Predictions Std            410.85217
Q Predictions Max            4480.055
Q Predictions Min            2725.7715
V Predictions Mean           3842.0967
V Predictions Std            408.64316
V Predictions Max            4458.423
V Predictions Min            2731.002
Log Pis Mean                 5.8535957
Log Pis Std                  3.7864046
Log Pis Max                  15.799607
Log Pis Min                  -4.9815745
Policy mu Mean               -0.12156268
Policy mu Std                1.4789321
Policy mu Max                2.8959918
Policy mu Min                -2.5350633
Policy log std Mean          -0.7918918
Policy log std Std           0.4202954
Policy log std Max           -0.12366739
Policy log std Min           -2.9927788
Z mean eval                  2.456414
Z variance eval              0.02775674
total_rewards                [10204.72688675 10128.07105752 10097.24090147 10184.86427586
 10099.87613565 10356.66521871 10211.98270098 10180.45993824
 10228.64019041 10209.52237708]
total_rewards_mean           10190.204968265763
total_rewards_std            71.4355139316702
total_rewards_max            10356.665218705584
total_rewards_min            10097.240901469808
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               27.45418040594086
(Previous) Eval Time (s)     21.93935450911522
Sample Time (s)              15.5891476389952
Epoch Time (s)               64.98268255405128
Total Train Time (s)         22271.00606926158
Epoch                        333
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:09:26.083866 UTC | [2020_01_10_08_58_14] Iteration #333 | Epoch Duration: 65.40922856330872
2020-01-10 15:09:26.084012 UTC | [2020_01_10_08_58_14] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.454916
Z variance train             0.027733702
KL Divergence                34.274452
KL Loss                      3.4274452
QF Loss                      340.88696
VF Loss                      214.39359
Policy Loss                  -3892.1248
Q Predictions Mean           3900.3806
Q Predictions Std            353.5708
Q Predictions Max            4433.8994
Q Predictions Min            2703.8782
V Predictions Mean           3899.4043
V Predictions Std            351.78424
V Predictions Max            4430.4297
V Predictions Min            2715.064
Log Pis Mean                 5.7826
Log Pis Std                  3.9794521
Log Pis Max                  15.531554
Log Pis Min                  -4.9183197
Policy mu Mean               -0.10765463
Policy mu Std                1.4992492
Policy mu Max                2.7646103
Policy mu Min                -2.9410288
Policy log std Mean          -0.79482716
Policy log std Std           0.4175061
Policy log std Max           -0.10754959
Policy log std Min           -3.0074754
Z mean eval                  2.4673731
Z variance eval              0.023021622
total_rewards                [9440.72462331 9524.61973423 9677.55907459 9606.33400573 9694.22153724
 9803.64523773 9624.93218083 9598.56484666 9455.70958259 9601.85155202]
total_rewards_mean           9602.816237492212
total_rewards_std            104.31824139108859
total_rewards_max            9803.645237730205
total_rewards_min            9440.724623311491
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               27.137583991046995
(Previous) Eval Time (s)     22.365627233870327
Sample Time (s)              15.668164270464331
Epoch Time (s)               65.17137549538165
Total Train Time (s)         22336.038340755273
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:10:31.118808 UTC | [2020_01_10_08_58_14] Iteration #334 | Epoch Duration: 65.03467130661011
2020-01-10 15:10:31.118970 UTC | [2020_01_10_08_58_14] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4675395
Z variance train             0.02302431
KL Divergence                34.72108
KL Loss                      3.4721081
QF Loss                      650.47363
VF Loss                      475.40213
Policy Loss                  -3906.8477
Q Predictions Mean           3912.9692
Q Predictions Std            414.21027
Q Predictions Max            4459.37
Q Predictions Min            703.9754
V Predictions Mean           3906.2231
V Predictions Std            399.7014
V Predictions Max            4459.158
V Predictions Min            1158.6998
Log Pis Mean                 6.2141213
Log Pis Std                  3.9561698
Log Pis Max                  15.148602
Log Pis Min                  -5.118819
Policy mu Mean               -0.09173814
Policy mu Std                1.5110999
Policy mu Max                2.8943102
Policy mu Min                -2.8458517
Policy log std Mean          -0.810729
Policy log std Std           0.42384422
Policy log std Max           -0.14029898
Policy log std Min           -2.8341048
Z mean eval                  2.482738
Z variance eval              0.046116423
total_rewards                [9329.35126543 9378.31669497 9446.728106   9054.76225881 9409.82007079
 9462.7417826  9461.9872605  9467.75539732 9199.24463032 9161.00801784]
total_rewards_mean           9337.171548459033
total_rewards_std            140.4442755719003
total_rewards_max            9467.755397319344
total_rewards_min            9054.762258812676
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               28.162320150062442
(Previous) Eval Time (s)     22.22865577135235
Sample Time (s)              15.283320433460176
Epoch Time (s)               65.67429635487497
Total Train Time (s)         22401.566516057122
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:11:36.652289 UTC | [2020_01_10_08_58_14] Iteration #335 | Epoch Duration: 65.5331597328186
2020-01-10 15:11:36.652545 UTC | [2020_01_10_08_58_14] Iteration #335 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4836333
Z variance train             0.045959834
KL Divergence                34.4467
KL Loss                      3.4446702
QF Loss                      376.46796
VF Loss                      999.7117
Policy Loss                  -3861.7104
Q Predictions Mean           3861.9634
Q Predictions Std            401.31247
Q Predictions Max            4394.7783
Q Predictions Min            2723.2422
V Predictions Mean           3836.9294
V Predictions Std            401.48727
V Predictions Max            4380.203
V Predictions Min            2700.2065
Log Pis Mean                 5.8077583
Log Pis Std                  4.0135965
Log Pis Max                  16.153048
Log Pis Min                  -5.8148556
Policy mu Mean               -0.033919353
Policy mu Std                1.4645941
Policy mu Max                3.1535375
Policy mu Min                -2.6782606
Policy log std Mean          -0.8060549
Policy log std Std           0.42590556
Policy log std Max           -0.116794705
Policy log std Min           -2.957318
Z mean eval                  2.4782014
Z variance eval              0.022756169
total_rewards                [ 9976.54948312  9740.39465583 10265.52838907 10192.03289056
 10148.85749248 10205.24333083 10106.53952616  9782.722291
  9676.45900942  9828.24045812]
total_rewards_mean           9992.256752658186
total_rewards_std            207.786188984113
total_rewards_max            10265.528389072248
total_rewards_min            9676.459009415279
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               27.886860684026033
(Previous) Eval Time (s)     22.087248449679464
Sample Time (s)              16.319108956493437
Epoch Time (s)               66.29321809019893
Total Train Time (s)         22467.842775921803
Epoch                        336
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:12:42.933070 UTC | [2020_01_10_08_58_14] Iteration #336 | Epoch Duration: 66.2803201675415
2020-01-10 15:12:42.933300 UTC | [2020_01_10_08_58_14] Iteration #336 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.479177
Z variance train             0.02283099
KL Divergence                34.85298
KL Loss                      3.4852982
QF Loss                      1161.5796
VF Loss                      281.99255
Policy Loss                  -3828.891
Q Predictions Mean           3832.6768
Q Predictions Std            452.28583
Q Predictions Max            4431.077
Q Predictions Min            193.18652
V Predictions Mean           3823.9346
V Predictions Std            455.47003
V Predictions Max            4396.2817
V Predictions Min            32.23158
Log Pis Mean                 5.6568136
Log Pis Std                  3.6177907
Log Pis Max                  21.440554
Log Pis Min                  -1.7848889
Policy mu Mean               -0.07121951
Policy mu Std                1.4515333
Policy mu Max                4.1473055
Policy mu Min                -3.198504
Policy log std Mean          -0.8025176
Policy log std Std           0.4409542
Policy log std Max           -0.06751585
Policy log std Min           -3.0005784
Z mean eval                  2.4679275
Z variance eval              0.020611772
total_rewards                [ 9849.03428031  9899.05337361 10189.493034    9916.63847526
 10134.70720594 10014.51591717 10041.53652569 10025.36569438
 10262.87424597  9988.66448003]
total_rewards_mean           10032.188323237588
total_rewards_std            124.67299223141113
total_rewards_max            10262.874245966545
total_rewards_min            9849.034280313863
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               28.13132479507476
(Previous) Eval Time (s)     22.07411915110424
Sample Time (s)              15.594864920247346
Epoch Time (s)               65.80030886642635
Total Train Time (s)         22533.71958067501
Epoch                        337
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:13:48.812424 UTC | [2020_01_10_08_58_14] Iteration #337 | Epoch Duration: 65.87896370887756
2020-01-10 15:13:48.812583 UTC | [2020_01_10_08_58_14] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4682174
Z variance train             0.020661453
KL Divergence                34.81481
KL Loss                      3.4814813
QF Loss                      307.9486
VF Loss                      132.99628
Policy Loss                  -3909.5244
Q Predictions Mean           3907.6072
Q Predictions Std            376.7387
Q Predictions Max            4472.7754
Q Predictions Min            2780.2231
V Predictions Mean           3904.2622
V Predictions Std            373.68436
V Predictions Max            4464.722
V Predictions Min            2769.9177
Log Pis Mean                 6.129305
Log Pis Std                  3.6050317
Log Pis Max                  16.339237
Log Pis Min                  -3.2485728
Policy mu Mean               -0.031899385
Policy mu Std                1.4968979
Policy mu Max                3.6699116
Policy mu Min                -2.6488192
Policy log std Mean          -0.775825
Policy log std Std           0.41146177
Policy log std Max           -0.06362969
Policy log std Min           -2.9118896
Z mean eval                  2.4685395
Z variance eval              0.01979579
total_rewards                [10047.38938739  9738.10108469 10041.60177585 10100.78619082
  9950.32589037 10031.90091791  9992.01694065 10043.61875394
  9945.24660152  9990.75095611]
total_rewards_mean           9988.17384992534
total_rewards_std            94.79544913000464
total_rewards_max            10100.786190819037
total_rewards_min            9738.101084687803
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               28.019087786786258
(Previous) Eval Time (s)     22.15247656684369
Sample Time (s)              16.15129509428516
Epoch Time (s)               66.3228594479151
Total Train Time (s)         22600.590065270197
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:14:55.685035 UTC | [2020_01_10_08_58_14] Iteration #338 | Epoch Duration: 66.87233757972717
2020-01-10 15:14:55.685175 UTC | [2020_01_10_08_58_14] Iteration #338 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4703746
Z variance train             0.019803306
KL Divergence                34.790665
KL Loss                      3.4790666
QF Loss                      411.55753
VF Loss                      272.7542
Policy Loss                  -3839.8596
Q Predictions Mean           3837.9602
Q Predictions Std            500.689
Q Predictions Max            4395.051
Q Predictions Min            -48.729053
V Predictions Mean           3829.5847
V Predictions Std            499.77795
V Predictions Max            4391.868
V Predictions Min            -61.306263
Log Pis Mean                 6.220438
Log Pis Std                  3.6698422
Log Pis Max                  14.378931
Log Pis Min                  -5.0637655
Policy mu Mean               -0.034347396
Policy mu Std                1.4851054
Policy mu Max                2.9875746
Policy mu Min                -2.939151
Policy log std Mean          -0.83062893
Policy log std Std           0.45109615
Policy log std Max           -0.105352074
Policy log std Min           -2.9740455
Z mean eval                  2.4505227
Z variance eval              0.04150939
total_rewards                [ 9500.79722704 10121.8292373   9947.54158169  9624.35352983
 10000.29443475  9751.85867951 10184.64407181  9861.41918647
  9689.88317077  9900.01971921]
total_rewards_mean           9858.264083837543
total_rewards_std            206.8956281730481
total_rewards_max            10184.644071808461
total_rewards_min            9500.797227037729
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               27.057451574131846
(Previous) Eval Time (s)     22.701685643289238
Sample Time (s)              16.914503519423306
Epoch Time (s)               66.67364073684439
Total Train Time (s)         22667.11016899394
Epoch                        339
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:16:02.208806 UTC | [2020_01_10_08_58_14] Iteration #339 | Epoch Duration: 66.52351236343384
2020-01-10 15:16:02.208989 UTC | [2020_01_10_08_58_14] Iteration #339 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4509854
Z variance train             0.042116385
KL Divergence                33.10544
KL Loss                      3.3105438
QF Loss                      1069.6227
VF Loss                      103.5038
Policy Loss                  -3886.0603
Q Predictions Mean           3893.4915
Q Predictions Std            388.76257
Q Predictions Max            4479.651
Q Predictions Min            2680.608
V Predictions Mean           3890.535
V Predictions Std            386.40103
V Predictions Max            4480.7085
V Predictions Min            2691.8647
Log Pis Mean                 6.0450873
Log Pis Std                  3.8688493
Log Pis Max                  17.187635
Log Pis Min                  -5.5610642
Policy mu Mean               -0.011142641
Policy mu Std                1.5279459
Policy mu Max                3.2122862
Policy mu Min                -2.7826822
Policy log std Mean          -0.7828247
Policy log std Std           0.4217586
Policy log std Max           0.0045312047
Policy log std Min           -2.8046012
Z mean eval                  2.4778285
Z variance eval              0.03921627
total_rewards                [ 9519.61154148  9712.86479567 10282.90442057  9808.74808534
 10110.70831257  9776.86394195 10096.46755258  9970.86464547
  9746.16605717  9684.74831556]
total_rewards_mean           9870.994766835074
total_rewards_std            223.47809386636254
total_rewards_max            10282.904420572722
total_rewards_min            9519.611541481729
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               28.486300472170115
(Previous) Eval Time (s)     22.55125358980149
Sample Time (s)              15.14672894962132
Epoch Time (s)               66.18428301159292
Total Train Time (s)         22732.679442366585
Epoch                        340
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:17:07.780897 UTC | [2020_01_10_08_58_14] Iteration #340 | Epoch Duration: 65.57176733016968
2020-01-10 15:17:07.781059 UTC | [2020_01_10_08_58_14] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4752543
Z variance train             0.039114937
KL Divergence                33.74478
KL Loss                      3.374478
QF Loss                      545.3592
VF Loss                      210.63263
Policy Loss                  -3789.2195
Q Predictions Mean           3788.324
Q Predictions Std            402.89322
Q Predictions Max            4379.601
Q Predictions Min            2652.6892
V Predictions Mean           3782.3032
V Predictions Std            401.25806
V Predictions Max            4400.3066
V Predictions Min            2645.971
Log Pis Mean                 6.1923676
Log Pis Std                  3.7227485
Log Pis Max                  15.134628
Log Pis Min                  -3.958356
Policy mu Mean               -0.103767656
Policy mu Std                1.4890159
Policy mu Max                3.2349086
Policy mu Min                -3.001234
Policy log std Mean          -0.78414583
Policy log std Std           0.40156698
Policy log std Max           -0.14143753
Policy log std Min           -2.653614
Z mean eval                  2.510469
Z variance eval              0.020580053
total_rewards                [ 9668.32025221 10133.96630788 10029.3786631  10134.14980155
  9886.3790041   9945.43409577  9898.39714779  9957.83992754
  9807.38389474  9928.61311654]
total_rewards_mean           9938.986221122928
total_rewards_std            134.08046865470007
total_rewards_max            10134.149801549578
total_rewards_min            9668.32025221333
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               28.66154843615368
(Previous) Eval Time (s)     21.938488190993667
Sample Time (s)              15.561967656482011
Epoch Time (s)               66.16200428362936
Total Train Time (s)         22798.98449698044
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:18:14.092726 UTC | [2020_01_10_08_58_14] Iteration #341 | Epoch Duration: 66.31150674819946
2020-01-10 15:18:14.093009 UTC | [2020_01_10_08_58_14] Iteration #341 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5098147
Z variance train             0.02054592
KL Divergence                35.629726
KL Loss                      3.5629728
QF Loss                      451.82
VF Loss                      403.71262
Policy Loss                  -3857.7932
Q Predictions Mean           3864.0457
Q Predictions Std            441.34766
Q Predictions Max            4443.171
Q Predictions Min            2734.6248
V Predictions Mean           3867.466
V Predictions Std            437.93463
V Predictions Max            4453.834
V Predictions Min            2744.0205
Log Pis Mean                 5.9092035
Log Pis Std                  3.9156184
Log Pis Max                  15.4910965
Log Pis Min                  -4.3263083
Policy mu Mean               -0.10618264
Policy mu Std                1.4863334
Policy mu Max                3.15212
Policy mu Min                -2.958393
Policy log std Mean          -0.80301905
Policy log std Std           0.4359684
Policy log std Max           -0.13415065
Policy log std Min           -2.9447951
Z mean eval                  2.5089324
Z variance eval              0.011822687
total_rewards                [ 9312.70943168 10096.64649922  9884.63936351 10018.17299101
 10047.08954888 10147.04573941 10066.11933116  9996.86124802
  9889.61892473  9845.46326891]
total_rewards_mean           9930.436634653273
total_rewards_std            226.106979773883
total_rewards_max            10147.045739407875
total_rewards_min            9312.709431680014
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               29.10994633520022
(Previous) Eval Time (s)     22.087712476961315
Sample Time (s)              15.207773662172258
Epoch Time (s)               66.4054324743338
Total Train Time (s)         22865.243191020098
Epoch                        342
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:19:20.353127 UTC | [2020_01_10_08_58_14] Iteration #342 | Epoch Duration: 66.25992131233215
2020-01-10 15:19:20.353287 UTC | [2020_01_10_08_58_14] Iteration #342 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5066879
Z variance train             0.011848775
KL Divergence                36.789047
KL Loss                      3.6789048
QF Loss                      477.95007
VF Loss                      237.85902
Policy Loss                  -3966.6797
Q Predictions Mean           3976.1875
Q Predictions Std            455.4002
Q Predictions Max            4489.1943
Q Predictions Min            -94.11671
V Predictions Mean           3974.3188
V Predictions Std            457.16666
V Predictions Max            4482.5723
V Predictions Min            -141.24461
Log Pis Mean                 6.1249285
Log Pis Std                  3.4829047
Log Pis Max                  15.253014
Log Pis Min                  -3.3111975
Policy mu Mean               0.013398399
Policy mu Std                1.4745117
Policy mu Max                2.7431533
Policy mu Min                -2.781412
Policy log std Mean          -0.8086781
Policy log std Std           0.4594165
Policy log std Max           0.29795516
Policy log std Min           -2.858915
Z mean eval                  2.4900973
Z variance eval              0.013145259
total_rewards                [ 9773.1442547  10074.01180398  9744.76698205 10043.92300773
 10070.81217229  6670.41557944  9927.08563563 10085.35266517
 10054.58712132 10197.5739069 ]
total_rewards_mean           9664.167312921585
total_rewards_std            1007.0720940009409
total_rewards_max            10197.573906896443
total_rewards_min            6670.41557943504
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               29.327856305986643
(Previous) Eval Time (s)     21.94195814523846
Sample Time (s)              15.28272931650281
Epoch Time (s)               66.55254376772791
Total Train Time (s)         22931.957730159163
Epoch                        343
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:20:27.069916 UTC | [2020_01_10_08_58_14] Iteration #343 | Epoch Duration: 66.71650886535645
2020-01-10 15:20:27.070090 UTC | [2020_01_10_08_58_14] Iteration #343 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4905202
Z variance train             0.013152704
KL Divergence                36.18598
KL Loss                      3.6185982
QF Loss                      372.36124
VF Loss                      181.87299
Policy Loss                  -3919.3755
Q Predictions Mean           3925.997
Q Predictions Std            391.8654
Q Predictions Max            4495.919
Q Predictions Min            2748.7131
V Predictions Mean           3925.063
V Predictions Std            391.11304
V Predictions Max            4495.5796
V Predictions Min            2744.862
Log Pis Mean                 5.706662
Log Pis Std                  3.6173224
Log Pis Max                  14.677523
Log Pis Min                  -3.8235419
Policy mu Mean               -0.08873212
Policy mu Std                1.4550148
Policy mu Max                2.992894
Policy mu Min                -3.1443498
Policy log std Mean          -0.8181012
Policy log std Std           0.44214594
Policy log std Max           -0.121889696
Policy log std Min           -2.728561
Z mean eval                  2.5058203
Z variance eval              0.011530912
total_rewards                [10093.64392249 10038.43143462 10077.66118727  9939.79525014
  9879.74435518 10055.73624509 10219.53794408  9997.77818041
 10203.40202744 10166.63353927]
total_rewards_mean           10067.236408600287
total_rewards_std            104.69173824354182
total_rewards_max            10219.53794408261
total_rewards_min            9879.744355181525
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               27.749225480947644
(Previous) Eval Time (s)     22.10567575925961
Sample Time (s)              15.992012657690793
Epoch Time (s)               65.84691389789805
Total Train Time (s)         22998.472031973302
Epoch                        344
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:21:33.591299 UTC | [2020_01_10_08_58_14] Iteration #344 | Epoch Duration: 66.52104783058167
2020-01-10 15:21:33.591594 UTC | [2020_01_10_08_58_14] Iteration #344 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5045822
Z variance train             0.0115548195
KL Divergence                36.574272
KL Loss                      3.6574273
QF Loss                      488.0905
VF Loss                      217.80492
Policy Loss                  -3930.1816
Q Predictions Mean           3945.251
Q Predictions Std            440.2137
Q Predictions Max            4450.8135
Q Predictions Min            -129.17676
V Predictions Mean           3939.6272
V Predictions Std            437.51492
V Predictions Max            4451.3667
V Predictions Min            -72.94365
Log Pis Mean                 5.906
Log Pis Std                  3.8921828
Log Pis Max                  16.332537
Log Pis Min                  -4.486736
Policy mu Mean               -0.08949391
Policy mu Std                1.4759668
Policy mu Max                3.2191784
Policy mu Min                -2.9614832
Policy log std Mean          -0.80077654
Policy log std Std           0.42197213
Policy log std Max           -0.107040614
Policy log std Min           -2.8024254
Z mean eval                  2.456781
Z variance eval              0.015399149
total_rewards                [ 9796.12685144  9963.58522861 10300.55578775 10102.94092914
 10351.77052297 10241.15416303 10117.31293409 10140.94637794
 10142.33143435  9799.54191661]
total_rewards_mean           10095.626614594574
total_rewards_std            181.20268653572853
total_rewards_max            10351.77052297426
total_rewards_min            9796.126851438314
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               28.291869494132698
(Previous) Eval Time (s)     22.779522384051234
Sample Time (s)              16.868656103033572
Epoch Time (s)               67.9400479812175
Total Train Time (s)         23065.828092688695
Epoch                        345
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:22:40.952094 UTC | [2020_01_10_08_58_14] Iteration #345 | Epoch Duration: 67.36026310920715
2020-01-10 15:22:40.952362 UTC | [2020_01_10_08_58_14] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.457171
Z variance train             0.01542024
KL Divergence                35.7043
KL Loss                      3.57043
QF Loss                      277.46658
VF Loss                      151.49783
Policy Loss                  -3904.3765
Q Predictions Mean           3908.273
Q Predictions Std            458.01788
Q Predictions Max            4487.9897
Q Predictions Min            -57.141228
V Predictions Mean           3897.1548
V Predictions Std            457.68774
V Predictions Max            4447.053
V Predictions Min            -90.46369
Log Pis Mean                 6.09918
Log Pis Std                  3.7932527
Log Pis Max                  15.788013
Log Pis Min                  -3.7626905
Policy mu Mean               -0.07690075
Policy mu Std                1.5042974
Policy mu Max                2.9140513
Policy mu Min                -2.517913
Policy log std Mean          -0.7804217
Policy log std Std           0.40310827
Policy log std Max           0.2176423
Policy log std Min           -2.934091
Z mean eval                  2.497226
Z variance eval              0.014711352
total_rewards                [ 9862.00621983  9944.84394555 10071.14623321 10180.68269892
 10096.89180131 10171.38144015 10014.52320794 10314.50530643
 10129.02492203 10215.72610165]
total_rewards_mean           10100.073187702195
total_rewards_std            126.77357015305189
total_rewards_max            10314.505306432013
total_rewards_min            9862.006219833958
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               29.697565214708447
(Previous) Eval Time (s)     22.199420981109142
Sample Time (s)              15.585286553483456
Epoch Time (s)               67.48227274930105
Total Train Time (s)         23132.99743711902
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:23:48.123509 UTC | [2020_01_10_08_58_14] Iteration #346 | Epoch Duration: 67.17097401618958
2020-01-10 15:23:48.123655 UTC | [2020_01_10_08_58_14] Iteration #346 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.489921
Z variance train             0.0148278
KL Divergence                36.313065
KL Loss                      3.6313064
QF Loss                      739.3415
VF Loss                      2353.0183
Policy Loss                  -3880.9783
Q Predictions Mean           3897.106
Q Predictions Std            395.71674
Q Predictions Max            4487.872
Q Predictions Min            2669.6848
V Predictions Mean           3926.645
V Predictions Std            400.6274
V Predictions Max            4552.3276
V Predictions Min            2695.5774
Log Pis Mean                 6.1332493
Log Pis Std                  3.8026752
Log Pis Max                  15.83881
Log Pis Min                  -7.1206446
Policy mu Mean               -0.08357341
Policy mu Std                1.4952388
Policy mu Max                2.8089213
Policy mu Min                -2.775236
Policy log std Mean          -0.80176777
Policy log std Std           0.43747088
Policy log std Max           -0.14235103
Policy log std Min           -2.8066268
Z mean eval                  2.4584725
Z variance eval              0.023168897
total_rewards                [ 9824.67861882 10170.66788652  9887.46067331  9979.22209083
 10149.03471402 10113.56664654  9764.85268732  9879.76272972
 10222.74296918  9969.7441915 ]
total_rewards_mean           9996.173320775544
total_rewards_std            151.064666383838
total_rewards_max            10222.742969183186
total_rewards_min            9764.85268731585
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               26.50851983996108
(Previous) Eval Time (s)     21.887890820857137
Sample Time (s)              15.470739126671106
Epoch Time (s)               63.867149787489325
Total Train Time (s)         23197.152376377024
Epoch                        347
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:24:52.283006 UTC | [2020_01_10_08_58_14] Iteration #347 | Epoch Duration: 64.1592059135437
2020-01-10 15:24:52.283219 UTC | [2020_01_10_08_58_14] Iteration #347 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4582033
Z variance train             0.023232294
KL Divergence                35.528996
KL Loss                      3.5528996
QF Loss                      363.57565
VF Loss                      174.37589
Policy Loss                  -3894.4072
Q Predictions Mean           3902.5918
Q Predictions Std            405.52505
Q Predictions Max            4472.4473
Q Predictions Min            2703.8018
V Predictions Mean           3899.886
V Predictions Std            404.2683
V Predictions Max            4472.043
V Predictions Min            2711.134
Log Pis Mean                 6.0556803
Log Pis Std                  3.9026911
Log Pis Max                  16.643744
Log Pis Min                  -3.4576356
Policy mu Mean               -0.036547706
Policy mu Std                1.5081623
Policy mu Max                3.1776676
Policy mu Min                -3.8442264
Policy log std Mean          -0.7924857
Policy log std Std           0.43842047
Policy log std Max           -0.031082362
Policy log std Min           -2.9680064
Z mean eval                  2.4817855
Z variance eval              0.017668288
total_rewards                [10118.78288345 10186.95008736 10257.90083362 10276.88762187
  1772.40539029 10115.21111293 10061.46245836 10082.50202985
 10364.40565042 10047.63047855]
total_rewards_mean           9328.413854668333
total_rewards_std            2520.598953012634
total_rewards_max            10364.405650422177
total_rewards_min            1772.40539028545
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               28.388372650835663
(Previous) Eval Time (s)     22.17966794874519
Sample Time (s)              15.988923309836537
Epoch Time (s)               66.55696390941739
Total Train Time (s)         23264.996001659427
Epoch                        348
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:26:00.132435 UTC | [2020_01_10_08_58_14] Iteration #348 | Epoch Duration: 67.84902691841125
2020-01-10 15:26:00.132708 UTC | [2020_01_10_08_58_14] Iteration #348 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4848506
Z variance train             0.01769644
KL Divergence                35.785652
KL Loss                      3.5785654
QF Loss                      1592.2539
VF Loss                      894.9121
Policy Loss                  -4017.7217
Q Predictions Mean           4018.2888
Q Predictions Std            454.52255
Q Predictions Max            4574.719
Q Predictions Min            -103.33687
V Predictions Mean           4000.0825
V Predictions Std            452.8687
V Predictions Max            4539.954
V Predictions Min            -78.52434
Log Pis Mean                 6.9893055
Log Pis Std                  3.9128551
Log Pis Max                  21.501911
Log Pis Min                  -6.67425
Policy mu Mean               -0.026796723
Policy mu Std                1.5664726
Policy mu Max                3.6114423
Policy mu Min                -3.277703
Policy log std Mean          -0.8302216
Policy log std Std           0.48327368
Policy log std Max           -0.05641997
Policy log std Min           -3.031668
Z mean eval                  2.4932592
Z variance eval              0.018998776
total_rewards                [ 9708.50100788  9876.91328391  9588.96812889  9900.30500544
  9709.68506961  9861.59304089 10019.94586469  9907.42514764
  9830.25495267  9759.25247082]
total_rewards_mean           9816.284397246392
total_rewards_std            118.60607319047853
total_rewards_max            10019.945864693671
total_rewards_min            9588.968128892888
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               28.375004875008017
(Previous) Eval Time (s)     23.47146843606606
Sample Time (s)              15.696008008439094
Epoch Time (s)               67.54248131951317
Total Train Time (s)         23331.460526582785
Epoch                        349
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:27:06.599358 UTC | [2020_01_10_08_58_14] Iteration #349 | Epoch Duration: 66.46646690368652
2020-01-10 15:27:06.599523 UTC | [2020_01_10_08_58_14] Iteration #349 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4929795
Z variance train             0.019011654
KL Divergence                35.34679
KL Loss                      3.5346792
QF Loss                      334.27817
VF Loss                      120.11633
Policy Loss                  -3905.177
Q Predictions Mean           3911.9893
Q Predictions Std            435.43622
Q Predictions Max            4472.5205
Q Predictions Min            2721.5857
V Predictions Mean           3907.2285
V Predictions Std            435.15622
V Predictions Max            4461.3286
V Predictions Min            2719.6296
Log Pis Mean                 6.120572
Log Pis Std                  3.7776687
Log Pis Max                  16.273743
Log Pis Min                  -4.0322266
Policy mu Mean               -0.10154352
Policy mu Std                1.5064989
Policy mu Max                2.7166624
Policy mu Min                -3.1197407
Policy log std Mean          -0.81294423
Policy log std Std           0.4540856
Policy log std Max           -0.111533046
Policy log std Min           -2.8641696
Z mean eval                  2.4649544
Z variance eval              0.029325103
total_rewards                [ 9942.66831197  9836.26931759 10111.4818676  10105.89589113
  9969.14195012  9905.23215275  9993.43131174  9696.48726081
 10050.41915046 10027.67697028]
total_rewards_mean           9963.870418446137
total_rewards_std            120.86676085116197
total_rewards_max            10111.481867595816
total_rewards_min            9696.487260814136
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               29.60340717388317
(Previous) Eval Time (s)     22.395196305122226
Sample Time (s)              16.462021647952497
Epoch Time (s)               68.4606251269579
Total Train Time (s)         23400.57262865128
Epoch                        350
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:28:15.717631 UTC | [2020_01_10_08_58_14] Iteration #350 | Epoch Duration: 69.11794424057007
2020-01-10 15:28:15.717903 UTC | [2020_01_10_08_58_14] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4632895
Z variance train             0.029270152
KL Divergence                34.704823
KL Loss                      3.4704823
QF Loss                      274.30817
VF Loss                      252.92317
Policy Loss                  -3982.4722
Q Predictions Mean           3990.1167
Q Predictions Std            385.87256
Q Predictions Max            4563.758
Q Predictions Min            2833.3423
V Predictions Mean           3991.315
V Predictions Std            384.81653
V Predictions Max            4562.7524
V Predictions Min            2873.671
Log Pis Mean                 6.2169256
Log Pis Std                  3.8592286
Log Pis Max                  15.426337
Log Pis Min                  -4.4451246
Policy mu Mean               -0.030118594
Policy mu Std                1.5018694
Policy mu Max                2.9930267
Policy mu Min                -2.5146077
Policy log std Mean          -0.77968615
Policy log std Std           0.4251725
Policy log std Max           -0.06356555
Policy log std Min           -2.8808165
Z mean eval                  2.4921784
Z variance eval              0.017146531
total_rewards                [1216.64793982 9219.86139129 8772.1345188  9320.17564525 8883.89271744
 9463.31695436 9572.60035603 9867.69272136 9056.44870682 9959.70735914]
total_rewards_mean           8533.247831031684
total_rewards_std            2466.5339562299637
total_rewards_max            9959.707359141192
total_rewards_min            1216.6479398248848
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               28.88177530793473
(Previous) Eval Time (s)     23.052183425985277
Sample Time (s)              17.164418660569936
Epoch Time (s)               69.09837739448994
Total Train Time (s)         23469.397900182288
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:29:24.545851 UTC | [2020_01_10_08_58_14] Iteration #351 | Epoch Duration: 68.82775259017944
2020-01-10 15:29:24.546064 UTC | [2020_01_10_08_58_14] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4918818
Z variance train             0.017187858
KL Divergence                36.131172
KL Loss                      3.6131172
QF Loss                      292.2379
VF Loss                      117.95467
Policy Loss                  -3996.996
Q Predictions Mean           4006.4768
Q Predictions Std            458.82333
Q Predictions Max            4587.0635
Q Predictions Min            -100.86493
V Predictions Mean           3999.1992
V Predictions Std            457.64383
V Predictions Max            4591.957
V Predictions Min            -85.10784
Log Pis Mean                 6.5084267
Log Pis Std                  3.7525811
Log Pis Max                  14.909624
Log Pis Min                  -1.6136906
Policy mu Mean               -0.036055032
Policy mu Std                1.5286738
Policy mu Max                3.0730608
Policy mu Min                -2.713645
Policy log std Mean          -0.8057573
Policy log std Std           0.44085133
Policy log std Max           -0.07989499
Policy log std Min           -2.9257994
Z mean eval                  2.478912
Z variance eval              0.016155414
total_rewards                [9565.46111107 9718.74350084 9885.48104679 9771.69648229 9844.11199342
 9867.57129952 9794.4169932  9745.61608448 9785.91367556 9823.92361834]
total_rewards_mean           9780.29358055173
total_rewards_std            87.2393664820953
total_rewards_max            9885.481046790119
total_rewards_min            9565.461111072727
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               29.639869773760438
(Previous) Eval Time (s)     22.78125099511817
Sample Time (s)              16.091805012896657
Epoch Time (s)               68.51292578177527
Total Train Time (s)         23538.063325214665
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:30:33.213884 UTC | [2020_01_10_08_58_14] Iteration #352 | Epoch Duration: 68.66767358779907
2020-01-10 15:30:33.214032 UTC | [2020_01_10_08_58_14] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4790435
Z variance train             0.016146025
KL Divergence                36.020226
KL Loss                      3.6020226
QF Loss                      336.77036
VF Loss                      265.07928
Policy Loss                  -3929.0828
Q Predictions Mean           3936.4678
Q Predictions Std            400.89966
Q Predictions Max            4521.78
Q Predictions Min            2765.936
V Predictions Mean           3934.6873
V Predictions Std            402.03168
V Predictions Max            4547.9146
V Predictions Min            2777.804
Log Pis Mean                 5.8900514
Log Pis Std                  3.727845
Log Pis Max                  16.264221
Log Pis Min                  -4.369183
Policy mu Mean               -0.13127732
Policy mu Std                1.4761243
Policy mu Max                2.7011502
Policy mu Min                -3.25711
Policy log std Mean          -0.80086344
Policy log std Std           0.42538625
Policy log std Max           -0.13116355
Policy log std Min           -3.014151
Z mean eval                  2.491005
Z variance eval              0.021089127
total_rewards                [4219.85947326 9779.58373501 7613.0029654  9584.81943753 9617.93191808
 9519.36421322 5847.43110498 9240.13713631 9540.21498663 9424.34021831]
total_rewards_mean           8438.668518873708
total_rewards_std            1835.5427225431365
total_rewards_max            9779.583735010543
total_rewards_min            4219.859473262649
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               27.810483627952635
(Previous) Eval Time (s)     22.935728836338967
Sample Time (s)              16.90830311505124
Epoch Time (s)               67.65451557934284
Total Train Time (s)         23604.97093263734
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:31:40.126431 UTC | [2020_01_10_08_58_14] Iteration #353 | Epoch Duration: 66.91226053237915
2020-01-10 15:31:40.126658 UTC | [2020_01_10_08_58_14] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.494473
Z variance train             0.021175846
KL Divergence                35.595142
KL Loss                      3.5595143
QF Loss                      559.6922
VF Loss                      356.98373
Policy Loss                  -3942.5974
Q Predictions Mean           3947.054
Q Predictions Std            478.3945
Q Predictions Max            4504.3706
Q Predictions Min            -83.85843
V Predictions Mean           3933.4849
V Predictions Std            475.03717
V Predictions Max            4486.9995
V Predictions Min            -92.44074
Log Pis Mean                 6.141387
Log Pis Std                  3.9137871
Log Pis Max                  15.471437
Log Pis Min                  -4.160246
Policy mu Mean               -0.019920835
Policy mu Std                1.5019269
Policy mu Max                3.1948764
Policy mu Min                -2.715316
Policy log std Mean          -0.7984918
Policy log std Std           0.41303217
Policy log std Max           -0.0753476
Policy log std Min           -2.858515
Z mean eval                  2.487134
Z variance eval              0.019603573
total_rewards                [9601.49831138 9861.3089712  9900.84423436 9611.27565021 9884.83198403
 9633.68221198 9857.99730752 9817.51727393 9665.94515757 9876.49028801]
total_rewards_mean           9771.139139017676
total_rewards_std            119.5695349191092
total_rewards_max            9900.844234359729
total_rewards_min            9601.498311375837
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               29.84558298625052
(Previous) Eval Time (s)     22.193169645033777
Sample Time (s)              16.258920058142394
Epoch Time (s)               68.29767268942669
Total Train Time (s)         23674.104540092405
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:32:49.262300 UTC | [2020_01_10_08_58_14] Iteration #354 | Epoch Duration: 69.13548159599304
2020-01-10 15:32:49.262478 UTC | [2020_01_10_08_58_14] Iteration #354 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4862213
Z variance train             0.01963967
KL Divergence                35.817673
KL Loss                      3.5817673
QF Loss                      542.53845
VF Loss                      272.65225
Policy Loss                  -4023.652
Q Predictions Mean           4037.2065
Q Predictions Std            401.82043
Q Predictions Max            4618.4077
Q Predictions Min            2798.5283
V Predictions Mean           4036.4746
V Predictions Std            399.09854
V Predictions Max            4611.363
V Predictions Min            2846.1323
Log Pis Mean                 6.463441
Log Pis Std                  4.0484343
Log Pis Max                  15.995684
Log Pis Min                  -4.614621
Policy mu Mean               -0.067370735
Policy mu Std                1.5382993
Policy mu Max                2.9034498
Policy mu Min                -2.903432
Policy log std Mean          -0.814548
Policy log std Std           0.43148065
Policy log std Max           -0.15650973
Policy log std Min           -2.8015778
Z mean eval                  2.4635642
Z variance eval              0.03398138
total_rewards                [10041.03525406 10161.48452642 10254.74790791 10111.16991546
 10097.32928375 10418.7705949  10036.69815253 10142.02927325
 10066.52736028 10261.47806585]
total_rewards_mean           10159.127033441015
total_rewards_std            114.43766923128933
total_rewards_max            10418.770594897633
total_rewards_min            10036.698152531379
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               28.610011239070445
(Previous) Eval Time (s)     23.03072652919218
Sample Time (s)              16.505991655867547
Epoch Time (s)               68.14672942413017
Total Train Time (s)         23741.807957878802
Epoch                        355
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:33:56.970154 UTC | [2020_01_10_08_58_14] Iteration #355 | Epoch Duration: 67.70752692222595
2020-01-10 15:33:56.970347 UTC | [2020_01_10_08_58_14] Iteration #355 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4636607
Z variance train             0.03405898
KL Divergence                34.550503
KL Loss                      3.4550502
QF Loss                      444.14526
VF Loss                      131.52057
Policy Loss                  -4037.7278
Q Predictions Mean           4045.812
Q Predictions Std            464.5422
Q Predictions Max            4588.709
Q Predictions Min            -52.82965
V Predictions Mean           4038.4443
V Predictions Std            461.28708
V Predictions Max            4566.8022
V Predictions Min            -4.4522533
Log Pis Mean                 6.5511346
Log Pis Std                  3.6146724
Log Pis Max                  14.487666
Log Pis Min                  -9.628759
Policy mu Mean               -0.05468064
Policy mu Std                1.515013
Policy mu Max                3.14963
Policy mu Min                -3.0587826
Policy log std Mean          -0.81154233
Policy log std Std           0.46219522
Policy log std Max           -0.010865748
Policy log std Min           -2.8506813
Z mean eval                  2.4802802
Z variance eval              0.023511043
total_rewards                [ 9814.61012067 10160.39711116 10321.61607336 10138.98442977
 10279.95586863 10201.60080116 10461.93557462 10054.33178091
 10186.91044565  7934.74449839]
total_rewards_mean           9955.50867043182
total_rewards_std            692.7211428483015
total_rewards_max            10461.935574620153
total_rewards_min            7934.7444983850755
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               29.66615855600685
(Previous) Eval Time (s)     22.591261618304998
Sample Time (s)              16.05003542173654
Epoch Time (s)               68.30745559604838
Total Train Time (s)         23810.002378819976
Epoch                        356
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:35:05.166916 UTC | [2020_01_10_08_58_14] Iteration #356 | Epoch Duration: 68.19642877578735
2020-01-10 15:35:05.167077 UTC | [2020_01_10_08_58_14] Iteration #356 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4804685
Z variance train             0.023481943
KL Divergence                35.65062
KL Loss                      3.565062
QF Loss                      1014.5715
VF Loss                      127.58818
Policy Loss                  -4119.2773
Q Predictions Mean           4120.673
Q Predictions Std            390.8939
Q Predictions Max            4661.9976
Q Predictions Min            2882.6064
V Predictions Mean           4117.7227
V Predictions Std            391.68698
V Predictions Max            4654.94
V Predictions Min            2882.4856
Log Pis Mean                 6.288705
Log Pis Std                  3.8346708
Log Pis Max                  16.161613
Log Pis Min                  -4.386445
Policy mu Mean               -0.058655906
Policy mu Std                1.5220104
Policy mu Max                3.0081253
Policy mu Min                -2.9436452
Policy log std Mean          -0.79838234
Policy log std Std           0.44639495
Policy log std Max           -0.112080306
Policy log std Min           -3.0227642
Z mean eval                  2.4832463
Z variance eval              0.025346752
total_rewards                [ 9261.83964704  9941.70260403  9458.98767375  9510.7861883
  9442.57354897  9614.35155276  9353.22139315  9806.03396436
  9402.3196303  10051.87400638]
total_rewards_mean           9584.369020902297
total_rewards_std            250.62317834084757
total_rewards_max            10051.874006376876
total_rewards_min            9261.839647037108
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               30.657283876091242
(Previous) Eval Time (s)     22.47992197982967
Sample Time (s)              16.48426068155095
Epoch Time (s)               69.62146653747186
Total Train Time (s)         23879.67472620262
Epoch                        357
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:36:14.845237 UTC | [2020_01_10_08_58_14] Iteration #357 | Epoch Duration: 69.67801213264465
2020-01-10 15:36:14.845497 UTC | [2020_01_10_08_58_14] Iteration #357 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.484469
Z variance train             0.025519544
KL Divergence                35.89212
KL Loss                      3.5892122
QF Loss                      502.1823
VF Loss                      1771.6042
Policy Loss                  -3980.0234
Q Predictions Mean           3990.176
Q Predictions Std            393.8161
Q Predictions Max            4556.931
Q Predictions Min            2771.2136
V Predictions Mean           3963.753
V Predictions Std            389.277
V Predictions Max            4521.394
V Predictions Min            2751.711
Log Pis Mean                 6.2495956
Log Pis Std                  3.4762325
Log Pis Max                  14.748073
Log Pis Min                  -4.2332563
Policy mu Mean               -0.029499048
Policy mu Std                1.500421
Policy mu Max                2.7719922
Policy mu Min                -2.8504112
Policy log std Mean          -0.7975895
Policy log std Std           0.44223985
Policy log std Max           -0.102632806
Policy log std Min           -2.6858914
Z mean eval                  2.4759681
Z variance eval              0.032368638
total_rewards                [ 9956.08084839  9852.98017233 10012.01487868  9906.28053875
  9874.97884312  9860.69975796  9551.44538664  9654.53012378
  9871.572563    9904.72698634]
total_rewards_mean           9844.53100990121
total_rewards_std            131.1188105693815
total_rewards_max            10012.014878680699
total_rewards_min            9551.44538664361
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               30.3475831001997
(Previous) Eval Time (s)     22.536157865077257
Sample Time (s)              16.88174700597301
Epoch Time (s)               69.76548797124997
Total Train Time (s)         23949.843077663332
Epoch                        358
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:37:25.016409 UTC | [2020_01_10_08_58_14] Iteration #358 | Epoch Duration: 70.17072081565857
2020-01-10 15:37:25.016598 UTC | [2020_01_10_08_58_14] Iteration #358 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4755805
Z variance train             0.032412093
KL Divergence                34.01988
KL Loss                      3.4019878
QF Loss                      926.0293
VF Loss                      450.11646
Policy Loss                  -3853.491
Q Predictions Mean           3857.8318
Q Predictions Std            544.5526
Q Predictions Max            4461.691
Q Predictions Min            -234.05952
V Predictions Mean           3838.6572
V Predictions Std            544.0015
V Predictions Max            4427.982
V Predictions Min            -269.87897
Log Pis Mean                 6.1655846
Log Pis Std                  3.9510062
Log Pis Max                  16.119799
Log Pis Min                  -5.2566557
Policy mu Mean               -0.02595027
Policy mu Std                1.4939747
Policy mu Max                2.8887897
Policy mu Min                -2.7765026
Policy log std Mean          -0.80176467
Policy log std Std           0.44083983
Policy log std Max           0.08433753
Policy log std Min           -2.9160652
Z mean eval                  2.46849
Z variance eval              0.039342705
total_rewards                [ 9905.46506403 10296.40710685 10081.13406264 10318.21605189
 10325.10655432 10494.09724189 10079.5871538  10412.21299925
  9941.83182378 10277.17718402]
total_rewards_mean           10213.123524247621
total_rewards_std            188.8683692431788
total_rewards_max            10494.09724189309
total_rewards_min            9905.465064029051
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               28.73873387137428
(Previous) Eval Time (s)     22.941139054950327
Sample Time (s)              16.327884485479444
Epoch Time (s)               68.00775741180405
Total Train Time (s)         24016.9769182764
Epoch                        359
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:38:32.153669 UTC | [2020_01_10_08_58_14] Iteration #359 | Epoch Duration: 67.13691234588623
2020-01-10 15:38:32.153892 UTC | [2020_01_10_08_58_14] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.46949
Z variance train             0.03935008
KL Divergence                33.699505
KL Loss                      3.3699505
QF Loss                      502.56537
VF Loss                      208.69156
Policy Loss                  -3967.5918
Q Predictions Mean           3977.3384
Q Predictions Std            474.1364
Q Predictions Max            4532.216
Q Predictions Min            -19.981737
V Predictions Mean           3969.103
V Predictions Std            472.4548
V Predictions Max            4521.5005
V Predictions Min            -71.07878
Log Pis Mean                 6.226827
Log Pis Std                  3.8882716
Log Pis Max                  14.828242
Log Pis Min                  -5.972333
Policy mu Mean               -0.0755217
Policy mu Std                1.5251034
Policy mu Max                3.3405783
Policy mu Min                -2.7341883
Policy log std Mean          -0.8070585
Policy log std Std           0.4217758
Policy log std Max           -0.034612954
Policy log std Min           -2.9666295
Z mean eval                  2.4853966
Z variance eval              0.032959078
total_rewards                [9363.4577867  9789.36075252 9851.12016963 9541.14567093 9715.03173053
 9438.02227156 9834.415995   9346.7449046  9694.81126202 9803.12447139]
total_rewards_mean           9637.723501486596
total_rewards_std            187.85927476316218
total_rewards_max            9851.12016962698
total_rewards_min            9346.744904599664
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               32.00396792218089
(Previous) Eval Time (s)     22.06998395593837
Sample Time (s)              16.616187556181103
Epoch Time (s)               70.69013943430036
Total Train Time (s)         24087.756874735467
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:39:42.936665 UTC | [2020_01_10_08_58_14] Iteration #360 | Epoch Duration: 70.7826030254364
2020-01-10 15:39:42.936853 UTC | [2020_01_10_08_58_14] Iteration #360 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4860187
Z variance train             0.0329426
KL Divergence                34.390034
KL Loss                      3.4390035
QF Loss                      415.74982
VF Loss                      102.35467
Policy Loss                  -4021.232
Q Predictions Mean           4031.325
Q Predictions Std            409.58917
Q Predictions Max            4570.523
Q Predictions Min            2830.4727
V Predictions Mean           4023.0386
V Predictions Std            408.99634
V Predictions Max            4538.7446
V Predictions Min            2829.55
Log Pis Mean                 6.1022224
Log Pis Std                  3.7440174
Log Pis Max                  14.249529
Log Pis Min                  -5.025323
Policy mu Mean               -0.029414067
Policy mu Std                1.5022863
Policy mu Max                2.9295332
Policy mu Min                -2.9844255
Policy log std Mean          -0.79872817
Policy log std Std           0.42695713
Policy log std Max           -0.11337957
Policy log std Min           -2.9088967
Z mean eval                  2.4874592
Z variance eval              0.041715965
total_rewards                [10000.74312843 10189.88710297 10190.11267851 10205.24713239
  9882.72967475 10167.08638734 10093.63636177  9893.23089726
 10192.54636626 10014.27222996]
total_rewards_mean           10082.94919596409
total_rewards_std            120.26495256756583
total_rewards_max            10205.247132393048
total_rewards_min            9882.729674749198
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               28.78434919193387
(Previous) Eval Time (s)     22.162180873099715
Sample Time (s)              16.148283147253096
Epoch Time (s)               67.09481321228668
Total Train Time (s)         24155.06454571802
Epoch                        361
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:40:50.248086 UTC | [2020_01_10_08_58_14] Iteration #361 | Epoch Duration: 67.31108784675598
2020-01-10 15:40:50.248264 UTC | [2020_01_10_08_58_14] Iteration #361 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4880776
Z variance train             0.04172686
KL Divergence                34.060215
KL Loss                      3.4060216
QF Loss                      323.1669
VF Loss                      174.10402
Policy Loss                  -4118.762
Q Predictions Mean           4129.107
Q Predictions Std            406.03748
Q Predictions Max            4673.2344
Q Predictions Min            2931.6042
V Predictions Mean           4128.0728
V Predictions Std            405.6644
V Predictions Max            4655.4663
V Predictions Min            2931.3066
Log Pis Mean                 6.1140046
Log Pis Std                  3.7999737
Log Pis Max                  16.291649
Log Pis Min                  -4.462302
Policy mu Mean               -0.058198154
Policy mu Std                1.4881433
Policy mu Max                2.9542365
Policy mu Min                -2.9853358
Policy log std Mean          -0.80002576
Policy log std Std           0.44327724
Policy log std Max           -0.089925915
Policy log std Min           -2.9712076
Z mean eval                  2.4706354
Z variance eval              0.023251357
total_rewards                [10234.5391955  10062.31149962 10414.64161008 10283.36606986
 10390.78388531 10403.48050342 10514.77318138 10362.15077839
 10049.92519635 10217.80157627]
total_rewards_mean           10293.377349617916
total_rewards_std            145.60078535197954
total_rewards_max            10514.773181381974
total_rewards_min            10049.925196345226
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               28.336331862024963
(Previous) Eval Time (s)     22.378193348646164
Sample Time (s)              16.65634583029896
Epoch Time (s)               67.37087104097009
Total Train Time (s)         24222.763776733074
Epoch                        362
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:41:57.950479 UTC | [2020_01_10_08_58_14] Iteration #362 | Epoch Duration: 67.70206689834595
2020-01-10 15:41:57.950679 UTC | [2020_01_10_08_58_14] Iteration #362 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4694371
Z variance train             0.023293065
KL Divergence                35.051804
KL Loss                      3.5051804
QF Loss                      381.6894
VF Loss                      133.184
Policy Loss                  -3949.6125
Q Predictions Mean           3958.5679
Q Predictions Std            429.37155
Q Predictions Max            4546.4053
Q Predictions Min            2760.3103
V Predictions Mean           3953.0225
V Predictions Std            428.496
V Predictions Max            4537.8975
V Predictions Min            2763.8145
Log Pis Mean                 6.547892
Log Pis Std                  3.8631284
Log Pis Max                  14.372337
Log Pis Min                  -3.978617
Policy mu Mean               0.0021395397
Policy mu Std                1.515385
Policy mu Max                3.7522225
Policy mu Min                -2.859422
Policy log std Mean          -0.81172425
Policy log std Std           0.444969
Policy log std Max           0.13339216
Policy log std Min           -2.9631276
Z mean eval                  2.4930367
Z variance eval              0.025812438
total_rewards                [10220.31992294 10038.75541402  9728.35050833  7539.08480687
 10042.73478331 10194.46573026 10384.30219386 10263.95779481
 10247.32906269 10068.2482762 ]
total_rewards_mean           9872.754849330875
total_rewards_std            796.2952448063329
total_rewards_max            10384.302193863885
total_rewards_min            7539.0848068744035
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               27.545735789928585
(Previous) Eval Time (s)     22.709086313843727
Sample Time (s)              16.434377079829574
Epoch Time (s)               66.68919918360189
Total Train Time (s)         24290.039449825417
Epoch                        363
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:43:05.228602 UTC | [2020_01_10_08_58_14] Iteration #363 | Epoch Duration: 67.27779173851013
2020-01-10 15:43:05.228778 UTC | [2020_01_10_08_58_14] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4929903
Z variance train             0.025819946
KL Divergence                35.431007
KL Loss                      3.5431008
QF Loss                      481.7541
VF Loss                      178.24025
Policy Loss                  -3998.3977
Q Predictions Mean           4004.2695
Q Predictions Std            494.82556
Q Predictions Max            4654.2705
Q Predictions Min            -142.57079
V Predictions Mean           4000.2715
V Predictions Std            493.307
V Predictions Max            4640.9585
V Predictions Min            -115.028824
Log Pis Mean                 6.142251
Log Pis Std                  3.9560096
Log Pis Max                  15.411885
Log Pis Min                  -8.160381
Policy mu Mean               -0.074978314
Policy mu Std                1.523077
Policy mu Max                3.073168
Policy mu Min                -2.9445198
Policy log std Mean          -0.80716664
Policy log std Std           0.44541863
Policy log std Max           -0.06495577
Policy log std Min           -2.906888
Z mean eval                  2.4712913
Z variance eval              0.021384176
total_rewards                [9608.28157122 9630.95687448 9460.269216   9448.06754015 9655.96636409
 9693.5908324  9412.41047755 9552.76444496 9601.95172915 9651.63660225]
total_rewards_mean           9571.589565224687
total_rewards_std            93.56612696908464
total_rewards_max            9693.59083239592
total_rewards_min            9412.410477553925
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               30.956884385086596
(Previous) Eval Time (s)     23.29738378105685
Sample Time (s)              16.45415848866105
Epoch Time (s)               70.7084266548045
Total Train Time (s)         24359.730712505523
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:44:14.922865 UTC | [2020_01_10_08_58_14] Iteration #364 | Epoch Duration: 69.69395685195923
2020-01-10 15:44:14.923052 UTC | [2020_01_10_08_58_14] Iteration #364 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4708476
Z variance train             0.02140132
KL Divergence                35.16475
KL Loss                      3.516475
QF Loss                      697.4863
VF Loss                      289.13132
Policy Loss                  -3885.6362
Q Predictions Mean           3888.1484
Q Predictions Std            521.7526
Q Predictions Max            4433.488
Q Predictions Min            -138.68282
V Predictions Mean           3881.1318
V Predictions Std            519.06665
V Predictions Max            4426.878
V Predictions Min            -138.19928
Log Pis Mean                 6.135818
Log Pis Std                  4.010763
Log Pis Max                  14.771647
Log Pis Min                  -5.861347
Policy mu Mean               0.05224563
Policy mu Std                1.503193
Policy mu Max                2.644396
Policy mu Min                -2.6284573
Policy log std Mean          -0.78839177
Policy log std Std           0.41279915
Policy log std Max           -0.115616485
Policy log std Min           -2.982873
Z mean eval                  2.4979436
Z variance eval              0.017860677
total_rewards                [ 9846.40842192  9772.01233111 10319.87376034  9808.30068588
  9660.85686774 10015.82283587  9840.73070739 10074.17982307
  9910.59173972  9958.43975889]
total_rewards_mean           9920.72169319294
total_rewards_std            175.39811029841124
total_rewards_max            10319.873760335922
total_rewards_min            9660.856867743798
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               29.94136423431337
(Previous) Eval Time (s)     22.28260499984026
Sample Time (s)              16.224024658091366
Epoch Time (s)               68.447993892245
Total Train Time (s)         24428.17551395856
Epoch                        365
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:45:23.369874 UTC | [2020_01_10_08_58_14] Iteration #365 | Epoch Duration: 68.44669270515442
2020-01-10 15:45:23.370034 UTC | [2020_01_10_08_58_14] Iteration #365 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4962723
Z variance train             0.0179246
KL Divergence                36.0698
KL Loss                      3.60698
QF Loss                      1320.1741
VF Loss                      277.3474
Policy Loss                  -3952.463
Q Predictions Mean           3959.602
Q Predictions Std            471.39777
Q Predictions Max            4515.384
Q Predictions Min            -116.42336
V Predictions Mean           3958.7275
V Predictions Std            471.1004
V Predictions Max            4501.3027
V Predictions Min            -112.96129
Log Pis Mean                 5.997681
Log Pis Std                  4.0586653
Log Pis Max                  15.415812
Log Pis Min                  -3.0654364
Policy mu Mean               0.046730418
Policy mu Std                1.4945083
Policy mu Max                3.0127714
Policy mu Min                -2.8023443
Policy log std Mean          -0.78289825
Policy log std Std           0.4151568
Policy log std Max           -0.011101842
Policy log std Min           -2.7689667
Z mean eval                  2.4935384
Z variance eval              0.015611902
total_rewards                [ 9755.40399962 10319.89319283 10432.14502365 10251.65876939
 10236.04197124 10116.49069195 10334.3878359  10209.56352183
 10546.10115669 10263.33631667]
total_rewards_mean           10246.502247977403
total_rewards_std            199.29807081794647
total_rewards_max            10546.10115669453
total_rewards_min            9755.403999616196
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               30.109294542111456
(Previous) Eval Time (s)     22.281045448966324
Sample Time (s)              16.311213615816087
Epoch Time (s)               68.70155360689387
Total Train Time (s)         24497.555130867753
Epoch                        366
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:46:32.752469 UTC | [2020_01_10_08_58_14] Iteration #366 | Epoch Duration: 69.38232231140137
2020-01-10 15:46:32.752611 UTC | [2020_01_10_08_58_14] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.491882
Z variance train             0.01560923
KL Divergence                36.63778
KL Loss                      3.663778
QF Loss                      292.47772
VF Loss                      482.61133
Policy Loss                  -4109.0576
Q Predictions Mean           4120.675
Q Predictions Std            379.26248
Q Predictions Max            4648.579
Q Predictions Min            2824.611
V Predictions Mean           4125.2817
V Predictions Std            376.48477
V Predictions Max            4631.8696
V Predictions Min            2837.0413
Log Pis Mean                 6.308688
Log Pis Std                  3.5945148
Log Pis Max                  15.325056
Log Pis Min                  -4.0428276
Policy mu Mean               -0.047532868
Policy mu Std                1.5048413
Policy mu Max                2.8399482
Policy mu Min                -2.9508145
Policy log std Mean          -0.80870223
Policy log std Std           0.42143
Policy log std Max           -0.12133062
Policy log std Min           -2.8089323
Z mean eval                  2.4823928
Z variance eval              0.019203795
total_rewards                [ 9869.75688441 10106.39074069 10307.58762996  9825.24233209
 10082.36254843  9882.35612214 10189.21488679 10087.87457322
 10013.08105556  6874.51580707]
total_rewards_mean           9723.83825803712
total_rewards_std            960.4035617310817
total_rewards_max            10307.587629960231
total_rewards_min            6874.515807072959
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               29.396750102750957
(Previous) Eval Time (s)     22.961498893797398
Sample Time (s)              16.527655454352498
Epoch Time (s)               68.88590445090085
Total Train Time (s)         24566.205722121987
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:47:41.409154 UTC | [2020_01_10_08_58_14] Iteration #367 | Epoch Duration: 68.65638899803162
2020-01-10 15:47:41.409430 UTC | [2020_01_10_08_58_14] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4757848
Z variance train             0.019376136
KL Divergence                35.59732
KL Loss                      3.5597322
QF Loss                      552.3917
VF Loss                      1127.378
Policy Loss                  -3981.3506
Q Predictions Mean           3990.0566
Q Predictions Std            403.92926
Q Predictions Max            4597.1987
Q Predictions Min            2770.395
V Predictions Mean           4011.69
V Predictions Std            405.36526
V Predictions Max            4623.54
V Predictions Min            2782.5127
Log Pis Mean                 6.3526506
Log Pis Std                  3.570796
Log Pis Max                  18.684708
Log Pis Min                  -2.7771847
Policy mu Mean               -0.07256471
Policy mu Std                1.513588
Policy mu Max                2.7264311
Policy mu Min                -2.853616
Policy log std Mean          -0.80677694
Policy log std Std           0.44004354
Policy log std Max           -0.0686073
Policy log std Min           -2.8868115
Z mean eval                  2.458364
Z variance eval              0.012824066
total_rewards                [9456.10211108 9580.11958133 9449.24857078 9682.04892736 9205.45892329
 9505.52000279 9396.39338864 9304.5780406  9318.83886217 9407.39558851]
total_rewards_mean           9430.570399652865
total_rewards_std            131.51536821399432
total_rewards_max            9682.048927355987
total_rewards_min            9205.458923287837
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               26.570884544868022
(Previous) Eval Time (s)     22.73166466783732
Sample Time (s)              16.26543111447245
Epoch Time (s)               65.56798032717779
Total Train Time (s)         24631.180137386546
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:48:46.386844 UTC | [2020_01_10_08_58_14] Iteration #368 | Epoch Duration: 64.97721672058105
2020-01-10 15:48:46.387019 UTC | [2020_01_10_08_58_14] Iteration #368 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.462533
Z variance train             0.012842325
KL Divergence                36.726196
KL Loss                      3.6726196
QF Loss                      567.40985
VF Loss                      527.40967
Policy Loss                  -3983.411
Q Predictions Mean           3992.976
Q Predictions Std            414.4624
Q Predictions Max            4568.5273
Q Predictions Min            2769.4421
V Predictions Mean           3969.272
V Predictions Std            411.24606
V Predictions Max            4528.053
V Predictions Min            2762.1248
Log Pis Mean                 6.447337
Log Pis Std                  3.765299
Log Pis Max                  15.74737
Log Pis Min                  -3.5403912
Policy mu Mean               -0.02474766
Policy mu Std                1.5450798
Policy mu Max                3.1442559
Policy mu Min                -2.888028
Policy log std Mean          -0.79846936
Policy log std Std           0.45424023
Policy log std Max           -0.054652035
Policy log std Min           -2.9270005
Z mean eval                  2.4669628
Z variance eval              0.0103660915
total_rewards                [10086.52052647 10091.70767026 10144.16892694  9997.15515266
  9871.4909652  10113.89308011 10082.44390154 10096.08998812
 10379.2886541   9997.64008713]
total_rewards_mean           10086.039895252741
total_rewards_std            123.30538347529217
total_rewards_max            10379.288654095419
total_rewards_min            9871.490965203398
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               29.59012974286452
(Previous) Eval Time (s)     22.14063186524436
Sample Time (s)              16.788394113536924
Epoch Time (s)               68.5191557216458
Total Train Time (s)         24700.290694612544
Epoch                        369
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:49:55.502599 UTC | [2020_01_10_08_58_14] Iteration #369 | Epoch Duration: 69.11542534828186
2020-01-10 15:49:55.502813 UTC | [2020_01_10_08_58_14] Iteration #369 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4674435
Z variance train             0.01036361
KL Divergence                37.336853
KL Loss                      3.7336853
QF Loss                      547.47046
VF Loss                      141.74957
Policy Loss                  -3928.4834
Q Predictions Mean           3932.607
Q Predictions Std            427.6314
Q Predictions Max            4561.4727
Q Predictions Min            2759.6677
V Predictions Mean           3928.1467
V Predictions Std            426.86575
V Predictions Max            4546.983
V Predictions Min            2761.5222
Log Pis Mean                 5.960536
Log Pis Std                  3.5011685
Log Pis Max                  14.233166
Log Pis Min                  -4.411309
Policy mu Mean               0.016927807
Policy mu Std                1.4883436
Policy mu Max                3.0520144
Policy mu Min                -2.8186448
Policy log std Mean          -0.81953675
Policy log std Std           0.44946635
Policy log std Max           -0.14443704
Policy log std Min           -2.9427547
Z mean eval                  2.4752643
Z variance eval              0.009487187
total_rewards                [10203.37713264 10458.27764865 10387.46156537 10224.35398672
 10292.17095164  4089.2092037  10371.44240419  9841.01980761
 10416.03067387 10417.07780319]
total_rewards_mean           9670.042117759182
total_rewards_std            1868.0527582508198
total_rewards_max            10458.27764864741
total_rewards_min            4089.2092037033094
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               26.291291820816696
(Previous) Eval Time (s)     22.736604584380984
Sample Time (s)              16.25187028478831
Epoch Time (s)               65.27976668998599
Total Train Time (s)         24764.885896434076
Epoch                        370
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:51:00.099959 UTC | [2020_01_10_08_58_14] Iteration #370 | Epoch Duration: 64.5969934463501
2020-01-10 15:51:00.100106 UTC | [2020_01_10_08_58_14] Iteration #370 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4743125
Z variance train             0.009472054
KL Divergence                37.90762
KL Loss                      3.790762
QF Loss                      689.4977
VF Loss                      263.65738
Policy Loss                  -3971.0647
Q Predictions Mean           3979.859
Q Predictions Std            526.3799
Q Predictions Max            4555.4277
Q Predictions Min            -137.45065
V Predictions Mean           3982.639
V Predictions Std            525.1938
V Predictions Max            4553.816
V Predictions Min            -122.49318
Log Pis Mean                 6.7564487
Log Pis Std                  3.4517756
Log Pis Max                  15.552725
Log Pis Min                  -2.4309382
Policy mu Mean               -0.0030920021
Policy mu Std                1.5165274
Policy mu Max                3.1096697
Policy mu Min                -3.0774658
Policy log std Mean          -0.8370654
Policy log std Std           0.4763135
Policy log std Max           -0.10452902
Policy log std Min           -3.0391917
Z mean eval                  2.4903502
Z variance eval              0.01154015
total_rewards                [10114.02955843 10138.8191406  10425.58416657 10472.42375813
 10427.34147973 10108.09068295 10468.96598466 10216.83460026
 10377.26311802 10216.10418948]
total_rewards_mean           10296.545667882141
total_rewards_std            144.03659544680247
total_rewards_max            10472.423758134602
total_rewards_min            10108.09068295147
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               26.67039203736931
(Previous) Eval Time (s)     22.053548474330455
Sample Time (s)              15.578178708907217
Epoch Time (s)               64.30211922060698
Total Train Time (s)         24829.437129979953
Epoch                        371
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:52:04.656186 UTC | [2020_01_10_08_58_14] Iteration #371 | Epoch Duration: 64.55591750144958
2020-01-10 15:52:04.656447 UTC | [2020_01_10_08_58_14] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4832711
Z variance train             0.011520614
KL Divergence                37.698074
KL Loss                      3.7698076
QF Loss                      1124.355
VF Loss                      1184.7286
Policy Loss                  -3985.6577
Q Predictions Mean           3998.397
Q Predictions Std            503.08917
Q Predictions Max            4556.619
Q Predictions Min            -101.670815
V Predictions Mean           4013.6636
V Predictions Std            506.78677
V Predictions Max            4581.944
V Predictions Min            -125.24048
Log Pis Mean                 6.132988
Log Pis Std                  3.7528832
Log Pis Max                  15.824352
Log Pis Min                  -3.9376495
Policy mu Mean               -0.078965105
Policy mu Std                1.4815277
Policy mu Max                2.932385
Policy mu Min                -2.9317162
Policy log std Mean          -0.8158412
Policy log std Std           0.45090282
Policy log std Max           -0.0886451
Policy log std Min           -2.9045424
Z mean eval                  2.4876406
Z variance eval              0.02042901
total_rewards                [10089.68541377 10133.55555045 10303.01240046 10301.89124834
 10258.06508465  9918.1938811  10273.86366374 10098.62847692
 10199.61210009 10235.17719048]
total_rewards_mean           10181.168501001026
total_rewards_std            115.66639737559562
total_rewards_max            10303.012400464517
total_rewards_min            9918.193881098618
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               27.48636927921325
(Previous) Eval Time (s)     22.307082842104137
Sample Time (s)              16.39937673555687
Epoch Time (s)               66.19282885687426
Total Train Time (s)         24895.55832076259
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:53:10.780174 UTC | [2020_01_10_08_58_14] Iteration #372 | Epoch Duration: 66.12355160713196
2020-01-10 15:53:10.780330 UTC | [2020_01_10_08_58_14] Iteration #372 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4891791
Z variance train             0.020497557
KL Divergence                36.708397
KL Loss                      3.6708398
QF Loss                      2177.6191
VF Loss                      689.588
Policy Loss                  -4002.676
Q Predictions Mean           4010.522
Q Predictions Std            434.94205
Q Predictions Max            4603.2373
Q Predictions Min            2813.3667
V Predictions Mean           3981.9956
V Predictions Std            431.36298
V Predictions Max            4575.6025
V Predictions Min            2792.8928
Log Pis Mean                 6.295223
Log Pis Std                  3.719857
Log Pis Max                  15.602931
Log Pis Min                  -4.084978
Policy mu Mean               -0.04135783
Policy mu Std                1.502537
Policy mu Max                3.5268054
Policy mu Min                -3.0080914
Policy log std Mean          -0.837907
Policy log std Std           0.46114147
Policy log std Max           -0.12178922
Policy log std Min           -3.092198
Z mean eval                  2.4961724
Z variance eval              0.01556367
total_rewards                [ 9880.29805696  9797.48570544 10163.41998335 10114.45514787
  9850.16465898  9949.11853847  9710.54266453  9903.83250461
  9955.01414171  9729.01001057]
total_rewards_mean           9905.33414125002
total_rewards_std            141.08969096446617
total_rewards_max            10163.419983353817
total_rewards_min            9710.54266452535
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               28.61084476672113
(Previous) Eval Time (s)     22.237481134943664
Sample Time (s)              16.539054250344634
Epoch Time (s)               67.38738015200943
Total Train Time (s)         24963.369680613745
Epoch                        373
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:54:18.595389 UTC | [2020_01_10_08_58_14] Iteration #373 | Epoch Duration: 67.8148980140686
2020-01-10 15:54:18.595684 UTC | [2020_01_10_08_58_14] Iteration #373 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4935513
Z variance train             0.015512404
KL Divergence                36.845818
KL Loss                      3.6845818
QF Loss                      528.665
VF Loss                      191.93347
Policy Loss                  -4019.7742
Q Predictions Mean           4033.944
Q Predictions Std            408.70056
Q Predictions Max            4560.9316
Q Predictions Min            2889.228
V Predictions Mean           4028.9458
V Predictions Std            408.67484
V Predictions Max            4549.408
V Predictions Min            2882.5415
Log Pis Mean                 6.094939
Log Pis Std                  3.7738242
Log Pis Max                  16.102522
Log Pis Min                  -4.1818237
Policy mu Mean               -0.06747595
Policy mu Std                1.4925706
Policy mu Max                3.1621523
Policy mu Min                -2.7519217
Policy log std Mean          -0.8284294
Policy log std Std           0.44177675
Policy log std Max           -0.1168699
Policy log std Min           -3.0314844
Z mean eval                  2.4682376
Z variance eval              0.01406016
total_rewards                [ 9822.19205795 10014.45951302  9868.23004514 10116.50199824
  9866.63463659 10218.40129988  9783.21069545  9891.340802
  9843.79657856 10054.81034086]
total_rewards_mean           9947.957796768487
total_rewards_std            136.8833164988667
total_rewards_max            10218.401299880064
total_rewards_min            9783.2106954482
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               26.640709810890257
(Previous) Eval Time (s)     22.664712366182357
Sample Time (s)              16.08905724203214
Epoch Time (s)               65.39447941910475
Total Train Time (s)         25028.407946298365
Epoch                        374
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:55:23.639717 UTC | [2020_01_10_08_58_14] Iteration #374 | Epoch Duration: 65.04375505447388
2020-01-10 15:55:23.640027 UTC | [2020_01_10_08_58_14] Iteration #374 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4670851
Z variance train             0.014028139
KL Divergence                37.51132
KL Loss                      3.7511318
QF Loss                      328.02826
VF Loss                      255.05846
Policy Loss                  -3962.773
Q Predictions Mean           3971.604
Q Predictions Std            420.49127
Q Predictions Max            4488.526
Q Predictions Min            2769.143
V Predictions Mean           3957.6443
V Predictions Std            420.27664
V Predictions Max            4474.0806
V Predictions Min            2763.1323
Log Pis Mean                 5.900273
Log Pis Std                  3.8023565
Log Pis Max                  14.855616
Log Pis Min                  -3.859076
Policy mu Mean               -0.04824252
Policy mu Std                1.4843153
Policy mu Max                2.848423
Policy mu Min                -2.5063741
Policy log std Mean          -0.802496
Policy log std Std           0.44951808
Policy log std Max           -0.13086921
Policy log std Min           -2.9015388
Z mean eval                  2.502425
Z variance eval              0.013517493
total_rewards                [10032.61819145 10020.7223389  10305.92791678  1180.1540972
 10143.76107103 10251.80967303  9961.38330468  3263.16163035
  9752.09080352  9800.53381051]
total_rewards_mean           8471.216283744972
total_rewards_std            3163.617771566874
total_rewards_max            10305.9279167771
total_rewards_min            1180.154097197899
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               30.072931631933898
(Previous) Eval Time (s)     22.31369359791279
Sample Time (s)              16.545731050893664
Epoch Time (s)               68.93235628074035
Total Train Time (s)         25097.917214505374
Epoch                        375
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:56:33.155571 UTC | [2020_01_10_08_58_14] Iteration #375 | Epoch Duration: 69.51528644561768
2020-01-10 15:56:33.155896 UTC | [2020_01_10_08_58_14] Iteration #375 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5024571
Z variance train             0.013564287
KL Divergence                37.378242
KL Loss                      3.7378242
QF Loss                      676.8985
VF Loss                      170.82358
Policy Loss                  -3965.256
Q Predictions Mean           3972.3403
Q Predictions Std            498.8591
Q Predictions Max            4563.492
Q Predictions Min            -138.29471
V Predictions Mean           3967.8765
V Predictions Std            498.253
V Predictions Max            4572.6694
V Predictions Min            -128.85748
Log Pis Mean                 5.997484
Log Pis Std                  3.869341
Log Pis Max                  16.406593
Log Pis Min                  -4.9731092
Policy mu Mean               -0.058596868
Policy mu Std                1.4908975
Policy mu Max                2.931682
Policy mu Min                -2.823543
Policy log std Mean          -0.8155349
Policy log std Std           0.4463222
Policy log std Max           0.19168353
Policy log std Min           -2.9834456
Z mean eval                  2.5936198
Z variance eval              0.013989528
total_rewards                [10336.72000752 10351.120831   10143.22392729  9944.93943296
  9968.40359244 10329.17623947 10175.44758673 10185.11417818
 10541.93982327  8366.94753458]
total_rewards_mean           10034.303315344467
total_rewards_std            581.670641986473
total_rewards_max            10541.93982327197
total_rewards_min            8366.94753458264
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               31.623064452782273
(Previous) Eval Time (s)     22.896356401965022
Sample Time (s)              16.179631436243653
Epoch Time (s)               70.69905229099095
Total Train Time (s)         25168.56331446441
Epoch                        376
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:57:43.804057 UTC | [2020_01_10_08_58_14] Iteration #376 | Epoch Duration: 70.64795184135437
2020-01-10 15:57:43.804251 UTC | [2020_01_10_08_58_14] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5933378
Z variance train             0.013965091
KL Divergence                38.182247
KL Loss                      3.8182247
QF Loss                      289.64548
VF Loss                      159.30554
Policy Loss                  -4016.742
Q Predictions Mean           4023.1904
Q Predictions Std            409.74292
Q Predictions Max            4546.6875
Q Predictions Min            2830.2905
V Predictions Mean           4024.3232
V Predictions Std            407.888
V Predictions Max            4553.3013
V Predictions Min            2833.361
Log Pis Mean                 6.67619
Log Pis Std                  3.7728574
Log Pis Max                  15.361648
Log Pis Min                  -4.749575
Policy mu Mean               -0.07615644
Policy mu Std                1.5542014
Policy mu Max                3.0891368
Policy mu Min                -2.9198496
Policy log std Mean          -0.815514
Policy log std Std           0.42862856
Policy log std Max           -0.10123521
Policy log std Min           -2.9768825
Z mean eval                  2.5188212
Z variance eval              0.016457606
total_rewards                [8617.00283268 7104.98790463 2585.01867207 2106.07509989 1362.03596388
 1048.55935128 9171.75311992 9036.47867881 8780.51622435 9746.63830362]
total_rewards_mean           5955.906615112993
total_rewards_std            3492.1522446496037
total_rewards_max            9746.638303616452
total_rewards_min            1048.559351283297
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               27.182392394170165
(Previous) Eval Time (s)     22.84501325059682
Sample Time (s)              16.17618278739974
Epoch Time (s)               66.20358843216673
Total Train Time (s)         25234.960875626188
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:58:50.211132 UTC | [2020_01_10_08_58_14] Iteration #377 | Epoch Duration: 66.40672826766968
2020-01-10 15:58:50.211417 UTC | [2020_01_10_08_58_14] Iteration #377 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5198085
Z variance train             0.016559381
KL Divergence                37.608917
KL Loss                      3.7608917
QF Loss                      407.10236
VF Loss                      165.33289
Policy Loss                  -4041.5168
Q Predictions Mean           4048.76
Q Predictions Std            399.40527
Q Predictions Max            4542.433
Q Predictions Min            2822.4119
V Predictions Mean           4041.8887
V Predictions Std            399.73657
V Predictions Max            4548.2676
V Predictions Min            2835.5105
Log Pis Mean                 6.106579
Log Pis Std                  3.675451
Log Pis Max                  16.262583
Log Pis Min                  -4.9856896
Policy mu Mean               -0.032969195
Policy mu Std                1.5312977
Policy mu Max                2.968394
Policy mu Min                -2.6126134
Policy log std Mean          -0.7872003
Policy log std Std           0.43878603
Policy log std Max           -0.011959195
Policy log std Min           -2.9292874
Z mean eval                  2.4930592
Z variance eval              0.0151711805
total_rewards                [ 9488.81761705 10238.1077245   8899.70805421  5020.97551956
 10273.80330693  1958.78780093 10465.32582597  1362.49769505
 10413.74226475 10429.30093454]
total_rewards_mean           7855.106674348729
total_rewards_std            3467.3934605599043
total_rewards_max            10465.32582597476
total_rewards_min            1362.4976950524544
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               30.375784961972386
(Previous) Eval Time (s)     23.04787016985938
Sample Time (s)              15.83910757303238
Epoch Time (s)               69.26276270486414
Total Train Time (s)         25303.5546823903
Epoch                        378
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 15:59:58.819881 UTC | [2020_01_10_08_58_14] Iteration #378 | Epoch Duration: 68.60820007324219
2020-01-10 15:59:58.820149 UTC | [2020_01_10_08_58_14] Iteration #378 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4939978
Z variance train             0.015165472
KL Divergence                37.400112
KL Loss                      3.7400112
QF Loss                      504.23038
VF Loss                      169.04704
Policy Loss                  -4035.838
Q Predictions Mean           4039.7014
Q Predictions Std            472.5218
Q Predictions Max            4577.1494
Q Predictions Min            -64.816124
V Predictions Mean           4031.208
V Predictions Std            471.72543
V Predictions Max            4557.3755
V Predictions Min            -60.720985
Log Pis Mean                 5.9103374
Log Pis Std                  3.937398
Log Pis Max                  15.231163
Log Pis Min                  -3.397741
Policy mu Mean               -0.036113605
Policy mu Std                1.4767929
Policy mu Max                3.0087206
Policy mu Min                -2.9696338
Policy log std Mean          -0.83270955
Policy log std Std           0.4525733
Policy log std Max           -0.04014018
Policy log std Min           -3.0112386
Z mean eval                  2.4872165
Z variance eval              0.015594547
total_rewards                [ 9996.58602085 10220.88810227  9988.97968262 10083.24287462
 10163.08355765  9513.11717292  9629.41848153  9945.38515989
  9939.71679585  9924.66896568]
total_rewards_mean           9940.508681387219
total_rewards_std            208.26311933724682
total_rewards_max            10220.88810227455
total_rewards_min            9513.117172917664
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               29.724910304881632
(Previous) Eval Time (s)     22.393020974006504
Sample Time (s)              15.372296543326229
Epoch Time (s)               67.49022782221437
Total Train Time (s)         25371.096178673673
Epoch                        379
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:01:06.354202 UTC | [2020_01_10_08_58_14] Iteration #379 | Epoch Duration: 67.53387641906738
2020-01-10 16:01:06.354362 UTC | [2020_01_10_08_58_14] Iteration #379 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4871352
Z variance train             0.015617996
KL Divergence                36.42661
KL Loss                      3.6426609
QF Loss                      375.4862
VF Loss                      146.20158
Policy Loss                  -4025.6833
Q Predictions Mean           4029.0527
Q Predictions Std            458.43546
Q Predictions Max            4582.4595
Q Predictions Min            -39.476387
V Predictions Mean           4028.7456
V Predictions Std            458.45923
V Predictions Max            4573.0903
V Predictions Min            -72.15539
Log Pis Mean                 6.2978954
Log Pis Std                  3.85517
Log Pis Max                  14.390083
Log Pis Min                  -4.286248
Policy mu Mean               0.0034476214
Policy mu Std                1.4978747
Policy mu Max                3.6249192
Policy mu Min                -3.3476772
Policy log std Mean          -0.8150096
Policy log std Std           0.44378966
Policy log std Max           -0.10267356
Policy log std Min           -2.8795896
Z mean eval                  2.5218902
Z variance eval              0.02209254
total_rewards                [ 8298.32158465  2763.08515745  9646.59445445  9923.40528906
  9978.98490417  9948.9388187  10282.62325863  9620.23668403
 10110.71171566 10050.04393154]
total_rewards_mean           9062.294579834337
total_rewards_std            2164.449121298614
total_rewards_max            10282.623258632044
total_rewards_min            2763.0851574501708
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               27.847660534083843
(Previous) Eval Time (s)     22.43642691615969
Sample Time (s)              15.718975591938943
Epoch Time (s)               66.00306304218248
Total Train Time (s)         25437.83875625534
Epoch                        380
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:02:13.101533 UTC | [2020_01_10_08_58_14] Iteration #380 | Epoch Duration: 66.74703979492188
2020-01-10 16:02:13.101763 UTC | [2020_01_10_08_58_14] Iteration #380 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.522994
Z variance train             0.022148153
KL Divergence                36.698357
KL Loss                      3.6698358
QF Loss                      716.11255
VF Loss                      266.8297
Policy Loss                  -3971.4246
Q Predictions Mean           3974.6843
Q Predictions Std            417.134
Q Predictions Max            4505.9497
Q Predictions Min            2764.9084
V Predictions Mean           3978.6914
V Predictions Std            419.03552
V Predictions Max            4488.0137
V Predictions Min            2771.6138
Log Pis Mean                 6.392216
Log Pis Std                  3.8199408
Log Pis Max                  16.188217
Log Pis Min                  -6.48584
Policy mu Mean               -0.0039030414
Policy mu Std                1.5024754
Policy mu Max                2.8757286
Policy mu Min                -3.7373304
Policy log std Mean          -0.8405092
Policy log std Std           0.4539615
Policy log std Max           0.093138695
Policy log std Min           -2.8983355
Z mean eval                  2.4690092
Z variance eval              0.018943448
total_rewards                [10059.42724665 10367.63916366 10276.2946772  10126.06857494
 10484.40613862 10324.69486567  9683.45055509 10137.54648799
 10252.45461877  9625.76951302]
total_rewards_mean           10133.77518416177
total_rewards_std            267.3844853103606
total_rewards_max            10484.406138622908
total_rewards_min            9625.769513021105
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               29.04554281802848
(Previous) Eval Time (s)     23.180137696675956
Sample Time (s)              16.719719401560724
Epoch Time (s)               68.94539991626516
Total Train Time (s)         25505.747808129527
Epoch                        381
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:03:21.013312 UTC | [2020_01_10_08_58_14] Iteration #381 | Epoch Duration: 67.91139721870422
2020-01-10 16:03:21.013458 UTC | [2020_01_10_08_58_14] Iteration #381 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.469006
Z variance train             0.018991772
KL Divergence                36.594044
KL Loss                      3.6594045
QF Loss                      540.95337
VF Loss                      253.5911
Policy Loss                  -4082.26
Q Predictions Mean           4082.0654
Q Predictions Std            439.36942
Q Predictions Max            4638.2466
Q Predictions Min            2537.4011
V Predictions Mean           4071.2104
V Predictions Std            437.71027
V Predictions Max            4633.6206
V Predictions Min            2515.2625
Log Pis Mean                 6.5392666
Log Pis Std                  3.763971
Log Pis Max                  17.243637
Log Pis Min                  -3.6506338
Policy mu Mean               -0.07238218
Policy mu Std                1.5235859
Policy mu Max                3.016052
Policy mu Min                -3.1683285
Policy log std Mean          -0.8052328
Policy log std Std           0.44667095
Policy log std Max           -0.06289306
Policy log std Min           -3.0428057
Z mean eval                  2.4964478
Z variance eval              0.015409182
total_rewards                [ 9992.86729492 10057.29277306 10142.08800608  9948.14544304
 10082.15688038 10322.17194304 10064.73969302 10205.78990731
  9784.48425715  9999.57444243]
total_rewards_mean           10059.931064044777
total_rewards_std            139.2215334261142
total_rewards_max            10322.171943040512
total_rewards_min            9784.484257149843
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               27.615171579178423
(Previous) Eval Time (s)     22.145818599965423
Sample Time (s)              15.686035401653498
Epoch Time (s)               65.44702558079734
Total Train Time (s)         25571.354022325482
Epoch                        382
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:04:26.622904 UTC | [2020_01_10_08_58_14] Iteration #382 | Epoch Duration: 65.60931873321533
2020-01-10 16:04:26.623109 UTC | [2020_01_10_08_58_14] Iteration #382 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4973705
Z variance train             0.015393047
KL Divergence                37.66911
KL Loss                      3.766911
QF Loss                      459.16925
VF Loss                      423.24622
Policy Loss                  -3950.357
Q Predictions Mean           3952.5303
Q Predictions Std            569.67914
Q Predictions Max            4512.917
Q Predictions Min            -117.971
V Predictions Mean           3936.449
V Predictions Std            560.6649
V Predictions Max            4486.146
V Predictions Min            -14.833019
Log Pis Mean                 6.504286
Log Pis Std                  4.06741
Log Pis Max                  17.61182
Log Pis Min                  -4.9035616
Policy mu Mean               -0.08369555
Policy mu Std                1.5424443
Policy mu Max                2.7083986
Policy mu Min                -2.7194316
Policy log std Mean          -0.8212804
Policy log std Std           0.45580912
Policy log std Max           -0.07039845
Policy log std Min           -3.0458946
Z mean eval                  2.463341
Z variance eval              0.018436247
total_rewards                [ 9598.30514195  9951.27788999  9764.14893346 10026.11564483
  9537.24237976  9681.41262972  9614.24767769  9756.01211143
  9992.58314545  9719.98850185]
total_rewards_mean           9764.13340561157
total_rewards_std            163.14066702215698
total_rewards_max            10026.115644831525
total_rewards_min            9537.242379756715
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               29.095987753011286
(Previous) Eval Time (s)     22.307817020919174
Sample Time (s)              15.480788346845657
Epoch Time (s)               66.88459312077612
Total Train Time (s)         25638.28209539829
Epoch                        383
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:05:33.554287 UTC | [2020_01_10_08_58_14] Iteration #383 | Epoch Duration: 66.93102145195007
2020-01-10 16:05:33.554480 UTC | [2020_01_10_08_58_14] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4593039
Z variance train             0.018597167
KL Divergence                36.35252
KL Loss                      3.635252
QF Loss                      1530.9497
VF Loss                      1753.7715
Policy Loss                  -4046.1917
Q Predictions Mean           4058.1663
Q Predictions Std            392.8167
Q Predictions Max            4604.056
Q Predictions Min            2873.7114
V Predictions Mean           4069.4263
V Predictions Std            394.31384
V Predictions Max            4651.3467
V Predictions Min            2893.5374
Log Pis Mean                 6.583051
Log Pis Std                  3.7921755
Log Pis Max                  15.103453
Log Pis Min                  -4.958761
Policy mu Mean               0.035493363
Policy mu Std                1.5335975
Policy mu Max                2.9573855
Policy mu Min                -2.887741
Policy log std Mean          -0.816511
Policy log std Std           0.44325504
Policy log std Max           -0.065811515
Policy log std Min           -2.9314237
Z mean eval                  2.4992692
Z variance eval              0.012371286
total_rewards                [9727.62429956 9329.65943683 9909.18838051 9552.30551608 9382.53106642
 2059.73996937 9351.48468341 9365.87945949 9378.43993108 9670.59102437]
total_rewards_mean           8772.744376712577
total_rewards_std            2245.377114233683
total_rewards_max            9909.18838050515
total_rewards_min            2059.739969372393
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               27.593219036236405
(Previous) Eval Time (s)     22.353971283882856
Sample Time (s)              15.903709487523884
Epoch Time (s)               65.85089980764315
Total Train Time (s)         25704.445561029483
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:06:39.723908 UTC | [2020_01_10_08_58_14] Iteration #384 | Epoch Duration: 66.16924047470093
2020-01-10 16:06:39.724190 UTC | [2020_01_10_08_58_14] Iteration #384 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4997418
Z variance train             0.012372905
KL Divergence                37.238144
KL Loss                      3.7238145
QF Loss                      421.38202
VF Loss                      100.55781
Policy Loss                  -4012.41
Q Predictions Mean           4020.715
Q Predictions Std            483.64035
Q Predictions Max            4543.2695
Q Predictions Min            29.585964
V Predictions Mean           4010.5986
V Predictions Std            481.14496
V Predictions Max            4543.9067
V Predictions Min            54.553684
Log Pis Mean                 6.0055575
Log Pis Std                  3.7472804
Log Pis Max                  15.211245
Log Pis Min                  -5.756074
Policy mu Mean               -0.03221755
Policy mu Std                1.5001872
Policy mu Max                2.89601
Policy mu Min                -2.8051853
Policy log std Mean          -0.8071282
Policy log std Std           0.4234991
Policy log std Max           -0.13199247
Policy log std Min           -2.892654
Z mean eval                  2.5006213
Z variance eval              0.011615499
total_rewards                [10169.88879325 10254.82193584 10281.49748434 10095.98662303
 10163.47780776 10103.61643951 10433.97173669 10283.23645493
 10396.31975313 10015.7008961 ]
total_rewards_mean           10219.85179245823
total_rewards_std            127.37117521283325
total_rewards_max            10433.971736691861
total_rewards_min            10015.700896104912
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               29.511506548151374
(Previous) Eval Time (s)     22.672014337964356
Sample Time (s)              15.812128271441907
Epoch Time (s)               67.99564915755764
Total Train Time (s)         25771.895293643698
Epoch                        385
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:07:47.175592 UTC | [2020_01_10_08_58_14] Iteration #385 | Epoch Duration: 67.45122146606445
2020-01-10 16:07:47.175740 UTC | [2020_01_10_08_58_14] Iteration #385 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5006204
Z variance train             0.011607088
KL Divergence                37.603207
KL Loss                      3.7603207
QF Loss                      440.83984
VF Loss                      213.6615
Policy Loss                  -3996.7253
Q Predictions Mean           4006.6758
Q Predictions Std            465.60864
Q Predictions Max            4628.097
Q Predictions Min            2822.1172
V Predictions Mean           4007.0073
V Predictions Std            465.79688
V Predictions Max            4624.4517
V Predictions Min            2829.2715
Log Pis Mean                 6.3533864
Log Pis Std                  3.6647468
Log Pis Max                  16.17674
Log Pis Min                  -3.0678806
Policy mu Mean               -0.09100453
Policy mu Std                1.4946861
Policy mu Max                3.3211398
Policy mu Min                -3.1521537
Policy log std Mean          -0.8300519
Policy log std Std           0.4587006
Policy log std Max           -0.16286612
Policy log std Min           -3.0168247
Z mean eval                  2.4546418
Z variance eval              0.014347466
total_rewards                [ 9716.61741287  9934.26616794  2294.80885794 10257.87984229
 10166.81664566 10194.49494401 10274.81935032  9542.72667836
  6964.20957642 10120.80147398]
total_rewards_mean           8946.744094980339
total_rewards_std            2408.4957192399306
total_rewards_max            10274.81935031891
total_rewards_min            2294.808857942979
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               28.911171378102154
(Previous) Eval Time (s)     22.127360231243074
Sample Time (s)              15.850875788833946
Epoch Time (s)               66.88940739817917
Total Train Time (s)         25839.58858715277
Epoch                        386
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:08:54.871577 UTC | [2020_01_10_08_58_14] Iteration #386 | Epoch Duration: 67.69569873809814
2020-01-10 16:08:54.871720 UTC | [2020_01_10_08_58_14] Iteration #386 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.45462
Z variance train             0.0143994335
KL Divergence                36.35763
KL Loss                      3.6357632
QF Loss                      566.70557
VF Loss                      186.00954
Policy Loss                  -4062.6462
Q Predictions Mean           4071.9924
Q Predictions Std            470.9839
Q Predictions Max            4601.277
Q Predictions Min            -298.07196
V Predictions Mean           4070.1333
V Predictions Std            471.5184
V Predictions Max            4597.033
V Predictions Min            -330.98376
Log Pis Mean                 5.547717
Log Pis Std                  3.7385
Log Pis Max                  16.695515
Log Pis Min                  -3.7038279
Policy mu Mean               -0.06773066
Policy mu Std                1.4878151
Policy mu Max                3.016086
Policy mu Min                -2.6849952
Policy log std Mean          -0.81405544
Policy log std Std           0.4478735
Policy log std Max           -0.12646922
Policy log std Min           -3.0254645
Z mean eval                  2.500258
Z variance eval              0.013481103
total_rewards                [ 9821.72670145 10519.32921135 10407.90156163 10623.55582486
 10480.15072911 10453.55901102 10420.4403437  10337.03730201
 10413.34913306  1532.48344844]
total_rewards_mean           9500.953326661875
total_rewards_std            2663.8793649320246
total_rewards_max            10623.555824855302
total_rewards_min            1532.483448443666
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               29.670883337967098
(Previous) Eval Time (s)     22.933389778248966
Sample Time (s)              16.107140582520515
Epoch Time (s)               68.71141369873658
Total Train Time (s)         25908.866647470277
Epoch                        387
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:10:04.155168 UTC | [2020_01_10_08_58_14] Iteration #387 | Epoch Duration: 69.28329038619995
2020-01-10 16:10:04.155414 UTC | [2020_01_10_08_58_14] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4994402
Z variance train             0.013465906
KL Divergence                36.985947
KL Loss                      3.6985948
QF Loss                      456.64664
VF Loss                      228.87689
Policy Loss                  -4018.3528
Q Predictions Mean           4022.3633
Q Predictions Std            430.10196
Q Predictions Max            4620.0938
Q Predictions Min            2792.154
V Predictions Mean           4019.9805
V Predictions Std            428.17014
V Predictions Max            4623.327
V Predictions Min            2787.438
Log Pis Mean                 6.339665
Log Pis Std                  3.898644
Log Pis Max                  16.43111
Log Pis Min                  -4.3852444
Policy mu Mean               -0.010308306
Policy mu Std                1.5193261
Policy mu Max                2.9119785
Policy mu Min                -2.7544656
Policy log std Mean          -0.83194464
Policy log std Std           0.45281485
Policy log std Max           -0.10648829
Policy log std Min           -3.0418606
Z mean eval                  2.4693456
Z variance eval              0.023654211
total_rewards                [ 9987.0327635  10039.65594382 10218.24290942 10114.87979161
 10063.89310887 10196.09986249 10140.67379224 10149.70457293
  6395.06854427  9962.51709031]
total_rewards_mean           9726.776837947393
total_rewards_std            1113.4510740818355
total_rewards_max            10218.242909424047
total_rewards_min            6395.0685442727645
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               27.24562893481925
(Previous) Eval Time (s)     23.50497899297625
Sample Time (s)              16.070116634480655
Epoch Time (s)               66.82072456227615
Total Train Time (s)         25974.18985255994
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:11:09.480835 UTC | [2020_01_10_08_58_14] Iteration #388 | Epoch Duration: 65.3252420425415
2020-01-10 16:11:09.481018 UTC | [2020_01_10_08_58_14] Iteration #388 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4689484
Z variance train             0.023612347
KL Divergence                35.980576
KL Loss                      3.5980575
QF Loss                      463.93683
VF Loss                      127.22561
Policy Loss                  -4002.54
Q Predictions Mean           4012.3738
Q Predictions Std            414.99158
Q Predictions Max            4513.692
Q Predictions Min            2729.393
V Predictions Mean           4005.4634
V Predictions Std            414.83026
V Predictions Max            4502.7637
V Predictions Min            2725.0244
Log Pis Mean                 5.8765078
Log Pis Std                  3.6972778
Log Pis Max                  14.092548
Log Pis Min                  -4.7615905
Policy mu Mean               0.002467649
Policy mu Std                1.4870489
Policy mu Max                3.0218525
Policy mu Min                -3.0742602
Policy log std Mean          -0.81000024
Policy log std Std           0.43072814
Policy log std Max           -0.16879176
Policy log std Min           -2.9417682
Z mean eval                  2.453517
Z variance eval              0.01854897
total_rewards                [ 9927.60118311  9999.28832114 10152.46067414 10204.29810464
 10297.04155018 10056.39684227 10243.33214455 10257.32245689
 10004.20650057 10180.12720106]
total_rewards_mean           10132.20749785543
total_rewards_std            120.3075275918441
total_rewards_max            10297.04155018232
total_rewards_min            9927.601183110533
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               27.38608559826389
(Previous) Eval Time (s)     22.009232671000063
Sample Time (s)              16.974535824730992
Epoch Time (s)               66.36985409399495
Total Train Time (s)         26041.49870656943
Epoch                        389
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:12:16.792276 UTC | [2020_01_10_08_58_14] Iteration #389 | Epoch Duration: 67.31114268302917
2020-01-10 16:12:16.792438 UTC | [2020_01_10_08_58_14] Iteration #389 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4532752
Z variance train             0.018579718
KL Divergence                35.825268
KL Loss                      3.582527
QF Loss                      572.0295
VF Loss                      403.57907
Policy Loss                  -3944.585
Q Predictions Mean           3950.728
Q Predictions Std            422.43735
Q Predictions Max            4501.1426
Q Predictions Min            2734.081
V Predictions Mean           3958.6914
V Predictions Std            424.05365
V Predictions Max            4510.5596
V Predictions Min            2737.9797
Log Pis Mean                 6.389412
Log Pis Std                  3.7142045
Log Pis Max                  14.953967
Log Pis Min                  -3.225624
Policy mu Mean               -0.043746497
Policy mu Std                1.5042412
Policy mu Max                2.8670695
Policy mu Min                -2.6577766
Policy log std Mean          -0.8323234
Policy log std Std           0.47624865
Policy log std Max           -0.04993099
Policy log std Min           -2.9207938
Z mean eval                  2.492592
Z variance eval              0.016276598
total_rewards                [ 9957.75507695  8866.03649311  9993.34192525 10053.0146122
  9951.27308948  8654.56257812 10416.30947227  9655.99238868
  9910.95601834 10050.30920398]
total_rewards_mean           9750.95508583673
total_rewards_std            527.7281386140303
total_rewards_max            10416.309472265786
total_rewards_min            8654.562578124222
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               30.128925983328372
(Previous) Eval Time (s)     22.95020496007055
Sample Time (s)              15.915597777348012
Epoch Time (s)               68.99472872074693
Total Train Time (s)         26109.65936369449
Epoch                        390
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:13:24.956383 UTC | [2020_01_10_08_58_14] Iteration #390 | Epoch Duration: 68.16382074356079
2020-01-10 16:13:24.956552 UTC | [2020_01_10_08_58_14] Iteration #390 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.487647
Z variance train             0.016199742
KL Divergence                37.078743
KL Loss                      3.7078743
QF Loss                      1281.0349
VF Loss                      859.53955
Policy Loss                  -4050.021
Q Predictions Mean           4050.9768
Q Predictions Std            438.53906
Q Predictions Max            4617.3506
Q Predictions Min            2821.6616
V Predictions Mean           4060.3486
V Predictions Std            439.5045
V Predictions Max            4647.0327
V Predictions Min            2837.2178
Log Pis Mean                 6.269522
Log Pis Std                  3.8918507
Log Pis Max                  18.529646
Log Pis Min                  -4.182684
Policy mu Mean               -0.035179164
Policy mu Std                1.5203642
Policy mu Max                3.0570488
Policy mu Min                -2.5801768
Policy log std Mean          -0.8025639
Policy log std Std           0.42494532
Policy log std Max           -0.023927987
Policy log std Min           -2.9523296
Z mean eval                  2.4887915
Z variance eval              0.017066572
total_rewards                [ 9738.20300139  7207.70176176  9745.94853291 10142.76967276
  9958.83381509 10058.10134822  9302.36953972  9882.44125786
  9649.44996301  9703.28521992]
total_rewards_mean           9538.910411264194
total_rewards_std            808.7558399342294
total_rewards_max            10142.769672756767
total_rewards_min            7207.70176176425
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               28.620395126752555
(Previous) Eval Time (s)     22.119004334323108
Sample Time (s)              15.990335619077086
Epoch Time (s)               66.72973508015275
Total Train Time (s)         26176.808197563514
Epoch                        391
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:14:32.108803 UTC | [2020_01_10_08_58_14] Iteration #391 | Epoch Duration: 67.1521098613739
2020-01-10 16:14:32.108991 UTC | [2020_01_10_08_58_14] Iteration #391 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4906943
Z variance train             0.01704727
KL Divergence                37.601078
KL Loss                      3.7601078
QF Loss                      401.27448
VF Loss                      801.30554
Policy Loss                  -3980.4036
Q Predictions Mean           3981.767
Q Predictions Std            457.10062
Q Predictions Max            4581.071
Q Predictions Min            2514.577
V Predictions Mean           3959.81
V Predictions Std            455.293
V Predictions Max            4525.1885
V Predictions Min            2436.1611
Log Pis Mean                 6.123254
Log Pis Std                  3.6663249
Log Pis Max                  14.37122
Log Pis Min                  -3.7503626
Policy mu Mean               -0.06824394
Policy mu Std                1.5197649
Policy mu Max                3.0223703
Policy mu Min                -3.0902362
Policy log std Mean          -0.79569197
Policy log std Std           0.42740914
Policy log std Max           0.06954247
Policy log std Min           -2.7636204
Z mean eval                  2.4766746
Z variance eval              0.0209371
total_rewards                [ 9615.83301209  9747.25219549  9834.82077001  9941.84101511
 10044.83521947  9906.26288092  9834.25478226  9444.51872099
  9739.53760974  3041.46361732]
total_rewards_mean           9115.061982339343
total_rewards_std            2030.9327029850135
total_rewards_max            10044.835219466746
total_rewards_min            3041.4636173224494
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               28.91043772920966
(Previous) Eval Time (s)     22.54112774413079
Sample Time (s)              15.690190036315471
Epoch Time (s)               67.14175550965592
Total Train Time (s)         26243.56158989342
Epoch                        392
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:15:38.868185 UTC | [2020_01_10_08_58_14] Iteration #392 | Epoch Duration: 66.75900506973267
2020-01-10 16:15:38.868500 UTC | [2020_01_10_08_58_14] Iteration #392 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4774976
Z variance train             0.020704646
KL Divergence                36.88469
KL Loss                      3.688469
QF Loss                      714.552
VF Loss                      2499.8723
Policy Loss                  -4036.3953
Q Predictions Mean           4041.9697
Q Predictions Std            421.91788
Q Predictions Max            4587.124
Q Predictions Min            2820.476
V Predictions Mean           4003.1318
V Predictions Std            418.1004
V Predictions Max            4563.138
V Predictions Min            2798.3481
Log Pis Mean                 6.1356916
Log Pis Std                  3.8622916
Log Pis Max                  16.259657
Log Pis Min                  -5.2411876
Policy mu Mean               0.020239823
Policy mu Std                1.4851465
Policy mu Max                3.1278267
Policy mu Min                -2.574575
Policy log std Mean          -0.82590026
Policy log std Std           0.4365101
Policy log std Max           -0.19018123
Policy log std Min           -2.7931898
Z mean eval                  2.4883904
Z variance eval              0.033583473
total_rewards                [10305.80975191 10229.33222713  9922.86886421 10376.74660895
 10484.7717438  10433.03245753  9852.3673409   9922.5385252
  1990.34166972 10199.34249001]
total_rewards_mean           9371.71516793496
total_rewards_std            2469.640909593595
total_rewards_max            10484.771743801804
total_rewards_min            1990.341669716014
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               29.259826850146055
(Previous) Eval Time (s)     22.15805656136945
Sample Time (s)              17.03757016034797
Epoch Time (s)               68.45545357186347
Total Train Time (s)         26312.26715726778
Epoch                        393
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:16:47.574656 UTC | [2020_01_10_08_58_14] Iteration #393 | Epoch Duration: 68.70595049858093
2020-01-10 16:16:47.574818 UTC | [2020_01_10_08_58_14] Iteration #393 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4861188
Z variance train             0.033591196
KL Divergence                36.357586
KL Loss                      3.6357586
QF Loss                      402.88544
VF Loss                      142.02295
Policy Loss                  -4100.317
Q Predictions Mean           4111.168
Q Predictions Std            405.17328
Q Predictions Max            4614.8667
Q Predictions Min            2855.8857
V Predictions Mean           4105.256
V Predictions Std            404.83252
V Predictions Max            4611.7324
V Predictions Min            2843.338
Log Pis Mean                 6.757446
Log Pis Std                  3.9022465
Log Pis Max                  15.967212
Log Pis Min                  -2.4575105
Policy mu Mean               -0.059196535
Policy mu Std                1.5448034
Policy mu Max                3.057357
Policy mu Min                -2.9341807
Policy log std Mean          -0.82012033
Policy log std Std           0.4617756
Policy log std Max           -0.0576998
Policy log std Min           -3.0085583
Z mean eval                  2.5143647
Z variance eval              0.03313583
total_rewards                [ 5142.53018438  9854.34798262 10224.73036993  7853.22751505
  2845.87421757 10389.97819476  3317.73390565 10170.61714329
  9634.49929227  2840.60938421]
total_rewards_mean           7227.4148189733705
total_rewards_std            3143.3887975552343
total_rewards_max            10389.97819475837
total_rewards_min            2840.609384210449
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               29.50928920507431
(Previous) Eval Time (s)     22.408250488806516
Sample Time (s)              15.356478696223348
Epoch Time (s)               67.27401839010417
Total Train Time (s)         26379.361470004544
Epoch                        394
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:17:54.674231 UTC | [2020_01_10_08_58_14] Iteration #394 | Epoch Duration: 67.09927153587341
2020-01-10 16:17:54.674460 UTC | [2020_01_10_08_58_14] Iteration #394 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5139353
Z variance train             0.033050865
KL Divergence                37.854523
KL Loss                      3.7854524
QF Loss                      696.89014
VF Loss                      235.81366
Policy Loss                  -4091.2073
Q Predictions Mean           4093.02
Q Predictions Std            464.9058
Q Predictions Max            4609.2505
Q Predictions Min            229.63878
V Predictions Mean           4086.1738
V Predictions Std            465.20157
V Predictions Max            4606.256
V Predictions Min            183.97797
Log Pis Mean                 6.3526673
Log Pis Std                  3.9625216
Log Pis Max                  17.05038
Log Pis Min                  -2.781886
Policy mu Mean               -0.02164778
Policy mu Std                1.5195509
Policy mu Max                3.2663023
Policy mu Min                -3.102731
Policy log std Mean          -0.80999976
Policy log std Std           0.44592935
Policy log std Max           -0.11432651
Policy log std Min           -2.7831836
Z mean eval                  2.501035
Z variance eval              0.031142166
total_rewards                [10199.33512415 10103.95644426 10039.79413246  7698.2059185
 10059.12081715  9995.57379439 10210.44994358  9836.12599303
  9811.35041212 10248.76421115]
total_rewards_mean           9820.267679080378
total_rewards_std            721.0738491833474
total_rewards_max            10248.764211151101
total_rewards_min            7698.205918504694
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               27.128613947425038
(Previous) Eval Time (s)     22.233202525880188
Sample Time (s)              15.533415637910366
Epoch Time (s)               64.89523211121559
Total Train Time (s)         26444.562616807874
Epoch                        395
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:18:59.880244 UTC | [2020_01_10_08_58_14] Iteration #395 | Epoch Duration: 65.20561337471008
2020-01-10 16:18:59.880443 UTC | [2020_01_10_08_58_14] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5029309
Z variance train             0.031092402
KL Divergence                38.096123
KL Loss                      3.8096123
QF Loss                      465.8945
VF Loss                      314.31796
Policy Loss                  -4072.3694
Q Predictions Mean           4075.1543
Q Predictions Std            422.70853
Q Predictions Max            4615.354
Q Predictions Min            2792.2588
V Predictions Mean           4058.479
V Predictions Std            419.3808
V Predictions Max            4579.197
V Predictions Min            2797.4387
Log Pis Mean                 6.2788897
Log Pis Std                  3.9887419
Log Pis Max                  15.922758
Log Pis Min                  -5.0522037
Policy mu Mean               -0.052607253
Policy mu Std                1.5344596
Policy mu Max                2.7961898
Policy mu Min                -2.7809649
Policy log std Mean          -0.80657667
Policy log std Std           0.42067596
Policy log std Max           -0.07804322
Policy log std Min           -2.8272798
Z mean eval                  2.4892025
Z variance eval              0.02898798
total_rewards                [9788.45034437 9846.83430358 9743.75199888 9580.25245437 9509.05327591
 9671.77825154 9954.65991938 9446.71785518 9776.13362269 9567.14380251]
total_rewards_mean           9688.477582841535
total_rewards_std            152.97632591638705
total_rewards_max            9954.659919380365
total_rewards_min            9446.717855182376
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               30.18818347901106
(Previous) Eval Time (s)     22.54328499827534
Sample Time (s)              16.71877698134631
Epoch Time (s)               69.45024545863271
Total Train Time (s)         26513.526564643253
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:20:08.848416 UTC | [2020_01_10_08_58_14] Iteration #396 | Epoch Duration: 68.96781206130981
2020-01-10 16:20:08.848627 UTC | [2020_01_10_08_58_14] Iteration #396 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4904823
Z variance train             0.028706422
KL Divergence                37.451332
KL Loss                      3.7451332
QF Loss                      544.8124
VF Loss                      243.93074
Policy Loss                  -3998.1372
Q Predictions Mean           4004.5942
Q Predictions Std            479.58734
Q Predictions Max            4599.3784
Q Predictions Min            231.9023
V Predictions Mean           4002.8628
V Predictions Std            478.4595
V Predictions Max            4559.5146
V Predictions Min            237.62471
Log Pis Mean                 6.2547636
Log Pis Std                  3.7024808
Log Pis Max                  14.51509
Log Pis Min                  -6.6061754
Policy mu Mean               -0.04891784
Policy mu Std                1.517206
Policy mu Max                3.2727206
Policy mu Min                -3.2738836
Policy log std Mean          -0.7848552
Policy log std Std           0.43199638
Policy log std Max           0.073975086
Policy log std Min           -2.8071437
Z mean eval                  2.4782422
Z variance eval              0.020052334
total_rewards                [ 2023.89813971  9847.7309045   9835.92683635  9835.61018893
  9841.06242109  9764.09431175  1280.76678537 10043.82563756
  9646.10636445  9841.9782516 ]
total_rewards_mean           8196.099984131186
total_rewards_std            3277.3899808727338
total_rewards_max            10043.82563755964
total_rewards_min            1280.7667853670787
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               28.76182494359091
(Previous) Eval Time (s)     22.060578601900488
Sample Time (s)              16.186468527652323
Epoch Time (s)               67.00887207314372
Total Train Time (s)         26581.670226986054
Epoch                        397
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:21:16.995170 UTC | [2020_01_10_08_58_14] Iteration #397 | Epoch Duration: 68.14639163017273
2020-01-10 16:21:16.995327 UTC | [2020_01_10_08_58_14] Iteration #397 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4788318
Z variance train             0.020103479
KL Divergence                38.048523
KL Loss                      3.8048522
QF Loss                      620.24915
VF Loss                      162.49028
Policy Loss                  -4075.4841
Q Predictions Mean           4081.8257
Q Predictions Std            431.72363
Q Predictions Max            4602.0596
Q Predictions Min            2795.0625
V Predictions Mean           4074.6145
V Predictions Std            428.99728
V Predictions Max            4594.432
V Predictions Min            2799.152
Log Pis Mean                 6.3038645
Log Pis Std                  3.7492774
Log Pis Max                  17.108253
Log Pis Min                  -4.491709
Policy mu Mean               -0.03492637
Policy mu Std                1.5055125
Policy mu Max                3.23556
Policy mu Min                -2.6973226
Policy log std Mean          -0.8047133
Policy log std Std           0.43404582
Policy log std Max           -0.12654215
Policy log std Min           -2.6049712
Z mean eval                  2.4597156
Z variance eval              0.027221873
total_rewards                [ 9781.08685508 10076.08327266  9893.47351176  9406.4130986
 10027.74167444  9856.95446824  9896.64656735  9864.7860033
  9810.80839607 10193.62058419]
total_rewards_mean           9880.761443168409
total_rewards_std            199.6760808105842
total_rewards_max            10193.620584189897
total_rewards_min            9406.413098597022
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               29.928803630638868
(Previous) Eval Time (s)     23.197832284029573
Sample Time (s)              16.447731761727482
Epoch Time (s)               69.57436767639592
Total Train Time (s)         26650.033442341723
Epoch                        398
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:22:25.360886 UTC | [2020_01_10_08_58_14] Iteration #398 | Epoch Duration: 68.36541604995728
2020-01-10 16:22:25.361059 UTC | [2020_01_10_08_58_14] Iteration #398 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.459783
Z variance train             0.027194863
KL Divergence                37.111702
KL Loss                      3.7111702
QF Loss                      744.0796
VF Loss                      1024.6682
Policy Loss                  -3991.1702
Q Predictions Mean           3989.4514
Q Predictions Std            478.83047
Q Predictions Max            4578.8047
Q Predictions Min            510.97214
V Predictions Mean           3967.719
V Predictions Std            472.42487
V Predictions Max            4561.19
V Predictions Min            599.0566
Log Pis Mean                 6.3549395
Log Pis Std                  3.616649
Log Pis Max                  19.814323
Log Pis Min                  -5.0215654
Policy mu Mean               0.009089445
Policy mu Std                1.5221374
Policy mu Max                3.3577526
Policy mu Min                -3.455961
Policy log std Mean          -0.8129978
Policy log std Std           0.43523613
Policy log std Max           -0.1372224
Policy log std Min           -2.7686124
Z mean eval                  2.482831
Z variance eval              0.02755459
total_rewards                [ 9496.08664423  9737.01955129  9919.01238702  9857.04098679
  9746.71263682  9957.3542043  10010.96431845  9639.59059717
  9925.72395913  9918.65275328]
total_rewards_mean           9820.815803849042
total_rewards_std            153.99237282826223
total_rewards_max            10010.964318450755
total_rewards_min            9496.086644231764
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               28.171876134350896
(Previous) Eval Time (s)     21.988577413838357
Sample Time (s)              15.713573180604726
Epoch Time (s)               65.87402672879398
Total Train Time (s)         26717.498555899132
Epoch                        399
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:23:32.832855 UTC | [2020_01_10_08_58_14] Iteration #399 | Epoch Duration: 67.47163772583008
2020-01-10 16:23:32.833152 UTC | [2020_01_10_08_58_14] Iteration #399 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4820602
Z variance train             0.027582591
KL Divergence                36.462395
KL Loss                      3.6462395
QF Loss                      534.8462
VF Loss                      170.7127
Policy Loss                  -4051.9785
Q Predictions Mean           4058.7383
Q Predictions Std            515.6446
Q Predictions Max            4645.8335
Q Predictions Min            281.20816
V Predictions Mean           4055.2803
V Predictions Std            514.60315
V Predictions Max            4650.5234
V Predictions Min            327.09732
Log Pis Mean                 6.3493466
Log Pis Std                  3.458537
Log Pis Max                  19.189821
Log Pis Min                  -1.4954864
Policy mu Mean               -0.090451695
Policy mu Std                1.5220194
Policy mu Max                3.6580157
Policy mu Min                -4.2597384
Policy log std Mean          -0.8157467
Policy log std Std           0.45226157
Policy log std Max           -0.1327596
Policy log std Min           -2.7040038
Z mean eval                  2.4977512
Z variance eval              0.019701537
total_rewards                [ 9709.95642704  9958.98205707  9667.94113367 10004.44116202
 10272.18296333 10181.64682592  9968.56720918 10023.72956434
 10229.33342897 10170.99354444]
total_rewards_mean           10018.777431597697
total_rewards_std            195.7108843289789
total_rewards_max            10272.182963325062
total_rewards_min            9667.941133667717
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               29.831411288119853
(Previous) Eval Time (s)     23.585902615915984
Sample Time (s)              16.128972203005105
Epoch Time (s)               69.54628610704094
Total Train Time (s)         26785.8082451229
Epoch                        400
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:24:41.148878 UTC | [2020_01_10_08_58_14] Iteration #400 | Epoch Duration: 68.31549644470215
2020-01-10 16:24:41.149138 UTC | [2020_01_10_08_58_14] Iteration #400 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4974341
Z variance train             0.01964361
KL Divergence                37.737354
KL Loss                      3.7737355
QF Loss                      412.49298
VF Loss                      251.0459
Policy Loss                  -4118.762
Q Predictions Mean           4128.441
Q Predictions Std            457.44507
Q Predictions Max            4625.7036
Q Predictions Min            285.4301
V Predictions Mean           4124.09
V Predictions Std            456.57803
V Predictions Max            4608.4736
V Predictions Min            310.3547
Log Pis Mean                 6.812192
Log Pis Std                  3.8830326
Log Pis Max                  15.995914
Log Pis Min                  -3.1623352
Policy mu Mean               -0.053500485
Policy mu Std                1.5647752
Policy mu Max                3.2005637
Policy mu Min                -3.6831324
Policy log std Mean          -0.8204446
Policy log std Std           0.44515318
Policy log std Max           -0.13009955
Policy log std Min           -2.818326
Z mean eval                  2.4615302
Z variance eval              0.022769518
total_rewards                [ 9857.21215177 10017.99199361 10081.93741975  9996.13416458
  9874.84835813  9877.16860273  9747.18687248 10160.42503017
 10277.16643204  9506.41133043]
total_rewards_mean           9939.648235568346
total_rewards_std            207.81471827532536
total_rewards_max            10277.16643203639
total_rewards_min            9506.411330432813
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               29.550655353814363
(Previous) Eval Time (s)     22.354824700858444
Sample Time (s)              16.20777903497219
Epoch Time (s)               68.113259089645
Total Train Time (s)         26853.687634544447
Epoch                        401
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:25:49.031385 UTC | [2020_01_10_08_58_14] Iteration #401 | Epoch Duration: 67.8820583820343
2020-01-10 16:25:49.031569 UTC | [2020_01_10_08_58_14] Iteration #401 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4619794
Z variance train             0.022825815
KL Divergence                37.42931
KL Loss                      3.7429311
QF Loss                      277.36368
VF Loss                      256.9305
Policy Loss                  -4014.2798
Q Predictions Mean           4022.4504
Q Predictions Std            483.46188
Q Predictions Max            4583.8823
Q Predictions Min            402.9845
V Predictions Mean           4003.6016
V Predictions Std            480.47876
V Predictions Max            4564.3247
V Predictions Min            409.25836
Log Pis Mean                 5.942251
Log Pis Std                  3.620764
Log Pis Max                  14.097749
Log Pis Min                  -8.712528
Policy mu Mean               0.0051594735
Policy mu Std                1.4765974
Policy mu Max                2.7157347
Policy mu Min                -2.535416
Policy log std Mean          -0.81100446
Policy log std Std           0.4238254
Policy log std Max           0.010647118
Policy log std Min           -2.619707
Z mean eval                  2.497153
Z variance eval              0.019645285
total_rewards                [ 9958.43594867 10157.41374044 10219.47231347 10033.44325096
 10127.71306611  9951.49808106  9921.75598735  9949.61610062
  9947.14801828 10116.48881632]
total_rewards_mean           10038.298532328972
total_rewards_std            102.37779554073327
total_rewards_max            10219.47231347146
total_rewards_min            9921.75598735308
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               30.925183827988803
(Previous) Eval Time (s)     22.123343312647194
Sample Time (s)              16.19781360635534
Epoch Time (s)               69.24634074699134
Total Train Time (s)         26923.951659763232
Epoch                        402
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:26:59.299086 UTC | [2020_01_10_08_58_14] Iteration #402 | Epoch Duration: 70.26737594604492
2020-01-10 16:26:59.299279 UTC | [2020_01_10_08_58_14] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.494286
Z variance train             0.019614527
KL Divergence                37.926212
KL Loss                      3.7926214
QF Loss                      635.33276
VF Loss                      492.1888
Policy Loss                  -4059.6956
Q Predictions Mean           4073.697
Q Predictions Std            422.7629
Q Predictions Max            4549.6978
Q Predictions Min            2845.4976
V Predictions Mean           4078.6953
V Predictions Std            423.02704
V Predictions Max            4572.749
V Predictions Min            2848.771
Log Pis Mean                 6.4044824
Log Pis Std                  4.136531
Log Pis Max                  19.11182
Log Pis Min                  -6.8655467
Policy mu Mean               -0.108549915
Policy mu Std                1.5082273
Policy mu Max                3.692501
Policy mu Min                -2.9053628
Policy log std Mean          -0.8351533
Policy log std Std           0.45546028
Policy log std Max           -0.16828947
Policy log std Min           -2.8272302
Z mean eval                  2.4703584
Z variance eval              0.014171389
total_rewards                [10026.64363857 10128.31899044  9948.34512214  9528.68328317
 10012.87974128 10209.16065364 10124.62976715 10217.63759644
  5002.83236558 10111.83914766]
total_rewards_mean           9531.097030608125
total_rewards_std            1520.9960060476176
total_rewards_max            10217.637596441782
total_rewards_min            5002.832365583316
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               30.0617495495826
(Previous) Eval Time (s)     23.144095078110695
Sample Time (s)              16.63980101980269
Epoch Time (s)               69.84564564749599
Total Train Time (s)         26993.72522343602
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:28:09.075488 UTC | [2020_01_10_08_58_14] Iteration #403 | Epoch Duration: 69.77607250213623
2020-01-10 16:28:09.075651 UTC | [2020_01_10_08_58_14] Iteration #403 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4686284
Z variance train             0.014176868
KL Divergence                37.92558
KL Loss                      3.792558
QF Loss                      465.26306
VF Loss                      219.64145
Policy Loss                  -4012.8848
Q Predictions Mean           4019.501
Q Predictions Std            582.13336
Q Predictions Max            4640.6567
Q Predictions Min            238.44373
V Predictions Mean           4022.4177
V Predictions Std            579.32764
V Predictions Max            4619.077
V Predictions Min            266.5317
Log Pis Mean                 5.8354626
Log Pis Std                  3.820186
Log Pis Max                  13.686657
Log Pis Min                  -4.249134
Policy mu Mean               -0.13657849
Policy mu Std                1.4988309
Policy mu Max                2.8996534
Policy mu Min                -2.5031896
Policy log std Mean          -0.79609615
Policy log std Std           0.42162675
Policy log std Max           -0.012185693
Policy log std Min           -2.7932634
Z mean eval                  2.4932017
Z variance eval              0.014607215
total_rewards                [ 9619.31995032  9658.51166425  9847.90330633  9694.99731146
 10147.42875389  9741.26229519  9899.47628061  9923.71441917
  9874.4372767   9899.26353096]
total_rewards_mean           9830.631478886367
total_rewards_std            148.77951724895505
total_rewards_max            10147.428753891492
total_rewards_min            9619.31995031734
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               27.327241288963705
(Previous) Eval Time (s)     23.07421449571848
Sample Time (s)              16.324064852204174
Epoch Time (s)               66.72552063688636
Total Train Time (s)         27059.313406087924
Epoch                        404
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:29:14.668714 UTC | [2020_01_10_08_58_14] Iteration #404 | Epoch Duration: 65.5929274559021
2020-01-10 16:29:14.668924 UTC | [2020_01_10_08_58_14] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4931338
Z variance train             0.014644554
KL Divergence                38.29012
KL Loss                      3.829012
QF Loss                      347.32596
VF Loss                      176.72075
Policy Loss                  -4056.1975
Q Predictions Mean           4067.0327
Q Predictions Std            410.64093
Q Predictions Max            4602.809
Q Predictions Min            2827.7441
V Predictions Mean           4061.939
V Predictions Std            410.35156
V Predictions Max            4608.9556
V Predictions Min            2833.0605
Log Pis Mean                 5.998117
Log Pis Std                  3.840559
Log Pis Max                  19.404345
Log Pis Min                  -4.342884
Policy mu Mean               -0.04175968
Policy mu Std                1.4939883
Policy mu Max                2.8133926
Policy mu Min                -3.0375621
Policy log std Mean          -0.7955396
Policy log std Std           0.39832616
Policy log std Max           -0.092051476
Policy log std Min           -2.5926342
Z mean eval                  2.498859
Z variance eval              0.013614814
total_rewards                [8855.3501975  9248.86811383 8913.48497106 9015.02167895 9040.94165897
 8957.94178039 9239.19167366 9003.10022475 9156.10531087 9078.78793656]
total_rewards_mean           9050.879354653687
total_rewards_std            124.87037505394973
total_rewards_max            9248.868113825423
total_rewards_min            8855.350197499632
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               28.76123071089387
(Previous) Eval Time (s)     21.94133154815063
Sample Time (s)              16.292836823500693
Epoch Time (s)               66.99539908254519
Total Train Time (s)         27126.327573883347
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:30:21.686131 UTC | [2020_01_10_08_58_14] Iteration #405 | Epoch Duration: 67.01703929901123
2020-01-10 16:30:21.686310 UTC | [2020_01_10_08_58_14] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4998384
Z variance train             0.013625026
KL Divergence                38.64173
KL Loss                      3.8641732
QF Loss                      382.36853
VF Loss                      166.5562
Policy Loss                  -4091.909
Q Predictions Mean           4099.166
Q Predictions Std            466.09717
Q Predictions Max            4644.1816
Q Predictions Min            376.05475
V Predictions Mean           4086.6965
V Predictions Std            463.78284
V Predictions Max            4635.27
V Predictions Min            356.88538
Log Pis Mean                 6.1779056
Log Pis Std                  4.148646
Log Pis Max                  16.919672
Log Pis Min                  -8.106038
Policy mu Mean               -0.07498164
Policy mu Std                1.5138509
Policy mu Max                2.7032642
Policy mu Min                -2.7388425
Policy log std Mean          -0.78808516
Policy log std Std           0.42543083
Policy log std Max           -0.07903248
Policy log std Min           -2.6361337
Z mean eval                  2.4748397
Z variance eval              0.018399006
total_rewards                [9553.70917941 9764.5976226  9471.8137598  9645.18193722 9624.44498418
 9630.53607037 9947.72538804 9716.21748501 9646.7808656  9610.93951227]
total_rewards_mean           9661.194680450291
total_rewards_std            121.86797297995979
total_rewards_max            9947.72538804302
total_rewards_min            9471.813759796512
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               29.751447175163776
(Previous) Eval Time (s)     21.962699262890965
Sample Time (s)              15.534976243507117
Epoch Time (s)               67.24912268156186
Total Train Time (s)         27194.054517058656
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:31:29.417514 UTC | [2020_01_10_08_58_14] Iteration #406 | Epoch Duration: 67.73106527328491
2020-01-10 16:31:29.417737 UTC | [2020_01_10_08_58_14] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4770298
Z variance train             0.018415619
KL Divergence                38.02294
KL Loss                      3.8022943
QF Loss                      790.32886
VF Loss                      417.5459
Policy Loss                  -4019.051
Q Predictions Mean           4025.0767
Q Predictions Std            438.0375
Q Predictions Max            4645.068
Q Predictions Min            2793.5732
V Predictions Mean           4014.0532
V Predictions Std            437.54446
V Predictions Max            4646.4863
V Predictions Min            2798.8403
Log Pis Mean                 5.9572186
Log Pis Std                  3.637225
Log Pis Max                  17.089142
Log Pis Min                  -4.433964
Policy mu Mean               -0.04801898
Policy mu Std                1.4824669
Policy mu Max                3.011901
Policy mu Min                -2.8342938
Policy log std Mean          -0.8084194
Policy log std Std           0.45081842
Policy log std Max           -0.11348903
Policy log std Min           -2.9075925
Z mean eval                  2.4751728
Z variance eval              0.015977979
total_rewards                [8975.66203154 9545.44355251 9123.0810398  9021.70856224 9399.20845962
 9165.04513365 9632.73902999 8723.38380335 9082.23682442 9515.76511869]
total_rewards_mean           9218.427355580603
total_rewards_std            278.0063230758395
total_rewards_max            9632.739029990722
total_rewards_min            8723.383803345963
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               26.33222338790074
(Previous) Eval Time (s)     22.444357363972813
Sample Time (s)              15.874072642531246
Epoch Time (s)               64.6506533944048
Total Train Time (s)         27258.754181454424
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:32:34.122317 UTC | [2020_01_10_08_58_14] Iteration #407 | Epoch Duration: 64.70431661605835
2020-01-10 16:32:34.122623 UTC | [2020_01_10_08_58_14] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4759467
Z variance train             0.015938397
KL Divergence                38.32975
KL Loss                      3.8329751
QF Loss                      525.54486
VF Loss                      430.9261
Policy Loss                  -4036.05
Q Predictions Mean           4041.7603
Q Predictions Std            509.1788
Q Predictions Max            4643.9033
Q Predictions Min            202.53354
V Predictions Mean           4028.362
V Predictions Std            507.84186
V Predictions Max            4601.538
V Predictions Min            151.90123
Log Pis Mean                 6.4264793
Log Pis Std                  3.9208658
Log Pis Max                  15.560217
Log Pis Min                  -3.8074026
Policy mu Mean               -0.014614618
Policy mu Std                1.521955
Policy mu Max                2.9952157
Policy mu Min                -2.7832975
Policy log std Mean          -0.8097153
Policy log std Std           0.4681786
Policy log std Max           -0.037349552
Policy log std Min           -2.8935905
Z mean eval                  2.474333
Z variance eval              0.016652143
total_rewards                [ 9739.96579203  9987.74634994  9470.02106034  9720.31722236
  9862.91087942  9773.01134969 10003.28691592  9951.30311965
  9921.80017071  9850.89096097]
total_rewards_mean           9828.125382102293
total_rewards_std            152.48193801782696
total_rewards_max            10003.286915922059
total_rewards_min            9470.02106034267
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               28.841902658808976
(Previous) Eval Time (s)     22.497759245801717
Sample Time (s)              15.787225706968457
Epoch Time (s)               67.12688761157915
Total Train Time (s)         27325.98825381417
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:33:41.361789 UTC | [2020_01_10_08_58_14] Iteration #408 | Epoch Duration: 67.23896408081055
2020-01-10 16:33:41.362048 UTC | [2020_01_10_08_58_14] Iteration #408 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4743621
Z variance train             0.016630705
KL Divergence                37.778736
KL Loss                      3.7778738
QF Loss                      697.8142
VF Loss                      368.08328
Policy Loss                  -4105.3384
Q Predictions Mean           4112.505
Q Predictions Std            429.0672
Q Predictions Max            4734.3843
Q Predictions Min            2522.6743
V Predictions Mean           4114.704
V Predictions Std            429.04337
V Predictions Max            4776.427
V Predictions Min            2580.011
Log Pis Mean                 6.6210217
Log Pis Std                  3.8481333
Log Pis Max                  16.796036
Log Pis Min                  -5.811275
Policy mu Mean               -0.05532719
Policy mu Std                1.5296795
Policy mu Max                2.9489212
Policy mu Min                -3.3967338
Policy log std Mean          -0.8252287
Policy log std Std           0.42994738
Policy log std Max           0.062490582
Policy log std Min           -2.9676986
Z mean eval                  2.4588592
Z variance eval              0.020620305
total_rewards                [ 9219.9175559  10055.34487083  4388.26087726  1455.32727376
  9360.02150132  9768.63551047  9678.19097137  9591.9749013
  9692.89816195  9709.29626476]
total_rewards_mean           8291.986788891092
total_rewards_std            2772.246671920511
total_rewards_max            10055.344870825526
total_rewards_min            1455.327273763308
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               27.754053540993482
(Previous) Eval Time (s)     22.609523553866893
Sample Time (s)              16.089494000189006
Epoch Time (s)               66.45307109504938
Total Train Time (s)         27391.78932872042
Epoch                        409
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:34:47.167961 UTC | [2020_01_10_08_58_14] Iteration #409 | Epoch Duration: 65.80570983886719
2020-01-10 16:34:47.168165 UTC | [2020_01_10_08_58_14] Iteration #409 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4594111
Z variance train             0.020624008
KL Divergence                36.92245
KL Loss                      3.6922452
QF Loss                      743.6474
VF Loss                      2330.1104
Policy Loss                  -4072.413
Q Predictions Mean           4072.941
Q Predictions Std            577.9108
Q Predictions Max            4637.859
Q Predictions Min            266.812
V Predictions Mean           4040.7344
V Predictions Std            571.8822
V Predictions Max            4641.6055
V Predictions Min            285.88864
Log Pis Mean                 6.627367
Log Pis Std                  3.8774748
Log Pis Max                  16.046713
Log Pis Min                  -4.317015
Policy mu Mean               -0.088766016
Policy mu Std                1.528744
Policy mu Max                3.5164344
Policy mu Min                -4.2719235
Policy log std Mean          -0.8262549
Policy log std Std           0.43829364
Policy log std Max           0.0923478
Policy log std Min           -2.792305
Z mean eval                  2.4705217
Z variance eval              0.017978366
total_rewards                [10041.33283632 10331.63107918 10247.4959914  10361.71452561
 10288.09603243 10353.13965211 10469.62295547  9866.69212361
 10327.6026588  10263.02810197]
total_rewards_mean           10255.035595690515
total_rewards_std            166.09594264491628
total_rewards_max            10469.622955471821
total_rewards_min            9866.692123606517
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               27.8654441148974
(Previous) Eval Time (s)     21.961852192878723
Sample Time (s)              15.722412614151835
Epoch Time (s)               65.54970892192796
Total Train Time (s)         27457.66400007112
Epoch                        410
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:35:53.046755 UTC | [2020_01_10_08_58_14] Iteration #410 | Epoch Duration: 65.87840342521667
2020-01-10 16:35:53.047041 UTC | [2020_01_10_08_58_14] Iteration #410 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4697843
Z variance train             0.018014466
KL Divergence                36.966236
KL Loss                      3.6966236
QF Loss                      720.8733
VF Loss                      207.63448
Policy Loss                  -4057.2205
Q Predictions Mean           4061.0034
Q Predictions Std            496.752
Q Predictions Max            4644.444
Q Predictions Min            294.747
V Predictions Mean           4061.1707
V Predictions Std            496.83405
V Predictions Max            4626.5728
V Predictions Min            281.42917
Log Pis Mean                 6.459593
Log Pis Std                  3.9813848
Log Pis Max                  15.3906355
Log Pis Min                  -8.151274
Policy mu Mean               -0.021195687
Policy mu Std                1.5314606
Policy mu Max                3.049204
Policy mu Min                -2.8068244
Policy log std Mean          -0.82199454
Policy log std Std           0.46166527
Policy log std Max           -0.056006312
Policy log std Min           -2.8640227
Z mean eval                  2.4797444
Z variance eval              0.016980644
total_rewards                [ 9891.17448738  9933.21810509 10310.4945304  10469.23340477
  9691.61484657 10004.92781212 10228.4947897   9913.45626671
 10107.48230586 10007.04451703]
total_rewards_mean           10055.714106562347
total_rewards_std            216.39696918244218
total_rewards_max            10469.233404766172
total_rewards_min            9691.61484657283
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               24.99459487805143
(Previous) Eval Time (s)     22.290259283035994
Sample Time (s)              15.592298313975334
Epoch Time (s)               62.87715247506276
Total Train Time (s)         27520.509416136425
Epoch                        411
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:36:55.895559 UTC | [2020_01_10_08_58_14] Iteration #411 | Epoch Duration: 62.8482620716095
2020-01-10 16:36:55.895826 UTC | [2020_01_10_08_58_14] Iteration #411 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4773934
Z variance train             0.016962122
KL Divergence                37.663715
KL Loss                      3.7663715
QF Loss                      385.41193
VF Loss                      156.556
Policy Loss                  -4035.735
Q Predictions Mean           4043.3018
Q Predictions Std            513.9508
Q Predictions Max            4656.193
Q Predictions Min            380.93604
V Predictions Mean           4039.9126
V Predictions Std            512.8562
V Predictions Max            4650.5796
V Predictions Min            429.69885
Log Pis Mean                 6.080885
Log Pis Std                  3.991815
Log Pis Max                  14.0689
Log Pis Min                  -6.1010847
Policy mu Mean               -0.0685617
Policy mu Std                1.508087
Policy mu Max                3.136476
Policy mu Min                -3.3894138
Policy log std Mean          -0.82126206
Policy log std Std           0.44167596
Policy log std Max           -0.12601316
Policy log std Min           -2.8606658
Z mean eval                  2.4403758
Z variance eval              0.16442505
total_rewards                [ 9442.2778927   9961.93978263  9792.47004318  9496.18052688
  9739.0388436  10012.77650919 10045.97200532  9823.89587859
  9699.32684426  9860.73813577]
total_rewards_mean           9787.461646212527
total_rewards_std            192.05937099821838
total_rewards_max            10045.97200532307
total_rewards_min            9442.277892699034
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               26.808150047902018
(Previous) Eval Time (s)     22.26111448602751
Sample Time (s)              16.125830572098494
Epoch Time (s)               65.19509510602802
Total Train Time (s)         27585.967937131412
Epoch                        412
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:38:01.358646 UTC | [2020_01_10_08_58_14] Iteration #412 | Epoch Duration: 65.46266150474548
2020-01-10 16:38:01.358854 UTC | [2020_01_10_08_58_14] Iteration #412 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4403982
Z variance train             0.16465569
KL Divergence                33.702087
KL Loss                      3.3702087
QF Loss                      342.86295
VF Loss                      129.5185
Policy Loss                  -3879.0933
Q Predictions Mean           3888.214
Q Predictions Std            647.07086
Q Predictions Max            4490.294
Q Predictions Min            220.89752
V Predictions Mean           3880.9443
V Predictions Std            644.724
V Predictions Max            4483.251
V Predictions Min            213.9981
Log Pis Mean                 6.68841
Log Pis Std                  3.6830542
Log Pis Max                  15.44813
Log Pis Min                  -2.2369285
Policy mu Mean               -0.0091290735
Policy mu Std                1.5347191
Policy mu Max                2.7754812
Policy mu Min                -3.0860655
Policy log std Mean          -0.8176617
Policy log std Std           0.44701374
Policy log std Max           0.035686612
Policy log std Min           -2.8915646
Z mean eval                  2.4506707
Z variance eval              0.06421128
total_rewards                [ 9467.33558475  9834.62318527 10024.10540338  9562.10889578
  9752.38848893  9852.98083079  5469.87804635 10193.20044014
 10187.35460155  9786.61267333]
total_rewards_mean           9413.058815026008
total_rewards_std            1333.4655725957625
total_rewards_max            10193.20044013749
total_rewards_min            5469.878046354274
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               29.227801509201527
(Previous) Eval Time (s)     22.528392898850143
Sample Time (s)              16.497674479149282
Epoch Time (s)               68.25386888720095
Total Train Time (s)         27653.28272783896
Epoch                        413
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:39:08.676526 UTC | [2020_01_10_08_58_14] Iteration #413 | Epoch Duration: 67.31751608848572
2020-01-10 16:39:08.676734 UTC | [2020_01_10_08_58_14] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4477549
Z variance train             0.06449731
KL Divergence                34.87596
KL Loss                      3.4875963
QF Loss                      319.60422
VF Loss                      513.03156
Policy Loss                  -4027.551
Q Predictions Mean           4036.935
Q Predictions Std            395.51385
Q Predictions Max            4584.747
Q Predictions Min            2784.209
V Predictions Mean           4044.164
V Predictions Std            397.95145
V Predictions Max            4571.2085
V Predictions Min            2781.8325
Log Pis Mean                 6.7622046
Log Pis Std                  3.955317
Log Pis Max                  15.936117
Log Pis Min                  -4.283739
Policy mu Mean               -0.0661836
Policy mu Std                1.5528216
Policy mu Max                3.146575
Policy mu Min                -2.6481826
Policy log std Mean          -0.8073468
Policy log std Std           0.44519252
Policy log std Max           0.015191823
Policy log std Min           -2.8390667
Z mean eval                  2.44582
Z variance eval              0.037059784
total_rewards                [ 9681.1232805   9801.39558931  9723.93924305  9792.87339013
  9622.06784716 10034.71708225  9143.3496336   9818.41852242
  9898.04412789  9753.74241334]
total_rewards_mean           9726.96711296515
total_rewards_std            222.85980890420558
total_rewards_max            10034.717082245998
total_rewards_min            9143.349633600581
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               31.129506153054535
(Previous) Eval Time (s)     21.591776721645147
Sample Time (s)              15.535199372563511
Epoch Time (s)               68.2564822472632
Total Train Time (s)         27721.96612682147
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:40:17.362177 UTC | [2020_01_10_08_58_14] Iteration #414 | Epoch Duration: 68.68530535697937
2020-01-10 16:40:17.362352 UTC | [2020_01_10_08_58_14] Iteration #414 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.446333
Z variance train             0.037081115
KL Divergence                35.96211
KL Loss                      3.596211
QF Loss                      442.7436
VF Loss                      177.14423
Policy Loss                  -4112.7246
Q Predictions Mean           4112.5103
Q Predictions Std            447.81445
Q Predictions Max            4621.8994
Q Predictions Min            2850.974
V Predictions Mean           4107.4014
V Predictions Std            447.73697
V Predictions Max            4613.7114
V Predictions Min            2856.882
Log Pis Mean                 6.4988213
Log Pis Std                  3.8603861
Log Pis Max                  15.318744
Log Pis Min                  -1.9913836
Policy mu Mean               -0.057532918
Policy mu Std                1.5209012
Policy mu Max                2.7404342
Policy mu Min                -2.8311977
Policy log std Mean          -0.8003009
Policy log std Std           0.44853556
Policy log std Max           -0.100890845
Policy log std Min           -2.7819571
Z mean eval                  2.4733562
Z variance eval              0.023884088
total_rewards                [ 9635.2733591  10200.68980655  9719.1001436  10135.55556286
  9854.89533504  9802.73292623  9935.86926177 10385.60485991
  9919.59293346 10067.70122695]
total_rewards_mean           9965.701541547733
total_rewards_std            219.6907810285418
total_rewards_max            10385.604859906736
total_rewards_min            9635.27335910288
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               28.79322103317827
(Previous) Eval Time (s)     22.020312043838203
Sample Time (s)              16.159691034350544
Epoch Time (s)               66.97322411136702
Total Train Time (s)         27789.65536729293
Epoch                        415
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:41:25.055389 UTC | [2020_01_10_08_58_14] Iteration #415 | Epoch Duration: 67.69291567802429
2020-01-10 16:41:25.055586 UTC | [2020_01_10_08_58_14] Iteration #415 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4710732
Z variance train             0.023879414
KL Divergence                36.790203
KL Loss                      3.6790204
QF Loss                      410.57422
VF Loss                      303.00397
Policy Loss                  -4099.055
Q Predictions Mean           4112.339
Q Predictions Std            457.34875
Q Predictions Max            4616.9976
Q Predictions Min            493.59998
V Predictions Mean           4112.825
V Predictions Std            457.84888
V Predictions Max            4608.351
V Predictions Min            503.9104
Log Pis Mean                 6.7346606
Log Pis Std                  3.8434618
Log Pis Max                  18.152912
Log Pis Min                  -4.8523054
Policy mu Mean               -0.053558063
Policy mu Std                1.5482391
Policy mu Max                3.210779
Policy mu Min                -3.0194416
Policy log std Mean          -0.79653865
Policy log std Std           0.42846608
Policy log std Max           -0.08644077
Policy log std Min           -2.7491527
Z mean eval                  2.4847622
Z variance eval              0.017584339
total_rewards                [10010.38050039  9897.77181708 10058.6066916  10295.21005397
  9511.98920214  9999.82331748 10046.74304934 10135.50063718
  9899.57829166 10162.40673289]
total_rewards_mean           10001.801029374481
total_rewards_std            199.06531871447507
total_rewards_max            10295.210053965622
total_rewards_min            9511.989202137336
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               29.255852110683918
(Previous) Eval Time (s)     22.739721041172743
Sample Time (s)              15.499126065522432
Epoch Time (s)               67.4946992173791
Total Train Time (s)         27856.532587707974
Epoch                        416
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:42:31.938490 UTC | [2020_01_10_08_58_14] Iteration #416 | Epoch Duration: 66.88274097442627
2020-01-10 16:42:31.938736 UTC | [2020_01_10_08_58_14] Iteration #416 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4847457
Z variance train             0.017586928
KL Divergence                37.541656
KL Loss                      3.7541656
QF Loss                      1595.709
VF Loss                      300.648
Policy Loss                  -4077.2925
Q Predictions Mean           4089.852
Q Predictions Std            554.2001
Q Predictions Max            4615.527
Q Predictions Min            240.11864
V Predictions Mean           4065.854
V Predictions Std            550.69135
V Predictions Max            4600.558
V Predictions Min            239.98909
Log Pis Mean                 6.1383533
Log Pis Std                  3.9478056
Log Pis Max                  16.930676
Log Pis Min                  -6.464409
Policy mu Mean               0.02472432
Policy mu Std                1.4904581
Policy mu Max                3.2360225
Policy mu Min                -2.919764
Policy log std Mean          -0.8164711
Policy log std Std           0.4349633
Policy log std Max           -0.12952858
Policy log std Min           -2.7772393
Z mean eval                  2.4600062
Z variance eval              0.021085296
total_rewards                [10238.08158057  9901.86662715 10021.86824883 10344.459796
  9905.9434608  10159.79491503 10139.6559612  10077.22814598
 10365.14767574 10095.75161417]
total_rewards_mean           10124.97980254812
total_rewards_std            152.18228443911877
total_rewards_max            10365.147675736913
total_rewards_min            9901.866627152907
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               28.142908378038555
(Previous) Eval Time (s)     22.12749932706356
Sample Time (s)              16.142655591946095
Epoch Time (s)               66.41306329704821
Total Train Time (s)         27923.138405233156
Epoch                        417
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:43:38.548932 UTC | [2020_01_10_08_58_14] Iteration #417 | Epoch Duration: 66.61000847816467
2020-01-10 16:43:38.549133 UTC | [2020_01_10_08_58_14] Iteration #417 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4580479
Z variance train             0.021183353
KL Divergence                37.149117
KL Loss                      3.7149117
QF Loss                      901.57336
VF Loss                      509.9021
Policy Loss                  -4032.5676
Q Predictions Mean           4039.185
Q Predictions Std            444.63107
Q Predictions Max            4581.1064
Q Predictions Min            2841.1726
V Predictions Mean           4049.8904
V Predictions Std            444.2952
V Predictions Max            4602.65
V Predictions Min            2835.0498
Log Pis Mean                 6.0133314
Log Pis Std                  3.8652596
Log Pis Max                  16.44358
Log Pis Min                  -5.675418
Policy mu Mean               -0.07840231
Policy mu Std                1.5144004
Policy mu Max                3.0222964
Policy mu Min                -3.0047278
Policy log std Mean          -0.8088812
Policy log std Std           0.42044345
Policy log std Max           -0.20958532
Policy log std Min           -2.776891
Z mean eval                  2.4969995
Z variance eval              0.018497752
total_rewards                [10235.53298764 10120.51141176 10245.71592361  1313.22490758
 10280.11148529 10178.90158994 10288.16846428 10137.22757519
 10105.58424799  9817.97984308]
total_rewards_mean           9272.295843635582
total_rewards_std            2656.1536718231546
total_rewards_max            10288.168464276427
total_rewards_min            1313.224907577622
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               27.5328181181103
(Previous) Eval Time (s)     22.32416746672243
Sample Time (s)              16.114799581002444
Epoch Time (s)               65.97178516583517
Total Train Time (s)         27989.478803219274
Epoch                        418
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:44:44.893214 UTC | [2020_01_10_08_58_14] Iteration #418 | Epoch Duration: 66.34392642974854
2020-01-10 16:44:44.893401 UTC | [2020_01_10_08_58_14] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4969203
Z variance train             0.018478222
KL Divergence                38.0781
KL Loss                      3.8078098
QF Loss                      1914.9774
VF Loss                      402.95297
Policy Loss                  -4155.5405
Q Predictions Mean           4167.9697
Q Predictions Std            417.8375
Q Predictions Max            4663.6304
Q Predictions Min            2897.998
V Predictions Mean           4157.1753
V Predictions Std            416.17218
V Predictions Max            4653.796
V Predictions Min            2891.7878
Log Pis Mean                 7.0284243
Log Pis Std                  3.8889863
Log Pis Max                  16.219933
Log Pis Min                  -3.5988274
Policy mu Mean               0.0067946115
Policy mu Std                1.5864671
Policy mu Max                2.9374814
Policy mu Min                -3.0454242
Policy log std Mean          -0.79534596
Policy log std Std           0.4367689
Policy log std Max           0.048365474
Policy log std Min           -2.9186745
Z mean eval                  2.5161817
Z variance eval              0.010236515
total_rewards                [9458.02734773 9782.77904164 9774.58073852 9655.1247552  9722.70135154
 9856.35676568 9684.65632016 9841.70261384 9925.52259257 9757.67200256]
total_rewards_mean           9745.912352943767
total_rewards_std            123.03012446571188
total_rewards_max            9925.522592571177
total_rewards_min            9458.027347731237
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               28.017821033019572
(Previous) Eval Time (s)     22.696041143964976
Sample Time (s)              15.841327595990151
Epoch Time (s)               66.5551897729747
Total Train Time (s)         28055.51581292227
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:45:50.937182 UTC | [2020_01_10_08_58_14] Iteration #419 | Epoch Duration: 66.04360103607178
2020-01-10 16:45:50.937464 UTC | [2020_01_10_08_58_14] Iteration #419 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.5157757
Z variance train             0.01024867
KL Divergence                39.257687
KL Loss                      3.9257686
QF Loss                      313.70886
VF Loss                      152.30055
Policy Loss                  -4146.027
Q Predictions Mean           4153.232
Q Predictions Std            458.26025
Q Predictions Max            4600.5366
Q Predictions Min            232.3483
V Predictions Mean           4147.737
V Predictions Std            455.51123
V Predictions Max            4596.6704
V Predictions Min            238.57463
Log Pis Mean                 7.0338526
Log Pis Std                  3.9627955
Log Pis Max                  17.459438
Log Pis Min                  -2.9995596
Policy mu Mean               0.06312292
Policy mu Std                1.5834945
Policy mu Max                3.3361151
Policy mu Min                -3.086251
Policy log std Mean          -0.7976937
Policy log std Std           0.42300677
Policy log std Max           -0.09519768
Policy log std Min           -2.9230094
Z mean eval                  2.4765596
Z variance eval              0.0075801685
total_rewards                [10316.82021436 10032.37989987 10028.65159818 10043.92778073
  3310.35608198 10317.95662134 10097.73312002 10122.09255892
  9834.6356112  10362.34142219]
total_rewards_mean           9446.68949087914
total_rewards_std            2051.296567565948
total_rewards_max            10362.341422185964
total_rewards_min            3310.356081979391
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               29.17294819885865
(Previous) Eval Time (s)     22.184182569850236
Sample Time (s)              16.025934169068933
Epoch Time (s)               67.38306493777782
Total Train Time (s)         28123.876819285564
Epoch                        420
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:46:59.306786 UTC | [2020_01_10_08_58_14] Iteration #420 | Epoch Duration: 68.36909103393555
2020-01-10 16:46:59.307070 UTC | [2020_01_10_08_58_14] Iteration #420 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.476548
Z variance train             0.0075739576
KL Divergence                39.062065
KL Loss                      3.9062066
QF Loss                      537.69446
VF Loss                      224.41075
Policy Loss                  -4087.2854
Q Predictions Mean           4097.742
Q Predictions Std            448.37888
Q Predictions Max            4633.173
Q Predictions Min            2827.7756
V Predictions Mean           4092.0793
V Predictions Std            448.1913
V Predictions Max            4628.9087
V Predictions Min            2818.8276
Log Pis Mean                 6.8583107
Log Pis Std                  3.742046
Log Pis Max                  17.33438
Log Pis Min                  -2.8252928
Policy mu Mean               -0.064918615
Policy mu Std                1.5368214
Policy mu Max                2.8542566
Policy mu Min                -2.8523533
Policy log std Mean          -0.8183012
Policy log std Std           0.4426531
Policy log std Max           -0.064331174
Policy log std Min           -2.8450058
Z mean eval                  2.4881072
Z variance eval              0.008282108
total_rewards                [ 9805.58385803 10388.85175566  9942.81388864 10010.65967108
  9941.65166924  9907.62980253 10113.87711166 10087.57322437
  9781.71191573 10131.09769574]
total_rewards_mean           10011.145059268967
total_rewards_std            169.8691324024806
total_rewards_max            10388.851755660657
total_rewards_min            9781.711915732878
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               30.831596785224974
(Previous) Eval Time (s)     23.169920606072992
Sample Time (s)              16.621296963188797
Epoch Time (s)               70.62281435448676
Total Train Time (s)         28193.161635914817
Epoch                        421
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:48:08.592456 UTC | [2020_01_10_08_58_14] Iteration #421 | Epoch Duration: 69.28519582748413
2020-01-10 16:48:08.592595 UTC | [2020_01_10_08_58_14] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4885106
Z variance train             0.008301453
KL Divergence                38.596386
KL Loss                      3.8596387
QF Loss                      1077.3074
VF Loss                      176.38976
Policy Loss                  -4077.3113
Q Predictions Mean           4080.931
Q Predictions Std            396.07635
Q Predictions Max            4553.4375
Q Predictions Min            2764.788
V Predictions Mean           4069.23
V Predictions Std            393.1739
V Predictions Max            4543.176
V Predictions Min            2765.9587
Log Pis Mean                 6.5792203
Log Pis Std                  3.625648
Log Pis Max                  16.897404
Log Pis Min                  -3.0869164
Policy mu Mean               -0.1501871
Policy mu Std                1.5196221
Policy mu Max                2.6632655
Policy mu Min                -3.0374322
Policy log std Mean          -0.8227871
Policy log std Std           0.44268662
Policy log std Max           -0.092986256
Policy log std Min           -2.9016266
Z mean eval                  2.4797544
Z variance eval              0.013884771
total_rewards                [9297.81921514 9113.41314207 9197.70614678 9520.41049531 1370.84824367
 9560.23490145 9552.63593099 9725.53124767 9266.40925505 9534.63720547]
total_rewards_mean           8613.964578359359
total_rewards_std            2421.3151947731726
total_rewards_max            9725.531247668814
total_rewards_min            1370.848243665175
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               29.826224205084145
(Previous) Eval Time (s)     21.83204197185114
Sample Time (s)              15.745431473478675
Epoch Time (s)               67.40369765041396
Total Train Time (s)         28262.02686447231
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:49:17.468866 UTC | [2020_01_10_08_58_14] Iteration #422 | Epoch Duration: 68.87608456611633
2020-01-10 16:49:17.469206 UTC | [2020_01_10_08_58_14] Iteration #422 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4795728
Z variance train             0.013908198
KL Divergence                37.8651
KL Loss                      3.7865102
QF Loss                      402.15564
VF Loss                      140.18501
Policy Loss                  -4108.8896
Q Predictions Mean           4114.933
Q Predictions Std            414.649
Q Predictions Max            4610.9756
Q Predictions Min            2914.793
V Predictions Mean           4107.9746
V Predictions Std            413.45047
V Predictions Max            4603.7485
V Predictions Min            2900.7788
Log Pis Mean                 6.2099
Log Pis Std                  3.6764543
Log Pis Max                  15.872423
Log Pis Min                  -3.2413044
Policy mu Mean               -0.06142046
Policy mu Std                1.523961
Policy mu Max                3.1590939
Policy mu Min                -2.8608143
Policy log std Mean          -0.7978935
Policy log std Std           0.40130585
Policy log std Max           -0.098493665
Policy log std Min           -2.5356536
Z mean eval                  2.486527
Z variance eval              0.021088745
total_rewards                [ 9368.39476086  8150.7190348   9750.02990466  9664.02790684
 10005.52776451  9839.85922494  9918.95201807  9925.99492074
 10144.09013011  9612.74925265]
total_rewards_mean           9638.034491818315
total_rewards_std            537.8088442228068
total_rewards_max            10144.090130112065
total_rewards_min            8150.71903480109
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               28.516933229286224
(Previous) Eval Time (s)     23.304131811019033
Sample Time (s)              16.54726865934208
Epoch Time (s)               68.36833369964734
Total Train Time (s)         28329.302943947725
Epoch                        423
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:50:24.745395 UTC | [2020_01_10_08_58_14] Iteration #423 | Epoch Duration: 67.27595448493958
2020-01-10 16:50:24.745593 UTC | [2020_01_10_08_58_14] Iteration #423 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.487446
Z variance train             0.021095846
KL Divergence                37.16727
KL Loss                      3.716727
QF Loss                      1015.3237
VF Loss                      162.73584
Policy Loss                  -4101.1777
Q Predictions Mean           4104.2666
Q Predictions Std            542.68567
Q Predictions Max            4620.0894
Q Predictions Min            135.80194
V Predictions Mean           4101.3555
V Predictions Std            540.4125
V Predictions Max            4625.189
V Predictions Min            203.72069
Log Pis Mean                 6.683948
Log Pis Std                  3.7865312
Log Pis Max                  22.162722
Log Pis Min                  -6.024178
Policy mu Mean               -0.026449157
Policy mu Std                1.5547594
Policy mu Max                4.0976443
Policy mu Min                -3.051484
Policy log std Mean          -0.82218224
Policy log std Std           0.449032
Policy log std Max           0.12298828
Policy log std Min           -2.8992352
Z mean eval                  2.47368
Z variance eval              0.013072452
total_rewards                [10144.80198545  9932.9919197  10126.84231627 10331.79533319
  9894.52122986  9912.95065202 10259.36364821  9973.94066647
  1050.93640097  9801.61454584]
total_rewards_mean           9142.975869798121
total_rewards_std            2702.19316954483
total_rewards_max            10331.795333189588
total_rewards_min            1050.936400971533
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               27.221605523955077
(Previous) Eval Time (s)     22.211477234959602
Sample Time (s)              16.134197030216455
Epoch Time (s)               65.56727978913113
Total Train Time (s)         28395.4192168382
Epoch                        424
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:51:30.868624 UTC | [2020_01_10_08_58_14] Iteration #424 | Epoch Duration: 66.12285804748535
2020-01-10 16:51:30.868882 UTC | [2020_01_10_08_58_14] Iteration #424 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4729447
Z variance train             0.013033548
KL Divergence                37.885967
KL Loss                      3.7885969
QF Loss                      21501.152
VF Loss                      332.21182
Policy Loss                  -4084.9858
Q Predictions Mean           4101.377
Q Predictions Std            423.24417
Q Predictions Max            4598.9546
Q Predictions Min            2823.189
V Predictions Mean           4092.7402
V Predictions Std            421.85965
V Predictions Max            4588.118
V Predictions Min            2820.3035
Log Pis Mean                 6.4198465
Log Pis Std                  3.9063668
Log Pis Max                  17.37425
Log Pis Min                  -5.846837
Policy mu Mean               -0.024319516
Policy mu Std                1.5511703
Policy mu Max                2.8900063
Policy mu Min                -3.0075283
Policy log std Mean          -0.8051246
Policy log std Std           0.42893407
Policy log std Max           -0.11834207
Policy log std Min           -2.9836206
Z mean eval                  2.4840713
Z variance eval              0.012878573
total_rewards                [ 9971.38331083 10137.32486832 10257.79148954 10192.31622144
 10169.07878406 10255.08709534 10002.49623064 10045.41282654
 10207.0873404  10151.75863178]
total_rewards_mean           10138.973679889667
total_rewards_std            95.7202406653978
total_rewards_max            10257.791489537067
total_rewards_min            9971.383310830473
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               27.9785663257353
(Previous) Eval Time (s)     22.766754196956754
Sample Time (s)              16.454868220258504
Epoch Time (s)               67.20018874295056
Total Train Time (s)         28462.09189623734
Epoch                        425
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:52:37.548490 UTC | [2020_01_10_08_58_14] Iteration #425 | Epoch Duration: 66.67940354347229
2020-01-10 16:52:37.548748 UTC | [2020_01_10_08_58_14] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4847906
Z variance train             0.012866354
KL Divergence                37.214188
KL Loss                      3.7214189
QF Loss                      439.39557
VF Loss                      226.24574
Policy Loss                  -4122.823
Q Predictions Mean           4131.1646
Q Predictions Std            404.77518
Q Predictions Max            4598.962
Q Predictions Min            2862.5283
V Predictions Mean           4112.4565
V Predictions Std            404.1676
V Predictions Max            4587.6753
V Predictions Min            2841.4614
Log Pis Mean                 6.415673
Log Pis Std                  3.4329731
Log Pis Max                  15.76613
Log Pis Min                  -1.3088067
Policy mu Mean               0.0069574616
Policy mu Std                1.5388149
Policy mu Max                3.0113423
Policy mu Min                -2.560683
Policy log std Mean          -0.8118538
Policy log std Std           0.42184666
Policy log std Max           -0.031041265
Policy log std Min           -2.9298205
Z mean eval                  2.4691024
Z variance eval              0.046857446
total_rewards                [10243.72370681 10273.09124523 10205.40960678 10017.75599397
 10150.02114489 10032.69580222 10193.18693882 10258.37925577
 10025.26576921  9881.55650455]
total_rewards_mean           10128.108596824983
total_rewards_std            124.37601971662707
total_rewards_max            10273.091245229392
total_rewards_min            9881.556504548931
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               27.111744317691773
(Previous) Eval Time (s)     22.24567058775574
Sample Time (s)              16.906407758127898
Epoch Time (s)               66.26382266357541
Total Train Time (s)         28528.54432115238
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:53:44.002904 UTC | [2020_01_10_08_58_14] Iteration #426 | Epoch Duration: 66.45396971702576
2020-01-10 16:53:44.003053 UTC | [2020_01_10_08_58_14] Iteration #426 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.470174
Z variance train             0.04674243
KL Divergence                35.987335
KL Loss                      3.5987337
QF Loss                      574.5058
VF Loss                      206.40579
Policy Loss                  -4008.9207
Q Predictions Mean           4016.2341
Q Predictions Std            426.8697
Q Predictions Max            4558.573
Q Predictions Min            2737.219
V Predictions Mean           4002.3423
V Predictions Std            425.62207
V Predictions Max            4544.9517
V Predictions Min            2733.7031
Log Pis Mean                 6.4086103
Log Pis Std                  3.717536
Log Pis Max                  19.09475
Log Pis Min                  -3.9860702
Policy mu Mean               -0.03938585
Policy mu Std                1.5018805
Policy mu Max                2.97363
Policy mu Min                -2.9031074
Policy log std Mean          -0.82640177
Policy log std Std           0.44570503
Policy log std Max           -0.15339339
Policy log std Min           -2.86942
Z mean eval                  2.4621894
Z variance eval              0.032622624
total_rewards                [ 9878.9997283  10308.32106651 10391.29993906 10133.24281095
 10303.89263812  9970.63503118 10313.57148863  4618.16116635
 10326.49948967 10448.56244253]
total_rewards_mean           9669.318580129879
total_rewards_std            1692.6490997436163
total_rewards_max            10448.562442525174
total_rewards_min            4618.161166354166
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               29.418350067920983
(Previous) Eval Time (s)     22.43555544130504
Sample Time (s)              16.065160727594048
Epoch Time (s)               67.91906623682007
Total Train Time (s)         28596.615289978217
Epoch                        427
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:54:52.076970 UTC | [2020_01_10_08_58_14] Iteration #427 | Epoch Duration: 68.07380104064941
2020-01-10 16:54:52.077159 UTC | [2020_01_10_08_58_14] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.460713
Z variance train             0.032574777
KL Divergence                35.274628
KL Loss                      3.5274627
QF Loss                      363.29413
VF Loss                      416.75305
Policy Loss                  -4005.4824
Q Predictions Mean           4016.4722
Q Predictions Std            507.2453
Q Predictions Max            4553.024
Q Predictions Min            446.91272
V Predictions Mean           4007.5505
V Predictions Std            511.60147
V Predictions Max            4536.799
V Predictions Min            396.72275
Log Pis Mean                 6.7177286
Log Pis Std                  3.7074397
Log Pis Max                  20.184282
Log Pis Min                  -3.0441976
Policy mu Mean               0.0075274264
Policy mu Std                1.5523295
Policy mu Max                3.792705
Policy mu Min                -3.0309443
Policy log std Mean          -0.8383166
Policy log std Std           0.45862845
Policy log std Max           -0.05530864
Policy log std Min           -2.7565484
Z mean eval                  2.44578
Z variance eval              0.02440027
total_rewards                [9535.24332969 9639.75423826 9684.31424216 9420.00936099 9148.1443049
 9588.75263835 9382.08383809 9727.52074846 9725.47829294 9684.67017125]
total_rewards_mean           9553.597116507432
total_rewards_std            177.4006703921211
total_rewards_max            9727.52074845879
total_rewards_min            9148.144304898837
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               30.30652569187805
(Previous) Eval Time (s)     22.59003612678498
Sample Time (s)              16.18359879264608
Epoch Time (s)               69.08016061130911
Total Train Time (s)         28664.96344235493
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:56:00.428458 UTC | [2020_01_10_08_58_14] Iteration #428 | Epoch Duration: 68.35116839408875
2020-01-10 16:56:00.428606 UTC | [2020_01_10_08_58_14] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4477224
Z variance train             0.024506027
KL Divergence                35.611935
KL Loss                      3.5611935
QF Loss                      1328.3489
VF Loss                      475.0952
Policy Loss                  -4022.255
Q Predictions Mean           4022.9001
Q Predictions Std            544.30756
Q Predictions Max            4597.2095
Q Predictions Min            267.45987
V Predictions Mean           4008.8784
V Predictions Std            549.0974
V Predictions Max            4572.5205
V Predictions Min            133.5317
Log Pis Mean                 6.635097
Log Pis Std                  4.0240526
Log Pis Max                  16.78297
Log Pis Min                  -7.9790974
Policy mu Mean               0.00031863464
Policy mu Std                1.5540192
Policy mu Max                2.867689
Policy mu Min                -3.1853282
Policy log std Mean          -0.7950368
Policy log std Std           0.4432903
Policy log std Max           0.07274616
Policy log std Min           -2.8775253
Z mean eval                  2.467716
Z variance eval              0.059486836
total_rewards                [9202.9310417  9265.54716421 9852.14853118 9332.69841257 9429.4083567
 9303.09765343 9563.23757036 9183.95477102 9085.23498794 9806.60775769]
total_rewards_mean           9402.486624679297
total_rewards_std            247.7505897599008
total_rewards_max            9852.148531184366
total_rewards_min            9085.234987943468
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               28.817539660725743
(Previous) Eval Time (s)     21.86076747532934
Sample Time (s)              15.957231207285076
Epoch Time (s)               66.63553834334016
Total Train Time (s)         28731.682440104894
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:57:07.154223 UTC | [2020_01_10_08_58_14] Iteration #429 | Epoch Duration: 66.72543382644653
2020-01-10 16:57:07.154509 UTC | [2020_01_10_08_58_14] Iteration #429 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4666848
Z variance train             0.059933234
KL Divergence                34.516598
KL Loss                      3.45166
QF Loss                      785.38025
VF Loss                      306.47363
Policy Loss                  -3991.5178
Q Predictions Mean           3993.4824
Q Predictions Std            448.09128
Q Predictions Max            4536.5435
Q Predictions Min            2799.0283
V Predictions Mean           3998.6377
V Predictions Std            451.11966
V Predictions Max            4547.6714
V Predictions Min            2808.0918
Log Pis Mean                 6.428289
Log Pis Std                  3.5269177
Log Pis Max                  14.984749
Log Pis Min                  -4.0280538
Policy mu Mean               0.15542011
Policy mu Std                1.5161135
Policy mu Max                2.821783
Policy mu Min                -2.5817168
Policy log std Mean          -0.81917
Policy log std Std           0.44782406
Policy log std Max           -0.13499582
Policy log std Min           -2.8668735
Z mean eval                  2.4690318
Z variance eval              0.05894479
total_rewards                [10019.40704508 10193.16148484  9777.10021037 10255.23552135
 10141.36481049 10144.01883304  9920.34899789 10133.84542691
 10075.72043604 10123.11983071]
total_rewards_mean           10078.332259671028
total_rewards_std            133.05429066786175
total_rewards_max            10255.235521348177
total_rewards_min            9777.100210370847
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               30.752344174776226
(Previous) Eval Time (s)     21.950369928963482
Sample Time (s)              15.5137402638793
Epoch Time (s)               68.21645436761901
Total Train Time (s)         28800.292021608446
Epoch                        430
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:58:15.771263 UTC | [2020_01_10_08_58_14] Iteration #430 | Epoch Duration: 68.61651515960693
2020-01-10 16:58:15.771567 UTC | [2020_01_10_08_58_14] Iteration #430 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4694338
Z variance train             0.059072863
KL Divergence                33.880672
KL Loss                      3.3880672
QF Loss                      1095.2029
VF Loss                      156.26271
Policy Loss                  -4178.1123
Q Predictions Mean           4188.2627
Q Predictions Std            443.39554
Q Predictions Max            4708.697
Q Predictions Min            2912.3271
V Predictions Mean           4171.7197
V Predictions Std            440.92044
V Predictions Max            4698.575
V Predictions Min            2914.0872
Log Pis Mean                 6.2543817
Log Pis Std                  3.8295248
Log Pis Max                  15.03223
Log Pis Min                  -3.2167647
Policy mu Mean               -0.11447123
Policy mu Std                1.5122017
Policy mu Max                2.893044
Policy mu Min                -3.524846
Policy log std Mean          -0.8056412
Policy log std Std           0.43060958
Policy log std Max           -0.12876457
Policy log std Min           -2.8609283
Z mean eval                  2.4416604
Z variance eval              0.1244127
total_rewards                [10027.4121401  10153.35529506 10372.06760703 10205.81166737
 10306.68558597 10209.35226939 10271.98416427  3591.28887324
  9844.92518103 10371.7068368 ]
total_rewards_mean           9535.45896202613
total_rewards_std            1987.2778000124456
total_rewards_max            10372.067607031504
total_rewards_min            3591.288873235913
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               29.166179197840393
(Previous) Eval Time (s)     22.350182810332626
Sample Time (s)              15.707105078268796
Epoch Time (s)               67.22346708644181
Total Train Time (s)         28868.023493968416
Epoch                        431
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 16:59:23.505868 UTC | [2020_01_10_08_58_14] Iteration #431 | Epoch Duration: 67.73409295082092
2020-01-10 16:59:23.506053 UTC | [2020_01_10_08_58_14] Iteration #431 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.441979
Z variance train             0.123923585
KL Divergence                32.638103
KL Loss                      3.2638104
QF Loss                      611.04224
VF Loss                      602.41815
Policy Loss                  -4167.617
Q Predictions Mean           4180.2495
Q Predictions Std            429.8747
Q Predictions Max            4695.5474
Q Predictions Min            2913.9465
V Predictions Mean           4174.3926
V Predictions Std            431.7786
V Predictions Max            4680.255
V Predictions Min            2913.6462
Log Pis Mean                 6.2650204
Log Pis Std                  3.8130233
Log Pis Max                  16.900581
Log Pis Min                  -8.803295
Policy mu Mean               0.0022118564
Policy mu Std                1.5073384
Policy mu Max                2.8752558
Policy mu Min                -2.6283998
Policy log std Mean          -0.8118367
Policy log std Std           0.44167382
Policy log std Max           -0.09363392
Policy log std Min           -2.6983235
Z mean eval                  2.480145
Z variance eval              0.07147607
total_rewards                [ 9579.03205923  9578.9627272   4842.79856863  9825.2217635
  9854.45061809  9970.11077792  9286.57807472  4406.33766393
 10191.91455439  4555.89554808]
total_rewards_mean           8209.13023556832
total_rewards_std            2374.9700406034285
total_rewards_max            10191.914554393537
total_rewards_min            4406.3376639327735
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               29.476422318723053
(Previous) Eval Time (s)     22.86056276038289
Sample Time (s)              16.44554139766842
Epoch Time (s)               68.78252647677436
Total Train Time (s)         28937.547588598914
Epoch                        432
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:00:33.037594 UTC | [2020_01_10_08_58_14] Iteration #432 | Epoch Duration: 69.53136587142944
2020-01-10 17:00:33.037898 UTC | [2020_01_10_08_58_14] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.480537
Z variance train             0.07146746
KL Divergence                34.294548
KL Loss                      3.4294548
QF Loss                      563.72455
VF Loss                      104.66911
Policy Loss                  -4026.8638
Q Predictions Mean           4031.8464
Q Predictions Std            491.29324
Q Predictions Max            4552.712
Q Predictions Min            518.0948
V Predictions Mean           4025.2224
V Predictions Std            489.61356
V Predictions Max            4545.391
V Predictions Min            521.64734
Log Pis Mean                 6.125785
Log Pis Std                  3.876065
Log Pis Max                  25.410202
Log Pis Min                  -6.7687745
Policy mu Mean               -0.021670325
Policy mu Std                1.5188663
Policy mu Max                3.6556003
Policy mu Min                -4.00586
Policy log std Mean          -0.79617923
Policy log std Std           0.40842202
Policy log std Max           -0.0844537
Policy log std Min           -2.6910439
Z mean eval                  2.4914422
Z variance eval              0.040703855
total_rewards                [ 9434.19473675 10179.32706968 10030.03129676  9896.05517444
  9863.68183424  9588.13948869  9786.47976178  9924.42477551
 10091.64490088 10010.05509627]
total_rewards_mean           9880.403413500335
total_rewards_std            216.559665441176
total_rewards_max            10179.327069679355
total_rewards_min            9434.194736750329
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               29.682548871729523
(Previous) Eval Time (s)     23.609086624812335
Sample Time (s)              16.014816742856055
Epoch Time (s)               69.30645223939791
Total Train Time (s)         29006.43955380842
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:01:41.932549 UTC | [2020_01_10_08_58_14] Iteration #433 | Epoch Duration: 68.89445447921753
2020-01-10 17:01:41.932717 UTC | [2020_01_10_08_58_14] Iteration #433 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4915748
Z variance train             0.040711056
KL Divergence                34.877792
KL Loss                      3.4877794
QF Loss                      429.3777
VF Loss                      340.3479
Policy Loss                  -3964.707
Q Predictions Mean           3969.3257
Q Predictions Std            417.82993
Q Predictions Max            4463.1885
Q Predictions Min            2224.8293
V Predictions Mean           3956.9712
V Predictions Std            414.34164
V Predictions Max            4459.6416
V Predictions Min            2377.7273
Log Pis Mean                 6.591055
Log Pis Std                  3.8587153
Log Pis Max                  14.535121
Log Pis Min                  -5.10439
Policy mu Mean               -0.03708226
Policy mu Std                1.5460992
Policy mu Max                2.9046361
Policy mu Min                -2.8516276
Policy log std Mean          -0.8133213
Policy log std Std           0.42318946
Policy log std Max           -0.14078093
Policy log std Min           -2.7493477
Z mean eval                  2.4945502
Z variance eval              0.039231937
total_rewards                [ 9981.06024139 10211.37344854 10331.02813317 10328.66844971
 10143.14404377 10307.43208204 10066.91296037 10183.50368009
 10092.57399704 10320.27133695]
total_rewards_mean           10196.596837306377
total_rewards_std            118.50577243382853
total_rewards_max            10331.028133165952
total_rewards_min            9981.060241387719
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               29.373557501938194
(Previous) Eval Time (s)     23.196809988003224
Sample Time (s)              16.060743416193873
Epoch Time (s)               68.63111090613529
Total Train Time (s)         29074.53616816085
Epoch                        434
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:02:50.031721 UTC | [2020_01_10_08_58_14] Iteration #434 | Epoch Duration: 68.09887528419495
2020-01-10 17:02:50.031945 UTC | [2020_01_10_08_58_14] Iteration #434 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4944746
Z variance train             0.039266855
KL Divergence                35.60061
KL Loss                      3.560061
QF Loss                      1022.9245
VF Loss                      149.50458
Policy Loss                  -4214.4097
Q Predictions Mean           4223.3706
Q Predictions Std            397.23813
Q Predictions Max            4708.0137
Q Predictions Min            2965.4214
V Predictions Mean           4211.005
V Predictions Std            395.95496
V Predictions Max            4693.8237
V Predictions Min            2960.6235
Log Pis Mean                 7.0335827
Log Pis Std                  3.8409653
Log Pis Max                  16.816486
Log Pis Min                  -4.3832808
Policy mu Mean               -0.007955033
Policy mu Std                1.5737729
Policy mu Max                3.236191
Policy mu Min                -2.9559147
Policy log std Mean          -0.809551
Policy log std Std           0.4375484
Policy log std Max           -0.09371334
Policy log std Min           -2.6893282
Z mean eval                  2.4964905
Z variance eval              0.060528427
total_rewards                [10184.37901847 10436.36274954 10194.343303    9984.64810478
 10021.91438541 10078.58988503 10430.81524041 10084.776829
 10340.57852324 10191.72187664]
total_rewards_mean           10194.812991552277
total_rewards_std            153.3259781870134
total_rewards_max            10436.362749542766
total_rewards_min            9984.648104778364
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               30.096598924137652
(Previous) Eval Time (s)     22.664285342674702
Sample Time (s)              16.003560137934983
Epoch Time (s)               68.76444440474734
Total Train Time (s)         29143.32860526815
Epoch                        435
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:03:58.827734 UTC | [2020_01_10_08_58_14] Iteration #435 | Epoch Duration: 68.79566287994385
2020-01-10 17:03:58.827921 UTC | [2020_01_10_08_58_14] Iteration #435 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4974558
Z variance train             0.06055703
KL Divergence                34.405445
KL Loss                      3.4405446
QF Loss                      712.37573
VF Loss                      158.07771
Policy Loss                  -4119.9126
Q Predictions Mean           4131.5234
Q Predictions Std            481.44763
Q Predictions Max            4660.6636
Q Predictions Min            362.6339
V Predictions Mean           4113.86
V Predictions Std            480.68198
V Predictions Max            4630.1816
V Predictions Min            333.40543
Log Pis Mean                 6.71758
Log Pis Std                  3.9492893
Log Pis Max                  18.18028
Log Pis Min                  -3.5070434
Policy mu Mean               -0.07951891
Policy mu Std                1.5445795
Policy mu Max                2.8024933
Policy mu Min                -3.4935684
Policy log std Mean          -0.82959944
Policy log std Std           0.4503502
Policy log std Max           0.03802097
Policy log std Min           -2.8248928
Z mean eval                  2.4557395
Z variance eval              0.09410675
total_rewards                [ 9943.26343851 10282.79431778 10257.71148637  9864.35152374
 10187.4748996   9174.75661275 10049.12610268 10300.90454852
  9747.57369522  9880.12603829]
total_rewards_mean           9968.80826634506
total_rewards_std            323.34151510753424
total_rewards_max            10300.90454851807
total_rewards_min            9174.756612747557
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               29.588908192701638
(Previous) Eval Time (s)     22.695207996759564
Sample Time (s)              15.622652345336974
Epoch Time (s)               67.90676853479818
Total Train Time (s)         29211.494432989042
Epoch                        436
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:05:06.996656 UTC | [2020_01_10_08_58_14] Iteration #436 | Epoch Duration: 68.16860628128052
2020-01-10 17:05:06.996877 UTC | [2020_01_10_08_58_14] Iteration #436 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.455901
Z variance train             0.094226636
KL Divergence                32.86408
KL Loss                      3.286408
QF Loss                      384.74426
VF Loss                      260.82193
Policy Loss                  -4006.3071
Q Predictions Mean           4016.4224
Q Predictions Std            454.43384
Q Predictions Max            4537.344
Q Predictions Min            805.4824
V Predictions Mean           4000.0945
V Predictions Std            450.94592
V Predictions Max            4508.275
V Predictions Min            883.22906
Log Pis Mean                 7.0122147
Log Pis Std                  4.061731
Log Pis Max                  16.042484
Log Pis Min                  -4.485106
Policy mu Mean               -0.07860058
Policy mu Std                1.578684
Policy mu Max                3.5368724
Policy mu Min                -2.7663434
Policy log std Mean          -0.8043761
Policy log std Std           0.426664
Policy log std Max           -0.08342588
Policy log std Min           -2.745629
Z mean eval                  2.4698684
Z variance eval              0.09032832
total_rewards                [10139.35380763 10022.12843876  9913.7167773  10233.56416947
 10106.74458895 10108.64168621 10167.58583215 10246.07619475
 10046.42907785 10167.14969514]
total_rewards_mean           10115.139026821085
total_rewards_std            95.53366954953243
total_rewards_max            10246.076194747844
total_rewards_min            9913.716777302347
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               28.618209162727
(Previous) Eval Time (s)     22.95674698986113
Sample Time (s)              15.880008790176362
Epoch Time (s)               67.45496494276449
Total Train Time (s)         29278.18415564811
Epoch                        437
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:06:13.691316 UTC | [2020_01_10_08_58_14] Iteration #437 | Epoch Duration: 66.69428706169128
2020-01-10 17:06:13.691530 UTC | [2020_01_10_08_58_14] Iteration #437 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4699981
Z variance train             0.09048166
KL Divergence                32.744038
KL Loss                      3.2744038
QF Loss                      643.0524
VF Loss                      151.0958
Policy Loss                  -4123.149
Q Predictions Mean           4133.0654
Q Predictions Std            425.65607
Q Predictions Max            4633.4375
Q Predictions Min            2832.0576
V Predictions Mean           4129.8965
V Predictions Std            424.37033
V Predictions Max            4638.5205
V Predictions Min            2834.6733
Log Pis Mean                 6.9743085
Log Pis Std                  3.6370738
Log Pis Max                  15.031807
Log Pis Min                  -2.206153
Policy mu Mean               -0.02304355
Policy mu Std                1.5612715
Policy mu Max                3.2586112
Policy mu Min                -2.7831447
Policy log std Mean          -0.83835775
Policy log std Std           0.45701924
Policy log std Max           -0.10579252
Policy log std Min           -2.9253962
Z mean eval                  2.4711325
Z variance eval              0.08566798
total_rewards                [ 9794.08891856 10179.17997989  9947.76628687 10036.8712988
  9853.44601479 10019.31725618 10161.93903073 10149.42729617
  9964.45432377  9975.22584801]
total_rewards_mean           10008.171625377474
total_rewards_std            122.55863278074438
total_rewards_max            10179.17997989223
total_rewards_min            9794.088918561156
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               29.24427886493504
(Previous) Eval Time (s)     22.19577152794227
Sample Time (s)              16.1871177572757
Epoch Time (s)               67.62716815015301
Total Train Time (s)         29345.884588501416
Epoch                        438
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:07:21.399252 UTC | [2020_01_10_08_58_14] Iteration #438 | Epoch Duration: 67.7075412273407
2020-01-10 17:07:21.399496 UTC | [2020_01_10_08_58_14] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4721699
Z variance train             0.08572673
KL Divergence                33.51036
KL Loss                      3.351036
QF Loss                      441.74133
VF Loss                      317.04526
Policy Loss                  -4133.8247
Q Predictions Mean           4137.7827
Q Predictions Std            451.1907
Q Predictions Max            4697.263
Q Predictions Min            2634.76
V Predictions Mean           4118.9146
V Predictions Std            449.16214
V Predictions Max            4663.863
V Predictions Min            2640.7473
Log Pis Mean                 6.8149004
Log Pis Std                  3.737602
Log Pis Max                  17.245182
Log Pis Min                  -5.3842974
Policy mu Mean               -0.0668833
Policy mu Std                1.5582943
Policy mu Max                3.3708227
Policy mu Min                -2.7522423
Policy log std Mean          -0.80491966
Policy log std Std           0.40850878
Policy log std Max           -0.11154264
Policy log std Min           -2.878232
Z mean eval                  2.438284
Z variance eval              0.059365977
total_rewards                [9564.8459323  9833.58018044 9931.20560943 9981.98091516 9586.12603847
 9799.36529449 9721.91015101 9761.49471747 9625.99441907 9928.27473307]
total_rewards_mean           9773.477799091062
total_rewards_std            141.34293862958785
total_rewards_max            9981.980915161119
total_rewards_min            9564.845932295837
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               27.465139663778245
(Previous) Eval Time (s)     22.275816906243563
Sample Time (s)              16.14533287798986
Epoch Time (s)               65.88628944801167
Total Train Time (s)         29411.577994562685
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:08:27.098540 UTC | [2020_01_10_08_58_14] Iteration #439 | Epoch Duration: 65.69882440567017
2020-01-10 17:08:27.098817 UTC | [2020_01_10_08_58_14] Iteration #439 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4368525
Z variance train             0.05939423
KL Divergence                33.76168
KL Loss                      3.376168
QF Loss                      393.4626
VF Loss                      155.8602
Policy Loss                  -4029.0923
Q Predictions Mean           4040.7188
Q Predictions Std            428.53702
Q Predictions Max            4601.4795
Q Predictions Min            2742.3562
V Predictions Mean           4031.5625
V Predictions Std            428.48483
V Predictions Max            4614.6455
V Predictions Min            2752.3726
Log Pis Mean                 6.929262
Log Pis Std                  3.8612058
Log Pis Max                  15.275995
Log Pis Min                  -6.531829
Policy mu Mean               -0.14253774
Policy mu Std                1.559994
Policy mu Max                2.7511451
Policy mu Min                -2.8966095
Policy log std Mean          -0.8151632
Policy log std Std           0.43815973
Policy log std Max           -0.07385039
Policy log std Min           -2.790351
Z mean eval                  2.4500823
Z variance eval              0.038591016
total_rewards                [ 9812.19818818 10027.92486574 10121.79085924  9878.43907169
  9928.01151702 10077.00177653  9885.59927339  9965.41200757
 10228.47208819  9918.14457355]
total_rewards_mean           9984.299422109427
total_rewards_std            121.44529078348586
total_rewards_max            10228.472088187389
total_rewards_min            9812.198188183458
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               28.88203882938251
(Previous) Eval Time (s)     22.08808061806485
Sample Time (s)              16.24749007122591
Epoch Time (s)               67.21760951867327
Total Train Time (s)         29479.09682137845
Epoch                        440
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:09:34.620871 UTC | [2020_01_10_08_58_14] Iteration #440 | Epoch Duration: 67.52186131477356
2020-01-10 17:09:34.621040 UTC | [2020_01_10_08_58_14] Iteration #440 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4517722
Z variance train             0.03860001
KL Divergence                34.848385
KL Loss                      3.4848385
QF Loss                      485.46933
VF Loss                      317.35303
Policy Loss                  -4240.3384
Q Predictions Mean           4245.337
Q Predictions Std            374.23068
Q Predictions Max            4753.979
Q Predictions Min            2912.443
V Predictions Mean           4229.2295
V Predictions Std            372.10165
V Predictions Max            4731.057
V Predictions Min            2900.84
Log Pis Mean                 6.848524
Log Pis Std                  3.9989934
Log Pis Max                  16.223112
Log Pis Min                  -6.645199
Policy mu Mean               -0.0011559079
Policy mu Std                1.5614176
Policy mu Max                2.9664855
Policy mu Min                -2.9024546
Policy log std Mean          -0.8110072
Policy log std Std           0.4267252
Policy log std Max           -0.07183802
Policy log std Min           -2.8086765
Z mean eval                  2.4693892
Z variance eval              0.02907246
total_rewards                [ 9907.35306639 10293.08889335  9815.23731188 10112.32286218
  9844.20511859 10092.8276835  10095.41709831  9866.54888226
 10111.80661705 10012.33045759]
total_rewards_mean           10015.11379911114
total_rewards_std            145.3992324389653
total_rewards_max            10293.088893347383
total_rewards_min            9815.237311879608
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               28.26428709598258
(Previous) Eval Time (s)     22.392049726098776
Sample Time (s)              15.658394978847355
Epoch Time (s)               66.31473180092871
Total Train Time (s)         29545.87099692365
Epoch                        441
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:10:41.398481 UTC | [2020_01_10_08_58_14] Iteration #441 | Epoch Duration: 66.77730965614319
2020-01-10 17:10:41.398634 UTC | [2020_01_10_08_58_14] Iteration #441 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4679918
Z variance train             0.029043084
KL Divergence                35.790188
KL Loss                      3.5790188
QF Loss                      608.8685
VF Loss                      505.2688
Policy Loss                  -3978.384
Q Predictions Mean           3984.4487
Q Predictions Std            558.5873
Q Predictions Max            4544.4155
Q Predictions Min            323.0173
V Predictions Mean           3983.8215
V Predictions Std            557.31244
V Predictions Max            4547.5884
V Predictions Min            298.97122
Log Pis Mean                 6.6501365
Log Pis Std                  4.189146
Log Pis Max                  16.108055
Log Pis Min                  -4.19906
Policy mu Mean               0.048761133
Policy mu Std                1.5364376
Policy mu Max                2.9728456
Policy mu Min                -3.3794696
Policy log std Mean          -0.8051588
Policy log std Std           0.44684216
Policy log std Max           0.07534385
Policy log std Min           -2.9389734
Z mean eval                  2.451222
Z variance eval              0.02285814
total_rewards                [10034.1898235  10316.19824815 10214.01344005 10049.45043914
  9891.6121234  10054.66197784 10268.35942192 10052.03522705
 10073.40138747 10303.83870279]
total_rewards_mean           10125.776079130039
total_rewards_std            133.55417724692586
total_rewards_max            10316.198248151157
total_rewards_min            9891.612123398754
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               30.484638675116003
(Previous) Eval Time (s)     22.85433743800968
Sample Time (s)              15.19663937902078
Epoch Time (s)               68.53561549214646
Total Train Time (s)         29613.543607899453
Epoch                        442
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:11:49.075047 UTC | [2020_01_10_08_58_14] Iteration #442 | Epoch Duration: 67.67628312110901
2020-01-10 17:11:49.075234 UTC | [2020_01_10_08_58_14] Iteration #442 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4529507
Z variance train             0.022885282
KL Divergence                35.945004
KL Loss                      3.5945003
QF Loss                      542.655
VF Loss                      192.15387
Policy Loss                  -4039.489
Q Predictions Mean           4047.8242
Q Predictions Std            486.86096
Q Predictions Max            4585.6255
Q Predictions Min            332.83878
V Predictions Mean           4033.0928
V Predictions Std            484.0231
V Predictions Max            4552.9863
V Predictions Min            333.70782
Log Pis Mean                 6.630585
Log Pis Std                  3.7354672
Log Pis Max                  14.718055
Log Pis Min                  -8.033959
Policy mu Mean               -0.065435514
Policy mu Std                1.5431398
Policy mu Max                3.070417
Policy mu Min                -2.7852745
Policy log std Mean          -0.8277001
Policy log std Std           0.4273038
Policy log std Max           -0.16668573
Policy log std Min           -2.6368742
Z mean eval                  2.486106
Z variance eval              0.028015401
total_rewards                [10241.77254082 10167.20443982 10347.53679323 10040.11462905
 10130.82036737  9798.87401798 10113.40798662 10220.89189447
 10148.83762909 10169.89227795]
total_rewards_mean           10137.9352576393
total_rewards_std            137.3962135119345
total_rewards_max            10347.536793229894
total_rewards_min            9798.874017978838
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               28.294854165054858
(Previous) Eval Time (s)     21.994726587086916
Sample Time (s)              15.594558430835605
Epoch Time (s)               65.88413918297738
Total Train Time (s)         29679.918941479642
Epoch                        443
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:12:55.453910 UTC | [2020_01_10_08_58_14] Iteration #443 | Epoch Duration: 66.37853670120239
2020-01-10 17:12:55.454059 UTC | [2020_01_10_08_58_14] Iteration #443 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4872894
Z variance train             0.02796567
KL Divergence                36.08626
KL Loss                      3.6086261
QF Loss                      1597.4646
VF Loss                      596.81396
Policy Loss                  -4030.015
Q Predictions Mean           4038.8696
Q Predictions Std            425.86728
Q Predictions Max            4554.3623
Q Predictions Min            2768.385
V Predictions Mean           4023.645
V Predictions Std            422.5983
V Predictions Max            4540.4644
V Predictions Min            2777.175
Log Pis Mean                 6.7007
Log Pis Std                  3.6962569
Log Pis Max                  16.169264
Log Pis Min                  -2.0871825
Policy mu Mean               -0.1301834
Policy mu Std                1.5393268
Policy mu Max                2.9777992
Policy mu Min                -2.794161
Policy log std Mean          -0.8269064
Policy log std Std           0.44093114
Policy log std Max           -0.038029015
Policy log std Min           -2.7713318
Z mean eval                  2.464282
Z variance eval              0.029899906
total_rewards                [10020.35025832 10030.93827505 10355.97012056 10075.93818552
  9926.91287572 10289.41240445  9976.4453561  10000.25055416
  9913.08268757 10142.25165727]
total_rewards_mean           10073.15523747113
total_rewards_std            140.6350104843774
total_rewards_max            10355.970120557571
total_rewards_min            9913.082687570515
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               28.085570977069438
(Previous) Eval Time (s)     22.488836276810616
Sample Time (s)              16.503618265502155
Epoch Time (s)               67.07802551938221
Total Train Time (s)         29747.196317247115
Epoch                        444
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:14:02.735437 UTC | [2020_01_10_08_58_14] Iteration #444 | Epoch Duration: 67.28125166893005
2020-01-10 17:14:02.735630 UTC | [2020_01_10_08_58_14] Iteration #444 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.464488
Z variance train             0.029871028
KL Divergence                36.299175
KL Loss                      3.6299176
QF Loss                      1289.1155
VF Loss                      184.21478
Policy Loss                  -4140.9893
Q Predictions Mean           4151.8154
Q Predictions Std            471.8833
Q Predictions Max            4684.7817
Q Predictions Min            905.3805
V Predictions Mean           4151.152
V Predictions Std            473.24838
V Predictions Max            4702.387
V Predictions Min            868.1405
Log Pis Mean                 6.175109
Log Pis Std                  3.7196262
Log Pis Max                  17.34963
Log Pis Min                  -7.234564
Policy mu Mean               -0.072048835
Policy mu Std                1.5094838
Policy mu Max                3.223083
Policy mu Min                -2.9867988
Policy log std Mean          -0.8135631
Policy log std Std           0.4128047
Policy log std Max           -0.09847689
Policy log std Min           -2.6661339
Z mean eval                  2.4734087
Z variance eval              0.021501174
total_rewards                [10030.655558   10090.74189178 10327.54131986  9639.36430114
 10197.94917423 10031.83894306 10262.6001347  10104.87992128
  9814.80267749 10175.27977993]
total_rewards_mean           10067.565370147882
total_rewards_std            196.47945369879523
total_rewards_max            10327.541319857666
total_rewards_min            9639.36430114083
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               27.365001949016005
(Previous) Eval Time (s)     22.691736383829266
Sample Time (s)              15.862846658565104
Epoch Time (s)               65.91958499141037
Total Train Time (s)         29813.817650488578
Epoch                        445
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:15:09.361962 UTC | [2020_01_10_08_58_14] Iteration #445 | Epoch Duration: 66.62617087364197
2020-01-10 17:15:09.362186 UTC | [2020_01_10_08_58_14] Iteration #445 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.475245
Z variance train             0.021552358
KL Divergence                36.576496
KL Loss                      3.6576498
QF Loss                      1089.6151
VF Loss                      151.70285
Policy Loss                  -4174.528
Q Predictions Mean           4186.627
Q Predictions Std            444.64178
Q Predictions Max            4697.829
Q Predictions Min            558.0754
V Predictions Mean           4169.2407
V Predictions Std            441.6629
V Predictions Max            4676.6235
V Predictions Min            580.94464
Log Pis Mean                 6.3906984
Log Pis Std                  4.0676184
Log Pis Max                  14.86995
Log Pis Min                  -8.228452
Policy mu Mean               -0.012795909
Policy mu Std                1.5214827
Policy mu Max                3.4939039
Policy mu Min                -3.226189
Policy log std Mean          -0.8093257
Policy log std Std           0.4321089
Policy log std Max           -0.026031494
Policy log std Min           -2.7072957
Z mean eval                  2.4787655
Z variance eval              0.01750863
total_rewards                [10040.2829687  10381.93824111 10190.55022738 10346.14491432
 10305.47304444 10218.67041377 10569.22512834 10225.31992167
 10561.72923217 10118.44140403]
total_rewards_mean           10295.777549592147
total_rewards_std            165.60995774782887
total_rewards_max            10569.225128336004
total_rewards_min            10040.282968704634
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               28.489126414991915
(Previous) Eval Time (s)     23.398013956844807
Sample Time (s)              16.66290835896507
Epoch Time (s)               68.55004873080179
Total Train Time (s)         29881.247842856217
Epoch                        446
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:16:16.795539 UTC | [2020_01_10_08_58_14] Iteration #446 | Epoch Duration: 67.43317461013794
2020-01-10 17:16:16.795692 UTC | [2020_01_10_08_58_14] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.477236
Z variance train             0.017503027
KL Divergence                37.07142
KL Loss                      3.7071419
QF Loss                      485.11365
VF Loss                      183.97614
Policy Loss                  -4028.3582
Q Predictions Mean           4039.1414
Q Predictions Std            493.1586
Q Predictions Max            4658.2954
Q Predictions Min            2414.43
V Predictions Mean           4029.1033
V Predictions Std            492.5691
V Predictions Max            4651.4585
V Predictions Min            2391.1147
Log Pis Mean                 6.6374702
Log Pis Std                  3.8749719
Log Pis Max                  16.222528
Log Pis Min                  -4.133118
Policy mu Mean               -0.110165276
Policy mu Std                1.5225521
Policy mu Max                3.5958369
Policy mu Min                -2.6005564
Policy log std Mean          -0.8233506
Policy log std Std           0.42664307
Policy log std Max           -0.16372982
Policy log std Min           -2.8739328
Z mean eval                  2.4773798
Z variance eval              0.015131125
total_rewards                [10006.29723975  9921.09807584 10152.78148307 10303.70368673
 10098.89627927 10334.89709525 10173.87873413 10112.12300962
 10342.23724731 10053.16963505]
total_rewards_mean           10149.90824860213
total_rewards_std            134.83831623337812
total_rewards_max            10342.23724730726
total_rewards_min            9921.098075840464
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               27.447302548214793
(Previous) Eval Time (s)     22.280869249254465
Sample Time (s)              15.401284746825695
Epoch Time (s)               65.12945654429495
Total Train Time (s)         29946.536217884626
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:17:22.089373 UTC | [2020_01_10_08_58_14] Iteration #447 | Epoch Duration: 65.29351997375488
2020-01-10 17:17:22.089610 UTC | [2020_01_10_08_58_14] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4766243
Z variance train             0.01507539
KL Divergence                37.357986
KL Loss                      3.7357986
QF Loss                      773.2993
VF Loss                      372.27847
Policy Loss                  -4081.2385
Q Predictions Mean           4095.414
Q Predictions Std            409.894
Q Predictions Max            4586.9297
Q Predictions Min            2751.866
V Predictions Mean           4094.3113
V Predictions Std            410.95233
V Predictions Max            4599.1597
V Predictions Min            2762.3167
Log Pis Mean                 6.532044
Log Pis Std                  3.921204
Log Pis Max                  15.575149
Log Pis Min                  -5.451985
Policy mu Mean               -0.086248465
Policy mu Std                1.5264963
Policy mu Max                2.8627746
Policy mu Min                -3.8361712
Policy log std Mean          -0.8338818
Policy log std Std           0.44320336
Policy log std Max           0.22781682
Policy log std Min           -2.9504776
Z mean eval                  2.4794426
Z variance eval              0.014350255
total_rewards                [9188.43779527 9609.97583604 9885.89034366 9800.66984468 9567.01210274
 9532.48729971 9655.84656653 9702.06161836 9719.88596436 4394.94712524]
total_rewards_mean           9105.721449659173
total_rewards_std            1580.3322891103312
total_rewards_max            9885.890343656927
total_rewards_min            4394.947125240487
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               28.11445704707876
(Previous) Eval Time (s)     22.444673881866038
Sample Time (s)              16.67734411545098
Epoch Time (s)               67.23647504439577
Total Train Time (s)         30014.22372712521
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:18:29.783963 UTC | [2020_01_10_08_58_14] Iteration #448 | Epoch Duration: 67.6941499710083
2020-01-10 17:18:29.784269 UTC | [2020_01_10_08_58_14] Iteration #448 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4820104
Z variance train             0.014329942
KL Divergence                37.67957
KL Loss                      3.767957
QF Loss                      574.9607
VF Loss                      213.20253
Policy Loss                  -4209.7236
Q Predictions Mean           4214.8726
Q Predictions Std            428.89853
Q Predictions Max            4707.0176
Q Predictions Min            2920.0466
V Predictions Mean           4207.2676
V Predictions Std            426.96588
V Predictions Max            4696.9043
V Predictions Min            2928.174
Log Pis Mean                 6.4591894
Log Pis Std                  3.4911284
Log Pis Max                  13.414103
Log Pis Min                  -3.708875
Policy mu Mean               -0.035767525
Policy mu Std                1.5266223
Policy mu Max                3.834246
Policy mu Min                -3.0086732
Policy log std Mean          -0.82330924
Policy log std Std           0.44429895
Policy log std Max           -0.12866777
Policy log std Min           -2.8048663
Z mean eval                  2.5198379
Z variance eval              0.016909372
total_rewards                [ 9925.62022043 10114.43539849 10136.6070987   9949.22663196
 10175.67573292 10067.95014306 10170.36547146 10009.37721572
 10240.58650564 10259.82387455]
total_rewards_mean           10104.966829293317
total_rewards_std            109.39319788496347
total_rewards_max            10259.823874549937
total_rewards_min            9925.620220434583
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               28.702472303994
(Previous) Eval Time (s)     22.902037710882723
Sample Time (s)              16.124096781481057
Epoch Time (s)               67.72860679635778
Total Train Time (s)         30081.21767530497
Epoch                        449
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:19:36.781421 UTC | [2020_01_10_08_58_14] Iteration #449 | Epoch Duration: 66.9969527721405
2020-01-10 17:19:36.781576 UTC | [2020_01_10_08_58_14] Iteration #449 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.519103
Z variance train             0.016878065
KL Divergence                37.63841
KL Loss                      3.763841
QF Loss                      526.03015
VF Loss                      439.93787
Policy Loss                  -4141.374
Q Predictions Mean           4151.4473
Q Predictions Std            423.67844
Q Predictions Max            4641.107
Q Predictions Min            2869.832
V Predictions Mean           4157.0425
V Predictions Std            424.21512
V Predictions Max            4657.025
V Predictions Min            2874.6821
Log Pis Mean                 6.0466733
Log Pis Std                  3.6824822
Log Pis Max                  14.551588
Log Pis Min                  -4.3963118
Policy mu Mean               -0.032529045
Policy mu Std                1.4909292
Policy mu Max                3.4763517
Policy mu Min                -2.6550226
Policy log std Mean          -0.810535
Policy log std Std           0.44201052
Policy log std Max           -0.05984786
Policy log std Min           -2.91432
Z mean eval                  2.4716516
Z variance eval              0.027788356
total_rewards                [10120.52047567 10094.84400336 10117.70785643 10517.64414641
 10229.79491231  9952.75454264 10103.81516205 10336.48702986
 10028.75987814 10076.56363692]
total_rewards_mean           10157.889164378426
total_rewards_std            155.48934198450087
total_rewards_max            10517.644146406168
total_rewards_min            9952.754542642564
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               30.78447501687333
(Previous) Eval Time (s)     22.170098446309566
Sample Time (s)              16.61478962143883
Epoch Time (s)               69.56936308462173
Total Train Time (s)         30151.11015047878
Epoch                        450
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:20:46.680742 UTC | [2020_01_10_08_58_14] Iteration #450 | Epoch Duration: 69.89901399612427
2020-01-10 17:20:46.681009 UTC | [2020_01_10_08_58_14] Iteration #450 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4715383
Z variance train             0.027789956
KL Divergence                37.200832
KL Loss                      3.7200832
QF Loss                      554.48315
VF Loss                      167.11752
Policy Loss                  -4137.5493
Q Predictions Mean           4143.9253
Q Predictions Std            506.67294
Q Predictions Max            4617.397
Q Predictions Min            121.06024
V Predictions Mean           4136.3916
V Predictions Std            505.1635
V Predictions Max            4608.01
V Predictions Min            92.097466
Log Pis Mean                 6.592946
Log Pis Std                  3.647776
Log Pis Max                  15.331597
Log Pis Min                  -5.5934467
Policy mu Mean               0.0022229466
Policy mu Std                1.5659562
Policy mu Max                3.3800614
Policy mu Min                -2.8320305
Policy log std Mean          -0.8100551
Policy log std Std           0.43594867
Policy log std Max           -0.07121965
Policy log std Min           -2.8478403
Z mean eval                  2.4633894
Z variance eval              0.0339121
total_rewards                [ 9805.62658013  9868.98416962 10248.70356972 10357.69742023
 10159.49357936 10003.69119148  9743.05519986  4369.11544672
 10268.63955917  3038.50797045]
total_rewards_mean           8786.351468674955
total_rewards_std            2566.090242137201
total_rewards_max            10357.697420229899
total_rewards_min            3038.5079704533473
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               27.76766946306452
(Previous) Eval Time (s)     22.499383771792054
Sample Time (s)              15.777903484646231
Epoch Time (s)               66.0449567195028
Total Train Time (s)         30217.701915859245
Epoch                        451
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:21:53.279441 UTC | [2020_01_10_08_58_14] Iteration #451 | Epoch Duration: 66.59821462631226
2020-01-10 17:21:53.279713 UTC | [2020_01_10_08_58_14] Iteration #451 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4622474
Z variance train             0.03423918
KL Divergence                36.56135
KL Loss                      3.6561353
QF Loss                      495.9544
VF Loss                      226.10791
Policy Loss                  -4115.0464
Q Predictions Mean           4123.721
Q Predictions Std            497.1702
Q Predictions Max            4675.281
Q Predictions Min            267.30566
V Predictions Mean           4122.5986
V Predictions Std            495.1856
V Predictions Max            4667.8687
V Predictions Min            338.47223
Log Pis Mean                 6.514802
Log Pis Std                  3.9316165
Log Pis Max                  15.848545
Log Pis Min                  -6.83381
Policy mu Mean               0.027224356
Policy mu Std                1.5432494
Policy mu Max                3.2851558
Policy mu Min                -2.9173937
Policy log std Mean          -0.8323621
Policy log std Std           0.4615733
Policy log std Max           0.005365014
Policy log std Min           -2.7846346
Z mean eval                  2.445647
Z variance eval              0.03800223
total_rewards                [10265.12456722 10371.01381327 10498.1645604  10813.78035601
 10479.09817724 10462.95124528 10512.45412112 10596.20794919
 10595.90690346 10538.33331389]
total_rewards_mean           10513.303500707332
total_rewards_std            137.97960094180738
total_rewards_max            10813.780356005622
total_rewards_min            10265.124567219958
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               29.38723434507847
(Previous) Eval Time (s)     23.052327851764858
Sample Time (s)              16.394951559137553
Epoch Time (s)               68.83451375598088
Total Train Time (s)         30285.60044849338
Epoch                        452
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:23:01.184012 UTC | [2020_01_10_08_58_14] Iteration #452 | Epoch Duration: 67.90404939651489
2020-01-10 17:23:01.184253 UTC | [2020_01_10_08_58_14] Iteration #452 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4457164
Z variance train             0.03805887
KL Divergence                35.768322
KL Loss                      3.5768323
QF Loss                      511.1647
VF Loss                      509.8427
Policy Loss                  -4090.7769
Q Predictions Mean           4093.0918
Q Predictions Std            420.7946
Q Predictions Max            4589.8594
Q Predictions Min            2812.515
V Predictions Mean           4073.1475
V Predictions Std            417.70798
V Predictions Max            4557.544
V Predictions Min            2824.424
Log Pis Mean                 6.331079
Log Pis Std                  3.6302464
Log Pis Max                  15.166345
Log Pis Min                  -3.6732886
Policy mu Mean               -0.102353
Policy mu Std                1.5174612
Policy mu Max                3.156489
Policy mu Min                -2.8463762
Policy log std Mean          -0.8446503
Policy log std Std           0.43035662
Policy log std Max           -0.10806942
Policy log std Min           -2.717327
Z mean eval                  2.445607
Z variance eval              0.026786443
total_rewards                [10318.97338594 10168.87210276 10509.98521621 10542.76812758
 10416.95919352 10191.91652407 10482.50154099 10302.21392737
 10307.98822029 10251.79143032]
total_rewards_mean           10349.396966905044
total_rewards_std            125.39742769306523
total_rewards_max            10542.768127581163
total_rewards_min            10168.87210276066
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               30.419520642608404
(Previous) Eval Time (s)     22.121542190667242
Sample Time (s)              15.21529007377103
Epoch Time (s)               67.75635290704668
Total Train Time (s)         30353.368994868826
Epoch                        453
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:24:08.955122 UTC | [2020_01_10_08_58_14] Iteration #453 | Epoch Duration: 67.77070450782776
2020-01-10 17:24:08.955263 UTC | [2020_01_10_08_58_14] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4451256
Z variance train             0.026825244
KL Divergence                36.384296
KL Loss                      3.6384296
QF Loss                      450.78006
VF Loss                      136.70563
Policy Loss                  -4086.0237
Q Predictions Mean           4091.94
Q Predictions Std            439.91174
Q Predictions Max            4639.2334
Q Predictions Min            2393.3318
V Predictions Mean           4082.0227
V Predictions Std            439.09235
V Predictions Max            4634.9307
V Predictions Min            2451.8542
Log Pis Mean                 6.1885977
Log Pis Std                  3.9186313
Log Pis Max                  17.889074
Log Pis Min                  -3.886667
Policy mu Mean               -0.07643056
Policy mu Std                1.5048314
Policy mu Max                3.1788151
Policy mu Min                -3.9107358
Policy log std Mean          -0.8230999
Policy log std Std           0.43806058
Policy log std Max           -0.15711057
Policy log std Min           -2.9139264
Z mean eval                  2.4650054
Z variance eval              0.026353035
total_rewards                [ 9969.75422589 10290.41231696 10094.57431224 10042.18955167
  9955.91338716 10179.66843525 10129.0316561  10126.07983189
 10099.17308729 10072.45281591]
total_rewards_mean           10095.924962034525
total_rewards_std            92.63734463092506
total_rewards_max            10290.412316958602
total_rewards_min            9955.913387156705
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               26.951836998108774
(Previous) Eval Time (s)     22.135627285111696
Sample Time (s)              16.670612782705575
Epoch Time (s)               65.75807706592605
Total Train Time (s)         30419.281819164287
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:25:14.873938 UTC | [2020_01_10_08_58_14] Iteration #454 | Epoch Duration: 65.91854882240295
2020-01-10 17:25:14.874119 UTC | [2020_01_10_08_58_14] Iteration #454 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4594548
Z variance train             0.026463818
KL Divergence                36.157326
KL Loss                      3.6157327
QF Loss                      1053.9442
VF Loss                      1026.2007
Policy Loss                  -4079.3384
Q Predictions Mean           4093.2698
Q Predictions Std            432.36905
Q Predictions Max            4599.527
Q Predictions Min            2823.158
V Predictions Mean           4090.401
V Predictions Std            427.31332
V Predictions Max            4580.077
V Predictions Min            2818.9836
Log Pis Mean                 7.0451736
Log Pis Std                  3.6314726
Log Pis Max                  16.343021
Log Pis Min                  -2.8378572
Policy mu Mean               0.025070608
Policy mu Std                1.6027657
Policy mu Max                3.550539
Policy mu Min                -2.7440386
Policy log std Mean          -0.83448535
Policy log std Std           0.44702968
Policy log std Max           -0.084454894
Policy log std Min           -2.8020344
Z mean eval                  2.440095
Z variance eval              0.028682053
total_rewards                [ 9620.25961401 10044.12118207  9972.77286034 10094.04431981
  9931.25502013  9970.73124166  9824.78121256 10026.65751803
  9854.49975229 10053.90659327]
total_rewards_mean           9939.302931417282
total_rewards_std            134.15094909382924
total_rewards_max            10094.044319807861
total_rewards_min            9620.25961400959
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               28.347966166213155
(Previous) Eval Time (s)     22.29581708321348
Sample Time (s)              15.895247353706509
Epoch Time (s)               66.53903060313314
Total Train Time (s)         30485.839257507585
Epoch                        455
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:26:21.434560 UTC | [2020_01_10_08_58_14] Iteration #455 | Epoch Duration: 66.56028532981873
2020-01-10 17:26:21.434730 UTC | [2020_01_10_08_58_14] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4384646
Z variance train             0.02871631
KL Divergence                35.926662
KL Loss                      3.5926664
QF Loss                      1849.4968
VF Loss                      1642.7247
Policy Loss                  -3990.6504
Q Predictions Mean           4001.1646
Q Predictions Std            448.3785
Q Predictions Max            4534.341
Q Predictions Min            2741.2373
V Predictions Mean           4007.249
V Predictions Std            456.5983
V Predictions Max            4534.628
V Predictions Min            2303.6272
Log Pis Mean                 6.4677978
Log Pis Std                  3.6964078
Log Pis Max                  19.370522
Log Pis Min                  -4.372055
Policy mu Mean               -0.044330936
Policy mu Std                1.5378399
Policy mu Max                3.5213122
Policy mu Min                -3.1060004
Policy log std Mean          -0.82679105
Policy log std Std           0.4119177
Policy log std Max           -0.14795548
Policy log std Min           -2.7266521
Z mean eval                  2.4610164
Z variance eval              0.025186468
total_rewards                [9422.72801071 9625.72003393 9754.88679677 9403.64306315 9453.83047536
 9395.87933105 9267.72109337 9621.84936746 9788.38325368 9531.52983329]
total_rewards_mean           9526.617125877397
total_rewards_std            159.6484389896851
total_rewards_max            9788.383253683896
total_rewards_min            9267.721093374379
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               28.835500384215266
(Previous) Eval Time (s)     22.31679450115189
Sample Time (s)              15.872815038077533
Epoch Time (s)               67.02510992344469
Total Train Time (s)         30552.741605810355
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:27:28.339686 UTC | [2020_01_10_08_58_14] Iteration #456 | Epoch Duration: 66.90484261512756
2020-01-10 17:27:28.339888 UTC | [2020_01_10_08_58_14] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.460404
Z variance train             0.024969723
KL Divergence                36.579674
KL Loss                      3.6579673
QF Loss                      833.67163
VF Loss                      922.2719
Policy Loss                  -4190.605
Q Predictions Mean           4212.3965
Q Predictions Std            429.8457
Q Predictions Max            4719.14
Q Predictions Min            2908.5815
V Predictions Mean           4207.902
V Predictions Std            431.707
V Predictions Max            4735.07
V Predictions Min            2938.7563
Log Pis Mean                 6.7075715
Log Pis Std                  3.7317066
Log Pis Max                  20.071049
Log Pis Min                  -9.233259
Policy mu Mean               0.006695971
Policy mu Std                1.596502
Policy mu Max                3.8387485
Policy mu Min                -3.6507547
Policy log std Mean          -0.80493623
Policy log std Std           0.43185604
Policy log std Max           -0.088792205
Policy log std Min           -2.8895476
Z mean eval                  2.4258525
Z variance eval              0.02097362
total_rewards                [ 9917.21526352 10370.04641911 10472.51683333 10195.56487535
 10249.57657088 10406.65345669 10184.02748431 10371.47823695
 10513.45315872 10412.83758613]
total_rewards_mean           10309.33698850052
total_rewards_std            167.928089195879
total_rewards_max            10513.453158719607
total_rewards_min            9917.215263515924
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               30.79528693901375
(Previous) Eval Time (s)     22.196236982941628
Sample Time (s)              16.116661306470633
Epoch Time (s)               69.10818522842601
Total Train Time (s)         30621.702428538818
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:28:37.304048 UTC | [2020_01_10_08_58_14] Iteration #457 | Epoch Duration: 68.96403765678406
2020-01-10 17:28:37.304233 UTC | [2020_01_10_08_58_14] Iteration #457 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4219265
Z variance train             0.02094407
KL Divergence                36.475857
KL Loss                      3.6475856
QF Loss                      820.01575
VF Loss                      314.66113
Policy Loss                  -4068.151
Q Predictions Mean           4074.3032
Q Predictions Std            482.95264
Q Predictions Max            4617.1084
Q Predictions Min            324.7653
V Predictions Mean           4076.3848
V Predictions Std            484.4771
V Predictions Max            4623.407
V Predictions Min            250.39243
Log Pis Mean                 6.6620865
Log Pis Std                  4.0824385
Log Pis Max                  18.122522
Log Pis Min                  -3.6916723
Policy mu Mean               0.09107099
Policy mu Std                1.5687071
Policy mu Max                3.2630856
Policy mu Min                -3.1643384
Policy log std Mean          -0.81473964
Policy log std Std           0.44367605
Policy log std Max           -0.08679059
Policy log std Min           -2.8460321
Z mean eval                  2.4346247
Z variance eval              0.01862914
total_rewards                [ 9961.70347112  9750.70576638  9899.49788405 10148.91483869
 10053.5046227  10009.11962121  9909.18331486  9769.0587021
 10346.0704936   9913.10316472]
total_rewards_mean           9976.086187942077
total_rewards_std            167.93306747154
total_rewards_max            10346.070493602627
total_rewards_min            9750.70576638185
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               26.91938598593697
(Previous) Eval Time (s)     22.05183374322951
Sample Time (s)              15.629336892161518
Epoch Time (s)               64.600556621328
Total Train Time (s)         30686.511209952645
Epoch                        458
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:29:42.120522 UTC | [2020_01_10_08_58_14] Iteration #458 | Epoch Duration: 64.81613230705261
2020-01-10 17:29:42.120809 UTC | [2020_01_10_08_58_14] Iteration #458 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4286847
Z variance train             0.018610796
KL Divergence                36.879356
KL Loss                      3.6879356
QF Loss                      698.1499
VF Loss                      1444.7139
Policy Loss                  -4156.715
Q Predictions Mean           4172.8867
Q Predictions Std            431.21945
Q Predictions Max            4659.5938
Q Predictions Min            2855.4373
V Predictions Mean           4189.671
V Predictions Std            430.73102
V Predictions Max            4683.854
V Predictions Min            2881.2578
Log Pis Mean                 6.148083
Log Pis Std                  4.0246634
Log Pis Max                  16.078156
Log Pis Min                  -5.582373
Policy mu Mean               0.00025749454
Policy mu Std                1.5317965
Policy mu Max                3.2932222
Policy mu Min                -3.2165625
Policy log std Mean          -0.81231993
Policy log std Std           0.43433097
Policy log std Max           -0.10021925
Policy log std Min           -2.7368844
Z mean eval                  2.4544022
Z variance eval              0.021376543
total_rewards                [10098.16438867 10238.86408889 10261.6264547  10400.52785738
 10513.3791626  10642.84198766 10391.29149005 10190.60813431
 10329.38883608 10234.70612333]
total_rewards_mean           10330.139852367345
total_rewards_std            153.44982622804164
total_rewards_max            10642.841987657197
total_rewards_min            10098.16438866686
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               30.242339425254613
(Previous) Eval Time (s)     22.267096714582294
Sample Time (s)              16.138761633541435
Epoch Time (s)               68.64819777337834
Total Train Time (s)         30755.11389361089
Epoch                        459
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:30:50.730015 UTC | [2020_01_10_08_58_14] Iteration #459 | Epoch Duration: 68.60897898674011
2020-01-10 17:30:50.730300 UTC | [2020_01_10_08_58_14] Iteration #459 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.454488
Z variance train             0.021364888
KL Divergence                36.42291
KL Loss                      3.6422908
QF Loss                      710.8504
VF Loss                      247.99178
Policy Loss                  -4044.0596
Q Predictions Mean           4050.435
Q Predictions Std            422.35046
Q Predictions Max            4618.419
Q Predictions Min            2808.6572
V Predictions Mean           4047.9646
V Predictions Std            422.63425
V Predictions Max            4618.8306
V Predictions Min            2818.6309
Log Pis Mean                 6.3135853
Log Pis Std                  3.677705
Log Pis Max                  15.29342
Log Pis Min                  -4.419999
Policy mu Mean               -0.027662778
Policy mu Std                1.4802094
Policy mu Max                2.9664214
Policy mu Min                -2.8695264
Policy log std Mean          -0.8286961
Policy log std Std           0.4376189
Policy log std Max           0.08578932
Policy log std Min           -2.6476212
Z mean eval                  2.4591985
Z variance eval              0.018979514
total_rewards                [ 9682.86858808 10068.34449091 10020.06030654  9745.42122336
 10010.88546178  9809.52485003  9612.81989532  9865.82173296
  9965.79279158  9462.05772796]
total_rewards_mean           9824.359706851814
total_rewards_std            188.89798397445648
total_rewards_max            10068.34449090832
total_rewards_min            9462.057727959233
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               29.090397255960852
(Previous) Eval Time (s)     22.227614970877767
Sample Time (s)              15.801665836013854
Epoch Time (s)               67.11967806285247
Total Train Time (s)         30822.427542644553
Epoch                        460
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:31:58.049042 UTC | [2020_01_10_08_58_14] Iteration #460 | Epoch Duration: 67.31853342056274
2020-01-10 17:31:58.049264 UTC | [2020_01_10_08_58_14] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4580379
Z variance train             0.019010048
KL Divergence                36.440876
KL Loss                      3.6440876
QF Loss                      840.46533
VF Loss                      280.38562
Policy Loss                  -4128.8286
Q Predictions Mean           4130.5986
Q Predictions Std            514.35565
Q Predictions Max            4666.5137
Q Predictions Min            420.5176
V Predictions Mean           4128.7725
V Predictions Std            513.8112
V Predictions Max            4654.658
V Predictions Min            408.245
Log Pis Mean                 6.7686462
Log Pis Std                  3.9490535
Log Pis Max                  16.625414
Log Pis Min                  -3.7002654
Policy mu Mean               -0.022944385
Policy mu Std                1.5485029
Policy mu Max                3.1710546
Policy mu Min                -2.8693373
Policy log std Mean          -0.8099303
Policy log std Std           0.45110074
Policy log std Max           -0.08919713
Policy log std Min           -2.8949165
Z mean eval                  2.4418387
Z variance eval              0.046614055
total_rewards                [10290.08739151 10298.40396383 10435.28586748 10246.27351065
 10144.80396938 10013.8208164  10251.84436178 10280.85752082
 10213.14048328 10164.79867798]
total_rewards_mean           10233.931656311313
total_rewards_std            105.89289613884321
total_rewards_max            10435.285867477149
total_rewards_min            10013.820816399455
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               30.41893257526681
(Previous) Eval Time (s)     22.42621714901179
Sample Time (s)              15.892436158843338
Epoch Time (s)               68.73758588312194
Total Train Time (s)         30891.24668657314
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:33:06.871570 UTC | [2020_01_10_08_58_14] Iteration #461 | Epoch Duration: 68.82212853431702
2020-01-10 17:33:06.871758 UTC | [2020_01_10_08_58_14] Iteration #461 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4427698
Z variance train             0.046692435
KL Divergence                34.78373
KL Loss                      3.478373
QF Loss                      458.99316
VF Loss                      153.69061
Policy Loss                  -4246.1304
Q Predictions Mean           4250.782
Q Predictions Std            437.78238
Q Predictions Max            4735.3804
Q Predictions Min            2608.8188
V Predictions Mean           4240.45
V Predictions Std            435.52417
V Predictions Max            4726.634
V Predictions Min            2758.0786
Log Pis Mean                 7.029682
Log Pis Std                  3.830751
Log Pis Max                  16.057081
Log Pis Min                  -2.830195
Policy mu Mean               0.011245366
Policy mu Std                1.5623337
Policy mu Max                2.874042
Policy mu Min                -2.7591293
Policy log std Mean          -0.8081753
Policy log std Std           0.42512572
Policy log std Max           -0.028153151
Policy log std Min           -2.8364856
Z mean eval                  2.4455137
Z variance eval              0.030506898
total_rewards                [ 9696.70391609 10070.02044386  9834.40197169  9872.1208442
  9529.68331071  9754.74153246  9797.14617471 10153.82656547
  9965.2923566   9915.60879268]
total_rewards_mean           9858.9545908468
total_rewards_std            172.10966715953103
total_rewards_max            10153.826565470927
total_rewards_min            9529.683310710814
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               27.954347194172442
(Previous) Eval Time (s)     22.51047002291307
Sample Time (s)              16.785800316836685
Epoch Time (s)               67.2506175339222
Total Train Time (s)         30957.966754376423
Epoch                        462
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:34:13.598747 UTC | [2020_01_10_08_58_14] Iteration #462 | Epoch Duration: 66.72680187225342
2020-01-10 17:34:13.599020 UTC | [2020_01_10_08_58_14] Iteration #462 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4448867
Z variance train             0.030415392
KL Divergence                36.123714
KL Loss                      3.6123714
QF Loss                      891.35046
VF Loss                      598.20526
Policy Loss                  -3967.3306
Q Predictions Mean           3974.8545
Q Predictions Std            447.11087
Q Predictions Max            4528.5703
Q Predictions Min            2433.061
V Predictions Mean           3985.136
V Predictions Std            448.62247
V Predictions Max            4544.3315
V Predictions Min            2425.4565
Log Pis Mean                 6.1726522
Log Pis Std                  3.9461784
Log Pis Max                  16.440054
Log Pis Min                  -5.8022914
Policy mu Mean               0.0583822
Policy mu Std                1.5206678
Policy mu Max                3.169915
Policy mu Min                -2.7301447
Policy log std Mean          -0.7998659
Policy log std Std           0.40591216
Policy log std Max           -0.014374763
Policy log std Min           -2.7143188
Z mean eval                  2.4494672
Z variance eval              0.0141541455
total_rewards                [ 9690.43707643  9994.64865237 10111.88869438  9999.03539302
  9823.50821866  9754.29896651 10019.87380992  9953.54383466
  9793.08541131  9891.40420028]
total_rewards_mean           9903.172425753235
total_rewards_std            127.78898415386837
total_rewards_max            10111.888694379837
total_rewards_min            9690.437076432007
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               29.940367213916034
(Previous) Eval Time (s)     21.986366035882384
Sample Time (s)              15.878144399262965
Epoch Time (s)               67.80487764906138
Total Train Time (s)         31026.794997792225
Epoch                        463
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:35:22.430060 UTC | [2020_01_10_08_58_14] Iteration #463 | Epoch Duration: 68.83085632324219
2020-01-10 17:35:22.430214 UTC | [2020_01_10_08_58_14] Iteration #463 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4530308
Z variance train             0.014079501
KL Divergence                37.725574
KL Loss                      3.7725575
QF Loss                      1499.815
VF Loss                      600.7446
Policy Loss                  -4099.2935
Q Predictions Mean           4094.687
Q Predictions Std            537.305
Q Predictions Max            4625.862
Q Predictions Min            203.65802
V Predictions Mean           4100.927
V Predictions Std            535.6541
V Predictions Max            4656.0522
V Predictions Min            235.03635
Log Pis Mean                 7.1199665
Log Pis Std                  4.4903164
Log Pis Max                  19.242317
Log Pis Min                  -6.7526817
Policy mu Mean               -0.06426467
Policy mu Std                1.6230617
Policy mu Max                3.1241088
Policy mu Min                -3.549327
Policy log std Mean          -0.80984277
Policy log std Std           0.43467924
Policy log std Max           0.034882903
Policy log std Min           -2.8274956
Z mean eval                  2.489902
Z variance eval              0.0199642
total_rewards                [10303.93020642 10196.52402968 10263.32722686 10279.94519208
 10156.864857   10211.77028065 10203.54372942 10205.28398749
 10033.76084357 10081.41206966]
total_rewards_mean           10193.636242284356
total_rewards_std            80.34200670606366
total_rewards_max            10303.930206423687
total_rewards_min            10033.760843570808
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               30.16919729206711
(Previous) Eval Time (s)     23.012069090735167
Sample Time (s)              16.003986658528447
Epoch Time (s)               69.18525304133072
Total Train Time (s)         31095.435149458237
Epoch                        464
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:36:31.075531 UTC | [2020_01_10_08_58_14] Iteration #464 | Epoch Duration: 68.64517855644226
2020-01-10 17:36:31.075758 UTC | [2020_01_10_08_58_14] Iteration #464 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4901958
Z variance train             0.01995514
KL Divergence                37.246674
KL Loss                      3.7246673
QF Loss                      409.8125
VF Loss                      270.12186
Policy Loss                  -4135.5083
Q Predictions Mean           4142.7324
Q Predictions Std            573.2117
Q Predictions Max            4709.855
Q Predictions Min            218.68336
V Predictions Mean           4128.078
V Predictions Std            569.89886
V Predictions Max            4677.321
V Predictions Min            239.54576
Log Pis Mean                 7.0946913
Log Pis Std                  3.738311
Log Pis Max                  15.918865
Log Pis Min                  -4.2902765
Policy mu Mean               -0.050678954
Policy mu Std                1.5656291
Policy mu Max                2.7878366
Policy mu Min                -2.988708
Policy log std Mean          -0.83176833
Policy log std Std           0.444775
Policy log std Max           -0.12715435
Policy log std Min           -2.9232287
Z mean eval                  2.4581635
Z variance eval              0.031781755
total_rewards                [ 9812.81834399 10288.92652948  9900.03242348  9793.02563432
 10082.15380224  9814.87025868 10183.80676133  1200.18316098
  9920.20596006  9711.17979534]
total_rewards_mean           9070.7202669911
total_rewards_std            2629.393599063552
total_rewards_max            10288.92652947897
total_rewards_min            1200.1831609798562
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               27.430615128017962
(Previous) Eval Time (s)     22.471666165161878
Sample Time (s)              16.079125544056296
Epoch Time (s)               65.98140683723614
Total Train Time (s)         31160.80880361842
Epoch                        465
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:37:36.454790 UTC | [2020_01_10_08_58_14] Iteration #465 | Epoch Duration: 65.37884211540222
2020-01-10 17:37:36.455018 UTC | [2020_01_10_08_58_14] Iteration #465 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4576492
Z variance train             0.031624813
KL Divergence                36.657513
KL Loss                      3.6657512
QF Loss                      1431.905
VF Loss                      224.60329
Policy Loss                  -4183.4165
Q Predictions Mean           4188.494
Q Predictions Std            411.00354
Q Predictions Max            4663.1465
Q Predictions Min            2886.379
V Predictions Mean           4189.1445
V Predictions Std            409.75305
V Predictions Max            4686.375
V Predictions Min            2890.9802
Log Pis Mean                 5.9824386
Log Pis Std                  3.841539
Log Pis Max                  14.496481
Log Pis Min                  -3.920692
Policy mu Mean               -0.0742748
Policy mu Std                1.4886016
Policy mu Max                2.7037385
Policy mu Min                -2.9020143
Policy log std Mean          -0.8160071
Policy log std Std           0.42233846
Policy log std Max           -0.12859824
Policy log std Min           -2.7591124
Z mean eval                  2.4417393
Z variance eval              0.030065369
total_rewards                [ 9779.5455153   9823.74714688  9809.44985832  9789.6850166
  9871.7628782   9614.52631043  9853.19186652  9780.13081415
  9630.44420497 10076.01815222]
total_rewards_mean           9802.850176359114
total_rewards_std            121.98627954945178
total_rewards_max            10076.01815221928
total_rewards_min            9614.526310433404
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               28.280066933017224
(Previous) Eval Time (s)     21.86881275102496
Sample Time (s)              16.245088112074882
Epoch Time (s)               66.39396779611707
Total Train Time (s)         31228.46732628066
Epoch                        466
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:38:44.116219 UTC | [2020_01_10_08_58_14] Iteration #466 | Epoch Duration: 67.66104769706726
2020-01-10 17:38:44.116374 UTC | [2020_01_10_08_58_14] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4399552
Z variance train             0.03002451
KL Divergence                36.350014
KL Loss                      3.6350014
QF Loss                      2480.2314
VF Loss                      277.82568
Policy Loss                  -4044.4915
Q Predictions Mean           4054.5364
Q Predictions Std            446.86807
Q Predictions Max            4600.501
Q Predictions Min            2802.5486
V Predictions Mean           4048.6792
V Predictions Std            446.63623
V Predictions Max            4590.6157
V Predictions Min            2787.2715
Log Pis Mean                 6.312795
Log Pis Std                  3.7603898
Log Pis Max                  23.77367
Log Pis Min                  -3.0529864
Policy mu Mean               0.0712749
Policy mu Std                1.5321845
Policy mu Max                5.1336446
Policy mu Min                -3.0642498
Policy log std Mean          -0.8130534
Policy log std Std           0.44818056
Policy log std Max           -0.0840435
Policy log std Min           -2.7590861
Z mean eval                  2.4278312
Z variance eval              0.022199545
total_rewards                [10202.29738937 10404.34484309 10111.78438341 10447.75326687
 10456.82572961 10389.16031824 10300.90084693 10247.68544234
 10225.89767572 10344.24813762]
total_rewards_mean           10313.089803319981
total_rewards_std            108.9527014461841
total_rewards_max            10456.825729611624
total_rewards_min            10111.784383411949
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               30.157409441191703
(Previous) Eval Time (s)     23.135624839924276
Sample Time (s)              15.44300477206707
Epoch Time (s)               68.73603905318305
Total Train Time (s)         31296.00472863391
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:39:51.657100 UTC | [2020_01_10_08_58_14] Iteration #467 | Epoch Duration: 67.54061031341553
2020-01-10 17:39:51.657257 UTC | [2020_01_10_08_58_14] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4271572
Z variance train             0.022196796
KL Divergence                36.720253
KL Loss                      3.6720254
QF Loss                      942.395
VF Loss                      258.90128
Policy Loss                  -4023.9436
Q Predictions Mean           4035.2805
Q Predictions Std            429.8717
Q Predictions Max            4532.3965
Q Predictions Min            2468.801
V Predictions Mean           4023.2986
V Predictions Std            430.63367
V Predictions Max            4505.3936
V Predictions Min            2431.3828
Log Pis Mean                 6.548549
Log Pis Std                  4.0705147
Log Pis Max                  15.577463
Log Pis Min                  -4.231203
Policy mu Mean               0.012240045
Policy mu Std                1.5304509
Policy mu Max                3.051626
Policy mu Min                -3.1581314
Policy log std Mean          -0.83737916
Policy log std Std           0.45309493
Policy log std Max           -0.08288133
Policy log std Min           -2.9833047
Z mean eval                  2.4592834
Z variance eval              0.03027319
total_rewards                [10329.22591964 10165.12810087 10098.33908989 10358.33718044
 10262.51318762 10136.82989259 10222.99586489 10531.24779381
 10465.45056824 10536.30955797]
total_rewards_mean           10310.63771559588
total_rewards_std            152.52355380542733
total_rewards_max            10536.309557969895
total_rewards_min            10098.339089888295
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               28.55617889109999
(Previous) Eval Time (s)     21.93993181688711
Sample Time (s)              15.908869988750666
Epoch Time (s)               66.40498069673777
Total Train Time (s)         31362.758758770768
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:40:58.417468 UTC | [2020_01_10_08_58_14] Iteration #468 | Epoch Duration: 66.76005244255066
2020-01-10 17:40:58.417704 UTC | [2020_01_10_08_58_14] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4585252
Z variance train             0.030367503
KL Divergence                36.676174
KL Loss                      3.6676176
QF Loss                      655.64124
VF Loss                      165.81212
Policy Loss                  -4025.5676
Q Predictions Mean           4030.4185
Q Predictions Std            510.86215
Q Predictions Max            4538.1714
Q Predictions Min            164.89375
V Predictions Mean           4030.8896
V Predictions Std            510.0299
V Predictions Max            4521.8643
V Predictions Min            186.7231
Log Pis Mean                 6.2322636
Log Pis Std                  4.159097
Log Pis Max                  15.232395
Log Pis Min                  -7.2375746
Policy mu Mean               -0.035171177
Policy mu Std                1.5159273
Policy mu Max                3.0764604
Policy mu Min                -2.8437986
Policy log std Mean          -0.81724066
Policy log std Std           0.42441505
Policy log std Max           -0.12042144
Policy log std Min           -2.8168962
Z mean eval                  2.4490767
Z variance eval              0.03780397
total_rewards                [10021.21768197 10117.39482749  9857.17396346  9963.92807885
 10154.11547282  9847.58305703  9797.77202929  9892.88732271
 10235.84069697  9961.41283866]
total_rewards_mean           9984.93259692514
total_rewards_std            137.88528348595977
total_rewards_max            10235.84069697432
total_rewards_min            9797.772029285146
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               28.36898547736928
(Previous) Eval Time (s)     22.29471876984462
Sample Time (s)              16.62370514124632
Epoch Time (s)               67.28740938846022
Total Train Time (s)         31430.195694115013
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:42:05.857031 UTC | [2020_01_10_08_58_14] Iteration #469 | Epoch Duration: 67.43916606903076
2020-01-10 17:42:05.857173 UTC | [2020_01_10_08_58_14] Iteration #469 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4513278
Z variance train             0.03802072
KL Divergence                36.150925
KL Loss                      3.6150925
QF Loss                      490.45798
VF Loss                      461.83566
Policy Loss                  -4081.5044
Q Predictions Mean           4090.8843
Q Predictions Std            543.38275
Q Predictions Max            4635.5557
Q Predictions Min            139.18748
V Predictions Mean           4072.615
V Predictions Std            540.11176
V Predictions Max            4610.7197
V Predictions Min            148.88689
Log Pis Mean                 6.7564583
Log Pis Std                  3.5637505
Log Pis Max                  16.670311
Log Pis Min                  -2.0594447
Policy mu Mean               0.004978545
Policy mu Std                1.5384034
Policy mu Max                3.0292346
Policy mu Min                -3.3208895
Policy log std Mean          -0.81777906
Policy log std Std           0.42583182
Policy log std Max           0.051795125
Policy log std Min           -2.781774
Z mean eval                  2.4840355
Z variance eval              0.029092055
total_rewards                [ 1004.48878319 10360.26036536 10428.6314546  10474.64859621
 10295.92474592 10624.01637529 10487.05238303 10169.64583535
 10164.92924329  5924.41924842]
total_rewards_mean           8993.401703065236
total_rewards_std            2978.3578063350565
total_rewards_max            10624.016375294708
total_rewards_min            1004.4887831885296
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               28.427022682037205
(Previous) Eval Time (s)     22.446151985786855
Sample Time (s)              16.006589612923563
Epoch Time (s)               66.87976428074762
Total Train Time (s)         31496.960887297057
Epoch                        470
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:43:12.625663 UTC | [2020_01_10_08_58_14] Iteration #470 | Epoch Duration: 66.76835703849792
2020-01-10 17:43:12.625817 UTC | [2020_01_10_08_58_14] Iteration #470 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.48246
Z variance train             0.02891329
KL Divergence                36.870354
KL Loss                      3.6870353
QF Loss                      763.22034
VF Loss                      217.59067
Policy Loss                  -4082.5203
Q Predictions Mean           4088.6128
Q Predictions Std            538.796
Q Predictions Max            4590.426
Q Predictions Min            114.49737
V Predictions Mean           4085.4517
V Predictions Std            537.33276
V Predictions Max            4588.539
V Predictions Min            145.42567
Log Pis Mean                 6.5195
Log Pis Std                  4.0145583
Log Pis Max                  14.652019
Log Pis Min                  -4.5476
Policy mu Mean               0.032588243
Policy mu Std                1.542702
Policy mu Max                3.396753
Policy mu Min                -3.046348
Policy log std Mean          -0.8256028
Policy log std Std           0.44900414
Policy log std Max           -0.055860877
Policy log std Min           -2.7683153
Z mean eval                  2.4398856
Z variance eval              0.02498088
total_rewards                [10083.07950476 10347.10815988 10421.41340406 10351.93322246
 10435.18550328 10490.64692915 10471.74801753 10406.91753637
 10469.73040178 10466.45650296]
total_rewards_mean           10394.421918222093
total_rewards_std            113.85221013174215
total_rewards_max            10490.646929146269
total_rewards_min            10083.079504759107
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               29.326407677028328
(Previous) Eval Time (s)     22.334478130098432
Sample Time (s)              16.309783211443573
Epoch Time (s)               67.97066901857033
Total Train Time (s)         31565.19346201187
Epoch                        471
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:44:20.863081 UTC | [2020_01_10_08_58_14] Iteration #471 | Epoch Duration: 68.23712825775146
2020-01-10 17:44:20.863281 UTC | [2020_01_10_08_58_14] Iteration #471 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.441812
Z variance train             0.024978623
KL Divergence                36.89
KL Loss                      3.689
QF Loss                      743.2468
VF Loss                      208.2309
Policy Loss                  -4056.6697
Q Predictions Mean           4063.6248
Q Predictions Std            470.5373
Q Predictions Max            4568.598
Q Predictions Min            495.53116
V Predictions Mean           4050.9312
V Predictions Std            469.76352
V Predictions Max            4550.001
V Predictions Min            461.12115
Log Pis Mean                 6.552207
Log Pis Std                  3.6672943
Log Pis Max                  15.860829
Log Pis Min                  -3.128725
Policy mu Mean               -0.0349843
Policy mu Std                1.5297536
Policy mu Max                3.1105623
Policy mu Min                -3.4427245
Policy log std Mean          -0.8303612
Policy log std Std           0.43323934
Policy log std Max           -0.09377205
Policy log std Min           -2.8700657
Z mean eval                  2.4531434
Z variance eval              0.026037892
total_rewards                [ 9882.75863132  1099.59047594 10303.84487899  9960.24455157
 10161.17730207 10289.72164826 10210.51993033 10226.4400258
 10308.45234314 10228.62557076]
total_rewards_mean           9267.137535818201
total_rewards_std            2725.930786150251
total_rewards_max            10308.452343138399
total_rewards_min            1099.5904759350854
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               27.084490185137838
(Previous) Eval Time (s)     22.60066207498312
Sample Time (s)              16.242972719483078
Epoch Time (s)               65.92812497960404
Total Train Time (s)         31630.734998697415
Epoch                        472
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:45:26.411694 UTC | [2020_01_10_08_58_14] Iteration #472 | Epoch Duration: 65.54814147949219
2020-01-10 17:45:26.412083 UTC | [2020_01_10_08_58_14] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.454742
Z variance train             0.026111608
KL Divergence                36.489063
KL Loss                      3.6489065
QF Loss                      6200.2593
VF Loss                      209.00339
Policy Loss                  -4082.6267
Q Predictions Mean           4089.4834
Q Predictions Std            451.67014
Q Predictions Max            4627.23
Q Predictions Min            2029.7994
V Predictions Mean           4074.7827
V Predictions Std            453.2507
V Predictions Max            4587.072
V Predictions Min            1788.0955
Log Pis Mean                 6.784624
Log Pis Std                  3.7457228
Log Pis Max                  16.379519
Log Pis Min                  -3.5848355
Policy mu Mean               -0.021548146
Policy mu Std                1.5440589
Policy mu Max                3.220915
Policy mu Min                -3.0338786
Policy log std Mean          -0.8338752
Policy log std Std           0.4679188
Policy log std Max           -0.11994624
Policy log std Min           -2.8637762
Z mean eval                  2.4443288
Z variance eval              0.027599836
total_rewards                [10262.03445604 10350.43770728 10403.21802509 10384.26895402
 10541.60113124 10311.7281117  10280.2234504  10329.43450698
 10241.79420721 10482.10176357]
total_rewards_mean           10358.684231352361
total_rewards_std            91.44249340838337
total_rewards_max            10541.60113123848
total_rewards_min            10241.794207207813
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               27.282950698863715
(Previous) Eval Time (s)     22.220400020014495
Sample Time (s)              16.117467727977782
Epoch Time (s)               65.62081844685599
Total Train Time (s)         31696.80042161327
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:46:32.482238 UTC | [2020_01_10_08_58_14] Iteration #473 | Epoch Duration: 66.06992483139038
2020-01-10 17:46:32.482457 UTC | [2020_01_10_08_58_14] Iteration #473 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4422197
Z variance train             0.027602196
KL Divergence                36.418518
KL Loss                      3.641852
QF Loss                      696.5856
VF Loss                      500.75366
Policy Loss                  -4103.369
Q Predictions Mean           4110.756
Q Predictions Std            545.14233
Q Predictions Max            4681.282
Q Predictions Min            40.003456
V Predictions Mean           4091.3848
V Predictions Std            539.7277
V Predictions Max            4662.1245
V Predictions Min            122.26703
Log Pis Mean                 6.2652125
Log Pis Std                  3.9066195
Log Pis Max                  16.372896
Log Pis Min                  -3.6766815
Policy mu Mean               -0.02827467
Policy mu Std                1.5304734
Policy mu Max                3.3053641
Policy mu Min                -3.3117523
Policy log std Mean          -0.8081007
Policy log std Std           0.4246035
Policy log std Max           -0.056636512
Policy log std Min           -2.9547176
Z mean eval                  2.4328287
Z variance eval              0.022181692
total_rewards                [10421.99509744 10490.22731399 10362.03216891 10586.35422042
 10485.04455263 10450.38932294 10295.60252869 10351.20010355
 10667.96481056 10311.0817516 ]
total_rewards_mean           10442.189187071875
total_rewards_std            113.91156456358902
total_rewards_max            10667.964810560687
total_rewards_min            10295.602528690075
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               26.626272096764296
(Previous) Eval Time (s)     22.669266504701227
Sample Time (s)              16.243470357730985
Epoch Time (s)               65.53900895919651
Total Train Time (s)         31762.11331827892
Epoch                        474
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:47:37.798885 UTC | [2020_01_10_08_58_14] Iteration #474 | Epoch Duration: 65.31618189811707
2020-01-10 17:47:37.799141 UTC | [2020_01_10_08_58_14] Iteration #474 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4325619
Z variance train             0.02220026
KL Divergence                36.782063
KL Loss                      3.6782062
QF Loss                      497.8042
VF Loss                      188.78708
Policy Loss                  -4024.9202
Q Predictions Mean           4033.0342
Q Predictions Std            455.95755
Q Predictions Max            4582.105
Q Predictions Min            2743.6077
V Predictions Mean           4028.1274
V Predictions Std            455.41537
V Predictions Max            4586.491
V Predictions Min            2764.8665
Log Pis Mean                 6.569887
Log Pis Std                  3.892348
Log Pis Max                  20.029303
Log Pis Min                  -5.7432895
Policy mu Mean               0.013575385
Policy mu Std                1.5230747
Policy mu Max                3.757556
Policy mu Min                -2.9324236
Policy log std Mean          -0.8480907
Policy log std Std           0.45777917
Policy log std Max           -0.03022319
Policy log std Min           -2.88445
Z mean eval                  2.4377406
Z variance eval              0.01823457
total_rewards                [10140.75838024 10296.62194165 10400.63698593 10108.32265963
 10289.91467602 10367.36436722 10283.77436005 10316.87064932
 10296.53271601 10318.68509195]
total_rewards_mean           10281.94818280298
total_rewards_std            86.32922222354775
total_rewards_max            10400.636985933239
total_rewards_min            10108.322659633379
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               28.539171542972326
(Previous) Eval Time (s)     22.446123850997537
Sample Time (s)              15.687785069458187
Epoch Time (s)               66.67308046342805
Total Train Time (s)         31828.89378134301
Epoch                        475
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:48:44.586435 UTC | [2020_01_10_08_58_14] Iteration #475 | Epoch Duration: 66.78708982467651
2020-01-10 17:48:44.586729 UTC | [2020_01_10_08_58_14] Iteration #475 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4380898
Z variance train             0.018305907
KL Divergence                37.129787
KL Loss                      3.7129788
QF Loss                      862.4713
VF Loss                      572.16815
Policy Loss                  -4064.7024
Q Predictions Mean           4070.913
Q Predictions Std            550.3559
Q Predictions Max            4605.6543
Q Predictions Min            196.20113
V Predictions Mean           4046.9854
V Predictions Std            546.19696
V Predictions Max            4555.2295
V Predictions Min            221.38414
Log Pis Mean                 6.550097
Log Pis Std                  4.1162257
Log Pis Max                  23.960995
Log Pis Min                  -7.6780806
Policy mu Mean               -0.051772207
Policy mu Std                1.5217729
Policy mu Max                5.8641925
Policy mu Min                -3.50976
Policy log std Mean          -0.8407709
Policy log std Std           0.44956484
Policy log std Max           -0.059666246
Policy log std Min           -2.9901407
Z mean eval                  2.4356549
Z variance eval              0.021127611
total_rewards                [10341.68799434 10364.41162383 10456.63741619 10261.35748248
 10244.35567473 10223.95623886 10470.64032931 10466.32834868
 10504.61781724 10383.11423927]
total_rewards_mean           10371.710716494566
total_rewards_std            97.43183046261068
total_rewards_max            10504.617817241042
total_rewards_min            10223.956238862744
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               27.10609777783975
(Previous) Eval Time (s)     22.559867264237255
Sample Time (s)              15.953760839998722
Epoch Time (s)               65.61972588207573
Total Train Time (s)         31894.24125860026
Epoch                        476
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:49:49.938234 UTC | [2020_01_10_08_58_14] Iteration #476 | Epoch Duration: 65.35129189491272
2020-01-10 17:49:49.938431 UTC | [2020_01_10_08_58_14] Iteration #476 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4367964
Z variance train             0.021200303
KL Divergence                36.592583
KL Loss                      3.6592584
QF Loss                      427.87512
VF Loss                      226.28795
Policy Loss                  -4079.0164
Q Predictions Mean           4085.482
Q Predictions Std            457.8377
Q Predictions Max            4592.053
Q Predictions Min            855.9176
V Predictions Mean           4068.8826
V Predictions Std            458.81674
V Predictions Max            4582.4785
V Predictions Min            714.3712
Log Pis Mean                 5.980729
Log Pis Std                  3.9872515
Log Pis Max                  17.533035
Log Pis Min                  -3.2090185
Policy mu Mean               -0.03593303
Policy mu Std                1.5040265
Policy mu Max                4.8441367
Policy mu Min                -2.9562032
Policy log std Mean          -0.82913214
Policy log std Std           0.44514528
Policy log std Max           0.19143474
Policy log std Min           -2.79435
Z mean eval                  2.4622967
Z variance eval              0.016104715
total_rewards                [10309.50387781 10373.09447101 10522.88127405 10584.84343678
 10453.59961952 10583.07468068 10583.05694149 10339.17421951
 10617.96942951 10697.08748903]
total_rewards_mean           10506.428543939619
total_rewards_std            124.20971591063993
total_rewards_max            10697.087489032472
total_rewards_min            10309.503877807118
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               27.218079402577132
(Previous) Eval Time (s)     22.29121550731361
Sample Time (s)              16.15335639892146
Epoch Time (s)               65.6626513088122
Total Train Time (s)         31960.586587396916
Epoch                        477
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:50:56.292510 UTC | [2020_01_10_08_58_14] Iteration #477 | Epoch Duration: 66.35389375686646
2020-01-10 17:50:56.292803 UTC | [2020_01_10_08_58_14] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4620636
Z variance train             0.016136883
KL Divergence                37.857986
KL Loss                      3.7857988
QF Loss                      409.92462
VF Loss                      108.38352
Policy Loss                  -4158.7935
Q Predictions Mean           4166.915
Q Predictions Std            414.3895
Q Predictions Max            4680.535
Q Predictions Min            2871.2815
V Predictions Mean           4163.202
V Predictions Std            413.8257
V Predictions Max            4658.3496
V Predictions Min            2869.732
Log Pis Mean                 6.437214
Log Pis Std                  3.6398573
Log Pis Max                  16.608263
Log Pis Min                  -4.691734
Policy mu Mean               -0.06809348
Policy mu Std                1.5200388
Policy mu Max                2.8362582
Policy mu Min                -2.726579
Policy log std Mean          -0.82521456
Policy log std Std           0.42843166
Policy log std Max           -0.18691221
Policy log std Min           -2.9777257
Z mean eval                  2.4479167
Z variance eval              0.014556763
total_rewards                [10223.11786513 10152.05495042 10329.8708364  10350.41429163
 10247.09969977 10353.99256923 10249.39317464 10344.96873409
 10292.10028096 10174.3452427 ]
total_rewards_mean           10271.735764495876
total_rewards_std            70.27958355585966
total_rewards_max            10353.99256923444
total_rewards_min            10152.054950418378
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               29.23089164821431
(Previous) Eval Time (s)     22.982163484208286
Sample Time (s)              16.34353065956384
Epoch Time (s)               68.55658579198644
Total Train Time (s)         32028.43184517324
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:52:04.143132 UTC | [2020_01_10_08_58_14] Iteration #478 | Epoch Duration: 67.85010433197021
2020-01-10 17:52:04.143356 UTC | [2020_01_10_08_58_14] Iteration #478 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.447738
Z variance train             0.014542821
KL Divergence                37.877777
KL Loss                      3.7877777
QF Loss                      312.65024
VF Loss                      150.97766
Policy Loss                  -4097.1924
Q Predictions Mean           4103.7266
Q Predictions Std            456.24918
Q Predictions Max            4612.633
Q Predictions Min            2830.5496
V Predictions Mean           4097.449
V Predictions Std            454.26993
V Predictions Max            4597.0454
V Predictions Min            2822.5723
Log Pis Mean                 6.180944
Log Pis Std                  3.8125472
Log Pis Max                  15.019434
Log Pis Min                  -7.6173973
Policy mu Mean               -0.07851965
Policy mu Std                1.5092459
Policy mu Max                3.0591774
Policy mu Min                -2.8739507
Policy log std Mean          -0.83122796
Policy log std Std           0.44153723
Policy log std Max           -0.103705525
Policy log std Min           -3.1346955
Z mean eval                  2.4334707
Z variance eval              0.011230507
total_rewards                [10301.46453865 10587.17283705 10659.50228467 10019.67631971
 10500.83456852 10529.71132729 10775.54141525 10685.17821388
 10517.67068448 10667.21700507]
total_rewards_mean           10524.396919456758
total_rewards_std            208.94650860139694
total_rewards_max            10775.5414152532
total_rewards_min            10019.676319714747
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               28.49893170176074
(Previous) Eval Time (s)     22.27538927597925
Sample Time (s)              17.32697010692209
Epoch Time (s)               68.10129108466208
Total Train Time (s)         32095.968284634408
Epoch                        479
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:53:11.683260 UTC | [2020_01_10_08_58_14] Iteration #479 | Epoch Duration: 67.53974485397339
2020-01-10 17:53:11.683426 UTC | [2020_01_10_08_58_14] Iteration #479 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4336503
Z variance train             0.011244021
KL Divergence                38.636677
KL Loss                      3.8636677
QF Loss                      600.1211
VF Loss                      216.5918
Policy Loss                  -4057.3132
Q Predictions Mean           4068.46
Q Predictions Std            553.7093
Q Predictions Max            4611.0938
Q Predictions Min            101.45009
V Predictions Mean           4055.9578
V Predictions Std            554.1892
V Predictions Max            4565.844
V Predictions Min            48.489967
Log Pis Mean                 6.1603994
Log Pis Std                  4.093764
Log Pis Max                  20.850014
Log Pis Min                  -4.2675934
Policy mu Mean               0.008725824
Policy mu Std                1.5343881
Policy mu Max                2.885206
Policy mu Min                -3.5897608
Policy log std Mean          -0.82155305
Policy log std Std           0.43798375
Policy log std Max           -0.0025655031
Policy log std Min           -3.0248098
Z mean eval                  2.4552681
Z variance eval              0.00923677
total_rewards                [10209.89509681 10101.64061206 10131.38451167 10522.27675429
 10026.2843744  10098.23552199 10219.80483997 10166.58011462
 10139.86412342 10159.580485  ]
total_rewards_mean           10177.554643421763
total_rewards_std            126.72696723440006
total_rewards_max            10522.276754289325
total_rewards_min            10026.284374403032
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               30.133423866704106
(Previous) Eval Time (s)     21.713507706765085
Sample Time (s)              15.390529030002654
Epoch Time (s)               67.23746060347185
Total Train Time (s)         32164.036441881675
Epoch                        480
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:54:19.755307 UTC | [2020_01_10_08_58_14] Iteration #480 | Epoch Duration: 68.07175850868225
2020-01-10 17:54:19.755482 UTC | [2020_01_10_08_58_14] Iteration #480 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.455669
Z variance train             0.009226562
KL Divergence                39.30479
KL Loss                      3.930479
QF Loss                      452.45947
VF Loss                      207.10806
Policy Loss                  -4156.051
Q Predictions Mean           4164.2676
Q Predictions Std            402.72925
Q Predictions Max            4677.0874
Q Predictions Min            2855.4575
V Predictions Mean           4155.291
V Predictions Std            400.6889
V Predictions Max            4659.26
V Predictions Min            2854.3367
Log Pis Mean                 6.36715
Log Pis Std                  4.015387
Log Pis Max                  15.685698
Log Pis Min                  -5.754486
Policy mu Mean               0.061653752
Policy mu Std                1.5213102
Policy mu Max                3.1744707
Policy mu Min                -2.7592893
Policy log std Mean          -0.8309038
Policy log std Std           0.4302819
Policy log std Max           -0.13537645
Policy log std Min           -2.7379894
Z mean eval                  2.4514625
Z variance eval              0.006820048
total_rewards                [ 9848.24031783  9626.5724778   9845.94603328  9872.94625616
  9994.18761209 10030.03460944  9502.99723615  9797.82574789
  9904.21593985  9949.55863862]
total_rewards_mean           9837.25248691189
total_rewards_std            154.2815018130108
total_rewards_max            10030.034609442604
total_rewards_min            9502.997236148583
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               28.625141341239214
(Previous) Eval Time (s)     22.547523226123303
Sample Time (s)              15.136171773541719
Epoch Time (s)               66.30883634090424
Total Train Time (s)         32230.436704710126
Epoch                        481
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:55:26.161666 UTC | [2020_01_10_08_58_14] Iteration #481 | Epoch Duration: 66.40603375434875
2020-01-10 17:55:26.161892 UTC | [2020_01_10_08_58_14] Iteration #481 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4574277
Z variance train             0.0067599667
KL Divergence                40.61949
KL Loss                      4.0619493
QF Loss                      1301.7401
VF Loss                      3006.373
Policy Loss                  -4178.601
Q Predictions Mean           4197.037
Q Predictions Std            428.4629
Q Predictions Max            4737.6235
Q Predictions Min            2856.9026
V Predictions Mean           4158.9595
V Predictions Std            422.73822
V Predictions Max            4722.2715
V Predictions Min            2848.0725
Log Pis Mean                 7.1434903
Log Pis Std                  3.9239542
Log Pis Max                  16.660767
Log Pis Min                  -3.5511909
Policy mu Mean               -0.054041777
Policy mu Std                1.6052067
Policy mu Max                3.6566005
Policy mu Min                -3.2774384
Policy log std Mean          -0.8219812
Policy log std Std           0.44151756
Policy log std Max           -0.09801239
Policy log std Min           -2.7921996
Z mean eval                  2.4452615
Z variance eval              0.0043897517
total_rewards                [ 4280.61382451 10014.57418533 10416.77038686 10310.88201469
 10167.90294326 10417.25013799 10108.97381272 10473.04408897
  3904.85199678 10438.77811446]
total_rewards_mean           9053.364150555877
total_rewards_std            2486.0014479499764
total_rewards_max            10473.044088968523
total_rewards_min            3904.85199677777
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               28.003697170875967
(Previous) Eval Time (s)     22.644472253043205
Sample Time (s)              15.352066084276885
Epoch Time (s)               66.00023550819606
Total Train Time (s)         32296.256358130835
Epoch                        482
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:56:31.986473 UTC | [2020_01_10_08_58_14] Iteration #482 | Epoch Duration: 65.82437348365784
2020-01-10 17:56:31.986694 UTC | [2020_01_10_08_58_14] Iteration #482 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4459836
Z variance train             0.0043898253
KL Divergence                41.30559
KL Loss                      4.1305594
QF Loss                      1251.5483
VF Loss                      267.47113
Policy Loss                  -4127.2256
Q Predictions Mean           4136.4146
Q Predictions Std            454.26755
Q Predictions Max            4701.529
Q Predictions Min            2760.069
V Predictions Mean           4128.522
V Predictions Std            453.97122
V Predictions Max            4704.8477
V Predictions Min            2670.7495
Log Pis Mean                 6.6376266
Log Pis Std                  3.7857256
Log Pis Max                  18.740017
Log Pis Min                  -3.4039228
Policy mu Mean               -0.0123479
Policy mu Std                1.5362352
Policy mu Max                3.7809494
Policy mu Min                -2.8209798
Policy log std Mean          -0.82642895
Policy log std Std           0.43426543
Policy log std Max           -0.12905523
Policy log std Min           -2.9492402
Z mean eval                  2.4588208
Z variance eval              0.004715325
total_rewards                [ 9952.06211203 10310.40521029 10029.46130584 10310.40309432
 10418.02217761 10087.58460945  9969.18434538  9966.6029043
  9981.89447465 10079.22815931]
total_rewards_mean           10110.484839318411
total_rewards_std            162.75195071801093
total_rewards_max            10418.02217761061
total_rewards_min            9952.06211202694
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               29.266057051718235
(Previous) Eval Time (s)     22.468360872007906
Sample Time (s)              15.804015766829252
Epoch Time (s)               67.5384336905554
Total Train Time (s)         32363.911602760665
Epoch                        483
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:57:39.644467 UTC | [2020_01_10_08_58_14] Iteration #483 | Epoch Duration: 67.65762972831726
2020-01-10 17:57:39.644625 UTC | [2020_01_10_08_58_14] Iteration #483 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4587786
Z variance train             0.004710427
KL Divergence                41.075386
KL Loss                      4.1075387
QF Loss                      586.9843
VF Loss                      160.27863
Policy Loss                  -4066.0278
Q Predictions Mean           4069.4214
Q Predictions Std            601.2933
Q Predictions Max            4658.8267
Q Predictions Min            11.889787
V Predictions Mean           4062.9758
V Predictions Std            602.82245
V Predictions Max            4649.736
V Predictions Min            7.800218
Log Pis Mean                 6.4250913
Log Pis Std                  3.702931
Log Pis Max                  15.250944
Log Pis Min                  -3.240752
Policy mu Mean               -0.075868055
Policy mu Std                1.520837
Policy mu Max                3.1935654
Policy mu Min                -2.9761336
Policy log std Mean          -0.7989578
Policy log std Std           0.4019386
Policy log std Max           -0.053173363
Policy log std Min           -2.7840524
Z mean eval                  2.4289765
Z variance eval              0.009516081
total_rewards                [10114.95134054 10300.13206789 10308.27610087  9652.64911698
 10670.63109228 10298.93951125 10295.29529179 10034.39407689
  9880.00989681 10098.55835584]
total_rewards_mean           10165.383685113255
total_rewards_std            264.0202181118127
total_rewards_max            10670.631092278454
total_rewards_min            9652.649116976443
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               27.710221581161022
(Previous) Eval Time (s)     22.587272233329713
Sample Time (s)              16.175837974529713
Epoch Time (s)               66.47333178902045
Total Train Time (s)         32430.34083741717
Epoch                        484
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:58:46.079981 UTC | [2020_01_10_08_58_14] Iteration #484 | Epoch Duration: 66.43520975112915
2020-01-10 17:58:46.080222 UTC | [2020_01_10_08_58_14] Iteration #484 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.429558
Z variance train             0.009499614
KL Divergence                40.695724
KL Loss                      4.0695724
QF Loss                      303.57208
VF Loss                      129.5724
Policy Loss                  -4114.9956
Q Predictions Mean           4123.6187
Q Predictions Std            455.90967
Q Predictions Max            4665.3296
Q Predictions Min            2871.8013
V Predictions Mean           4112.1606
V Predictions Std            453.3482
V Predictions Max            4645.825
V Predictions Min            2870.5962
Log Pis Mean                 6.581879
Log Pis Std                  3.6109722
Log Pis Max                  15.624053
Log Pis Min                  -3.503376
Policy mu Mean               0.008311284
Policy mu Std                1.5598141
Policy mu Max                2.994277
Policy mu Min                -3.2702389
Policy log std Mean          -0.8001525
Policy log std Std           0.4134642
Policy log std Max           -0.116568744
Policy log std Min           -2.6548157
Z mean eval                  2.4281402
Z variance eval              0.018292638
total_rewards                [10025.29007835 10371.82570854 10340.79944049 10158.76100711
 10398.53609095 10420.16678794 10288.56994438 10618.19190493
 10376.30682835 10311.15533969]
total_rewards_mean           10330.960313073347
total_rewards_std            149.70819529741416
total_rewards_max            10618.191904929265
total_rewards_min            10025.290078354365
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               30.66827335488051
(Previous) Eval Time (s)     22.548855585046113
Sample Time (s)              15.777948803268373
Epoch Time (s)               68.995077743195
Total Train Time (s)         32499.974451511633
Epoch                        485
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 17:59:55.722328 UTC | [2020_01_10_08_58_14] Iteration #485 | Epoch Duration: 69.64188694953918
2020-01-10 17:59:55.722651 UTC | [2020_01_10_08_58_14] Iteration #485 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4271812
Z variance train             0.018279646
KL Divergence                39.962963
KL Loss                      3.9962964
QF Loss                      1367.6482
VF Loss                      241.22137
Policy Loss                  -3966.078
Q Predictions Mean           3976.2717
Q Predictions Std            567.3292
Q Predictions Max            4549.6904
Q Predictions Min            -375.04123
V Predictions Mean           3971.6152
V Predictions Std            564.8248
V Predictions Max            4535.7505
V Predictions Min            -408.81546
Log Pis Mean                 6.7604194
Log Pis Std                  3.9881997
Log Pis Max                  17.477184
Log Pis Min                  -6.485217
Policy mu Mean               -0.071176715
Policy mu Std                1.5666649
Policy mu Max                3.2824965
Policy mu Min                -3.1319633
Policy log std Mean          -0.81060576
Policy log std Std           0.4191826
Policy log std Max           0.16409183
Policy log std Min           -2.830651
Z mean eval                  2.4444475
Z variance eval              0.00770647
total_rewards                [ 9879.71332088 10164.69852759 10207.31656403  9970.118476
 10226.56543879 10050.01575068 10055.6583097  10091.80641079
 10503.72732378 10245.82274557]
total_rewards_mean           10139.544286781169
total_rewards_std            164.39928541830952
total_rewards_max            10503.727323780735
total_rewards_min            9879.713320881203
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               29.944394026882946
(Previous) Eval Time (s)     23.19538572616875
Sample Time (s)              16.163821850903332
Epoch Time (s)               69.30360160395503
Total Train Time (s)         32568.282637955155
Epoch                        486
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:01:04.034722 UTC | [2020_01_10_08_58_14] Iteration #486 | Epoch Duration: 68.31184506416321
2020-01-10 18:01:04.034943 UTC | [2020_01_10_08_58_14] Iteration #486 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4414568
Z variance train             0.0076814853
KL Divergence                40.990807
KL Loss                      4.0990806
QF Loss                      610.548
VF Loss                      1742.664
Policy Loss                  -4086.7957
Q Predictions Mean           4098.615
Q Predictions Std            434.11197
Q Predictions Max            4593.0933
Q Predictions Min            2794.2742
V Predictions Mean           4111.9653
V Predictions Std            434.8808
V Predictions Max            4611.9863
V Predictions Min            2813.737
Log Pis Mean                 6.5652494
Log Pis Std                  3.5860543
Log Pis Max                  14.765797
Log Pis Min                  -2.8061194
Policy mu Mean               0.029399535
Policy mu Std                1.5394249
Policy mu Max                2.999325
Policy mu Min                -2.993422
Policy log std Mean          -0.8173595
Policy log std Std           0.43072462
Policy log std Max           -0.10977754
Policy log std Min           -2.8456516
Z mean eval                  2.4484487
Z variance eval              0.008533696
total_rewards                [10150.30324455 10102.45538775 10488.79042793 10326.36075553
 10404.69389648 10369.03225395 10494.36646869 10355.10784526
 10336.84152838 10446.38854839]
total_rewards_mean           10347.434035692222
total_rewards_std            124.33752379382322
total_rewards_max            10494.366468694418
total_rewards_min            10102.45538774937
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               30.036942396778613
(Previous) Eval Time (s)     22.203386074863374
Sample Time (s)              16.06539364764467
Epoch Time (s)               68.30572211928666
Total Train Time (s)         32636.661081598606
Epoch                        487
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:02:12.420441 UTC | [2020_01_10_08_58_14] Iteration #487 | Epoch Duration: 68.38532304763794
2020-01-10 18:02:12.420689 UTC | [2020_01_10_08_58_14] Iteration #487 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4469285
Z variance train             0.008491771
KL Divergence                40.740314
KL Loss                      4.0740314
QF Loss                      518.56274
VF Loss                      398.2962
Policy Loss                  -4138.891
Q Predictions Mean           4152.4443
Q Predictions Std            545.4242
Q Predictions Max            4651.394
Q Predictions Min            16.73416
V Predictions Mean           4152.33
V Predictions Std            548.5919
V Predictions Max            4641.0933
V Predictions Min            7.4571676
Log Pis Mean                 7.033407
Log Pis Std                  3.7518778
Log Pis Max                  19.02957
Log Pis Min                  -3.8697429
Policy mu Mean               -0.015733771
Policy mu Std                1.5690024
Policy mu Max                3.4696383
Policy mu Min                -3.8665166
Policy log std Mean          -0.83729196
Policy log std Std           0.46854642
Policy log std Max           -0.01293844
Policy log std Min           -2.9148097
Z mean eval                  2.4300225
Z variance eval              0.011278582
total_rewards                [10179.30392397 10429.28046041 10351.40855099 10196.47338728
 10460.8309381  10091.79488187 10140.19550804 10327.52010567
 10335.58223511 10358.1792196 ]
total_rewards_mean           10287.056921104331
total_rewards_std            119.63613865974817
total_rewards_max            10460.830938095069
total_rewards_min            10091.794881871243
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               29.653971792198718
(Previous) Eval Time (s)     22.282710274215788
Sample Time (s)              16.893676930107176
Epoch Time (s)               68.83035899652168
Total Train Time (s)         32705.603405174334
Epoch                        488
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:03:21.365031 UTC | [2020_01_10_08_58_14] Iteration #488 | Epoch Duration: 68.94417548179626
2020-01-10 18:03:21.365186 UTC | [2020_01_10_08_58_14] Iteration #488 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4305847
Z variance train             0.011371586
KL Divergence                40.182484
KL Loss                      4.0182486
QF Loss                      604.14996
VF Loss                      137.36743
Policy Loss                  -4150.6587
Q Predictions Mean           4160.687
Q Predictions Std            402.22092
Q Predictions Max            4626.0957
Q Predictions Min            2889.1816
V Predictions Mean           4148.992
V Predictions Std            400.29553
V Predictions Max            4604.232
V Predictions Min            2884.513
Log Pis Mean                 6.634948
Log Pis Std                  3.8896062
Log Pis Max                  16.970272
Log Pis Min                  -3.6514885
Policy mu Mean               -0.012709715
Policy mu Std                1.5670764
Policy mu Max                3.157988
Policy mu Min                -2.8549497
Policy log std Mean          -0.8078497
Policy log std Std           0.41999406
Policy log std Max           -0.16419655
Policy log std Min           -2.9249663
Z mean eval                  2.4150321
Z variance eval              0.012160939
total_rewards                [10437.12220071 10438.12124627 10364.26554377 10305.56107174
 10394.7115057  10495.50928201 10452.39657813 10501.11189534
 10548.2807156  10232.57960231]
total_rewards_mean           10416.96596415744
total_rewards_std            90.71068207053679
total_rewards_max            10548.280715595329
total_rewards_min            10232.579602313303
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               30.52820779522881
(Previous) Eval Time (s)     22.396229594945908
Sample Time (s)              16.16908571496606
Epoch Time (s)               69.09352310514078
Total Train Time (s)         32774.56753402995
Epoch                        489
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:04:30.338939 UTC | [2020_01_10_08_58_14] Iteration #489 | Epoch Duration: 68.97359275817871
2020-01-10 18:04:30.339253 UTC | [2020_01_10_08_58_14] Iteration #489 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4182608
Z variance train             0.012275554
KL Divergence                40.39769
KL Loss                      4.039769
QF Loss                      798.571
VF Loss                      341.24292
Policy Loss                  -4143.028
Q Predictions Mean           4149.034
Q Predictions Std            428.41187
Q Predictions Max            4673.2485
Q Predictions Min            2781.639
V Predictions Mean           4130.204
V Predictions Std            425.17493
V Predictions Max            4668.9526
V Predictions Min            2789.2834
Log Pis Mean                 6.1081724
Log Pis Std                  3.8184474
Log Pis Max                  17.186977
Log Pis Min                  -3.2340622
Policy mu Mean               0.025895894
Policy mu Std                1.5017838
Policy mu Max                5.6183586
Policy mu Min                -2.8553352
Policy log std Mean          -0.81924003
Policy log std Std           0.44320643
Policy log std Max           0.6540791
Policy log std Min           -3.01722
Z mean eval                  2.4656248
Z variance eval              0.007809372
total_rewards                [10235.29987877 10358.52131325 10257.33196431 10431.35858914
 10187.47417894 10204.44420427 10119.91453996 10419.7450762
 10274.27230333 10081.14585508]
total_rewards_mean           10256.950790325815
total_rewards_std            111.92668282721718
total_rewards_max            10431.358589142854
total_rewards_min            10081.145855083625
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               29.62876795604825
(Previous) Eval Time (s)     22.27591415401548
Sample Time (s)              15.549145673401654
Epoch Time (s)               67.45382778346539
Total Train Time (s)         32842.25170133589
Epoch                        490
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:05:38.025247 UTC | [2020_01_10_08_58_14] Iteration #490 | Epoch Duration: 67.68577289581299
2020-01-10 18:05:38.025458 UTC | [2020_01_10_08_58_14] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4664407
Z variance train             0.007811436
KL Divergence                42.413242
KL Loss                      4.2413244
QF Loss                      502.6807
VF Loss                      132.05397
Policy Loss                  -4174.79
Q Predictions Mean           4180.1934
Q Predictions Std            439.12738
Q Predictions Max            4660.119
Q Predictions Min            2828.686
V Predictions Mean           4169.168
V Predictions Std            436.88947
V Predictions Max            4634.7144
V Predictions Min            2832.9492
Log Pis Mean                 6.6409597
Log Pis Std                  3.7255292
Log Pis Max                  17.464159
Log Pis Min                  -4.6543865
Policy mu Mean               0.013574821
Policy mu Std                1.5422801
Policy mu Max                2.947519
Policy mu Min                -2.6118174
Policy log std Mean          -0.8324434
Policy log std Std           0.45538387
Policy log std Max           -0.093458295
Policy log std Min           -3.0266404
Z mean eval                  2.423424
Z variance eval              0.007579236
total_rewards                [9618.19540767 9766.32038942 9907.48200847 9717.64986871 9566.93689862
 9473.32006637 9651.29044108 9821.02259148 9693.8052329  9753.15688595]
total_rewards_mean           9696.917979066788
total_rewards_std            119.71983889816205
total_rewards_max            9907.482008474242
total_rewards_min            9473.32006636926
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               30.398993778973818
(Previous) Eval Time (s)     22.507616977673024
Sample Time (s)              16.79193833237514
Epoch Time (s)               69.69854908902198
Total Train Time (s)         32911.52714868775
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:06:47.306759 UTC | [2020_01_10_08_58_14] Iteration #491 | Epoch Duration: 69.28115773200989
2020-01-10 18:06:47.307001 UTC | [2020_01_10_08_58_14] Iteration #491 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4247785
Z variance train             0.0075869365
KL Divergence                41.909576
KL Loss                      4.1909575
QF Loss                      891.20026
VF Loss                      183.08855
Policy Loss                  -4067.301
Q Predictions Mean           4076.892
Q Predictions Std            429.17178
Q Predictions Max            4592.283
Q Predictions Min            2843.6616
V Predictions Mean           4071.1475
V Predictions Std            430.62613
V Predictions Max            4588.9536
V Predictions Min            2831.156
Log Pis Mean                 6.2205324
Log Pis Std                  3.8431876
Log Pis Max                  14.067902
Log Pis Min                  -3.621254
Policy mu Mean               -0.0919955
Policy mu Std                1.5258725
Policy mu Max                2.9595442
Policy mu Min                -3.3719625
Policy log std Mean          -0.80349857
Policy log std Std           0.4339738
Policy log std Max           -0.056034803
Policy log std Min           -2.9400494
Z mean eval                  2.4528885
Z variance eval              0.0070343455
total_rewards                [10003.76901731 10423.87811518 10497.16384108 10407.92512626
 10467.01427603 10578.42172649 10475.12518252 10583.98195647
 10436.04282463 10491.43013866]
total_rewards_mean           10436.475220463208
total_rewards_std            154.67556144512707
total_rewards_max            10583.98195647047
total_rewards_min            10003.769017309349
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               27.489015161059797
(Previous) Eval Time (s)     22.08995296433568
Sample Time (s)              17.388549830764532
Epoch Time (s)               66.96751795616001
Total Train Time (s)         32978.56086644484
Epoch                        492
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:07:54.344286 UTC | [2020_01_10_08_58_14] Iteration #492 | Epoch Duration: 67.03710079193115
2020-01-10 18:07:54.344440 UTC | [2020_01_10_08_58_14] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4512756
Z variance train             0.0070460006
KL Divergence                41.610893
KL Loss                      4.1610894
QF Loss                      844.09686
VF Loss                      504.55188
Policy Loss                  -4153.963
Q Predictions Mean           4168.7783
Q Predictions Std            433.15973
Q Predictions Max            4645.9785
Q Predictions Min            2799.9653
V Predictions Mean           4171.3887
V Predictions Std            431.4092
V Predictions Max            4638.5317
V Predictions Min            2865.363
Log Pis Mean                 6.6417274
Log Pis Std                  3.9258783
Log Pis Max                  18.891844
Log Pis Min                  -8.537319
Policy mu Mean               -0.07936889
Policy mu Std                1.5332325
Policy mu Max                3.0034437
Policy mu Min                -3.0577948
Policy log std Mean          -0.8170378
Policy log std Std           0.4412075
Policy log std Max           -0.03758931
Policy log std Min           -2.8545585
Z mean eval                  2.4280615
Z variance eval              0.06588973
total_rewards                [10122.94120836 10095.26754255  9977.09665798 10449.00048291
  9957.14692719  9990.12549814 10289.70031592 10038.38686168
 10337.05046271 10097.66758759]
total_rewards_mean           10135.43835450433
total_rewards_std            159.17181010154556
total_rewards_max            10449.000482913145
total_rewards_min            9957.146927194524
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               25.96663074195385
(Previous) Eval Time (s)     22.15922225918621
Sample Time (s)              15.372200926300138
Epoch Time (s)               63.498053927440196
Total Train Time (s)         33042.68017872842
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:08:58.469689 UTC | [2020_01_10_08_58_14] Iteration #493 | Epoch Duration: 64.1251106262207
2020-01-10 18:08:58.469918 UTC | [2020_01_10_08_58_14] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4277391
Z variance train             0.06609429
KL Divergence                39.790306
KL Loss                      3.9790306
QF Loss                      477.87598
VF Loss                      192.44856
Policy Loss                  -4163.6416
Q Predictions Mean           4171.0024
Q Predictions Std            411.40076
Q Predictions Max            4688.448
Q Predictions Min            2862.4822
V Predictions Mean           4167.549
V Predictions Std            410.26767
V Predictions Max            4693.5806
V Predictions Min            2862.9468
Log Pis Mean                 6.636588
Log Pis Std                  4.076968
Log Pis Max                  20.668112
Log Pis Min                  -5.044341
Policy mu Mean               0.0072165877
Policy mu Std                1.5357466
Policy mu Max                3.2611914
Policy mu Min                -3.055043
Policy log std Mean          -0.8385587
Policy log std Std           0.45467833
Policy log std Max           -0.05459085
Policy log std Min           -2.8982038
Z mean eval                  2.4549084
Z variance eval              0.03522168
total_rewards                [9276.21659584 9562.90330588 9351.20195147 9554.53212237 9528.01784484
 9210.29662418 9361.52552673 9762.17174848 9852.87996508 9556.78781951]
total_rewards_mean           9501.653350438679
total_rewards_std            194.80618343437914
total_rewards_max            9852.879965078975
total_rewards_min            9210.296624184091
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               29.215172687079757
(Previous) Eval Time (s)     22.785978239029646
Sample Time (s)              15.535302095580846
Epoch Time (s)               67.53645302169025
Total Train Time (s)         33109.806289688684
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:10:05.603746 UTC | [2020_01_10_08_58_14] Iteration #494 | Epoch Duration: 67.1336281299591
2020-01-10 18:10:05.604033 UTC | [2020_01_10_08_58_14] Iteration #494 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4503999
Z variance train             0.03498245
KL Divergence                39.35322
KL Loss                      3.9353223
QF Loss                      3144.7063
VF Loss                      851.3788
Policy Loss                  -4170.857
Q Predictions Mean           4188.4697
Q Predictions Std            452.80576
Q Predictions Max            4754.176
Q Predictions Min            2317.3005
V Predictions Mean           4188.2676
V Predictions Std            447.21603
V Predictions Max            4734.193
V Predictions Min            2410.3892
Log Pis Mean                 7.144004
Log Pis Std                  4.1477885
Log Pis Max                  16.63244
Log Pis Min                  -4.4231443
Policy mu Mean               -0.07788243
Policy mu Std                1.6042625
Policy mu Max                3.3784776
Policy mu Min                -3.3464231
Policy log std Mean          -0.8144544
Policy log std Std           0.42278972
Policy log std Max           0.093808055
Policy log std Min           -2.9734404
Z mean eval                  2.4264314
Z variance eval              0.03444892
total_rewards                [10104.92412138 10110.70152664 10318.3965342  10209.27709924
 10211.71876074 10137.71012664 10189.24968895 10347.74133296
 10391.47656776 10097.32998137]
total_rewards_mean           10211.85257398768
total_rewards_std            101.42851959538235
total_rewards_max            10391.476567756752
total_rewards_min            10097.329981368322
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               28.380645130295306
(Previous) Eval Time (s)     22.38287849118933
Sample Time (s)              15.629903918597847
Epoch Time (s)               66.39342754008248
Total Train Time (s)         33176.530198963825
Epoch                        495
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:11:12.335523 UTC | [2020_01_10_08_58_14] Iteration #495 | Epoch Duration: 66.73126339912415
2020-01-10 18:11:12.335818 UTC | [2020_01_10_08_58_14] Iteration #495 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4269075
Z variance train             0.034344412
KL Divergence                38.334576
KL Loss                      3.8334577
QF Loss                      359.2766
VF Loss                      147.11438
Policy Loss                  -4129.611
Q Predictions Mean           4136.2134
Q Predictions Std            456.286
Q Predictions Max            4729.1357
Q Predictions Min            2877.1064
V Predictions Mean           4124.3325
V Predictions Std            455.30283
V Predictions Max            4716.6606
V Predictions Min            2876.271
Log Pis Mean                 6.6544485
Log Pis Std                  3.947176
Log Pis Max                  16.280947
Log Pis Min                  -4.73084
Policy mu Mean               -0.04270935
Policy mu Std                1.5212337
Policy mu Max                3.5447986
Policy mu Min                -3.6207497
Policy log std Mean          -0.83568984
Policy log std Std           0.4475957
Policy log std Max           -0.07627115
Policy log std Min           -2.9376163
Z mean eval                  2.4289732
Z variance eval              0.02915074
total_rewards                [ 9936.84490529 10545.44995106 10421.28305725 10456.91997982
 10284.077086   10623.01637762  9997.29118576 10495.05260111
 10523.03243829 10520.80556705]
total_rewards_mean           10380.377314923302
total_rewards_std            223.52303316984336
total_rewards_max            10623.016377617972
total_rewards_min            9936.844905288057
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               26.641451673116535
(Previous) Eval Time (s)     22.720458760857582
Sample Time (s)              16.335673130117357
Epoch Time (s)               65.69758356409147
Total Train Time (s)         33241.77879739506
Epoch                        496
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:12:17.588432 UTC | [2020_01_10_08_58_14] Iteration #496 | Epoch Duration: 65.25240135192871
2020-01-10 18:12:17.588626 UTC | [2020_01_10_08_58_14] Iteration #496 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4316106
Z variance train             0.029018715
KL Divergence                38.200245
KL Loss                      3.8200245
QF Loss                      539.23206
VF Loss                      310.94385
Policy Loss                  -4121.487
Q Predictions Mean           4130.139
Q Predictions Std            571.2756
Q Predictions Max            4665.5806
Q Predictions Min            -50.926815
V Predictions Mean           4112.024
V Predictions Std            569.7373
V Predictions Max            4639.4883
V Predictions Min            -91.50416
Log Pis Mean                 6.533255
Log Pis Std                  3.8235238
Log Pis Max                  23.796913
Log Pis Min                  -3.1162248
Policy mu Mean               -0.035579186
Policy mu Std                1.5338948
Policy mu Max                4.086043
Policy mu Min                -2.8438
Policy log std Mean          -0.8196833
Policy log std Std           0.44359183
Policy log std Max           -0.071038365
Policy log std Min           -3.0785675
Z mean eval                  2.4270434
Z variance eval              0.024038257
total_rewards                [10572.95822879 10788.52335226 10339.42070942 10771.17531248
 10552.47982605 10583.51195489 10468.28856844 10512.22503636
 10550.55480546 10486.06586118]
total_rewards_mean           10562.520365532508
total_rewards_std            127.45031160506038
total_rewards_max            10788.523352261067
total_rewards_min            10339.420709417294
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               28.805050510913134
(Previous) Eval Time (s)     22.275027132127434
Sample Time (s)              16.600750314071774
Epoch Time (s)               67.68082795711234
Total Train Time (s)         33309.2371028848
Epoch                        497
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:13:25.051561 UTC | [2020_01_10_08_58_14] Iteration #497 | Epoch Duration: 67.46278548240662
2020-01-10 18:13:25.051768 UTC | [2020_01_10_08_58_14] Iteration #497 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4238434
Z variance train             0.024043433
KL Divergence                37.373013
KL Loss                      3.7373013
QF Loss                      1179.1129
VF Loss                      281.88577
Policy Loss                  -4015.0679
Q Predictions Mean           4023.3804
Q Predictions Std            537.59485
Q Predictions Max            4602.806
Q Predictions Min            394.72144
V Predictions Mean           4018.1333
V Predictions Std            532.2564
V Predictions Max            4596.6157
V Predictions Min            559.7024
Log Pis Mean                 6.472979
Log Pis Std                  4.162854
Log Pis Max                  26.707241
Log Pis Min                  -3.7449577
Policy mu Mean               -0.03214096
Policy mu Std                1.5107342
Policy mu Max                3.7463675
Policy mu Min                -2.9919782
Policy log std Mean          -0.83369064
Policy log std Std           0.45239812
Policy log std Max           -0.09869397
Policy log std Min           -2.7860289
Z mean eval                  2.403609
Z variance eval              0.01789214
total_rewards                [10429.2836507  10710.22077953 10383.13666988 10534.88306101
 10524.61775266 10610.09806822 10751.62607585 10700.01171997
 10503.61381942 10521.85668756]
total_rewards_mean           10566.934828481255
total_rewards_std            116.53475638897899
total_rewards_max            10751.626075850247
total_rewards_min            10383.13666988158
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               29.774192839860916
(Previous) Eval Time (s)     22.056707287207246
Sample Time (s)              16.090643369592726
Epoch Time (s)               67.92154349666089
Total Train Time (s)         33377.4149875436
Epoch                        498
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:14:33.234427 UTC | [2020_01_10_08_58_14] Iteration #498 | Epoch Duration: 68.18249034881592
2020-01-10 18:14:33.234607 UTC | [2020_01_10_08_58_14] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 2.4027257
Z variance train             0.017925348
KL Divergence                37.893543
KL Loss                      3.7893543
QF Loss                      1056.9752
VF Loss                      207.71823
Policy Loss                  -4091.1138
Q Predictions Mean           4095.9026
Q Predictions Std            596.5349
Q Predictions Max            4628.0444
Q Predictions Min            -98.719696
V Predictions Mean           4087.4734
V Predictions Std            590.0769
V Predictions Max            4625.6064
V Predictions Min            -39.47792
Log Pis Mean                 6.3216796
Log Pis Std                  3.5681927
Log Pis Max                  15.05362
Log Pis Min                  -2.781202
Policy mu Mean               -0.07283809
Policy mu Std                1.4949883
Policy mu Max                2.7756395
Policy mu Min                -2.8685544
Policy log std Mean          -0.84899753
Policy log std Std           0.45618072
Policy log std Max           0.00035727024
Policy log std Min           -2.9911087
Z mean eval                  2.416322
Z variance eval              0.01751992
total_rewards                [8132.3776858  8392.19931446 7403.15350992 8254.54517566 8137.90422219
 7641.76016829 8434.14484174 8354.72964793 7318.38896709 7284.23431546]
total_rewards_mean           7935.343784854155
total_rewards_std            445.99789295039557
total_rewards_max            8434.144841739506
total_rewards_min            7284.234315462731
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               29.90423148404807
(Previous) Eval Time (s)     22.31736724311486
Sample Time (s)              15.473231124226004
Epoch Time (s)               67.69482985138893
Total Train Time (s)         33445.24847558467
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:15:41.070871 UTC | [2020_01_10_08_58_14] Iteration #499 | Epoch Duration: 67.83613204956055
2020-01-10 18:15:41.071031 UTC | [2020_01_10_08_58_14] Iteration #499 | Started Training: True
2020-01-10 18:15:41.499362 UTC | [2020_01_10_08_58_14] Variant:
2020-01-10 18:15:41.499734 UTC | [2020_01_10_08_58_14] {
  "env_name": "Humanoid-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 5000
  }
}
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0058326833
Z variance train             0.6952301
KL Divergence                0.1469768
KL Loss                      0.01469768
QF Loss                      1096.0537
VF Loss                      134.23282
Policy Loss                  -11.559128
Q Predictions Mean           0.008233771
Q Predictions Std            0.012814306
Q Predictions Max            0.04206539
Q Predictions Min            -0.02449881
V Predictions Mean           0.0064341715
V Predictions Std            0.013787466
V Predictions Max            0.0484702
V Predictions Min            -0.022130998
Log Pis Mean                 -11.472197
Log Pis Std                  0.8767863
Log Pis Max                  -9.05932
Log Pis Min                  -14.125285
Policy mu Mean               0.0016821767
Policy mu Std                0.010037625
Policy mu Max                0.037136186
Policy mu Min                -0.02831097
Policy log std Mean          8.041704e-05
Policy log std Std           0.010179829
Policy log std Max           0.026718998
Policy log std Min           -0.034992058
Z mean eval                  0.054413926
Z variance eval              0.8308446
total_rewards                [ 76.70637422  76.48264171  76.58868154  76.62822764  94.31105297
  81.44148577  81.25811529  76.86447289 105.14665759  85.33482314]
total_rewards_mean           83.07625327718303
total_rewards_std            9.114305288011114
total_rewards_max            105.14665758764197
total_rewards_min            76.48264170812162
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               28.07400479633361
(Previous) Eval Time (s)     0
Sample Time (s)              19.44052276853472
Epoch Time (s)               47.51452756486833
Total Train Time (s)         48.02341976296157
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:16:29.640994 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #0 | Epoch Duration: 48.027963638305664
2020-01-10 18:16:29.641264 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056043006
Z variance train             0.82817936
KL Divergence                0.056827202
KL Loss                      0.0056827203
QF Loss                      28.805588
VF Loss                      20.434093
Policy Loss                  -40.986233
Q Predictions Mean           29.819742
Q Predictions Std            23.717487
Q Predictions Max            138.1879
Q Predictions Min            17.38671
V Predictions Mean           41.349747
V Predictions Std            23.166662
V Predictions Max            149.95357
V Predictions Min            26.422953
Log Pis Mean                 -11.589502
Log Pis Std                  0.65305054
Log Pis Max                  -8.384132
Log Pis Min                  -13.714687
Policy mu Mean               -0.0053963903
Policy mu Std                0.09200074
Policy mu Max                0.7732209
Policy mu Min                -0.8160324
Policy log std Mean          -0.13393469
Policy log std Std           0.021077141
Policy log std Max           -0.052993372
Policy log std Min           -0.29792815
Z mean eval                  0.0127270995
Z variance eval              0.73557854
total_rewards                [143.38860641  81.1935327   71.57996396  81.4784317   81.58868894
  81.28832453  76.49114456  88.26079724  76.55748878  81.16581498]
total_rewards_mean           86.29927937966238
total_rewards_std            19.477577007405895
total_rewards_max            143.38860640537223
total_rewards_min            71.57996395769614
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               27.85772487707436
(Previous) Eval Time (s)     0.5132128507830203
Sample Time (s)              13.66343351546675
Epoch Time (s)               42.03437124332413
Total Train Time (s)         90.04587569041178
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:17:11.663641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #1 | Epoch Duration: 42.02217936515808
2020-01-10 18:17:11.663856 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011158152
Z variance train             0.72889364
KL Divergence                0.11381082
KL Loss                      0.011381082
QF Loss                      29.734713
VF Loss                      28.66847
Policy Loss                  -53.846725
Q Predictions Mean           42.09821
Q Predictions Std            58.75579
Q Predictions Max            321.2953
Q Predictions Min            17.107006
V Predictions Mean           52.02818
V Predictions Std            59.13592
V Predictions Max            326.20602
V Predictions Min            26.062658
Log Pis Mean                 -10.932015
Log Pis Std                  2.1012826
Log Pis Max                  -0.5960698
Log Pis Min                  -14.025029
Policy mu Mean               0.006129952
Policy mu Std                0.2508453
Policy mu Max                1.5143558
Policy mu Min                -1.2096674
Policy log std Mean          -0.14960432
Policy log std Std           0.054979846
Policy log std Max           -0.05516535
Policy log std Min           -0.5305394
Z mean eval                  0.012813196
Z variance eval              0.66823655
total_rewards                [ 94.91368159 149.9712586  163.70138997 114.41287676 207.50951705
 243.70297665 184.19475039 161.85734431  83.13108202 244.14499395]
total_rewards_mean           164.75398712994152
total_rewards_std            53.89255551576256
total_rewards_max            244.14499395484265
total_rewards_min            83.1310820153196
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               29.907842500600964
(Previous) Eval Time (s)     0.5007483097724617
Sample Time (s)              13.645100407768041
Epoch Time (s)               44.053691218141466
Total Train Time (s)         134.59965923428535
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:17:56.218306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #2 | Epoch Duration: 44.55429124832153
2020-01-10 18:17:56.218496 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012987572
Z variance train             0.6684264
KL Divergence                0.17953977
KL Loss                      0.017953977
QF Loss                      282.51083
VF Loss                      51.068653
Policy Loss                  -63.858524
Q Predictions Mean           53.913208
Q Predictions Std            87.47704
Q Predictions Max            448.2394
Q Predictions Min            17.785908
V Predictions Mean           61.720547
V Predictions Std            84.92431
V Predictions Max            438.47354
V Predictions Min            25.56304
Log Pis Mean                 -10.724955
Log Pis Std                  2.5292666
Log Pis Max                  1.1779332
Log Pis Min                  -14.748277
Policy mu Mean               0.043990627
Policy mu Std                0.2659044
Policy mu Max                1.6815864
Policy mu Min                -1.3560401
Policy log std Mean          -0.14253137
Policy log std Std           0.055719133
Policy log std Max           4.1790307e-05
Policy log std Min           -0.6090744
Z mean eval                  0.017843015
Z variance eval              0.633819
total_rewards                [147.24070959 251.46863157 320.04851281 251.91641086  81.23905492
 178.91370631  91.459217   119.12026178  81.85839907 158.03593026]
total_rewards_mean           168.13008341596677
total_rewards_std            78.08486062080789
total_rewards_max            320.0485128137936
total_rewards_min            81.23905491517533
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               27.365097501780838
(Previous) Eval Time (s)     1.0010582143440843
Sample Time (s)              13.44310741731897
Epoch Time (s)               41.80926313344389
Total Train Time (s)         176.2834681966342
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:18:37.903903 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #3 | Epoch Duration: 41.68519115447998
2020-01-10 18:18:37.904226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #3 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017598549
Z variance train             0.6339625
KL Divergence                0.23444518
KL Loss                      0.023444518
QF Loss                      792.37805
VF Loss                      140.95865
Policy Loss                  -83.46926
Q Predictions Mean           74.00551
Q Predictions Std            126.88896
Q Predictions Max            573.80743
Q Predictions Min            16.547346
V Predictions Mean           82.248634
V Predictions Std            125.5823
V Predictions Max            584.9868
V Predictions Min            25.844734
Log Pis Mean                 -10.332216
Log Pis Std                  3.0816948
Log Pis Max                  0.8519976
Log Pis Min                  -14.321962
Policy mu Mean               0.045506798
Policy mu Std                0.3393598
Policy mu Max                2.0789206
Policy mu Min                -1.4613286
Policy log std Mean          -0.15258037
Policy log std Std           0.07801445
Policy log std Max           -0.042639047
Policy log std Min           -0.64696026
Z mean eval                  0.025483033
Z variance eval              0.59037894
total_rewards                [437.18867862 281.52808395 415.97075926 375.87586837 344.2767924
 309.677727   428.67664647 368.93950427 313.33561288 298.16557585]
total_rewards_mean           357.3635249056268
total_rewards_std            53.85926174195251
total_rewards_max            437.1886786176177
total_rewards_min            281.52808394652294
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               30.416287067811936
(Previous) Eval Time (s)     0.8767276811413467
Sample Time (s)              14.024593932554126
Epoch Time (s)               45.31760868150741
Total Train Time (s)         222.90357937524095
Epoch                        4
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:19:24.524379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #4 | Epoch Duration: 46.61999988555908
2020-01-10 18:19:24.524590 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025477832
Z variance train             0.59028614
KL Divergence                0.30868775
KL Loss                      0.030868774
QF Loss                      2049.0044
VF Loss                      101.39503
Policy Loss                  -91.95936
Q Predictions Mean           88.31565
Q Predictions Std            159.72987
Q Predictions Max            669.4842
Q Predictions Min            17.794113
V Predictions Mean           94.351425
V Predictions Std            148.7654
V Predictions Max            655.01776
V Predictions Min            28.98047
Log Pis Mean                 -10.100298
Log Pis Std                  3.7279644
Log Pis Max                  4.863374
Log Pis Min                  -13.312058
Policy mu Mean               0.042331003
Policy mu Std                0.35703218
Policy mu Max                2.201228
Policy mu Min                -1.4969262
Policy log std Mean          -0.16241081
Policy log std Std           0.077007316
Policy log std Max           -0.030488748
Policy log std Min           -0.6946025
Z mean eval                  0.02037416
Z variance eval              0.5373589
total_rewards                [366.08265903 425.13939393 692.32417163 356.2420528  287.60513703
 306.8284354  633.07734354 753.12151566 446.57672143 468.44764371]
total_rewards_mean           473.54450741706813
total_rewards_std            155.6439777718196
total_rewards_max            753.1215156557299
total_rewards_min            287.60513703470303
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               26.459600113797933
(Previous) Eval Time (s)     2.1788655798882246
Sample Time (s)              14.515389536973089
Epoch Time (s)               43.153855230659246
Total Train Time (s)         266.6271453425288
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:20:08.251928 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #5 | Epoch Duration: 43.72706699371338
2020-01-10 18:20:08.252260 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020565713
Z variance train             0.5372708
KL Divergence                0.42211437
KL Loss                      0.04221144
QF Loss                      429.4404
VF Loss                      237.56151
Policy Loss                  -135.05579
Q Predictions Mean           126.89357
Q Predictions Std            206.05052
Q Predictions Max            740.96704
Q Predictions Min            17.821224
V Predictions Mean           141.64166
V Predictions Std            209.9796
V Predictions Max            746.55115
V Predictions Min            28.954437
Log Pis Mean                 -9.212425
Log Pis Std                  4.831298
Log Pis Max                  8.598116
Log Pis Min                  -13.888796
Policy mu Mean               0.070189044
Policy mu Std                0.44801486
Policy mu Max                2.244586
Policy mu Min                -1.8165473
Policy log std Mean          -0.1692065
Policy log std Std           0.09775431
Policy log std Max           -0.011415292
Policy log std Min           -0.68852526
Z mean eval                  0.017701048
Z variance eval              0.49919042
total_rewards                [217.03744249 302.54155118 182.51697497 288.38438401 223.53095265
 209.96933078 220.06778842 291.70573108 292.9418699  273.30222293]
total_rewards_mean           250.19982484073518
total_rewards_std            41.47219927575712
total_rewards_max            302.54155118235457
total_rewards_min            182.51697496506756
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               30.70167098985985
(Previous) Eval Time (s)     2.7518000369891524
Sample Time (s)              14.840898233931512
Epoch Time (s)               48.29436926078051
Total Train Time (s)         313.6509791868739
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:20:55.275046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #6 | Epoch Duration: 47.02256989479065
2020-01-10 18:20:55.275247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017727062
Z variance train             0.4992052
KL Divergence                0.50900745
KL Loss                      0.050900746
QF Loss                      1335.6299
VF Loss                      456.3025
Policy Loss                  -178.98083
Q Predictions Mean           172.96063
Q Predictions Std            264.8745
Q Predictions Max            830.5262
Q Predictions Min            18.323406
V Predictions Mean           184.5603
V Predictions Std            263.68298
V Predictions Max            857.3492
V Predictions Min            28.524223
Log Pis Mean                 -8.141666
Log Pis Std                  6.1263194
Log Pis Max                  11.831881
Log Pis Min                  -13.53581
Policy mu Mean               0.059788514
Policy mu Std                0.5538025
Policy mu Max                2.4305286
Policy mu Min                -1.9677081
Policy log std Mean          -0.19255698
Policy log std Std           0.1165971
Policy log std Max           -0.015580725
Policy log std Min           -0.7340178
Z mean eval                  0.016183876
Z variance eval              0.46598133
total_rewards                [313.04835101 332.62296726 299.49079907 324.53699716 350.94842634
 358.63787796 415.59924522 282.24577842 281.96223167 356.70616801]
total_rewards_mean           331.57988421168034
total_rewards_std            38.88115409538275
total_rewards_max            415.59924522217057
total_rewards_min            281.9622316711171
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               29.99180360417813
(Previous) Eval Time (s)     1.4797451528720558
Sample Time (s)              14.515162801370025
Epoch Time (s)               45.98671155842021
Total Train Time (s)         359.9648782410659
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:21:41.590909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #7 | Epoch Duration: 46.315468311309814
2020-01-10 18:21:41.591209 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016212892
Z variance train             0.46596813
KL Divergence                0.60148615
KL Loss                      0.060148615
QF Loss                      363.92804
VF Loss                      251.21255
Policy Loss                  -156.59662
Q Predictions Mean           145.61392
Q Predictions Std            268.9105
Q Predictions Max            960.06464
Q Predictions Min            15.916364
V Predictions Mean           152.18222
V Predictions Std            257.5917
V Predictions Max            924.64923
V Predictions Min            26.938023
Log Pis Mean                 -9.037186
Log Pis Std                  5.412168
Log Pis Max                  10.73988
Log Pis Min                  -14.534502
Policy mu Mean               0.080568165
Policy mu Std                0.4534902
Policy mu Max                2.261407
Policy mu Min                -1.867022
Policy log std Mean          -0.16927768
Policy log std Std           0.103066064
Policy log std Max           -0.0012102276
Policy log std Min           -0.6809919
Z mean eval                  0.018896528
Z variance eval              0.44401807
total_rewards                [400.8539623  307.68352485 348.12819619 202.94675427 280.10612203
 308.33863706 402.97822872 309.67417976 375.554969   335.74446822]
total_rewards_mean           327.2009042401056
total_rewards_std            57.19872994098558
total_rewards_max            402.9782287207369
total_rewards_min            202.94675426693374
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               29.041709031909704
(Previous) Eval Time (s)     1.8081778907217085
Sample Time (s)              15.242943601682782
Epoch Time (s)               46.092830524314195
Total Train Time (s)         406.3384142643772
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:22:27.966187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #8 | Epoch Duration: 46.37475347518921
2020-01-10 18:22:27.966446 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01889966
Z variance train             0.44396615
KL Divergence                0.6691991
KL Loss                      0.066919915
QF Loss                      449.33197
VF Loss                      129.91182
Policy Loss                  -158.6708
Q Predictions Mean           149.48181
Q Predictions Std            275.019
Q Predictions Max            986.289
Q Predictions Min            17.160603
V Predictions Mean           156.44983
V Predictions Std            268.6801
V Predictions Max            977.0878
V Predictions Min            23.854511
Log Pis Mean                 -8.812423
Log Pis Std                  6.1210556
Log Pis Max                  18.009422
Log Pis Min                  -13.703266
Policy mu Mean               0.076462016
Policy mu Std                0.48115045
Policy mu Max                2.487758
Policy mu Min                -1.9026136
Policy log std Mean          -0.17368858
Policy log std Std           0.103818744
Policy log std Max           -0.02431959
Policy log std Min           -0.7001261
Z mean eval                  0.01919584
Z variance eval              0.41061935
total_rewards                [263.67465944 396.30119742 379.33029927 338.14929669 314.10481342
 287.54581355 245.21591562 291.02042233 340.65710717 279.20656224]
total_rewards_mean           313.520608714402
total_rewards_std            46.941874979648375
total_rewards_max            396.3011974155822
total_rewards_min            245.21591562070498
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               29.37958288192749
(Previous) Eval Time (s)     2.0898464978672564
Sample Time (s)              15.913882202468812
Epoch Time (s)               47.38331158226356
Total Train Time (s)         453.37779325572774
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:23:15.005063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #9 | Epoch Duration: 47.038429737091064
2020-01-10 18:23:15.005214 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01917705
Z variance train             0.41060847
KL Divergence                0.77344084
KL Loss                      0.07734408
QF Loss                      427.48358
VF Loss                      154.9581
Policy Loss                  -179.90735
Q Predictions Mean           168.73495
Q Predictions Std            310.03244
Q Predictions Max            1075.7642
Q Predictions Min            16.197674
V Predictions Mean           183.66829
V Predictions Std            311.81848
V Predictions Max            1040.7246
V Predictions Min            21.824114
Log Pis Mean                 -9.276833
Log Pis Std                  4.9260254
Log Pis Max                  11.469994
Log Pis Min                  -13.907295
Policy mu Mean               0.084552206
Policy mu Std                0.44890904
Policy mu Max                2.435639
Policy mu Min                -1.899501
Policy log std Mean          -0.16415176
Policy log std Std           0.09884575
Policy log std Max           -0.046184983
Policy log std Min           -0.7173912
Z mean eval                  0.020105043
Z variance eval              0.40045628
total_rewards                [376.66575034 287.51259139 313.86007032 313.18940335 433.09308409
 259.16428594 300.93770397 276.02775974 349.62299577 353.15597637]
total_rewards_mean           326.32296212688937
total_rewards_std            49.71470899760189
total_rewards_max            433.0930840875302
total_rewards_min            259.1642859374414
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               29.53097669314593
(Previous) Eval Time (s)     1.7446745741181076
Sample Time (s)              14.397250947076827
Epoch Time (s)               45.672902214340866
Total Train Time (s)         499.1245957426727
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:24:00.753836 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #10 | Epoch Duration: 45.748459577560425
2020-01-10 18:24:00.754064 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020193402
Z variance train             0.4003869
KL Divergence                0.8270619
KL Loss                      0.08270619
QF Loss                      509.67303
VF Loss                      188.11479
Policy Loss                  -225.82648
Q Predictions Mean           213.64943
Q Predictions Std            360.42136
Q Predictions Max            1101.268
Q Predictions Min            16.513659
V Predictions Mean           222.86691
V Predictions Std            357.9317
V Predictions Max            1076.5975
V Predictions Min            26.136509
Log Pis Mean                 -8.433476
Log Pis Std                  5.885137
Log Pis Max                  13.043144
Log Pis Min                  -13.438625
Policy mu Mean               0.06932642
Policy mu Std                0.5047428
Policy mu Max                2.560092
Policy mu Min                -1.8647106
Policy log std Mean          -0.17931062
Policy log std Std           0.10693204
Policy log std Max           -0.0445123
Policy log std Min           -0.7609233
Z mean eval                  0.023733398
Z variance eval              0.3783256
total_rewards                [249.85710655 304.97360503 276.29030297 303.70823893 302.07725456
 259.1616143  242.33706154 245.90125165 294.13338319 265.63816495]
total_rewards_mean           274.4077983667989
total_rewards_std            23.883613868299896
total_rewards_max            304.97360502985225
total_rewards_min            242.33706153690702
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               29.552116066217422
(Previous) Eval Time (s)     1.8199798529967666
Sample Time (s)              15.374527959618717
Epoch Time (s)               46.74662387883291
Total Train Time (s)         545.8700591004454
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:24:47.501675 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #11 | Epoch Duration: 46.74739980697632
2020-01-10 18:24:47.501959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023748865
Z variance train             0.37827802
KL Divergence                0.9203953
KL Loss                      0.09203953
QF Loss                      516.8019
VF Loss                      160.43974
Policy Loss                  -217.94984
Q Predictions Mean           209.26492
Q Predictions Std            369.05768
Q Predictions Max            1127.92
Q Predictions Min            12.972704
V Predictions Mean           222.29239
V Predictions Std            372.34326
V Predictions Max            1149.655
V Predictions Min            19.373148
Log Pis Mean                 -8.614812
Log Pis Std                  5.599145
Log Pis Max                  11.657046
Log Pis Min                  -13.233217
Policy mu Mean               0.10298844
Policy mu Std                0.48799282
Policy mu Max                2.5353563
Policy mu Min                -1.8706094
Policy log std Mean          -0.18199167
Policy log std Std           0.107402414
Policy log std Max           -0.028425306
Policy log std Min           -0.8340601
Z mean eval                  0.025295135
Z variance eval              0.36218002
total_rewards                [268.14042471 271.54150781 444.02654767 336.88255031 303.21119968
 289.07301291 269.42174753 236.96855913 255.72276949 286.97749122]
total_rewards_mean           296.196581045521
total_rewards_std            55.63451185771637
total_rewards_max            444.02654766603973
total_rewards_min            236.9685591344233
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               28.846329268068075
(Previous) Eval Time (s)     1.8204516773112118
Sample Time (s)              14.770802801009268
Epoch Time (s)               45.437583746388555
Total Train Time (s)         591.1903416090645
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:25:32.821275 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #12 | Epoch Duration: 45.31910967826843
2020-01-10 18:25:32.821468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025325129
Z variance train             0.3621642
KL Divergence                0.9950371
KL Loss                      0.09950371
QF Loss                      424.78174
VF Loss                      211.11203
Policy Loss                  -203.17538
Q Predictions Mean           192.56866
Q Predictions Std            351.66617
Q Predictions Max            1205.8975
Q Predictions Min            17.263962
V Predictions Mean           200.25098
V Predictions Std            345.71863
V Predictions Max            1177.125
V Predictions Min            25.25182
Log Pis Mean                 -8.943547
Log Pis Std                  5.440773
Log Pis Max                  14.101913
Log Pis Min                  -13.788811
Policy mu Mean               0.060860436
Policy mu Std                0.4820692
Policy mu Max                2.5523498
Policy mu Min                -2.0396767
Policy log std Mean          -0.1790824
Policy log std Std           0.10846852
Policy log std Max           -0.043271072
Policy log std Min           -0.75801367
Z mean eval                  0.0257968
Z variance eval              0.3451813
total_rewards                [289.44780153 318.25154768 267.64861627 325.69034024 454.23095316
 282.7021436  311.54276159 252.80566843 287.32253123 282.64652392]
total_rewards_mean           307.2288887653993
total_rewards_std            53.42032341951192
total_rewards_max            454.2309531622125
total_rewards_min            252.8056684260374
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               27.97297855792567
(Previous) Eval Time (s)     1.7016995348967612
Sample Time (s)              14.327519420068711
Epoch Time (s)               44.002197512891144
Total Train Time (s)         635.4203544179909
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:26:17.056178 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #13 | Epoch Duration: 44.23452115058899
2020-01-10 18:26:17.056471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025726208
Z variance train             0.34518066
KL Divergence                1.0815973
KL Loss                      0.108159736
QF Loss                      290.16364
VF Loss                      139.62639
Policy Loss                  -211.70673
Q Predictions Mean           203.43523
Q Predictions Std            375.06393
Q Predictions Max            1206.2394
Q Predictions Min            18.991856
V Predictions Mean           212.8956
V Predictions Std            373.2084
V Predictions Max            1234.5706
V Predictions Min            28.755749
Log Pis Mean                 -8.90415
Log Pis Std                  5.2591023
Log Pis Max                  11.8939085
Log Pis Min                  -13.361626
Policy mu Mean               0.06433079
Policy mu Std                0.46787152
Policy mu Max                2.556254
Policy mu Min                -1.8482867
Policy log std Mean          -0.17955767
Policy log std Std           0.10300694
Policy log std Max           -0.069270924
Policy log std Min           -0.78914225
Z mean eval                  0.030519256
Z variance eval              0.3402341
total_rewards                [291.66868211 317.64182357 291.02644006 323.29740403 358.19315956
 295.84686107 315.08719313 356.75980053 348.5226619  320.48328001]
total_rewards_mean           321.8527305977225
total_rewards_std            24.198191000507126
total_rewards_max            358.1931595597193
total_rewards_min            291.02644006497934
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               29.134020518045872
(Previous) Eval Time (s)     1.9337448189035058
Sample Time (s)              14.183808698318899
Epoch Time (s)               45.25157403526828
Total Train Time (s)         680.5725797289051
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:27:02.206859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #14 | Epoch Duration: 45.150150537490845
2020-01-10 18:27:02.207082 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #14 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030465912
Z variance train             0.34022382
KL Divergence                1.0982702
KL Loss                      0.10982702
QF Loss                      586.1839
VF Loss                      297.72916
Policy Loss                  -222.16042
Q Predictions Mean           213.99374
Q Predictions Std            382.96497
Q Predictions Max            1229.7307
Q Predictions Min            18.208565
V Predictions Mean           220.2927
V Predictions Std            375.3722
V Predictions Max            1240.7189
V Predictions Min            24.976
Log Pis Mean                 -8.930431
Log Pis Std                  5.008998
Log Pis Max                  8.941965
Log Pis Min                  -14.86006
Policy mu Mean               0.067400776
Policy mu Std                0.4917381
Policy mu Max                2.4450095
Policy mu Min                -2.1761584
Policy log std Mean          -0.17815661
Policy log std Std           0.10287109
Policy log std Max           -0.027608268
Policy log std Min           -0.71165204
Z mean eval                  0.034040958
Z variance eval              0.32821602
total_rewards                [284.36819679 293.95853871 272.60299861 311.52341195 269.7033637
 315.49718037 293.98894404 333.83127213 331.67969057 273.82843342]
total_rewards_mean           298.0982030297761
total_rewards_std            22.705415976663062
total_rewards_max            333.83127212920067
total_rewards_min            269.70336370184117
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               30.396215680986643
(Previous) Eval Time (s)     1.8320693303830922
Sample Time (s)              14.716521728783846
Epoch Time (s)               46.94480674015358
Total Train Time (s)         727.44381608814
Epoch                        15
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:27:49.078203 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #15 | Epoch Duration: 46.870957136154175
2020-01-10 18:27:49.078401 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033988066
Z variance train             0.3282563
KL Divergence                1.15795
KL Loss                      0.11579501
QF Loss                      620.2591
VF Loss                      170.28937
Policy Loss                  -261.6382
Q Predictions Mean           252.74069
Q Predictions Std            420.13763
Q Predictions Max            1265.5465
Q Predictions Min            16.457357
V Predictions Mean           263.35788
V Predictions Std            418.29636
V Predictions Max            1258.3914
V Predictions Min            26.182137
Log Pis Mean                 -8.179572
Log Pis Std                  5.973585
Log Pis Max                  12.93039
Log Pis Min                  -13.457066
Policy mu Mean               0.07782741
Policy mu Std                0.5292389
Policy mu Max                2.4435298
Policy mu Min                -1.7526683
Policy log std Mean          -0.1913018
Policy log std Std           0.116332166
Policy log std Max           -0.05932612
Policy log std Min           -0.76137716
Z mean eval                  0.036823224
Z variance eval              0.32183138
total_rewards                [434.03353077 338.67569    417.24125433 350.18049879 365.42479198
 377.25914853 366.45491439 297.14096633 331.16518363 357.65724314]
total_rewards_mean           363.52332218876677
total_rewards_std            37.87043891723845
total_rewards_max            434.0335307700876
total_rewards_min            297.14096633473764
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               30.68416219810024
(Previous) Eval Time (s)     1.757945055142045
Sample Time (s)              15.291342379525304
Epoch Time (s)               47.73344963276759
Total Train Time (s)         775.5077126557007
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:28:37.144241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #16 | Epoch Duration: 48.06568360328674
2020-01-10 18:28:37.144454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036813032
Z variance train             0.32169417
KL Divergence                1.1838117
KL Loss                      0.118381165
QF Loss                      479.72974
VF Loss                      235.31424
Policy Loss                  -245.52617
Q Predictions Mean           236.1871
Q Predictions Std            401.37195
Q Predictions Max            1266.2959
Q Predictions Min            15.949271
V Predictions Mean           241.57573
V Predictions Std            393.92603
V Predictions Max            1272.9762
V Predictions Min            25.01774
Log Pis Mean                 -8.345785
Log Pis Std                  5.8420873
Log Pis Max                  11.254019
Log Pis Min                  -13.438822
Policy mu Mean               0.10241984
Policy mu Std                0.51254505
Policy mu Max                2.4860554
Policy mu Min                -1.8619708
Policy log std Mean          -0.18546534
Policy log std Std           0.10808584
Policy log std Max           -0.059661835
Policy log std Min           -0.70414305
Z mean eval                  0.037647475
Z variance eval              0.3208233
total_rewards                [308.53163985 319.49377534 336.11798009 360.91628002 362.87829365
 313.22714621 372.30983027 337.52784206 285.40437197 414.41027198]
total_rewards_mean           341.0817431435804
total_rewards_std            35.580095559395325
total_rewards_max            414.4102719806079
total_rewards_min            285.4043719690922
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               29.74538654787466
(Previous) Eval Time (s)     2.0898836348205805
Sample Time (s)              14.320422414224595
Epoch Time (s)               46.155692596919835
Total Train Time (s)         821.5771852061152
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:29:23.214901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #17 | Epoch Duration: 46.07021379470825
2020-01-10 18:29:23.215189 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #17 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037905596
Z variance train             0.32092947
KL Divergence                1.1790171
KL Loss                      0.117901705
QF Loss                      440.59485
VF Loss                      253.96494
Policy Loss                  -221.3528
Q Predictions Mean           210.18091
Q Predictions Std            370.66394
Q Predictions Max            1324.8231
Q Predictions Min            17.356033
V Predictions Mean           216.18405
V Predictions Std            362.34122
V Predictions Max            1283.6797
V Predictions Min            28.7055
Log Pis Mean                 -8.604006
Log Pis Std                  5.4559846
Log Pis Max                  10.067706
Log Pis Min                  -14.791357
Policy mu Mean               0.07666325
Policy mu Std                0.5126564
Policy mu Max                2.4784017
Policy mu Min                -1.6896602
Policy log std Mean          -0.18634008
Policy log std Std           0.11081578
Policy log std Max           -0.066835366
Policy log std Min           -0.6974933
Z mean eval                  0.043008305
Z variance eval              0.31278685
total_rewards                [344.45293467 306.85753228 310.7737925  350.64515019 373.5981505
 290.54965502 330.66181738 398.88380872 285.62951199 426.25232754]
total_rewards_mean           341.83046808029314
total_rewards_std            44.24536922765967
total_rewards_max            426.252327544163
total_rewards_min            285.6295119887447
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               30.257435540668666
(Previous) Eval Time (s)     2.0041194148361683
Sample Time (s)              14.49753241892904
Epoch Time (s)               46.759087374433875
Total Train Time (s)         868.3364415490068
Epoch                        18
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:30:09.976907 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #18 | Epoch Duration: 46.76150584220886
2020-01-10 18:30:09.977200 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04294114
Z variance train             0.31284097
KL Divergence                1.2184696
KL Loss                      0.12184697
QF Loss                      376.08337
VF Loss                      127.342255
Policy Loss                  -219.54092
Q Predictions Mean           208.16675
Q Predictions Std            359.6377
Q Predictions Max            1266.0428
Q Predictions Min            15.742927
V Predictions Mean           217.7912
V Predictions Std            359.4795
V Predictions Max            1303.2362
V Predictions Min            26.22999
Log Pis Mean                 -8.865077
Log Pis Std                  5.273268
Log Pis Max                  15.192863
Log Pis Min                  -13.70646
Policy mu Mean               0.07710296
Policy mu Std                0.477852
Policy mu Max                2.4905832
Policy mu Min                -1.9721724
Policy log std Mean          -0.18026377
Policy log std Std           0.1012363
Policy log std Max           -0.08204214
Policy log std Min           -0.76623905
Z mean eval                  0.047412775
Z variance eval              0.29997286
total_rewards                [365.47439461 372.37751917 356.810615   333.30388968 306.40438966
 317.83362832 322.54410128 377.44244283 368.85669428 404.09233484]
total_rewards_mean           352.51400096797863
total_rewards_std            29.53959237953541
total_rewards_max            404.0923348416988
total_rewards_min            306.40438966402894
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               27.4862366062589
(Previous) Eval Time (s)     2.006230320315808
Sample Time (s)              15.152953885030001
Epoch Time (s)               44.64542081160471
Total Train Time (s)         912.840828796383
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:30:54.482703 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #19 | Epoch Duration: 44.50520443916321
2020-01-10 18:30:54.483006 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04749315
Z variance train             0.29994184
KL Divergence                1.2883927
KL Loss                      0.12883927
QF Loss                      395.59485
VF Loss                      255.69754
Policy Loss                  -180.09749
Q Predictions Mean           169.66446
Q Predictions Std            338.88312
Q Predictions Max            1515.3885
Q Predictions Min            18.548195
V Predictions Mean           176.8955
V Predictions Std            330.8747
V Predictions Max            1409.2136
V Predictions Min            27.270754
Log Pis Mean                 -9.286646
Log Pis Std                  5.0915446
Log Pis Max                  12.685326
Log Pis Min                  -13.879165
Policy mu Mean               0.07865753
Policy mu Std                0.43808016
Policy mu Max                2.7814014
Policy mu Min                -1.8553487
Policy log std Mean          -0.16866857
Policy log std Std           0.098267235
Policy log std Max           -0.07658867
Policy log std Min           -0.7545402
Z mean eval                  0.04834462
Z variance eval              0.29537097
total_rewards                [356.29449433 412.97303008 375.89875004 356.19744124 357.62348338
 286.6105106  288.43818031 360.77925749 324.86221337 458.65655934]
total_rewards_mean           357.8333920173148
total_rewards_std            49.518993837661476
total_rewards_max            458.65655933525727
total_rewards_min            286.61051059842856
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               27.590650307945907
(Previous) Eval Time (s)     1.8657281370833516
Sample Time (s)              15.043463693466038
Epoch Time (s)               44.499842138495296
Total Train Time (s)         957.6512748175301
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:31:39.295381 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #20 | Epoch Duration: 44.812166690826416
2020-01-10 18:31:39.295668 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #20 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048266347
Z variance train             0.29537612
KL Divergence                1.307803
KL Loss                      0.13078031
QF Loss                      520.54443
VF Loss                      121.76765
Policy Loss                  -242.36673
Q Predictions Mean           234.15889
Q Predictions Std            397.0437
Q Predictions Max            1292.5901
Q Predictions Min            16.888805
V Predictions Mean           243.65155
V Predictions Std            394.89517
V Predictions Max            1293.8818
V Predictions Min            25.310438
Log Pis Mean                 -8.821828
Log Pis Std                  4.840367
Log Pis Max                  7.0700226
Log Pis Min                  -13.214195
Policy mu Mean               0.07616374
Policy mu Std                0.47709453
Policy mu Max                2.3362932
Policy mu Min                -1.812032
Policy log std Mean          -0.17877547
Policy log std Std           0.1043239
Policy log std Max           -0.063407056
Policy log std Min           -0.66410553
Z mean eval                  0.05260427
Z variance eval              0.28883728
total_rewards                [375.0770293  392.72363692 357.79850939 346.65007947 401.3812127
 517.86220493 370.72074804 333.51011217 340.21378419 396.33290567]
total_rewards_mean           383.2270222761794
total_rewards_std            50.24676905131508
total_rewards_max            517.86220492668
total_rewards_min            333.5101121714685
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               27.245232727844268
(Previous) Eval Time (s)     2.177779223769903
Sample Time (s)              14.64215253200382
Epoch Time (s)               44.06516448361799
Total Train Time (s)         1001.7272097943351
Epoch                        21
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:32:23.372130 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #21 | Epoch Duration: 44.0761981010437
2020-01-10 18:32:23.372407 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052861564
Z variance train             0.2888359
KL Divergence                1.3497586
KL Loss                      0.13497587
QF Loss                      416.11798
VF Loss                      156.12386
Policy Loss                  -249.77446
Q Predictions Mean           239.19989
Q Predictions Std            386.57053
Q Predictions Max            1316.7441
Q Predictions Min            18.449114
V Predictions Mean           249.38692
V Predictions Std            386.32852
V Predictions Max            1296.221
V Predictions Min            25.885769
Log Pis Mean                 -8.451639
Log Pis Std                  5.4705625
Log Pis Max                  11.924088
Log Pis Min                  -13.692337
Policy mu Mean               0.098237105
Policy mu Std                0.51210517
Policy mu Max                2.565071
Policy mu Min                -2.0375743
Policy log std Mean          -0.18693627
Policy log std Std           0.11360939
Policy log std Max           -0.02420675
Policy log std Min           -0.7273039
Z mean eval                  0.060346346
Z variance eval              0.27639413
total_rewards                [496.77795461 403.73063495 322.63822129 385.50385114 382.52133153
 270.38713811 341.22265278 423.47389771 317.59144387 465.10978371]
total_rewards_mean           380.89569096995416
total_rewards_std            66.38251225608123
total_rewards_max            496.77795461167574
total_rewards_min            270.3871381144163
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               28.792947520967573
(Previous) Eval Time (s)     2.1885625990107656
Sample Time (s)              14.530646201223135
Epoch Time (s)               45.51215632120147
Total Train Time (s)         1047.2941684988327
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:33:08.939444 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #22 | Epoch Duration: 45.56683158874512
2020-01-10 18:33:08.939650 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06008328
Z variance train             0.27640072
KL Divergence                1.4277792
KL Loss                      0.14277792
QF Loss                      589.71173
VF Loss                      219.16583
Policy Loss                  -253.6863
Q Predictions Mean           245.00194
Q Predictions Std            394.4331
Q Predictions Max            1293.1285
Q Predictions Min            18.197187
V Predictions Mean           255.3138
V Predictions Std            394.49908
V Predictions Max            1319.7876
V Predictions Min            26.897398
Log Pis Mean                 -8.7302885
Log Pis Std                  5.105197
Log Pis Max                  11.402178
Log Pis Min                  -14.490823
Policy mu Mean               0.08433892
Policy mu Std                0.4929085
Policy mu Max                2.3410904
Policy mu Min                -1.8486053
Policy log std Mean          -0.18430403
Policy log std Std           0.112730555
Policy log std Max           -0.050537035
Policy log std Min           -0.78096694
Z mean eval                  0.06044901
Z variance eval              0.2743731
total_rewards                [348.32848267 361.78682058 395.06703408 321.0050904  316.29014408
 351.59101061 392.93420049 423.25574108 510.76238844 483.99601416]
total_rewards_mean           390.5016926579379
total_rewards_std            62.25568776581017
total_rewards_max            510.76238843658825
total_rewards_min            316.2901440766744
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               28.122186624910682
(Previous) Eval Time (s)     2.242952947039157
Sample Time (s)              14.34771200409159
Epoch Time (s)               44.71285157604143
Total Train Time (s)         1092.1686711222865
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:33:53.814438 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #23 | Epoch Duration: 44.874632120132446
2020-01-10 18:33:53.814628 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060757983
Z variance train             0.27434644
KL Divergence                1.4455721
KL Loss                      0.14455722
QF Loss                      458.9263
VF Loss                      204.92632
Policy Loss                  -269.3025
Q Predictions Mean           258.8258
Q Predictions Std            417.63843
Q Predictions Max            1306.6703
Q Predictions Min            19.208103
V Predictions Mean           264.64285
V Predictions Std            412.1112
V Predictions Max            1294.8921
V Predictions Min            28.442558
Log Pis Mean                 -8.379164
Log Pis Std                  5.355378
Log Pis Max                  10.480431
Log Pis Min                  -13.133204
Policy mu Mean               0.13258082
Policy mu Std                0.5057917
Policy mu Max                2.5241625
Policy mu Min                -1.9820722
Policy log std Mean          -0.19017549
Policy log std Std           0.115680575
Policy log std Max           -0.08540964
Policy log std Min           -0.83963144
Z mean eval                  0.06353116
Z variance eval              0.28241548
total_rewards                [503.29095349 481.7272065  550.8651653  358.02088928 297.99498653
 392.30272436 316.28214771 358.69422047 691.25105269 342.17025098]
total_rewards_mean           429.25995973120524
total_rewards_std            118.60017763952236
total_rewards_max            691.2510526912088
total_rewards_min            297.994986532958
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               31.372239738237113
(Previous) Eval Time (s)     2.404495502822101
Sample Time (s)              14.48362832609564
Epoch Time (s)               48.260363567154855
Total Train Time (s)         1140.66968005104
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:34:42.318051 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #24 | Epoch Duration: 48.50326657295227
2020-01-10 18:34:42.318241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06356458
Z variance train             0.2824616
KL Divergence                1.3961315
KL Loss                      0.13961315
QF Loss                      378.7669
VF Loss                      112.22792
Policy Loss                  -276.5993
Q Predictions Mean           269.04517
Q Predictions Std            438.2717
Q Predictions Max            1300.8162
Q Predictions Min            17.978199
V Predictions Mean           276.83325
V Predictions Std            432.85107
V Predictions Max            1320.6819
V Predictions Min            25.575651
Log Pis Mean                 -8.580681
Log Pis Std                  5.314486
Log Pis Max                  9.0719595
Log Pis Min                  -14.009889
Policy mu Mean               0.1345827
Policy mu Std                0.5031806
Policy mu Max                2.314824
Policy mu Min                -1.747617
Policy log std Mean          -0.18898875
Policy log std Std           0.11202905
Policy log std Max           -0.04142137
Policy log std Min           -0.6673774
Z mean eval                  0.067470275
Z variance eval              0.26938987
total_rewards                [465.28895217 575.74504984 400.99566985 678.41273765 301.52419314
 337.27601269 511.09679158 380.00877589 371.68250676 539.27226351]
total_rewards_mean           456.13029530795075
total_rewards_std            113.0177358727393
total_rewards_max            678.4127376483614
total_rewards_min            301.5241931354769
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               29.852612355258316
(Previous) Eval Time (s)     2.6471386151388288
Sample Time (s)              14.88149814400822
Epoch Time (s)               47.381249114405364
Total Train Time (s)         1188.1886953446083
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:35:29.838943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #25 | Epoch Duration: 47.52051401138306
2020-01-10 18:35:29.839211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06745306
Z variance train             0.2693812
KL Divergence                1.4741787
KL Loss                      0.14741787
QF Loss                      707.10803
VF Loss                      233.91795
Policy Loss                  -267.6972
Q Predictions Mean           261.11484
Q Predictions Std            405.99905
Q Predictions Max            1352.902
Q Predictions Min            17.805634
V Predictions Mean           267.1916
V Predictions Std            398.4142
V Predictions Max            1349.9786
V Predictions Min            29.49473
Log Pis Mean                 -8.029875
Log Pis Std                  6.1218467
Log Pis Max                  19.332108
Log Pis Min                  -14.01127
Policy mu Mean               0.13048774
Policy mu Std                0.540313
Policy mu Max                2.4485126
Policy mu Min                -2.3359313
Policy log std Mean          -0.1977697
Policy log std Std           0.12701729
Policy log std Max           -0.06565531
Policy log std Min           -0.8971897
Z mean eval                  0.07090014
Z variance eval              0.267474
total_rewards                [322.89244363 373.52254811 502.29580588 496.2521785  345.12355521
 391.25210326 341.50444261 420.83986502 356.05043253 476.64518643]
total_rewards_mean           402.637856116751
total_rewards_std            64.07494893350528
total_rewards_max            502.2958058809851
total_rewards_min            322.8924436282934
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               30.410582433920354
(Previous) Eval Time (s)     2.786124211270362
Sample Time (s)              15.162646552082151
Epoch Time (s)               48.35935319727287
Total Train Time (s)         1236.143880458083
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:36:17.793709 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #26 | Epoch Duration: 47.9543035030365
2020-01-10 18:36:17.793888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0709705
Z variance train             0.26748228
KL Divergence                1.5005403
KL Loss                      0.15005402
QF Loss                      506.2517
VF Loss                      165.98827
Policy Loss                  -249.19081
Q Predictions Mean           240.39285
Q Predictions Std            396.4265
Q Predictions Max            1326.945
Q Predictions Min            16.51717
V Predictions Mean           249.79736
V Predictions Std            389.74948
V Predictions Max            1313.5691
V Predictions Min            30.614023
Log Pis Mean                 -8.759819
Log Pis Std                  5.175242
Log Pis Max                  15.661969
Log Pis Min                  -14.314182
Policy mu Mean               0.10719437
Policy mu Std                0.48052293
Policy mu Max                2.4319663
Policy mu Min                -2.050119
Policy log std Mean          -0.18294919
Policy log std Std           0.10543698
Policy log std Max           -0.07943801
Policy log std Min           -0.7737639
Z mean eval                  0.07452296
Z variance eval              0.26774037
total_rewards                [299.96362712 358.97984993 461.458138   388.080753   480.58603667
 432.42030327 283.63699275 408.40152474 462.49956061 787.73645071]
total_rewards_mean           436.3763236789138
total_rewards_std            133.33364214325616
total_rewards_max            787.7364507096069
total_rewards_min            283.6369927502834
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               27.9041876103729
(Previous) Eval Time (s)     2.3807971766218543
Sample Time (s)              14.866403551772237
Epoch Time (s)               45.15138833876699
Total Train Time (s)         1281.7519109509885
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:37:03.404156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #27 | Epoch Duration: 45.61013197898865
2020-01-10 18:37:03.404383 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07449082
Z variance train             0.2676855
KL Divergence                1.4961333
KL Loss                      0.14961334
QF Loss                      419.534
VF Loss                      596.85785
Policy Loss                  -284.30948
Q Predictions Mean           275.9621
Q Predictions Std            427.23114
Q Predictions Max            1322.5807
Q Predictions Min            17.185942
V Predictions Mean           287.90283
V Predictions Std            424.84082
V Predictions Max            1342.3563
V Predictions Min            27.367252
Log Pis Mean                 -8.273943
Log Pis Std                  5.263603
Log Pis Max                  6.538555
Log Pis Min                  -12.855019
Policy mu Mean               0.12351457
Policy mu Std                0.5057755
Policy mu Max                2.51097
Policy mu Min                -1.9333879
Policy log std Mean          -0.1870132
Policy log std Std           0.11095801
Policy log std Max           -0.047211237
Policy log std Min           -0.76577
Z mean eval                  0.075122915
Z variance eval              0.25738782
total_rewards                [378.07174824 394.38320578 476.95999068 481.29496296 572.31140524
 583.70303377 273.85504268 316.09106379 305.22930454 284.53265053]
total_rewards_mean           406.6432408213872
total_rewards_std            110.14002888185139
total_rewards_max            583.7030337674165
total_rewards_min            273.8550426780246
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               28.637616583146155
(Previous) Eval Time (s)     2.839248728007078
Sample Time (s)              15.061953753698617
Epoch Time (s)               46.53881906485185
Total Train Time (s)         1327.9296580548398
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:37:49.582106 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #28 | Epoch Duration: 46.17755460739136
2020-01-10 18:37:49.582277 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07519637
Z variance train             0.25735533
KL Divergence                1.5689657
KL Loss                      0.15689658
QF Loss                      595.73883
VF Loss                      204.4251
Policy Loss                  -274.22598
Q Predictions Mean           265.4394
Q Predictions Std            424.53833
Q Predictions Max            1373.4279
Q Predictions Min            15.766169
V Predictions Mean           270.2663
V Predictions Std            416.20322
V Predictions Max            1329.7798
V Predictions Min            23.827713
Log Pis Mean                 -9.117685
Log Pis Std                  4.5700774
Log Pis Max                  9.74398
Log Pis Min                  -16.007223
Policy mu Mean               0.0939896
Policy mu Std                0.47056574
Policy mu Max                2.7142878
Policy mu Min                -1.8064928
Policy log std Mean          -0.17830905
Policy log std Std           0.10277683
Policy log std Max           -0.05427271
Policy log std Min           -0.8516612
Z mean eval                  0.07354412
Z variance eval              0.25571066
total_rewards                [510.8123633  413.82650441 387.44420196 358.32551887 233.61144355
 581.57142749 434.33960195 384.89925218 344.43598478 424.29711956]
total_rewards_mean           407.35634180639715
total_rewards_std            89.19758434616577
total_rewards_max            581.57142749083
total_rewards_min            233.61144354731124
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               28.50445739692077
(Previous) Eval Time (s)     2.477695527020842
Sample Time (s)              14.077352504245937
Epoch Time (s)               45.05950542818755
Total Train Time (s)         1372.8624402433634
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:38:34.518002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #29 | Epoch Duration: 44.93554949760437
2020-01-10 18:38:34.518298 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07311803
Z variance train             0.25568774
KL Divergence                1.5903733
KL Loss                      0.15903734
QF Loss                      306.7881
VF Loss                      201.20154
Policy Loss                  -268.79227
Q Predictions Mean           260.90247
Q Predictions Std            423.89096
Q Predictions Max            1326.0955
Q Predictions Min            14.772324
V Predictions Mean           271.2245
V Predictions Std            425.36276
V Predictions Max            1360.0585
V Predictions Min            21.50914
Log Pis Mean                 -8.818242
Log Pis Std                  5.2458816
Log Pis Max                  16.942333
Log Pis Min                  -14.937386
Policy mu Mean               0.09933926
Policy mu Std                0.47678658
Policy mu Max                2.7551103
Policy mu Min                -2.5220718
Policy log std Mean          -0.18545619
Policy log std Std           0.10899918
Policy log std Max           -0.07547817
Policy log std Min           -0.85118824
Z mean eval                  0.076857775
Z variance eval              0.2503298
total_rewards                [365.92366554 587.55989873 444.28238732 391.76860337 413.00254812
 370.79573634 449.66883444 365.48762715 397.69335304 363.17810329]
total_rewards_mean           414.9360757332687
total_rewards_std            64.94533030186588
total_rewards_max            587.5598987258508
total_rewards_min            363.1781032933876
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               29.339934944175184
(Previous) Eval Time (s)     2.3534650462679565
Sample Time (s)              14.672052232082933
Epoch Time (s)               46.36545222252607
Total Train Time (s)         1419.2545330272987
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:39:20.909657 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #30 | Epoch Duration: 46.3911566734314
2020-01-10 18:39:20.909851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07675657
Z variance train             0.25030994
KL Divergence                1.630304
KL Loss                      0.1630304
QF Loss                      646.9778
VF Loss                      351.41418
Policy Loss                  -264.75745
Q Predictions Mean           258.65814
Q Predictions Std            421.73926
Q Predictions Max            1382.878
Q Predictions Min            17.087914
V Predictions Mean           270.7279
V Predictions Std            421.59808
V Predictions Max            1385.5587
V Predictions Min            21.740084
Log Pis Mean                 -8.535409
Log Pis Std                  5.1937265
Log Pis Max                  16.826786
Log Pis Min                  -12.918938
Policy mu Mean               0.11166004
Policy mu Std                0.49876437
Policy mu Max                2.5398378
Policy mu Min                -2.295317
Policy log std Mean          -0.18971793
Policy log std Std           0.114045724
Policy log std Max           -0.08151432
Policy log std Min           -0.84451723
Z mean eval                  0.077063404
Z variance eval              0.24829745
total_rewards                [330.34425213 472.47416619 476.10755135 392.32737885 378.16950561
 566.97462124 441.97874511 410.20964301 485.83402196 418.88707585]
total_rewards_mean           437.3306961306051
total_rewards_std            63.21992974152018
total_rewards_max            566.9746212438445
total_rewards_min            330.34425212785777
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               30.061023687943816
(Previous) Eval Time (s)     2.3789298380725086
Sample Time (s)              14.651121148839593
Epoch Time (s)               47.09107467485592
Total Train Time (s)         1466.6076230471954
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:40:08.263885 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #31 | Epoch Duration: 47.35390615463257
2020-01-10 18:40:08.264053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07710009
Z variance train             0.2483176
KL Divergence                1.6376894
KL Loss                      0.16376893
QF Loss                      633.3739
VF Loss                      308.69095
Policy Loss                  -307.1281
Q Predictions Mean           301.08615
Q Predictions Std            460.28436
Q Predictions Max            1377.3513
Q Predictions Min            15.757421
V Predictions Mean           313.20874
V Predictions Std            462.25766
V Predictions Max            1377.0671
V Predictions Min            26.922901
Log Pis Mean                 -8.720402
Log Pis Std                  4.9675164
Log Pis Max                  13.247938
Log Pis Min                  -13.268082
Policy mu Mean               0.11565436
Policy mu Std                0.4929501
Policy mu Max                2.5765245
Policy mu Min                -2.1653345
Policy log std Mean          -0.19111823
Policy log std Std           0.11366291
Policy log std Max           0.038578957
Policy log std Min           -0.8252287
Z mean eval                  0.075649515
Z variance eval              0.24128702
total_rewards                [396.39624241 367.17316147 364.5679921  392.86047428 387.31074192
 454.05334697 323.05345334 297.96570208 632.39237467 352.60367442]
total_rewards_mean           396.8377163659026
total_rewards_std            88.29731938040996
total_rewards_max            632.3923746708879
total_rewards_min            297.965702083624
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               30.086195063777268
(Previous) Eval Time (s)     2.641470046248287
Sample Time (s)              15.088220663368702
Epoch Time (s)               47.81588577339426
Total Train Time (s)         1514.2446968718432
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:40:55.902901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #32 | Epoch Duration: 47.638654947280884
2020-01-10 18:40:55.903125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07569021
Z variance train             0.24123271
KL Divergence                1.6948951
KL Loss                      0.16948952
QF Loss                      312.93884
VF Loss                      162.91876
Policy Loss                  -272.53387
Q Predictions Mean           264.13803
Q Predictions Std            431.3992
Q Predictions Max            1363.7695
Q Predictions Min            18.926277
V Predictions Mean           272.997
V Predictions Std            428.49622
V Predictions Max            1373.5566
V Predictions Min            30.05374
Log Pis Mean                 -8.44823
Log Pis Std                  5.292596
Log Pis Max                  9.134952
Log Pis Min                  -14.771905
Policy mu Mean               0.109092645
Policy mu Std                0.49713832
Policy mu Max                2.2404606
Policy mu Min                -2.0151048
Policy log std Mean          -0.18606794
Policy log std Std           0.11209877
Policy log std Max           -0.06998356
Policy log std Min           -0.7101392
Z mean eval                  0.07224205
Z variance eval              0.23401356
total_rewards                [340.46756876 408.61968164 328.8186454  446.07561184 492.50553717
 564.72294449 414.05468048 568.75864489 474.56766416 459.22007489]
total_rewards_mean           449.7811053706373
total_rewards_std            77.1115185517776
total_rewards_max            568.7586448876489
total_rewards_min            328.8186453976216
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               26.8084783940576
(Previous) Eval Time (s)     2.463960826396942
Sample Time (s)              14.824873632285744
Epoch Time (s)               44.09731285274029
Total Train Time (s)         1558.7317127618007
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:41:40.393425 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #33 | Epoch Duration: 44.49009323120117
2020-01-10 18:41:40.393732 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #33 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.072085455
Z variance train             0.23404446
KL Divergence                1.752306
KL Loss                      0.1752306
QF Loss                      725.35767
VF Loss                      518.0855
Policy Loss                  -287.95178
Q Predictions Mean           276.16074
Q Predictions Std            429.71445
Q Predictions Max            1400.7202
Q Predictions Min            13.44331
V Predictions Mean           282.64404
V Predictions Std            425.25174
V Predictions Max            1383.6528
V Predictions Min            12.886461
Log Pis Mean                 -8.543211
Log Pis Std                  5.3982954
Log Pis Max                  18.072039
Log Pis Min                  -14.913155
Policy mu Mean               0.13963208
Policy mu Std                0.49752378
Policy mu Max                2.8719153
Policy mu Min                -2.873848
Policy log std Mean          -0.1888073
Policy log std Std           0.10797903
Policy log std Max           -0.06795153
Policy log std Min           -0.8205447
Z mean eval                  0.070543036
Z variance eval              0.23104873
total_rewards                [394.41648851 462.95763248 479.05987882 316.38217097 562.5417329
 312.20665549 365.85693117 359.0518139  451.17123371 344.71992761]
total_rewards_mean           404.8364465560094
total_rewards_std            77.23192580593201
total_rewards_max            562.541732897464
total_rewards_min            312.20665549384165
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               29.65988288866356
(Previous) Eval Time (s)     2.8564751013182104
Sample Time (s)              14.642881444189698
Epoch Time (s)               47.15923943417147
Total Train Time (s)         1605.2951434766874
Epoch                        34
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:42:26.958872 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #34 | Epoch Duration: 46.56489181518555
2020-01-10 18:42:26.959146 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07054403
Z variance train             0.23106083
KL Divergence                1.7844524
KL Loss                      0.17844525
QF Loss                      735.3191
VF Loss                      319.58112
Policy Loss                  -264.29895
Q Predictions Mean           253.43729
Q Predictions Std            409.9892
Q Predictions Max            1396.4685
Q Predictions Min            16.905834
V Predictions Mean           263.64987
V Predictions Std            407.103
V Predictions Max            1386.1447
V Predictions Min            29.411093
Log Pis Mean                 -8.647006
Log Pis Std                  5.3996353
Log Pis Max                  16.138384
Log Pis Min                  -13.488781
Policy mu Mean               0.13301511
Policy mu Std                0.4940456
Policy mu Max                2.7924213
Policy mu Min                -2.4347625
Policy log std Mean          -0.18599038
Policy log std Std           0.11045283
Policy log std Max           -0.059082627
Policy log std Min           -0.83544254
Z mean eval                  0.06851625
Z variance eval              0.23090644
total_rewards                [326.75610157 339.64130282 518.48637405 236.81474392 254.39276729
 346.27903839 370.48588016 285.54872481 319.84850343 406.79005506]
total_rewards_mean           340.5043491503279
total_rewards_std            76.68566865019697
total_rewards_max            518.4863740481684
total_rewards_min            236.81474392413142
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               28.898961955681443
(Previous) Eval Time (s)     2.2618635832332075
Sample Time (s)              15.094688445329666
Epoch Time (s)               46.25551398424432
Total Train Time (s)         1651.3856873637997
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:43:13.047721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #35 | Epoch Duration: 46.08837699890137
2020-01-10 18:43:13.047908 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068708934
Z variance train             0.23083338
KL Divergence                1.7723147
KL Loss                      0.17723148
QF Loss                      634.9258
VF Loss                      454.59436
Policy Loss                  -321.97003
Q Predictions Mean           315.68933
Q Predictions Std            452.05725
Q Predictions Max            1390.2203
Q Predictions Min            16.37507
V Predictions Mean           322.4224
V Predictions Std            444.89636
V Predictions Max            1378.5068
V Predictions Min            13.031582
Log Pis Mean                 -7.973175
Log Pis Std                  5.356464
Log Pis Max                  9.16981
Log Pis Min                  -12.951699
Policy mu Mean               0.16730724
Policy mu Std                0.52566266
Policy mu Max                2.3662813
Policy mu Min                -1.8236136
Policy log std Mean          -0.19908097
Policy log std Std           0.118263096
Policy log std Max           -0.046322092
Policy log std Min           -0.65936625
Z mean eval                  0.067467295
Z variance eval              0.22402962
total_rewards                [285.76225291 404.72596837 591.19416016 410.85977765 348.83533891
 708.4422555  353.24353343 498.82324869 430.14675951 370.79011103]
total_rewards_mean           440.2823406152156
total_rewards_std            120.41086476006082
total_rewards_max            708.4422554985572
total_rewards_min            285.7622529072779
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               29.43502045609057
(Previous) Eval Time (s)     2.0944630848243833
Sample Time (s)              15.007344298064709
Epoch Time (s)               46.53682783897966
Total Train Time (s)         1698.4554422916844
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:44:00.119307 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #36 | Epoch Duration: 47.07125473022461
2020-01-10 18:44:00.119497 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06752057
Z variance train             0.22406927
KL Divergence                1.8240983
KL Loss                      0.18240984
QF Loss                      477.15723
VF Loss                      242.75613
Policy Loss                  -256.3601
Q Predictions Mean           243.2154
Q Predictions Std            397.63232
Q Predictions Max            1390.6609
Q Predictions Min            15.747646
V Predictions Mean           253.6962
V Predictions Std            396.78934
V Predictions Max            1399.5023
V Predictions Min            26.354536
Log Pis Mean                 -8.488961
Log Pis Std                  5.3442163
Log Pis Max                  12.193266
Log Pis Min                  -12.83714
Policy mu Mean               0.16084988
Policy mu Std                0.47282317
Policy mu Max                2.37641
Policy mu Min                -1.6655641
Policy log std Mean          -0.1861924
Policy log std Std           0.11006806
Policy log std Max           -0.08575863
Policy log std Min           -0.7442971
Z mean eval                  0.06476614
Z variance eval              0.21952227
total_rewards                [401.18156744 411.25201047 431.7042906  313.1720865  363.61363293
 389.08016379 230.91519651 275.69831081 634.70595822 533.45778793]
total_rewards_mean           398.478100519657
total_rewards_std            112.70791892608612
total_rewards_max            634.7059582192699
total_rewards_min            230.91519650840593
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               28.311438297852874
(Previous) Eval Time (s)     2.6285948711447418
Sample Time (s)              15.602520405314863
Epoch Time (s)               46.54255357431248
Total Train Time (s)         1744.9813335835934
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:44:46.647774 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #37 | Epoch Duration: 46.528106927871704
2020-01-10 18:44:46.648021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06449141
Z variance train             0.21950233
KL Divergence                1.8656461
KL Loss                      0.18656461
QF Loss                      632.18475
VF Loss                      366.8207
Policy Loss                  -283.14316
Q Predictions Mean           278.34085
Q Predictions Std            452.1845
Q Predictions Max            1396.1362
Q Predictions Min            17.025286
V Predictions Mean           289.17337
V Predictions Std            449.94714
V Predictions Max            1382.3978
V Predictions Min            29.365171
Log Pis Mean                 -8.519749
Log Pis Std                  5.1575823
Log Pis Max                  7.956127
Log Pis Min                  -13.875981
Policy mu Mean               0.12458329
Policy mu Std                0.4845235
Policy mu Max                2.4987185
Policy mu Min                -1.8120395
Policy log std Mean          -0.18438868
Policy log std Std           0.11032452
Policy log std Max           -0.057816923
Policy log std Min           -0.80766237
Z mean eval                  0.061061494
Z variance eval              0.21480438
total_rewards                [726.85213509 308.78940625 433.62130958 492.91213818 416.73520753
 598.56198298 226.12235077 334.05304169 343.97172805 462.09493987]
total_rewards_mean           434.3714239991972
total_rewards_std            139.42206278423762
total_rewards_max            726.8521350868954
total_rewards_min            226.1223507678305
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               30.06010342389345
(Previous) Eval Time (s)     2.6138536506332457
Sample Time (s)              14.989127045031637
Epoch Time (s)               47.663084119558334
Total Train Time (s)         1792.7974860477261
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:45:34.463188 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #38 | Epoch Duration: 47.81500434875488
2020-01-10 18:45:34.463328 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061149634
Z variance train             0.21486571
KL Divergence                1.9108815
KL Loss                      0.19108815
QF Loss                      229.88657
VF Loss                      124.3402
Policy Loss                  -263.88962
Q Predictions Mean           253.68393
Q Predictions Std            429.94687
Q Predictions Max            1426.798
Q Predictions Min            17.140087
V Predictions Mean           259.76645
V Predictions Std            422.93457
V Predictions Max            1411.375
V Predictions Min            28.456589
Log Pis Mean                 -8.864034
Log Pis Std                  4.672903
Log Pis Max                  7.0200005
Log Pis Min                  -13.220898
Policy mu Mean               0.109464705
Policy mu Std                0.47281456
Policy mu Max                2.2114317
Policy mu Min                -1.8783911
Policy log std Mean          -0.18326664
Policy log std Std           0.10789739
Policy log std Max           -0.07489814
Policy log std Min           -0.6911335
Z mean eval                  0.061048996
Z variance eval              0.21317509
total_rewards                [362.18253481 321.82910258 328.20401567 304.40389979 413.62123879
 278.65004044 257.586719   361.03493633 585.04957766 386.31902009]
total_rewards_mean           359.8881085174803
total_rewards_std            87.6847616533309
total_rewards_max            585.0495776644317
total_rewards_min            257.5867190008766
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               28.56821842910722
(Previous) Eval Time (s)     2.765498989727348
Sample Time (s)              15.502181211486459
Epoch Time (s)               46.835898630321026
Total Train Time (s)         1839.158522624988
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:46:20.827685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #39 | Epoch Duration: 46.3642053604126
2020-01-10 18:46:20.827971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061127227
Z variance train             0.21315686
KL Divergence                1.9324515
KL Loss                      0.19324516
QF Loss                      433.76004
VF Loss                      112.61423
Policy Loss                  -260.24915
Q Predictions Mean           249.10327
Q Predictions Std            425.66904
Q Predictions Max            1394.6487
Q Predictions Min            16.466688
V Predictions Mean           260.82858
V Predictions Std            424.44217
V Predictions Max            1395.5325
V Predictions Min            26.2429
Log Pis Mean                 -8.9532
Log Pis Std                  5.060437
Log Pis Max                  11.260677
Log Pis Min                  -13.558026
Policy mu Mean               0.08943007
Policy mu Std                0.471062
Policy mu Max                2.3107946
Policy mu Min                -2.0048194
Policy log std Mean          -0.18324693
Policy log std Std           0.11044882
Policy log std Max           -0.04828669
Policy log std Min           -0.70684874
Z mean eval                  0.06061719
Z variance eval              0.21908097
total_rewards                [481.41815497 338.02579183 385.81638885 380.59405424 383.32575966
 515.65891492 353.11860803 511.13812031 355.17147857 358.91663688]
total_rewards_mean           406.3183908245232
total_rewards_std            65.23056340014905
total_rewards_max            515.6589149175011
total_rewards_min            338.02579183411143
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               29.37916994187981
(Previous) Eval Time (s)     2.2935030637308955
Sample Time (s)              15.046517287380993
Epoch Time (s)               46.7191902929917
Total Train Time (s)         1886.3362390529364
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:47:08.005765 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #40 | Epoch Duration: 47.17760467529297
2020-01-10 18:47:08.005961 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.060628913
Z variance train             0.21902986
KL Divergence                1.8837495
KL Loss                      0.18837495
QF Loss                      465.20813
VF Loss                      350.55823
Policy Loss                  -312.44284
Q Predictions Mean           305.27405
Q Predictions Std            464.64966
Q Predictions Max            1373.2157
Q Predictions Min            17.792439
V Predictions Mean           317.16412
V Predictions Std            465.4722
V Predictions Max            1418.0153
V Predictions Min            27.952585
Log Pis Mean                 -8.252048
Log Pis Std                  5.476054
Log Pis Max                  11.749509
Log Pis Min                  -14.635162
Policy mu Mean               0.11958125
Policy mu Std                0.5275799
Policy mu Max                2.1597743
Policy mu Min                -1.7310485
Policy log std Mean          -0.19187252
Policy log std Std           0.11403767
Policy log std Max           -0.046594106
Policy log std Min           -0.6754937
Z mean eval                  0.058975983
Z variance eval              0.21330726
total_rewards                [439.35571468 310.10121698 416.3690046  343.39415305 362.99789523
 441.12859251 406.25677113 753.95561103 565.62137958 390.4270118 ]
total_rewards_mean           442.96073505860466
total_rewards_std            122.70008322674231
total_rewards_max            753.9556110311613
total_rewards_min            310.1012169837729
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               28.121662674937397
(Previous) Eval Time (s)     2.751653949264437
Sample Time (s)              15.851657079998404
Epoch Time (s)               46.72497370420024
Total Train Time (s)         1933.1021690377966
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:47:54.772926 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #41 | Epoch Duration: 46.76681566238403
2020-01-10 18:47:54.773130 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058925927
Z variance train             0.21325834
KL Divergence                1.9244871
KL Loss                      0.19244872
QF Loss                      618.60596
VF Loss                      123.29894
Policy Loss                  -308.03516
Q Predictions Mean           302.21182
Q Predictions Std            442.2882
Q Predictions Max            1408.2361
Q Predictions Min            14.975464
V Predictions Mean           309.87125
V Predictions Std            436.2058
V Predictions Max            1409.9604
V Predictions Min            28.314535
Log Pis Mean                 -8.242598
Log Pis Std                  5.199874
Log Pis Max                  7.2736244
Log Pis Min                  -16.298977
Policy mu Mean               0.15561819
Policy mu Std                0.51430494
Policy mu Max                2.2081418
Policy mu Min                -2.1530826
Policy log std Mean          -0.19632603
Policy log std Std           0.11378673
Policy log std Max           -0.062217683
Policy log std Min           -0.70918155
Z mean eval                  0.057864875
Z variance eval              0.21223155
total_rewards                [531.89171415 521.82613596 402.23940717 430.20713424 362.11667386
 319.71389432 607.69676061 674.25442522 447.89267026 292.90723114]
total_rewards_mean           459.07460469341476
total_rewards_std            117.58122157183598
total_rewards_max            674.2544252230373
total_rewards_min            292.9072311350431
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               29.876233558170497
(Previous) Eval Time (s)     2.793188137933612
Sample Time (s)              15.50439037103206
Epoch Time (s)               48.17381206713617
Total Train Time (s)         1981.2631133543327
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:48:42.936707 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #42 | Epoch Duration: 48.16339683532715
2020-01-10 18:48:42.936950 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057839967
Z variance train             0.21223135
KL Divergence                1.9346758
KL Loss                      0.19346759
QF Loss                      868.8207
VF Loss                      254.52472
Policy Loss                  -289.66888
Q Predictions Mean           285.02982
Q Predictions Std            460.1375
Q Predictions Max            1420.2006
Q Predictions Min            14.913112
V Predictions Mean           296.0226
V Predictions Std            458.49716
V Predictions Max            1409.6
V Predictions Min            24.444632
Log Pis Mean                 -8.44869
Log Pis Std                  5.3673396
Log Pis Max                  11.149096
Log Pis Min                  -13.006442
Policy mu Mean               0.12419265
Policy mu Std                0.4886939
Policy mu Max                2.2321818
Policy mu Min                -2.0328095
Policy log std Mean          -0.1894725
Policy log std Std           0.11657756
Policy log std Max           -0.05097288
Policy log std Min           -0.7617391
Z mean eval                  0.057677448
Z variance eval              0.20763497
total_rewards                [365.84301597 596.84481327 396.10163102 386.42119261 415.92740231
 391.22500604 477.51385838 411.76042777 406.07749846 531.20393657]
total_rewards_mean           437.89187824003994
total_rewards_std            70.34558587243394
total_rewards_max            596.8448132670455
total_rewards_min            365.84301597443
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               29.415200907271355
(Previous) Eval Time (s)     2.782473268918693
Sample Time (s)              15.323828437831253
Epoch Time (s)               47.5215026140213
Total Train Time (s)         2028.7039079563692
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:49:30.379259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #43 | Epoch Duration: 47.44210696220398
2020-01-10 18:49:30.379484 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057653077
Z variance train             0.20761128
KL Divergence                1.9761007
KL Loss                      0.19761007
QF Loss                      758.7517
VF Loss                      102.18637
Policy Loss                  -292.66544
Q Predictions Mean           285.48706
Q Predictions Std            454.13318
Q Predictions Max            1442.5701
Q Predictions Min            15.26025
V Predictions Mean           293.77856
V Predictions Std            449.10184
V Predictions Max            1408.4337
V Predictions Min            24.956488
Log Pis Mean                 -8.2952175
Log Pis Std                  5.532467
Log Pis Max                  9.672121
Log Pis Min                  -13.489283
Policy mu Mean               0.15372531
Policy mu Std                0.5053267
Policy mu Max                2.220722
Policy mu Min                -1.6948655
Policy log std Mean          -0.19288717
Policy log std Std           0.11621113
Policy log std Max           -0.088102415
Policy log std Min           -0.8294046
Z mean eval                  0.055144258
Z variance eval              0.20736916
total_rewards                [551.80530526 299.3650434  574.73337159 569.29573609 601.18875412
 584.40846453 341.3743827  338.04991658 328.70053969 834.93610183]
total_rewards_mean           502.3857615792368
total_rewards_std            162.34155321166537
total_rewards_max            834.9361018309452
total_rewards_min            299.36504340143057
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               30.049361408688128
(Previous) Eval Time (s)     2.7028127517551184
Sample Time (s)              15.371022967621684
Epoch Time (s)               48.12319712806493
Total Train Time (s)         2076.9848831701092
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:50:18.661771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #44 | Epoch Duration: 48.282081842422485
2020-01-10 18:50:18.662020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055297147
Z variance train             0.20734882
KL Divergence                1.9759644
KL Loss                      0.19759645
QF Loss                      572.3775
VF Loss                      159.4213
Policy Loss                  -325.02182
Q Predictions Mean           314.3524
Q Predictions Std            475.94266
Q Predictions Max            1423.729
Q Predictions Min            16.700748
V Predictions Mean           322.15408
V Predictions Std            472.01984
V Predictions Max            1426.9369
V Predictions Min            28.147303
Log Pis Mean                 -8.523071
Log Pis Std                  4.981628
Log Pis Max                  9.822711
Log Pis Min                  -14.054959
Policy mu Mean               0.12840277
Policy mu Std                0.51693213
Policy mu Max                2.4882362
Policy mu Min                -1.9536452
Policy log std Mean          -0.19164109
Policy log std Std           0.11364066
Policy log std Max           -0.07185815
Policy log std Min           -0.7436504
Z mean eval                  0.05499495
Z variance eval              0.20845318
total_rewards                [333.95116096 438.56220286 458.82239748 289.38019095 687.50364851
 469.55614242 444.47768528 407.44970241 700.50010486 556.78949444]
total_rewards_mean           478.6992730164673
total_rewards_std            128.07184682650683
total_rewards_max            700.5001048612164
total_rewards_min            289.3801909450915
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               28.95242449408397
(Previous) Eval Time (s)     2.861392774619162
Sample Time (s)              15.885226044338197
Epoch Time (s)               47.69904331304133
Total Train Time (s)         2124.846480135806
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:51:06.524254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #45 | Epoch Duration: 47.862016916275024
2020-01-10 18:51:06.524524 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05502355
Z variance train             0.20846288
KL Divergence                1.9681617
KL Loss                      0.19681618
QF Loss                      631.23883
VF Loss                      132.52344
Policy Loss                  -389.81845
Q Predictions Mean           381.88647
Q Predictions Std            504.82748
Q Predictions Max            1443.0292
Q Predictions Min            16.145977
V Predictions Mean           387.46045
V Predictions Std            497.69077
V Predictions Max            1448.7268
V Predictions Min            25.09509
Log Pis Mean                 -7.793885
Log Pis Std                  5.185053
Log Pis Max                  6.057217
Log Pis Min                  -13.803915
Policy mu Mean               0.16199401
Policy mu Std                0.55916536
Policy mu Max                2.2998133
Policy mu Min                -2.159678
Policy log std Mean          -0.20552267
Policy log std Std           0.12311974
Policy log std Max           -0.028983608
Policy log std Min           -0.7793852
Z mean eval                  0.05493179
Z variance eval              0.20847395
total_rewards                [333.30640812 397.53548696 397.920823   562.03450243 388.13200522
 471.52833312 386.50147415 388.27955689 407.97098846 410.28784792]
total_rewards_mean           414.3497426276266
total_rewards_std            58.6519974434973
total_rewards_max            562.0345024313369
total_rewards_min            333.3064081181012
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               28.780391518957913
(Previous) Eval Time (s)     3.0240674037486315
Sample Time (s)              15.628536849282682
Epoch Time (s)               47.432995771989226
Total Train Time (s)         2172.1095556849614
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:51:53.790646 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #46 | Epoch Duration: 47.2659010887146
2020-01-10 18:51:53.790905 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054832287
Z variance train             0.20851707
KL Divergence                1.9619955
KL Loss                      0.19619955
QF Loss                      563.7736
VF Loss                      183.5419
Policy Loss                  -317.86368
Q Predictions Mean           309.5315
Q Predictions Std            471.16562
Q Predictions Max            1410.3815
Q Predictions Min            18.527342
V Predictions Mean           317.7494
V Predictions Std            470.32758
V Predictions Max            1435.6466
V Predictions Min            22.864746
Log Pis Mean                 -8.215149
Log Pis Std                  5.5967455
Log Pis Max                  11.709699
Log Pis Min                  -15.062069
Policy mu Mean               0.11918133
Policy mu Std                0.5266056
Policy mu Max                2.8718219
Policy mu Min                -2.1790109
Policy log std Mean          -0.19440599
Policy log std Std           0.11864989
Policy log std Max           0.03375733
Policy log std Min           -0.8122005
Z mean eval                  0.05294656
Z variance eval              0.20273383
total_rewards                [512.91151224 549.77411431 544.28751977 333.87498221 423.44394614
 531.08207889 528.85730142 625.76248972 346.58130896 346.41401332]
total_rewards_mean           474.29892669815234
total_rewards_std            98.08131656852396
total_rewards_max            625.7624897223828
total_rewards_min            333.87498221151293
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               29.992644269950688
(Previous) Eval Time (s)     2.8566961023025215
Sample Time (s)              14.558768478222191
Epoch Time (s)               47.4081088504754
Total Train Time (s)         2219.572987737134
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:52:41.252717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #47 | Epoch Duration: 47.46162128448486
2020-01-10 18:52:41.252886 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05292474
Z variance train             0.20273693
KL Divergence                2.0176373
KL Loss                      0.20176373
QF Loss                      452.3009
VF Loss                      160.87376
Policy Loss                  -328.65808
Q Predictions Mean           321.51733
Q Predictions Std            489.27573
Q Predictions Max            1464.2544
Q Predictions Min            17.59993
V Predictions Mean           326.2052
V Predictions Std            482.5409
V Predictions Max            1422.7197
V Predictions Min            23.244501
Log Pis Mean                 -9.1922655
Log Pis Std                  4.155115
Log Pis Max                  9.605139
Log Pis Min                  -14.557643
Policy mu Mean               0.113279775
Policy mu Std                0.4593607
Policy mu Max                2.3459308
Policy mu Min                -2.0462968
Policy log std Mean          -0.1836716
Policy log std Std           0.10233687
Policy log std Max           -0.05112011
Policy log std Min           -0.70370334
Z mean eval                  0.052569233
Z variance eval              0.19816259
total_rewards                [304.70926946 631.73154181 350.68803471 295.23510041 419.58440776
 334.9010911  364.23854873 616.54252863 671.65762271 457.75421859]
total_rewards_mean           444.704236391194
total_rewards_std            136.4283241133271
total_rewards_max            671.6576227120768
total_rewards_min            295.2351004056543
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               28.972232873085886
(Previous) Eval Time (s)     2.9099656301550567
Sample Time (s)              15.174305133987218
Epoch Time (s)               47.05650363722816
Total Train Time (s)         2266.4011849300005
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:53:28.085245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #48 | Epoch Duration: 46.832199811935425
2020-01-10 18:53:28.085529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #48 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052394163
Z variance train             0.19813876
KL Divergence                2.0682926
KL Loss                      0.20682926
QF Loss                      551.1388
VF Loss                      199.52185
Policy Loss                  -326.55353
Q Predictions Mean           320.30975
Q Predictions Std            461.04926
Q Predictions Max            1441.5763
Q Predictions Min            20.933718
V Predictions Mean           327.77472
V Predictions Std            457.66763
V Predictions Max            1452.0583
V Predictions Min            28.150742
Log Pis Mean                 -8.694656
Log Pis Std                  4.412686
Log Pis Max                  5.3019886
Log Pis Min                  -13.062882
Policy mu Mean               0.14684685
Policy mu Std                0.4917721
Policy mu Max                2.343265
Policy mu Min                -2.4962401
Policy log std Mean          -0.19527242
Policy log std Std           0.11215237
Policy log std Max           -0.05679506
Policy log std Min           -0.7118468
Z mean eval                  0.052771337
Z variance eval              0.1976796
total_rewards                [624.35514576 381.48334532 647.27397407 592.7021959  337.68052865
 496.38403974 505.51429125 317.17474525 521.11448488 542.77126666]
total_rewards_mean           496.64540174852266
total_rewards_std            110.35060345820666
total_rewards_max            647.2739740714969
total_rewards_min            317.17474525426485
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               29.6387547547929
(Previous) Eval Time (s)     2.6853926139883697
Sample Time (s)              15.35027790395543
Epoch Time (s)               47.6744252727367
Total Train Time (s)         2314.304562740959
Epoch                        49
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:54:15.988098 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #49 | Epoch Duration: 47.902353286743164
2020-01-10 18:54:15.988290 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #49 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052661914
Z variance train             0.19767639
KL Divergence                2.0764174
KL Loss                      0.20764175
QF Loss                      509.60837
VF Loss                      155.32089
Policy Loss                  -405.38147
Q Predictions Mean           399.10352
Q Predictions Std            509.6202
Q Predictions Max            1454.168
Q Predictions Min            17.252094
V Predictions Mean           406.20563
V Predictions Std            505.0195
V Predictions Max            1467.8822
V Predictions Min            28.39806
Log Pis Mean                 -7.329221
Log Pis Std                  5.580095
Log Pis Max                  6.4943957
Log Pis Min                  -14.329434
Policy mu Mean               0.19135767
Policy mu Std                0.5769896
Policy mu Max                2.282282
Policy mu Min                -1.8786446
Policy log std Mean          -0.20934185
Policy log std Std           0.12191504
Policy log std Max           -0.043911666
Policy log std Min           -0.690775
Z mean eval                  0.05095006
Z variance eval              0.19460562
total_rewards                [ 633.28848635 1118.81082438  391.95102135  941.82657559  785.54715729
  458.6381259   397.50187488  454.55673027  313.85667652  426.37181586]
total_rewards_mean           592.2349288398084
total_rewards_std            256.5919965882652
total_rewards_max            1118.810824384294
total_rewards_min            313.856676517532
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               28.10394454281777
(Previous) Eval Time (s)     2.913055815268308
Sample Time (s)              15.40587470587343
Epoch Time (s)               46.42287506395951
Total Train Time (s)         2361.535105658695
Epoch                        50
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:55:03.219173 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #50 | Epoch Duration: 47.230740785598755
2020-01-10 18:55:03.219341 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050997514
Z variance train             0.19461535
KL Divergence                2.107809
KL Loss                      0.2107809
QF Loss                      677.15094
VF Loss                      214.42662
Policy Loss                  -368.53925
Q Predictions Mean           360.66614
Q Predictions Std            500.96765
Q Predictions Max            1465.4336
Q Predictions Min            14.2770815
V Predictions Mean           368.34586
V Predictions Std            497.2864
V Predictions Max            1463.195
V Predictions Min            24.694635
Log Pis Mean                 -8.058878
Log Pis Std                  5.1260223
Log Pis Max                  5.7057886
Log Pis Min                  -13.463812
Policy mu Mean               0.17486209
Policy mu Std                0.52729356
Policy mu Max                2.1512058
Policy mu Min                -1.9319104
Policy log std Mean          -0.2043811
Policy log std Std           0.12359242
Policy log std Max           -0.08849114
Policy log std Min           -0.7581008
Z mean eval                  0.05180139
Z variance eval              0.18922475
total_rewards                [339.40562938 571.15720891 324.01467478 510.55652561 521.12999946
 488.27522791 264.35749189 577.08381159 424.92386842 500.07095878]
total_rewards_mean           452.09753967181234
total_rewards_std            103.28572093480281
total_rewards_max            577.0838115915546
total_rewards_min            264.35749188711856
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               28.953416743781418
(Previous) Eval Time (s)     3.7206378718838096
Sample Time (s)              15.404344980139285
Epoch Time (s)               48.07839959580451
Total Train Time (s)         2409.0295669492334
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:55:50.718589 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #51 | Epoch Duration: 47.49907422065735
2020-01-10 18:55:50.718914 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051880352
Z variance train             0.18921664
KL Divergence                2.1660244
KL Loss                      0.21660244
QF Loss                      738.56055
VF Loss                      149.78796
Policy Loss                  -348.22122
Q Predictions Mean           342.88104
Q Predictions Std            489.4673
Q Predictions Max            1462.2009
Q Predictions Min            16.468279
V Predictions Mean           345.58185
V Predictions Std            479.6263
V Predictions Max            1463.8153
V Predictions Min            24.041918
Log Pis Mean                 -8.337919
Log Pis Std                  4.9621706
Log Pis Max                  9.571594
Log Pis Min                  -13.534017
Policy mu Mean               0.15423247
Policy mu Std                0.5130867
Policy mu Max                2.4746463
Policy mu Min                -2.0106883
Policy log std Mean          -0.19259632
Policy log std Std           0.11529893
Policy log std Max           -0.05647345
Policy log std Min           -0.68287694
Z mean eval                  0.052110035
Z variance eval              0.18754062
total_rewards                [522.12330223 486.47383458 553.64082914 431.18092634 425.43382656
 443.55213988 390.67661969 447.86062896 463.92894292 384.02329149]
total_rewards_mean           454.8894341786445
total_rewards_std            51.09254184435932
total_rewards_max            553.6408291390753
total_rewards_min            384.02329148535335
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               29.337612344883382
(Previous) Eval Time (s)     3.1410077367909253
Sample Time (s)              14.786245379131287
Epoch Time (s)               47.264865460805595
Total Train Time (s)         2455.9566576168872
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:56:37.646642 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #52 | Epoch Duration: 46.92747473716736
2020-01-10 18:56:37.646908 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #52 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052166183
Z variance train             0.1875366
KL Divergence                2.1863327
KL Loss                      0.21863328
QF Loss                      592.2448
VF Loss                      173.52321
Policy Loss                  -350.98932
Q Predictions Mean           343.3743
Q Predictions Std            502.6125
Q Predictions Max            1472.3278
Q Predictions Min            17.396595
V Predictions Mean           347.6486
V Predictions Std            493.267
V Predictions Max            1460.8776
V Predictions Min            26.524076
Log Pis Mean                 -8.261487
Log Pis Std                  5.250941
Log Pis Max                  5.938769
Log Pis Min                  -14.122036
Policy mu Mean               0.15144193
Policy mu Std                0.53074646
Policy mu Max                2.3312654
Policy mu Min                -1.9523895
Policy log std Mean          -0.19988877
Policy log std Std           0.11920903
Policy log std Max           -0.044039503
Policy log std Min           -0.69689786
Z mean eval                  0.05247301
Z variance eval              0.19659397
total_rewards                [487.86667141 780.49785758 361.68136224 736.64558183 430.33347022
 459.11599257 444.11845155 467.07271181 719.12605121 404.47265873]
total_rewards_mean           529.0930809155984
total_rewards_std            146.0715405546758
total_rewards_max            780.49785758419
total_rewards_min            361.68136224434767
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               29.405104795005172
(Previous) Eval Time (s)     2.8033539783209562
Sample Time (s)              15.163821263704449
Epoch Time (s)               47.37228003703058
Total Train Time (s)         2503.755238433834
Epoch                        53
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:57:25.447922 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #53 | Epoch Duration: 47.800779819488525
2020-01-10 18:57:25.448193 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052313752
Z variance train             0.19653039
KL Divergence                2.0943868
KL Loss                      0.20943868
QF Loss                      913.27814
VF Loss                      165.7413
Policy Loss                  -377.10266
Q Predictions Mean           369.32513
Q Predictions Std            496.55295
Q Predictions Max            1472.051
Q Predictions Min            15.574758
V Predictions Mean           378.21063
V Predictions Std            494.5115
V Predictions Max            1461.1
V Predictions Min            24.476778
Log Pis Mean                 -7.9063725
Log Pis Std                  5.096348
Log Pis Max                  11.100575
Log Pis Min                  -12.873631
Policy mu Mean               0.16986285
Policy mu Std                0.5400235
Policy mu Max                2.604579
Policy mu Min                -1.8962703
Policy log std Mean          -0.20552883
Policy log std Std           0.12330931
Policy log std Max           -0.067517
Policy log std Min           -0.7618009
Z mean eval                  0.05285403
Z variance eval              0.18786576
total_rewards                [370.00203923 609.94088014 486.97907046 425.20547026 431.35872982
 419.43382111 322.14236161 448.19516219 455.47266498 453.27313954]
total_rewards_mean           442.2003339342656
total_rewards_std            71.43382686381652
total_rewards_max            609.9408801439728
total_rewards_min            322.1423616075615
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               29.544628193136305
(Previous) Eval Time (s)     3.23157563759014
Sample Time (s)              15.103885744698346
Epoch Time (s)               47.88008957542479
Total Train Time (s)         2551.2140518524684
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:58:12.906292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #54 | Epoch Duration: 47.45788908004761
2020-01-10 18:58:12.906458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052895837
Z variance train             0.18791635
KL Divergence                2.178265
KL Loss                      0.21782652
QF Loss                      373.93063
VF Loss                      294.10327
Policy Loss                  -328.76477
Q Predictions Mean           319.91263
Q Predictions Std            455.55795
Q Predictions Max            1467.4849
Q Predictions Min            14.672165
V Predictions Mean           332.00317
V Predictions Std            454.4953
V Predictions Max            1468.6511
V Predictions Min            28.339508
Log Pis Mean                 -7.915146
Log Pis Std                  5.475192
Log Pis Max                  10.701864
Log Pis Min                  -12.872934
Policy mu Mean               0.16525833
Policy mu Std                0.53263146
Policy mu Max                2.4215508
Policy mu Min                -2.3048832
Policy log std Mean          -0.19934298
Policy log std Std           0.11510062
Policy log std Max           -0.027319632
Policy log std Min           -0.7032553
Z mean eval                  0.05427609
Z variance eval              0.1929049
total_rewards                [563.77373638 395.50655118 466.49240262 398.68202385 450.94209034
 512.30515745 553.97815256 459.33787767 402.91549658 344.11552861]
total_rewards_mean           454.8049017219605
total_rewards_std            68.4095069138021
total_rewards_max            563.773736377976
total_rewards_min            344.1155286068299
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               29.612082125619054
(Previous) Eval Time (s)     2.809118981938809
Sample Time (s)              14.642541883513331
Epoch Time (s)               47.063742991071194
Total Train Time (s)         2598.2623136998154
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:58:59.958392 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #55 | Epoch Duration: 47.051753520965576
2020-01-10 18:58:59.958685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054372203
Z variance train             0.1928606
KL Divergence                2.1280375
KL Loss                      0.21280375
QF Loss                      567.07184
VF Loss                      253.85277
Policy Loss                  -332.7091
Q Predictions Mean           326.1825
Q Predictions Std            493.28433
Q Predictions Max            1499.007
Q Predictions Min            15.068592
V Predictions Mean           330.13208
V Predictions Std            482.25955
V Predictions Max            1456.6028
V Predictions Min            24.276312
Log Pis Mean                 -8.094526
Log Pis Std                  5.360708
Log Pis Max                  9.259875
Log Pis Min                  -13.554456
Policy mu Mean               0.15547276
Policy mu Std                0.51009417
Policy mu Max                2.0743737
Policy mu Min                -2.0840044
Policy log std Mean          -0.19438925
Policy log std Std           0.11096976
Policy log std Max           -0.046764024
Policy log std Min           -0.679855
Z mean eval                  0.054860987
Z variance eval              0.18747114
total_rewards                [554.03586485 428.22701521 454.98828202 587.0988831  564.72040646
 449.22554133 618.45350674 559.12331949 518.9721478  357.10942727]
total_rewards_mean           509.1954394277317
total_rewards_std            78.68238695321183
total_rewards_max            618.4535067447998
total_rewards_min            357.1094272677001
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               31.55522852903232
(Previous) Eval Time (s)     2.7968473536893725
Sample Time (s)              15.406065572984517
Epoch Time (s)               49.75814145570621
Total Train Time (s)         2648.6390900309198
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 18:59:50.335097 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #56 | Epoch Duration: 50.37619161605835
2020-01-10 18:59:50.335292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05488683
Z variance train             0.1874723
KL Divergence                2.1983516
KL Loss                      0.21983516
QF Loss                      490.96088
VF Loss                      212.0051
Policy Loss                  -340.81146
Q Predictions Mean           331.39673
Q Predictions Std            493.03223
Q Predictions Max            1484.319
Q Predictions Min            15.310037
V Predictions Mean           335.7619
V Predictions Std            484.84872
V Predictions Max            1466.7358
V Predictions Min            23.870245
Log Pis Mean                 -8.208284
Log Pis Std                  5.3435087
Log Pis Max                  11.529324
Log Pis Min                  -13.3849125
Policy mu Mean               0.15136452
Policy mu Std                0.53143716
Policy mu Max                2.8078837
Policy mu Min                -2.1300771
Policy log std Mean          -0.1985215
Policy log std Std           0.12457074
Policy log std Max           -0.04132215
Policy log std Min           -0.7930511
Z mean eval                  0.055101644
Z variance eval              0.18951866
total_rewards                [683.30059702 381.65701845 375.81936603 491.18173746 320.06660487
 529.96054999 555.08620285 530.19942664 573.51696354 518.89574505]
total_rewards_mean           495.96842119093435
total_rewards_std            102.9184992805348
total_rewards_max            683.3005970221985
total_rewards_min            320.0666048739533
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               29.92888205870986
(Previous) Eval Time (s)     3.414639593102038
Sample Time (s)              15.569766778033227
Epoch Time (s)               48.913288429845124
Total Train Time (s)         2697.18105755141
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:00:38.877496 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #57 | Epoch Duration: 48.542070150375366
2020-01-10 19:00:38.877641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055277877
Z variance train             0.18948542
KL Divergence                2.1819906
KL Loss                      0.21819906
QF Loss                      647.1181
VF Loss                      560.47235
Policy Loss                  -438.4054
Q Predictions Mean           429.1432
Q Predictions Std            544.96246
Q Predictions Max            1483.782
Q Predictions Min            15.661069
V Predictions Mean           430.24103
V Predictions Std            531.4871
V Predictions Max            1484.3604
V Predictions Min            26.890541
Log Pis Mean                 -7.403731
Log Pis Std                  5.5869274
Log Pis Max                  8.272204
Log Pis Min                  -14.371599
Policy mu Mean               0.1888563
Policy mu Std                0.5624241
Policy mu Max                2.4468899
Policy mu Min                -2.1583555
Policy log std Mean          -0.21157978
Policy log std Std           0.12810338
Policy log std Max           -0.036609434
Policy log std Min           -0.725216
Z mean eval                  0.055945735
Z variance eval              0.183646
total_rewards                [581.94642397 554.53990142 477.68330068 401.79367494 433.03785027
 465.11223264 484.47172658 457.63020926 598.88060625 615.47835382]
total_rewards_mean           507.0574279839144
total_rewards_std            70.84087693410223
total_rewards_max            615.4783538244923
total_rewards_min            401.7936749395179
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               28.255586883984506
(Previous) Eval Time (s)     3.0431041410192847
Sample Time (s)              15.30225224327296
Epoch Time (s)               46.60094326827675
Total Train Time (s)         2743.9346259692684
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:01:25.633765 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #58 | Epoch Duration: 46.75599670410156
2020-01-10 19:01:25.633958 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056336123
Z variance train             0.1836278
KL Divergence                2.2447743
KL Loss                      0.22447744
QF Loss                      436.26324
VF Loss                      590.32294
Policy Loss                  -326.0384
Q Predictions Mean           315.52283
Q Predictions Std            480.10788
Q Predictions Max            1483.0121
Q Predictions Min            13.171864
V Predictions Mean           313.41815
V Predictions Std            461.6731
V Predictions Max            1461.202
V Predictions Min            21.686565
Log Pis Mean                 -8.665829
Log Pis Std                  4.591591
Log Pis Max                  4.4580884
Log Pis Min                  -13.219149
Policy mu Mean               0.15084627
Policy mu Std                0.4856527
Policy mu Max                2.233676
Policy mu Min                -1.9771116
Policy log std Mean          -0.19090058
Policy log std Std           0.1124097
Policy log std Max           -0.07589186
Policy log std Min           -0.75733185
Z mean eval                  0.05711884
Z variance eval              0.19100025
total_rewards                [400.40391466 356.4858449  529.64218784 254.51462785 216.99194133
 554.05893211 691.68372954 410.3317673  554.55254866 408.54569804]
total_rewards_mean           437.7211192239699
total_rewards_std            138.56755526130166
total_rewards_max            691.6837295393211
total_rewards_min            216.99194133216156
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               28.70942292176187
(Previous) Eval Time (s)     3.197861331049353
Sample Time (s)              15.740273261908442
Epoch Time (s)               47.647557514719665
Total Train Time (s)         2790.979160121642
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:02:12.680879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #59 | Epoch Duration: 47.0467574596405
2020-01-10 19:02:12.681091 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.057210356
Z variance train             0.19102848
KL Divergence                2.1859984
KL Loss                      0.21859984
QF Loss                      394.94336
VF Loss                      164.46848
Policy Loss                  -362.81717
Q Predictions Mean           356.34634
Q Predictions Std            502.4623
Q Predictions Max            1489.4364
Q Predictions Min            18.418177
V Predictions Mean           359.28763
V Predictions Std            493.5962
V Predictions Max            1472.3096
V Predictions Min            26.530323
Log Pis Mean                 -8.177139
Log Pis Std                  5.1157956
Log Pis Max                  9.72048
Log Pis Min                  -13.5320215
Policy mu Mean               0.14567605
Policy mu Std                0.51622146
Policy mu Max                2.1333778
Policy mu Min                -1.7502288
Policy log std Mean          -0.20021275
Policy log std Std           0.118116476
Policy log std Max           -0.046832755
Policy log std Min           -0.7172616
Z mean eval                  0.058963727
Z variance eval              0.18170944
total_rewards                [473.50025164 500.33459925 526.81173996 414.70514517 647.52496332
 499.17005382 502.94898033 470.83169671 663.98433436 630.59070839]
total_rewards_mean           533.0402472968798
total_rewards_std            80.21747684681542
total_rewards_max            663.9843343639868
total_rewards_min            414.7051451741101
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               28.528963828925043
(Previous) Eval Time (s)     2.596811051014811
Sample Time (s)              15.922149201855063
Epoch Time (s)               47.04792408179492
Total Train Time (s)         2838.7614636141807
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:03:00.462171 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #60 | Epoch Duration: 47.780919313430786
2020-01-10 19:03:00.462319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.059139065
Z variance train             0.18165903
KL Divergence                2.2945194
KL Loss                      0.22945194
QF Loss                      469.54346
VF Loss                      343.07742
Policy Loss                  -350.42108
Q Predictions Mean           340.6975
Q Predictions Std            503.2664
Q Predictions Max            1487.3093
Q Predictions Min            15.946404
V Predictions Mean           347.14026
V Predictions Std            497.18027
V Predictions Max            1459.066
V Predictions Min            26.835974
Log Pis Mean                 -8.442846
Log Pis Std                  4.929884
Log Pis Max                  5.404495
Log Pis Min                  -13.720801
Policy mu Mean               0.13974845
Policy mu Std                0.49657387
Policy mu Max                2.0977154
Policy mu Min                -1.9847546
Policy log std Mean          -0.19506353
Policy log std Std           0.11481668
Policy log std Max           -0.072006784
Policy log std Min           -0.7052943
Z mean eval                  0.06256729
Z variance eval              0.17894971
total_rewards                [638.91828151 623.88104787 355.14068007 454.94260152 470.38806515
 978.83876414 306.03875027 956.28895244 614.13888266 839.68851022]
total_rewards_mean           623.8264535848808
total_rewards_std            225.55027385607525
total_rewards_max            978.8387641357406
total_rewards_min            306.03875026999873
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               28.28275008779019
(Previous) Eval Time (s)     3.3295040782541037
Sample Time (s)              14.699839332140982
Epoch Time (s)               46.31209349818528
Total Train Time (s)         2885.6099046953022
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:03:47.312348 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #61 | Epoch Duration: 46.849910259246826
2020-01-10 19:03:47.312535 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062230356
Z variance train             0.17892316
KL Divergence                2.3233333
KL Loss                      0.23233333
QF Loss                      523.3862
VF Loss                      258.6006
Policy Loss                  -394.40045
Q Predictions Mean           384.92496
Q Predictions Std            525.6506
Q Predictions Max            1494.6228
Q Predictions Min            15.091722
V Predictions Mean           396.07852
V Predictions Std            526.4925
V Predictions Max            1500.3529
V Predictions Min            24.439732
Log Pis Mean                 -8.078514
Log Pis Std                  5.0947175
Log Pis Max                  10.002331
Log Pis Min                  -14.891397
Policy mu Mean               0.14326932
Policy mu Std                0.5272694
Policy mu Max                1.9922649
Policy mu Min                -2.2400012
Policy log std Mean          -0.203835
Policy log std Std           0.12109532
Policy log std Max           -0.02292063
Policy log std Min           -0.66080445
Z mean eval                  0.06374952
Z variance eval              0.17685041
total_rewards                [674.32735796 440.32521544 403.6359535  431.37277953 460.92472237
 453.78022529 571.64364176 392.24538787 412.19235672 575.46491391]
total_rewards_mean           481.5912554333889
total_rewards_std            88.52692353988999
total_rewards_max            674.3273579597916
total_rewards_min            392.24538786919527
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               28.281461289618164
(Previous) Eval Time (s)     3.8670299192890525
Sample Time (s)              15.423148879781365
Epoch Time (s)               47.57164008868858
Total Train Time (s)         2932.1888240277767
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:04:33.892216 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #62 | Epoch Duration: 46.579561948776245
2020-01-10 19:04:33.892410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #62 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06351521
Z variance train             0.17690834
KL Divergence                2.343508
KL Loss                      0.2343508
QF Loss                      589.29675
VF Loss                      263.43088
Policy Loss                  -422.76166
Q Predictions Mean           418.0148
Q Predictions Std            544.45825
Q Predictions Max            1500.5345
Q Predictions Min            15.320072
V Predictions Mean           418.29938
V Predictions Std            533.1742
V Predictions Max            1492.0785
V Predictions Min            25.856396
Log Pis Mean                 -7.6713457
Log Pis Std                  5.189043
Log Pis Max                  5.9579806
Log Pis Min                  -12.72308
Policy mu Mean               0.16588536
Policy mu Std                0.5516708
Policy mu Max                2.126182
Policy mu Min                -1.8116708
Policy log std Mean          -0.20824255
Policy log std Std           0.12481777
Policy log std Max           -0.0791149
Policy log std Min           -0.6946342
Z mean eval                  0.064088084
Z variance eval              0.17902303
total_rewards                [ 427.67640018 1027.65958889  608.28484067  568.98236973  394.47046301
  531.03697793  507.56399944  610.14765416  561.76221641  668.05211472]
total_rewards_mean           590.5636625131866
total_rewards_std            165.670555870918
total_rewards_max            1027.6595888872434
total_rewards_min            394.4704630100093
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               29.5793292298913
(Previous) Eval Time (s)     2.874653724953532
Sample Time (s)              15.224870905280113
Epoch Time (s)               47.678853860124946
Total Train Time (s)         2980.3296053344384
Epoch                        63
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:05:22.034999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #63 | Epoch Duration: 48.14245581626892
2020-01-10 19:05:22.035198 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06415793
Z variance train             0.17898111
KL Divergence                2.3309133
KL Loss                      0.23309134
QF Loss                      428.12738
VF Loss                      129.2545
Policy Loss                  -394.36285
Q Predictions Mean           385.16156
Q Predictions Std            530.0829
Q Predictions Max            1479.1871
Q Predictions Min            17.377625
V Predictions Mean           394.68622
V Predictions Std            525.13367
V Predictions Max            1506.276
V Predictions Min            27.725893
Log Pis Mean                 -8.133754
Log Pis Std                  5.0927234
Log Pis Max                  15.645012
Log Pis Min                  -14.753168
Policy mu Mean               0.15759704
Policy mu Std                0.5336427
Policy mu Max                2.8469489
Policy mu Min                -2.3563132
Policy log std Mean          -0.20406395
Policy log std Std           0.123871945
Policy log std Max           -0.04937978
Policy log std Min           -0.8628002
Z mean eval                  0.06398843
Z variance eval              0.17887208
total_rewards                [484.59468903 386.04412954 375.74438077 405.5666275  514.35625481
 419.23729776 480.18746928 603.82758482 629.52791345 407.64656651]
total_rewards_mean           470.6732913470722
total_rewards_std            84.96345289134578
total_rewards_max            629.5279134460858
total_rewards_min            375.7443807667391
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               28.84367781318724
(Previous) Eval Time (s)     3.3379511600360274
Sample Time (s)              16.115846116561443
Epoch Time (s)               48.29747508978471
Total Train Time (s)         3028.024296731688
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:06:09.731135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #64 | Epoch Duration: 47.695778131484985
2020-01-10 19:06:09.731305 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #64 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06392891
Z variance train             0.17886809
KL Divergence                2.3539495
KL Loss                      0.23539495
QF Loss                      702.3433
VF Loss                      199.12497
Policy Loss                  -397.40265
Q Predictions Mean           388.625
Q Predictions Std            525.60455
Q Predictions Max            1513.896
Q Predictions Min            15.04479
V Predictions Mean           400.7736
V Predictions Std            528.32275
V Predictions Max            1525.0316
V Predictions Min            26.171732
Log Pis Mean                 -8.131986
Log Pis Std                  4.9088206
Log Pis Max                  9.43655
Log Pis Min                  -13.496551
Policy mu Mean               0.18546483
Policy mu Std                0.518275
Policy mu Max                2.2481954
Policy mu Min                -2.1414587
Policy log std Mean          -0.2045134
Policy log std Std           0.12229574
Policy log std Max           -0.062014878
Policy log std Min           -0.7310409
Z mean eval                  0.06703157
Z variance eval              0.18258162
total_rewards                [398.00868723 557.75976354 671.62079761 405.79070206 414.98716414
 349.24504917 594.59910731 410.4421458  438.93601577 416.63202929]
total_rewards_mean           465.8021461918273
total_rewards_std            98.98254524313427
total_rewards_max            671.620797608727
total_rewards_min            349.24504916563967
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               29.039086082018912
(Previous) Eval Time (s)     2.7359877382405102
Sample Time (s)              14.95768222771585
Epoch Time (s)               46.73275604797527
Total Train Time (s)         3074.862975896802
Epoch                        65
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:06:56.572018 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #65 | Epoch Duration: 46.84053134918213
2020-01-10 19:06:56.572254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #65 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.067208394
Z variance train             0.18257245
KL Divergence                2.33629
KL Loss                      0.23362899
QF Loss                      470.2871
VF Loss                      190.9648
Policy Loss                  -361.53033
Q Predictions Mean           354.89368
Q Predictions Std            500.1619
Q Predictions Max            1532.8373
Q Predictions Min            16.39086
V Predictions Mean           356.1763
V Predictions Std            491.60117
V Predictions Max            1514.4393
V Predictions Min            23.63777
Log Pis Mean                 -8.218601
Log Pis Std                  4.97036
Log Pis Max                  7.813325
Log Pis Min                  -13.730883
Policy mu Mean               0.18275356
Policy mu Std                0.5250716
Policy mu Max                2.157035
Policy mu Min                -1.8371931
Policy log std Mean          -0.20423496
Policy log std Std           0.12490917
Policy log std Max           -0.054283544
Policy log std Min           -0.7687874
Z mean eval                  0.07050316
Z variance eval              0.17955084
total_rewards                [430.68168697 449.42342876 569.57420087 516.53435823 425.52227815
 478.74876604 562.59217886 303.23298189 473.37352855 478.9893427 ]
total_rewards_mean           468.8672751005841
total_rewards_std            72.5041446280829
total_rewards_max            569.5742008684105
total_rewards_min            303.2329818895295
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               30.925021305214614
(Previous) Eval Time (s)     2.8434714446775615
Sample Time (s)              16.003857701085508
Epoch Time (s)               49.77235045097768
Total Train Time (s)         3124.397966630757
Epoch                        66
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:07:46.107513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #66 | Epoch Duration: 49.535086154937744
2020-01-10 19:07:46.107663 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06989389
Z variance train             0.17950907
KL Divergence                2.3775654
KL Loss                      0.23775654
QF Loss                      703.5105
VF Loss                      385.81314
Policy Loss                  -379.23663
Q Predictions Mean           375.00153
Q Predictions Std            511.61255
Q Predictions Max            1528.6505
Q Predictions Min            15.254405
V Predictions Mean           387.10626
V Predictions Std            513.02313
V Predictions Max            1527.158
V Predictions Min            25.384268
Log Pis Mean                 -8.202248
Log Pis Std                  4.817983
Log Pis Max                  10.498009
Log Pis Min                  -14.237687
Policy mu Mean               0.14615595
Policy mu Std                0.52871966
Policy mu Max                2.2236538
Policy mu Min                -2.1074462
Policy log std Mean          -0.202754
Policy log std Std           0.12102117
Policy log std Max           -0.036472328
Policy log std Min           -0.7373354
Z mean eval                  0.07243027
Z variance eval              0.17549261
total_rewards                [491.332785   598.84838923 721.59505204 503.13411215 376.37920602
 653.96981359 476.71429923 401.69800169 397.19105385 412.02068729]
total_rewards_mean           503.2883400083536
total_rewards_std            112.40842158118491
total_rewards_max            721.595052043269
total_rewards_min            376.3792060222746
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               27.798441278282553
(Previous) Eval Time (s)     2.6059334888122976
Sample Time (s)              14.710106507875025
Epoch Time (s)               45.114481274969876
Total Train Time (s)         3170.211628019344
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:08:31.922507 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #67 | Epoch Duration: 45.81467366218567
2020-01-10 19:08:31.922685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #67 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07187448
Z variance train             0.17547898
KL Divergence                2.4107301
KL Loss                      0.24107301
QF Loss                      998.0627
VF Loss                      183.50842
Policy Loss                  -373.08676
Q Predictions Mean           366.37057
Q Predictions Std            505.99863
Q Predictions Max            1470.269
Q Predictions Min            16.970705
V Predictions Mean           375.55942
V Predictions Std            504.63193
V Predictions Max            1475.1946
V Predictions Min            26.738895
Log Pis Mean                 -8.097445
Log Pis Std                  5.057472
Log Pis Max                  13.380533
Log Pis Min                  -13.890743
Policy mu Mean               0.15553486
Policy mu Std                0.51392454
Policy mu Max                2.541996
Policy mu Min                -1.8370247
Policy log std Mean          -0.20319219
Policy log std Std           0.12072366
Policy log std Max           -0.08877878
Policy log std Min           -0.75919807
Z mean eval                  0.07286509
Z variance eval              0.17797069
total_rewards                [596.81287643 718.58197794 389.3204738  442.69905439 442.07700969
 743.42089298 422.63508123 511.1042206  361.28930839 480.16957377]
total_rewards_mean           510.81104692157476
total_rewards_std            126.4384129699595
total_rewards_max            743.4208929805579
total_rewards_min            361.28930839434395
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               28.562138034962118
(Previous) Eval Time (s)     3.3058418347500265
Sample Time (s)              15.682508184108883
Epoch Time (s)               47.55048805382103
Total Train Time (s)         3217.686350424774
Epoch                        68
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:09:19.399543 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #68 | Epoch Duration: 47.476699352264404
2020-01-10 19:09:19.399760 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #68 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.072935365
Z variance train             0.17793517
KL Divergence                2.3793094
KL Loss                      0.23793094
QF Loss                      826.297
VF Loss                      164.95297
Policy Loss                  -425.77423
Q Predictions Mean           414.67563
Q Predictions Std            540.7276
Q Predictions Max            1506.81
Q Predictions Min            15.660431
V Predictions Mean           422.47668
V Predictions Std            538.02576
V Predictions Max            1514.3097
V Predictions Min            24.436754
Log Pis Mean                 -7.801108
Log Pis Std                  5.0854173
Log Pis Max                  6.0442157
Log Pis Min                  -14.229221
Policy mu Mean               0.1437485
Policy mu Std                0.53407013
Policy mu Max                2.1645293
Policy mu Min                -2.315469
Policy log std Mean          -0.20605485
Policy log std Std           0.11957845
Policy log std Max           -0.05208713
Policy log std Min           -0.7216494
Z mean eval                  0.07505369
Z variance eval              0.17229877
total_rewards                [537.82374589 784.21175355 750.18663668 835.04327795 629.47247413
 535.78775527 456.79379072 962.32108218 547.6143331  659.52885022]
total_rewards_mean           669.8783699698446
total_rewards_std            151.60333945902974
total_rewards_max            962.3210821845332
total_rewards_min            456.7937907228573
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               30.044058325700462
(Previous) Eval Time (s)     3.2317560124211013
Sample Time (s)              15.683361530303955
Epoch Time (s)               48.95917586842552
Total Train Time (s)         3267.340070386417
Epoch                        69
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:10:09.055141 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #69 | Epoch Duration: 49.65518546104431
2020-01-10 19:10:09.055363 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0748817
Z variance train             0.17236672
KL Divergence                2.4570131
KL Loss                      0.24570131
QF Loss                      737.08887
VF Loss                      184.66052
Policy Loss                  -431.2089
Q Predictions Mean           426.91522
Q Predictions Std            551.51306
Q Predictions Max            1538.6418
Q Predictions Min            16.506668
V Predictions Mean           431.96393
V Predictions Std            545.5491
V Predictions Max            1542.2189
V Predictions Min            24.076283
Log Pis Mean                 -7.7250767
Log Pis Std                  5.159061
Log Pis Max                  6.5745325
Log Pis Min                  -13.7460785
Policy mu Mean               0.17472088
Policy mu Std                0.54719615
Policy mu Max                2.2404308
Policy mu Min                -1.9759271
Policy log std Mean          -0.2068088
Policy log std Std           0.12347523
Policy log std Max           -0.01760374
Policy log std Min           -0.6784769
Z mean eval                  0.07494198
Z variance eval              0.17513375
total_rewards                [ 760.67227456  501.68981035  534.27077108  533.22469439  664.65573877
  712.2301171   734.48408815  523.14606717  805.35626246 1023.20421248]
total_rewards_mean           679.29340365245
total_rewards_std            156.02139860920607
total_rewards_max            1023.2042124799091
total_rewards_min            501.6898103504759
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               28.428817940875888
(Previous) Eval Time (s)     3.9274881719611585
Sample Time (s)              16.34583072271198
Epoch Time (s)               48.70213683554903
Total Train Time (s)         3316.512153682299
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:10:58.227362 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #70 | Epoch Duration: 49.17184591293335
2020-01-10 19:10:58.227525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #70 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.075242445
Z variance train             0.17511714
KL Divergence                2.418065
KL Loss                      0.2418065
QF Loss                      443.66763
VF Loss                      202.21085
Policy Loss                  -405.3396
Q Predictions Mean           398.16364
Q Predictions Std            548.79926
Q Predictions Max            1541.6478
Q Predictions Min            16.562561
V Predictions Mean           399.2142
V Predictions Std            538.3829
V Predictions Max            1528.0447
V Predictions Min            23.655546
Log Pis Mean                 -8.123079
Log Pis Std                  5.1827135
Log Pis Max                  16.10641
Log Pis Min                  -13.001947
Policy mu Mean               0.14071958
Policy mu Std                0.5265752
Policy mu Max                2.324731
Policy mu Min                -2.6119585
Policy log std Mean          -0.20085186
Policy log std Std           0.123075284
Policy log std Max           0.044496596
Policy log std Min           -0.75908834
Z mean eval                  0.078435495
Z variance eval              0.17529672
total_rewards                [831.42809433 681.76188166 533.5519479  735.06503835 676.20519204
 556.34354442 329.87940326 456.63074316 389.58901088 643.49622667]
total_rewards_mean           583.3951082694085
total_rewards_std            150.84507155632784
total_rewards_max            831.4280943345145
total_rewards_min            329.8794032648548
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               29.830969718750566
(Previous) Eval Time (s)     4.396891771815717
Sample Time (s)              16.239987748209387
Epoch Time (s)               50.46784923877567
Total Train Time (s)         3366.212575906422
Epoch                        71
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:11:47.931501 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #71 | Epoch Duration: 49.70382642745972
2020-01-10 19:11:47.931754 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #71 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07851999
Z variance train             0.17523131
KL Divergence                2.441573
KL Loss                      0.2441573
QF Loss                      685.3821
VF Loss                      186.15265
Policy Loss                  -422.05692
Q Predictions Mean           410.49475
Q Predictions Std            547.62445
Q Predictions Max            1546.2565
Q Predictions Min            16.935518
V Predictions Mean           420.50595
V Predictions Std            550.2105
V Predictions Max            1545.8005
V Predictions Min            25.779745
Log Pis Mean                 -7.9080496
Log Pis Std                  5.1124454
Log Pis Max                  5.211029
Log Pis Min                  -14.769003
Policy mu Mean               0.17599007
Policy mu Std                0.5455304
Policy mu Max                2.1325834
Policy mu Min                -1.9408325
Policy log std Mean          -0.20757544
Policy log std Std           0.121763274
Policy log std Max           -0.03440731
Policy log std Min           -0.6988192
Z mean eval                  0.077946834
Z variance eval              0.16899721
total_rewards                [366.81720081 343.53221145 600.83260077 409.00133039 621.95084455
 735.59124633 673.54501404 609.81085768 439.41425831 395.62976326]
total_rewards_mean           519.6125327576441
total_rewards_std            135.62322894522637
total_rewards_max            735.5912463255248
total_rewards_min            343.5322114520339
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               30.24762400565669
(Previous) Eval Time (s)     3.632535771932453
Sample Time (s)              16.67781088454649
Epoch Time (s)               50.55797066213563
Total Train Time (s)         3416.44238396734
Epoch                        72
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:12:38.163296 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #72 | Epoch Duration: 50.23130512237549
2020-01-10 19:12:38.163578 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #72 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07748062
Z variance train             0.16896997
KL Divergence                2.5062418
KL Loss                      0.25062418
QF Loss                      595.6101
VF Loss                      288.36694
Policy Loss                  -422.11337
Q Predictions Mean           414.5111
Q Predictions Std            522.65735
Q Predictions Max            1509.0394
Q Predictions Min            17.201082
V Predictions Mean           428.0794
V Predictions Std            528.3618
V Predictions Max            1554.5474
V Predictions Min            24.623446
Log Pis Mean                 -7.4811554
Log Pis Std                  5.3410716
Log Pis Max                  8.396592
Log Pis Min                  -14.403568
Policy mu Mean               0.20694144
Policy mu Std                0.5471389
Policy mu Max                2.015942
Policy mu Min                -1.7334703
Policy log std Mean          -0.21129839
Policy log std Std           0.1241369
Policy log std Max           -0.07842173
Policy log std Min           -0.6921972
Z mean eval                  0.08000753
Z variance eval              0.16843714
total_rewards                [506.03872862 858.73594058 482.44312769 565.44420163 554.07908155
 400.56168715 671.2150493  488.10045936 541.85089362 554.03793527]
total_rewards_mean           562.2507104776031
total_rewards_std            118.95710659480288
total_rewards_max            858.7359405802121
total_rewards_min            400.5616871505448
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               28.669041437562555
(Previous) Eval Time (s)     3.305585321970284
Sample Time (s)              15.99780952418223
Epoch Time (s)               47.97243628371507
Total Train Time (s)         3464.530839710962
Epoch                        73
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:13:26.254771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #73 | Epoch Duration: 48.090938568115234
2020-01-10 19:13:26.255078 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #73 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07993146
Z variance train             0.16843598
KL Divergence                2.4990804
KL Loss                      0.24990804
QF Loss                      441.0578
VF Loss                      106.54009
Policy Loss                  -376.62167
Q Predictions Mean           368.7987
Q Predictions Std            521.29126
Q Predictions Max            1550.3892
Q Predictions Min            15.164082
V Predictions Mean           379.3151
V Predictions Std            519.53046
V Predictions Max            1557.4825
V Predictions Min            26.069607
Log Pis Mean                 -8.12871
Log Pis Std                  5.067148
Log Pis Max                  7.217819
Log Pis Min                  -14.279886
Policy mu Mean               0.1619362
Policy mu Std                0.5093772
Policy mu Max                2.0827146
Policy mu Min                -2.1225543
Policy log std Mean          -0.19647251
Policy log std Std           0.11722377
Policy log std Max           -0.041989982
Policy log std Min           -0.7143139
Z mean eval                  0.08140719
Z variance eval              0.16811313
total_rewards                [560.19419789 473.87281949 538.25277292 349.77165046 649.1331626
 311.98485685 404.83541742 436.64418988 291.3699094  463.35768213]
total_rewards_mean           447.9416659038977
total_rewards_std            108.05874607525317
total_rewards_max            649.1331626040902
total_rewards_min            291.36990940462607
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               29.79075339110568
(Previous) Eval Time (s)     3.4237741040997207
Sample Time (s)              16.155663682613522
Epoch Time (s)               49.370191177818924
Total Train Time (s)         3513.3777599059977
Epoch                        74
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:14:15.100642 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #74 | Epoch Duration: 48.84536051750183
2020-01-10 19:14:15.100785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #74 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08139937
Z variance train             0.16814387
KL Divergence                2.5056353
KL Loss                      0.25056353
QF Loss                      592.8383
VF Loss                      189.93434
Policy Loss                  -433.18445
Q Predictions Mean           421.8954
Q Predictions Std            536.51404
Q Predictions Max            1546.63
Q Predictions Min            16.419106
V Predictions Mean           435.5255
V Predictions Std            539.23193
V Predictions Max            1555.6453
V Predictions Min            29.02465
Log Pis Mean                 -7.361286
Log Pis Std                  5.6631103
Log Pis Max                  11.82995
Log Pis Min                  -15.139048
Policy mu Mean               0.16570075
Policy mu Std                0.5648047
Policy mu Max                2.9113135
Policy mu Min                -3.2320945
Policy log std Mean          -0.21792383
Policy log std Std           0.13720852
Policy log std Max           0.0017064065
Policy log std Min           -0.81350315
Z mean eval                  0.08197312
Z variance eval              0.16599329
total_rewards                [589.22184305 325.25046132 564.75280468 454.04317035 525.78074126
 465.72242913 317.21841278 383.2944615  507.32300733 860.95493901]
total_rewards_mean           499.3562270415722
total_rewards_std            149.66954742875598
total_rewards_max            860.9549390126116
total_rewards_min            317.2184127838754
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               28.69791462412104
(Previous) Eval Time (s)     2.898687087930739
Sample Time (s)              16.518881137482822
Epoch Time (s)               48.1154828495346
Total Train Time (s)         3562.003291362431
Epoch                        75
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:15:03.728628 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #75 | Epoch Duration: 48.62770223617554
2020-01-10 19:15:03.728846 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #75 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08236688
Z variance train             0.16599502
KL Divergence                2.5415664
KL Loss                      0.25415665
QF Loss                      790.1883
VF Loss                      212.31479
Policy Loss                  -432.4289
Q Predictions Mean           423.93762
Q Predictions Std            562.03625
Q Predictions Max            1562.578
Q Predictions Min            16.978922
V Predictions Mean           430.91388
V Predictions Std            559.8075
V Predictions Max            1564.8418
V Predictions Min            28.03821
Log Pis Mean                 -7.9409885
Log Pis Std                  5.2105026
Log Pis Max                  6.257602
Log Pis Min                  -14.21825
Policy mu Mean               0.18989982
Policy mu Std                0.5320027
Policy mu Max                2.1501226
Policy mu Min                -1.8587546
Policy log std Mean          -0.21089964
Policy log std Std           0.12811531
Policy log std Max           -0.0669432
Policy log std Min           -0.7282754
Z mean eval                  0.083543114
Z variance eval              0.16387138
total_rewards                [777.51771857 380.55043275 471.93307538 529.88950031 574.21665073
 416.90230706 682.60380462 541.29861277 642.46428686 551.96196904]
total_rewards_mean           556.9338358101288
total_rewards_std            114.45959246647251
total_rewards_max            777.5177185735923
total_rewards_min            380.550432754325
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               28.982150639872998
(Previous) Eval Time (s)     3.4106012820266187
Sample Time (s)              16.870591037906706
Epoch Time (s)               49.26334295980632
Total Train Time (s)         3611.6898906053975
Epoch                        76
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:15:53.418766 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #76 | Epoch Duration: 49.68973159790039
2020-01-10 19:15:53.419035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #76 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08350806
Z variance train             0.16385576
KL Divergence                2.5702329
KL Loss                      0.2570233
QF Loss                      843.6976
VF Loss                      297.29926
Policy Loss                  -421.79898
Q Predictions Mean           417.39578
Q Predictions Std            540.2178
Q Predictions Max            1581.4192
Q Predictions Min            16.904278
V Predictions Mean           418.41254
V Predictions Std            530.0381
V Predictions Max            1581.5768
V Predictions Min            25.088865
Log Pis Mean                 -7.7569327
Log Pis Std                  5.4610176
Log Pis Max                  15.1029
Log Pis Min                  -14.264317
Policy mu Mean               0.17958213
Policy mu Std                0.54086965
Policy mu Max                2.5424309
Policy mu Min                -1.9701868
Policy log std Mean          -0.20533946
Policy log std Std           0.12220839
Policy log std Max           -0.051918194
Policy log std Min           -0.7102263
Z mean eval                  0.08274623
Z variance eval              0.16538797
total_rewards                [412.93942631 407.34175003 558.66864471 573.6960346  638.9337445
 369.79734098 543.77431777 633.50583018 961.7475614  814.63908052]
total_rewards_mean           591.5043731007809
total_rewards_std            175.92941312022595
total_rewards_max            961.7475613980611
total_rewards_min            369.79734098487125
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               27.630319064948708
(Previous) Eval Time (s)     3.83668390288949
Sample Time (s)              15.871917000040412
Epoch Time (s)               47.33891996787861
Total Train Time (s)         3658.983250196092
Epoch                        77
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:16:40.714616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #77 | Epoch Duration: 47.295347452163696
2020-01-10 19:16:40.714917 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #77 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08276658
Z variance train             0.16538534
KL Divergence                2.5622683
KL Loss                      0.25622684
QF Loss                      536.3258
VF Loss                      210.7392
Policy Loss                  -429.81134
Q Predictions Mean           425.34882
Q Predictions Std            542.8783
Q Predictions Max            1567.2083
Q Predictions Min            14.797942
V Predictions Mean           434.4127
V Predictions Std            541.6011
V Predictions Max            1569.6608
V Predictions Min            23.797857
Log Pis Mean                 -7.53553
Log Pis Std                  5.3225026
Log Pis Max                  7.3941774
Log Pis Min                  -12.971193
Policy mu Mean               0.18356787
Policy mu Std                0.5614791
Policy mu Max                2.583323
Policy mu Min                -2.3942447
Policy log std Mean          -0.21514076
Policy log std Std           0.13201356
Policy log std Max           -0.059420213
Policy log std Min           -0.8111089
Z mean eval                  0.08437639
Z variance eval              0.16206023
total_rewards                [769.54246677 557.97287994 767.4682203  362.82483722 682.7997716
 489.91584035 642.26276352 728.77509511 489.03551206 993.89729377]
total_rewards_mean           648.4494680629441
total_rewards_std            172.0891531333844
total_rewards_max            993.8972937698268
total_rewards_min            362.82483721871876
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               30.250762628391385
(Previous) Eval Time (s)     3.792833521962166
Sample Time (s)              16.483042172156274
Epoch Time (s)               50.526638322509825
Total Train Time (s)         3709.7377125420608
Epoch                        78
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:17:31.471783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #78 | Epoch Duration: 50.75661635398865
2020-01-10 19:17:31.472089 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0847892
Z variance train             0.16201426
KL Divergence                2.5989082
KL Loss                      0.25989082
QF Loss                      952.14746
VF Loss                      332.705
Policy Loss                  -429.50955
Q Predictions Mean           419.83286
Q Predictions Std            549.4934
Q Predictions Max            1578.0757
Q Predictions Min            14.483223
V Predictions Mean           423.84497
V Predictions Std            538.9168
V Predictions Max            1551.3287
V Predictions Min            26.188316
Log Pis Mean                 -7.916849
Log Pis Std                  5.4060555
Log Pis Max                  20.999664
Log Pis Min                  -13.155464
Policy mu Mean               0.1701555
Policy mu Std                0.5439248
Policy mu Max                3.000787
Policy mu Min                -2.5763626
Policy log std Mean          -0.20909297
Policy log std Std           0.12768297
Policy log std Max           -0.016712487
Policy log std Min           -0.85147715
Z mean eval                  0.0847667
Z variance eval              0.1571128
total_rewards                [ 690.34233713  454.35727271  848.45927283  363.68804439 1260.35837649
  468.26510277  524.804243    746.2359077   396.02217547  592.63925071]
total_rewards_mean           634.5171983194193
total_rewards_std            256.3517636692695
total_rewards_max            1260.3583764893267
total_rewards_min            363.6880443858834
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               30.654760632198304
(Previous) Eval Time (s)     4.0225235456600785
Sample Time (s)              15.710936232935637
Epoch Time (s)               50.38822041079402
Total Train Time (s)         3759.922546380665
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:18:21.658493 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #79 | Epoch Duration: 50.18616580963135
2020-01-10 19:18:21.658763 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #79 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.084660575
Z variance train             0.1571249
KL Divergence                2.6673784
KL Loss                      0.26673785
QF Loss                      546.34924
VF Loss                      219.12616
Policy Loss                  -433.04907
Q Predictions Mean           426.42966
Q Predictions Std            573.6034
Q Predictions Max            1577.1495
Q Predictions Min            15.809026
V Predictions Mean           436.25357
V Predictions Std            572.1369
V Predictions Max            1612.9517
V Predictions Min            28.466288
Log Pis Mean                 -7.962944
Log Pis Std                  5.183541
Log Pis Max                  13.220518
Log Pis Min                  -13.397182
Policy mu Mean               0.1772813
Policy mu Std                0.5431739
Policy mu Max                2.0154448
Policy mu Min                -1.7124903
Policy log std Mean          -0.21308431
Policy log std Std           0.13446435
Policy log std Max           -0.06652783
Policy log std Min           -0.74581933
Z mean eval                  0.08348928
Z variance eval              0.15647891
total_rewards                [611.98968373 941.84429944 805.51432118 448.27981637 634.15357173
 629.27164403 513.3590545  884.45172823 585.18510302 314.34579846]
total_rewards_mean           636.8395020684868
total_rewards_std            184.64708975400978
total_rewards_max            941.844299435688
total_rewards_min            314.3457984586491
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               31.241049374919385
(Previous) Eval Time (s)     3.820171410217881
Sample Time (s)              16.186761753167957
Epoch Time (s)               51.24798253830522
Total Train Time (s)         3811.1365087614395
Epoch                        80
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:19:12.873070 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #80 | Epoch Duration: 51.214115619659424
2020-01-10 19:19:12.873215 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #80 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08358337
Z variance train             0.15647373
KL Divergence                2.6659632
KL Loss                      0.26659632
QF Loss                      500.118
VF Loss                      364.7413
Policy Loss                  -463.4417
Q Predictions Mean           451.7873
Q Predictions Std            573.59064
Q Predictions Max            1592.459
Q Predictions Min            14.504319
V Predictions Mean           456.24182
V Predictions Std            564.0423
V Predictions Max            1590.1847
V Predictions Min            23.848907
Log Pis Mean                 -7.7000303
Log Pis Std                  5.1925597
Log Pis Max                  13.692345
Log Pis Min                  -12.873077
Policy mu Mean               0.17771769
Policy mu Std                0.5480092
Policy mu Max                2.4217985
Policy mu Min                -2.8498569
Policy log std Mean          -0.21363401
Policy log std Std           0.129173
Policy log std Max           -0.03562884
Policy log std Min           -0.70786124
Z mean eval                  0.08213893
Z variance eval              0.15746959
total_rewards                [422.52114549 489.2077448  426.07254919 710.04154932 362.22997275
 348.4375665  755.0403547  351.89783982 525.34355205 377.53497857]
total_rewards_mean           476.8327253201167
total_rewards_std            139.60891843678345
total_rewards_max            755.0403547033193
total_rewards_min            348.4375665004551
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               27.91494226595387
(Previous) Eval Time (s)     3.7860330836847425
Sample Time (s)              14.910303380805999
Epoch Time (s)               46.61127873044461
Total Train Time (s)         3856.8598786578514
Epoch                        81
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:19:58.599871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #81 | Epoch Duration: 45.726492404937744
2020-01-10 19:19:58.600134 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #81 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08214001
Z variance train             0.15747505
KL Divergence                2.6428967
KL Loss                      0.26428968
QF Loss                      668.4893
VF Loss                      430.86725
Policy Loss                  -464.79263
Q Predictions Mean           452.60342
Q Predictions Std            582.9206
Q Predictions Max            1590.2982
Q Predictions Min            17.178257
V Predictions Mean           453.7391
V Predictions Std            573.03186
V Predictions Max            1584.0248
V Predictions Min            25.51841
Log Pis Mean                 -7.8346863
Log Pis Std                  5.0147862
Log Pis Max                  9.601648
Log Pis Min                  -14.533342
Policy mu Mean               0.1470464
Policy mu Std                0.5459545
Policy mu Max                2.1518283
Policy mu Min                -2.6250815
Policy log std Mean          -0.2088465
Policy log std Std           0.12577775
Policy log std Max           -0.06113662
Policy log std Min           -0.6931896
Z mean eval                  0.08452369
Z variance eval              0.15293312
total_rewards                [777.96237088 838.27027817 814.900069   541.53347605 675.54138635
 438.6855085  867.93440319 738.11647225 535.14348562 748.22826145]
total_rewards_mean           697.6315711460304
total_rewards_std            138.38219669831253
total_rewards_max            867.934403189538
total_rewards_min            438.68550849925464
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               28.355181811843067
(Previous) Eval Time (s)     2.9009291199035943
Sample Time (s)              15.650811087340117
Epoch Time (s)               46.90692201908678
Total Train Time (s)         3905.2318292818964
Epoch                        82
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:20:46.971418 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #82 | Epoch Duration: 48.37107992172241
2020-01-10 19:20:46.971643 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #82 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08489923
Z variance train             0.15291937
KL Divergence                2.692742
KL Loss                      0.2692742
QF Loss                      621.12195
VF Loss                      198.36539
Policy Loss                  -383.34912
Q Predictions Mean           376.02866
Q Predictions Std            538.8529
Q Predictions Max            1607.786
Q Predictions Min            17.645966
V Predictions Mean           384.8695
V Predictions Std            538.0307
V Predictions Max            1607.459
V Predictions Min            25.127726
Log Pis Mean                 -8.160025
Log Pis Std                  4.9932623
Log Pis Max                  5.9572926
Log Pis Min                  -13.351402
Policy mu Mean               0.16036463
Policy mu Std                0.51047486
Policy mu Max                2.2248785
Policy mu Min                -1.7633681
Policy log std Mean          -0.20181948
Policy log std Std           0.12026615
Policy log std Max           -0.007052511
Policy log std Min           -0.74224347
Z mean eval                  0.08608176
Z variance eval              0.15260549
total_rewards                [403.61721092 610.21380534 639.3516115  946.90332305 494.18111574
 660.19897655 655.5386388  617.46332827 639.70381854 704.9122191 ]
total_rewards_mean           637.2084047805664
total_rewards_std            133.23301425439874
total_rewards_max            946.9033230466863
total_rewards_min            403.6172109220403
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               28.796982176136225
(Previous) Eval Time (s)     4.364828363060951
Sample Time (s)              17.32526326738298
Epoch Time (s)               50.487073806580156
Total Train Time (s)         3955.043085965328
Epoch                        83
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:21:36.785983 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #83 | Epoch Duration: 49.81419348716736
2020-01-10 19:21:36.786184 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #83 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0856204
Z variance train             0.15259735
KL Divergence                2.6935081
KL Loss                      0.26935083
QF Loss                      625.3059
VF Loss                      309.54703
Policy Loss                  -450.31067
Q Predictions Mean           448.8714
Q Predictions Std            582.7851
Q Predictions Max            1588.6609
Q Predictions Min            16.849848
V Predictions Mean           457.95276
V Predictions Std            578.95264
V Predictions Max            1595.0002
V Predictions Min            27.045477
Log Pis Mean                 -7.319423
Log Pis Std                  5.868153
Log Pis Max                  11.112621
Log Pis Min                  -14.372536
Policy mu Mean               0.17566255
Policy mu Std                0.56931853
Policy mu Max                2.3467243
Policy mu Min                -2.8790786
Policy log std Mean          -0.2120773
Policy log std Std           0.13176982
Policy log std Max           0.056851402
Policy log std Min           -0.70105684
Z mean eval                  0.087278865
Z variance eval              0.14801057
total_rewards                [814.54498294 644.68357267 523.6254319  605.24499784 856.32028181
 719.21876677 835.10516971 463.26837856 630.70298457 432.4220858 ]
total_rewards_mean           652.5136652585048
total_rewards_std            144.64373977930225
total_rewards_max            856.3202818144455
total_rewards_min            432.422085801806
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               28.568216062150896
(Previous) Eval Time (s)     3.6916347187943757
Sample Time (s)              16.041907711420208
Epoch Time (s)               48.30175849236548
Total Train Time (s)         4003.655459221918
Epoch                        84
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:22:25.398962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #84 | Epoch Duration: 48.612622022628784
2020-01-10 19:22:25.399168 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08722372
Z variance train             0.1480222
KL Divergence                2.756969
KL Loss                      0.2756969
QF Loss                      710.79205
VF Loss                      211.42502
Policy Loss                  -478.96805
Q Predictions Mean           471.42474
Q Predictions Std            594.7575
Q Predictions Max            1605.1869
Q Predictions Min            13.209159
V Predictions Mean           481.6501
V Predictions Std            595.0945
V Predictions Max            1605.4268
V Predictions Min            15.496822
Log Pis Mean                 -7.611172
Log Pis Std                  5.231862
Log Pis Max                  11.030508
Log Pis Min                  -13.043573
Policy mu Mean               0.19795106
Policy mu Std                0.54674065
Policy mu Max                2.3056931
Policy mu Min                -1.8832275
Policy log std Mean          -0.21457618
Policy log std Std           0.12754622
Policy log std Max           -0.044089437
Policy log std Min           -0.7149719
Z mean eval                  0.08483784
Z variance eval              0.14821605
total_rewards                [ 367.17310466 1448.14849453  602.30528226  681.94295116  647.47495429
  906.10672577  768.33564882  772.63767685  504.1307257   624.92099588]
total_rewards_mean           732.3176559923306
total_rewards_std            277.3287585954738
total_rewards_max            1448.148494533296
total_rewards_min            367.1731046559376
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               29.860274642240256
(Previous) Eval Time (s)     4.002219962887466
Sample Time (s)              16.681831831578165
Epoch Time (s)               50.54432643670589
Total Train Time (s)         4054.8272267356515
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:23:16.572005 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #85 | Epoch Duration: 51.17267966270447
2020-01-10 19:23:16.572231 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #85 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08463236
Z variance train             0.14821519
KL Divergence                2.7711232
KL Loss                      0.27711233
QF Loss                      475.36096
VF Loss                      439.46494
Policy Loss                  -427.51358
Q Predictions Mean           420.86652
Q Predictions Std            563.46765
Q Predictions Max            1610.0155
Q Predictions Min            15.709076
V Predictions Mean           436.53436
V Predictions Std            568.7555
V Predictions Max            1625.6234
V Predictions Min            30.630468
Log Pis Mean                 -7.9350033
Log Pis Std                  5.356392
Log Pis Max                  8.282875
Log Pis Min                  -13.339846
Policy mu Mean               0.16707253
Policy mu Std                0.5284178
Policy mu Max                2.173271
Policy mu Min                -2.0820112
Policy log std Mean          -0.20741837
Policy log std Std           0.12505834
Policy log std Max           -0.02630438
Policy log std Min           -0.70905507
Z mean eval                  0.0868859
Z variance eval              0.14251631
total_rewards                [526.18676756 758.97703672 695.64127986 315.00071984 715.83783128
 508.68914194 639.57494154 503.39090883 839.2074561  681.30654744]
total_rewards_mean           618.3812631108788
total_rewards_std            146.35633140359027
total_rewards_max            839.2074561030098
total_rewards_min            315.0007198418632
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               31.16448884876445
(Previous) Eval Time (s)     4.6302565559744835
Sample Time (s)              16.921627413947135
Epoch Time (s)               52.71637281868607
Total Train Time (s)         4106.635549239814
Epoch                        86
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:24:08.383928 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #86 | Epoch Duration: 51.81150817871094
2020-01-10 19:24:08.384231 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #86 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.086760394
Z variance train             0.14248547
KL Divergence                2.8320985
KL Loss                      0.28320986
QF Loss                      766.6648
VF Loss                      373.6175
Policy Loss                  -480.51642
Q Predictions Mean           474.73108
Q Predictions Std            571.2847
Q Predictions Max            1616.641
Q Predictions Min            13.23162
V Predictions Mean           487.36957
V Predictions Std            574.8536
V Predictions Max            1626.4913
V Predictions Min            26.293823
Log Pis Mean                 -7.6165953
Log Pis Std                  5.3399806
Log Pis Max                  9.932411
Log Pis Min                  -14.45177
Policy mu Mean               0.1708077
Policy mu Std                0.5722885
Policy mu Max                2.3912766
Policy mu Min                -2.0149255
Policy log std Mean          -0.2150402
Policy log std Std           0.12787858
Policy log std Max           -0.053793646
Policy log std Min           -0.8837827
Z mean eval                  0.08454771
Z variance eval              0.1432378
total_rewards                [583.5867194  656.174489   629.19954783 677.23546339 745.74240898
 503.53715848 483.99912113 523.82948631 635.4132475  601.82484105]
total_rewards_mean           604.0542483093184
total_rewards_std            78.19209606195776
total_rewards_max            745.7424089837979
total_rewards_min            483.99912113432976
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               30.262341923546046
(Previous) Eval Time (s)     3.7250466248951852
Sample Time (s)              17.02848206181079
Epoch Time (s)               51.01587061025202
Total Train Time (s)         4157.552232609596
Epoch                        87
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:24:59.301356 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #87 | Epoch Duration: 50.916898250579834
2020-01-10 19:24:59.301556 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08426683
Z variance train             0.14322636
KL Divergence                2.8363483
KL Loss                      0.28363484
QF Loss                      624.4661
VF Loss                      200.25601
Policy Loss                  -444.3379
Q Predictions Mean           435.8751
Q Predictions Std            571.39404
Q Predictions Max            1618.4133
Q Predictions Min            15.777546
V Predictions Mean           448.21103
V Predictions Std            573.1729
V Predictions Max            1630.9949
V Predictions Min            26.070864
Log Pis Mean                 -7.5759773
Log Pis Std                  5.4892073
Log Pis Max                  14.970667
Log Pis Min                  -14.786559
Policy mu Mean               0.18312299
Policy mu Std                0.5488649
Policy mu Max                2.116956
Policy mu Min                -2.5107062
Policy log std Mean          -0.21207224
Policy log std Std           0.12498785
Policy log std Max           -0.0370768
Policy log std Min           -0.7034781
Z mean eval                  0.08665343
Z variance eval              0.13952003
total_rewards                [ 812.41098288 1212.11079958  509.35250956  861.79789272  696.05979276
  941.83421583  670.18963601  770.45159556  706.34477368  465.336647  ]
total_rewards_mean           764.588884557302
total_rewards_std            203.7547612747634
total_rewards_max            1212.1107995771908
total_rewards_min            465.33664700341626
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               30.232655704952776
(Previous) Eval Time (s)     3.625771447084844
Sample Time (s)              16.032385980710387
Epoch Time (s)               49.89081313274801
Total Train Time (s)         4208.544036954176
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:25:50.295066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #88 | Epoch Duration: 50.99334263801575
2020-01-10 19:25:50.295287 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #88 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08699666
Z variance train             0.13946822
KL Divergence                2.9026818
KL Loss                      0.29026818
QF Loss                      734.8064
VF Loss                      247.58383
Policy Loss                  -456.5694
Q Predictions Mean           447.50082
Q Predictions Std            568.7335
Q Predictions Max            1646.0314
Q Predictions Min            17.278307
V Predictions Mean           455.80072
V Predictions Std            566.27924
V Predictions Max            1640.3005
V Predictions Min            27.236483
Log Pis Mean                 -7.3379536
Log Pis Std                  5.8021083
Log Pis Max                  12.52339
Log Pis Min                  -17.37882
Policy mu Mean               0.20668945
Policy mu Std                0.5576228
Policy mu Max                2.3134181
Policy mu Min                -1.9635452
Policy log std Mean          -0.21511324
Policy log std Std           0.12659729
Policy log std Max           -0.038865283
Policy log std Min           -0.6701726
Z mean eval                  0.085504465
Z variance eval              0.13486186
total_rewards                [573.94917847 539.94803761 666.54365413 864.06645513 599.81037503
 635.41948471 634.49839902 529.85996297 644.37931207 363.48531791]
total_rewards_mean           605.1960177048061
total_rewards_std            119.76940614563615
total_rewards_max            864.0664551250459
total_rewards_min            363.48531791077016
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               31.159705112222582
(Previous) Eval Time (s)     4.728001464158297
Sample Time (s)              17.873930926900357
Epoch Time (s)               53.761637503281236
Total Train Time (s)         4261.506454571616
Epoch                        89
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:26:43.259925 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #89 | Epoch Duration: 52.964457511901855
2020-01-10 19:26:43.260156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08534758
Z variance train             0.13485992
KL Divergence                2.9700263
KL Loss                      0.29700264
QF Loss                      944.4426
VF Loss                      224.6025
Policy Loss                  -484.8903
Q Predictions Mean           474.646
Q Predictions Std            579.96155
Q Predictions Max            1634.5963
Q Predictions Min            15.671376
V Predictions Mean           483.25403
V Predictions Std            580.54535
V Predictions Max            1645.655
V Predictions Min            24.600178
Log Pis Mean                 -7.0624986
Log Pis Std                  5.809189
Log Pis Max                  14.253908
Log Pis Min                  -14.354021
Policy mu Mean               0.22387828
Policy mu Std                0.5842413
Policy mu Max                2.3640442
Policy mu Min                -2.0898829
Policy log std Mean          -0.22808994
Policy log std Std           0.13729778
Policy log std Max           -0.073580585
Policy log std Min           -0.72938305
Z mean eval                  0.08328243
Z variance eval              0.13631193
total_rewards                [ 526.75956223  855.93192347 1142.01452969  563.37535315  630.38641229
  602.61343719 1268.31844977 1094.95387225  733.16876955  633.68374898]
total_rewards_mean           805.120605857566
total_rewards_std            256.25560736404015
total_rewards_max            1268.3184497749412
total_rewards_min            526.7595622313369
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               28.721076005138457
(Previous) Eval Time (s)     3.930474378168583
Sample Time (s)              17.369047079235315
Epoch Time (s)               50.020597462542355
Total Train Time (s)         4312.480719428044
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:27:34.236921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #90 | Epoch Duration: 50.97657513618469
2020-01-10 19:27:34.237167 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08370169
Z variance train             0.13642715
KL Divergence                2.9249816
KL Loss                      0.29249817
QF Loss                      545.6112
VF Loss                      226.89612
Policy Loss                  -448.38193
Q Predictions Mean           436.5732
Q Predictions Std            564.06573
Q Predictions Max            1622.6792
Q Predictions Min            17.352707
V Predictions Mean           444.68195
V Predictions Std            562.1652
V Predictions Max            1622.2316
V Predictions Min            24.23902
Log Pis Mean                 -7.8313584
Log Pis Std                  5.1826487
Log Pis Max                  8.890979
Log Pis Min                  -13.646014
Policy mu Mean               0.175555
Policy mu Std                0.5319575
Policy mu Max                2.0332606
Policy mu Min                -1.9732715
Policy log std Mean          -0.2069815
Policy log std Std           0.12244842
Policy log std Max           -0.043153405
Policy log std Min           -0.6540364
Z mean eval                  0.081561014
Z variance eval              0.13882896
total_rewards                [ 493.88724658 1229.37879214  536.04172907  667.49770342  853.22992973
 1018.95077314 1222.94933992 1044.95496007  705.43699184  559.49666055]
total_rewards_mean           833.1824126465453
total_rewards_std            266.59655457683834
total_rewards_max            1229.3787921411572
total_rewards_min            493.88724658300924
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               29.952926198020577
(Previous) Eval Time (s)     4.88615095987916
Sample Time (s)              16.607952166348696
Epoch Time (s)               51.44702932424843
Total Train Time (s)         4364.011936846655
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:28:25.769742 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #91 | Epoch Duration: 51.53237271308899
2020-01-10 19:28:25.769981 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08147154
Z variance train             0.13883455
KL Divergence                2.9022574
KL Loss                      0.29022574
QF Loss                      750.371
VF Loss                      306.30035
Policy Loss                  -527.73425
Q Predictions Mean           515.88086
Q Predictions Std            613.90686
Q Predictions Max            1653.8918
Q Predictions Min            15.047263
V Predictions Mean           519.16296
V Predictions Std            607.81305
V Predictions Max            1650.5477
V Predictions Min            23.2796
Log Pis Mean                 -7.423759
Log Pis Std                  5.3561673
Log Pis Max                  11.975271
Log Pis Min                  -13.491543
Policy mu Mean               0.17831898
Policy mu Std                0.5847518
Policy mu Max                2.278201
Policy mu Min                -2.404498
Policy log std Mean          -0.22400106
Policy log std Std           0.13773397
Policy log std Max           -0.046696857
Policy log std Min           -0.79212236
Z mean eval                  0.081452474
Z variance eval              0.13750458
total_rewards                [1072.42048296 1001.95012883  499.05414282  460.54261283  871.97899662
  468.12552224  953.11994905  648.3895236   712.56625938  649.38995962]
total_rewards_mean           733.7537577957099
total_rewards_std            216.5622308304915
total_rewards_max            1072.4204829604928
total_rewards_min            460.542612832498
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               29.13750141998753
(Previous) Eval Time (s)     4.971158695872873
Sample Time (s)              17.66132955858484
Epoch Time (s)               51.76998967444524
Total Train Time (s)         4415.361328924075
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:29:17.119404 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #92 | Epoch Duration: 51.3492648601532
2020-01-10 19:29:17.119560 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0812072
Z variance train             0.13752943
KL Divergence                2.9258704
KL Loss                      0.29258704
QF Loss                      565.6627
VF Loss                      240.68307
Policy Loss                  -486.43378
Q Predictions Mean           480.01587
Q Predictions Std            591.7602
Q Predictions Max            1645.8685
Q Predictions Min            13.210207
V Predictions Mean           490.99646
V Predictions Std            591.77765
V Predictions Max            1658.2754
V Predictions Min            24.868994
Log Pis Mean                 -7.2676454
Log Pis Std                  5.76075
Log Pis Max                  7.862551
Log Pis Min                  -13.641155
Policy mu Mean               0.15702501
Policy mu Std                0.59213006
Policy mu Max                2.4519088
Policy mu Min                -2.324213
Policy log std Mean          -0.22003403
Policy log std Std           0.13263156
Policy log std Max           -0.0014902651
Policy log std Min           -0.7806892
Z mean eval                  0.079099275
Z variance eval              0.13116367
total_rewards                [1172.97587352  686.51016265  964.75380596  424.31313943  676.43620038
  540.4927155   812.10753466  684.19671391  523.81700201  610.56412442]
total_rewards_mean           709.6167272430815
total_rewards_std            211.40389195602972
total_rewards_max            1172.9758735208043
total_rewards_min            424.31313942971303
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               29.257998079061508
(Previous) Eval Time (s)     4.550113103818148
Sample Time (s)              16.48043925780803
Epoch Time (s)               50.288550440687686
Total Train Time (s)         4465.578277855646
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:30:07.341360 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #93 | Epoch Duration: 50.221633434295654
2020-01-10 19:30:07.341658 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07927301
Z variance train             0.13116246
KL Divergence                3.0286102
KL Loss                      0.30286103
QF Loss                      699.66907
VF Loss                      445.44543
Policy Loss                  -512.09906
Q Predictions Mean           509.0913
Q Predictions Std            602.9227
Q Predictions Max            1646.8486
Q Predictions Min            15.455569
V Predictions Mean           522.36115
V Predictions Std            607.435
V Predictions Max            1681.6864
V Predictions Min            25.888718
Log Pis Mean                 -7.264071
Log Pis Std                  5.6020665
Log Pis Max                  10.775833
Log Pis Min                  -13.526523
Policy mu Mean               0.17628081
Policy mu Std                0.57538664
Policy mu Max                2.0686965
Policy mu Min                -1.9580562
Policy log std Mean          -0.22343113
Policy log std Std           0.13517931
Policy log std Max           -0.049477346
Policy log std Min           -0.71144205
Z mean eval                  0.077393755
Z variance eval              0.13191923
total_rewards                [ 767.27644641 1146.65858107  934.33074084 1241.56267898  721.04544567
  577.02571692  516.03453853  607.18628947 1171.90174909 1127.79107245]
total_rewards_mean           881.0813259414601
total_rewards_std            262.30636611002086
total_rewards_max            1241.562678978216
total_rewards_min            516.0345385293397
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               29.961018837988377
(Previous) Eval Time (s)     4.482876083813608
Sample Time (s)              16.10987473744899
Epoch Time (s)               50.553769659250975
Total Train Time (s)         4516.735178925097
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:30:58.500562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #94 | Epoch Duration: 51.15865731239319
2020-01-10 19:30:58.500848 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.077585675
Z variance train             0.13194886
KL Divergence                3.033986
KL Loss                      0.3033986
QF Loss                      738.7051
VF Loss                      323.5286
Policy Loss                  -440.24835
Q Predictions Mean           434.10425
Q Predictions Std            581.6528
Q Predictions Max            1671.3733
Q Predictions Min            15.310394
V Predictions Mean           437.04987
V Predictions Std            576.6892
V Predictions Max            1664.5222
V Predictions Min            26.458065
Log Pis Mean                 -7.8320456
Log Pis Std                  5.1008773
Log Pis Max                  5.9728074
Log Pis Min                  -13.324635
Policy mu Mean               0.16451941
Policy mu Std                0.538471
Policy mu Max                2.3321123
Policy mu Min                -2.5969605
Policy log std Mean          -0.20844188
Policy log std Std           0.12643272
Policy log std Max           -0.026451893
Policy log std Min           -0.7203541
Z mean eval                  0.076908536
Z variance eval              0.13000321
total_rewards                [ 743.002797    615.20576968  930.33576168  742.42898002  682.72077227
  837.96223734 1163.76415527  864.31338862  695.87751175  619.64801005]
total_rewards_mean           789.5259383677114
total_rewards_std            158.62749330622455
total_rewards_max            1163.764155269622
total_rewards_min            615.2057696818016
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               29.092064212076366
(Previous) Eval Time (s)     5.08745955536142
Sample Time (s)              16.707505298312753
Epoch Time (s)               50.88702906575054
Total Train Time (s)         4567.214637851808
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:31:48.980323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #95 | Epoch Duration: 50.479241132736206
2020-01-10 19:31:48.980483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #95 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07671334
Z variance train             0.13000992
KL Divergence                3.0561638
KL Loss                      0.30561638
QF Loss                      495.8783
VF Loss                      166.15175
Policy Loss                  -490.09518
Q Predictions Mean           483.74686
Q Predictions Std            619.4815
Q Predictions Max            1662.8053
Q Predictions Min            15.561727
V Predictions Mean           492.51135
V Predictions Std            618.4192
V Predictions Max            1674.5685
V Predictions Min            24.06473
Log Pis Mean                 -7.4986134
Log Pis Std                  5.3872824
Log Pis Max                  11.0107565
Log Pis Min                  -13.624991
Policy mu Mean               0.19169617
Policy mu Std                0.53980565
Policy mu Max                2.233528
Policy mu Min                -2.26215
Policy log std Mean          -0.21409413
Policy log std Std           0.1306256
Policy log std Max           -0.03586159
Policy log std Min           -0.69590914
Z mean eval                  0.07737422
Z variance eval              0.13109721
total_rewards                [423.30768446 645.53074299 383.54854326 523.04631439 477.80814451
 572.94137558 411.13844128 709.83464684 714.6367047  441.70164023]
total_rewards_mean           530.3494238243638
total_rewards_std            117.96168854590175
total_rewards_max            714.6367047032984
total_rewards_min            383.54854326337704
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               28.617864227853715
(Previous) Eval Time (s)     4.679377915337682
Sample Time (s)              16.376173664350063
Epoch Time (s)               49.67341580754146
Total Train Time (s)         4615.323789976537
Epoch                        96
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:32:37.090773 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #96 | Epoch Duration: 48.11016345024109
2020-01-10 19:32:37.090955 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.077592574
Z variance train             0.1311545
KL Divergence                3.0617535
KL Loss                      0.30617535
QF Loss                      865.0183
VF Loss                      276.729
Policy Loss                  -558.82623
Q Predictions Mean           551.94464
Q Predictions Std            647.2287
Q Predictions Max            1693.4498
Q Predictions Min            14.345992
V Predictions Mean           553.7455
V Predictions Std            637.80774
V Predictions Max            1676.6467
V Predictions Min            24.846766
Log Pis Mean                 -7.0282116
Log Pis Std                  5.816865
Log Pis Max                  13.992428
Log Pis Min                  -13.104
Policy mu Mean               0.18760182
Policy mu Std                0.57986957
Policy mu Max                2.243546
Policy mu Min                -2.194384
Policy log std Mean          -0.2208596
Policy log std Std           0.1334106
Policy log std Max           -0.024826288
Policy log std Min           -0.674366
Z mean eval                  0.078048475
Z variance eval              0.13527249
total_rewards                [ 612.96101768  889.11139342  882.23473652  560.33839338  640.38649928
 1147.25907769  827.19575757  532.99143295  575.89454683  543.06479728]
total_rewards_mean           721.14376526039
total_rewards_std            194.75088565903525
total_rewards_max            1147.2590776915708
total_rewards_min            532.9914329463954
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               29.42655768804252
(Previous) Eval Time (s)     3.1158571606501937
Sample Time (s)              15.518162112683058
Epoch Time (s)               48.06057696137577
Total Train Time (s)         4664.632439881563
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:33:26.403591 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #97 | Epoch Duration: 49.31246519088745
2020-01-10 19:33:26.403909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #97 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07859279
Z variance train             0.13522288
KL Divergence                3.0142977
KL Loss                      0.30142978
QF Loss                      602.64294
VF Loss                      312.70795
Policy Loss                  -487.84348
Q Predictions Mean           478.1012
Q Predictions Std            611.62396
Q Predictions Max            1689.5925
Q Predictions Min            13.737334
V Predictions Mean           481.93457
V Predictions Std            604.524
V Predictions Max            1679.9961
V Predictions Min            24.196255
Log Pis Mean                 -7.767334
Log Pis Std                  5.244333
Log Pis Max                  10.284809
Log Pis Min                  -13.00566
Policy mu Mean               0.16363658
Policy mu Std                0.54040736
Policy mu Max                2.142451
Policy mu Min                -2.2644162
Policy log std Mean          -0.20868772
Policy log std Std           0.12973145
Policy log std Max           -0.009776309
Policy log std Min           -0.73508775
Z mean eval                  0.07846065
Z variance eval              0.13393149
total_rewards                [796.8636143  605.1195994  560.64364066 428.74885972 449.25668669
 756.71016622 798.70858748 412.71340611 682.85222722 461.07411707]
total_rewards_mean           595.2690904864451
total_rewards_std            147.4589570522352
total_rewards_max            798.7085874785964
total_rewards_min            412.71340610774854
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               30.439670982770622
(Previous) Eval Time (s)     4.367448745761067
Sample Time (s)              17.263367432169616
Epoch Time (s)               52.070487160701305
Total Train Time (s)         4716.191066147294
Epoch                        98
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:34:17.963140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #98 | Epoch Duration: 51.55893564224243
2020-01-10 19:34:17.963442 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07869927
Z variance train             0.13392302
KL Divergence                3.0221128
KL Loss                      0.30221128
QF Loss                      596.6007
VF Loss                      264.37473
Policy Loss                  -586.66034
Q Predictions Mean           577.807
Q Predictions Std            671.70703
Q Predictions Max            1703.5234
Q Predictions Min            15.426311
V Predictions Mean           585.40063
V Predictions Std            667.55396
V Predictions Max            1708.3878
V Predictions Min            27.573147
Log Pis Mean                 -7.0101976
Log Pis Std                  5.651733
Log Pis Max                  9.614008
Log Pis Min                  -13.553629
Policy mu Mean               0.19151315
Policy mu Std                0.5872477
Policy mu Max                2.683962
Policy mu Min                -2.0552578
Policy log std Mean          -0.22926067
Policy log std Std           0.14474075
Policy log std Max           -0.07752471
Policy log std Min           -0.81756294
Z mean eval                  0.07834592
Z variance eval              0.12865658
total_rewards                [ 710.05366576  799.88346244  821.63216533 1092.79126671  757.74424298
  621.7168738   773.30806487  560.4497385   483.04481542  621.71140141]
total_rewards_mean           724.2335697212168
total_rewards_std            161.49121839539782
total_rewards_max            1092.7912667107144
total_rewards_min            483.04481541713943
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               28.486337542999536
(Previous) Eval Time (s)     3.8555826591327786
Sample Time (s)              16.27454407280311
Epoch Time (s)               48.616464274935424
Total Train Time (s)         4765.361993419938
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:35:07.134758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #99 | Epoch Duration: 49.17114853858948
2020-01-10 19:35:07.134956 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.078292355
Z variance train             0.1286561
KL Divergence                3.0923076
KL Loss                      0.30923077
QF Loss                      618.28467
VF Loss                      174.9131
Policy Loss                  -485.51074
Q Predictions Mean           476.61536
Q Predictions Std            604.7164
Q Predictions Max            1674.6866
Q Predictions Min            17.001068
V Predictions Mean           483.21088
V Predictions Std            602.04645
V Predictions Max            1682.6733
V Predictions Min            25.873457
Log Pis Mean                 -6.9874682
Log Pis Std                  5.91226
Log Pis Max                  11.675655
Log Pis Min                  -15.966562
Policy mu Mean               0.20008734
Policy mu Std                0.56779
Policy mu Max                2.2142794
Policy mu Min                -1.9965479
Policy log std Mean          -0.21861462
Policy log std Std           0.13452058
Policy log std Max           -0.047219507
Policy log std Min           -0.7248382
Z mean eval                  0.07907621
Z variance eval              0.13155952
total_rewards                [ 829.5483334   744.98713286 1283.66095371  534.6387307  1279.75315546
  892.05759912 1573.99044931  815.6154694   782.09983944  478.94983133]
total_rewards_mean           921.5301494729425
total_rewards_std            331.94647843067344
total_rewards_max            1573.9904493065449
total_rewards_min            478.94983133195353
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               30.668282662983984
(Previous) Eval Time (s)     4.409951804205775
Sample Time (s)              17.1199469990097
Epoch Time (s)               52.19818146619946
Total Train Time (s)         4818.6580420406535
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:36:00.435044 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #100 | Epoch Duration: 53.29979372024536
2020-01-10 19:36:00.435416 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07904286
Z variance train             0.13166615
KL Divergence                3.0568714
KL Loss                      0.30568716
QF Loss                      816.3999
VF Loss                      285.80402
Policy Loss                  -506.5933
Q Predictions Mean           494.52466
Q Predictions Std            629.0897
Q Predictions Max            1706.9495
Q Predictions Min            14.203755
V Predictions Mean           506.76617
V Predictions Std            631.4507
V Predictions Max            1709.6135
V Predictions Min            22.191833
Log Pis Mean                 -7.405303
Log Pis Std                  5.7774806
Log Pis Max                  13.881322
Log Pis Min                  -13.11356
Policy mu Mean               0.16659597
Policy mu Std                0.5599776
Policy mu Max                2.2195358
Policy mu Min                -2.5241766
Policy log std Mean          -0.21738787
Policy log std Std           0.13581865
Policy log std Max           -0.08141237
Policy log std Min           -0.8779402
Z mean eval                  0.07909142
Z variance eval              0.1257678
total_rewards                [ 914.3734606   638.13205658  840.98934673  524.93550591 1105.22076537
  712.12974527 1094.51488408  792.23504862  709.75281178 1108.25368261]
total_rewards_mean           844.053730754869
total_rewards_std            196.9926157578858
total_rewards_max            1108.2536826063672
total_rewards_min            524.9355059128313
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               29.985677314922214
(Previous) Eval Time (s)     5.511259275022894
Sample Time (s)              16.818098575342447
Epoch Time (s)               52.315035165287554
Total Train Time (s)         4870.626769701019
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:36:52.407384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #101 | Epoch Duration: 51.97173619270325
2020-01-10 19:36:52.407659 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #101 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.079174265
Z variance train             0.12578063
KL Divergence                3.1514523
KL Loss                      0.31514522
QF Loss                      646.68823
VF Loss                      253.23456
Policy Loss                  -574.4719
Q Predictions Mean           567.7566
Q Predictions Std            647.4859
Q Predictions Max            1716.038
Q Predictions Min            15.065566
V Predictions Mean           570.9357
V Predictions Std            641.2269
V Predictions Max            1701.195
V Predictions Min            23.942778
Log Pis Mean                 -6.704004
Log Pis Std                  5.906859
Log Pis Max                  15.62129
Log Pis Min                  -14.179894
Policy mu Mean               0.22002998
Policy mu Std                0.60973835
Policy mu Max                2.655732
Policy mu Min                -3.1918862
Policy log std Mean          -0.2322303
Policy log std Std           0.13968484
Policy log std Max           -0.037971914
Policy log std Min           -0.84356797
Z mean eval                  0.07945769
Z variance eval              0.12757786
total_rewards                [882.41708671 867.46661256 808.16594912 920.15319409 930.26575177
 547.75842555 498.21078704 760.98002373 657.45340308 501.98237655]
total_rewards_mean           737.4853610198754
total_rewards_std            164.0412428774531
total_rewards_max            930.2657517709118
total_rewards_min            498.2107870396713
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               30.35818051220849
(Previous) Eval Time (s)     5.167628235183656
Sample Time (s)              17.381157831288874
Epoch Time (s)               52.90696657868102
Total Train Time (s)         4922.692161572631
Epoch                        102
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:37:44.473299 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #102 | Epoch Duration: 52.065415143966675
2020-01-10 19:37:44.473603 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #102 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08008643
Z variance train             0.1276129
KL Divergence                3.0968149
KL Loss                      0.3096815
QF Loss                      851.732
VF Loss                      195.39255
Policy Loss                  -514.45087
Q Predictions Mean           502.83273
Q Predictions Std            625.97284
Q Predictions Max            1730.242
Q Predictions Min            15.101295
V Predictions Mean           510.31293
V Predictions Std            624.6292
V Predictions Max            1717.2112
V Predictions Min            23.370998
Log Pis Mean                 -7.380838
Log Pis Std                  5.766716
Log Pis Max                  15.25946
Log Pis Min                  -15.618342
Policy mu Mean               0.1646856
Policy mu Std                0.56399703
Policy mu Max                2.1625154
Policy mu Min                -2.2239778
Policy log std Mean          -0.22140181
Policy log std Std           0.13409388
Policy log std Max           0.06273648
Policy log std Min           -0.7234309
Z mean eval                  0.08134721
Z variance eval              0.12029521
total_rewards                [571.81558354 738.08428724 807.3232755  848.68233109 892.97607044
 592.70711796 457.77051575 655.50657447 773.74271385 830.27076383]
total_rewards_mean           716.8879233646564
total_rewards_std            134.338800446789
total_rewards_max            892.9760704404227
total_rewards_min            457.7705157479797
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               30.59501967113465
(Previous) Eval Time (s)     4.3257830971851945
Sample Time (s)              16.674509970471263
Epoch Time (s)               51.59531273879111
Total Train Time (s)         4974.050639472902
Epoch                        103
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:38:35.836151 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #103 | Epoch Duration: 51.36229181289673
2020-01-10 19:38:35.836385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.081521995
Z variance train             0.12028022
KL Divergence                3.228449
KL Loss                      0.32284492
QF Loss                      661.01086
VF Loss                      181.94695
Policy Loss                  -581.06525
Q Predictions Mean           574.5283
Q Predictions Std            630.9306
Q Predictions Max            1737.2565
Q Predictions Min            14.918989
V Predictions Mean           579.23413
V Predictions Std            625.4988
V Predictions Max            1729.8649
V Predictions Min            26.170923
Log Pis Mean                 -6.3697963
Log Pis Std                  5.9238915
Log Pis Max                  10.311815
Log Pis Min                  -13.581451
Policy mu Mean               0.21764836
Policy mu Std                0.6177679
Policy mu Max                2.058559
Policy mu Min                -2.00565
Policy log std Mean          -0.23444813
Policy log std Std           0.1421113
Policy log std Max           -0.04045248
Policy log std Min           -0.7628933
Z mean eval                  0.08008665
Z variance eval              0.11673598
total_rewards                [ 638.1311104  1038.51083404  725.24101113 1409.33219949  686.38368657
  710.83207736  478.04444775  505.59077599  611.10232774  757.46466608]
total_rewards_mean           756.0633136557773
total_rewards_std            262.5533481377783
total_rewards_max            1409.332199490207
total_rewards_min            478.0444477527456
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               29.148309679236263
(Previous) Eval Time (s)     4.092453727964312
Sample Time (s)              16.86026818724349
Epoch Time (s)               50.101031594444066
Total Train Time (s)         5024.388712068554
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:39:26.173068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #104 | Epoch Duration: 50.3365113735199
2020-01-10 19:39:26.173249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08017744
Z variance train             0.1167238
KL Divergence                3.2988136
KL Loss                      0.32988137
QF Loss                      858.63525
VF Loss                      331.97864
Policy Loss                  -542.80035
Q Predictions Mean           531.3032
Q Predictions Std            631.38525
Q Predictions Max            1714.4973
Q Predictions Min            16.122715
V Predictions Mean           541.8805
V Predictions Std            631.9481
V Predictions Max            1738.3289
V Predictions Min            27.218596
Log Pis Mean                 -7.2550497
Log Pis Std                  5.457736
Log Pis Max                  6.881275
Log Pis Min                  -13.822659
Policy mu Mean               0.2015469
Policy mu Std                0.57336354
Policy mu Max                2.2237458
Policy mu Min                -1.9177077
Policy log std Mean          -0.2236376
Policy log std Std           0.13613991
Policy log std Max           -0.056567155
Policy log std Min           -0.75674725
Z mean eval                  0.07915036
Z variance eval              0.11400585
total_rewards                [ 772.62867501  666.19020463  417.03701688 1157.16839775 1311.18543411
  880.89051207 1028.64917327  886.46912553  694.04275135  857.71011403]
total_rewards_mean           867.1971404637067
total_rewards_std            242.87819531489242
total_rewards_max            1311.185434113626
total_rewards_min            417.03701688313856
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               29.821832736954093
(Previous) Eval Time (s)     4.327637515962124
Sample Time (s)              16.133267145603895
Epoch Time (s)               50.28273739852011
Total Train Time (s)         5075.526710285805
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:40:17.314158 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #105 | Epoch Duration: 51.14072632789612
2020-01-10 19:40:17.314467 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #105 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0791151
Z variance train             0.11398747
KL Divergence                3.3437657
KL Loss                      0.33437657
QF Loss                      1038.5344
VF Loss                      270.7187
Policy Loss                  -627.767
Q Predictions Mean           616.70386
Q Predictions Std            672.9857
Q Predictions Max            1725.0106
Q Predictions Min            17.52378
V Predictions Mean           626.3331
V Predictions Std            671.01733
V Predictions Max            1744.005
V Predictions Min            27.74387
Log Pis Mean                 -6.8619313
Log Pis Std                  5.377736
Log Pis Max                  9.256976
Log Pis Min                  -13.443987
Policy mu Mean               0.2026103
Policy mu Std                0.6057733
Policy mu Max                2.1423678
Policy mu Min                -2.0812821
Policy log std Mean          -0.23487863
Policy log std Std           0.14049019
Policy log std Max           -0.062378094
Policy log std Min           -0.8793348
Z mean eval                  0.077223785
Z variance eval              0.11701135
total_rewards                [ 624.47428626  886.14714861 1250.4473757   857.30033351  673.6782219
  607.59011662  730.36645101  416.80686993 1052.38813693  537.41565861]
total_rewards_mean           763.6614599084617
total_rewards_std            238.437989392449
total_rewards_max            1250.4473756991263
total_rewards_min            416.80686993373024
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               31.340556893963367
(Previous) Eval Time (s)     5.185311019886285
Sample Time (s)              16.753983889706433
Epoch Time (s)               53.279851803556085
Total Train Time (s)         5127.736985226627
Epoch                        106
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:41:09.527619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #106 | Epoch Duration: 52.21289563179016
2020-01-10 19:41:09.527930 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07728202
Z variance train             0.11702208
KL Divergence                3.3186932
KL Loss                      0.33186933
QF Loss                      1271.329
VF Loss                      359.63254
Policy Loss                  -586.59235
Q Predictions Mean           580.07367
Q Predictions Std            645.0504
Q Predictions Max            1748.088
Q Predictions Min            16.898636
V Predictions Mean           585.71936
V Predictions Std            639.71063
V Predictions Max            1735.3269
V Predictions Min            27.49564
Log Pis Mean                 -6.732945
Log Pis Std                  5.9158773
Log Pis Max                  13.690415
Log Pis Min                  -13.804308
Policy mu Mean               0.21760857
Policy mu Std                0.6085029
Policy mu Max                2.6194787
Policy mu Min                -2.14703
Policy log std Mean          -0.22680001
Policy log std Std           0.14000201
Policy log std Max           -0.022884995
Policy log std Min           -0.8510914
Z mean eval                  0.0773403
Z variance eval              0.1108314
total_rewards                [ 850.09513014  533.38553512  843.05122987 1149.87357552  605.09599723
 1232.89762086  744.09441954  937.05302231  665.9773939   979.60595984]
total_rewards_mean           854.1129884336704
total_rewards_std            215.89182755861356
total_rewards_max            1232.8976208617446
total_rewards_min            533.3855351174524
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               31.668143230024725
(Previous) Eval Time (s)     4.118049644865096
Sample Time (s)              16.806452243123204
Epoch Time (s)               52.592645118013024
Total Train Time (s)         5181.027880683076
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:42:02.819374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #107 | Epoch Duration: 53.291224002838135
2020-01-10 19:42:02.819586 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07703644
Z variance train             0.11077316
KL Divergence                3.426742
KL Loss                      0.34267423
QF Loss                      1013.15125
VF Loss                      315.0353
Policy Loss                  -609.7996
Q Predictions Mean           598.11633
Q Predictions Std            670.2821
Q Predictions Max            1728.8805
Q Predictions Min            14.903282
V Predictions Mean           613.3739
V Predictions Std            677.07385
V Predictions Max            1749.8082
V Predictions Min            23.650124
Log Pis Mean                 -6.890933
Log Pis Std                  5.75908
Log Pis Max                  16.034164
Log Pis Min                  -12.6702385
Policy mu Mean               0.22545448
Policy mu Std                0.60102624
Policy mu Max                2.752432
Policy mu Min                -2.1613865
Policy log std Mean          -0.22943558
Policy log std Std           0.14060909
Policy log std Max           0.0900393
Policy log std Min           -0.856744
Z mean eval                  0.07491733
Z variance eval              0.10746435
total_rewards                [ 642.02908109 2581.32127083 1419.63172511 1348.91879854  842.43781891
  538.1041669  1007.66443569  898.64100669  724.70208615 1952.14240322]
total_rewards_mean           1195.5592793143514
total_rewards_std            614.4095559017392
total_rewards_max            2581.321270834845
total_rewards_min            538.1041669045851
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               30.59054965013638
(Previous) Eval Time (s)     4.816294653806835
Sample Time (s)              16.793555340729654
Epoch Time (s)               52.20039964467287
Total Train Time (s)         5235.973649427295
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:42:57.766113 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #108 | Epoch Duration: 54.946367502212524
2020-01-10 19:42:57.766272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07505669
Z variance train             0.107475325
KL Divergence                3.479839
KL Loss                      0.34798393
QF Loss                      838.2106
VF Loss                      201.25928
Policy Loss                  -579.9729
Q Predictions Mean           571.1436
Q Predictions Std            649.044
Q Predictions Max            1756.885
Q Predictions Min            15.174127
V Predictions Mean           580.34424
V Predictions Std            646.5339
V Predictions Max            1752.984
V Predictions Min            28.02318
Log Pis Mean                 -6.795284
Log Pis Std                  5.8239627
Log Pis Max                  13.736293
Log Pis Min                  -13.328293
Policy mu Mean               0.20413493
Policy mu Std                0.6059054
Policy mu Max                2.6181076
Policy mu Min                -2.3667815
Policy log std Mean          -0.23021598
Policy log std Std           0.14144075
Policy log std Max           -0.011465684
Policy log std Min           -0.8385585
Z mean eval                  0.07329822
Z variance eval              0.10689038
total_rewards                [1133.29939767  634.03126396  442.60290257 1119.94630142  739.64161735
  581.56745712  737.24456586  420.73071693 2404.70702858 1043.64583585]
total_rewards_mean           925.7417087313485
total_rewards_std            551.7435946498056
total_rewards_max            2404.7070285810364
total_rewards_min            420.7307169342528
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               31.886845189146698
(Previous) Eval Time (s)     7.561991636175662
Sample Time (s)              17.583581047598273
Epoch Time (s)               57.03241787292063
Total Train Time (s)         5290.733307969291
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:43:52.530871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #109 | Epoch Duration: 54.764427185058594
2020-01-10 19:43:52.531179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0729449
Z variance train             0.10688619
KL Divergence                3.4585485
KL Loss                      0.34585485
QF Loss                      575.0835
VF Loss                      387.35068
Policy Loss                  -532.7192
Q Predictions Mean           527.6427
Q Predictions Std            654.0156
Q Predictions Max            1738.2335
Q Predictions Min            15.017004
V Predictions Mean           540.3415
V Predictions Std            654.917
V Predictions Max            1767.8618
V Predictions Min            27.885715
Log Pis Mean                 -7.047427
Log Pis Std                  5.8061996
Log Pis Max                  8.067343
Log Pis Min                  -14.67092
Policy mu Mean               0.21706374
Policy mu Std                0.5649494
Policy mu Max                2.3198783
Policy mu Min                -2.379479
Policy log std Mean          -0.22203822
Policy log std Std           0.13630076
Policy log std Max           -0.07606004
Policy log std Min           -0.7966962
Z mean eval                  0.07107599
Z variance eval              0.10687685
total_rewards                [ 584.44951823  887.69540725  567.00018737  702.52932961  550.16169813
 1018.05737377  613.10479247 1043.21641051  673.52360383 1380.10453322]
total_rewards_mean           801.9842854379967
total_rewards_std            259.7060549072536
total_rewards_max            1380.1045332201243
total_rewards_min            550.161698130329
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               31.572845601011068
(Previous) Eval Time (s)     5.293673264794052
Sample Time (s)              17.134410458616912
Epoch Time (s)               54.00092932442203
Total Train Time (s)         5344.027940570377
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:44:45.827513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #110 | Epoch Duration: 53.29610776901245
2020-01-10 19:44:45.827740 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07116554
Z variance train             0.10688327
KL Divergence                3.5004742
KL Loss                      0.35004744
QF Loss                      1181.8901
VF Loss                      479.1266
Policy Loss                  -600.6654
Q Predictions Mean           589.3098
Q Predictions Std            657.33264
Q Predictions Max            1758.7366
Q Predictions Min            13.023487
V Predictions Mean           598.02527
V Predictions Std            657.4495
V Predictions Max            1766.6105
V Predictions Min            23.424786
Log Pis Mean                 -6.448933
Log Pis Std                  5.876077
Log Pis Max                  13.9509735
Log Pis Min                  -14.230065
Policy mu Mean               0.22924674
Policy mu Std                0.6072379
Policy mu Max                2.3119562
Policy mu Min                -2.986501
Policy log std Mean          -0.23195486
Policy log std Std           0.14182988
Policy log std Max           -0.025174186
Policy log std Min           -0.7444943
Z mean eval                  0.069848746
Z variance eval              0.105844185
total_rewards                [ 455.30204253  705.21979042  881.19520055  985.84971696  656.93688478
  547.59579757  600.47648188  618.80363791 1024.90370912  989.55311315]
total_rewards_mean           746.5836374856658
total_rewards_std            195.88987299012857
total_rewards_max            1024.9037091240884
total_rewards_min            455.3020425294265
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               27.667228335049003
(Previous) Eval Time (s)     4.588559529744089
Sample Time (s)              17.16215696465224
Epoch Time (s)               49.41794482944533
Total Train Time (s)         5393.040757659357
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:45:34.842199 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #111 | Epoch Duration: 49.01429557800293
2020-01-10 19:45:34.842392 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.069658086
Z variance train             0.105835654
KL Divergence                3.5367198
KL Loss                      0.353672
QF Loss                      728.6974
VF Loss                      193.35187
Policy Loss                  -551.6766
Q Predictions Mean           542.2947
Q Predictions Std            644.90924
Q Predictions Max            1774.3911
Q Predictions Min            17.158464
V Predictions Mean           548.6067
V Predictions Std            640.5265
V Predictions Max            1764.9103
V Predictions Min            28.545498
Log Pis Mean                 -6.930938
Log Pis Std                  5.8179526
Log Pis Max                  8.822022
Log Pis Min                  -14.3374195
Policy mu Mean               0.18741782
Policy mu Std                0.58928126
Policy mu Max                2.4480178
Policy mu Min                -2.1050682
Policy log std Mean          -0.22441205
Policy log std Std           0.1373234
Policy log std Max           -0.055356026
Policy log std Min           -0.7077796
Z mean eval                  0.06910411
Z variance eval              0.10078082
total_rewards                [2393.0356065   685.73111113  966.82169883  932.38735974 1399.36972728
  814.57958986  631.00174773  787.59823172  789.27803607 1086.60388811]
total_rewards_mean           1048.6406996958576
total_rewards_std            494.81121006321956
total_rewards_max            2393.0356065002466
total_rewards_min            631.0017477318313
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               29.251854528672993
(Previous) Eval Time (s)     4.184567602816969
Sample Time (s)              16.788450602907687
Epoch Time (s)               50.22487273439765
Total Train Time (s)         5445.35442804778
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:46:27.159259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #112 | Epoch Duration: 52.316697120666504
2020-01-10 19:46:27.159577 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #112 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06910522
Z variance train             0.100820854
KL Divergence                3.621169
KL Loss                      0.3621169
QF Loss                      719.9168
VF Loss                      328.8875
Policy Loss                  -480.14062
Q Predictions Mean           474.93292
Q Predictions Std            606.3966
Q Predictions Max            1775.0492
Q Predictions Min            15.687178
V Predictions Mean           486.60855
V Predictions Std            605.5538
V Predictions Max            1776.5271
V Predictions Min            24.630903
Log Pis Mean                 -6.977851
Log Pis Std                  6.1296163
Log Pis Max                  15.52659
Log Pis Min                  -15.254621
Policy mu Mean               0.21951912
Policy mu Std                0.56924987
Policy mu Max                2.3373132
Policy mu Min                -2.3772764
Policy log std Mean          -0.21986687
Policy log std Std           0.13621019
Policy log std Max           -0.07599589
Policy log std Min           -0.7908772
Z mean eval                  0.06927718
Z variance eval              0.098808214
total_rewards                [724.00491795 527.94564578 410.74670861 684.11425353 865.98723347
 916.43096076 958.62351584 725.3461346  745.64975303 805.91053442]
total_rewards_mean           736.475965798254
total_rewards_std            160.00544140308327
total_rewards_max            958.6235158377751
total_rewards_min            410.74670861278577
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               31.660066077951342
(Previous) Eval Time (s)     6.276063110213727
Sample Time (s)              17.529689284972847
Epoch Time (s)               55.465818473137915
Total Train Time (s)         5499.2037998130545
Epoch                        113
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:47:21.011677 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #113 | Epoch Duration: 53.85184192657471
2020-01-10 19:47:21.011984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #113 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06932729
Z variance train             0.09881826
KL Divergence                3.6537573
KL Loss                      0.36537573
QF Loss                      746.53784
VF Loss                      276.78958
Policy Loss                  -567.23724
Q Predictions Mean           560.7627
Q Predictions Std            669.94763
Q Predictions Max            1783.0582
Q Predictions Min            14.437466
V Predictions Mean           573.19336
V Predictions Std            670.2483
V Predictions Max            1796.4602
V Predictions Min            24.816092
Log Pis Mean                 -6.875036
Log Pis Std                  6.125635
Log Pis Max                  28.193539
Log Pis Min                  -12.657325
Policy mu Mean               0.20779108
Policy mu Std                0.56980187
Policy mu Max                2.9994588
Policy mu Min                -2.5454972
Policy log std Mean          -0.22306624
Policy log std Std           0.13993675
Policy log std Max           -0.050394394
Policy log std Min           -0.8855348
Z mean eval                  0.06858408
Z variance eval              0.095778726
total_rewards                [439.58046305 735.16148309 396.20437695 958.51812423 521.42456897
 505.28167137 532.09880141 426.40317856 828.37594381 525.80004504]
total_rewards_mean           586.8848656485812
total_rewards_std            178.85865441311185
total_rewards_max            958.5181242333164
total_rewards_min            396.2043769499861
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               30.376707090996206
(Previous) Eval Time (s)     4.661793961189687
Sample Time (s)              16.84790709707886
Epoch Time (s)               51.88640814926475
Total Train Time (s)         5550.007444102783
Epoch                        114
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:48:11.816651 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #114 | Epoch Duration: 50.80445122718811
2020-01-10 19:48:11.816834 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06870487
Z variance train             0.09579955
KL Divergence                3.7160084
KL Loss                      0.37160084
QF Loss                      640.33716
VF Loss                      294.6831
Policy Loss                  -567.3788
Q Predictions Mean           560.1688
Q Predictions Std            674.1147
Q Predictions Max            1801.7832
Q Predictions Min            15.855105
V Predictions Mean           560.5254
V Predictions Std            662.72534
V Predictions Max            1775.7961
V Predictions Min            27.069815
Log Pis Mean                 -6.6392136
Log Pis Std                  6.182586
Log Pis Max                  14.507552
Log Pis Min                  -12.736542
Policy mu Mean               0.21967593
Policy mu Std                0.60406256
Policy mu Max                2.269489
Policy mu Min                -2.9019976
Policy log std Mean          -0.23182775
Policy log std Std           0.14576948
Policy log std Max           -0.07695208
Policy log std Min           -0.7546724
Z mean eval                  0.06894416
Z variance eval              0.09627144
total_rewards                [ 706.62393533 1726.20943354  549.34512322  396.27368252 1112.69344243
 1539.37890275 1128.69648025  744.05800277 1110.23307272  395.22412036]
total_rewards_mean           940.873619590798
total_rewards_std            436.9976372985793
total_rewards_max            1726.2094335398888
total_rewards_min            395.2241203644524
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               29.41136733116582
(Previous) Eval Time (s)     3.5794899659231305
Sample Time (s)              17.819645361509174
Epoch Time (s)               50.810502658598125
Total Train Time (s)         5602.491340268403
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:49:04.302753 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #115 | Epoch Duration: 52.48575758934021
2020-01-10 19:49:04.302982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068954065
Z variance train             0.09626275
KL Divergence                3.7123425
KL Loss                      0.37123427
QF Loss                      1137.3069
VF Loss                      465.51056
Policy Loss                  -512.9277
Q Predictions Mean           506.03046
Q Predictions Std            650.0119
Q Predictions Max            1764.3761
Q Predictions Min            15.80231
V Predictions Mean           518.9822
V Predictions Std            653.7177
V Predictions Max            1777.1152
V Predictions Min            25.145952
Log Pis Mean                 -7.398997
Log Pis Std                  5.6057596
Log Pis Max                  6.5903444
Log Pis Min                  -12.690598
Policy mu Mean               0.18183708
Policy mu Std                0.5783271
Policy mu Max                2.283806
Policy mu Min                -2.5201557
Policy log std Mean          -0.21914965
Policy log std Std           0.1397459
Policy log std Max           -0.034824774
Policy log std Min           -0.7313075
Z mean eval                  0.063152134
Z variance eval              0.09108377
total_rewards                [ 564.57541906 1033.71324027  595.08835602 1287.86622512 1394.26209975
  804.27698681 1022.66858119  555.13584797  905.85702341  389.12685954]
total_rewards_mean           855.2570639141338
total_rewards_std            316.58227194366015
total_rewards_max            1394.2620997537929
total_rewards_min            389.12685954104944
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               29.545147823169827
(Previous) Eval Time (s)     5.254446031991392
Sample Time (s)              17.16281591448933
Epoch Time (s)               51.96240976965055
Total Train Time (s)         5654.337301480118
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:49:56.150256 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #116 | Epoch Duration: 51.84710097312927
2020-01-10 19:49:56.150448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #116 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06285802
Z variance train             0.09107672
KL Divergence                3.8272276
KL Loss                      0.38272277
QF Loss                      1071.0537
VF Loss                      412.65686
Policy Loss                  -605.82666
Q Predictions Mean           596.54816
Q Predictions Std            675.20795
Q Predictions Max            1790.8893
Q Predictions Min            16.046986
V Predictions Mean           612.4284
V Predictions Std            678.9575
V Predictions Max            1798.3246
V Predictions Min            28.533619
Log Pis Mean                 -6.5730505
Log Pis Std                  5.823535
Log Pis Max                  8.829964
Log Pis Min                  -15.471424
Policy mu Mean               0.24202117
Policy mu Std                0.61193806
Policy mu Max                2.264978
Policy mu Min                -2.1601171
Policy log std Mean          -0.2412492
Policy log std Std           0.14908071
Policy log std Max           -0.05318363
Policy log std Min           -0.8810509
Z mean eval                  0.06268127
Z variance eval              0.091734335
total_rewards                [673.41476495 654.36991116 457.62712163 929.3364833  493.13386248
 601.59593303 777.90339168 821.11701277 930.70972382 810.36056904]
total_rewards_mean           714.9568773864405
total_rewards_std            158.2761172730808
total_rewards_max            930.7097238246785
total_rewards_min            457.6271216327193
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               29.11768696922809
(Previous) Eval Time (s)     5.1388394152745605
Sample Time (s)              17.274205594323575
Epoch Time (s)               51.530731978826225
Total Train Time (s)         5704.82045111293
Epoch                        117
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:50:46.636760 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #117 | Epoch Duration: 50.486138105392456
2020-01-10 19:50:46.637016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0627717
Z variance train             0.09176324
KL Divergence                3.8190281
KL Loss                      0.3819028
QF Loss                      1530.1163
VF Loss                      281.373
Policy Loss                  -628.7963
Q Predictions Mean           629.47656
Q Predictions Std            682.29254
Q Predictions Max            1816.6157
Q Predictions Min            15.625192
V Predictions Mean           629.7422
V Predictions Std            672.1506
V Predictions Max            1819.2249
V Predictions Min            27.042345
Log Pis Mean                 -6.247574
Log Pis Std                  6.181583
Log Pis Max                  13.167095
Log Pis Min                  -13.983601
Policy mu Mean               0.2308666
Policy mu Std                0.6316705
Policy mu Max                2.197192
Policy mu Min                -2.298717
Policy log std Mean          -0.24350531
Policy log std Std           0.14885916
Policy log std Max           -0.056101985
Policy log std Min           -0.74291366
Z mean eval                  0.061699796
Z variance eval              0.0888738
total_rewards                [ 674.41676142 1548.83736603  581.36055875  779.10687732  747.99066528
 1047.87213931  762.63584363  492.21210136  598.63970938 1250.64954908]
total_rewards_mean           848.3721571570708
total_rewards_std            317.0608213485451
total_rewards_max            1548.8373660343777
total_rewards_min            492.21210136039343
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               29.478402095846832
(Previous) Eval Time (s)     4.093935553915799
Sample Time (s)              16.308544875588268
Epoch Time (s)               49.8808825253509
Total Train Time (s)         5755.71411463758
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:51:37.533615 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #118 | Epoch Duration: 50.8963840007782
2020-01-10 19:51:37.533875 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062008716
Z variance train             0.08887803
KL Divergence                3.8723788
KL Loss                      0.38723788
QF Loss                      1187.9003
VF Loss                      339.71832
Policy Loss                  -652.08734
Q Predictions Mean           639.05835
Q Predictions Std            700.4651
Q Predictions Max            1809.2456
Q Predictions Min            17.824976
V Predictions Mean           647.93024
V Predictions Std            699.2851
V Predictions Max            1830.353
V Predictions Min            24.590063
Log Pis Mean                 -6.1984944
Log Pis Std                  6.177597
Log Pis Max                  11.012258
Log Pis Min                  -14.483406
Policy mu Mean               0.23401165
Policy mu Std                0.63034946
Policy mu Max                2.35633
Policy mu Min                -2.6943736
Policy log std Mean          -0.24514583
Policy log std Std           0.15201072
Policy log std Max           -0.053169206
Policy log std Min           -0.7792633
Z mean eval                  0.058020372
Z variance eval              0.08466556
total_rewards                [ 773.28924211  514.11600626  665.93749324  545.45777455 1280.37054369
  808.92752535  923.06374278 1504.08832899  760.70153926  734.76300853]
total_rewards_mean           851.0715204753609
total_rewards_std            297.7659272850329
total_rewards_max            1504.0883289922544
total_rewards_min            514.1160062600491
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               29.435001477599144
(Previous) Eval Time (s)     5.109130760654807
Sample Time (s)              16.74820353090763
Epoch Time (s)               51.29233576916158
Total Train Time (s)         5806.886795778759
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:52:28.709323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #119 | Epoch Duration: 51.17522573471069
2020-01-10 19:52:28.709579 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05813829
Z variance train             0.084678635
KL Divergence                3.9736934
KL Loss                      0.39736935
QF Loss                      840.50024
VF Loss                      208.35895
Policy Loss                  -572.38086
Q Predictions Mean           566.1007
Q Predictions Std            681.7896
Q Predictions Max            1835.3525
Q Predictions Min            16.132076
V Predictions Mean           577.90137
V Predictions Std            682.5042
V Predictions Max            1834.4347
V Predictions Min            27.405518
Log Pis Mean                 -6.6873
Log Pis Std                  6.300193
Log Pis Max                  16.726612
Log Pis Min                  -13.686106
Policy mu Mean               0.2063105
Policy mu Std                0.60697895
Policy mu Max                2.2900257
Policy mu Min                -2.411013
Policy log std Mean          -0.22820479
Policy log std Std           0.14346598
Policy log std Max           -0.07309347
Policy log std Min           -0.82347757
Z mean eval                  0.052480698
Z variance eval              0.08348994
total_rewards                [2152.40243143 1548.25429502  560.97157856 1005.73715778 3024.65173636
 1444.50824896  898.88861474  927.9314092   588.58993826  727.15308248]
total_rewards_mean           1287.908849279333
total_rewards_std            744.875913230429
total_rewards_max            3024.651736359746
total_rewards_min            560.9715785585596
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               29.181339436210692
(Previous) Eval Time (s)     4.991708172019571
Sample Time (s)              17.66205171169713
Epoch Time (s)               51.835099319927394
Total Train Time (s)         5861.69132839283
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:53:23.515090 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #120 | Epoch Duration: 54.8053092956543
2020-01-10 19:53:23.515337 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052448142
Z variance train             0.083511874
KL Divergence                4.0022354
KL Loss                      0.40022355
QF Loss                      1783.1947
VF Loss                      290.23962
Policy Loss                  -710.10913
Q Predictions Mean           699.8346
Q Predictions Std            697.0663
Q Predictions Max            1827.2382
Q Predictions Min            15.128986
V Predictions Mean           707.4336
V Predictions Std            695.139
V Predictions Max            1845.0992
V Predictions Min            24.101906
Log Pis Mean                 -5.383744
Log Pis Std                  6.5345974
Log Pis Max                  19.675447
Log Pis Min                  -14.287443
Policy mu Mean               0.2510813
Policy mu Std                0.66856
Policy mu Max                2.1748161
Policy mu Min                -2.1680639
Policy log std Mean          -0.25689209
Policy log std Std           0.15210472
Policy log std Max           -0.031368062
Policy log std Min           -0.83998364
Z mean eval                  0.05339852
Z variance eval              0.084503934
total_rewards                [1459.14625075  721.0552659  1495.61862855 1826.01649203  886.56466668
 1007.06999856  758.45756592  832.92173486  694.34489955  736.53230744]
total_rewards_mean           1041.7727810236393
total_rewards_std            382.24763979879657
total_rewards_max            1826.016492027927
total_rewards_min            694.3448995504696
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               28.570401578210294
(Previous) Eval Time (s)     7.961630459874868
Sample Time (s)              18.592409945093095
Epoch Time (s)               55.12444198317826
Total Train Time (s)         5915.076804067474
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:54:16.901888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #121 | Epoch Duration: 53.386364459991455
2020-01-10 19:54:16.902093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05342067
Z variance train             0.08451833
KL Divergence                3.9732041
KL Loss                      0.39732042
QF Loss                      860.0832
VF Loss                      373.44547
Policy Loss                  -606.6092
Q Predictions Mean           595.916
Q Predictions Std            700.7488
Q Predictions Max            1822.0831
Q Predictions Min            14.530637
V Predictions Mean           600.98206
V Predictions Std            697.181
V Predictions Max            1814.9547
V Predictions Min            26.245882
Log Pis Mean                 -6.5082827
Log Pis Std                  6.1109905
Log Pis Max                  9.215873
Log Pis Min                  -12.950298
Policy mu Mean               0.24372031
Policy mu Std                0.6172361
Policy mu Max                2.1284876
Policy mu Min                -2.1962497
Policy log std Mean          -0.23708007
Policy log std Std           0.14865965
Policy log std Max           -0.030476823
Policy log std Min           -0.77097356
Z mean eval                  0.052585106
Z variance eval              0.079855666
total_rewards                [1418.62874361  881.55112142  363.65558621 1203.43691887  742.83368013
 1442.98004655 1016.92403608 1558.22675226 1322.45574368  979.71152435]
total_rewards_mean           1093.0404153163468
total_rewards_std            350.38471177188734
total_rewards_max            1558.2267522586728
total_rewards_min            363.6555862140411
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               28.82170864380896
(Previous) Eval Time (s)     6.223241825122386
Sample Time (s)              18.559669078327715
Epoch Time (s)               53.60461954725906
Total Train Time (s)         5968.67931650253
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:55:10.508126 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #122 | Epoch Duration: 53.60586953163147
2020-01-10 19:55:10.508366 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05273086
Z variance train             0.079816215
KL Divergence                4.1066303
KL Loss                      0.41066304
QF Loss                      1060.0898
VF Loss                      266.096
Policy Loss                  -561.88855
Q Predictions Mean           554.9138
Q Predictions Std            689.0946
Q Predictions Max            1843.2532
Q Predictions Min            15.146368
V Predictions Mean           557.6776
V Predictions Std            677.65875
V Predictions Max            1837.4044
V Predictions Min            28.64676
Log Pis Mean                 -6.852813
Log Pis Std                  5.890943
Log Pis Max                  9.08453
Log Pis Min                  -13.560209
Policy mu Mean               0.23990788
Policy mu Std                0.58788306
Policy mu Max                2.5208948
Policy mu Min                -2.1243546
Policy log std Mean          -0.23456761
Policy log std Std           0.146469
Policy log std Max           -0.08411555
Policy log std Min           -0.8377891
Z mean eval                  0.05306811
Z variance eval              0.07999178
total_rewards                [1219.9248495  1000.51601497  627.06175671 2023.08248582  869.68896225
 1263.25975559 1113.75219094  859.62897367  930.18361056  522.88316249]
total_rewards_mean           1042.998176249584
total_rewards_std            395.86671197743937
total_rewards_max            2023.0824858207936
total_rewards_min            522.8831624875635
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               29.3509532478638
(Previous) Eval Time (s)     6.224158457946032
Sample Time (s)              18.02846524026245
Epoch Time (s)               53.60357694607228
Total Train Time (s)         6022.164527430665
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:56:03.994043 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #123 | Epoch Duration: 53.4854793548584
2020-01-10 19:56:03.994261 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #123 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053129088
Z variance train             0.080012485
KL Divergence                4.102104
KL Loss                      0.41021043
QF Loss                      1234.295
VF Loss                      281.38287
Policy Loss                  -695.06464
Q Predictions Mean           686.84576
Q Predictions Std            699.27496
Q Predictions Max            1843.4845
Q Predictions Min            16.037323
V Predictions Mean           698.69415
V Predictions Std            700.83966
V Predictions Max            1847.6825
V Predictions Min            25.284441
Log Pis Mean                 -5.7081046
Log Pis Std                  6.4000998
Log Pis Max                  15.035889
Log Pis Min                  -13.752399
Policy mu Mean               0.24269177
Policy mu Std                0.65158224
Policy mu Max                2.4148648
Policy mu Min                -2.9516354
Policy log std Mean          -0.2470946
Policy log std Std           0.14788648
Policy log std Max           -0.008434877
Policy log std Min           -0.8163954
Z mean eval                  0.050496142
Z variance eval              0.07895823
total_rewards                [ 999.52478121 1280.60118421 1172.98753623  701.94852154  558.1871401
  768.02476457  830.00961952  588.44199595  678.00930684  696.78509783]
total_rewards_mean           827.4519947998027
total_rewards_std            232.9535570661109
total_rewards_max            1280.6011842121957
total_rewards_min            558.1871400969973
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               30.7356523796916
(Previous) Eval Time (s)     6.105768384877592
Sample Time (s)              18.727060948032886
Epoch Time (s)               55.56848171260208
Total Train Time (s)         6076.649323506281
Epoch                        124
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:56:58.481513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #124 | Epoch Duration: 54.48701500892639
2020-01-10 19:56:58.481819 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050130196
Z variance train             0.07896353
KL Divergence                4.130799
KL Loss                      0.4130799
QF Loss                      773.18555
VF Loss                      288.78812
Policy Loss                  -608.28125
Q Predictions Mean           600.8898
Q Predictions Std            710.76624
Q Predictions Max            1844.9589
Q Predictions Min            16.16882
V Predictions Mean           603.558
V Predictions Std            701.66895
V Predictions Max            1846.7025
V Predictions Min            27.480019
Log Pis Mean                 -6.6850424
Log Pis Std                  6.1086845
Log Pis Max                  10.761111
Log Pis Min                  -14.611896
Policy mu Mean               0.21936665
Policy mu Std                0.59953964
Policy mu Max                2.5334337
Policy mu Min                -2.3853471
Policy log std Mean          -0.23138297
Policy log std Std           0.14488311
Policy log std Max           -0.07050805
Policy log std Min           -0.78993225
Z mean eval                  0.049146555
Z variance eval              0.07932913
total_rewards                [2185.08174734  897.12107953  484.78519039  712.66863655 2218.72509013
  942.5495248   684.55881833  459.56132836  691.45365988 1333.28775343]
total_rewards_mean           1060.979282874972
total_rewards_std            617.4361321731899
total_rewards_max            2218.7250901295856
total_rewards_min            459.56132835880095
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               29.973064777906984
(Previous) Eval Time (s)     5.024006125982851
Sample Time (s)              18.450793168041855
Epoch Time (s)               53.44786407193169
Total Train Time (s)         6131.65892726602
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:57:53.493254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #125 | Epoch Duration: 55.011253356933594
2020-01-10 19:57:53.493466 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049161755
Z variance train             0.07932834
KL Divergence                4.0966716
KL Loss                      0.40966716
QF Loss                      781.0619
VF Loss                      276.34543
Policy Loss                  -681.0696
Q Predictions Mean           671.88336
Q Predictions Std            725.9967
Q Predictions Max            1863.3363
Q Predictions Min            16.831661
V Predictions Mean           675.18756
V Predictions Std            719.8128
V Predictions Max            1858.3813
V Predictions Min            27.281776
Log Pis Mean                 -6.0851
Log Pis Std                  6.1479645
Log Pis Max                  11.468126
Log Pis Min                  -14.560292
Policy mu Mean               0.18784212
Policy mu Std                0.6597629
Policy mu Max                2.5573034
Policy mu Min                -2.6824913
Policy log std Mean          -0.24354121
Policy log std Std           0.14900047
Policy log std Max           -0.041615985
Policy log std Min           -0.8198621
Z mean eval                  0.044696607
Z variance eval              0.08100006
total_rewards                [1005.31213317 1280.37009691  684.94203512  973.44302158  676.80408482
 1835.18639348 1030.09033075  920.46552134  639.41426025  603.53012198]
total_rewards_mean           964.9557999394121
total_rewards_std            355.35263575755044
total_rewards_max            1835.1863934822543
total_rewards_min            603.5301219757863
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               29.440406229812652
(Previous) Eval Time (s)     6.5870716399513185
Sample Time (s)              17.763929625041783
Epoch Time (s)               53.79140749480575
Total Train Time (s)         6184.5872665103525
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:58:46.422916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #126 | Epoch Duration: 52.929285764694214
2020-01-10 19:58:46.423138 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044678926
Z variance train             0.08100779
KL Divergence                4.0576525
KL Loss                      0.40576527
QF Loss                      829.60925
VF Loss                      330.21375
Policy Loss                  -708.1453
Q Predictions Mean           700.7417
Q Predictions Std            715.8694
Q Predictions Max            1862.6879
Q Predictions Min            15.511472
V Predictions Mean           705.568
V Predictions Std            709.41534
V Predictions Max            1875.3229
V Predictions Min            24.185585
Log Pis Mean                 -5.851516
Log Pis Std                  6.301472
Log Pis Max                  13.553543
Log Pis Min                  -13.528417
Policy mu Mean               0.24029331
Policy mu Std                0.6570752
Policy mu Max                2.5175116
Policy mu Min                -2.2319016
Policy log std Mean          -0.25172126
Policy log std Std           0.15210219
Policy log std Max           -0.059667885
Policy log std Min           -0.8403343
Z mean eval                  0.045956872
Z variance eval              0.07968919
total_rewards                [2151.84750293 1248.58359295  656.45302232 1828.01142629  774.93490096
  578.29780336  830.26902381  734.00186464  912.95804333 1700.77764047]
total_rewards_mean           1141.6134821060239
total_rewards_std            530.8810031297357
total_rewards_max            2151.8475029326482
total_rewards_min            578.2978033575711
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               29.632669256068766
(Previous) Eval Time (s)     5.724651925265789
Sample Time (s)              18.34745584987104
Epoch Time (s)               53.704777031205595
Total Train Time (s)         6239.281945460476
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 19:59:41.119020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #127 | Epoch Duration: 54.69571876525879
2020-01-10 19:59:41.119214 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #127 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046027638
Z variance train             0.07969178
KL Divergence                4.1141233
KL Loss                      0.41141233
QF Loss                      1242.9583
VF Loss                      467.7934
Policy Loss                  -719.2179
Q Predictions Mean           709.06116
Q Predictions Std            741.43726
Q Predictions Max            1868.4491
Q Predictions Min            17.775805
V Predictions Mean           723.0152
V Predictions Std            743.0699
V Predictions Max            1872.5936
V Predictions Min            28.368683
Log Pis Mean                 -5.656287
Log Pis Std                  6.9612527
Log Pis Max                  20.424452
Log Pis Min                  -14.187653
Policy mu Mean               0.2797548
Policy mu Std                0.6735869
Policy mu Max                2.7717116
Policy mu Min                -2.8481975
Policy log std Mean          -0.2563727
Policy log std Std           0.1543456
Policy log std Max           -0.05356726
Policy log std Min           -0.8111422
Z mean eval                  0.045661904
Z variance eval              0.07796587
total_rewards                [1195.08772699 1214.74586999  962.78892345 1018.22306441 1299.4177501
 1511.89723797  620.16582475  937.93874054 1451.04196489 3432.10790741]
total_rewards_mean           1364.3415010501021
total_rewards_std            733.2699066258731
total_rewards_max            3432.1079074114236
total_rewards_min            620.1658247546135
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               29.377211935818195
(Previous) Eval Time (s)     6.715292289387435
Sample Time (s)              17.461507672443986
Epoch Time (s)               53.554011897649616
Total Train Time (s)         6294.596420743503
Epoch                        128
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:00:36.435860 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #128 | Epoch Duration: 55.31643199920654
2020-01-10 20:00:36.436093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04593741
Z variance train             0.07797885
KL Divergence                4.14795
KL Loss                      0.414795
QF Loss                      928.7538
VF Loss                      424.79208
Policy Loss                  -640.3641
Q Predictions Mean           629.09314
Q Predictions Std            721.81696
Q Predictions Max            1886.5105
Q Predictions Min            16.806293
V Predictions Mean           633.5265
V Predictions Std            714.859
V Predictions Max            1873.795
V Predictions Min            26.591534
Log Pis Mean                 -6.2328997
Log Pis Std                  6.5378785
Log Pis Max                  14.9376955
Log Pis Min                  -15.682207
Policy mu Mean               0.21507594
Policy mu Std                0.63429457
Policy mu Max                2.366396
Policy mu Min                -2.417121
Policy log std Mean          -0.24387096
Policy log std Std           0.1518742
Policy log std Max           -0.04279244
Policy log std Min           -0.7774774
Z mean eval                  0.044474162
Z variance eval              0.07618626
total_rewards                [ 560.32563295 1864.85262945  917.08279558 1044.77408607 1188.60915842
  966.86337141  807.05228229 2780.23320842  772.46677236 1158.44056399]
total_rewards_mean           1206.0700500943851
total_rewards_std            620.1225908425018
total_rewards_max            2780.2332084199493
total_rewards_min            560.3256329535683
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               30.383901475928724
(Previous) Eval Time (s)     8.477438502013683
Sample Time (s)              19.16843366343528
Epoch Time (s)               58.02977364137769
Total Train Time (s)         6351.112454016227
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:01:32.956616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #129 | Epoch Duration: 56.52031993865967
2020-01-10 20:01:32.956935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044601064
Z variance train             0.07617487
KL Divergence                4.2135324
KL Loss                      0.42135325
QF Loss                      1107.04
VF Loss                      436.0867
Policy Loss                  -753.38086
Q Predictions Mean           744.74365
Q Predictions Std            753.2691
Q Predictions Max            1882.927
Q Predictions Min            16.977545
V Predictions Mean           757.6898
V Predictions Std            754.0006
V Predictions Max            1904.4117
V Predictions Min            30.02235
Log Pis Mean                 -5.563938
Log Pis Std                  6.618018
Log Pis Max                  11.563185
Log Pis Min                  -13.777894
Policy mu Mean               0.24361286
Policy mu Std                0.66330194
Policy mu Max                2.228711
Policy mu Min                -2.4418814
Policy log std Mean          -0.25333253
Policy log std Std           0.15218033
Policy log std Max           -0.05573956
Policy log std Min           -0.8041079
Z mean eval                  0.043852977
Z variance eval              0.07571353
total_rewards                [1048.35877804 1260.05694384  555.23921306 1637.25539272  901.97752044
 1196.13370204  550.97269966  717.4797564   659.22650207 1313.55920504]
total_rewards_mean           984.0259713299495
total_rewards_std            348.6099646749031
total_rewards_max            1637.2553927152685
total_rewards_min            550.972699655105
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               30.03333900682628
(Previous) Eval Time (s)     6.967649010941386
Sample Time (s)              17.712196587584913
Epoch Time (s)               54.71318460535258
Total Train Time (s)         6404.819737305399
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:02:26.665144 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #130 | Epoch Duration: 53.70795655250549
2020-01-10 20:02:26.665410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043872677
Z variance train             0.07572128
KL Divergence                4.2151303
KL Loss                      0.42151305
QF Loss                      1549.7751
VF Loss                      686.57446
Policy Loss                  -686.5461
Q Predictions Mean           676.39966
Q Predictions Std            742.2037
Q Predictions Max            1897.8313
Q Predictions Min            16.0276
V Predictions Mean           674.0183
V Predictions Std            730.1392
V Predictions Max            1889.5409
V Predictions Min            25.823074
Log Pis Mean                 -5.7673697
Log Pis Std                  6.265822
Log Pis Max                  11.521034
Log Pis Min                  -13.109542
Policy mu Mean               0.24343294
Policy mu Std                0.644453
Policy mu Max                2.3448672
Policy mu Min                -2.8111699
Policy log std Mean          -0.24435027
Policy log std Std           0.14885397
Policy log std Max           0.054727063
Policy log std Min           -0.777859
Z mean eval                  0.044617943
Z variance eval              0.075152636
total_rewards                [1048.88576447  736.12705493  389.35189895 1513.81632492  932.17286414
  942.56344371  561.65944421  763.17575712 1051.86346676  741.60683797]
total_rewards_mean           868.122285717006
total_rewards_std            293.35716141469595
total_rewards_max            1513.816324922396
total_rewards_min            389.35189894570044
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               30.221008902881294
(Previous) Eval Time (s)     5.962110390421003
Sample Time (s)              18.185721646994352
Epoch Time (s)               54.36884094029665
Total Train Time (s)         6458.5948939062655
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:03:20.441645 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #131 | Epoch Duration: 53.77604866027832
2020-01-10 20:03:20.441819 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043940138
Z variance train             0.07515599
KL Divergence                4.255366
KL Loss                      0.4255366
QF Loss                      1472.803
VF Loss                      658.4097
Policy Loss                  -738.40283
Q Predictions Mean           730.3777
Q Predictions Std            756.06323
Q Predictions Max            1904.2714
Q Predictions Min            17.205702
V Predictions Mean           737.8516
V Predictions Std            756.9128
V Predictions Max            1913.6774
V Predictions Min            26.522957
Log Pis Mean                 -5.397064
Log Pis Std                  6.873315
Log Pis Max                  17.735256
Log Pis Min                  -13.35359
Policy mu Mean               0.24024801
Policy mu Std                0.6781064
Policy mu Max                2.4605181
Policy mu Min                -2.6785414
Policy log std Mean          -0.25525278
Policy log std Std           0.1587908
Policy log std Max           -0.05510144
Policy log std Min           -0.8417462
Z mean eval                  0.041675434
Z variance eval              0.072774105
total_rewards                [1173.58254371 1971.32164276 1028.94209104 1924.98780737 2188.96334435
  898.31400366 2552.73176354 1814.0112933   901.65528069  850.12921602]
total_rewards_mean           1530.4638986429777
total_rewards_std            595.4674105977642
total_rewards_max            2552.7317635365625
total_rewards_min            850.1292160180186
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               32.73431638814509
(Previous) Eval Time (s)     5.369018587749451
Sample Time (s)              17.622606061864644
Epoch Time (s)               55.725941037759185
Total Train Time (s)         6518.931753893383
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:04:20.780692 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #132 | Epoch Duration: 60.33871912956238
2020-01-10 20:04:20.780901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041815933
Z variance train             0.07278056
KL Divergence                4.309789
KL Loss                      0.43097892
QF Loss                      921.84283
VF Loss                      297.12183
Policy Loss                  -775.53143
Q Predictions Mean           766.75793
Q Predictions Std            763.2933
Q Predictions Max            1912.2323
Q Predictions Min            13.627495
V Predictions Mean           775.49194
V Predictions Std            760.0106
V Predictions Max            1900.5802
V Predictions Min            27.083483
Log Pis Mean                 -5.6557875
Log Pis Std                  6.3212643
Log Pis Max                  16.367327
Log Pis Min                  -12.53951
Policy mu Mean               0.24526052
Policy mu Std                0.6667184
Policy mu Max                2.260893
Policy mu Min                -2.4828336
Policy log std Mean          -0.2539477
Policy log std Std           0.15451199
Policy log std Max           -0.015771054
Policy log std Min           -0.7761258
Z mean eval                  0.041056883
Z variance eval              0.07299688
total_rewards                [1506.72075138  609.11977186  749.06829529 1675.01869361  816.88002112
 1138.15377565 1204.38848001  544.26633134 1021.16694319 1305.04777516]
total_rewards_mean           1056.9830838610037
total_rewards_std            359.34508704647715
total_rewards_max            1675.0186936131577
total_rewards_min            544.2663313373309
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               33.64587543811649
(Previous) Eval Time (s)     9.981491434853524
Sample Time (s)              18.17554415203631
Epoch Time (s)               61.802911025006324
Total Train Time (s)         6577.260328265373
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:05:19.111464 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #133 | Epoch Duration: 58.3304078578949
2020-01-10 20:05:19.111638 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040911935
Z variance train             0.072975405
KL Divergence                4.2884207
KL Loss                      0.42884207
QF Loss                      859.96246
VF Loss                      272.18265
Policy Loss                  -753.6578
Q Predictions Mean           745.1042
Q Predictions Std            745.8652
Q Predictions Max            1920.2765
Q Predictions Min            15.645634
V Predictions Mean           759.50574
V Predictions Std            749.3552
V Predictions Max            1931.356
V Predictions Min            26.877626
Log Pis Mean                 -5.278556
Log Pis Std                  6.5982633
Log Pis Max                  17.639107
Log Pis Min                  -14.072407
Policy mu Mean               0.2302241
Policy mu Std                0.68456614
Policy mu Max                2.941588
Policy mu Min                -2.8856387
Policy log std Mean          -0.25732484
Policy log std Std           0.15566766
Policy log std Max           -0.061148964
Policy log std Min           -0.87129426
Z mean eval                  0.03657046
Z variance eval              0.07421291
total_rewards                [ 877.16374979  976.88380466 1198.52536738  669.26810568 1073.98651014
 1924.36815629  839.78470253 1573.8660821  1277.21817702  732.83895226]
total_rewards_mean           1114.3903607852876
total_rewards_std            373.7263866455124
total_rewards_max            1924.368156294083
total_rewards_min            669.2681056846296
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               30.212511277291924
(Previous) Eval Time (s)     6.508685092907399
Sample Time (s)              17.742167880292982
Epoch Time (s)               54.463364250492305
Total Train Time (s)         6631.67248412827
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:06:13.526827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #134 | Epoch Duration: 54.41503572463989
2020-01-10 20:06:13.527048 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036437582
Z variance train             0.07422939
KL Divergence                4.2370815
KL Loss                      0.42370817
QF Loss                      899.0509
VF Loss                      358.2352
Policy Loss                  -738.3476
Q Predictions Mean           728.9749
Q Predictions Std            775.701
Q Predictions Max            1907.0527
Q Predictions Min            15.136856
V Predictions Mean           740.7986
V Predictions Std            779.8589
V Predictions Max            1922.497
V Predictions Min            25.116838
Log Pis Mean                 -5.885681
Log Pis Std                  6.2798004
Log Pis Max                  12.554679
Log Pis Min                  -13.030993
Policy mu Mean               0.2375019
Policy mu Std                0.65168315
Policy mu Max                2.586802
Policy mu Min                -2.3690398
Policy log std Mean          -0.25257474
Policy log std Std           0.15524942
Policy log std Max           0.04827845
Policy log std Min           -0.8493413
Z mean eval                  0.035033725
Z variance eval              0.07340371
total_rewards                [ 614.86391908 1938.29404682 1348.11487652 1017.94414355 1433.87392843
 2174.92217068 1626.54242119  791.63084513 1788.24736423  552.1367946 ]
total_rewards_mean           1328.6570510223953
total_rewards_std            538.2057290613726
total_rewards_max            2174.9221706832764
total_rewards_min            552.1367945998089
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               29.539088860619813
(Previous) Eval Time (s)     6.460038790944964
Sample Time (s)              18.860195657704026
Epoch Time (s)               54.8593233092688
Total Train Time (s)         6688.602691291366
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:07:10.459813 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #135 | Epoch Duration: 56.932559967041016
2020-01-10 20:07:10.460089 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03505411
Z variance train             0.07339892
KL Divergence                4.2598505
KL Loss                      0.42598507
QF Loss                      1226.4939
VF Loss                      226.895
Policy Loss                  -731.96155
Q Predictions Mean           724.8501
Q Predictions Std            767.19336
Q Predictions Max            1909.0591
Q Predictions Min            15.068309
V Predictions Mean           733.6454
V Predictions Std            766.2472
V Predictions Max            1927.2109
V Predictions Min            25.09951
Log Pis Mean                 -5.280695
Log Pis Std                  6.923543
Log Pis Max                  17.579947
Log Pis Min                  -13.272882
Policy mu Mean               0.25085992
Policy mu Std                0.67426395
Policy mu Max                2.9008474
Policy mu Min                -2.4968364
Policy log std Mean          -0.25639623
Policy log std Std           0.157399
Policy log std Max           -0.05160433
Policy log std Min           -0.7925242
Z mean eval                  0.03534832
Z variance eval              0.07343028
total_rewards                [ 614.26404976 2471.88750339  984.03942439  761.41943321  353.22397979
 1125.16647681  793.76208454 1242.64041791  895.13511629 1861.2738762 ]
total_rewards_mean           1110.28123622875
total_rewards_std            594.8936554703034
total_rewards_max            2471.887503386658
total_rewards_min            353.2239797913219
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               30.75570689002052
(Previous) Eval Time (s)     8.532925253733993
Sample Time (s)              19.435499149374664
Epoch Time (s)               58.724131293129176
Total Train Time (s)         6745.300059909467
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:08:07.157699 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #136 | Epoch Duration: 56.69742155075073
2020-01-10 20:08:07.157922 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03535579
Z variance train             0.07344908
KL Divergence                4.2736197
KL Loss                      0.42736197
QF Loss                      1014.94653
VF Loss                      488.7382
Policy Loss                  -644.9063
Q Predictions Mean           639.6162
Q Predictions Std            753.87555
Q Predictions Max            1953.0278
Q Predictions Min            15.393262
V Predictions Mean           640.9621
V Predictions Std            743.9656
V Predictions Max            1934.9971
V Predictions Min            23.335766
Log Pis Mean                 -6.8874655
Log Pis Std                  6.014697
Log Pis Max                  13.211145
Log Pis Min                  -13.553668
Policy mu Mean               0.19692548
Policy mu Std                0.61014336
Policy mu Max                2.401468
Policy mu Min                -2.5410023
Policy log std Mean          -0.23355472
Policy log std Std           0.14755197
Policy log std Max           -0.043489233
Policy log std Min           -0.86337805
Z mean eval                  0.037066758
Z variance eval              0.07176197
total_rewards                [1063.64550133  462.86049834  577.26554033  793.92684844 1224.11990254
 1252.64354133 1402.92320846  913.42550284  587.92577004 1912.93766609]
total_rewards_mean           1019.1673979753457
total_rewards_std            423.93718498732704
total_rewards_max            1912.9376660917726
total_rewards_min            462.86049834025613
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               30.311199880205095
(Previous) Eval Time (s)     6.50588534027338
Sample Time (s)              18.137796123046428
Epoch Time (s)               54.9548813435249
Total Train Time (s)         6799.747405691538
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:09:01.610384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #137 | Epoch Duration: 54.45228862762451
2020-01-10 20:09:01.610683 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037182137
Z variance train             0.07177043
KL Divergence                4.318894
KL Loss                      0.43188938
QF Loss                      1185.6172
VF Loss                      635.4535
Policy Loss                  -766.9065
Q Predictions Mean           759.48157
Q Predictions Std            775.62714
Q Predictions Max            1937.1073
Q Predictions Min            14.731312
V Predictions Mean           771.95544
V Predictions Std            776.5127
V Predictions Max            1944.1234
V Predictions Min            28.002821
Log Pis Mean                 -4.912983
Log Pis Std                  7.170162
Log Pis Max                  18.334072
Log Pis Min                  -13.673217
Policy mu Mean               0.27096394
Policy mu Std                0.67950654
Policy mu Max                2.3330953
Policy mu Min                -2.9184299
Policy log std Mean          -0.25684243
Policy log std Std           0.15794349
Policy log std Max           -0.07046274
Policy log std Min           -0.87274677
Z mean eval                  0.03500054
Z variance eval              0.071565434
total_rewards                [4097.71453484 3103.58323845 1898.44256136 1563.18880084 1764.34719071
  958.65312722 1386.85036956 1315.81072009 2340.61194251 1503.1851327 ]
total_rewards_mean           1993.2387618286211
total_rewards_std            903.6485783372232
total_rewards_max            4097.714534842996
total_rewards_min            958.6531272231449
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               30.828430864959955
(Previous) Eval Time (s)     6.002920250874013
Sample Time (s)              18.12247800268233
Epoch Time (s)               54.953829118516296
Total Train Time (s)         6861.6744098560885
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:10:03.541601 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #138 | Epoch Duration: 61.93067789077759
2020-01-10 20:10:03.541903 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03525027
Z variance train             0.071559325
KL Divergence                4.337258
KL Loss                      0.4337258
QF Loss                      1433.7631
VF Loss                      367.87332
Policy Loss                  -795.04736
Q Predictions Mean           785.2471
Q Predictions Std            777.566
Q Predictions Max            1955.8634
Q Predictions Min            15.769971
V Predictions Mean           788.43164
V Predictions Std            769.6059
V Predictions Max            1939.3916
V Predictions Min            29.158863
Log Pis Mean                 -4.583227
Log Pis Std                  7.3918796
Log Pis Max                  17.88439
Log Pis Min                  -13.475793
Policy mu Mean               0.2340347
Policy mu Std                0.711954
Policy mu Max                2.5614781
Policy mu Min                -3.0574396
Policy log std Mean          -0.26110917
Policy log std Std           0.1596487
Policy log std Max           -0.038501896
Policy log std Min           -0.7739307
Z mean eval                  0.036866613
Z variance eval              0.071829565
total_rewards                [ 819.1660392   564.34994951  352.06206032  658.69685315 1786.6821357
  770.48272257 1449.54386826  863.93734473 1637.97129781 1116.01203016]
total_rewards_mean           1001.8904301406612
total_rewards_std            455.1245356197058
total_rewards_max            1786.6821356986127
total_rewards_min            352.0620603152686
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               31.23234604485333
(Previous) Eval Time (s)     12.979470582213253
Sample Time (s)              19.450811546761543
Epoch Time (s)               63.662628173828125
Total Train Time (s)         6918.501568629406
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:11:00.371178 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #139 | Epoch Duration: 56.8290319442749
2020-01-10 20:11:00.371470 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036986392
Z variance train             0.07183764
KL Divergence                4.32147
KL Loss                      0.432147
QF Loss                      1180.2651
VF Loss                      289.20935
Policy Loss                  -775.8509
Q Predictions Mean           769.8834
Q Predictions Std            816.14886
Q Predictions Max            1970.0103
Q Predictions Min            13.338215
V Predictions Mean           773.911
V Predictions Std            808.07184
V Predictions Max            1958.2383
V Predictions Min            27.372902
Log Pis Mean                 -5.4092956
Log Pis Std                  6.8532753
Log Pis Max                  13.748753
Log Pis Min                  -13.023031
Policy mu Mean               0.2555179
Policy mu Std                0.6502926
Policy mu Max                2.2524922
Policy mu Min                -2.4258118
Policy log std Mean          -0.25352836
Policy log std Std           0.15620735
Policy log std Max           -0.02201476
Policy log std Min           -0.83088326
Z mean eval                  0.037635107
Z variance eval              0.071903676
total_rewards                [ 934.34357494 1035.54400685  567.59674354  818.13203947  848.83676916
  678.27638888  877.77520507 1660.23909079  830.6744777  1420.92478934]
total_rewards_mean           967.2343085738712
total_rewards_std            315.90291880351964
total_rewards_max            1660.2390907896392
total_rewards_min            567.5967435400834
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               26.828109943773597
(Previous) Eval Time (s)     6.145559025928378
Sample Time (s)              17.929350710473955
Epoch Time (s)               50.90301968017593
Total Train Time (s)         6968.924419444054
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:11:50.794958 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #140 | Epoch Duration: 50.42327165603638
2020-01-10 20:11:50.795167 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037586026
Z variance train             0.07187331
KL Divergence                4.3253417
KL Loss                      0.4325342
QF Loss                      1487.4976
VF Loss                      612.0613
Policy Loss                  -756.2658
Q Predictions Mean           750.8413
Q Predictions Std            789.8876
Q Predictions Max            1961.7247
Q Predictions Min            16.502617
V Predictions Mean           767.5434
V Predictions Std            794.47046
V Predictions Max            1988.4253
V Predictions Min            27.075663
Log Pis Mean                 -5.150487
Log Pis Std                  7.267796
Log Pis Max                  22.108175
Log Pis Min                  -13.555801
Policy mu Mean               0.23558412
Policy mu Std                0.6898171
Policy mu Max                3.0470395
Policy mu Min                -2.6154177
Policy log std Mean          -0.2513099
Policy log std Std           0.15719855
Policy log std Max           0.044935048
Policy log std Min           -0.9062541
Z mean eval                  0.037125587
Z variance eval              0.07229094
total_rewards                [3119.31271232  880.05698855 1619.53847306 3760.6396684   959.10634015
 2234.2564959  1305.72400863 1472.45224762 1362.91827325 2755.18850359]
total_rewards_mean           1946.9193711472685
total_rewards_std            927.2758534245111
total_rewards_max            3760.63966840195
total_rewards_min            880.0569885463528
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               31.494269351940602
(Previous) Eval Time (s)     5.6655437969602644
Sample Time (s)              18.304231321439147
Epoch Time (s)               55.46404447034001
Total Train Time (s)         7030.989505250938
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:12:52.864006 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #141 | Epoch Duration: 62.06864070892334
2020-01-10 20:12:52.864321 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0372346
Z variance train             0.07229964
KL Divergence                4.298156
KL Loss                      0.4298156
QF Loss                      984.8795
VF Loss                      344.01605
Policy Loss                  -827.76373
Q Predictions Mean           822.86475
Q Predictions Std            778.4942
Q Predictions Max            1975.7097
Q Predictions Min            14.337363
V Predictions Mean           830.2554
V Predictions Std            777.99915
V Predictions Max            1988.6573
V Predictions Min            26.919924
Log Pis Mean                 -4.4750896
Log Pis Std                  7.1601806
Log Pis Max                  17.553436
Log Pis Min                  -14.163613
Policy mu Mean               0.25784585
Policy mu Std                0.71842337
Policy mu Max                2.5513752
Policy mu Min                -2.3965726
Policy log std Mean          -0.26328927
Policy log std Std           0.16184688
Policy log std Max           -0.018583313
Policy log std Min           -0.96042204
Z mean eval                  0.03535944
Z variance eval              0.069655985
total_rewards                [1075.11981554 1068.83797613 1240.8881456  1524.53339534 1192.97586824
 1334.09706216 2140.92891484 1948.51943352  878.17746947 1179.40909073]
total_rewards_mean           1358.348717155618
total_rewards_std            381.66776025794013
total_rewards_max            2140.9289148351386
total_rewards_min            878.1774694679094
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               29.3945464217104
(Previous) Eval Time (s)     12.269825408235192
Sample Time (s)              18.98232551664114
Epoch Time (s)               60.646697346586734
Total Train Time (s)         7087.658136010636
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:13:49.534713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #142 | Epoch Duration: 56.67015528678894
2020-01-10 20:13:49.534957 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035341054
Z variance train             0.06966807
KL Divergence                4.38151
KL Loss                      0.43815097
QF Loss                      1378.2844
VF Loss                      661.07324
Policy Loss                  -798.79126
Q Predictions Mean           794.0543
Q Predictions Std            795.63416
Q Predictions Max            1981.9811
Q Predictions Min            18.174301
V Predictions Mean           812.85443
V Predictions Std            799.897
V Predictions Max            1999.5878
V Predictions Min            27.566748
Log Pis Mean                 -5.5725365
Log Pis Std                  6.41273
Log Pis Max                  14.603925
Log Pis Min                  -13.682769
Policy mu Mean               0.24176957
Policy mu Std                0.6630635
Policy mu Max                2.1985626
Policy mu Min                -3.1935678
Policy log std Mean          -0.25041732
Policy log std Std           0.14988524
Policy log std Max           -0.028225183
Policy log std Min           -0.8205875
Z mean eval                  0.035407383
Z variance eval              0.06975417
total_rewards                [2316.52640679  723.98851486  924.02301128 1865.47781185 1099.26401299
 1343.54694548 1488.88259708 1270.30552221 1021.12935482 1154.17453306]
total_rewards_mean           1320.7318710417471
total_rewards_std            447.1827912253824
total_rewards_max            2316.526406792023
total_rewards_min            723.9885148620585
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               28.341759735252708
(Previous) Eval Time (s)     8.29297487763688
Sample Time (s)              19.646510053426027
Epoch Time (s)               56.281244666315615
Total Train Time (s)         7143.43027746398
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:14:45.308228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #143 | Epoch Duration: 55.77310585975647
2020-01-10 20:14:45.308437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035246365
Z variance train             0.0697792
KL Divergence                4.382925
KL Loss                      0.4382925
QF Loss                      1403.0671
VF Loss                      548.7315
Policy Loss                  -812.5742
Q Predictions Mean           805.75256
Q Predictions Std            822.0556
Q Predictions Max            2000.9332
Q Predictions Min            15.44367
V Predictions Mean           807.6245
V Predictions Std            813.47577
V Predictions Max            1986.9327
V Predictions Min            28.38718
Log Pis Mean                 -5.4511757
Log Pis Std                  6.9931087
Log Pis Max                  21.434662
Log Pis Min                  -13.962599
Policy mu Mean               0.23075402
Policy mu Std                0.68092763
Policy mu Max                2.8520133
Policy mu Min                -2.5373032
Policy log std Mean          -0.25447133
Policy log std Std           0.16107538
Policy log std Max           -0.05045423
Policy log std Min           -0.88703644
Z mean eval                  0.035838768
Z variance eval              0.06834377
total_rewards                [ 543.62122199 1012.3114512  1078.03172999 1453.01889371  795.93849475
 1825.27168304 2863.19465435 1239.9443326  2125.92587455 2311.65593504]
total_rewards_mean           1524.8914271206966
total_rewards_std            700.3263914440464
total_rewards_max            2863.194654346681
total_rewards_min            543.6212219854027
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               28.391421175096184
(Previous) Eval Time (s)     7.784510727971792
Sample Time (s)              18.212134221568704
Epoch Time (s)               54.38806612463668
Total Train Time (s)         7199.438404024113
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:15:41.321253 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #144 | Epoch Duration: 56.01265263557434
2020-01-10 20:15:41.321585 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03582567
Z variance train             0.06833446
KL Divergence                4.409648
KL Loss                      0.4409648
QF Loss                      1033.4534
VF Loss                      255.12987
Policy Loss                  -877.9879
Q Predictions Mean           875.0631
Q Predictions Std            824.4936
Q Predictions Max            2014.2999
Q Predictions Min            16.61599
V Predictions Mean           880.09705
V Predictions Std            818.82367
V Predictions Max            1987.0043
V Predictions Min            27.740253
Log Pis Mean                 -4.564384
Log Pis Std                  7.000337
Log Pis Max                  14.947648
Log Pis Min                  -15.019312
Policy mu Mean               0.26572832
Policy mu Std                0.7134633
Policy mu Max                2.7664413
Policy mu Min                -2.6926131
Policy log std Mean          -0.27575603
Policy log std Std           0.16608831
Policy log std Max           -0.054202437
Policy log std Min           -0.9277035
Z mean eval                  0.03562316
Z variance eval              0.07018842
total_rewards                [2355.45111387 1262.56046236 1121.88902898 1753.94399461 1196.66716852
 1390.41252911 2599.17621804 1486.31827953 2151.91969169  817.21371026]
total_rewards_mean           1613.555219696079
total_rewards_std            554.1005226442126
total_rewards_max            2599.1762180388782
total_rewards_min            817.213710257403
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               29.548777902964503
(Previous) Eval Time (s)     9.408747131936252
Sample Time (s)              19.10384306125343
Epoch Time (s)               58.06136809615418
Total Train Time (s)         7257.938697618432
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:16:39.822670 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #145 | Epoch Duration: 58.500864028930664
2020-01-10 20:16:39.822880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035676226
Z variance train             0.07019062
KL Divergence                4.351918
KL Loss                      0.43519184
QF Loss                      1578.9229
VF Loss                      463.5412
Policy Loss                  -876.24243
Q Predictions Mean           867.6122
Q Predictions Std            827.21606
Q Predictions Max            2023.713
Q Predictions Min            19.591429
V Predictions Mean           869.3475
V Predictions Std            819.5595
V Predictions Max            2008.2524
V Predictions Min            28.67249
Log Pis Mean                 -4.2266374
Log Pis Std                  7.6345015
Log Pis Max                  17.908747
Log Pis Min                  -12.742495
Policy mu Mean               0.25466034
Policy mu Std                0.7568976
Policy mu Max                2.5794156
Policy mu Min                -2.754119
Policy log std Mean          -0.2737757
Policy log std Std           0.16607483
Policy log std Max           -0.03408184
Policy log std Min           -0.8827286
Z mean eval                  0.033684023
Z variance eval              0.068966284
total_rewards                [ 717.20881781  646.12384533 1809.43027986 1024.62008818  817.99706033
 1292.93801548 1077.57929192 1716.98726705 1859.1091421  1425.0667014 ]
total_rewards_mean           1238.7060509467192
total_rewards_std            429.994672289111
total_rewards_max            1859.1091421041265
total_rewards_min            646.1238453272942
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               31.181528009008616
(Previous) Eval Time (s)     9.84790949523449
Sample Time (s)              19.29134810436517
Epoch Time (s)               60.320785608608276
Total Train Time (s)         7316.298360310961
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:17:38.184781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #146 | Epoch Duration: 58.36173748970032
2020-01-10 20:17:38.185004 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033915095
Z variance train             0.06897712
KL Divergence                4.392834
KL Loss                      0.43928343
QF Loss                      1435.9707
VF Loss                      598.35315
Policy Loss                  -826.0524
Q Predictions Mean           819.7947
Q Predictions Std            803.2006
Q Predictions Max            1995.8275
Q Predictions Min            13.441498
V Predictions Mean           835.2376
V Predictions Std            802.8196
V Predictions Max            2005.0764
V Predictions Min            24.58782
Log Pis Mean                 -5.044426
Log Pis Std                  6.948749
Log Pis Max                  18.999046
Log Pis Min                  -13.390934
Policy mu Mean               0.23388153
Policy mu Std                0.70335907
Policy mu Max                2.6119275
Policy mu Min                -2.625391
Policy log std Mean          -0.26250705
Policy log std Std           0.15929823
Policy log std Max           -0.045541406
Policy log std Min           -0.8737272
Z mean eval                  0.03514383
Z variance eval              0.06907757
total_rewards                [1325.15369199 1472.61853914 1047.8299999  1209.82883594 2087.12273367
 1378.76481604  565.94681176  888.57379488  826.70089321 1041.70288607]
total_rewards_mean           1184.4243002604621
total_rewards_std            399.14585497383024
total_rewards_max            2087.1227336679394
total_rewards_min            565.9468117593992
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               29.307928061578423
(Previous) Eval Time (s)     7.888507903087884
Sample Time (s)              18.369105544872582
Epoch Time (s)               55.56554150953889
Total Train Time (s)         7371.36531662615
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:18:33.252725 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #147 | Epoch Duration: 55.06756925582886
2020-01-10 20:18:33.252879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034877785
Z variance train             0.06904412
KL Divergence                4.4153624
KL Loss                      0.44153625
QF Loss                      1164.6886
VF Loss                      492.4836
Policy Loss                  -844.1597
Q Predictions Mean           841.4729
Q Predictions Std            821.8715
Q Predictions Max            2024.3708
Q Predictions Min            15.104547
V Predictions Mean           842.5908
V Predictions Std            815.3235
V Predictions Max            2024.5824
V Predictions Min            26.022173
Log Pis Mean                 -5.2351937
Log Pis Std                  6.7328463
Log Pis Max                  16.894989
Log Pis Min                  -15.525944
Policy mu Mean               0.2554662
Policy mu Std                0.7041849
Policy mu Max                2.6629145
Policy mu Min                -2.8187973
Policy log std Mean          -0.26826978
Policy log std Std           0.16694753
Policy log std Max           -0.04818462
Policy log std Min           -0.89279896
Z mean eval                  0.03523856
Z variance eval              0.06695466
total_rewards                [ 452.1543781  1378.35157657 1009.97629174 1141.96593498  553.59400552
  841.56712012  936.68196227  736.40580319  856.64605709 1395.47858099]
total_rewards_mean           930.2821710563094
total_rewards_std            298.2879250142251
total_rewards_max            1395.478580988085
total_rewards_min            452.154378097979
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               32.079945819918066
(Previous) Eval Time (s)     7.390214202925563
Sample Time (s)              18.086767819710076
Epoch Time (s)               57.556927842553705
Total Train Time (s)         7427.015191642102
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:19:28.906292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #148 | Epoch Duration: 55.65326714515686
2020-01-10 20:19:28.906530 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035261802
Z variance train             0.06690757
KL Divergence                4.4697495
KL Loss                      0.44697496
QF Loss                      1629.6992
VF Loss                      498.51752
Policy Loss                  -907.8249
Q Predictions Mean           902.25323
Q Predictions Std            839.97076
Q Predictions Max            2032.3345
Q Predictions Min            15.448609
V Predictions Mean           912.5557
V Predictions Std            839.6241
V Predictions Max            2027.037
V Predictions Min            25.796658
Log Pis Mean                 -4.8411684
Log Pis Std                  7.0334625
Log Pis Max                  18.586353
Log Pis Min                  -13.904748
Policy mu Mean               0.23715883
Policy mu Std                0.7238822
Policy mu Max                2.4606905
Policy mu Min                -2.8045201
Policy log std Mean          -0.2772559
Policy log std Std           0.16969961
Policy log std Max           0.0034442842
Policy log std Min           -0.8055001
Z mean eval                  0.034282364
Z variance eval              0.064399734
total_rewards                [4978.75377472 1074.76736494 1969.98114102 1858.69409974 1277.56069868
 1765.33839607  539.37844119 1739.01238953 4004.87206773 1517.66091247]
total_rewards_mean           2072.6019286088067
total_rewards_std            1293.3624803188313
total_rewards_max            4978.7537747166725
total_rewards_min            539.378441193064
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               31.0397896762006
(Previous) Eval Time (s)     5.48622857267037
Sample Time (s)              18.99842408299446
Epoch Time (s)               55.52444233186543
Total Train Time (s)         7489.686620832887
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:20:31.577945 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #149 | Epoch Duration: 62.67123532295227
2020-01-10 20:20:31.578098 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034352377
Z variance train             0.06440076
KL Divergence                4.554348
KL Loss                      0.4554348
QF Loss                      1037.2352
VF Loss                      870.02277
Policy Loss                  -748.92804
Q Predictions Mean           739.88446
Q Predictions Std            822.0834
Q Predictions Max            2032.0496
Q Predictions Min            16.1029
V Predictions Mean           750.2782
V Predictions Std            821.32745
V Predictions Max            2029.0028
V Predictions Min            27.412493
Log Pis Mean                 -5.8932877
Log Pis Std                  6.561278
Log Pis Max                  18.275093
Log Pis Min                  -13.190204
Policy mu Mean               0.2446831
Policy mu Std                0.6573297
Policy mu Max                2.6405923
Policy mu Min                -3.4344876
Policy log std Mean          -0.24669425
Policy log std Std           0.15332256
Policy log std Max           -0.029676951
Policy log std Min           -0.8431938
Z mean eval                  0.035393275
Z variance eval              0.06521252
total_rewards                [1773.55262902 1266.42896639 1179.67702436  981.89641909  688.49356504
 2171.9600547  2934.8485518   929.11842821 2020.10340682 2779.96494745]
total_rewards_mean           1672.6043992867212
total_rewards_std            748.7381903243947
total_rewards_max            2934.8485517955255
total_rewards_min            688.4935650353225
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               30.53308603586629
(Previous) Eval Time (s)     12.632692839950323
Sample Time (s)              18.146012344863266
Epoch Time (s)               61.31179122067988
Total Train Time (s)         7548.66249633953
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:21:30.557144 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #150 | Epoch Duration: 58.9789023399353
2020-01-10 20:21:30.557338 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035432957
Z variance train             0.065177515
KL Divergence                4.526952
KL Loss                      0.4526952
QF Loss                      2116.8413
VF Loss                      867.7871
Policy Loss                  -738.1142
Q Predictions Mean           729.681
Q Predictions Std            784.77277
Q Predictions Max            2055.1396
Q Predictions Min            15.119546
V Predictions Mean           745.4968
V Predictions Std            788.039
V Predictions Max            2030.9524
V Predictions Min            24.891735
Log Pis Mean                 -5.150299
Log Pis Std                  7.3356857
Log Pis Max                  23.75356
Log Pis Min                  -12.945562
Policy mu Mean               0.1946327
Policy mu Std                0.7114063
Policy mu Max                2.8001156
Policy mu Min                -2.782471
Policy log std Mean          -0.26387027
Policy log std Std           0.16427751
Policy log std Max           -0.012212679
Policy log std Min           -0.9552017
Z mean eval                  0.035054415
Z variance eval              0.0642457
total_rewards                [1370.51397675 2218.08768112 1302.47862134 1504.27757895 2073.12673528
 2313.43178549 3654.25099097 1743.85931113 1551.69283845  914.43200351]
total_rewards_mean           1864.6151522981158
total_rewards_std            726.4970540855328
total_rewards_max            3654.250990967439
total_rewards_min            914.4320035091681
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               27.715290745720267
(Previous) Eval Time (s)     10.299474556930363
Sample Time (s)              18.673646301496774
Epoch Time (s)               56.688411604147404
Total Train Time (s)         7606.057791810483
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:22:27.953891 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #151 | Epoch Duration: 57.39640951156616
2020-01-10 20:22:27.954092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034978148
Z variance train             0.06425418
KL Divergence                4.5663404
KL Loss                      0.45663404
QF Loss                      1208.8905
VF Loss                      664.8878
Policy Loss                  -943.54034
Q Predictions Mean           931.9538
Q Predictions Std            847.3447
Q Predictions Max            2061.059
Q Predictions Min            16.392529
V Predictions Mean           933.0667
V Predictions Std            837.89905
V Predictions Max            2046.9941
V Predictions Min            24.423931
Log Pis Mean                 -4.4553356
Log Pis Std                  7.1614757
Log Pis Max                  21.376266
Log Pis Min                  -16.393112
Policy mu Mean               0.2663189
Policy mu Std                0.71670467
Policy mu Max                2.5911572
Policy mu Min                -2.7052476
Policy log std Mean          -0.2794912
Policy log std Std           0.16862422
Policy log std Max           0.034848884
Policy log std Min           -0.9288389
Z mean eval                  0.031048274
Z variance eval              0.0644558
total_rewards                [2143.94333688 1181.42877024 2119.90528218 1117.28304827 1096.06668036
 1732.35797362 2481.33868236 1429.56556199 1069.62718743 1321.52577666]
total_rewards_mean           1569.3042299988279
total_rewards_std            490.0089275689303
total_rewards_max            2481.3386823550695
total_rewards_min            1069.6271874300353
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               30.811701458878815
(Previous) Eval Time (s)     11.00718175014481
Sample Time (s)              19.449690759181976
Epoch Time (s)               61.2685739682056
Total Train Time (s)         7665.8783623767085
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:23:27.779069 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #152 | Epoch Duration: 59.824803590774536
2020-01-10 20:23:27.779342 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031098615
Z variance train             0.06445937
KL Divergence                4.573895
KL Loss                      0.4573895
QF Loss                      1591.2175
VF Loss                      462.15494
Policy Loss                  -897.38275
Q Predictions Mean           888.0648
Q Predictions Std            832.4733
Q Predictions Max            2043.5913
Q Predictions Min            16.145039
V Predictions Mean           893.9797
V Predictions Std            829.5032
V Predictions Max            2038.1572
V Predictions Min            25.77217
Log Pis Mean                 -4.647893
Log Pis Std                  7.0795918
Log Pis Max                  20.736933
Log Pis Min                  -14.314436
Policy mu Mean               0.24183683
Policy mu Std                0.7276579
Policy mu Max                3.0143638
Policy mu Min                -2.6976523
Policy log std Mean          -0.27253672
Policy log std Std           0.1651027
Policy log std Max           -0.028975047
Policy log std Min           -0.9369832
Z mean eval                  0.03213852
Z variance eval              0.06526528
total_rewards                [3612.34960801 1062.55849209 4064.00051809 1587.96789032 1359.80141639
 2256.01948169 1892.44719549 2453.4521825  1425.19758807 2210.51898629]
total_rewards_mean           2192.4313358953723
total_rewards_std            927.6497718618104
total_rewards_max            4064.000518093331
total_rewards_min            1062.5584920899894
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               30.684279548935592
(Previous) Eval Time (s)     9.563055540900677
Sample Time (s)              18.977285417728126
Epoch Time (s)               59.224620507564396
Total Train Time (s)         7729.104183244519
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:24:31.005029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #153 | Epoch Duration: 63.22549223899841
2020-01-10 20:24:31.005198 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #153 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0323209
Z variance train             0.06524616
KL Divergence                4.5419054
KL Loss                      0.45419055
QF Loss                      947.1791
VF Loss                      410.9711
Policy Loss                  -841.50543
Q Predictions Mean           834.37836
Q Predictions Std            840.5975
Q Predictions Max            2055.3203
Q Predictions Min            17.280865
V Predictions Mean           843.1918
V Predictions Std            841.0215
V Predictions Max            2061.5134
V Predictions Min            28.22217
Log Pis Mean                 -5.065077
Log Pis Std                  7.22255
Log Pis Max                  22.369934
Log Pis Min                  -15.354989
Policy mu Mean               0.2359773
Policy mu Std                0.7103107
Policy mu Max                2.702932
Policy mu Min                -3.828039
Policy log std Mean          -0.26676914
Policy log std Std           0.16006929
Policy log std Max           -0.059901096
Policy log std Min           -0.7922279
Z mean eval                  0.030849915
Z variance eval              0.06588049
total_rewards                [ 973.72610191  982.48847559 1056.23629425 4908.9068876  2424.92497326
  625.11709585 1576.04398236 1002.78690663  632.84090616 4929.85764489]
total_rewards_mean           1911.2929268501325
total_rewards_std            1583.0519347016773
total_rewards_max            4929.857644889301
total_rewards_min            625.117095849917
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               29.42088347999379
(Previous) Eval Time (s)     13.563595452811569
Sample Time (s)              18.92417359771207
Epoch Time (s)               61.90865253051743
Total Train Time (s)         7788.918307143729
Epoch                        154
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:25:30.820407 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #154 | Epoch Duration: 59.815083265304565
2020-01-10 20:25:30.820591 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030708084
Z variance train             0.06589402
KL Divergence                4.5192804
KL Loss                      0.45192805
QF Loss                      1687.4844
VF Loss                      404.1734
Policy Loss                  -871.5986
Q Predictions Mean           863.50977
Q Predictions Std            837.7221
Q Predictions Max            2069.229
Q Predictions Min            14.435888
V Predictions Mean           874.9791
V Predictions Std            836.34247
V Predictions Max            2072.2744
V Predictions Min            28.346798
Log Pis Mean                 -4.4793615
Log Pis Std                  7.38007
Log Pis Max                  20.649763
Log Pis Min                  -14.636772
Policy mu Mean               0.23575856
Policy mu Std                0.72163975
Policy mu Max                2.8799314
Policy mu Min                -2.868363
Policy log std Mean          -0.26665014
Policy log std Std           0.16239372
Policy log std Max           -0.05191326
Policy log std Min           -0.843796
Z mean eval                  0.03263221
Z variance eval              0.066682376
total_rewards                [1215.12015029 1379.95963631 3241.35256738 1239.80287959 4136.36852329
 2051.33063363 1848.85429527  723.1060202   898.97617805 2227.67018082]
total_rewards_mean           1896.2541064816219
total_rewards_std            1024.4904057127433
total_rewards_max            4136.36852328736
total_rewards_min            723.1060201996432
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               28.5908275982365
(Previous) Eval Time (s)     11.469718744046986
Sample Time (s)              19.094761430751532
Epoch Time (s)               59.15530777303502
Total Train Time (s)         7847.835874528624
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:26:29.742525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #155 | Epoch Duration: 58.921788930892944
2020-01-10 20:26:29.742779 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03270852
Z variance train             0.06668749
KL Divergence                4.503337
KL Loss                      0.45033368
QF Loss                      1148.0789
VF Loss                      377.48422
Policy Loss                  -912.31274
Q Predictions Mean           908.49475
Q Predictions Std            841.28925
Q Predictions Max            2071.552
Q Predictions Min            17.723522
V Predictions Mean           912.55334
V Predictions Std            835.4189
V Predictions Max            2074.7725
V Predictions Min            28.296179
Log Pis Mean                 -3.872551
Log Pis Std                  7.3917565
Log Pis Max                  28.656021
Log Pis Min                  -12.606259
Policy mu Mean               0.2792863
Policy mu Std                0.7473039
Policy mu Max                2.9602003
Policy mu Min                -3.1781828
Policy log std Mean          -0.28288502
Policy log std Std           0.1705206
Policy log std Max           -0.027275376
Policy log std Min           -0.8304714
Z mean eval                  0.03165979
Z variance eval              0.066048786
total_rewards                [ 801.77332284 1985.74867124 1287.78382634 1038.26260498 1016.63234836
 1936.59924239 1238.07475429  687.5899989   806.75645992  505.49399227]
total_rewards_mean           1130.4715221534118
total_rewards_std            473.1493702659582
total_rewards_max            1985.7486712390719
total_rewards_min            505.49399227430956
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               29.18125886283815
(Previous) Eval Time (s)     11.23582197772339
Sample Time (s)              18.399876076728106
Epoch Time (s)               58.816956917289644
Total Train Time (s)         7902.263584100641
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:27:24.172592 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #156 | Epoch Duration: 54.42960834503174
2020-01-10 20:27:24.172826 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #156 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031667646
Z variance train             0.06602927
KL Divergence                4.4912443
KL Loss                      0.44912443
QF Loss                      1180.6575
VF Loss                      392.48947
Policy Loss                  -915.5771
Q Predictions Mean           910.8113
Q Predictions Std            865.8359
Q Predictions Max            2073.3147
Q Predictions Min            15.737384
V Predictions Mean           914.47687
V Predictions Std            862.34143
V Predictions Max            2066.9404
V Predictions Min            26.861547
Log Pis Mean                 -4.465926
Log Pis Std                  7.3136706
Log Pis Max                  16.597595
Log Pis Min                  -14.759158
Policy mu Mean               0.22556995
Policy mu Std                0.73184204
Policy mu Max                2.4498847
Policy mu Min                -2.4721367
Policy log std Mean          -0.27527452
Policy log std Std           0.16718148
Policy log std Max           -0.08229819
Policy log std Min           -0.88266057
Z mean eval                  0.03126305
Z variance eval              0.06859911
total_rewards                [2910.08609064  400.88121471 1507.48668965  936.23585519 2195.1929587
 2509.54403988 1168.07563896 1406.47656313 2233.02352847  768.02427956]
total_rewards_mean           1603.5026858904482
total_rewards_std            781.1317219523895
total_rewards_max            2910.086090636151
total_rewards_min            400.88121471400194
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               30.412847386673093
(Previous) Eval Time (s)     6.848197241779417
Sample Time (s)              19.21028873929754
Epoch Time (s)               56.47133336775005
Total Train Time (s)         7961.241881957278
Epoch                        157
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:28:23.155379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #157 | Epoch Duration: 58.98234438896179
2020-01-10 20:28:23.155690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03133298
Z variance train             0.06854442
KL Divergence                4.401528
KL Loss                      0.4401528
QF Loss                      1538.3319
VF Loss                      804.7046
Policy Loss                  -838.16473
Q Predictions Mean           830.73676
Q Predictions Std            852.6001
Q Predictions Max            2082.6553
Q Predictions Min            17.34243
V Predictions Mean           825.7773
V Predictions Std            840.0432
V Predictions Max            2054.2837
V Predictions Min            26.188562
Log Pis Mean                 -5.5735493
Log Pis Std                  6.6837964
Log Pis Max                  18.48571
Log Pis Min                  -13.210118
Policy mu Mean               0.23774894
Policy mu Std                0.6817684
Policy mu Max                2.372854
Policy mu Min                -2.7327845
Policy log std Mean          -0.25692904
Policy log std Std           0.15796681
Policy log std Max           -0.060302675
Policy log std Min           -0.8550329
Z mean eval                  0.03174346
Z variance eval              0.06867932
total_rewards                [1160.64697621 1766.1066356  1658.19188481 1937.77925882 1196.66362171
  579.74247439 1510.78288595  962.2574695  1482.73566941 3062.57883252]
total_rewards_mean           1531.7485708915842
total_rewards_std            637.3923193099076
total_rewards_max            3062.578832524825
total_rewards_min            579.7424743868119
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               30.83744539413601
(Previous) Eval Time (s)     9.358889567200094
Sample Time (s)              18.07798546133563
Epoch Time (s)               58.274320422671735
Total Train Time (s)         8019.0171181089245
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:29:20.932490 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #158 | Epoch Duration: 57.77654671669006
2020-01-10 20:29:20.932714 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031601273
Z variance train             0.06866474
KL Divergence                4.3975773
KL Loss                      0.43975773
QF Loss                      1313.9602
VF Loss                      414.37076
Policy Loss                  -894.71545
Q Predictions Mean           892.42236
Q Predictions Std            859.277
Q Predictions Max            2079.4702
Q Predictions Min            16.679195
V Predictions Mean           893.1888
V Predictions Std            851.4385
V Predictions Max            2075.8608
V Predictions Min            25.089397
Log Pis Mean                 -4.72808
Log Pis Std                  6.9659348
Log Pis Max                  16.787994
Log Pis Min                  -15.492394
Policy mu Mean               0.24621212
Policy mu Std                0.7121695
Policy mu Max                2.985907
Policy mu Min                -2.4639895
Policy log std Mean          -0.2724423
Policy log std Std           0.16868193
Policy log std Max           0.006594941
Policy log std Min           -0.92719626
Z mean eval                  0.03217522
Z variance eval              0.06657338
total_rewards                [1013.92381279 1106.38768866 1021.74104183 2114.46777973  606.21193888
 1590.15348933 1434.66458743 1142.68614702 1755.48336474 4943.61910323]
total_rewards_mean           1672.9338953625133
total_rewards_std            1164.5236196162275
total_rewards_max            4943.619103227818
total_rewards_min            606.2119388755112
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               29.959326812066138
(Previous) Eval Time (s)     8.860854378901422
Sample Time (s)              19.182359338272363
Epoch Time (s)               58.00254052923992
Total Train Time (s)         8078.03471539868
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:30:19.953263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #159 | Epoch Duration: 59.02036786079407
2020-01-10 20:30:19.953492 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031916466
Z variance train             0.06658074
KL Divergence                4.4629683
KL Loss                      0.44629684
QF Loss                      1905.6339
VF Loss                      584.1171
Policy Loss                  -862.8893
Q Predictions Mean           856.5419
Q Predictions Std            846.5857
Q Predictions Max            2088.059
Q Predictions Min            14.238593
V Predictions Mean           868.9308
V Predictions Std            844.3758
V Predictions Max            2087.5256
V Predictions Min            26.065655
Log Pis Mean                 -4.9938507
Log Pis Std                  7.3401656
Log Pis Max                  23.349846
Log Pis Min                  -13.731112
Policy mu Mean               0.24804194
Policy mu Std                0.70225114
Policy mu Max                2.570414
Policy mu Min                -3.2707634
Policy log std Mean          -0.25859246
Policy log std Std           0.15713894
Policy log std Max           -0.058444604
Policy log std Min           -0.8889476
Z mean eval                  0.032445617
Z variance eval              0.06497843
total_rewards                [ 929.78987797 1565.60995064 2941.95802435 1761.73146469 1009.58229951
 1348.66972279 1639.84826596 2048.30491279 3131.81340619 1717.8871854 ]
total_rewards_mean           1809.519511028807
total_rewards_std            693.7624436525048
total_rewards_max            3131.8134061923224
total_rewards_min            929.7898779656632
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               31.756944031920284
(Previous) Eval Time (s)     9.878328058868647
Sample Time (s)              19.637614319566637
Epoch Time (s)               61.27288641035557
Total Train Time (s)         8140.020271338522
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:31:21.940545 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #160 | Epoch Duration: 61.986881494522095
2020-01-10 20:31:21.940744 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #160 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032066427
Z variance train             0.06497042
KL Divergence                4.520313
KL Loss                      0.45203128
QF Loss                      1583.9597
VF Loss                      307.11804
Policy Loss                  -911.382
Q Predictions Mean           909.5014
Q Predictions Std            860.06104
Q Predictions Max            2110.7178
Q Predictions Min            14.707416
V Predictions Mean           916.3186
V Predictions Std            856.15405
V Predictions Max            2105.4724
V Predictions Min            28.641659
Log Pis Mean                 -4.861906
Log Pis Std                  6.5431957
Log Pis Max                  16.240425
Log Pis Min                  -13.18697
Policy mu Mean               0.21988226
Policy mu Std                0.7088386
Policy mu Max                2.343788
Policy mu Min                -2.7465706
Policy log std Mean          -0.2713931
Policy log std Std           0.16454266
Policy log std Max           -0.021938227
Policy log std Min           -0.9087824
Z mean eval                  0.03336564
Z variance eval              0.06402376
total_rewards                [2772.96635286 2736.00720106 4947.7853637  1699.2783292  1300.8408834
 1193.097189   4687.86545095  912.49051268 3577.57500493 2725.44578938]
total_rewards_mean           2655.3352077162776
total_rewards_std            1348.5785474080558
total_rewards_max            4947.785363695824
total_rewards_min            912.4905126808698
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               28.706157551147044
(Previous) Eval Time (s)     10.592025553341955
Sample Time (s)              18.338398369029164
Epoch Time (s)               57.63658147351816
Total Train Time (s)         8203.409367159009
Epoch                        161
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:32:25.333032 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #161 | Epoch Duration: 63.392125606536865
2020-01-10 20:32:25.333263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033513553
Z variance train             0.0639996
KL Divergence                4.5523505
KL Loss                      0.45523506
QF Loss                      1456.5254
VF Loss                      449.21487
Policy Loss                  -861.1816
Q Predictions Mean           851.74
Q Predictions Std            856.27325
Q Predictions Max            2108.3218
Q Predictions Min            12.909324
V Predictions Mean           856.0377
V Predictions Std            851.29504
V Predictions Max            2093.994
V Predictions Min            22.57032
Log Pis Mean                 -5.019525
Log Pis Std                  7.0836153
Log Pis Max                  16.102448
Log Pis Min                  -14.226097
Policy mu Mean               0.21646206
Policy mu Std                0.6975024
Policy mu Max                2.6453524
Policy mu Min                -2.4977376
Policy log std Mean          -0.27044398
Policy log std Std           0.1678144
Policy log std Max           -0.014214188
Policy log std Min           -0.84629893
Z mean eval                  0.034150485
Z variance eval              0.06679324
total_rewards                [1652.54271717  889.51527155 1339.69147278 1377.80138928 3368.39606686
 1413.55426402 1220.19247942 2516.89099194 1809.88540974 3021.74201107]
total_rewards_mean           1861.0212073821992
total_rewards_std            784.58224987749
total_rewards_max            3368.3960668603722
total_rewards_min            889.5152715467727
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               30.367212005890906
(Previous) Eval Time (s)     16.34726141579449
Sample Time (s)              19.00199487619102
Epoch Time (s)               65.71646829787642
Total Train Time (s)         8264.30437753722
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:33:26.228710 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #162 | Epoch Duration: 60.89528465270996
2020-01-10 20:33:26.228947 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033731136
Z variance train             0.06681069
KL Divergence                4.454277
KL Loss                      0.44542772
QF Loss                      1751.2227
VF Loss                      547.4901
Policy Loss                  -985.4497
Q Predictions Mean           979.8476
Q Predictions Std            855.37213
Q Predictions Max            2099.0652
Q Predictions Min            14.277159
V Predictions Mean           995.44244
V Predictions Std            859.6181
V Predictions Max            2110.4001
V Predictions Min            26.09215
Log Pis Mean                 -4.238066
Log Pis Std                  7.163249
Log Pis Max                  15.491269
Log Pis Min                  -16.145891
Policy mu Mean               0.22487208
Policy mu Std                0.7709795
Policy mu Max                2.7706456
Policy mu Min                -3.2001872
Policy log std Mean          -0.2807551
Policy log std Std           0.16478202
Policy log std Max           -0.022955403
Policy log std Min           -0.830262
Z mean eval                  0.034926347
Z variance eval              0.063461
total_rewards                [2177.10271291 1966.00800957  857.28290445  748.17507508  554.72716162
 1842.07898861 3452.71401862 1818.96753857 5032.92397988 4006.46189653]
total_rewards_mean           2245.644228584662
total_rewards_std            1406.5346979102287
total_rewards_max            5032.923979884155
total_rewards_min            554.7271616155737
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               32.19267912907526
(Previous) Eval Time (s)     11.52576954383403
Sample Time (s)              18.30684640072286
Epoch Time (s)               62.02529507363215
Total Train Time (s)         8328.202467984054
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:34:30.130402 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #163 | Epoch Duration: 63.901283740997314
2020-01-10 20:34:30.130662 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03472348
Z variance train             0.06346644
KL Divergence                4.5819187
KL Loss                      0.45819187
QF Loss                      1507.5427
VF Loss                      600.30133
Policy Loss                  -940.0254
Q Predictions Mean           933.8259
Q Predictions Std            882.38696
Q Predictions Max            2095.5176
Q Predictions Min            16.108189
V Predictions Mean           944.2693
V Predictions Std            884.2677
V Predictions Max            2112.9336
V Predictions Min            26.933744
Log Pis Mean                 -4.4197245
Log Pis Std                  7.7021623
Log Pis Max                  20.96985
Log Pis Min                  -15.714471
Policy mu Mean               0.23966293
Policy mu Std                0.73170704
Policy mu Max                2.956918
Policy mu Min                -3.3030648
Policy log std Mean          -0.2792015
Policy log std Std           0.17199862
Policy log std Max           -0.009037547
Policy log std Min           -0.86530566
Z mean eval                  0.034539774
Z variance eval              0.06322025
total_rewards                [2079.8559687   955.95387499 1408.71353602 1623.72081674 2145.79805565
  792.77050405 1161.12358904  599.29309238  679.85586628 3146.51784084]
total_rewards_mean           1459.3603144683814
total_rewards_std            765.9203348541387
total_rewards_max            3146.517840836818
total_rewards_min            599.293092375597
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               30.629673975985497
(Previous) Eval Time (s)     13.401403126772493
Sample Time (s)              18.89428985817358
Epoch Time (s)               62.92536696093157
Total Train Time (s)         8387.092379022855
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:35:29.024039 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #164 | Epoch Duration: 58.893176317214966
2020-01-10 20:35:29.024291 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034986265
Z variance train             0.063204974
KL Divergence                4.603547
KL Loss                      0.46035472
QF Loss                      1455.189
VF Loss                      671.65894
Policy Loss                  -967.949
Q Predictions Mean           957.7465
Q Predictions Std            885.4033
Q Predictions Max            2124.8096
Q Predictions Min            14.494929
V Predictions Mean           953.04767
V Predictions Std            868.9099
V Predictions Max            2099.0327
V Predictions Min            26.222609
Log Pis Mean                 -4.182412
Log Pis Std                  7.7960634
Log Pis Max                  23.300629
Log Pis Min                  -13.719095
Policy mu Mean               0.22692214
Policy mu Std                0.7627699
Policy mu Max                3.0096684
Policy mu Min                -3.1473858
Policy log std Mean          -0.28265345
Policy log std Std           0.16880482
Policy log std Max           0.04129602
Policy log std Min           -0.9907776
Z mean eval                  0.035371672
Z variance eval              0.06267838
total_rewards                [ 879.7049445   864.18543974  502.78837094 1874.70977455 1224.15865343
  891.11829671 2505.08859067 1711.65621253  928.92941727 3879.22798844]
total_rewards_mean           1526.1567688788268
total_rewards_std            969.8297288450362
total_rewards_max            3879.227988442135
total_rewards_min            502.78837094030774
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               31.08094642870128
(Previous) Eval Time (s)     9.368919835891575
Sample Time (s)              19.325312288943678
Epoch Time (s)               59.775178553536534
Total Train Time (s)         8446.659907245077
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:36:28.594526 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #165 | Epoch Duration: 59.57003355026245
2020-01-10 20:36:28.594781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03563713
Z variance train             0.06266312
KL Divergence                4.623762
KL Loss                      0.4623762
QF Loss                      1470.0469
VF Loss                      566.45374
Policy Loss                  -1014.9216
Q Predictions Mean           1007.10046
Q Predictions Std            896.6086
Q Predictions Max            2112.731
Q Predictions Min            14.68309
V Predictions Mean           1003.1279
V Predictions Std            885.3177
V Predictions Max            2108.6877
V Predictions Min            26.856966
Log Pis Mean                 -4.630645
Log Pis Std                  6.378707
Log Pis Max                  13.179247
Log Pis Min                  -12.561796
Policy mu Mean               0.25838235
Policy mu Std                0.72601825
Policy mu Max                2.548395
Policy mu Min                -2.3872044
Policy log std Mean          -0.27887097
Policy log std Std           0.16293497
Policy log std Max           -0.01642491
Policy log std Min           -0.89018446
Z mean eval                  0.035499435
Z variance eval              0.05999726
total_rewards                [3356.23104226  900.24002849 2212.50086189  506.7035752  1431.29153903
 1786.669111   1157.99325492 1899.24026342 1937.41547983  676.97615317]
total_rewards_mean           1586.526130921699
total_rewards_std            803.5356399038857
total_rewards_max            3356.231042264264
total_rewards_min            506.7035751955253
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               31.285903666634113
(Previous) Eval Time (s)     9.163445875048637
Sample Time (s)              19.82502804044634
Epoch Time (s)               60.27437758212909
Total Train Time (s)         8507.102569940034
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:37:29.037992 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #166 | Epoch Duration: 60.443033933639526
2020-01-10 20:37:29.038153 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035476428
Z variance train             0.059999555
KL Divergence                4.7310953
KL Loss                      0.47310954
QF Loss                      1540.6768
VF Loss                      456.39206
Policy Loss                  -991.83246
Q Predictions Mean           986.4163
Q Predictions Std            888.06647
Q Predictions Max            2124.2668
Q Predictions Min            16.519613
V Predictions Mean           991.53925
V Predictions Std            884.10803
V Predictions Max            2126.308
V Predictions Min            27.33948
Log Pis Mean                 -4.8258767
Log Pis Std                  6.5771413
Log Pis Max                  15.521692
Log Pis Min                  -13.745633
Policy mu Mean               0.25474668
Policy mu Std                0.7049807
Policy mu Max                2.7122262
Policy mu Min                -2.473259
Policy log std Mean          -0.2730508
Policy log std Std           0.16050707
Policy log std Max           -0.02493371
Policy log std Min           -0.85685575
Z mean eval                  0.03654869
Z variance eval              0.06070295
total_rewards                [4950.07896212  724.5330925  2196.41466837  618.43919506  537.64571666
  712.76473199 1681.7170509   580.5379191   971.82596097 3164.6924037 ]
total_rewards_mean           1613.8649701371226
total_rewards_std            1382.4380511064471
total_rewards_max            4950.078962117999
total_rewards_min            537.6457166586761
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               33.72959906980395
(Previous) Eval Time (s)     9.331737066153437
Sample Time (s)              19.939028116874397
Epoch Time (s)               63.00036425283179
Total Train Time (s)         8570.906634467654
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:38:32.843444 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #167 | Epoch Duration: 63.8051643371582
2020-01-10 20:38:32.843698 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03556905
Z variance train             0.060699712
KL Divergence                4.7221193
KL Loss                      0.47221193
QF Loss                      1096.3485
VF Loss                      650.10156
Policy Loss                  -825.88873
Q Predictions Mean           821.5148
Q Predictions Std            895.25543
Q Predictions Max            2118.084
Q Predictions Min            17.896568
V Predictions Mean           838.0124
V Predictions Std            902.3166
V Predictions Max            2150.8164
V Predictions Min            27.817999
Log Pis Mean                 -6.219237
Log Pis Std                  6.4227524
Log Pis Max                  13.240643
Log Pis Min                  -15.698792
Policy mu Mean               0.20278156
Policy mu Std                0.63857615
Policy mu Max                2.5481334
Policy mu Min                -2.6283932
Policy log std Mean          -0.24798073
Policy log std Std           0.1508837
Policy log std Max           -0.06835291
Policy log std Min           -0.8426931
Z mean eval                  0.035579056
Z variance eval              0.058649242
total_rewards                [1312.3728116   710.58162879 1233.82896539 4700.70325427  876.45015339
 1053.94872415 3097.34148686 1055.32691686 1855.87858822 1407.79261844]
total_rewards_mean           1730.4225147966185
total_rewards_std            1179.616472167914
total_rewards_max            4700.703254265072
total_rewards_min            710.5816287867881
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               29.315327988006175
(Previous) Eval Time (s)     10.13619240699336
Sample Time (s)              18.636565032880753
Epoch Time (s)               58.08808542788029
Total Train Time (s)         8628.908436718863
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:39:30.847499 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #168 | Epoch Duration: 58.00367212295532
2020-01-10 20:39:30.847671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035529263
Z variance train             0.058625203
KL Divergence                4.785776
KL Loss                      0.4785776
QF Loss                      1002.8343
VF Loss                      521.3291
Policy Loss                  -964.4682
Q Predictions Mean           953.5361
Q Predictions Std            877.0832
Q Predictions Max            2115.624
Q Predictions Min            16.99143
V Predictions Mean           971.8702
V Predictions Std            884.31915
V Predictions Max            2140.2524
V Predictions Min            28.601974
Log Pis Mean                 -4.7352543
Log Pis Std                  7.0471153
Log Pis Max                  18.298397
Log Pis Min                  -13.955519
Policy mu Mean               0.24080305
Policy mu Std                0.7108653
Policy mu Max                2.8347945
Policy mu Min                -3.1658983
Policy log std Mean          -0.2701412
Policy log std Std           0.16632657
Policy log std Max           -0.05116182
Policy log std Min           -0.9177153
Z mean eval                  0.03622938
Z variance eval              0.056237943
total_rewards                [ 404.73474757 2296.97700287 1897.19432105 2504.16166976 1223.85829691
 1780.56064075 3984.81643416 4846.82985151  504.52302437 3267.87084803]
total_rewards_mean           2271.152683699612
total_rewards_std            1367.5163879195513
total_rewards_max            4846.829851513747
total_rewards_min            404.7347475734161
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               31.313270152080804
(Previous) Eval Time (s)     10.051411373075098
Sample Time (s)              19.0422430629842
Epoch Time (s)               60.4069245881401
Total Train Time (s)         8692.78613604838
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:40:34.726677 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #169 | Epoch Duration: 63.87886953353882
2020-01-10 20:40:34.726883 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036603905
Z variance train             0.056234963
KL Divergence                4.878684
KL Loss                      0.4878684
QF Loss                      3036.044
VF Loss                      701.9221
Policy Loss                  -1026.9437
Q Predictions Mean           1021.07745
Q Predictions Std            892.8756
Q Predictions Max            2141.8586
Q Predictions Min            17.106258
V Predictions Mean           1015.2745
V Predictions Std            879.0018
V Predictions Max            2127.7686
V Predictions Min            25.001474
Log Pis Mean                 -4.6038733
Log Pis Std                  6.7327666
Log Pis Max                  14.417679
Log Pis Min                  -14.495519
Policy mu Mean               0.23985386
Policy mu Std                0.74910843
Policy mu Max                2.8891404
Policy mu Min                -2.6676888
Policy log std Mean          -0.28143692
Policy log std Std           0.17092252
Policy log std Max           -0.003592506
Policy log std Min           -1.0953944
Z mean eval                  0.034608345
Z variance eval              0.05720576
total_rewards                [2002.89752101 5085.34501512  710.67961415 1782.68542537 3725.50780706
  676.10140442 5023.729895    892.8438961  3415.78247511  943.14728947]
total_rewards_mean           2425.8720342797337
total_rewards_std            1662.391786322584
total_rewards_max            5085.345015119542
total_rewards_min            676.1014044232649
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               29.546120672952384
(Previous) Eval Time (s)     13.523034281097353
Sample Time (s)              19.236594325862825
Epoch Time (s)               62.30574927991256
Total Train Time (s)         8755.762042833492
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:41:37.704428 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #170 | Epoch Duration: 62.97742581367493
2020-01-10 20:41:37.704583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034677118
Z variance train             0.05720082
KL Divergence                4.8350363
KL Loss                      0.48350364
QF Loss                      1304.3606
VF Loss                      481.72742
Policy Loss                  -1031.547
Q Predictions Mean           1023.60394
Q Predictions Std            892.1948
Q Predictions Max            2134.2139
Q Predictions Min            16.86392
V Predictions Mean           1028.3085
V Predictions Std            887.93695
V Predictions Max            2119.752
V Predictions Min            28.048319
Log Pis Mean                 -3.7591403
Log Pis Std                  7.3349156
Log Pis Max                  22.066093
Log Pis Min                  -13.210235
Policy mu Mean               0.2826666
Policy mu Std                0.7514107
Policy mu Max                2.736985
Policy mu Min                -2.751478
Policy log std Mean          -0.28869596
Policy log std Std           0.1724318
Policy log std Max           -0.033563226
Policy log std Min           -0.93444896
Z mean eval                  0.03645461
Z variance eval              0.05732618
total_rewards                [1957.15675553 4910.21800137 3580.40022188 2587.68491714 2934.33334099
 3610.72060939 3250.06891842 1385.72455663 2916.28572541 2982.49831012]
total_rewards_mean           3011.5091356878265
total_rewards_std            910.7702356328865
total_rewards_max            4910.2180013687075
total_rewards_min            1385.7245566290433
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               29.98495283117518
(Previous) Eval Time (s)     14.194359759800136
Sample Time (s)              19.029257743619382
Epoch Time (s)               63.2085703345947
Total Train Time (s)         8823.031737315934
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:42:44.977855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #171 | Epoch Duration: 67.27312302589417
2020-01-10 20:42:44.978055 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #171 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036711156
Z variance train             0.057343453
KL Divergence                4.8452373
KL Loss                      0.48452374
QF Loss                      1784.1191
VF Loss                      504.1974
Policy Loss                  -1035.8195
Q Predictions Mean           1025.114
Q Predictions Std            917.1044
Q Predictions Max            2144.132
Q Predictions Min            17.322647
V Predictions Mean           1028.743
V Predictions Std            911.81213
V Predictions Max            2142.5256
V Predictions Min            26.340998
Log Pis Mean                 -4.4188213
Log Pis Std                  7.268119
Log Pis Max                  19.801624
Log Pis Min                  -13.503855
Policy mu Mean               0.25084338
Policy mu Std                0.72483236
Policy mu Max                2.4972079
Policy mu Min                -2.874135
Policy log std Mean          -0.27847028
Policy log std Std           0.16691563
Policy log std Max           -0.04050138
Policy log std Min           -0.8518942
Z mean eval                  0.037823886
Z variance eval              0.055317976
total_rewards                [3071.28169532 4944.14326406 1817.51834535 3359.9809919  1133.7216502
  929.08567236 1508.02687126 3823.2277828  1817.22410094 2108.14961845]
total_rewards_mean           2451.2359992658244
total_rewards_std            1231.7032420761475
total_rewards_max            4944.143264060193
total_rewards_min            929.0856723630899
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               31.060454783029854
(Previous) Eval Time (s)     18.258563328068703
Sample Time (s)              20.15225371159613
Epoch Time (s)               69.47127182269469
Total Train Time (s)         8888.935756671242
Epoch                        172
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:43:50.882501 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #172 | Epoch Duration: 65.90429830551147
2020-01-10 20:43:50.882654 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037854373
Z variance train             0.05531607
KL Divergence                4.9210668
KL Loss                      0.49210668
QF Loss                      1379.5298
VF Loss                      379.2578
Policy Loss                  -1060.8934
Q Predictions Mean           1056.7485
Q Predictions Std            920.0717
Q Predictions Max            2153.2678
Q Predictions Min            15.890201
V Predictions Mean           1059.7217
V Predictions Std            912.12964
V Predictions Max            2144.3389
V Predictions Min            25.692823
Log Pis Mean                 -5.138942
Log Pis Std                  6.4463973
Log Pis Max                  16.412498
Log Pis Min                  -13.34101
Policy mu Mean               0.23136644
Policy mu Std                0.70409226
Policy mu Max                2.5401099
Policy mu Min                -2.5576158
Policy log std Mean          -0.2785342
Policy log std Std           0.1657426
Policy log std Max           -0.07212192
Policy log std Min           -0.8813806
Z mean eval                  0.036955617
Z variance eval              0.05530156
total_rewards                [ 958.41575414 5039.38399721 2122.34948764 5029.98789734 1763.39355278
 3178.89013197 1260.58810032 1941.85419999 2024.96746499 4468.10899481]
total_rewards_mean           2778.79395811873
total_rewards_std            1467.6992000073071
total_rewards_max            5039.383997207951
total_rewards_min            958.4157541421846
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               29.815601617097855
(Previous) Eval Time (s)     14.69120289804414
Sample Time (s)              18.85100649576634
Epoch Time (s)               63.357811010908335
Total Train Time (s)         8953.885165725835
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:44:55.836830 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #173 | Epoch Duration: 64.95402312278748
2020-01-10 20:44:55.837115 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0368185
Z variance train             0.0553074
KL Divergence                4.9302816
KL Loss                      0.49302816
QF Loss                      1281.4944
VF Loss                      371.7483
Policy Loss                  -998.02295
Q Predictions Mean           989.1136
Q Predictions Std            893.7114
Q Predictions Max            2127.993
Q Predictions Min            14.718544
V Predictions Mean           1005.5449
V Predictions Std            896.31104
V Predictions Max            2151.8118
V Predictions Min            26.04771
Log Pis Mean                 -4.5770826
Log Pis Std                  7.018559
Log Pis Max                  18.802269
Log Pis Min                  -13.108779
Policy mu Mean               0.25413805
Policy mu Std                0.73089594
Policy mu Max                2.533586
Policy mu Min                -2.9084253
Policy log std Mean          -0.27317417
Policy log std Std           0.16617532
Policy log std Max           -0.030958757
Policy log std Min           -0.83555675
Z mean eval                  0.03690244
Z variance eval              0.05564921
total_rewards                [1337.37312071 1265.68663545 3423.78340889 4883.9247864  2117.98255212
  714.02229412 2785.8184949  2846.73917771 4893.94158589 2538.33586792]
total_rewards_mean           2680.7607924086687
total_rewards_std            1354.8047533344125
total_rewards_max            4893.941585885355
total_rewards_min            714.022294115854
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               30.43362140096724
(Previous) Eval Time (s)     16.287098618224263
Sample Time (s)              19.447502365335822
Epoch Time (s)               66.16822238452733
Total Train Time (s)         9019.893953047227
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:46:01.850004 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #174 | Epoch Duration: 66.01264882087708
2020-01-10 20:46:01.850309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036813516
Z variance train             0.055659104
KL Divergence                4.9096713
KL Loss                      0.49096712
QF Loss                      1527.011
VF Loss                      516.38983
Policy Loss                  -952.07764
Q Predictions Mean           949.84845
Q Predictions Std            907.685
Q Predictions Max            2151.309
Q Predictions Min            13.602624
V Predictions Mean           952.56934
V Predictions Std            899.2441
V Predictions Max            2149.9841
V Predictions Min            23.574516
Log Pis Mean                 -4.9033813
Log Pis Std                  7.082966
Log Pis Max                  18.51905
Log Pis Min                  -13.964746
Policy mu Mean               0.21507196
Policy mu Std                0.7225591
Policy mu Max                2.7188027
Policy mu Min                -3.2283068
Policy log std Mean          -0.269821
Policy log std Std           0.16709952
Policy log std Max           -0.012163505
Policy log std Min           -0.94945574
Z mean eval                  0.037485026
Z variance eval              0.056041002
total_rewards                [1500.86125095 2803.91415317 1310.70496283  905.96709158 2083.00474531
  670.29706591  774.41540098 1632.47007846 1104.76925533 1842.70611509]
total_rewards_mean           1462.911011962387
total_rewards_std            626.1886524364894
total_rewards_max            2803.9141531721534
total_rewards_min            670.2970659139277
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               32.144943316001445
(Previous) Eval Time (s)     16.131200041156262
Sample Time (s)              19.131123459897935
Epoch Time (s)               67.40726681705564
Total Train Time (s)         9079.750911362004
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:47:01.724244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #175 | Epoch Duration: 59.873695611953735
2020-01-10 20:47:01.724544 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #175 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037192594
Z variance train             0.056017853
KL Divergence                4.8828917
KL Loss                      0.48828918
QF Loss                      1051.7312
VF Loss                      389.41983
Policy Loss                  -982.41785
Q Predictions Mean           976.10284
Q Predictions Std            929.8504
Q Predictions Max            2159.4058
Q Predictions Min            15.533054
V Predictions Mean           980.9706
V Predictions Std            927.4725
V Predictions Max            2153.1562
V Predictions Min            23.701246
Log Pis Mean                 -5.1757126
Log Pis Std                  6.9053626
Log Pis Max                  19.590027
Log Pis Min                  -12.68718
Policy mu Mean               0.21962857
Policy mu Std                0.6972396
Policy mu Max                3.0505188
Policy mu Min                -3.1429877
Policy log std Mean          -0.2627387
Policy log std Std           0.16213736
Policy log std Max           -0.059851438
Policy log std Min           -0.8270004
Z mean eval                  0.039754458
Z variance eval              0.056943417
total_rewards                [3099.72232215 1680.74373692 2022.29668761 5014.57864442  981.9347859
 3339.48459649 2021.18485178 4989.58551194 1287.63225113 3715.01755331]
total_rewards_mean           2815.2180941638107
total_rewards_std            1377.359393760028
total_rewards_max            5014.57864441804
total_rewards_min            981.934785902091
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               28.31536402227357
(Previous) Eval Time (s)     8.597309589851648
Sample Time (s)              18.934015127830207
Epoch Time (s)               55.846688739955425
Total Train Time (s)         9143.82576554548
Epoch                        176
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:48:05.788817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #176 | Epoch Duration: 64.06407570838928
2020-01-10 20:48:05.789015 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039780743
Z variance train             0.056954004
KL Divergence                4.8243766
KL Loss                      0.48243767
QF Loss                      1736.4467
VF Loss                      453.9156
Policy Loss                  -1043.6077
Q Predictions Mean           1040.3594
Q Predictions Std            897.88873
Q Predictions Max            2171.394
Q Predictions Min            17.33849
V Predictions Mean           1043.3068
V Predictions Std            894.21924
V Predictions Max            2163.5544
V Predictions Min            26.19528
Log Pis Mean                 -4.8231363
Log Pis Std                  6.591215
Log Pis Max                  17.871672
Log Pis Min                  -14.51915
Policy mu Mean               0.27654356
Policy mu Std                0.72309226
Policy mu Max                2.6622264
Policy mu Min                -2.493652
Policy log std Mean          -0.2767818
Policy log std Std           0.16100387
Policy log std Max           -0.023548275
Policy log std Min           -0.92351127
Z mean eval                  0.04135581
Z variance eval              0.055487595
total_rewards                [5128.22987753  929.64358632 1330.37866393 1263.56734123 4660.64644218
 3549.01606068 3075.3798905  1683.43168411 2419.74868058 1429.6228626 ]
total_rewards_mean           2546.966508966022
total_rewards_std            1420.1110478442445
total_rewards_max            5128.22987753487
total_rewards_min            929.6435863188852
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               33.67632210673764
(Previous) Eval Time (s)     16.814414781983942
Sample Time (s)              19.299460073467344
Epoch Time (s)               69.79019696218893
Total Train Time (s)         9211.658115356695
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:49:13.626205 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #177 | Epoch Duration: 67.83702874183655
2020-01-10 20:49:13.626498 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041571736
Z variance train             0.055502106
KL Divergence                4.8913956
KL Loss                      0.48913956
QF Loss                      1825.2269
VF Loss                      537.5379
Policy Loss                  -969.836
Q Predictions Mean           960.46204
Q Predictions Std            878.26526
Q Predictions Max            2164.849
Q Predictions Min            15.40827
V Predictions Mean           964.1564
V Predictions Std            869.9059
V Predictions Max            2158.4543
V Predictions Min            18.747524
Log Pis Mean                 -4.707211
Log Pis Std                  7.0997725
Log Pis Max                  17.86744
Log Pis Min                  -15.669974
Policy mu Mean               0.26075083
Policy mu Std                0.7379732
Policy mu Max                2.811119
Policy mu Min                -3.2796297
Policy log std Mean          -0.28039172
Policy log std Std           0.16643235
Policy log std Max           -0.023747578
Policy log std Min           -0.96200085
Z mean eval                  0.040857762
Z variance eval              0.053408198
total_rewards                [4369.18707902 4963.50540845  827.57728918  608.21746198 3994.58607202
 4990.41510292 4923.78567532 1847.92373417 4936.17600171  753.77935544]
total_rewards_mean           3221.5153180206576
total_rewards_std            1856.147892975165
total_rewards_max            4990.415102915344
total_rewards_min            608.2174619806964
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               30.977295492310077
(Previous) Eval Time (s)     14.860892647877336
Sample Time (s)              19.058709860779345
Epoch Time (s)               64.89689800096676
Total Train Time (s)         9280.850665524602
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:50:22.820666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #178 | Epoch Duration: 69.19394445419312
2020-01-10 20:50:22.820888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04101265
Z variance train             0.053398985
KL Divergence                4.9832935
KL Loss                      0.49832937
QF Loss                      1338.3752
VF Loss                      576.0951
Policy Loss                  -1058.0583
Q Predictions Mean           1049.8037
Q Predictions Std            914.76715
Q Predictions Max            2168.703
Q Predictions Min            12.387477
V Predictions Mean           1048.6138
V Predictions Std            903.929
V Predictions Max            2150.5212
V Predictions Min            26.451973
Log Pis Mean                 -3.8178024
Log Pis Std                  7.4894285
Log Pis Max                  17.352844
Log Pis Min                  -13.225046
Policy mu Mean               0.24857773
Policy mu Std                0.75876147
Policy mu Max                2.7729354
Policy mu Min                -2.662925
Policy log std Mean          -0.28609297
Policy log std Std           0.16361548
Policy log std Max           -0.025855802
Policy log std Min           -0.93515384
Z mean eval                  0.041406166
Z variance eval              0.05390364
total_rewards                [3864.38793654 3322.60623367 1450.20468949 1509.93445881  907.83871423
 1552.36283969 1218.83824278 1161.89023778 1083.26940712 1035.12474578]
total_rewards_mean           1710.6457505902424
total_rewards_std            969.9291794190315
total_rewards_max            3864.387936544497
total_rewards_min            907.8387142346053
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               30.773639659862965
(Previous) Eval Time (s)     19.15761212911457
Sample Time (s)              19.613808108028024
Epoch Time (s)               69.54505989700556
Total Train Time (s)         9341.48766893614
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:51:23.462587 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #179 | Epoch Duration: 60.64150810241699
2020-01-10 20:51:23.462870 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041319117
Z variance train             0.05390083
KL Divergence                4.9562135
KL Loss                      0.49562135
QF Loss                      1784.5615
VF Loss                      489.8689
Policy Loss                  -1127.6543
Q Predictions Mean           1119.8414
Q Predictions Std            910.235
Q Predictions Max            2166.343
Q Predictions Min            16.83186
V Predictions Mean           1132.5281
V Predictions Std            910.14575
V Predictions Max            2177.548
V Predictions Min            23.399843
Log Pis Mean                 -3.4405093
Log Pis Std                  7.421569
Log Pis Max                  24.989515
Log Pis Min                  -13.033765
Policy mu Mean               0.27324036
Policy mu Std                0.7678951
Policy mu Max                2.7641354
Policy mu Min                -2.8527706
Policy log std Mean          -0.29060546
Policy log std Std           0.16199392
Policy log std Max           -0.05702243
Policy log std Min           -0.8828885
Z mean eval                  0.042485334
Z variance eval              0.053511582
total_rewards                [2071.81057561 4329.3634629  5043.18355624 3860.57191447 2272.41898641
 4313.36766979 1567.51975517 1304.27149361 2986.19846866  405.55036663]
total_rewards_mean           2815.4256249488944
total_rewards_std            1453.1487142837077
total_rewards_max            5043.183556237945
total_rewards_min            405.5503666272611
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               28.559020559303463
(Previous) Eval Time (s)     10.253710712306201
Sample Time (s)              18.70992382010445
Epoch Time (s)               57.522655091714114
Total Train Time (s)         9405.987100865692
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:52:27.974251 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #180 | Epoch Duration: 64.51114249229431
2020-01-10 20:52:27.974558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04238381
Z variance train             0.05350659
KL Divergence                4.9770627
KL Loss                      0.49770626
QF Loss                      1275.5051
VF Loss                      552.2252
Policy Loss                  -998.9861
Q Predictions Mean           993.63727
Q Predictions Std            900.4469
Q Predictions Max            2170.3123
Q Predictions Min            16.15212
V Predictions Mean           1004.2293
V Predictions Std            898.97516
V Predictions Max            2175.8613
V Predictions Min            27.442335
Log Pis Mean                 -4.436183
Log Pis Std                  7.2611
Log Pis Max                  16.172935
Log Pis Min                  -15.523791
Policy mu Mean               0.2645173
Policy mu Std                0.7397066
Policy mu Max                2.5714116
Policy mu Min                -2.9440386
Policy log std Mean          -0.28488243
Policy log std Std           0.17095879
Policy log std Max           0.07725942
Policy log std Min           -0.89854676
Z mean eval                  0.044084754
Z variance eval              0.049705096
total_rewards                [1154.45750923 1246.59036035 1452.11919865 5027.99119298 3156.48326098
 3511.90191969 3246.5359597  5064.27924525 2442.93474349  449.41593692]
total_rewards_mean           2675.2709327229772
total_rewards_std            1528.3659955434755
total_rewards_max            5064.279245251326
total_rewards_min            449.41593691860743
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               30.330880464054644
(Previous) Eval Time (s)     17.241906165611
Sample Time (s)              19.07144526997581
Epoch Time (s)               66.64423189964145
Total Train Time (s)         9470.92077281233
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:53:32.899783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #181 | Epoch Duration: 64.92502450942993
2020-01-10 20:53:32.899965 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04378993
Z variance train             0.049693197
KL Divergence                5.152337
KL Loss                      0.5152337
QF Loss                      1822.1388
VF Loss                      549.75006
Policy Loss                  -1076.5537
Q Predictions Mean           1075.8931
Q Predictions Std            930.28375
Q Predictions Max            2183.5723
Q Predictions Min            15.557226
V Predictions Mean           1087.2881
V Predictions Std            928.28204
V Predictions Max            2192.9463
V Predictions Min            28.73017
Log Pis Mean                 -4.7962227
Log Pis Std                  6.9256606
Log Pis Max                  21.278378
Log Pis Min                  -13.10825
Policy mu Mean               0.25827026
Policy mu Std                0.7102912
Policy mu Max                3.0743554
Policy mu Min                -2.722146
Policy log std Mean          -0.2773606
Policy log std Std           0.16316237
Policy log std Max           -0.054709956
Policy log std Min           -0.8136482
Z mean eval                  0.0432076
Z variance eval              0.04862938
total_rewards                [4975.96624488 1755.46394236 5015.11984563 4857.28762235 5010.24442618
 2397.60071985 4932.12612219 3180.27937566 5017.27339928 1725.45584382]
total_rewards_mean           3886.681754219694
total_rewards_std            1377.1320523443899
total_rewards_max            5017.2733992833655
total_rewards_min            1725.4558438246106
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               31.987993041984737
(Previous) Eval Time (s)     15.522387328092009
Sample Time (s)              19.6998305269517
Epoch Time (s)               67.21021089702845
Total Train Time (s)         9546.071622894611
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:54:48.055743 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #182 | Epoch Duration: 75.15561604499817
2020-01-10 20:54:48.056082 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043210093
Z variance train             0.048618555
KL Divergence                5.2037926
KL Loss                      0.52037925
QF Loss                      1513.9609
VF Loss                      645.2829
Policy Loss                  -1120.3582
Q Predictions Mean           1115.7975
Q Predictions Std            907.05725
Q Predictions Max            2192.5942
Q Predictions Min            16.03118
V Predictions Mean           1125.7896
V Predictions Std            904.62
V Predictions Max            2211.8857
V Predictions Min            26.363499
Log Pis Mean                 -3.9458506
Log Pis Std                  6.80959
Log Pis Max                  19.759789
Log Pis Min                  -15.052688
Policy mu Mean               0.27378392
Policy mu Std                0.74893063
Policy mu Max                2.5093703
Policy mu Min                -3.2808373
Policy log std Mean          -0.28950858
Policy log std Std           0.1615292
Policy log std Max           -0.046636485
Policy log std Min           -0.9055445
Z mean eval                  0.0423927
Z variance eval              0.05016021
total_rewards                [2857.76913536 1533.98239016 5128.21582052 2126.30698655 2581.49746762
 3683.62680882 3112.49977803 5155.06625041 1318.09405062 2956.3058483 ]
total_rewards_mean           3045.3364536394697
total_rewards_std            1247.8661346436156
total_rewards_max            5155.066250409393
total_rewards_min            1318.0940506226452
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               29.747369992081076
(Previous) Eval Time (s)     23.467420127242804
Sample Time (s)              20.364790994673967
Epoch Time (s)               73.57958111399785
Total Train Time (s)         9613.67594903009
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:55:55.660375 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #183 | Epoch Duration: 67.60410404205322
2020-01-10 20:55:55.660528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042424053
Z variance train             0.050160896
KL Divergence                5.1311593
KL Loss                      0.51311594
QF Loss                      1119.1818
VF Loss                      280.92007
Policy Loss                  -1068.0477
Q Predictions Mean           1062.1198
Q Predictions Std            921.94507
Q Predictions Max            2196.4177
Q Predictions Min            19.545015
V Predictions Mean           1065.1501
V Predictions Std            918.1579
V Predictions Max            2208.5066
V Predictions Min            27.550695
Log Pis Mean                 -4.3935785
Log Pis Std                  6.5344143
Log Pis Max                  14.975478
Log Pis Min                  -17.235546
Policy mu Mean               0.33429858
Policy mu Std                0.70204675
Policy mu Max                2.7335622
Policy mu Min                -3.0458436
Policy log std Mean          -0.28524646
Policy log std Std           0.16125055
Policy log std Max           -0.02834367
Policy log std Min           -0.9152366
Z mean eval                  0.04308415
Z variance eval              0.048936374
total_rewards                [2248.40335755 5108.74208734 4002.3544385  2787.32810334 1758.74538753
 1250.2280982  5092.09579255 1985.83888015 1077.30506503 1141.11541661]
total_rewards_mean           2645.215662679322
total_rewards_std            1481.9893795393498
total_rewards_max            5108.742087338098
total_rewards_min            1077.305065026707
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               30.510503518395126
(Previous) Eval Time (s)     17.491622402798384
Sample Time (s)              19.147706917021424
Epoch Time (s)               67.14983283821493
Total Train Time (s)         9679.299180241767
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:57:01.288738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #184 | Epoch Duration: 65.62806272506714
2020-01-10 20:57:01.289003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04310996
Z variance train             0.048936624
KL Divergence                5.1983433
KL Loss                      0.51983434
QF Loss                      1132.0864
VF Loss                      363.80887
Policy Loss                  -1062.4219
Q Predictions Mean           1057.3535
Q Predictions Std            933.97595
Q Predictions Max            2196.7935
Q Predictions Min            16.107746
V Predictions Mean           1054.1111
V Predictions Std            923.99304
V Predictions Max            2170.4758
V Predictions Min            24.778542
Log Pis Mean                 -4.787854
Log Pis Std                  6.7470617
Log Pis Max                  13.536746
Log Pis Min                  -13.725691
Policy mu Mean               0.2528943
Policy mu Std                0.69639164
Policy mu Max                2.4158092
Policy mu Min                -2.878755
Policy log std Mean          -0.27459502
Policy log std Std           0.16156302
Policy log std Max           -0.0670821
Policy log std Min           -0.8983844
Z mean eval                  0.040730916
Z variance eval              0.048134573
total_rewards                [2077.49113802 1788.86765587  949.33122507  696.39584784 1413.50124134
 1326.64505047 1218.110038    965.71956654 2478.22089516 1187.68536986]
total_rewards_mean           1410.1968028172837
total_rewards_std            523.6619311985429
total_rewards_max            2478.220895157031
total_rewards_min            696.3958478416254
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               28.68336513917893
(Previous) Eval Time (s)     15.969542117789388
Sample Time (s)              19.288817456457764
Epoch Time (s)               63.94172471342608
Total Train Time (s)         9735.37289664615
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:57:57.362581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #185 | Epoch Duration: 56.073402881622314
2020-01-10 20:57:57.362727 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040622268
Z variance train             0.0481328
KL Divergence                5.2464485
KL Loss                      0.52464485
QF Loss                      1348.5625
VF Loss                      416.97522
Policy Loss                  -1068.9591
Q Predictions Mean           1067.4402
Q Predictions Std            929.67523
Q Predictions Max            2219.3748
Q Predictions Min            16.690483
V Predictions Mean           1072.6721
V Predictions Std            923.66785
V Predictions Max            2208.212
V Predictions Min            29.04719
Log Pis Mean                 -4.1058893
Log Pis Std                  7.371989
Log Pis Max                  25.94606
Log Pis Min                  -13.603908
Policy mu Mean               0.2952708
Policy mu Std                0.7436399
Policy mu Max                3.0868177
Policy mu Min                -3.3591096
Policy log std Mean          -0.28599343
Policy log std Std           0.16591024
Policy log std Max           -0.017742708
Policy log std Min           -1.0316486
Z mean eval                  0.037984423
Z variance eval              0.046465054
total_rewards                [2617.51954677 5071.08388347 3111.0353857  1536.06635131 1355.54550189
 2325.66737197 3302.05730457 2492.14714697 4584.01091028 1230.09201913]
total_rewards_mean           2762.522542204245
total_rewards_std            1231.9467502428533
total_rewards_max            5071.083883471165
total_rewards_min            1230.0920191253288
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               31.809301215223968
(Previous) Eval Time (s)     8.10090040229261
Sample Time (s)              18.634361004456878
Epoch Time (s)               58.544562621973455
Total Train Time (s)         9801.859154247679
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 20:59:03.851722 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #186 | Epoch Duration: 66.48887872695923
2020-01-10 20:59:03.851916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0381198
Z variance train             0.046454154
KL Divergence                5.3413353
KL Loss                      0.53413355
QF Loss                      1862.5532
VF Loss                      409.46066
Policy Loss                  -1114.3948
Q Predictions Mean           1108.0614
Q Predictions Std            947.0263
Q Predictions Max            2223.1606
Q Predictions Min            17.273203
V Predictions Mean           1109.6252
V Predictions Std            937.9876
V Predictions Max            2197.5522
V Predictions Min            29.011345
Log Pis Mean                 -4.626284
Log Pis Std                  6.7320623
Log Pis Max                  19.704807
Log Pis Min                  -13.106439
Policy mu Mean               0.25644627
Policy mu Std                0.70982057
Policy mu Max                2.4616146
Policy mu Min                -2.8212326
Policy log std Mean          -0.27787763
Policy log std Std           0.16320468
Policy log std Max           -0.034402072
Policy log std Min           -0.8453351
Z mean eval                  0.03515008
Z variance eval              0.044601165
total_rewards                [2785.88685811 1570.66089876  911.228185   5004.42203006 5072.40642801
 1868.45761361 3258.03579155 5030.62990816 5031.16578403 2183.81671097]
total_rewards_mean           3271.671020827428
total_rewards_std            1558.478909393923
total_rewards_max            5072.406428012834
total_rewards_min            911.228185003515
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               31.324161848053336
(Previous) Eval Time (s)     16.04487324366346
Sample Time (s)              18.938089470379055
Epoch Time (s)               66.30712456209585
Total Train Time (s)         9871.548860268667
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:00:13.545887 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #187 | Epoch Duration: 69.69380211830139
2020-01-10 21:00:13.546178 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035150696
Z variance train             0.044627465
KL Divergence                5.4215965
KL Loss                      0.5421597
QF Loss                      1867.2566
VF Loss                      265.78897
Policy Loss                  -1124.3887
Q Predictions Mean           1114.9427
Q Predictions Std            934.43207
Q Predictions Max            2207.4504
Q Predictions Min            16.680498
V Predictions Mean           1127.3953
V Predictions Std            936.46155
V Predictions Max            2206.7864
V Predictions Min            27.876438
Log Pis Mean                 -4.506099
Log Pis Std                  6.8251147
Log Pis Max                  16.571152
Log Pis Min                  -14.220602
Policy mu Mean               0.25116885
Policy mu Std                0.7441586
Policy mu Max                2.6375196
Policy mu Min                -2.9047537
Policy log std Mean          -0.2834115
Policy log std Std           0.16328043
Policy log std Max           -0.051580153
Policy log std Min           -0.8511062
Z mean eval                  0.03601303
Z variance eval              0.04317497
total_rewards                [4915.68559869 2629.39638424 3426.04308809 5072.21132871 2703.97151417
 2271.17164369 4810.39094595 4965.58984663 4966.73886419 4962.00093384]
total_rewards_mean           4072.3200148215847
total_rewards_std            1107.3147971120181
total_rewards_max            5072.211328712025
total_rewards_min            2271.171643689497
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               30.80354418605566
(Previous) Eval Time (s)     19.4312450774014
Sample Time (s)              19.091743024997413
Epoch Time (s)               69.32653228845447
Total Train Time (s)         9946.010796285234
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:01:28.010265 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #188 | Epoch Duration: 74.46386933326721
2020-01-10 21:01:28.010493 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035641365
Z variance train             0.043193962
KL Divergence                5.499551
KL Loss                      0.54995507
QF Loss                      1305.4263
VF Loss                      470.8662
Policy Loss                  -1071.8132
Q Predictions Mean           1068.6351
Q Predictions Std            935.44885
Q Predictions Max            2198.8257
Q Predictions Min            15.885109
V Predictions Mean           1077.7937
V Predictions Std            935.2541
V Predictions Max            2210.9614
V Predictions Min            24.278873
Log Pis Mean                 -4.840087
Log Pis Std                  6.7705445
Log Pis Max                  22.111866
Log Pis Min                  -14.342339
Policy mu Mean               0.26822534
Policy mu Std                0.70551264
Policy mu Max                3.419094
Policy mu Min                -2.8854976
Policy log std Mean          -0.27129966
Policy log std Std           0.16175243
Policy log std Max           -0.026408121
Policy log std Min           -0.9185446
Z mean eval                  0.035953
Z variance eval              0.042543225
total_rewards                [5077.74418471 5027.84962904 1237.69896414 5042.8084336  3176.99805967
 3245.64736255 5003.83905211 4256.78024825 1552.35817561 5080.38766147]
total_rewards_mean           3870.2111771145646
total_rewards_std            1422.8671574473717
total_rewards_max            5080.387661470712
total_rewards_min            1237.6989641438377
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               29.707852988969535
(Previous) Eval Time (s)     24.56829989887774
Sample Time (s)              20.039829983841628
Epoch Time (s)               74.3159828716889
Total Train Time (s)         10018.12508303579
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:02:40.128844 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #189 | Epoch Duration: 72.11815524101257
2020-01-10 21:02:40.129126 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035710383
Z variance train             0.04252723
KL Divergence                5.5468807
KL Loss                      0.5546881
QF Loss                      1799.1832
VF Loss                      796.31
Policy Loss                  -1081.919
Q Predictions Mean           1074.7661
Q Predictions Std            914.0839
Q Predictions Max            2193.0056
Q Predictions Min            17.241129
V Predictions Mean           1095.0298
V Predictions Std            919.20056
V Predictions Max            2218.5684
V Predictions Min            25.421572
Log Pis Mean                 -3.7899184
Log Pis Std                  7.5694804
Log Pis Max                  29.480694
Log Pis Min                  -13.6596985
Policy mu Mean               0.26125222
Policy mu Std                0.7669351
Policy mu Max                3.044481
Policy mu Min                -3.2219162
Policy log std Mean          -0.29050317
Policy log std Std           0.17017987
Policy log std Max           -0.0801157
Policy log std Min           -0.9562322
Z mean eval                  0.033542745
Z variance eval              0.044105113
total_rewards                [2449.82818715 1322.16580111 1744.82789724 4042.09752788 4442.83907129
 1090.09935488 2562.6095161  2141.36473094 2108.9880477  4971.55026056]
total_rewards_mean           2687.637039482782
total_rewards_std            1270.532071472246
total_rewards_max            4971.550260562862
total_rewards_min            1090.0993548754238
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               29.29344047792256
(Previous) Eval Time (s)     22.370149481110275
Sample Time (s)              19.30938108637929
Epoch Time (s)               70.97297104541212
Total Train Time (s)         10082.177774849348
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:03:44.183688 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #190 | Epoch Duration: 64.05435967445374
2020-01-10 21:03:44.183896 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0338751
Z variance train             0.044087872
KL Divergence                5.447865
KL Loss                      0.5447865
QF Loss                      1798.2422
VF Loss                      751.1485
Policy Loss                  -1087.9175
Q Predictions Mean           1076.9873
Q Predictions Std            935.9423
Q Predictions Max            2215.5225
Q Predictions Min            13.768699
V Predictions Mean           1078.1609
V Predictions Std            926.15894
V Predictions Max            2216.799
V Predictions Min            23.575464
Log Pis Mean                 -4.380626
Log Pis Std                  7.1229753
Log Pis Max                  20.407925
Log Pis Min                  -13.908377
Policy mu Mean               0.26424852
Policy mu Std                0.72116035
Policy mu Max                2.8272922
Policy mu Min                -2.6099913
Policy log std Mean          -0.27146998
Policy log std Std           0.16090845
Policy log std Max           -0.028888822
Policy log std Min           -0.8729315
Z mean eval                  0.033658758
Z variance eval              0.042360254
total_rewards                [5054.21717904  931.81659279 4444.68783423 1994.41921664 1126.73058575
 4733.7306641  3256.33684892  849.07446403 2908.91598227 1498.37684272]
total_rewards_mean           2679.830621048851
total_rewards_std            1550.5076627589483
total_rewards_max            5054.217179038613
total_rewards_min            849.0744640295418
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               32.31827328586951
(Previous) Eval Time (s)     15.451248966623098
Sample Time (s)              19.029699594248086
Epoch Time (s)               66.79922184674069
Total Train Time (s)         10149.3045098125
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:04:51.313868 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #191 | Epoch Duration: 67.12980914115906
2020-01-10 21:04:51.314098 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033491097
Z variance train             0.042365544
KL Divergence                5.5651855
KL Loss                      0.55651855
QF Loss                      1305.8384
VF Loss                      342.71503
Policy Loss                  -1152.5713
Q Predictions Mean           1141.1012
Q Predictions Std            935.3094
Q Predictions Max            2227.9954
Q Predictions Min            18.318317
V Predictions Mean           1156.3481
V Predictions Std            937.576
V Predictions Max            2219.8787
V Predictions Min            27.511454
Log Pis Mean                 -4.220793
Log Pis Std                  6.65095
Log Pis Max                  14.879238
Log Pis Min                  -13.440561
Policy mu Mean               0.26360255
Policy mu Std                0.75496763
Policy mu Max                2.5234177
Policy mu Min                -2.9178216
Policy log std Mean          -0.28630745
Policy log std Std           0.15912636
Policy log std Max           -0.052561477
Policy log std Min           -0.86381304
Z mean eval                  0.03164665
Z variance eval              0.041655205
total_rewards                [5029.74740842 3011.25088258 5030.56964038 2099.47252587 1714.15614874
 4738.88229296 5014.36114996  881.8972166  1172.12623157 4974.14009068]
total_rewards_mean           3366.6603587758063
total_rewards_std            1678.3692569412592
total_rewards_max            5030.569640378655
total_rewards_min            881.8972166041223
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               32.19214996602386
(Previous) Eval Time (s)     15.781536410097033
Sample Time (s)              20.18801589962095
Epoch Time (s)               68.16170227574185
Total Train Time (s)         10221.07503942633
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:06:03.089398 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #192 | Epoch Duration: 71.7750940322876
2020-01-10 21:06:03.089710 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031547084
Z variance train             0.041653086
KL Divergence                5.5993032
KL Loss                      0.5599303
QF Loss                      1313.1511
VF Loss                      408.43402
Policy Loss                  -1188.9976
Q Predictions Mean           1183.8077
Q Predictions Std            940.1218
Q Predictions Max            2228.141
Q Predictions Min            15.677752
V Predictions Mean           1187.2877
V Predictions Std            934.6658
V Predictions Max            2226.0928
V Predictions Min            26.893053
Log Pis Mean                 -4.1026635
Log Pis Std                  6.857554
Log Pis Max                  15.159134
Log Pis Min                  -13.607664
Policy mu Mean               0.29047945
Policy mu Std                0.7409143
Policy mu Max                2.5852802
Policy mu Min                -2.414989
Policy log std Mean          -0.291981
Policy log std Std           0.1744545
Policy log std Max           -0.03275699
Policy log std Min           -0.9101656
Z mean eval                  0.03144941
Z variance eval              0.039749194
total_rewards                [4304.14671673 4964.73128949 1093.75184392 4973.35963971 5033.62360484
 5012.81683689 5022.10615114 4801.83645772 3620.10445294 4923.66282559]
total_rewards_mean           4375.013981899061
total_rewards_std            1174.3021836706669
total_rewards_max            5033.623604843724
total_rewards_min            1093.7518439193502
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               31.42729291692376
(Previous) Eval Time (s)     19.394596594851464
Sample Time (s)              19.461867063306272
Epoch Time (s)               70.2837565750815
Total Train Time (s)         10297.758670132142
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:07:19.776259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #193 | Epoch Duration: 76.68629288673401
2020-01-10 21:07:19.776559 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031514984
Z variance train             0.03976647
KL Divergence                5.7078004
KL Loss                      0.57078004
QF Loss                      1579.48
VF Loss                      418.2515
Policy Loss                  -1119.5927
Q Predictions Mean           1106.3639
Q Predictions Std            935.7141
Q Predictions Max            2217.2566
Q Predictions Min            13.824341
V Predictions Mean           1117.1858
V Predictions Std            931.26074
V Predictions Max            2223.8503
V Predictions Min            27.53145
Log Pis Mean                 -3.8588486
Log Pis Std                  7.5690327
Log Pis Max                  19.232239
Log Pis Min                  -12.991938
Policy mu Mean               0.24386992
Policy mu Std                0.7719315
Policy mu Max                2.7658272
Policy mu Min                -3.2084737
Policy log std Mean          -0.28626537
Policy log std Std           0.16216539
Policy log std Max           -0.030334957
Policy log std Min           -0.8034404
Z mean eval                  0.030792445
Z variance eval              0.039445646
total_rewards                [1613.39461465 1782.08779522 3620.11408447 1575.61881985 2040.57263133
 4670.6521404   901.47498061 1732.3740557  5137.20196477 3861.72812298]
total_rewards_mean           2693.5219209981287
total_rewards_std            1411.1190440946796
total_rewards_max            5137.201964771496
total_rewards_min            901.4749806142885
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               31.555955849587917
(Previous) Eval Time (s)     25.796820412855595
Sample Time (s)              20.011347657069564
Epoch Time (s)               77.36412391951308
Total Train Time (s)         10364.622125680093
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:08:26.640517 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #194 | Epoch Duration: 66.86375117301941
2020-01-10 21:08:26.640669 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030917738
Z variance train             0.03944886
KL Divergence                5.7210875
KL Loss                      0.57210875
QF Loss                      1287.3245
VF Loss                      329.33438
Policy Loss                  -1149.8351
Q Predictions Mean           1142.7461
Q Predictions Std            943.97833
Q Predictions Max            2230.2488
Q Predictions Min            13.830819
V Predictions Mean           1147.478
V Predictions Std            940.1813
V Predictions Max            2226.0151
V Predictions Min            24.538599
Log Pis Mean                 -3.8859844
Log Pis Std                  7.5116005
Log Pis Max                  23.596754
Log Pis Min                  -13.159862
Policy mu Mean               0.26146272
Policy mu Std                0.7624166
Policy mu Max                3.189121
Policy mu Min                -3.34482
Policy log std Mean          -0.28408277
Policy log std Std           0.168138
Policy log std Max           -0.025035113
Policy log std Min           -0.89677256
Z mean eval                  0.031202918
Z variance eval              0.041312248
total_rewards                [5025.87262305 5006.31037419 3519.40440427 1147.31922758  973.29737422
 3147.50447625 1339.13392143 2370.60436685 4991.80922922 1098.64185733]
total_rewards_mean           2861.9897854378205
total_rewards_std            1628.1137208125494
total_rewards_max            5025.872623045664
total_rewards_min            973.2973742157972
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               29.881661847699434
(Previous) Eval Time (s)     15.29612409742549
Sample Time (s)              18.76499957824126
Epoch Time (s)               63.94278552336618
Total Train Time (s)         10430.280410445761
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:09:32.302334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #195 | Epoch Duration: 65.66152501106262
2020-01-10 21:09:32.302571 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031370692
Z variance train             0.041315425
KL Divergence                5.608832
KL Loss                      0.5608832
QF Loss                      1394.5719
VF Loss                      399.99713
Policy Loss                  -1105.4312
Q Predictions Mean           1092.7279
Q Predictions Std            945.7499
Q Predictions Max            2232.1736
Q Predictions Min            15.924878
V Predictions Mean           1108.5964
V Predictions Std            948.90625
V Predictions Max            2240.4443
V Predictions Min            25.869526
Log Pis Mean                 -4.0249815
Log Pis Std                  7.628635
Log Pis Max                  24.207418
Log Pis Min                  -15.867526
Policy mu Mean               0.28549957
Policy mu Std                0.7436075
Policy mu Max                2.4107656
Policy mu Min                -2.8087602
Policy log std Mean          -0.28372732
Policy log std Std           0.16367133
Policy log std Max           -0.036927707
Policy log std Min           -0.895741
Z mean eval                  0.025244066
Z variance eval              0.03921537
total_rewards                [3408.85441674 1623.19997195 5086.6986096  5107.01034257 3086.36910699
 2015.3371325  5098.62875256 2635.92917534 5179.99730121 1899.16502662]
total_rewards_mean           3514.1189836085787
total_rewards_std            1403.2603925473445
total_rewards_max            5179.997301209297
total_rewards_min            1623.1999719478774
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               29.225039602722973
(Previous) Eval Time (s)     17.014558168128133
Sample Time (s)              19.022723250556737
Epoch Time (s)               65.26232102140784
Total Train Time (s)         10499.243702989072
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:10:41.267213 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #196 | Epoch Duration: 68.96447777748108
2020-01-10 21:10:41.267410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02504307
Z variance train             0.03919342
KL Divergence                5.747039
KL Loss                      0.5747039
QF Loss                      1711.7578
VF Loss                      855.30804
Policy Loss                  -1234.443
Q Predictions Mean           1229.7661
Q Predictions Std            916.28503
Q Predictions Max            2244.7756
Q Predictions Min            15.950275
V Predictions Mean           1248.0668
V Predictions Std            924.20703
V Predictions Max            2280.9248
V Predictions Min            26.106394
Log Pis Mean                 -2.702684
Log Pis Std                  7.6350718
Log Pis Max                  32.32879
Log Pis Min                  -15.420637
Policy mu Mean               0.32207617
Policy mu Std                0.79957825
Policy mu Max                3.3591871
Policy mu Min                -3.2261465
Policy log std Mean          -0.30912653
Policy log std Std           0.17300718
Policy log std Max           0.015136197
Policy log std Min           -0.88061786
Z mean eval                  0.028619999
Z variance eval              0.04059881
total_rewards                [1911.93798803 1219.7575783  3761.87018117 2252.59551449 3880.53954983
 3327.54913008 2129.38747446 5066.83595687 2264.9711961  1221.56027724]
total_rewards_mean           2703.700484657577
total_rewards_std            1192.8871780514344
total_rewards_max            5066.835956865962
total_rewards_min            1219.7575783022037
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               32.875448178034276
(Previous) Eval Time (s)     20.71633945312351
Sample Time (s)              19.524504339322448
Epoch Time (s)               73.11629197048023
Total Train Time (s)         10567.697448255494
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:11:49.724735 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #197 | Epoch Duration: 68.45716524124146
2020-01-10 21:11:49.725017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028622607
Z variance train             0.0405923
KL Divergence                5.6717954
KL Loss                      0.56717956
QF Loss                      1315.8513
VF Loss                      540.70734
Policy Loss                  -1124.3618
Q Predictions Mean           1119.3596
Q Predictions Std            961.1015
Q Predictions Max            2253.9507
Q Predictions Min            16.603373
V Predictions Mean           1122.1548
V Predictions Std            956.227
V Predictions Max            2241.2505
V Predictions Min            27.945763
Log Pis Mean                 -3.8436034
Log Pis Std                  7.327923
Log Pis Max                  18.681961
Log Pis Min                  -13.645176
Policy mu Mean               0.2849666
Policy mu Std                0.74677175
Policy mu Max                3.4794497
Policy mu Min                -2.682502
Policy log std Mean          -0.28143433
Policy log std Std           0.16581333
Policy log std Max           -0.029440105
Policy log std Min           -0.8991608
Z mean eval                  0.027636766
Z variance eval              0.04185867
total_rewards                [3297.98808454 5029.84510447 4420.78584325 5080.39954915 1507.62875079
 5082.03743738 1646.18490469  519.73276743 5046.10702875 3247.23841123]
total_rewards_mean           3487.794788167293
total_rewards_std            1642.2727753954562
total_rewards_max            5082.037437377315
total_rewards_min            519.7327674257405
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               31.465750867966563
(Previous) Eval Time (s)     16.056886028964072
Sample Time (s)              19.186749314889312
Epoch Time (s)               66.70938621181995
Total Train Time (s)         10638.736714628525
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:13:00.768135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #198 | Epoch Duration: 71.04289817810059
2020-01-10 21:13:00.768426 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027869219
Z variance train             0.041865427
KL Divergence                5.575942
KL Loss                      0.55759424
QF Loss                      987.96765
VF Loss                      553.9047
Policy Loss                  -1162.0703
Q Predictions Mean           1151.4307
Q Predictions Std            942.5211
Q Predictions Max            2247.944
Q Predictions Min            15.833226
V Predictions Mean           1157.5137
V Predictions Std            936.1754
V Predictions Max            2235.1848
V Predictions Min            23.463818
Log Pis Mean                 -3.944435
Log Pis Std                  7.4382577
Log Pis Max                  30.495953
Log Pis Min                  -14.493174
Policy mu Mean               0.24238059
Policy mu Std                0.7694887
Policy mu Max                3.6735609
Policy mu Min                -3.0092115
Policy log std Mean          -0.28706115
Policy log std Std           0.1633652
Policy log std Max           -0.042670965
Policy log std Min           -1.0133165
Z mean eval                  0.028638825
Z variance eval              0.041905575
total_rewards                [4989.19907146 2469.05553962 1002.2045013  1957.01066482 5060.58375283
 2713.99937922 1922.40815867 1650.64097872 1029.91135675 5071.00780094]
total_rewards_mean           2786.6021204332474
total_rewards_std            1560.2096109161794
total_rewards_max            5071.007800944055
total_rewards_min            1002.2045013010869
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               30.527102175634354
(Previous) Eval Time (s)     20.390069260261953
Sample Time (s)              19.43385523511097
Epoch Time (s)               70.35102667100728
Total Train Time (s)         10705.114419456571
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:14:07.146949 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #199 | Epoch Duration: 66.37832140922546
2020-01-10 21:14:07.147106 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028948318
Z variance train             0.041888136
KL Divergence                5.5944986
KL Loss                      0.55944985
QF Loss                      1361.2643
VF Loss                      477.18073
Policy Loss                  -1280.1552
Q Predictions Mean           1269.7462
Q Predictions Std            959.3044
Q Predictions Max            2267.7517
Q Predictions Min            16.273932
V Predictions Mean           1270.2975
V Predictions Std            950.58527
V Predictions Max            2256.4944
V Predictions Min            25.902422
Log Pis Mean                 -3.5047002
Log Pis Std                  7.2125983
Log Pis Max                  18.087425
Log Pis Min                  -12.912048
Policy mu Mean               0.2990071
Policy mu Std                0.7694043
Policy mu Max                2.7407007
Policy mu Min                -2.3513916
Policy log std Mean          -0.29791978
Policy log std Std           0.16691583
Policy log std Max           -0.072189495
Policy log std Min           -0.91023135
Z mean eval                  0.028144648
Z variance eval              0.039610375
total_rewards                [3619.55793463 1873.32228177 1016.79537283  871.13025161 5086.37205918
  729.77009041  874.76017917 3045.52842484 1549.5187204  3283.52047059]
total_rewards_mean           2195.027578542392
total_rewards_std            1408.8479288342833
total_rewards_max            5086.372059177869
total_rewards_min            729.7700904082803
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               31.214602364227176
(Previous) Eval Time (s)     16.417085194028914
Sample Time (s)              19.439001207239926
Epoch Time (s)               67.07068876549602
Total Train Time (s)         10768.57494741911
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:15:10.609182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #200 | Epoch Duration: 63.46195864677429
2020-01-10 21:15:10.609360 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #200 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028122285
Z variance train             0.039620213
KL Divergence                5.725684
KL Loss                      0.5725684
QF Loss                      1753.5122
VF Loss                      316.88965
Policy Loss                  -1342.5249
Q Predictions Mean           1338.7216
Q Predictions Std            935.12366
Q Predictions Max            2271.2458
Q Predictions Min            13.265395
V Predictions Mean           1338.0087
V Predictions Std            927.8472
V Predictions Max            2261.3733
V Predictions Min            25.838152
Log Pis Mean                 -3.7413008
Log Pis Std                  6.714703
Log Pis Max                  20.252666
Log Pis Min                  -14.030409
Policy mu Mean               0.27447057
Policy mu Std                0.7697103
Policy mu Max                3.13351
Policy mu Min                -3.172793
Policy log std Mean          -0.28854743
Policy log std Std           0.16122515
Policy log std Max           -0.07859941
Policy log std Min           -0.91736674
Z mean eval                  0.026464108
Z variance eval              0.039156664
total_rewards                [1223.46939983 5023.25268221 5057.50178683 5034.03449117 1435.6688638
 5027.08673208 1705.24026168  945.62197529 5058.42067609 2923.26309546]
total_rewards_mean           3343.3559964430183
total_rewards_std            1764.5780658368826
total_rewards_max            5058.42067609212
total_rewards_min            945.6219752853511
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               30.469021238852292
(Previous) Eval Time (s)     12.808047960046679
Sample Time (s)              19.31066887965426
Epoch Time (s)               62.58773807855323
Total Train Time (s)         10837.695301702712
Epoch                        201
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:16:19.734214 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #201 | Epoch Duration: 69.12471055984497
2020-01-10 21:16:19.734473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #201 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026785523
Z variance train             0.03915642
KL Divergence                5.754321
KL Loss                      0.5754321
QF Loss                      1699.6624
VF Loss                      572.8993
Policy Loss                  -1216.0896
Q Predictions Mean           1208.4885
Q Predictions Std            962.6698
Q Predictions Max            2258.2278
Q Predictions Min            15.360878
V Predictions Mean           1203.1671
V Predictions Std            948.9691
V Predictions Max            2240.329
V Predictions Min            26.346325
Log Pis Mean                 -3.823221
Log Pis Std                  6.9701204
Log Pis Max                  20.016808
Log Pis Min                  -13.404871
Policy mu Mean               0.2810054
Policy mu Std                0.74852765
Policy mu Max                2.8387113
Policy mu Min                -2.5715747
Policy log std Mean          -0.28460318
Policy log std Std           0.16232957
Policy log std Max           -0.0051566064
Policy log std Min           -1.0100319
Z mean eval                  0.026462013
Z variance eval              0.03956961
total_rewards                [4980.23128671 1096.19615677 2442.80287291 2950.24897046 4986.9874109
 4813.12513852 4400.2563967  1374.75583618 5015.96819489 2709.46235321]
total_rewards_mean           3477.0034617265205
total_rewards_std            1468.6600694275364
total_rewards_max            5015.968194894949
total_rewards_min            1096.1961567734118
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               29.107594455126673
(Previous) Eval Time (s)     19.344686604104936
Sample Time (s)              19.153125355020165
Epoch Time (s)               67.60540641425177
Total Train Time (s)         10908.144136316609
Epoch                        202
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:17:30.187806 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #202 | Epoch Duration: 70.45299196243286
2020-01-10 21:17:30.188105 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027004804
Z variance train             0.039558154
KL Divergence                5.7456737
KL Loss                      0.5745674
QF Loss                      1843.9554
VF Loss                      627.71277
Policy Loss                  -1279.1908
Q Predictions Mean           1268.9924
Q Predictions Std            940.9511
Q Predictions Max            2265.1626
Q Predictions Min            16.950151
V Predictions Mean           1269.742
V Predictions Std            932.95654
V Predictions Max            2272.1965
V Predictions Min            25.337551
Log Pis Mean                 -4.1952295
Log Pis Std                  6.1492968
Log Pis Max                  19.57556
Log Pis Min                  -13.109549
Policy mu Mean               0.31768322
Policy mu Std                0.7297733
Policy mu Max                2.7976143
Policy mu Min                -2.8700938
Policy log std Mean          -0.29056016
Policy log std Std           0.15430866
Policy log std Max           0.009912476
Policy log std Min           -0.99692
Z mean eval                  0.031006401
Z variance eval              0.040733792
total_rewards                [3847.73486126 4202.00189648 1141.32726767 4096.81132958 1267.15403695
 4103.96156295 5065.21777332 5149.80175155 1856.82403558 5096.81653626]
total_rewards_mean           3582.7651051598177
total_rewards_std            1491.1981710514815
total_rewards_max            5149.801751547012
total_rewards_min            1141.327267669891
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               32.56027152668685
(Previous) Eval Time (s)     22.19210471911356
Sample Time (s)              19.712921069469303
Epoch Time (s)               74.46529731526971
Total Train Time (s)         10980.96366247302
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:18:43.008199 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #203 | Epoch Duration: 72.81989336013794
2020-01-10 21:18:43.008385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031366456
Z variance train             0.040719297
KL Divergence                5.7035885
KL Loss                      0.5703589
QF Loss                      2170.1714
VF Loss                      513.8741
Policy Loss                  -1300.3542
Q Predictions Mean           1291.8916
Q Predictions Std            937.45166
Q Predictions Max            2276.9412
Q Predictions Min            16.886135
V Predictions Mean           1295.9868
V Predictions Std            932.7869
V Predictions Max            2269.0164
V Predictions Min            26.066572
Log Pis Mean                 -3.1997976
Log Pis Std                  7.4469423
Log Pis Max                  24.471758
Log Pis Min                  -14.110402
Policy mu Mean               0.28244013
Policy mu Std                0.8132476
Policy mu Max                2.7430391
Policy mu Min                -2.9134538
Policy log std Mean          -0.30806738
Policy log std Std           0.17009713
Policy log std Max           -0.04758881
Policy log std Min           -0.991652
Z mean eval                  0.032464474
Z variance eval              0.041018546
total_rewards                [4362.52337464  925.94835179 4586.05498523 5067.2539389  1755.45602816
 3729.36284314 1775.807393   4663.52913858 3278.45025732 1328.72890922]
total_rewards_mean           3147.3115219990473
total_rewards_std            1481.4783426798763
total_rewards_max            5067.253938902917
total_rewards_min            925.9483517863712
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               28.668740226887167
(Previous) Eval Time (s)     20.546346626244485
Sample Time (s)              19.81535291299224
Epoch Time (s)               69.03043976612389
Total Train Time (s)         11048.053524204995
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:19:50.101522 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #204 | Epoch Duration: 67.09300088882446
2020-01-10 21:19:50.101696 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031967133
Z variance train             0.0410274
KL Divergence                5.638197
KL Loss                      0.5638197
QF Loss                      1554.9751
VF Loss                      567.9967
Policy Loss                  -1260.2593
Q Predictions Mean           1257.4286
Q Predictions Std            959.5478
Q Predictions Max            2268.6033
Q Predictions Min            13.4897175
V Predictions Mean           1270.8276
V Predictions Std            962.4339
V Predictions Max            2284.888
V Predictions Min            25.98063
Log Pis Mean                 -4.4122066
Log Pis Std                  6.783132
Log Pis Max                  17.10992
Log Pis Min                  -14.33546
Policy mu Mean               0.2704121
Policy mu Std                0.744225
Policy mu Max                3.203708
Policy mu Min                -4.214845
Policy log std Mean          -0.28571716
Policy log std Std           0.1614883
Policy log std Max           -0.0084604025
Policy log std Min           -0.8850059
Z mean eval                  0.035412107
Z variance eval              0.039359353
total_rewards                [5088.18754655 4858.48896826 4281.63226367 2412.59494547 5012.32717478
 5124.09177925 5106.16518097  892.16737629 5054.65112447 5093.88395007]
total_rewards_mean           4292.41903097862
total_rewards_std            1383.6445656141561
total_rewards_max            5124.091779247016
total_rewards_min            892.1673762890474
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               30.246351511683315
(Previous) Eval Time (s)     18.60859286878258
Sample Time (s)              20.2010881411843
Epoch Time (s)               69.0560325216502
Total Train Time (s)         11123.414485485293
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:21:05.464715 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #205 | Epoch Duration: 75.36285543441772
2020-01-10 21:21:05.464934 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035598602
Z variance train             0.039355926
KL Divergence                5.7394633
KL Loss                      0.57394636
QF Loss                      1828.2832
VF Loss                      542.139
Policy Loss                  -1277.2083
Q Predictions Mean           1274.5889
Q Predictions Std            936.1841
Q Predictions Max            2298.019
Q Predictions Min            17.059614
V Predictions Mean           1282.9481
V Predictions Std            932.5705
V Predictions Max            2278.9075
V Predictions Min            28.25006
Log Pis Mean                 -3.3063304
Log Pis Std                  6.9725084
Log Pis Max                  19.982632
Log Pis Min                  -12.831554
Policy mu Mean               0.2989769
Policy mu Std                0.7699621
Policy mu Max                3.2564242
Policy mu Min                -2.9510655
Policy log std Mean          -0.29546046
Policy log std Std           0.15919374
Policy log std Max           -0.0007735491
Policy log std Min           -0.95102775
Z mean eval                  0.034472726
Z variance eval              0.03804194
total_rewards                [1490.1021451  4067.05648321  987.96749916 4414.18217323 5090.72768568
 5169.39080283 4219.4099861  1852.28483789 3449.30163737 5058.99340326]
total_rewards_mean           3579.941665382909
total_rewards_std            1497.5379473081914
total_rewards_max            5169.390802832742
total_rewards_min            987.9674991580861
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               29.373728330247104
(Previous) Eval Time (s)     24.915077870246023
Sample Time (s)              19.113560297060758
Epoch Time (s)               73.40236649755388
Total Train Time (s)         11192.676010231487
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:22:14.730245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #206 | Epoch Duration: 69.26513314247131
2020-01-10 21:22:14.730499 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034498744
Z variance train             0.038040318
KL Divergence                5.8290963
KL Loss                      0.58290964
QF Loss                      1373.104
VF Loss                      347.50528
Policy Loss                  -1223.3812
Q Predictions Mean           1217.0999
Q Predictions Std            951.18524
Q Predictions Max            2282.0413
Q Predictions Min            19.805958
V Predictions Mean           1224.6831
V Predictions Std            951.50104
V Predictions Max            2287.803
V Predictions Min            30.839592
Log Pis Mean                 -3.6174128
Log Pis Std                  7.2037735
Log Pis Max                  22.386929
Log Pis Min                  -16.235573
Policy mu Mean               0.29640484
Policy mu Std                0.7668081
Policy mu Max                2.6925306
Policy mu Min                -3.549145
Policy log std Mean          -0.299462
Policy log std Std           0.16624686
Policy log std Max           -0.02434422
Policy log std Min           -0.9247942
Z mean eval                  0.03648317
Z variance eval              0.038894553
total_rewards                [5035.1890061  1072.47541089 5007.1845518  5076.73427365 5058.93455315
 5032.92308223 4311.83657493 5006.70624695 2408.74949341 4493.58619717]
total_rewards_mean           4250.431939028567
total_rewards_std            1313.8991537531115
total_rewards_max            5076.734273653616
total_rewards_min            1072.47541089059
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               30.660489299334586
(Previous) Eval Time (s)     20.77754511963576
Sample Time (s)              19.790029557421803
Epoch Time (s)               71.22806397639215
Total Train Time (s)         11267.774480172899
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:23:29.832955 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #207 | Epoch Duration: 75.10225558280945
2020-01-10 21:23:29.833191 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036678992
Z variance train             0.0389148
KL Divergence                5.7779417
KL Loss                      0.5777942
QF Loss                      1520.4253
VF Loss                      929.4757
Policy Loss                  -1296.262
Q Predictions Mean           1293.2458
Q Predictions Std            961.7821
Q Predictions Max            2286.485
Q Predictions Min            17.42337
V Predictions Mean           1282.5842
V Predictions Std            949.57715
V Predictions Max            2286.4421
V Predictions Min            24.619106
Log Pis Mean                 -3.3191743
Log Pis Std                  7.582769
Log Pis Max                  30.69828
Log Pis Min                  -14.296112
Policy mu Mean               0.28652745
Policy mu Std                0.76936936
Policy mu Max                2.936515
Policy mu Min                -3.8174112
Policy log std Mean          -0.29027987
Policy log std Std           0.162712
Policy log std Max           -0.009907484
Policy log std Min           -0.9711093
Z mean eval                  0.033214115
Z variance eval              0.037889563
total_rewards                [ 706.38880901 4127.69606782 1377.56071575 2133.57966469 5106.8076764
 2967.98779918 3712.19113366 1810.38514724 1265.73218852 2307.26895763]
total_rewards_mean           2551.5598159905135
total_rewards_std            1332.4407068638882
total_rewards_max            5106.807676398614
total_rewards_min            706.3888090066974
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               30.35179172223434
(Previous) Eval Time (s)     24.651379307266325
Sample Time (s)              19.54929716512561
Epoch Time (s)               74.55246819462627
Total Train Time (s)         11333.19812258659
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:24:35.259698 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #208 | Epoch Duration: 65.4263014793396
2020-01-10 21:24:35.260002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033189274
Z variance train             0.03789271
KL Divergence                5.827532
KL Loss                      0.5827532
QF Loss                      1463.153
VF Loss                      543.2438
Policy Loss                  -1300.2306
Q Predictions Mean           1292.0126
Q Predictions Std            950.7056
Q Predictions Max            2288.0007
Q Predictions Min            17.5041
V Predictions Mean           1298.616
V Predictions Std            944.7235
V Predictions Max            2292.0854
V Predictions Min            28.399553
Log Pis Mean                 -3.3707824
Log Pis Std                  6.6908603
Log Pis Max                  16.528126
Log Pis Min                  -14.513618
Policy mu Mean               0.29651
Policy mu Std                0.77883244
Policy mu Max                2.882622
Policy mu Min                -2.9793215
Policy log std Mean          -0.299993
Policy log std Std           0.16701838
Policy log std Max           -0.013679683
Policy log std Min           -0.9008853
Z mean eval                  0.034657255
Z variance eval              0.03920925
total_rewards                [3821.65658821 5081.29522202 1476.85955543 5170.80801426 3058.57645769
  381.84194455 1330.3195131  5190.48796613 1909.5545947   800.81641562]
total_rewards_mean           2822.2216271714888
total_rewards_std            1794.2395320285816
total_rewards_max            5190.487966133367
total_rewards_min            381.8419445512035
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               31.057226965669543
(Previous) Eval Time (s)     15.524869536980987
Sample Time (s)              19.514442835003138
Epoch Time (s)               66.09653933765367
Total Train Time (s)         11400.542870615143
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:25:42.606437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #209 | Epoch Duration: 67.34623670578003
2020-01-10 21:25:42.606610 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03460548
Z variance train             0.03919462
KL Divergence                5.724283
KL Loss                      0.57242835
QF Loss                      1492.1387
VF Loss                      473.40176
Policy Loss                  -1260.6292
Q Predictions Mean           1253.6274
Q Predictions Std            986.8698
Q Predictions Max            2309.3125
Q Predictions Min            15.214797
V Predictions Mean           1257.3213
V Predictions Std            983.0391
V Predictions Max            2297.362
V Predictions Min            23.736738
Log Pis Mean                 -4.235394
Log Pis Std                  6.9665065
Log Pis Max                  16.332771
Log Pis Min                  -14.650883
Policy mu Mean               0.25386548
Policy mu Std                0.75384146
Policy mu Max                2.9710464
Policy mu Min                -2.752844
Policy log std Mean          -0.28438592
Policy log std Std           0.1543063
Policy log std Max           0.009982556
Policy log std Min           -0.84428674
Z mean eval                  0.034908377
Z variance eval              0.038075097
total_rewards                [2965.72467809 5090.90139823 5133.09213506 5124.3301249  5134.78845808
 1276.00551554 5088.94156378 2281.34337548 1639.55547446 5075.95657241]
total_rewards_mean           3881.0639296045106
total_rewards_std            1557.022654046902
total_rewards_max            5134.788458081221
total_rewards_min            1276.005515542993
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               30.954234819859266
(Previous) Eval Time (s)     16.77423836896196
Sample Time (s)              19.689081653021276
Epoch Time (s)               67.4175548418425
Total Train Time (s)         11473.337475717999
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:26:55.403529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #210 | Epoch Duration: 72.79675889015198
2020-01-10 21:26:55.403742 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034958657
Z variance train             0.03807483
KL Divergence                5.790654
KL Loss                      0.57906544
QF Loss                      2178.9355
VF Loss                      558.839
Policy Loss                  -1315.4186
Q Predictions Mean           1309.7283
Q Predictions Std            977.60895
Q Predictions Max            2314.7832
Q Predictions Min            18.284634
V Predictions Mean           1315.019
V Predictions Std            973.79266
V Predictions Max            2306.6523
V Predictions Min            27.942986
Log Pis Mean                 -3.66768
Log Pis Std                  8.01057
Log Pis Max                  26.85854
Log Pis Min                  -12.970585
Policy mu Mean               0.26530844
Policy mu Std                0.7758993
Policy mu Max                3.1191027
Policy mu Min                -3.1370585
Policy log std Mean          -0.27964997
Policy log std Std           0.16217068
Policy log std Max           -0.04235001
Policy log std Min           -0.88149655
Z mean eval                  0.03256762
Z variance eval              0.03667327
total_rewards                [4212.8542962  5048.97188872 5160.28248781 2010.76381027 5073.46351285
 5059.27343629  996.09543607 1720.09491623 4824.59258316 1214.57973403]
total_rewards_mean           3532.0972101626694
total_rewards_std            1708.6236499046781
total_rewards_max            5160.28248781123
total_rewards_min            996.0954360654214
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               29.365848303306848
(Previous) Eval Time (s)     22.15313478279859
Sample Time (s)              18.95881540188566
Epoch Time (s)               70.4777984879911
Total Train Time (s)         11541.88062444143
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:28:03.960501 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #211 | Epoch Duration: 68.55655932426453
2020-01-10 21:28:03.960734 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032665353
Z variance train             0.03667303
KL Divergence                5.881998
KL Loss                      0.5881998
QF Loss                      1996.7922
VF Loss                      604.40784
Policy Loss                  -1330.3368
Q Predictions Mean           1325.6576
Q Predictions Std            959.3446
Q Predictions Max            2318.577
Q Predictions Min            14.925591
V Predictions Mean           1326.6272
V Predictions Std            949.4646
V Predictions Max            2304.9656
V Predictions Min            24.22055
Log Pis Mean                 -3.294355
Log Pis Std                  7.2534714
Log Pis Max                  17.331196
Log Pis Min                  -13.92623
Policy mu Mean               0.3132688
Policy mu Std                0.7774508
Policy mu Max                2.6111896
Policy mu Min                -2.8837886
Policy log std Mean          -0.29963493
Policy log std Std           0.16547021
Policy log std Max           -0.029281564
Policy log std Min           -1.0625368
Z mean eval                  0.032630812
Z variance eval              0.037827887
total_rewards                [4668.29613016 2679.58556881 1887.96204407 2810.37390194 5102.81103958
 2838.63523083 4311.18939985 2986.37680099 1506.92145244 2582.75527527]
total_rewards_mean           3137.4906843933086
total_rewards_std            1119.8240833011578
total_rewards_max            5102.811039582071
total_rewards_min            1506.9214524357446
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               30.287096947897226
(Previous) Eval Time (s)     20.23157817311585
Sample Time (s)              19.314047689549625
Epoch Time (s)               69.8327228105627
Total Train Time (s)         11609.048129312228
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:29:11.121329 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #212 | Epoch Duration: 67.16041135787964
2020-01-10 21:29:11.121546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032469183
Z variance train             0.0378138
KL Divergence                5.8127794
KL Loss                      0.58127797
QF Loss                      1549.5432
VF Loss                      459.5471
Policy Loss                  -1388.2756
Q Predictions Mean           1381.8162
Q Predictions Std            967.4202
Q Predictions Max            2319.3843
Q Predictions Min            11.90666
V Predictions Mean           1391.8976
V Predictions Std            963.92596
V Predictions Max            2321.7112
V Predictions Min            28.132542
Log Pis Mean                 -4.375554
Log Pis Std                  6.4867277
Log Pis Max                  17.753876
Log Pis Min                  -13.674035
Policy mu Mean               0.2922899
Policy mu Std                0.7240953
Policy mu Max                2.4227726
Policy mu Min                -2.8827932
Policy log std Mean          -0.28689995
Policy log std Std           0.1581551
Policy log std Max           -0.03489615
Policy log std Min           -0.8069431
Z mean eval                  0.03281153
Z variance eval              0.037087224
total_rewards                [2671.29481698 5064.2545023  5100.36826315 4775.47258172 5052.63579571
 5045.28660278 5116.00059052 5083.95464439 4686.30601143 5075.66485258]
total_rewards_mean           4767.1238661555135
total_rewards_std            712.3640146882216
total_rewards_max            5116.00059052362
total_rewards_min            2671.294816981269
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               29.99349836120382
(Previous) Eval Time (s)     17.558996026869863
Sample Time (s)              19.834889626596123
Epoch Time (s)               67.3873840146698
Total Train Time (s)         11687.34662578348
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:30:29.422726 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #213 | Epoch Duration: 78.30099606513977
2020-01-10 21:30:29.422959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032680914
Z variance train             0.03710053
KL Divergence                5.8657537
KL Loss                      0.5865754
QF Loss                      1078.0076
VF Loss                      338.67712
Policy Loss                  -1343.7698
Q Predictions Mean           1335.2876
Q Predictions Std            989.1167
Q Predictions Max            2308.6372
Q Predictions Min            14.801392
V Predictions Mean           1343.7899
V Predictions Std            986.04016
V Predictions Max            2313.5408
V Predictions Min            25.307026
Log Pis Mean                 -4.6113625
Log Pis Std                  6.5027814
Log Pis Max                  20.97939
Log Pis Min                  -15.605923
Policy mu Mean               0.28490645
Policy mu Std                0.7106172
Policy mu Max                3.098097
Policy mu Min                -3.1852903
Policy log std Mean          -0.2710302
Policy log std Std           0.1515628
Policy log std Max           -0.046487287
Policy log std Min           -0.8488173
Z mean eval                  0.030323222
Z variance eval              0.03743966
total_rewards                [1630.62601929 5141.58728487 4224.04688145 2880.00518059 5128.44097583
 5160.36274942 2423.32437973 2353.32691718 4359.69801995 5172.35269885]
total_rewards_mean           3847.3771107153234
total_rewards_std            1315.669222948168
total_rewards_max            5172.352698845361
total_rewards_min            1630.6260192924926
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               30.762075419072062
(Previous) Eval Time (s)     28.472283335402608
Sample Time (s)              19.717486616689712
Epoch Time (s)               78.95184537116438
Total Train Time (s)         11759.53820593888
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:31:41.617079 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #214 | Epoch Duration: 72.19393920898438
2020-01-10 21:31:41.617295 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030332819
Z variance train             0.037450787
KL Divergence                5.836515
KL Loss                      0.5836515
QF Loss                      1293.8826
VF Loss                      279.02866
Policy Loss                  -1447.7789
Q Predictions Mean           1448.7383
Q Predictions Std            976.9746
Q Predictions Max            2328.7493
Q Predictions Min            15.661137
V Predictions Mean           1448.7164
V Predictions Std            968.38055
V Predictions Max            2317.7166
V Predictions Min            27.032785
Log Pis Mean                 -3.9773407
Log Pis Std                  6.4547176
Log Pis Max                  22.18599
Log Pis Min                  -14.12631
Policy mu Mean               0.3377584
Policy mu Std                0.7417687
Policy mu Max                2.6416326
Policy mu Min                -2.8944962
Policy log std Mean          -0.29318428
Policy log std Std           0.15960516
Policy log std Max           -0.04639869
Policy log std Min           -0.88601947
Z mean eval                  0.03063156
Z variance eval              0.037537597
total_rewards                [5129.24735087 4893.93508427 5070.10054132 3293.24257141 5088.60018156
 1511.03702071 2065.70533821 5111.46000143 5101.54259472 1496.04639899]
total_rewards_mean           3876.091708348767
total_rewards_std            1529.882808038298
total_rewards_max            5129.24735087246
total_rewards_min            1496.0463989929642
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               30.94733469374478
(Previous) Eval Time (s)     21.714067931752652
Sample Time (s)              19.60673160245642
Epoch Time (s)               72.26813422795385
Total Train Time (s)         11832.185777908191
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:32:54.267570 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #215 | Epoch Duration: 72.65010285377502
2020-01-10 21:32:54.267778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03075192
Z variance train             0.037524458
KL Divergence                5.8263855
KL Loss                      0.58263856
QF Loss                      2417.0854
VF Loss                      498.46432
Policy Loss                  -1399.8876
Q Predictions Mean           1390.8179
Q Predictions Std            966.4675
Q Predictions Max            2331.316
Q Predictions Min            15.556598
V Predictions Mean           1387.613
V Predictions Std            958.3001
V Predictions Max            2321.634
V Predictions Min            25.984928
Log Pis Mean                 -3.143428
Log Pis Std                  7.042554
Log Pis Max                  20.373634
Log Pis Min                  -13.556747
Policy mu Mean               0.3208318
Policy mu Std                0.76232964
Policy mu Max                3.2481048
Policy mu Min                -2.7586038
Policy log std Mean          -0.2958434
Policy log std Std           0.15887192
Policy log std Max           0.062735125
Policy log std Min           -0.86422306
Z mean eval                  0.029311826
Z variance eval              0.037298083
total_rewards                [5167.24180912 5146.40687578  353.8914981  5134.44237141 4562.29546431
 3470.91362643 5131.73337885 4048.66890559 5033.42265646 5197.02133408]
total_rewards_mean           4324.603792011201
total_rewards_std            1434.7199306405964
total_rewards_max            5197.021334075556
total_rewards_min            353.8914980954427
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               31.793099138885736
(Previous) Eval Time (s)     22.09573476575315
Sample Time (s)              19.653300338424742
Epoch Time (s)               73.54213424306363
Total Train Time (s)         11908.41568608908
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:34:10.498987 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #216 | Epoch Duration: 76.23103618621826
2020-01-10 21:34:10.499145 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029335517
Z variance train             0.03730295
KL Divergence                5.8388605
KL Loss                      0.5838861
QF Loss                      1612.4746
VF Loss                      408.13037
Policy Loss                  -1455.164
Q Predictions Mean           1445.0942
Q Predictions Std            947.73566
Q Predictions Max            2327.682
Q Predictions Min            17.675545
V Predictions Mean           1446.7991
V Predictions Std            943.455
V Predictions Max            2333.025
V Predictions Min            25.472631
Log Pis Mean                 -3.451408
Log Pis Std                  6.7132025
Log Pis Max                  27.34129
Log Pis Min                  -14.453611
Policy mu Mean               0.33688346
Policy mu Std                0.7600541
Policy mu Max                2.8252296
Policy mu Min                -2.8859072
Policy log std Mean          -0.29975745
Policy log std Std           0.15860967
Policy log std Max           -0.033957735
Policy log std Min           -0.94958854
Z mean eval                  0.03184029
Z variance eval              0.038458645
total_rewards                [1411.81345717 5026.98118476 1762.70290984 1914.58610417 2051.29868086
 3061.62359399  875.11784571  885.95494445 1505.61047155 5077.20594904]
total_rewards_mean           2357.2895141526847
total_rewards_std            1471.2367549406317
total_rewards_max            5077.20594904381
total_rewards_min            875.117845708232
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               32.73581496393308
(Previous) Eval Time (s)     24.784341694787145
Sample Time (s)              19.42119406769052
Epoch Time (s)               76.94135072641075
Total Train Time (s)         11974.246831132565
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:35:16.332985 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #217 | Epoch Duration: 65.83371543884277
2020-01-10 21:35:16.333183 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03186757
Z variance train             0.038444474
KL Divergence                5.791271
KL Loss                      0.57912713
QF Loss                      1267.8069
VF Loss                      540.902
Policy Loss                  -1375.1865
Q Predictions Mean           1366.7683
Q Predictions Std            971.0588
Q Predictions Max            2341.2307
Q Predictions Min            17.053205
V Predictions Mean           1366.6539
V Predictions Std            961.7208
V Predictions Max            2336.7317
V Predictions Min            25.550304
Log Pis Mean                 -4.230542
Log Pis Std                  6.545982
Log Pis Max                  20.602318
Log Pis Min                  -13.000455
Policy mu Mean               0.30885404
Policy mu Std                0.7201469
Policy mu Max                2.9839551
Policy mu Min                -2.5131824
Policy log std Mean          -0.29334402
Policy log std Std           0.15690094
Policy log std Max           -0.03816256
Policy log std Min           -1.038948
Z mean eval                  0.032949157
Z variance eval              0.038509343
total_rewards                [5112.99625365 1373.75279527 5117.35940767 3365.63881363 5140.82183145
 2897.27803596 1984.52357797 1227.08229848 5206.77387689 1194.87968102]
total_rewards_mean           3262.1106571985615
total_rewards_std            1671.3983828397043
total_rewards_max            5206.773876891995
total_rewards_min            1194.8796810219812
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               29.709178410936147
(Previous) Eval Time (s)     13.676373626105487
Sample Time (s)              19.271276188548654
Epoch Time (s)               62.65682822559029
Total Train Time (s)         12041.855241945013
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:36:23.945195 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #218 | Epoch Duration: 67.61186170578003
2020-01-10 21:36:23.945440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03263161
Z variance train             0.038503714
KL Divergence                5.797838
KL Loss                      0.57978386
QF Loss                      1214.3235
VF Loss                      603.38214
Policy Loss                  -1408.8208
Q Predictions Mean           1408.5366
Q Predictions Std            991.3612
Q Predictions Max            2344.733
Q Predictions Min            17.010904
V Predictions Mean           1419.157
V Predictions Std            989.8941
V Predictions Max            2348.6292
V Predictions Min            27.752792
Log Pis Mean                 -4.455597
Log Pis Std                  6.30883
Log Pis Max                  18.06321
Log Pis Min                  -14.000421
Policy mu Mean               0.3080543
Policy mu Std                0.71556765
Policy mu Max                2.6761904
Policy mu Min                -2.7390878
Policy log std Mean          -0.2886587
Policy log std Std           0.16086419
Policy log std Max           -0.044519544
Policy log std Min           -0.9254381
Z mean eval                  0.032534502
Z variance eval              0.039104152
total_rewards                [2436.43780403 2797.42249835 1325.58755356 2959.42292135 1196.20718187
 1202.82482779 2025.15599931  953.94488485 1391.9093499  1811.56104929]
total_rewards_mean           1810.0474070308228
total_rewards_std            679.8958719262903
total_rewards_max            2959.4229213540443
total_rewards_min            953.9448848527992
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               29.272386563010514
(Previous) Eval Time (s)     18.631092065945268
Sample Time (s)              18.98176698666066
Epoch Time (s)               66.88524561561644
Total Train Time (s)         12100.504411782138
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:37:22.599373 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #219 | Epoch Duration: 58.65372371673584
2020-01-10 21:37:22.599666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03336223
Z variance train             0.03911986
KL Divergence                5.7702913
KL Loss                      0.57702917
QF Loss                      1254.4729
VF Loss                      928.39716
Policy Loss                  -1503.1128
Q Predictions Mean           1494.5886
Q Predictions Std            951.2321
Q Predictions Max            2347.779
Q Predictions Min            14.768613
V Predictions Mean           1490.5771
V Predictions Std            942.7031
V Predictions Max            2355.378
V Predictions Min            25.302753
Log Pis Mean                 -3.4629273
Log Pis Std                  6.4668655
Log Pis Max                  20.931908
Log Pis Min                  -15.134369
Policy mu Mean               0.30762044
Policy mu Std                0.7561257
Policy mu Max                2.7678533
Policy mu Min                -2.7279804
Policy log std Mean          -0.2921504
Policy log std Std           0.15335403
Policy log std Max           -0.008401409
Policy log std Min           -0.9407612
Z mean eval                  0.033749692
Z variance eval              0.038450975
total_rewards                [5158.4239215  5063.65747684 5028.11940697 2213.68481851 5049.33403465
 5042.91603806 3909.87956363 5106.56966142 5080.75856467 1630.35774395]
total_rewards_mean           4328.370123018367
total_rewards_std            1258.8738085981568
total_rewards_max            5158.423921498019
total_rewards_min            1630.357743945138
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               31.296680506318808
(Previous) Eval Time (s)     10.399283579085022
Sample Time (s)              19.938204342499375
Epoch Time (s)               61.634168427903205
Total Train Time (s)         12177.361021923833
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:38:39.457929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #220 | Epoch Duration: 76.85804033279419
2020-01-10 21:38:39.458120 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033633865
Z variance train             0.038463235
KL Divergence                5.8105507
KL Loss                      0.5810551
QF Loss                      1419.2617
VF Loss                      378.86246
Policy Loss                  -1442.8102
Q Predictions Mean           1439.1244
Q Predictions Std            958.02875
Q Predictions Max            2349.1614
Q Predictions Min            16.668022
V Predictions Mean           1441.7778
V Predictions Std            954.9035
V Predictions Max            2348.1772
V Predictions Min            25.252584
Log Pis Mean                 -3.6499655
Log Pis Std                  6.7096844
Log Pis Max                  23.367428
Log Pis Min                  -13.135724
Policy mu Mean               0.33246443
Policy mu Std                0.73420805
Policy mu Max                2.7258728
Policy mu Min                -3.0855663
Policy log std Mean          -0.29459882
Policy log std Std           0.1572883
Policy log std Max           -0.018537626
Policy log std Min           -0.8654705
Z mean eval                  0.03415552
Z variance eval              0.039584927
total_rewards                [5093.68112273 2089.05788793 5125.68868141 2733.99127289 1436.92648896
 5164.67949993 5093.00684584 3468.4452111  5107.16963574 5071.91108431]
total_rewards_mean           4038.4557730844
total_rewards_std            1395.7384922615465
total_rewards_max            5164.679499930603
total_rewards_min            1436.9264889586648
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               31.342354838270694
(Previous) Eval Time (s)     25.622821923345327
Sample Time (s)              19.63640833646059
Epoch Time (s)               76.60158509807661
Total Train Time (s)         12251.600540840998
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:39:53.700829 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #221 | Epoch Duration: 74.24254369735718
2020-01-10 21:39:53.701046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0340193
Z variance train             0.03956348
KL Divergence                5.7520404
KL Loss                      0.5752041
QF Loss                      1165.6418
VF Loss                      369.7165
Policy Loss                  -1396.5554
Q Predictions Mean           1392.1285
Q Predictions Std            998.4635
Q Predictions Max            2366.889
Q Predictions Min            16.20194
V Predictions Mean           1397.8462
V Predictions Std            993.67175
V Predictions Max            2357.72
V Predictions Min            28.5747
Log Pis Mean                 -4.400017
Log Pis Std                  6.7246413
Log Pis Max                  23.433918
Log Pis Min                  -14.824168
Policy mu Mean               0.33234158
Policy mu Std                0.6986633
Policy mu Max                2.649563
Policy mu Min                -3.2264583
Policy log std Mean          -0.28055325
Policy log std Std           0.15337689
Policy log std Max           -0.05122745
Policy log std Min           -0.8630383
Z mean eval                  0.034213014
Z variance eval              0.038455784
total_rewards                [1153.87234481 5092.07048221 5125.58496719 1369.7781046  4536.52642021
 2122.14864918 5149.3287277   774.77436028 1021.94592193 3797.72429957]
total_rewards_mean           3014.3754277675152
total_rewards_std            1794.7271694860876
total_rewards_max            5149.328727696921
total_rewards_min            774.7743602787531
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               30.31411249190569
(Previous) Eval Time (s)     23.26345787709579
Sample Time (s)              19.529111430514604
Epoch Time (s)               73.10668179951608
Total Train Time (s)         12319.553529313765
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:41:01.655111 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #222 | Epoch Duration: 67.95391249656677
2020-01-10 21:41:01.655258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03419198
Z variance train             0.038467158
KL Divergence                5.8309927
KL Loss                      0.5830993
QF Loss                      2432.7139
VF Loss                      600.6559
Policy Loss                  -1464.7794
Q Predictions Mean           1457.4141
Q Predictions Std            963.52246
Q Predictions Max            2361.3882
Q Predictions Min            16.12774
V Predictions Mean           1469.5422
V Predictions Std            962.885
V Predictions Max            2357.656
V Predictions Min            27.820335
Log Pis Mean                 -3.529057
Log Pis Std                  6.5600157
Log Pis Max                  24.085508
Log Pis Min                  -12.9020405
Policy mu Mean               0.26559472
Policy mu Std                0.79449815
Policy mu Max                2.7954812
Policy mu Min                -2.57893
Policy log std Mean          -0.29591846
Policy log std Std           0.15613224
Policy log std Max           -0.06360232
Policy log std Min           -0.8545892
Z mean eval                  0.035459388
Z variance eval              0.03895615
total_rewards                [5147.49769682 4494.93969776 5161.83334479 5154.02203269 5092.87781124
 1285.33201224 3497.73111163 1857.17406041 3069.8292623  1338.54410591]
total_rewards_mean           3609.9781135777944
total_rewards_std            1551.7253441852818
total_rewards_max            5161.833344786496
total_rewards_min            1285.33201223877
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               30.741760935168713
(Previous) Eval Time (s)     18.110354244709015
Sample Time (s)              19.223109069745988
Epoch Time (s)               68.07522424962372
Total Train Time (s)         12390.809492504224
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:42:12.915413 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #223 | Epoch Duration: 71.26002359390259
2020-01-10 21:42:12.915625 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035560302
Z variance train             0.0389627
KL Divergence                5.80883
KL Loss                      0.58088297
QF Loss                      1474.2556
VF Loss                      680.0696
Policy Loss                  -1485.5643
Q Predictions Mean           1477.7574
Q Predictions Std            944.5654
Q Predictions Max            2355.528
Q Predictions Min            16.944304
V Predictions Mean           1494.8455
V Predictions Std            946.8842
V Predictions Max            2363.817
V Predictions Min            29.856136
Log Pis Mean                 -3.3865004
Log Pis Std                  6.613677
Log Pis Max                  21.368397
Log Pis Min                  -15.658547
Policy mu Mean               0.33597004
Policy mu Std                0.76645494
Policy mu Max                3.2025514
Policy mu Min                -2.9538767
Policy log std Mean          -0.30532354
Policy log std Std           0.15727651
Policy log std Max           -0.053314403
Policy log std Min           -1.1676152
Z mean eval                  0.035852566
Z variance eval              0.039399207
total_rewards                [2133.01109818  925.58630441 1918.4283109  2705.40094105 5356.70040288
 4448.96947232 3184.775272   5299.91503116 5137.83753606 1542.82586295]
total_rewards_mean           3265.345023193423
total_rewards_std            1589.9174260261252
total_rewards_max            5356.700402880825
total_rewards_min            925.5863044143023
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               30.228503271006048
(Previous) Eval Time (s)     21.294833038933575
Sample Time (s)              19.100492233410478
Epoch Time (s)               70.6238285433501
Total Train Time (s)         12458.479822502937
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:43:20.587789 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #224 | Epoch Duration: 67.67200422286987
2020-01-10 21:43:20.588248 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03613829
Z variance train             0.039394453
KL Divergence                5.789915
KL Loss                      0.57899153
QF Loss                      1068.3994
VF Loss                      391.88138
Policy Loss                  -1434.3608
Q Predictions Mean           1424.1355
Q Predictions Std            1015.32056
Q Predictions Max            2366.8394
Q Predictions Min            14.841655
V Predictions Mean           1426.7333
V Predictions Std            1008.2951
V Predictions Max            2363.1777
V Predictions Min            26.69734
Log Pis Mean                 -4.4822054
Log Pis Std                  6.673278
Log Pis Max                  18.623453
Log Pis Min                  -14.110594
Policy mu Mean               0.28248787
Policy mu Std                0.7320216
Policy mu Max                3.0089958
Policy mu Min                -3.9620743
Policy log std Mean          -0.2825534
Policy log std Std           0.15332268
Policy log std Max           0.011157393
Policy log std Min           -0.853279
Z mean eval                  0.03718474
Z variance eval              0.036363907
total_rewards                [5288.84494816 1111.43030249 1067.60653836 2656.83811727 2577.15862936
  738.79727253 5210.74840745 2023.41500996 5149.42074493 5150.23349334]
total_rewards_mean           3097.4493463861277
total_rewards_std            1814.9082757596718
total_rewards_max            5288.844948160463
total_rewards_min            738.7972725263286
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               31.392721224110574
(Previous) Eval Time (s)     18.34264274314046
Sample Time (s)              19.445488347206265
Epoch Time (s)               69.1808523144573
Total Train Time (s)         12527.249011011329
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:44:29.361046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #225 | Epoch Duration: 68.77257466316223
2020-01-10 21:44:29.361323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #225 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037443023
Z variance train             0.03636397
KL Divergence                5.9587684
KL Loss                      0.5958769
QF Loss                      1156.8265
VF Loss                      961.9318
Policy Loss                  -1501.7439
Q Predictions Mean           1497.4447
Q Predictions Std            993.90656
Q Predictions Max            2386.7705
Q Predictions Min            14.813761
V Predictions Mean           1488.9036
V Predictions Std            978.4125
V Predictions Max            2360.0432
V Predictions Min            28.254065
Log Pis Mean                 -3.52598
Log Pis Std                  6.807019
Log Pis Max                  25.566418
Log Pis Min                  -14.882128
Policy mu Mean               0.27841058
Policy mu Std                0.75206363
Policy mu Max                3.022871
Policy mu Min                -2.9091737
Policy log std Mean          -0.29289556
Policy log std Std           0.15713243
Policy log std Max           -0.052422874
Policy log std Min           -0.87174994
Z mean eval                  0.03860988
Z variance eval              0.038716868
total_rewards                [5283.63068268 5273.74513574 5263.70231411 3382.22390297 5241.3164022
  666.07400778 5275.70143983 2847.37561622 5230.28409502 5247.96023526]
total_rewards_mean           4371.201383180406
total_rewards_std            1501.7892776696897
total_rewards_max            5283.630682679448
total_rewards_min            666.0740077798473
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               28.30432291282341
(Previous) Eval Time (s)     17.934049931820482
Sample Time (s)              20.56921824021265
Epoch Time (s)               66.80759108485654
Total Train Time (s)         12600.259936752263
Epoch                        226
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:45:42.375741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #226 | Epoch Duration: 73.01420855522156
2020-01-10 21:45:42.376026 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038794223
Z variance train             0.03870794
KL Divergence                5.861021
KL Loss                      0.5861021
QF Loss                      1287.7378
VF Loss                      523.36096
Policy Loss                  -1529.7524
Q Predictions Mean           1520.2213
Q Predictions Std            968.5761
Q Predictions Max            2389.7344
Q Predictions Min            17.189987
V Predictions Mean           1521.5833
V Predictions Std            962.9405
V Predictions Max            2383.0479
V Predictions Min            28.345337
Log Pis Mean                 -3.8384905
Log Pis Std                  6.399178
Log Pis Max                  21.093752
Log Pis Min                  -13.47272
Policy mu Mean               0.31823146
Policy mu Std                0.76317847
Policy mu Max                2.750542
Policy mu Min                -3.3047845
Policy log std Mean          -0.30263585
Policy log std Std           0.15793803
Policy log std Max           -0.023307487
Policy log std Min           -0.87449354
Z mean eval                  0.041429907
Z variance eval              0.037809618
total_rewards                [4756.16219262 3793.49333988 1592.26127236 1251.13766771 1935.50983976
 1719.32060087 1537.53105425 1405.15507433 1530.37899213 1865.57816258]
total_rewards_mean           2138.65281964795
total_rewards_std            1106.2151259872116
total_rewards_max            4756.162192620002
total_rewards_min            1251.1376677107407
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               28.0862593697384
(Previous) Eval Time (s)     24.140299579128623
Sample Time (s)              20.20744275767356
Epoch Time (s)               72.43400170654058
Total Train Time (s)         12660.528202068992
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:46:42.647876 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #227 | Epoch Duration: 60.271628618240356
2020-01-10 21:46:42.648135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04114164
Z variance train             0.037807036
KL Divergence                5.88801
KL Loss                      0.588801
QF Loss                      1266.7744
VF Loss                      532.97864
Policy Loss                  -1498.8855
Q Predictions Mean           1496.9741
Q Predictions Std            980.22577
Q Predictions Max            2385.7717
Q Predictions Min            13.828944
V Predictions Mean           1506.7539
V Predictions Std            975.74365
V Predictions Max            2386.1338
V Predictions Min            27.009495
Log Pis Mean                 -3.9864783
Log Pis Std                  6.7444844
Log Pis Max                  23.068798
Log Pis Min                  -16.489006
Policy mu Mean               0.3187378
Policy mu Std                0.74985254
Policy mu Max                2.6227412
Policy mu Min                -3.2016332
Policy log std Mean          -0.2852603
Policy log std Std           0.15439525
Policy log std Max           -0.019187935
Policy log std Min           -0.97180796
Z mean eval                  0.041716237
Z variance eval              0.039573997
total_rewards                [1633.71014625 5056.72078075 1989.98946201 5142.08358682 4937.75434165
 1033.1178831  5068.41240226 2123.53742463 3514.19841612 2257.40293633]
total_rewards_mean           3275.692737993277
total_rewards_std            1563.0518522652899
total_rewards_max            5142.083586824413
total_rewards_min            1033.1178831007549
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               30.117431653663516
(Previous) Eval Time (s)     11.977574851829559
Sample Time (s)              19.394325049594045
Epoch Time (s)               61.48933155508712
Total Train Time (s)         12728.78063135501
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:47:50.904635 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #228 | Epoch Duration: 68.25629663467407
2020-01-10 21:47:50.904897 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041416984
Z variance train             0.039574213
KL Divergence                5.7701035
KL Loss                      0.57701033
QF Loss                      1738.7914
VF Loss                      601.6638
Policy Loss                  -1588.1663
Q Predictions Mean           1589.4303
Q Predictions Std            934.09705
Q Predictions Max            2409.998
Q Predictions Min            17.253706
V Predictions Mean           1594.6611
V Predictions Std            931.93634
V Predictions Max            2406.9163
V Predictions Min            27.908245
Log Pis Mean                 -3.2776666
Log Pis Std                  6.1412487
Log Pis Max                  16.787449
Log Pis Min                  -12.892127
Policy mu Mean               0.30673274
Policy mu Std                0.77476275
Policy mu Max                2.8437543
Policy mu Min                -2.8044488
Policy log std Mean          -0.3037455
Policy log std Std           0.1563517
Policy log std Max           -0.017057009
Policy log std Min           -0.93594015
Z mean eval                  0.04329015
Z variance eval              0.039760817
total_rewards                [2863.15317669 5207.25181884 2143.96441692 5268.88600141  680.88694135
 2933.8534036  3859.37548957  545.20760115 1845.71804726 1742.73182879]
total_rewards_mean           2709.1028725584956
total_rewards_std            1580.6770590323615
total_rewards_max            5268.886001410332
total_rewards_min            545.2076011495234
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               29.639224193058908
(Previous) Eval Time (s)     18.74424656573683
Sample Time (s)              20.156762095168233
Epoch Time (s)               68.54023285396397
Total Train Time (s)         12793.44053101074
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:48:55.565570 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #229 | Epoch Duration: 64.66049575805664
2020-01-10 21:48:55.565762 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04337622
Z variance train             0.03976754
KL Divergence                5.7624607
KL Loss                      0.5762461
QF Loss                      1745.1875
VF Loss                      544.93195
Policy Loss                  -1621.1045
Q Predictions Mean           1621.3145
Q Predictions Std            959.8568
Q Predictions Max            2408.9775
Q Predictions Min            15.62228
V Predictions Mean           1619.4153
V Predictions Std            956.3047
V Predictions Max            2395.7063
V Predictions Min            27.316645
Log Pis Mean                 -3.279817
Log Pis Std                  6.502512
Log Pis Max                  21.280605
Log Pis Min                  -15.4568
Policy mu Mean               0.31394726
Policy mu Std                0.75875896
Policy mu Max                3.181608
Policy mu Min                -2.6288304
Policy log std Mean          -0.299186
Policy log std Std           0.14860435
Policy log std Max           -0.07744649
Policy log std Min           -1.0568589
Z mean eval                  0.04172145
Z variance eval              0.038029544
total_rewards                [2477.74907422 5125.30221918 3821.20340228 5145.36453428 4919.71258238
 5000.47984715 3709.30315632 5046.18669337 4983.73281397 2150.69318996]
total_rewards_mean           4237.972751310987
total_rewards_std            1085.1073283127378
total_rewards_max            5145.3645342783175
total_rewards_min            2150.6931899637884
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               31.077676753047854
(Previous) Eval Time (s)     14.86417895089835
Sample Time (s)              19.44311852939427
Epoch Time (s)               65.38497423334047
Total Train Time (s)         12869.126217152923
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:50:11.255730 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #230 | Epoch Duration: 75.6897931098938
2020-01-10 21:50:11.256024 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041842643
Z variance train             0.038022593
KL Divergence                5.872095
KL Loss                      0.5872095
QF Loss                      1669.2642
VF Loss                      729.87335
Policy Loss                  -1531.0288
Q Predictions Mean           1520.3427
Q Predictions Std            991.5613
Q Predictions Max            2403.2314
Q Predictions Min            16.16765
V Predictions Mean           1522.8901
V Predictions Std            985.54376
V Predictions Max            2402.158
V Predictions Min            25.228325
Log Pis Mean                 -3.154763
Log Pis Std                  7.6438813
Log Pis Max                  33.255318
Log Pis Min                  -12.38895
Policy mu Mean               0.2573355
Policy mu Std                0.7835338
Policy mu Max                2.9312727
Policy mu Min                -2.9024246
Policy log std Mean          -0.297984
Policy log std Std           0.15587008
Policy log std Max           0.017841324
Policy log std Min           -0.8722164
Z mean eval                  0.04023288
Z variance eval              0.040519025
total_rewards                [1357.18882852 5146.45447611 1512.14233874 5138.38766044 5239.23592314
 5140.74093866 5236.89633747 1244.11446475 2181.07795163 4061.75225778]
total_rewards_mean           3625.799117723453
total_rewards_std            1722.150165165957
total_rewards_max            5239.235923138009
total_rewards_min            1244.114464749598
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               30.267913268413395
(Previous) Eval Time (s)     25.168670741375536
Sample Time (s)              19.692120105959475
Epoch Time (s)               75.1287041157484
Total Train Time (s)         12939.69354567537
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:51:21.826173 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #231 | Epoch Duration: 70.56992030143738
2020-01-10 21:51:21.826437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040188417
Z variance train             0.040529262
KL Divergence                5.742132
KL Loss                      0.5742132
QF Loss                      1446.9865
VF Loss                      400.33542
Policy Loss                  -1663.6642
Q Predictions Mean           1660.0194
Q Predictions Std            936.62994
Q Predictions Max            2411.1206
Q Predictions Min            16.85568
V Predictions Mean           1662.3768
V Predictions Std            931.0865
V Predictions Max            2409.662
V Predictions Min            28.589409
Log Pis Mean                 -3.2788033
Log Pis Std                  6.664256
Log Pis Max                  22.381767
Log Pis Min                  -13.389063
Policy mu Mean               0.30280694
Policy mu Std                0.7837962
Policy mu Max                3.2878098
Policy mu Min                -3.315475
Policy log std Mean          -0.29035947
Policy log std Std           0.1546486
Policy log std Max           -0.016770594
Policy log std Min           -1.1424499
Z mean eval                  0.042657714
Z variance eval              0.040649477
total_rewards                [2090.36574365 3573.05687621  963.42598389 4444.95871278 3426.23224675
 3624.25715672 4398.05330821 3517.52723744 1500.57859145 3923.04289238]
total_rewards_mean           3146.1498749486145
total_rewards_std            1143.3197877471216
total_rewards_max            4444.958712780444
total_rewards_min            963.4259838889342
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               28.749567646998912
(Previous) Eval Time (s)     20.6095730853267
Sample Time (s)              20.281919309403747
Epoch Time (s)               69.64106004172936
Total Train Time (s)         13007.869964275043
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:52:30.007454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #232 | Epoch Duration: 68.18071460723877
2020-01-10 21:52:30.007890 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042455636
Z variance train             0.040646855
KL Divergence                5.7175837
KL Loss                      0.5717584
QF Loss                      1947.4712
VF Loss                      427.30484
Policy Loss                  -1490.1118
Q Predictions Mean           1486.1936
Q Predictions Std            985.0719
Q Predictions Max            2421.948
Q Predictions Min            16.645847
V Predictions Mean           1493.1696
V Predictions Std            981.83386
V Predictions Max            2417.257
V Predictions Min            29.646788
Log Pis Mean                 -3.6271899
Log Pis Std                  6.666305
Log Pis Max                  24.71354
Log Pis Min                  -13.041916
Policy mu Mean               0.34375548
Policy mu Std                0.7429153
Policy mu Max                2.996075
Policy mu Min                -3.359384
Policy log std Mean          -0.28556144
Policy log std Std           0.1537377
Policy log std Max           0.013138846
Policy log std Min           -0.9393882
Z mean eval                  0.0427872
Z variance eval              0.038833234
total_rewards                [2390.42479617 3625.69027175 2109.8790196  5265.75041348 5271.74189523
 2370.69315614 4484.23142325 1551.61329423 3500.44635504 3216.88416556]
total_rewards_mean           3378.735479045259
total_rewards_std            1241.3579465802766
total_rewards_max            5271.741895231759
total_rewards_min            1551.6132942340707
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               29.580155069939792
(Previous) Eval Time (s)     19.148853308986872
Sample Time (s)              19.529262833297253
Epoch Time (s)               68.25827121222392
Total Train Time (s)         13075.968511351384
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:53:38.107370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #233 | Epoch Duration: 68.09926700592041
2020-01-10 21:53:38.107588 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04283346
Z variance train             0.038828783
KL Divergence                5.8137875
KL Loss                      0.58137876
QF Loss                      1713.5913
VF Loss                      420.0228
Policy Loss                  -1598.7625
Q Predictions Mean           1590.6721
Q Predictions Std            958.38745
Q Predictions Max            2413.5757
Q Predictions Min            16.4549
V Predictions Mean           1594.2753
V Predictions Std            954.58044
V Predictions Max            2422.983
V Predictions Min            29.738127
Log Pis Mean                 -2.9916306
Log Pis Std                  6.482249
Log Pis Max                  22.403671
Log Pis Min                  -13.839676
Policy mu Mean               0.35142305
Policy mu Std                0.7680625
Policy mu Max                2.6372848
Policy mu Min                -3.1501255
Policy log std Mean          -0.29536474
Policy log std Std           0.1583001
Policy log std Max           -0.051561706
Policy log std Min           -1.0315367
Z mean eval                  0.043143902
Z variance eval              0.037853707
total_rewards                [5132.76656538 2703.52774142 5134.2898527  5137.137708   1464.68554246
 2677.40998481 5145.18459965 5173.36343333 5222.04661915 4534.60939904]
total_rewards_mean           4232.502144593217
total_rewards_std            1328.4435246999712
total_rewards_max            5222.046619146478
total_rewards_min            1464.6855424601802
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               28.644945167936385
(Previous) Eval Time (s)     18.989557108841836
Sample Time (s)              19.947077014949173
Epoch Time (s)               67.5815792917274
Total Train Time (s)         13148.968990134541
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:54:51.112868 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #234 | Epoch Duration: 73.00494003295898
2020-01-10 21:54:51.113270 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04327449
Z variance train             0.037861478
KL Divergence                5.886643
KL Loss                      0.5886643
QF Loss                      1108.7185
VF Loss                      471.36063
Policy Loss                  -1495.1938
Q Predictions Mean           1485.345
Q Predictions Std            1008.0291
Q Predictions Max            2408.6128
Q Predictions Min            17.034163
V Predictions Mean           1492.4512
V Predictions Std            1008.4327
V Predictions Max            2411.1038
V Predictions Min            29.656738
Log Pis Mean                 -4.014985
Log Pis Std                  6.7577276
Log Pis Max                  25.47107
Log Pis Min                  -14.516317
Policy mu Mean               0.29396933
Policy mu Std                0.73465896
Policy mu Max                2.8793066
Policy mu Min                -2.8309264
Policy log std Mean          -0.27707455
Policy log std Std           0.14900438
Policy log std Max           -0.035037093
Policy log std Min           -0.9712986
Z mean eval                  0.042620696
Z variance eval              0.03831544
total_rewards                [1443.84808639 3842.76650483 1424.77243659 5341.48801583 2408.74269567
 2626.36663506 2034.57537455 1440.271731   4302.46204148 3274.96313765]
total_rewards_mean           2814.0256659064135
total_rewards_std            1279.6837032517492
total_rewards_max            5341.4880158303995
total_rewards_min            1424.7724365931986
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               29.770895558875054
(Previous) Eval Time (s)     24.412604053970426
Sample Time (s)              19.305047106929123
Epoch Time (s)               73.4885467197746
Total Train Time (s)         13213.608381623402
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:55:55.755379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #235 | Epoch Duration: 64.64187359809875
2020-01-10 21:55:55.755631 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042543914
Z variance train             0.03831149
KL Divergence                5.87084
KL Loss                      0.587084
QF Loss                      2329.335
VF Loss                      545.8301
Policy Loss                  -1525.8525
Q Predictions Mean           1520.8394
Q Predictions Std            1002.01196
Q Predictions Max            2408.7654
Q Predictions Min            8.226335
V Predictions Mean           1527.3104
V Predictions Std            1000.07666
V Predictions Max            2417.3154
V Predictions Min            25.87277
Log Pis Mean                 -3.5384488
Log Pis Std                  6.417698
Log Pis Max                  23.442068
Log Pis Min                  -12.782278
Policy mu Mean               0.31794268
Policy mu Std                0.73554456
Policy mu Max                2.552212
Policy mu Min                -2.8094902
Policy log std Mean          -0.29392198
Policy log std Std           0.15348719
Policy log std Max           0.021442324
Policy log std Min           -0.9243922
Z mean eval                  0.043948617
Z variance eval              0.0376643
total_rewards                [1314.31547513 1735.69781345 5261.66989271 1675.91689342 3481.01514584
 2115.42576354 1373.80356707 2903.71566433 2813.92003958 5191.67999749]
total_rewards_mean           2786.716025257683
total_rewards_std            1391.3719200630173
total_rewards_max            5261.669892713714
total_rewards_min            1314.3154751275622
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               31.841576118953526
(Previous) Eval Time (s)     15.565617760643363
Sample Time (s)              19.137880694586784
Epoch Time (s)               66.54507457418367
Total Train Time (s)         13280.53639140958
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:57:02.688855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #236 | Epoch Duration: 66.93289971351624
2020-01-10 21:57:02.689294 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043821607
Z variance train             0.037655454
KL Divergence                5.925145
KL Loss                      0.5925145
QF Loss                      1335.959
VF Loss                      484.8392
Policy Loss                  -1665.4695
Q Predictions Mean           1661.9496
Q Predictions Std            944.25165
Q Predictions Max            2415.441
Q Predictions Min            17.001232
V Predictions Mean           1662.6045
V Predictions Std            939.9301
V Predictions Max            2413.2415
V Predictions Min            27.369448
Log Pis Mean                 -2.7813482
Log Pis Std                  6.450047
Log Pis Max                  21.723705
Log Pis Min                  -14.941367
Policy mu Mean               0.31723407
Policy mu Std                0.7857352
Policy mu Max                3.0118754
Policy mu Min                -2.9078865
Policy log std Mean          -0.3081323
Policy log std Std           0.15634352
Policy log std Max           -0.004076615
Policy log std Min           -0.9268413
Z mean eval                  0.044158477
Z variance eval              0.039968718
total_rewards                [5183.08849315 5170.82506761 5220.78015909 5270.73493358 3438.03695289
 2016.67316148 2555.42391257 3761.68807456 1009.14890869 2303.6160785 ]
total_rewards_mean           3593.0015742110327
total_rewards_std            1497.832204364293
total_rewards_max            5270.734933577232
total_rewards_min            1009.1489086873326
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               30.582031853031367
(Previous) Eval Time (s)     15.953113955911249
Sample Time (s)              20.29176701279357
Epoch Time (s)               66.82691282173619
Total Train Time (s)         13351.777677750215
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:58:13.931874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #237 | Epoch Duration: 71.2423164844513
2020-01-10 21:58:13.932102 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043875795
Z variance train             0.039953582
KL Divergence                5.8270416
KL Loss                      0.5827042
QF Loss                      1743.6748
VF Loss                      1129.7224
Policy Loss                  -1582.2479
Q Predictions Mean           1580.7903
Q Predictions Std            962.01044
Q Predictions Max            2418.702
Q Predictions Min            17.643684
V Predictions Mean           1606.8608
V Predictions Std            968.1076
V Predictions Max            2445.4756
V Predictions Min            26.792366
Log Pis Mean                 -3.2538877
Log Pis Std                  6.7608633
Log Pis Max                  22.46505
Log Pis Min                  -19.327307
Policy mu Mean               0.3363918
Policy mu Std                0.77667147
Policy mu Max                2.7232478
Policy mu Min                -3.0225487
Policy log std Mean          -0.3031584
Policy log std Std           0.15940835
Policy log std Max           -0.045643896
Policy log std Min           -1.1371409
Z mean eval                  0.04637776
Z variance eval              0.040578138
total_rewards                [1897.92705371  773.30246871 5225.05195645 2177.40273039 4309.26320382
 3231.29490523  958.16577483 5255.59461227 5290.10782457 2742.10825984]
total_rewards_mean           3186.0218789814535
total_rewards_std            1667.0270328598751
total_rewards_max            5290.107824566182
total_rewards_min            773.3024687117309
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               31.31967031210661
(Previous) Eval Time (s)     20.36819818802178
Sample Time (s)              18.879204785916954
Epoch Time (s)               70.56707328604534
Total Train Time (s)         13420.864945566282
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 21:59:23.024653 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #238 | Epoch Duration: 69.09226417541504
2020-01-10 21:59:23.025036 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046513647
Z variance train             0.040572084
KL Divergence                5.820902
KL Loss                      0.5820902
QF Loss                      1294.3695
VF Loss                      525.6453
Policy Loss                  -1644.544
Q Predictions Mean           1642.5991
Q Predictions Std            975.58435
Q Predictions Max            2450.7368
Q Predictions Min            14.634184
V Predictions Mean           1633.2694
V Predictions Std            962.9903
V Predictions Max            2436.3418
V Predictions Min            23.07191
Log Pis Mean                 -3.713776
Log Pis Std                  6.1974363
Log Pis Max                  25.4208
Log Pis Min                  -14.607997
Policy mu Mean               0.3036946
Policy mu Std                0.7553506
Policy mu Max                2.9565077
Policy mu Min                -3.9598165
Policy log std Mean          -0.29365957
Policy log std Std           0.15953441
Policy log std Max           -0.033338055
Policy log std Min           -1.0771701
Z mean eval                  0.045347545
Z variance eval              0.039846197
total_rewards                [4484.89115975 1222.89696598 3900.34843607 1384.7437836  1886.46276557
 5244.82623609 2235.59679799 2705.83516625 5227.63657556 1897.4647681 ]
total_rewards_mean           3019.0702654975626
total_rewards_std            1480.102834543786
total_rewards_max            5244.826236094519
total_rewards_min            1222.8969659813351
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               30.774870521388948
(Previous) Eval Time (s)     18.89309736387804
Sample Time (s)              19.442824194207788
Epoch Time (s)               69.11079207947478
Total Train Time (s)         13488.436322812922
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:00:30.596912 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #239 | Epoch Duration: 67.57167625427246
2020-01-10 22:00:30.597077 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04527057
Z variance train             0.03984988
KL Divergence                5.8570766
KL Loss                      0.58570766
QF Loss                      1087.882
VF Loss                      603.45605
Policy Loss                  -1682.5745
Q Predictions Mean           1678.5328
Q Predictions Std            956.79517
Q Predictions Max            2432.975
Q Predictions Min            16.210093
V Predictions Mean           1676.0576
V Predictions Std            948.695
V Predictions Max            2429.653
V Predictions Min            27.050735
Log Pis Mean                 -3.3321335
Log Pis Std                  6.570448
Log Pis Max                  23.473885
Log Pis Min                  -13.897055
Policy mu Mean               0.32188204
Policy mu Std                0.7566287
Policy mu Max                3.6403105
Policy mu Min                -3.6421013
Policy log std Mean          -0.29369622
Policy log std Std           0.14965896
Policy log std Max           -0.020262897
Policy log std Min           -0.8869981
Z mean eval                  0.04475643
Z variance eval              0.038338043
total_rewards                [2889.14984224 4376.39796841 1985.32432077 2850.7076727  2642.90135848
 3946.41316781 5368.90540478 1366.78549875 3254.59470683 1339.18039612]
total_rewards_mean           3002.036033689607
total_rewards_std            1228.1706954995336
total_rewards_max            5368.905404779954
total_rewards_min            1339.1803961230987
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               30.081444647163153
(Previous) Eval Time (s)     17.353658710140735
Sample Time (s)              19.500678778626025
Epoch Time (s)               66.93578213592991
Total Train Time (s)         13555.047901172657
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:01:37.213851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #240 | Epoch Duration: 66.61660122871399
2020-01-10 22:01:37.214133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044927895
Z variance train             0.03833783
KL Divergence                5.9332266
KL Loss                      0.5933227
QF Loss                      2239.6367
VF Loss                      335.6813
Policy Loss                  -1706.2567
Q Predictions Mean           1705.6985
Q Predictions Std            926.97516
Q Predictions Max            2450.8728
Q Predictions Min            14.285945
V Predictions Mean           1705.3918
V Predictions Std            920.62225
V Predictions Max            2443.694
V Predictions Min            22.86319
Log Pis Mean                 -3.1112819
Log Pis Std                  6.6514883
Log Pis Max                  23.430208
Log Pis Min                  -14.318382
Policy mu Mean               0.33873
Policy mu Std                0.7756234
Policy mu Max                2.708753
Policy mu Min                -3.75276
Policy log std Mean          -0.30005696
Policy log std Std           0.1549625
Policy log std Max           -0.03856919
Policy log std Min           -0.9113892
Z mean eval                  0.045292784
Z variance eval              0.039564814
total_rewards                [2781.7555893  3070.68867658 4080.69418102 4030.41650397 2099.89894673
 3938.74597983 5067.67016996 2760.71649882 5216.45331354 1523.50051208]
total_rewards_mean           3457.0540371814677
total_rewards_std            1153.6880056001767
total_rewards_max            5216.453313539683
total_rewards_min            1523.5005120758742
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               30.321414501871914
(Previous) Eval Time (s)     17.03412104398012
Sample Time (s)              19.167701745405793
Epoch Time (s)               66.52323729125783
Total Train Time (s)         13624.724613187369
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:02:46.895506 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #241 | Epoch Duration: 69.68105244636536
2020-01-10 22:02:46.895925 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045434203
Z variance train             0.039558988
KL Divergence                5.863311
KL Loss                      0.58633107
QF Loss                      1056.2969
VF Loss                      330.2472
Policy Loss                  -1664.5319
Q Predictions Mean           1662.8822
Q Predictions Std            958.9718
Q Predictions Max            2444.7056
Q Predictions Min            15.1735
V Predictions Mean           1662.29
V Predictions Std            951.5273
V Predictions Max            2431.9026
V Predictions Min            25.301132
Log Pis Mean                 -3.2497504
Log Pis Std                  6.4140406
Log Pis Max                  20.12231
Log Pis Min                  -17.318867
Policy mu Mean               0.2953539
Policy mu Std                0.77725524
Policy mu Max                2.5743387
Policy mu Min                -3.266532
Policy log std Mean          -0.2959111
Policy log std Std           0.15395571
Policy log std Max           0.007016659
Policy log std Min           -1.0112762
Z mean eval                  0.04577956
Z variance eval              0.038640104
total_rewards                [1135.94374626 5258.1489151  4686.21614312 1134.4562766  5378.15032793
  623.21531409 5360.40968209 1228.15282574 4394.17675881 2168.05912017]
total_rewards_mean           3136.692910991973
total_rewards_std            1932.9305768693432
total_rewards_max            5378.150327927619
total_rewards_min            623.2153140880083
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               30.37555193528533
(Previous) Eval Time (s)     20.191615296062082
Sample Time (s)              20.05687533179298
Epoch Time (s)               70.62404256314039
Total Train Time (s)         13692.204081282951
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:03:54.379477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #242 | Epoch Duration: 67.48331117630005
2020-01-10 22:03:54.379748 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04562955
Z variance train             0.03864049
KL Divergence                5.932513
KL Loss                      0.59325135
QF Loss                      1453.6565
VF Loss                      503.9274
Policy Loss                  -1706.019
Q Predictions Mean           1700.9241
Q Predictions Std            940.7881
Q Predictions Max            2438.5703
Q Predictions Min            15.133312
V Predictions Mean           1705.0281
V Predictions Std            936.5085
V Predictions Max            2437.0173
V Predictions Min            25.778357
Log Pis Mean                 -3.4155447
Log Pis Std                  6.441983
Log Pis Max                  20.2522
Log Pis Min                  -14.850185
Policy mu Mean               0.3059894
Policy mu Std                0.7594782
Policy mu Max                2.879174
Policy mu Min                -2.6025727
Policy log std Mean          -0.29443783
Policy log std Std           0.15658809
Policy log std Max           0.0075283945
Policy log std Min           -1.1025577
Z mean eval                  0.04349626
Z variance eval              0.037821613
total_rewards                [5243.98480448 5290.10130312 4504.15797994 5292.1263381  2499.43381814
 5264.8140902  5192.77749328 5280.98810951 5285.84476901 4441.11568461]
total_rewards_mean           4829.534439041166
total_rewards_std            837.7012298078092
total_rewards_max            5292.126338104394
total_rewards_min            2499.4338181426015
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               30.20021388027817
(Previous) Eval Time (s)     17.050550816114992
Sample Time (s)              19.94926033169031
Epoch Time (s)               67.20002502808347
Total Train Time (s)         13769.06113910349
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:05:11.238814 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #243 | Epoch Duration: 76.85882830619812
2020-01-10 22:05:11.239108 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04327079
Z variance train             0.037829034
KL Divergence                5.9555297
KL Loss                      0.595553
QF Loss                      1690.2639
VF Loss                      478.35004
Policy Loss                  -1645.6556
Q Predictions Mean           1633.6082
Q Predictions Std            958.4972
Q Predictions Max            2441.339
Q Predictions Min            13.565253
V Predictions Mean           1646.709
V Predictions Std            954.7697
V Predictions Max            2443.7517
V Predictions Min            26.7785
Log Pis Mean                 -3.0800507
Log Pis Std                  6.9854755
Log Pis Max                  25.562168
Log Pis Min                  -13.380584
Policy mu Mean               0.3237093
Policy mu Std                0.7819935
Policy mu Max                2.8286502
Policy mu Min                -2.8954072
Policy log std Mean          -0.30844715
Policy log std Std           0.1525531
Policy log std Max           -0.07624387
Policy log std Min           -0.9644981
Z mean eval                  0.044371977
Z variance eval              0.036339767
total_rewards                [2426.33908304 3686.92118632 4455.40169998 4010.24038198 1023.52688282
 5289.93988574 2532.01088659 5339.77255964 3270.49686696 5236.33948693]
total_rewards_mean           3727.0988919993697
total_rewards_std            1362.7619848777833
total_rewards_max            5339.772559643362
total_rewards_min            1023.5268828153584
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               30.651755258906633
(Previous) Eval Time (s)     26.70901366136968
Sample Time (s)              20.12237021373585
Epoch Time (s)               77.48313913401216
Total Train Time (s)         13841.198112062644
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:06:23.377119 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #244 | Epoch Duration: 72.13780450820923
2020-01-10 22:06:23.377328 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04412715
Z variance train             0.036349412
KL Divergence                6.0389633
KL Loss                      0.6038963
QF Loss                      1481.2988
VF Loss                      612.80206
Policy Loss                  -1798.2487
Q Predictions Mean           1792.2644
Q Predictions Std            866.3468
Q Predictions Max            2453.5483
Q Predictions Min            18.87435
V Predictions Mean           1802.7842
V Predictions Std            864.02686
V Predictions Max            2454.2148
V Predictions Min            29.121511
Log Pis Mean                 -2.6200128
Log Pis Std                  6.432815
Log Pis Max                  18.956963
Log Pis Min                  -15.050383
Policy mu Mean               0.3547756
Policy mu Std                0.8037954
Policy mu Max                2.8416414
Policy mu Min                -2.8915381
Policy log std Mean          -0.3188039
Policy log std Std           0.15706092
Policy log std Max           -0.015537277
Policy log std Min           -0.9404345
Z mean eval                  0.045015495
Z variance eval              0.03697781
total_rewards                [5218.01934824 5151.30234476 5342.22821186 4370.43507335 5228.23944223
 5244.13916388 4672.4981347   864.42240354 5189.25046974 1748.75767638]
total_rewards_mean           4302.929226867747
total_rewards_std            1537.9586939742478
total_rewards_max            5342.228211858284
total_rewards_min            864.4224035396473
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               30.57841501617804
(Previous) Eval Time (s)     21.363318449817598
Sample Time (s)              18.60569280060008
Epoch Time (s)               70.54742626659572
Total Train Time (s)         13915.456295217853
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:07:37.643919 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #245 | Epoch Duration: 74.26627135276794
2020-01-10 22:07:37.644393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #245 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04492306
Z variance train             0.03699801
KL Divergence                5.9921
KL Loss                      0.59920996
QF Loss                      2139.1675
VF Loss                      882.31604
Policy Loss                  -1707.5817
Q Predictions Mean           1699.9503
Q Predictions Std            953.6073
Q Predictions Max            2455.17
Q Predictions Min            16.391329
V Predictions Mean           1700.6396
V Predictions Std            947.44794
V Predictions Max            2446.3474
V Predictions Min            27.799845
Log Pis Mean                 -3.5368612
Log Pis Std                  7.068317
Log Pis Max                  23.643353
Log Pis Min                  -16.086409
Policy mu Mean               0.29995593
Policy mu Std                0.77308726
Policy mu Max                2.9719582
Policy mu Min                -3.652371
Policy log std Mean          -0.3014482
Policy log std Std           0.15371743
Policy log std Max           -0.03788416
Policy log std Min           -1.005395
Z mean eval                  0.04640891
Z variance eval              0.036916714
total_rewards                [5276.25382893 4967.71890594 2316.61276888 5011.41829906 3033.0684043
 2296.05801192 3973.94187085 5171.51520117 5238.95279266 5279.37295382]
total_rewards_mean           4256.491303753672
total_rewards_std            1189.432068379026
total_rewards_max            5279.372953822226
total_rewards_min            2296.0580119246897
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               29.946553009096533
(Previous) Eval Time (s)     25.081869488116354
Sample Time (s)              19.87256888858974
Epoch Time (s)               74.90099138580263
Total Train Time (s)         13989.465692387894
Epoch                        246
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:08:51.651822 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #246 | Epoch Duration: 74.00717306137085
2020-01-10 22:08:51.652001 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046064086
Z variance train             0.03691939
KL Divergence                5.9326386
KL Loss                      0.59326386
QF Loss                      1523.6062
VF Loss                      808.0415
Policy Loss                  -1741.1743
Q Predictions Mean           1739.5073
Q Predictions Std            910.6313
Q Predictions Max            2453.0261
Q Predictions Min            15.760167
V Predictions Mean           1758.9463
V Predictions Std            913.0559
V Predictions Max            2484.9514
V Predictions Min            25.383781
Log Pis Mean                 -3.3718305
Log Pis Std                  6.020606
Log Pis Max                  19.54868
Log Pis Min                  -13.926701
Policy mu Mean               0.34523422
Policy mu Std                0.7617092
Policy mu Max                3.1993613
Policy mu Min                -3.9551792
Policy log std Mean          -0.29805622
Policy log std Std           0.15440224
Policy log std Max           -0.026248157
Policy log std Min           -1.0095205
Z mean eval                  0.04546443
Z variance eval              0.036716558
total_rewards                [1718.04546332 3070.39190304  998.50319144 1128.52842087 2047.09514745
  787.8101547  1174.88224416 5230.15049617  721.1916276  2044.70176794]
total_rewards_mean           1892.1300416681574
total_rewards_std            1307.4784622623456
total_rewards_max            5230.150496173585
total_rewards_min            721.1916275983261
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               31.76973367901519
(Previous) Eval Time (s)     24.18775484384969
Sample Time (s)              19.511304075364023
Epoch Time (s)               75.4687925982289
Total Train Time (s)         14050.93508171197
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:09:53.127221 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #247 | Epoch Duration: 61.47506237030029
2020-01-10 22:09:53.127498 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04581988
Z variance train             0.03672193
KL Divergence                5.975382
KL Loss                      0.5975382
QF Loss                      1198.0244
VF Loss                      374.5726
Policy Loss                  -1733.8723
Q Predictions Mean           1724.9792
Q Predictions Std            936.00146
Q Predictions Max            2456.008
Q Predictions Min            19.437023
V Predictions Mean           1732.9602
V Predictions Std            934.85333
V Predictions Max            2464.8384
V Predictions Min            29.991783
Log Pis Mean                 -3.0970876
Log Pis Std                  6.8120875
Log Pis Max                  25.19485
Log Pis Min                  -13.684394
Policy mu Mean               0.3604987
Policy mu Std                0.7727656
Policy mu Max                3.1676953
Policy mu Min                -2.8177977
Policy log std Mean          -0.3088559
Policy log std Std           0.15774293
Policy log std Max           -0.07928275
Policy log std Min           -0.9605954
Z mean eval                  0.046831805
Z variance eval              0.03558085
total_rewards                [1384.51722588 2616.95364047 2793.85010807 2656.46314419 1364.99908051
 5252.99113024 5242.06045531 4862.36014157 1191.24090289 1341.99500345]
total_rewards_mean           2870.743083256132
total_rewards_std            1581.6117858948605
total_rewards_max            5252.991130235653
total_rewards_min            1191.2409028890982
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               30.12672841688618
(Previous) Eval Time (s)     10.193648112937808
Sample Time (s)              19.114916518796235
Epoch Time (s)               59.435293048620224
Total Train Time (s)         14116.41764147114
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:10:58.610125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #248 | Epoch Duration: 65.48244094848633
2020-01-10 22:10:58.610274 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046554897
Z variance train             0.035571538
KL Divergence                6.0253572
KL Loss                      0.6025357
QF Loss                      1602.7
VF Loss                      586.4351
Policy Loss                  -1754.3069
Q Predictions Mean           1748.6409
Q Predictions Std            929.45776
Q Predictions Max            2461.7964
Q Predictions Min            13.964859
V Predictions Mean           1762.1101
V Predictions Std            930.1514
V Predictions Max            2471.1033
V Predictions Min            25.537764
Log Pis Mean                 -2.7603226
Log Pis Std                  6.422924
Log Pis Max                  20.211105
Log Pis Min                  -13.73385
Policy mu Mean               0.35632354
Policy mu Std                0.75813913
Policy mu Max                3.234362
Policy mu Min                -2.3376467
Policy log std Mean          -0.2973547
Policy log std Std           0.15473503
Policy log std Max           -0.0152064115
Policy log std Min           -0.9519964
Z mean eval                  0.046688564
Z variance eval              0.03430043
total_rewards                [5142.81988064 5265.40438889 1633.74868661 5211.53813893 5255.31716944
 2887.19061943 2512.64105095 5199.65308805 4455.237435   5190.31531229]
total_rewards_mean           4275.386577021645
total_rewards_std            1315.505209888566
total_rewards_max            5265.404388888151
total_rewards_min            1633.7486866082174
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               29.371140057221055
(Previous) Eval Time (s)     16.240527171175927
Sample Time (s)              19.24593177717179
Epoch Time (s)               64.85759900556877
Total Train Time (s)         14190.125231180806
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:12:12.323562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #249 | Epoch Duration: 73.71313619613647
2020-01-10 22:12:12.323873 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #249 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046754077
Z variance train             0.034292366
KL Divergence                6.1428137
KL Loss                      0.61428136
QF Loss                      1903.627
VF Loss                      379.3749
Policy Loss                  -1860.4832
Q Predictions Mean           1854.6348
Q Predictions Std            879.6615
Q Predictions Max            2480.1792
Q Predictions Min            17.403282
V Predictions Mean           1863.3464
V Predictions Std            878.705
V Predictions Max            2484.4404
V Predictions Min            27.337915
Log Pis Mean                 -2.7288198
Log Pis Std                  6.527014
Log Pis Max                  22.897055
Log Pis Min                  -13.151428
Policy mu Mean               0.34842408
Policy mu Std                0.7860995
Policy mu Max                3.1163158
Policy mu Min                -2.8047447
Policy log std Mean          -0.3140061
Policy log std Std           0.15236847
Policy log std Max           -0.01208473
Policy log std Min           -0.93897015
Z mean eval                  0.04579317
Z variance eval              0.033884473
total_rewards                [1394.00766681 5047.49323189 5270.56373778 5138.57832229 5162.2688888
 4385.29667941 2258.35992477 2721.56760088 5141.37103456 3748.77016262]
total_rewards_mean           4026.8277249807084
total_rewards_std            1353.6912488628484
total_rewards_max            5270.563737777231
total_rewards_min            1394.0076668059153
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               31.790105491876602
(Previous) Eval Time (s)     25.095712705980986
Sample Time (s)              19.647457882761955
Epoch Time (s)               76.53327608061954
Total Train Time (s)         14264.665131893475
Epoch                        250
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:13:26.865879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #250 | Epoch Duration: 74.54178285598755
2020-01-10 22:13:26.866081 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045623858
Z variance train             0.033894785
KL Divergence                6.1558523
KL Loss                      0.61558527
QF Loss                      1710.2336
VF Loss                      361.06653
Policy Loss                  -1784.0363
Q Predictions Mean           1778.1917
Q Predictions Std            896.9643
Q Predictions Max            2461.4346
Q Predictions Min            14.732462
V Predictions Mean           1782.8613
V Predictions Std            892.12463
V Predictions Max            2466.1753
V Predictions Min            25.332363
Log Pis Mean                 -2.7491992
Log Pis Std                  7.082111
Log Pis Max                  30.908258
Log Pis Min                  -16.8527
Policy mu Mean               0.3140578
Policy mu Std                0.8107396
Policy mu Max                2.87881
Policy mu Min                -2.9531424
Policy log std Mean          -0.30580458
Policy log std Std           0.1537823
Policy log std Max           0.04372719
Policy log std Min           -1.0664663
Z mean eval                  0.044591263
Z variance eval              0.034462996
total_rewards                [2080.89540118 2894.19615223 2090.05484742 1991.42977669 1892.53297321
 1342.22202856 1334.1340486  3804.38308119 5249.51240472 5284.88052542]
total_rewards_mean           2796.424123923466
total_rewards_std            1412.960297475169
total_rewards_max            5284.8805254245735
total_rewards_min            1334.13404860209
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               28.222252022940665
(Previous) Eval Time (s)     23.103889661375433
Sample Time (s)              19.23341958038509
Epoch Time (s)               70.55956126470119
Total Train Time (s)         14327.45534059126
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:14:29.662052 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #251 | Epoch Duration: 62.795774936676025
2020-01-10 22:14:29.662366 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #251 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044818144
Z variance train             0.034459654
KL Divergence                6.0978155
KL Loss                      0.60978156
QF Loss                      1058.9283
VF Loss                      614.0307
Policy Loss                  -1705.3489
Q Predictions Mean           1696.9106
Q Predictions Std            978.75165
Q Predictions Max            2474.0063
Q Predictions Min            16.814224
V Predictions Mean           1695.2417
V Predictions Std            969.2077
V Predictions Max            2465.9482
V Predictions Min            26.549055
Log Pis Mean                 -3.9659479
Log Pis Std                  5.986618
Log Pis Max                  21.344643
Log Pis Min                  -13.07359
Policy mu Mean               0.3725936
Policy mu Std                0.7235718
Policy mu Max                2.6060684
Policy mu Min                -2.3018093
Policy log std Mean          -0.29067448
Policy log std Std           0.14848271
Policy log std Max           0.03213519
Policy log std Min           -1.0268118
Z mean eval                  0.044258893
Z variance eval              0.033232305
total_rewards                [5330.15141849 5293.0352161  5239.65257818 2784.87353834 1267.2000971
 1440.35951912 1205.44006349 3754.90219987 3483.48330005 3024.03382672]
total_rewards_mean           3282.3131757462847
total_rewards_std            1562.455191846432
total_rewards_max            5330.151418487032
total_rewards_min            1205.440063492427
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               30.876704288180918
(Previous) Eval Time (s)     15.33976936712861
Sample Time (s)              19.559536036103964
Epoch Time (s)               65.77600969141349
Total Train Time (s)         14396.77089978708
Epoch                        252
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:15:38.981268 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #252 | Epoch Duration: 69.31858921051025
2020-01-10 22:15:38.981634 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044175196
Z variance train             0.033225782
KL Divergence                6.1790385
KL Loss                      0.6179039
QF Loss                      1427.3219
VF Loss                      360.81097
Policy Loss                  -1821.9916
Q Predictions Mean           1812.6599
Q Predictions Std            914.45013
Q Predictions Max            2464.6785
Q Predictions Min            15.0691395
V Predictions Mean           1821.2812
V Predictions Std            911.1789
V Predictions Max            2472.4954
V Predictions Min            25.386642
Log Pis Mean                 -3.0150561
Log Pis Std                  6.2315335
Log Pis Max                  31.035069
Log Pis Min                  -13.827909
Policy mu Mean               0.33886814
Policy mu Std                0.7559966
Policy mu Max                3.5295281
Policy mu Min                -2.7726538
Policy log std Mean          -0.3051104
Policy log std Std           0.1515225
Policy log std Max           -0.054875724
Policy log std Min           -0.9234431
Z mean eval                  0.045944367
Z variance eval              0.03443531
total_rewards                [2203.19466655 4636.20117098 5209.39097987 4307.906785   5182.53440017
 2401.17435377 3400.7368075  3834.97233727 1235.612242    759.7555548 ]
total_rewards_mean           3317.1479297910955
total_rewards_std            1516.899148528742
total_rewards_max            5209.390979872892
total_rewards_min            759.7555547988683
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               30.79924609605223
(Previous) Eval Time (s)     18.88205445976928
Sample Time (s)              19.264038195833564
Epoch Time (s)               68.94533875165507
Total Train Time (s)         14465.652959780302
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:16:47.865787 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #253 | Epoch Duration: 68.88395500183105
2020-01-10 22:16:47.866017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046253733
Z variance train             0.034434512
KL Divergence                6.078804
KL Loss                      0.6078804
QF Loss                      1858.918
VF Loss                      936.557
Policy Loss                  -1823.6176
Q Predictions Mean           1817.2068
Q Predictions Std            909.0657
Q Predictions Max            2481.0315
Q Predictions Min            15.995248
V Predictions Mean           1811.3593
V Predictions Std            898.2057
V Predictions Max            2452.583
V Predictions Min            27.289915
Log Pis Mean                 -2.685443
Log Pis Std                  6.8130164
Log Pis Max                  23.209583
Log Pis Min                  -12.637444
Policy mu Mean               0.34285596
Policy mu Std                0.80039585
Policy mu Max                3.3318913
Policy mu Min                -3.6413052
Policy log std Mean          -0.30653518
Policy log std Std           0.15200202
Policy log std Max           0.0037908852
Policy log std Min           -1.0844762
Z mean eval                  0.04602558
Z variance eval              0.032309048
total_rewards                [1898.14119928 1443.36340187 1533.28968514 3872.53934587 5205.99066467
 4958.11733289 2897.86993136 5208.02711663 3539.10404766 5184.19056597]
total_rewards_mean           3574.06332913445
total_rewards_std            1479.9338335867083
total_rewards_max            5208.027116634063
total_rewards_min            1443.3634018735627
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               30.035377531778067
(Previous) Eval Time (s)     18.8203620351851
Sample Time (s)              18.972718944773078
Epoch Time (s)               67.82845851173624
Total Train Time (s)         14535.045235555153
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:17:57.266027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #254 | Epoch Duration: 69.39970016479492
2020-01-10 22:17:57.266447 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046014126
Z variance train             0.032304734
KL Divergence                6.223476
KL Loss                      0.6223476
QF Loss                      1557.6404
VF Loss                      480.7534
Policy Loss                  -1844.4645
Q Predictions Mean           1836.4132
Q Predictions Std            933.05475
Q Predictions Max            2486.9407
Q Predictions Min            16.487167
V Predictions Mean           1839.1277
V Predictions Std            926.37244
V Predictions Max            2488.3457
V Predictions Min            25.495955
Log Pis Mean                 -2.8759449
Log Pis Std                  6.8093266
Log Pis Max                  38.512352
Log Pis Min                  -13.77673
Policy mu Mean               0.34383988
Policy mu Std                0.76097256
Policy mu Max                2.9155068
Policy mu Min                -3.2717953
Policy log std Mean          -0.30609614
Policy log std Std           0.15036976
Policy log std Max           -0.087230235
Policy log std Min           -0.985015
Z mean eval                  0.044054195
Z variance eval              0.033514693
total_rewards                [4732.55262728 4952.79573654 5265.64426891 5220.00384232 5184.04860323
 5246.19140329 1868.79262042 5288.57045028 5310.07837762 1470.00659514]
total_rewards_mean           4453.868452503377
total_rewards_std            1405.3236968381955
total_rewards_max            5310.078377624134
total_rewards_min            1470.0065951350996
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               31.768336253706366
(Previous) Eval Time (s)     20.391266179736704
Sample Time (s)              19.205735445022583
Epoch Time (s)               71.36533787846565
Total Train Time (s)         14612.064283619635
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:19:14.287312 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #255 | Epoch Duration: 77.02061700820923
2020-01-10 22:19:14.287603 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04431633
Z variance train             0.03351134
KL Divergence                6.119444
KL Loss                      0.6119444
QF Loss                      1748.3262
VF Loss                      484.07776
Policy Loss                  -1805.3829
Q Predictions Mean           1800.0009
Q Predictions Std            918.8822
Q Predictions Max            2484.1082
Q Predictions Min            14.966358
V Predictions Mean           1811.0614
V Predictions Std            917.53357
V Predictions Max            2489.369
V Predictions Min            27.471846
Log Pis Mean                 -3.6570828
Log Pis Std                  6.1612163
Log Pis Max                  21.75326
Log Pis Min                  -13.416044
Policy mu Mean               0.3223109
Policy mu Std                0.7761507
Policy mu Max                2.9204192
Policy mu Min                -3.0661263
Policy log std Mean          -0.29611433
Policy log std Std           0.14725862
Policy log std Max           -0.03791789
Policy log std Min           -0.8945288
Z mean eval                  0.04385542
Z variance eval              0.031601645
total_rewards                [2904.65066804 3125.71781501 5094.80676535 4413.07561584 3809.23424811
 4160.34861946 5094.90483236 5129.32314593 1333.3140762  5176.65204362]
total_rewards_mean           4024.2027829914928
total_rewards_std            1198.3133783997794
total_rewards_max            5176.652043624012
total_rewards_min            1333.3140761968195
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               32.103923671878874
(Previous) Eval Time (s)     26.046258277259767
Sample Time (s)              19.461076219566166
Epoch Time (s)               77.61125816870481
Total Train Time (s)         14686.921096454374
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:20:29.147204 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #256 | Epoch Duration: 74.85939407348633
2020-01-10 22:20:29.147430 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043710016
Z variance train             0.03159497
KL Divergence                6.2534013
KL Loss                      0.62534016
QF Loss                      1205.1654
VF Loss                      403.20496
Policy Loss                  -1820.0815
Q Predictions Mean           1818.3351
Q Predictions Std            929.63525
Q Predictions Max            2488.3716
Q Predictions Min            19.945396
V Predictions Mean           1826.1924
V Predictions Std            927.408
V Predictions Max            2480.6233
V Predictions Min            28.121801
Log Pis Mean                 -3.3737993
Log Pis Std                  5.867406
Log Pis Max                  13.632038
Log Pis Min                  -15.941832
Policy mu Mean               0.3562775
Policy mu Std                0.7379507
Policy mu Max                2.9309576
Policy mu Min                -2.4914498
Policy log std Mean          -0.29863736
Policy log std Std           0.15077083
Policy log std Max           -0.021593593
Policy log std Min           -0.9979993
Z mean eval                  0.04120574
Z variance eval              0.030811321
total_rewards                [3268.13710959 5116.52221848 5294.84442482 5208.27716746 2748.14536669
 5182.14745563 2061.71714409 5157.48809737 3784.52013836 2422.80025378]
total_rewards_mean           4024.459937626837
total_rewards_std            1245.316844510809
total_rewards_max            5294.844424815217
total_rewards_min            2061.717144094493
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               31.458914621267468
(Previous) Eval Time (s)     23.294073538854718
Sample Time (s)              19.640184436924756
Epoch Time (s)               74.39317259704694
Total Train Time (s)         14762.018059502821
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:21:44.245847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #257 | Epoch Duration: 75.09825778007507
2020-01-10 22:21:44.246044 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04101197
Z variance train             0.03079904
KL Divergence                6.3096447
KL Loss                      0.63096446
QF Loss                      999.1875
VF Loss                      548.29083
Policy Loss                  -1840.6609
Q Predictions Mean           1836.6284
Q Predictions Std            931.47235
Q Predictions Max            2495.9458
Q Predictions Min            17.939491
V Predictions Mean           1845.868
V Predictions Std            925.52313
V Predictions Max            2495.9705
V Predictions Min            31.606459
Log Pis Mean                 -3.071632
Log Pis Std                  6.379184
Log Pis Max                  21.2416
Log Pis Min                  -13.381122
Policy mu Mean               0.38136813
Policy mu Std                0.7412515
Policy mu Max                2.69709
Policy mu Min                -3.2570143
Policy log std Mean          -0.2974301
Policy log std Std           0.15170571
Policy log std Max           -0.03524535
Policy log std Min           -1.042486
Z mean eval                  0.04182426
Z variance eval              0.030714069
total_rewards                [1542.15794396 4903.53285032 3376.54541528 5228.09616683 5164.73648788
 3927.15368501 2460.78527161 5216.08620682 1098.01665942 1288.86148193]
total_rewards_mean           3420.597216906129
total_rewards_std            1624.1595929933728
total_rewards_max            5228.096166831481
total_rewards_min            1098.0166594187074
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               30.27634391700849
(Previous) Eval Time (s)     23.998848831281066
Sample Time (s)              19.994435489177704
Epoch Time (s)               74.26962823746726
Total Train Time (s)         14832.348294549622
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:22:54.582461 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #258 | Epoch Duration: 70.33623480796814
2020-01-10 22:22:54.582785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #258 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041293696
Z variance train             0.030712962
KL Divergence                6.3411255
KL Loss                      0.63411254
QF Loss                      1359.3671
VF Loss                      530.0421
Policy Loss                  -1896.3707
Q Predictions Mean           1897.5348
Q Predictions Std            877.3312
Q Predictions Max            2489.4812
Q Predictions Min            16.925127
V Predictions Mean           1905.0789
V Predictions Std            875.62006
V Predictions Max            2492.4219
V Predictions Min            29.576591
Log Pis Mean                 -3.0263424
Log Pis Std                  5.93422
Log Pis Max                  28.623425
Log Pis Min                  -13.73077
Policy mu Mean               0.3251373
Policy mu Std                0.76819086
Policy mu Max                2.7731519
Policy mu Min                -2.5458965
Policy log std Mean          -0.31194228
Policy log std Std           0.15331608
Policy log std Max           -0.006794527
Policy log std Min           -1.0107476
Z mean eval                  0.041611694
Z variance eval              0.030490357
total_rewards                [5178.31346283 5108.57027022 1524.48079854 5177.91863423 5199.4748723
 2725.84327193 5183.83731183 1979.08736197 5196.74212571 5039.85927598]
total_rewards_mean           4231.41273855343
total_rewards_std            1437.3166933005625
total_rewards_max            5199.474872301378
total_rewards_min            1524.4807985384539
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               30.204966506920755
(Previous) Eval Time (s)     20.065080446191132
Sample Time (s)              20.206059756223112
Epoch Time (s)               70.476106709335
Total Train Time (s)         14906.852315116674
Epoch                        259
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:24:09.091542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #259 | Epoch Duration: 74.50849628448486
2020-01-10 22:24:09.091864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04173519
Z variance train             0.030472586
KL Divergence                6.367944
KL Loss                      0.6367944
QF Loss                      1626.5078
VF Loss                      504.5596
Policy Loss                  -1927.2882
Q Predictions Mean           1929.107
Q Predictions Std            877.95123
Q Predictions Max            2512.216
Q Predictions Min            15.914051
V Predictions Mean           1915.6162
V Predictions Std            868.5833
V Predictions Max            2495.3557
V Predictions Min            27.458162
Log Pis Mean                 -3.1916986
Log Pis Std                  6.0786867
Log Pis Max                  21.369635
Log Pis Min                  -14.952079
Policy mu Mean               0.2862917
Policy mu Std                0.7903441
Policy mu Max                3.122334
Policy mu Min                -2.2015603
Policy log std Mean          -0.3167186
Policy log std Std           0.14719148
Policy log std Max           -0.04700531
Policy log std Min           -0.9220248
Z mean eval                  0.038581025
Z variance eval              0.031028977
total_rewards                [ 962.68008895 1656.74676776 5217.44977693 1539.86929772 4730.33442562
 5240.38889594 2180.32432948 2433.21900024 5224.87254041 5177.26713676]
total_rewards_mean           3436.315225981171
total_rewards_std            1726.192794114774
total_rewards_max            5240.388895935765
total_rewards_min            962.6800889478767
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               29.47041170904413
(Previous) Eval Time (s)     24.09714180417359
Sample Time (s)              19.51555730542168
Epoch Time (s)               73.0831108186394
Total Train Time (s)         14975.608168225735
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:25:17.853075 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #260 | Epoch Duration: 68.76094508171082
2020-01-10 22:25:17.853410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038439054
Z variance train             0.031029422
KL Divergence                6.314392
KL Loss                      0.6314392
QF Loss                      1418.4246
VF Loss                      1024.3496
Policy Loss                  -1872.9685
Q Predictions Mean           1871.3838
Q Predictions Std            900.4298
Q Predictions Max            2518.7952
Q Predictions Min            15.848248
V Predictions Mean           1891.2725
V Predictions Std            904.56964
V Predictions Max            2522.8162
V Predictions Min            23.96138
Log Pis Mean                 -2.414671
Log Pis Std                  6.8753676
Log Pis Max                  25.876331
Log Pis Min                  -12.43674
Policy mu Mean               0.36983916
Policy mu Std                0.7854666
Policy mu Max                2.7676477
Policy mu Min                -3.8854153
Policy log std Mean          -0.30961215
Policy log std Std           0.15432563
Policy log std Max           -0.010918781
Policy log std Min           -1.1902467
Z mean eval                  0.040639475
Z variance eval              0.03147713
total_rewards                [5202.15324496 1478.90738176 2880.97123391 1427.08058383 3938.78570536
 2184.10154819 1081.96780154 2486.15539882 2678.90765448 5220.737257  ]
total_rewards_mean           2857.9767809839855
total_rewards_std            1413.3083877486667
total_rewards_max            5220.73725699595
total_rewards_min            1081.967801536436
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               31.20113766985014
(Previous) Eval Time (s)     19.77465305617079
Sample Time (s)              19.115757818799466
Epoch Time (s)               70.0915485448204
Total Train Time (s)         15042.585458472371
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:26:24.835751 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #261 | Epoch Duration: 66.98209404945374
2020-01-10 22:26:24.836084 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04036647
Z variance train             0.03146959
KL Divergence                6.253211
KL Loss                      0.6253211
QF Loss                      1631.7635
VF Loss                      417.3072
Policy Loss                  -1843.2556
Q Predictions Mean           1835.3877
Q Predictions Std            917.59
Q Predictions Max            2507.0503
Q Predictions Min            21.880936
V Predictions Mean           1849.2603
V Predictions Std            916.17975
V Predictions Max            2518.4673
V Predictions Min            31.639845
Log Pis Mean                 -3.7142694
Log Pis Std                  6.2527113
Log Pis Max                  22.560453
Log Pis Min                  -13.557387
Policy mu Mean               0.35883877
Policy mu Std                0.74494356
Policy mu Max                3.203988
Policy mu Min                -3.6197784
Policy log std Mean          -0.29366338
Policy log std Std           0.14722922
Policy log std Max           -0.045606382
Policy log std Min           -1.0855813
Z mean eval                  0.03815492
Z variance eval              0.031136533
total_rewards                [5264.82429792 3470.2608192  5264.16533361 5223.50102613 5200.92941879
 2610.95021934 1435.2636643  5266.86134872 1954.32762656 5197.13967898]
total_rewards_mean           4088.8223433550384
total_rewards_std            1485.5638172156396
total_rewards_max            5266.861348716067
total_rewards_min            1435.2636642997732
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               31.160232258960605
(Previous) Eval Time (s)     16.66487690899521
Sample Time (s)              20.142131824512035
Epoch Time (s)               67.96724099246785
Total Train Time (s)         15117.134228212759
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:27:39.406571 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #262 | Epoch Duration: 74.57023119926453
2020-01-10 22:27:39.406887 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03800435
Z variance train             0.031151915
KL Divergence                6.2770405
KL Loss                      0.6277041
QF Loss                      1258.3636
VF Loss                      737.46924
Policy Loss                  -1883.408
Q Predictions Mean           1887.2439
Q Predictions Std            882.5871
Q Predictions Max            2504.4646
Q Predictions Min            14.495511
V Predictions Mean           1900.1685
V Predictions Std            881.8643
V Predictions Max            2513.0823
V Predictions Min            26.181963
Log Pis Mean                 -3.1167402
Log Pis Std                  5.7148237
Log Pis Max                  16.088875
Log Pis Min                  -12.683647
Policy mu Mean               0.38080087
Policy mu Std                0.7469894
Policy mu Max                3.009706
Policy mu Min                -3.3601878
Policy log std Mean          -0.3018028
Policy log std Std           0.15499967
Policy log std Max           0.084134266
Policy log std Min           -0.9685974
Z mean eval                  0.039289284
Z variance eval              0.031441897
total_rewards                [5195.97941845 5334.58024026 5304.94529176 2350.79921037 4875.42711244
 1591.81777822 2191.66561504 5226.49679967 2248.27309768 3610.30377261]
total_rewards_mean           3793.028833649279
total_rewards_std            1475.3419328726447
total_rewards_max            5334.580240256119
total_rewards_min            1591.8177782186108
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               33.005044838413596
(Previous) Eval Time (s)     23.267531509976834
Sample Time (s)              20.4632630571723
Epoch Time (s)               76.73583940556273
Total Train Time (s)         15192.226301939227
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:28:54.484644 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #263 | Epoch Duration: 75.07752752304077
2020-01-10 22:28:54.484902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039381366
Z variance train             0.03142719
KL Divergence                6.2727323
KL Loss                      0.62727326
QF Loss                      792.4442
VF Loss                      564.4058
Policy Loss                  -1971.0239
Q Predictions Mean           1967.5295
Q Predictions Std            856.6935
Q Predictions Max            2512.1802
Q Predictions Min            21.744602
V Predictions Mean           1969.6255
V Predictions Std            852.5861
V Predictions Max            2513.8171
V Predictions Min            30.128517
Log Pis Mean                 -3.0577424
Log Pis Std                  6.063567
Log Pis Max                  30.93778
Log Pis Min                  -13.288755
Policy mu Mean               0.36825538
Policy mu Std                0.7486817
Policy mu Max                2.9041185
Policy mu Min                -2.7671363
Policy log std Mean          -0.3108548
Policy log std Std           0.14647594
Policy log std Max           -0.036517493
Policy log std Min           -0.9118347
Z mean eval                  0.034986086
Z variance eval              0.030952599
total_rewards                [1922.49253988 5251.57118992 5258.38474148 1287.56277628  857.97311722
 1475.59762225 1299.95163958 5287.20181649 5237.63829385 1169.80876436]
total_rewards_mean           2904.8182501306724
total_rewards_std            1938.1152139803007
total_rewards_max            5287.201816489682
total_rewards_min            857.9731172186436
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               31.148346145171672
(Previous) Eval Time (s)     21.608867703936994
Sample Time (s)              19.544520064722747
Epoch Time (s)               72.30173391383141
Total Train Time (s)         15259.928324314766
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:30:02.196514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #264 | Epoch Duration: 67.71138334274292
2020-01-10 22:30:02.196847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035161942
Z variance train             0.030958619
KL Divergence                6.322424
KL Loss                      0.6322424
QF Loss                      1518.4072
VF Loss                      721.3235
Policy Loss                  -1813.0117
Q Predictions Mean           1809.7878
Q Predictions Std            970.76337
Q Predictions Max            2524.9563
Q Predictions Min            15.668155
V Predictions Mean           1798.7048
V Predictions Std            958.61957
V Predictions Max            2512.5784
V Predictions Min            24.855515
Log Pis Mean                 -4.009309
Log Pis Std                  6.259169
Log Pis Max                  23.472769
Log Pis Min                  -17.259163
Policy mu Mean               0.32968172
Policy mu Std                0.7188454
Policy mu Max                2.86568
Policy mu Min                -2.6230657
Policy log std Mean          -0.290382
Policy log std Std           0.14903398
Policy log std Max           -0.056250393
Policy log std Min           -1.0064836
Z mean eval                  0.03509235
Z variance eval              0.030931467
total_rewards                [2923.84463459 5248.2697108  5251.30479408 3020.58140275 5207.66474925
 4986.77009566 2250.38326986 5317.44712269 4746.20552491 2633.94884507]
total_rewards_mean           4158.642014966102
total_rewards_std            1210.022837125578
total_rewards_max            5317.447122687485
total_rewards_min            2250.3832698553488
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               32.2398831397295
(Previous) Eval Time (s)     17.01819316809997
Sample Time (s)              19.23211292270571
Epoch Time (s)               68.49018923053518
Total Train Time (s)         15335.129381057806
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:31:17.396244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #265 | Epoch Duration: 75.19917345046997
2020-01-10 22:31:17.396466 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035211805
Z variance train             0.03094497
KL Divergence                6.3225985
KL Loss                      0.63225985
QF Loss                      1763.0564
VF Loss                      679.4428
Policy Loss                  -1949.8041
Q Predictions Mean           1948.3103
Q Predictions Std            848.6925
Q Predictions Max            2517.4739
Q Predictions Min            15.947787
V Predictions Mean           1950.799
V Predictions Std            847.4975
V Predictions Max            2527.1594
V Predictions Min            25.938854
Log Pis Mean                 -2.4310403
Log Pis Std                  6.594424
Log Pis Max                  30.163631
Log Pis Min                  -13.295082
Policy mu Mean               0.35669875
Policy mu Std                0.78857327
Policy mu Max                2.984364
Policy mu Min                -3.279421
Policy log std Mean          -0.31721994
Policy log std Std           0.15751655
Policy log std Max           -0.041882664
Policy log std Min           -0.9641072
Z mean eval                  0.031752992
Z variance eval              0.029160867
total_rewards                [4602.16412495 4377.80228418 5278.4984038  5204.32251214  873.79566201
 4108.58241121 5216.52313374 5179.85136381 5226.31165776 5247.58719386]
total_rewards_mean           4531.543874745433
total_rewards_std            1283.8276262802365
total_rewards_max            5278.498403801394
total_rewards_min            873.7956620106373
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               31.067203066311777
(Previous) Eval Time (s)     23.726876161061227
Sample Time (s)              19.66390373976901
Epoch Time (s)               74.45798296714202
Total Train Time (s)         15411.656379782129
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:32:33.924926 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #266 | Epoch Duration: 76.52830767631531
2020-01-10 22:32:33.925074 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032017276
Z variance train             0.029166246
KL Divergence                6.4405193
KL Loss                      0.64405197
QF Loss                      1131.137
VF Loss                      266.15012
Policy Loss                  -1930.2277
Q Predictions Mean           1926.8015
Q Predictions Std            909.7392
Q Predictions Max            2520.828
Q Predictions Min            15.267494
V Predictions Mean           1925.3679
V Predictions Std            901.35
V Predictions Max            2521.8982
V Predictions Min            27.762245
Log Pis Mean                 -4.10617
Log Pis Std                  5.7750044
Log Pis Max                  19.38028
Log Pis Min                  -12.994457
Policy mu Mean               0.37337235
Policy mu Std                0.7003536
Policy mu Max                2.5380912
Policy mu Min                -2.9003043
Policy log std Mean          -0.2934084
Policy log std Std           0.14981431
Policy log std Max           -0.034597278
Policy log std Min           -1.094646
Z mean eval                  0.02927028
Z variance eval              0.029744063
total_rewards                [3214.77568002 2090.34923248  937.66697676 5328.43143226 3171.27806541
 2698.60170969 2267.8859477  5139.60727158 1928.68480962 2267.12572324]
total_rewards_mean           2904.4406848760345
total_rewards_std            1318.1804135981613
total_rewards_max            5328.4314322647815
total_rewards_min            937.6669767582919
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               28.587480958085507
(Previous) Eval Time (s)     25.796882405877113
Sample Time (s)              20.605284248944372
Epoch Time (s)               74.98964761290699
Total Train Time (s)         15476.535460623447
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:33:38.807551 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #267 | Epoch Duration: 64.88235020637512
2020-01-10 22:33:38.807758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029129628
Z variance train             0.029729787
KL Divergence                6.38073
KL Loss                      0.638073
QF Loss                      2268.0767
VF Loss                      605.47125
Policy Loss                  -1904.4755
Q Predictions Mean           1902.2422
Q Predictions Std            890.5388
Q Predictions Max            2521.5608
Q Predictions Min            16.446556
V Predictions Mean           1913.4779
V Predictions Std            891.0063
V Predictions Max            2533.616
V Predictions Min            25.568321
Log Pis Mean                 -3.0562668
Log Pis Std                  6.5071907
Log Pis Max                  30.276596
Log Pis Min                  -13.83776
Policy mu Mean               0.360495
Policy mu Std                0.75130737
Policy mu Max                2.847066
Policy mu Min                -3.6063757
Policy log std Mean          -0.3094418
Policy log std Std           0.15214668
Policy log std Max           -0.02279596
Policy log std Min           -1.1020274
Z mean eval                  0.026209135
Z variance eval              0.030207211
total_rewards                [2907.03074509 5169.88367339 1707.90609251 3908.62728045 5403.38918643
 5234.93681392 5304.1088461  2692.3352413  1660.04558875 5318.97311987]
total_rewards_mean           3930.7236587813322
total_rewards_std            1479.7835931579523
total_rewards_max            5403.389186430462
total_rewards_min            1660.0455887456937
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               31.243031003978103
(Previous) Eval Time (s)     15.68926660111174
Sample Time (s)              18.668275407515466
Epoch Time (s)               65.60057301260531
Total Train Time (s)         15549.161482773256
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:34:51.439611 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #268 | Epoch Duration: 72.63164234161377
2020-01-10 22:34:51.439964 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #268 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026078809
Z variance train             0.030214036
KL Divergence                6.3378506
KL Loss                      0.63378507
QF Loss                      1371.1877
VF Loss                      437.5358
Policy Loss                  -1918.9652
Q Predictions Mean           1916.5995
Q Predictions Std            889.1934
Q Predictions Max            2536.04
Q Predictions Min            17.82644
V Predictions Mean           1920.8726
V Predictions Std            885.2543
V Predictions Max            2536.3218
V Predictions Min            26.356308
Log Pis Mean                 -2.8744884
Log Pis Std                  7.0017376
Log Pis Max                  29.877476
Log Pis Min                  -17.039906
Policy mu Mean               0.364967
Policy mu Std                0.7687106
Policy mu Max                3.6194246
Policy mu Min                -3.358286
Policy log std Mean          -0.3010767
Policy log std Std           0.1540286
Policy log std Max           0.0091894865
Policy log std Min           -0.9819174
Z mean eval                  0.024386538
Z variance eval              0.030635241
total_rewards                [5266.25073659 2765.90906143 5032.07852763 5168.68736852 3606.2907659
 5251.15741068 2969.4463137  5061.78302459 4948.33175589 3831.44152625]
total_rewards_mean           4390.137649118657
total_rewards_std            941.9599126172037
total_rewards_max            5266.250736589722
total_rewards_min            2765.9090614315846
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               32.14803109085187
(Previous) Eval Time (s)     22.720041133929044
Sample Time (s)              20.106686000712216
Epoch Time (s)               74.97475822549313
Total Train Time (s)         15626.711299937684
Epoch                        269
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:36:08.993660 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #269 | Epoch Duration: 77.5534451007843
2020-01-10 22:36:08.993945 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #269 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024437116
Z variance train             0.03063457
KL Divergence                6.3105545
KL Loss                      0.6310555
QF Loss                      1305.6025
VF Loss                      317.30533
Policy Loss                  -2005.593
Q Predictions Mean           2002.5984
Q Predictions Std            843.79
Q Predictions Max            2529.853
Q Predictions Min            18.476694
V Predictions Mean           2009.5413
V Predictions Std            843.3217
V Predictions Max            2548.2913
V Predictions Min            27.924185
Log Pis Mean                 -3.6103923
Log Pis Std                  5.573767
Log Pis Max                  17.899809
Log Pis Min                  -18.558453
Policy mu Mean               0.347181
Policy mu Std                0.72588855
Policy mu Max                2.7840838
Policy mu Min                -3.1825671
Policy log std Mean          -0.29380175
Policy log std Std           0.14392559
Policy log std Max           -0.023110062
Policy log std Min           -0.9630724
Z mean eval                  0.022470422
Z variance eval              0.031168606
total_rewards                [3296.93536325 1598.3022177  4519.37101784 5269.71235198 3364.0239305
 3655.70394938  738.71570938 1132.64167173 1285.95823469 1676.31888661]
total_rewards_mean           2653.7683333062587
total_rewards_std            1488.8657356104784
total_rewards_max            5269.712351976703
total_rewards_min            738.7157093820797
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               28.326684914994985
(Previous) Eval Time (s)     25.298446730244905
Sample Time (s)              19.877931668423116
Epoch Time (s)               73.503063313663
Total Train Time (s)         15689.64575047139
Epoch                        270
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:37:11.932946 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #270 | Epoch Duration: 62.93875765800476
2020-01-10 22:37:11.933236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022673784
Z variance train             0.031157335
KL Divergence                6.274152
KL Loss                      0.6274152
QF Loss                      1257.7798
VF Loss                      592.0379
Policy Loss                  -2012.7732
Q Predictions Mean           2010.6091
Q Predictions Std            838.98303
Q Predictions Max            2546.8296
Q Predictions Min            11.603132
V Predictions Mean           2012.7219
V Predictions Std            830.8696
V Predictions Max            2535.767
V Predictions Min            22.757734
Log Pis Mean                 -3.5467749
Log Pis Std                  5.7698183
Log Pis Max                  24.948437
Log Pis Min                  -14.7312355
Policy mu Mean               0.4009343
Policy mu Std                0.717281
Policy mu Max                3.3099122
Policy mu Min                -2.9199963
Policy log std Mean          -0.29903057
Policy log std Std           0.14434671
Policy log std Max           -0.035623007
Policy log std Min           -0.90839624
Z mean eval                  0.023617785
Z variance eval              0.03087456
total_rewards                [5180.24936756 1132.75367931  778.54208958 1186.05742953 5144.71593213
 4980.31796433 1443.53339314 2831.55303148 2850.62505653 1437.67177793]
total_rewards_mean           2696.601972152884
total_rewards_std            1702.3650045345296
total_rewards_max            5180.249367557604
total_rewards_min            778.5420895834146
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               30.81027228711173
(Previous) Eval Time (s)     14.733820754103363
Sample Time (s)              19.77846052777022
Epoch Time (s)               65.32255356898531
Total Train Time (s)         15755.77800675761
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:38:18.069558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #271 | Epoch Duration: 66.1360867023468
2020-01-10 22:38:18.069844 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #271 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023377182
Z variance train             0.030876394
KL Divergence                6.2984977
KL Loss                      0.6298498
QF Loss                      1202.81
VF Loss                      521.6581
Policy Loss                  -1831.6304
Q Predictions Mean           1827.2117
Q Predictions Std            945.1866
Q Predictions Max            2536.0374
Q Predictions Min            13.803177
V Predictions Mean           1836.478
V Predictions Std            944.9495
V Predictions Max            2552.3994
V Predictions Min            25.42434
Log Pis Mean                 -3.8879256
Log Pis Std                  6.3977103
Log Pis Max                  34.808075
Log Pis Min                  -12.5998955
Policy mu Mean               0.32110226
Policy mu Std                0.73161316
Policy mu Max                3.5090044
Policy mu Min                -4.7665863
Policy log std Mean          -0.2937273
Policy log std Std           0.15442589
Policy log std Max           -0.020499215
Policy log std Min           -0.94945323
Z mean eval                  0.02082814
Z variance eval              0.033193212
total_rewards                [ 691.53017584 5300.69197354 1139.66149438 1094.10457458 5312.3042246
 1408.4869337  3780.7389152  4653.18010717 2318.26720872 3388.71711236]
total_rewards_mean           2908.768272009471
total_rewards_std            1716.6934470746212
total_rewards_max            5312.304224601497
total_rewards_min            691.530175839947
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               31.233114338014275
(Previous) Eval Time (s)     15.547030790243298
Sample Time (s)              19.258812594227493
Epoch Time (s)               66.03895772248507
Total Train Time (s)         15823.015186991543
Epoch                        272
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:39:25.313206 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #272 | Epoch Duration: 67.2431378364563
2020-01-10 22:39:25.313465 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020721424
Z variance train             0.033186335
KL Divergence                6.1557426
KL Loss                      0.6155743
QF Loss                      2037.3712
VF Loss                      589.79004
Policy Loss                  -1962.0647
Q Predictions Mean           1955.7295
Q Predictions Std            865.82306
Q Predictions Max            2534.8403
Q Predictions Min            16.422224
V Predictions Mean           1968.0411
V Predictions Std            862.9583
V Predictions Max            2546.7114
V Predictions Min            23.50099
Log Pis Mean                 -3.9482865
Log Pis Std                  5.504664
Log Pis Max                  13.420942
Log Pis Min                  -13.600612
Policy mu Mean               0.36520547
Policy mu Std                0.70756656
Policy mu Max                2.7270896
Policy mu Min                -3.6370554
Policy log std Mean          -0.2953725
Policy log std Std           0.14697644
Policy log std Max           0.042672083
Policy log std Min           -1.0434902
Z mean eval                  0.022035217
Z variance eval              0.03260125
total_rewards                [4453.72028545 1378.27390866 3037.81444177 5076.91791927 5091.55988376
 5229.74680988 2590.16262436 5232.21859296 1095.72068455 2682.44253014]
total_rewards_mean           3586.8577680801072
total_rewards_std            1543.9746863915962
total_rewards_max            5232.218592959387
total_rewards_min            1095.7206845485323
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               31.55398309091106
(Previous) Eval Time (s)     16.75087448209524
Sample Time (s)              19.793664255645126
Epoch Time (s)               68.09852182865143
Total Train Time (s)         15895.2375794705
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:40:37.539929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #273 | Epoch Duration: 72.22625255584717
2020-01-10 22:40:37.540222 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #273 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022224396
Z variance train             0.032597456
KL Divergence                6.1894293
KL Loss                      0.6189429
QF Loss                      1786.5898
VF Loss                      670.572
Policy Loss                  -2018.4083
Q Predictions Mean           2019.2675
Q Predictions Std            831.61084
Q Predictions Max            2566.4834
Q Predictions Min            17.29116
V Predictions Mean           2008.2688
V Predictions Std            823.0169
V Predictions Max            2534.4502
V Predictions Min            27.971682
Log Pis Mean                 -3.2922487
Log Pis Std                  5.9500766
Log Pis Max                  20.90326
Log Pis Min                  -13.717058
Policy mu Mean               0.3987535
Policy mu Std                0.7254048
Policy mu Max                2.4840946
Policy mu Min                -3.4411957
Policy log std Mean          -0.30077863
Policy log std Std           0.15006512
Policy log std Max           -0.04342743
Policy log std Min           -0.9042618
Z mean eval                  0.020957578
Z variance eval              0.03176288
total_rewards                [2725.5802416  1183.7431777  5194.73390903 5263.03373543 2274.5070454
 5221.67174095 5222.9471353  4182.2420243  5199.53970533 5177.22467766]
total_rewards_mean           4164.52233926971
total_rewards_std            1453.6433061564512
total_rewards_max            5263.0337354344965
total_rewards_min            1183.7431776959843
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               31.13209810294211
(Previous) Eval Time (s)     20.87829412287101
Sample Time (s)              19.561129457317293
Epoch Time (s)               71.57152168313041
Total Train Time (s)         15970.073731075507
Epoch                        274
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:41:52.381573 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #274 | Epoch Duration: 74.84112763404846
2020-01-10 22:41:52.381859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #274 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020940233
Z variance train             0.03177071
KL Divergence                6.245083
KL Loss                      0.6245083
QF Loss                      1187.4294
VF Loss                      769.1653
Policy Loss                  -2106.3884
Q Predictions Mean           2102.677
Q Predictions Std            744.8494
Q Predictions Max            2553.3423
Q Predictions Min            21.632502
V Predictions Mean           2094.0854
V Predictions Std            744.0154
V Predictions Max            2549.8845
V Predictions Min            32.11138
Log Pis Mean                 -2.4984837
Log Pis Std                  5.49849
Log Pis Max                  18.86473
Log Pis Min                  -14.798332
Policy mu Mean               0.38171673
Policy mu Std                0.75571394
Policy mu Max                2.808072
Policy mu Min                -2.4828315
Policy log std Mean          -0.31556243
Policy log std Std           0.15350103
Policy log std Max           -0.019270517
Policy log std Min           -1.0947897
Z mean eval                  0.023550237
Z variance eval              0.030608397
total_rewards                [5293.33820888 5229.45113541 5321.69154907 5259.19032802 1929.5224981
 4593.55547588 3160.08799051 1823.32661275 2049.4885347  5264.75023447]
total_rewards_mean           3992.4402567787606
total_rewards_std            1483.3328585291558
total_rewards_max            5321.691549073708
total_rewards_min            1823.3266127456
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               29.232578422874212
(Previous) Eval Time (s)     24.147545346058905
Sample Time (s)              19.355363915208727
Epoch Time (s)               72.73548768414184
Total Train Time (s)         16040.923290714622
Epoch                        275
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:43:03.236074 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #275 | Epoch Duration: 70.85397672653198
2020-01-10 22:43:03.236363 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023634668
Z variance train             0.030609194
KL Divergence                6.3418493
KL Loss                      0.63418496
QF Loss                      1684.9701
VF Loss                      477.37006
Policy Loss                  -2079.3596
Q Predictions Mean           2073.5706
Q Predictions Std            819.9756
Q Predictions Max            2569.4907
Q Predictions Min            17.31657
V Predictions Mean           2074.4912
V Predictions Std            812.56146
V Predictions Max            2553.9312
V Predictions Min            26.688028
Log Pis Mean                 -3.3073244
Log Pis Std                  5.9336805
Log Pis Max                  30.734446
Log Pis Min                  -12.45608
Policy mu Mean               0.38379747
Policy mu Std                0.73985845
Policy mu Max                2.5850213
Policy mu Min                -2.9207678
Policy log std Mean          -0.30152044
Policy log std Std           0.14683633
Policy log std Max           -0.0146032125
Policy log std Min           -0.935761
Z mean eval                  0.023939036
Z variance eval              0.03212385
total_rewards                [1922.87197976 3278.85409149 5224.84608984 2280.75724119 5274.08643712
 2924.34643984 2261.04360753 5177.63432546 4306.69387695 1347.27169602]
total_rewards_mean           3399.8405785202826
total_rewards_std            1414.5949911007242
total_rewards_max            5274.086437118262
total_rewards_min            1347.2716960156627
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               33.09165578195825
(Previous) Eval Time (s)     22.265719070099294
Sample Time (s)              20.220577453728765
Epoch Time (s)               75.57795230578631
Total Train Time (s)         16113.108652350027
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:44:15.422661 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #276 | Epoch Duration: 72.18609023094177
2020-01-10 22:44:15.422827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024233464
Z variance train             0.032128163
KL Divergence                6.246858
KL Loss                      0.6246858
QF Loss                      975.95123
VF Loss                      378.38458
Policy Loss                  -1940.6448
Q Predictions Mean           1933.9592
Q Predictions Std            916.2338
Q Predictions Max            2543.7595
Q Predictions Min            17.285757
V Predictions Mean           1939.9009
V Predictions Std            918.11847
V Predictions Max            2562.844
V Predictions Min            26.72378
Log Pis Mean                 -4.617774
Log Pis Std                  5.1546187
Log Pis Max                  18.655876
Log Pis Min                  -14.428265
Policy mu Mean               0.37491405
Policy mu Std                0.6770888
Policy mu Max                2.5546958
Policy mu Min                -2.6040037
Policy log std Mean          -0.2862477
Policy log std Std           0.13769047
Policy log std Max           -0.05695784
Policy log std Min           -0.816489
Z mean eval                  0.01953978
Z variance eval              0.033164702
total_rewards                [1392.60266975 3760.95063354 5116.82352972 2386.57505831 1553.06298472
 5142.96372048 3177.91045543 3281.32081268 5068.48280522  757.37087546]
total_rewards_mean           3163.8063545307527
total_rewards_std            1544.5516860950784
total_rewards_max            5142.963720476959
total_rewards_min            757.3708754614765
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               33.540430368855596
(Previous) Eval Time (s)     18.873541154898703
Sample Time (s)              19.441174376755953
Epoch Time (s)               71.85514590051025
Total Train Time (s)         16184.60382598266
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:45:26.923261 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #277 | Epoch Duration: 71.50029039382935
2020-01-10 22:45:26.923507 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019428331
Z variance train             0.0331576
KL Divergence                6.1549754
KL Loss                      0.6154975
QF Loss                      2119.9517
VF Loss                      417.33792
Policy Loss                  -1973.8512
Q Predictions Mean           1973.8442
Q Predictions Std            876.6943
Q Predictions Max            2551.4126
Q Predictions Min            19.613308
V Predictions Mean           1975.4252
V Predictions Std            873.7688
V Predictions Max            2561.325
V Predictions Min            32.814617
Log Pis Mean                 -3.7669792
Log Pis Std                  5.9271216
Log Pis Max                  17.945938
Log Pis Min                  -16.138515
Policy mu Mean               0.32560512
Policy mu Std                0.75064635
Policy mu Max                2.8380508
Policy mu Min                -3.2830453
Policy log std Mean          -0.3049811
Policy log std Std           0.15303656
Policy log std Max           -0.030442074
Policy log std Min           -0.98482394
Z mean eval                  0.020927086
Z variance eval              0.032777257
total_rewards                [2596.2193755  3670.58025239 5257.58307747 1532.11956953 1208.43128444
 5276.25092209 5200.69618211 5204.83219476 5268.40743408 5207.09070245]
total_rewards_mean           4042.2210994821485
total_rewards_std            1584.7438230538294
total_rewards_max            5276.250922087103
total_rewards_min            1208.4312844444855
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               30.45200662408024
(Previous) Eval Time (s)     18.518320141825825
Sample Time (s)              20.006689028348774
Epoch Time (s)               68.97701579425484
Total Train Time (s)         16257.588316244539
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:46:39.909884 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #278 | Epoch Duration: 72.98619318008423
2020-01-10 22:46:39.910083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020805089
Z variance train             0.032759365
KL Divergence                6.210182
KL Loss                      0.62101823
QF Loss                      812.797
VF Loss                      514.86414
Policy Loss                  -1982.6823
Q Predictions Mean           1985.3187
Q Predictions Std            905.93854
Q Predictions Max            2578.22
Q Predictions Min            14.199143
V Predictions Mean           1997.1349
V Predictions Std            905.9853
V Predictions Max            2584.9424
V Predictions Min            23.880049
Log Pis Mean                 -4.471617
Log Pis Std                  5.1078897
Log Pis Max                  13.397146
Log Pis Min                  -12.527321
Policy mu Mean               0.36292988
Policy mu Std                0.66643304
Policy mu Max                2.8421779
Policy mu Min                -2.5534728
Policy log std Mean          -0.2867163
Policy log std Std           0.13778365
Policy log std Max           0.051126346
Policy log std Min           -0.94346344
Z mean eval                  0.020568285
Z variance eval              0.0348728
total_rewards                [3010.95760344 1167.79946559 2418.26730121 1992.28005026 1276.96252689
  669.02934806 5348.80276178 5243.94497328 4810.48458799 3272.11236277]
total_rewards_mean           2921.064098127211
total_rewards_std            1641.798644275567
total_rewards_max            5348.802761782018
total_rewards_min            669.0293480609574
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               29.55515231611207
(Previous) Eval Time (s)     22.52712468104437
Sample Time (s)              19.257393484469503
Epoch Time (s)               71.33967048162594
Total Train Time (s)         16323.494899836835
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:47:45.819031 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #279 | Epoch Duration: 65.90880846977234
2020-01-10 22:47:45.819224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020618057
Z variance train             0.034864653
KL Divergence                6.0497465
KL Loss                      0.6049747
QF Loss                      1397.7083
VF Loss                      344.17023
Policy Loss                  -2094.8557
Q Predictions Mean           2090.0598
Q Predictions Std            757.98065
Q Predictions Max            2587.406
Q Predictions Min            19.162237
V Predictions Mean           2099.3323
V Predictions Std            756.38324
V Predictions Max            2590.8816
V Predictions Min            28.248184
Log Pis Mean                 -2.91041
Log Pis Std                  6.1624694
Log Pis Max                  24.260681
Log Pis Min                  -14.235875
Policy mu Mean               0.36796355
Policy mu Std                0.7693631
Policy mu Max                2.7916358
Policy mu Min                -2.6640015
Policy log std Mean          -0.31735587
Policy log std Std           0.15063976
Policy log std Max           -0.043350473
Policy log std Min           -0.98830265
Z mean eval                  0.021387445
Z variance eval              0.034382302
total_rewards                [5329.04670494 5284.40905842 3621.11966467 5360.68566734 5250.20249705
 4628.41258381 4312.41033219 2865.57493734 2535.45390542 5326.50524865]
total_rewards_mean           4451.382059982187
total_rewards_std            1030.5615198386315
total_rewards_max            5360.685667338119
total_rewards_min            2535.4539054206807
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               32.03822758141905
(Previous) Eval Time (s)     17.095989214256406
Sample Time (s)              19.978134816046804
Epoch Time (s)               69.11235161172226
Total Train Time (s)         16399.67202048702
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:49:01.998247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #280 | Epoch Duration: 76.17886734008789
2020-01-10 22:49:01.998440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021380778
Z variance train             0.03438139
KL Divergence                6.0909853
KL Loss                      0.60909855
QF Loss                      1704.9221
VF Loss                      446.9551
Policy Loss                  -2040.3557
Q Predictions Mean           2034.5199
Q Predictions Std            841.7961
Q Predictions Max            2578.6646
Q Predictions Min            22.110615
V Predictions Mean           2046.6641
V Predictions Std            841.5295
V Predictions Max            2586.6482
V Predictions Min            31.633202
Log Pis Mean                 -3.1848845
Log Pis Std                  6.080637
Log Pis Max                  21.27113
Log Pis Min                  -12.334542
Policy mu Mean               0.3737369
Policy mu Std                0.72989434
Policy mu Max                2.8753924
Policy mu Min                -2.8709736
Policy log std Mean          -0.30606046
Policy log std Std           0.15530108
Policy log std Max           0.0017932355
Policy log std Min           -1.1297244
Z mean eval                  0.0226756
Z variance eval              0.035545103
total_rewards                [1081.47831048 5157.57440087 5218.15428418 5160.6505824  4059.05416344
 5159.78379733 5105.48162183 2959.25781202  921.73180115 5229.946272  ]
total_rewards_mean           4005.311304570377
total_rewards_std            1653.2028788251016
total_rewards_max            5229.946271997656
total_rewards_min            921.7318011511022
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               30.488655182998627
(Previous) Eval Time (s)     24.162173992022872
Sample Time (s)              19.660336944740266
Epoch Time (s)               74.31116611976177
Total Train Time (s)         16473.135160140228
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:50:15.466433 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #281 | Epoch Duration: 73.46782541275024
2020-01-10 22:50:15.466702 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022575077
Z variance train             0.035533886
KL Divergence                6.007953
KL Loss                      0.6007953
QF Loss                      1036.0305
VF Loss                      420.4051
Policy Loss                  -2068.5886
Q Predictions Mean           2061.3164
Q Predictions Std            804.7829
Q Predictions Max            2563.8108
Q Predictions Min            18.413048
V Predictions Mean           2070.0527
V Predictions Std            802.1301
V Predictions Max            2565.1504
V Predictions Min            27.560537
Log Pis Mean                 -3.16727
Log Pis Std                  5.6978526
Log Pis Max                  26.260067
Log Pis Min                  -13.496144
Policy mu Mean               0.34263515
Policy mu Std                0.7635793
Policy mu Max                2.763075
Policy mu Min                -2.7639399
Policy log std Mean          -0.30985788
Policy log std Std           0.15077701
Policy log std Max           0.08981365
Policy log std Min           -1.0858479
Z mean eval                  0.023358162
Z variance eval              0.034009993
total_rewards                [1130.84448832 5226.67758945 5339.63822543 1502.96832937 1784.69749642
 3363.43365845 5277.7638488  5411.74970929 5281.37494526 2146.09825825]
total_rewards_mean           3646.524654902851
total_rewards_std            1747.4127676318021
total_rewards_max            5411.749709286365
total_rewards_min            1130.8444883218963
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               31.798643342684954
(Previous) Eval Time (s)     23.318490631878376
Sample Time (s)              19.67643063189462
Epoch Time (s)               74.79356460645795
Total Train Time (s)         16544.88913180027
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:51:27.221877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #282 | Epoch Duration: 71.75499820709229
2020-01-10 22:51:27.222028 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02323853
Z variance train             0.034003444
KL Divergence                6.099079
KL Loss                      0.6099079
QF Loss                      1024.7205
VF Loss                      690.4468
Policy Loss                  -2173.7483
Q Predictions Mean           2170.9653
Q Predictions Std            741.3183
Q Predictions Max            2583.6023
Q Predictions Min            17.445929
V Predictions Mean           2185.0183
V Predictions Std            742.715
V Predictions Max            2595.3032
V Predictions Min            23.204668
Log Pis Mean                 -3.36565
Log Pis Std                  5.6140265
Log Pis Max                  16.6917
Log Pis Min                  -15.192122
Policy mu Mean               0.38598257
Policy mu Std                0.7394808
Policy mu Max                2.4753523
Policy mu Min                -3.2073822
Policy log std Mean          -0.3041362
Policy log std Std           0.14782177
Policy log std Max           -0.07010819
Policy log std Min           -1.157417
Z mean eval                  0.025955457
Z variance eval              0.033516817
total_rewards                [5306.4790057  2915.66743273 1303.3199028  1828.72370852 5149.05992612
 2879.18552241 3402.9379634  1521.67491982 3569.48324823 2013.16898366]
total_rewards_mean           2988.970061339234
total_rewards_std            1336.2394122069468
total_rewards_max            5306.479005704668
total_rewards_min            1303.3199028011304
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               29.20390593400225
(Previous) Eval Time (s)     20.2796060112305
Sample Time (s)              19.86821362376213
Epoch Time (s)               69.35172556899488
Total Train Time (s)         16610.92947231373
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:52:33.265828 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #283 | Epoch Duration: 66.04367399215698
2020-01-10 22:52:33.266016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025750538
Z variance train             0.033511627
KL Divergence                6.1304073
KL Loss                      0.61304075
QF Loss                      1968.749
VF Loss                      537.51575
Policy Loss                  -2069.7017
Q Predictions Mean           2066.5996
Q Predictions Std            800.177
Q Predictions Max            2577.7927
Q Predictions Min            18.695187
V Predictions Mean           2071.1997
V Predictions Std            793.1968
V Predictions Max            2564.8977
V Predictions Min            30.317247
Log Pis Mean                 -2.943143
Log Pis Std                  5.8305345
Log Pis Max                  30.979605
Log Pis Min                  -13.088004
Policy mu Mean               0.39087954
Policy mu Std                0.74342823
Policy mu Max                3.0463917
Policy mu Min                -2.874936
Policy log std Mean          -0.3177983
Policy log std Std           0.15092891
Policy log std Max           -0.008566037
Policy log std Min           -1.0516379
Z mean eval                  0.024552524
Z variance eval              0.03304248
total_rewards                [5281.56418199 3307.26989933 4051.44297408 5343.35757442  815.17145368
 5329.2817838  1405.36800939 3107.11845771 5260.92643647 5261.60794389]
total_rewards_mean           3916.310871475774
total_rewards_std            1627.2849972486897
total_rewards_max            5343.357574417172
total_rewards_min            815.1714536809742
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               29.593883990775794
(Previous) Eval Time (s)     16.971218270715326
Sample Time (s)              19.129524925723672
Epoch Time (s)               65.69462718721479
Total Train Time (s)         16681.332064154558
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:53:43.672334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #284 | Epoch Duration: 70.40616869926453
2020-01-10 22:53:43.672565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024328804
Z variance train             0.033043183
KL Divergence                6.1812153
KL Loss                      0.61812156
QF Loss                      878.352
VF Loss                      758.90247
Policy Loss                  -2171.4714
Q Predictions Mean           2173.6538
Q Predictions Std            720.6045
Q Predictions Max            2586.0303
Q Predictions Min            19.668186
V Predictions Mean           2186.7915
V Predictions Std            718.2353
V Predictions Max            2594.732
V Predictions Min            30.78316
Log Pis Mean                 -3.5859253
Log Pis Std                  5.0356402
Log Pis Max                  14.940099
Log Pis Min                  -13.790367
Policy mu Mean               0.37353483
Policy mu Std                0.7276639
Policy mu Max                3.271042
Policy mu Min                -2.5890088
Policy log std Mean          -0.30324823
Policy log std Std           0.13937879
Policy log std Max           -0.036522254
Policy log std Min           -1.0814049
Z mean eval                  0.024453256
Z variance eval              0.034175586
total_rewards                [5035.22041396 3586.18212705 5265.40087081 5274.03384491 4550.94850325
 5152.46038639 5256.18590168  768.38628823 1001.4658363  5305.59380295]
total_rewards_mean           4119.587797552797
total_rewards_std            1693.3144253895089
total_rewards_max            5305.5938029506115
total_rewards_min            768.3862882303997
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               31.838163318112493
(Previous) Eval Time (s)     21.682410541921854
Sample Time (s)              19.96913735428825
Epoch Time (s)               73.4897112143226
Total Train Time (s)         16756.905955061782
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:54:59.252379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #285 | Epoch Duration: 75.57959723472595
2020-01-10 22:54:59.252693 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #285 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024473118
Z variance train             0.034179643
KL Divergence                6.085781
KL Loss                      0.60857815
QF Loss                      776.83154
VF Loss                      256.3059
Policy Loss                  -2168.2815
Q Predictions Mean           2164.1074
Q Predictions Std            714.6703
Q Predictions Max            2581.3281
Q Predictions Min            15.69574
V Predictions Mean           2165.0366
V Predictions Std            712.2833
V Predictions Max            2579.4207
V Predictions Min            26.32191
Log Pis Mean                 -3.6105354
Log Pis Std                  5.195037
Log Pis Max                  16.198053
Log Pis Min                  -12.315929
Policy mu Mean               0.39231846
Policy mu Std                0.72367394
Policy mu Max                3.0984156
Policy mu Min                -2.948668
Policy log std Mean          -0.30404213
Policy log std Std           0.13954374
Policy log std Max           0.07300398
Policy log std Min           -1.1456298
Z mean eval                  0.027866032
Z variance eval              0.033922337
total_rewards                [5351.18612803 5274.1223187  1056.79484601  911.33941836 2007.64115108
 4343.36100652 1443.17011865  364.78721576 5262.94389398 5033.12898183]
total_rewards_mean           3104.847507892309
total_rewards_std            2003.5048521606934
total_rewards_max            5351.186128025557
total_rewards_min            364.787215764221
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               30.989286500029266
(Previous) Eval Time (s)     23.771942209918052
Sample Time (s)              20.422937414608896
Epoch Time (s)               75.18416612455621
Total Train Time (s)         16825.961580780335
Epoch                        286
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:56:08.311888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #286 | Epoch Duration: 69.05895066261292
2020-01-10 22:56:08.312176 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028047746
Z variance train             0.0339124
KL Divergence                6.132217
KL Loss                      0.6132217
QF Loss                      1832.4327
VF Loss                      602.7639
Policy Loss                  -2129.9158
Q Predictions Mean           2126.7258
Q Predictions Std            765.4521
Q Predictions Max            2590.3308
Q Predictions Min            17.734291
V Predictions Mean           2130.9832
V Predictions Std            763.7742
V Predictions Max            2593.228
V Predictions Min            26.791882
Log Pis Mean                 -3.7413197
Log Pis Std                  5.339474
Log Pis Max                  18.32248
Log Pis Min                  -13.979051
Policy mu Mean               0.3948897
Policy mu Std                0.7104857
Policy mu Max                2.7884164
Policy mu Min                -2.7309494
Policy log std Mean          -0.30717328
Policy log std Std           0.14566329
Policy log std Max           0.09886283
Policy log std Min           -1.2616137
Z mean eval                  0.026143068
Z variance eval              0.035043623
total_rewards                [4051.6070254  3962.17504366 5253.22201474 2194.73029049 2135.97669753
 5371.91713636 5321.95152499 4545.29966298 1390.95422266 5309.37950144]
total_rewards_mean           3953.7213120254614
total_rewards_std            1439.9820342697728
total_rewards_max            5371.917136361456
total_rewards_min            1390.9542226635044
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               31.262750206980854
(Previous) Eval Time (s)     17.646379567217082
Sample Time (s)              19.6160913198255
Epoch Time (s)               68.52522109402344
Total Train Time (s)         16899.35534338327
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:57:21.707589 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #287 | Epoch Duration: 73.39522051811218
2020-01-10 22:57:21.707767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026239771
Z variance train             0.035050016
KL Divergence                6.0490036
KL Loss                      0.60490036
QF Loss                      1233.1384
VF Loss                      391.16376
Policy Loss                  -2146.038
Q Predictions Mean           2136.9268
Q Predictions Std            789.45197
Q Predictions Max            2580.5437
Q Predictions Min            16.259945
V Predictions Mean           2139.398
V Predictions Std            783.60754
V Predictions Max            2580.5315
V Predictions Min            26.99299
Log Pis Mean                 -3.9247239
Log Pis Std                  5.825497
Log Pis Max                  28.592926
Log Pis Min                  -14.191395
Policy mu Mean               0.40212414
Policy mu Std                0.69679385
Policy mu Max                2.9276652
Policy mu Min                -3.474233
Policy log std Mean          -0.29597148
Policy log std Std           0.14785728
Policy log std Max           -0.004522398
Policy log std Min           -1.0693934
Z mean eval                  0.026332
Z variance eval              0.036847226
total_rewards                [3855.47591232 1412.46643669 1352.740185   5129.70098399 1166.45624805
 3162.41577555 3882.32765885 1129.47849505 3264.38260554 1961.84375388]
total_rewards_mean           2631.7288054925043
total_rewards_std            1340.0834761103608
total_rewards_max            5129.70098399319
total_rewards_min            1129.478495048067
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               29.33431091811508
(Previous) Eval Time (s)     22.51606353605166
Sample Time (s)              19.41593021573499
Epoch Time (s)               71.26630466990173
Total Train Time (s)         16963.574892261997
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:58:25.931462 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #288 | Epoch Duration: 64.22352170944214
2020-01-10 22:58:25.931701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026063627
Z variance train             0.036849044
KL Divergence                5.959747
KL Loss                      0.5959747
QF Loss                      1006.9844
VF Loss                      1161.6329
Policy Loss                  -2191.7175
Q Predictions Mean           2188.9565
Q Predictions Std            709.25323
Q Predictions Max            2582.6436
Q Predictions Min            18.26158
V Predictions Mean           2212.5415
V Predictions Std            709.7357
V Predictions Max            2605.632
V Predictions Min            29.087402
Log Pis Mean                 -3.740868
Log Pis Std                  5.5116224
Log Pis Max                  19.472168
Log Pis Min                  -12.467224
Policy mu Mean               0.3507529
Policy mu Std                0.7112892
Policy mu Max                2.8225815
Policy mu Min                -2.8717248
Policy log std Mean          -0.30345705
Policy log std Std           0.13821013
Policy log std Max           -0.04853089
Policy log std Min           -0.9875674
Z mean eval                  0.02821136
Z variance eval              0.034729548
total_rewards                [5155.40974083 4583.28086136 2029.99081403 2342.68172146 5200.65438113
 4123.24606554 5215.78474957  979.87054396 2866.78422973 3088.63121401]
total_rewards_mean           3558.633432161153
total_rewards_std            1432.6768616736715
total_rewards_max            5215.784749569147
total_rewards_min            979.8705439623618
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               31.53554046014324
(Previous) Eval Time (s)     15.472975015640259
Sample Time (s)              19.935103794559836
Epoch Time (s)               66.94361927034333
Total Train Time (s)         17035.595936453436
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 22:59:37.955187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #289 | Epoch Duration: 72.02329111099243
2020-01-10 22:59:37.955368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028191265
Z variance train             0.034737214
KL Divergence                6.101731
KL Loss                      0.6101731
QF Loss                      1396.3508
VF Loss                      499.62238
Policy Loss                  -2172.652
Q Predictions Mean           2175.9248
Q Predictions Std            766.2201
Q Predictions Max            2614.667
Q Predictions Min            17.36577
V Predictions Mean           2167.9585
V Predictions Std            759.463
V Predictions Max            2609.6023
V Predictions Min            26.49587
Log Pis Mean                 -3.5577648
Log Pis Std                  5.620529
Log Pis Max                  17.885029
Log Pis Min                  -15.833452
Policy mu Mean               0.3502688
Policy mu Std                0.7436219
Policy mu Max                3.357684
Policy mu Min                -3.0622492
Policy log std Mean          -0.30548948
Policy log std Std           0.13839863
Policy log std Max           -0.06399053
Policy log std Min           -1.0465937
Z mean eval                  0.02711622
Z variance eval              0.035327256
total_rewards                [2872.36072091 5286.41712551 3429.86586895 5259.11731832 5326.84853766
 2765.22565239 5242.52726526 1638.84567986 5344.20263143  680.03359232]
total_rewards_mean           3784.5444392615013
total_rewards_std            1661.5003415281983
total_rewards_max            5344.20263142719
total_rewards_min            680.0335923208584
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               29.633486432023346
(Previous) Eval Time (s)     20.552343375980854
Sample Time (s)              19.08797572599724
Epoch Time (s)               69.27380553400144
Total Train Time (s)         17105.74538588198
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:00:48.110415 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #290 | Epoch Duration: 70.1548683643341
2020-01-10 23:00:48.110728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #290 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027002115
Z variance train             0.035327278
KL Divergence                6.0237055
KL Loss                      0.60237056
QF Loss                      794.57355
VF Loss                      390.4052
Policy Loss                  -2101.3975
Q Predictions Mean           2096.3184
Q Predictions Std            844.43555
Q Predictions Max            2615.4243
Q Predictions Min            16.381083
V Predictions Mean           2108.001
V Predictions Std            843.4938
V Predictions Max            2622.784
V Predictions Min            27.610756
Log Pis Mean                 -3.5394483
Log Pis Std                  6.000514
Log Pis Max                  28.745464
Log Pis Min                  -13.468493
Policy mu Mean               0.3805913
Policy mu Std                0.71769094
Policy mu Max                2.9112284
Policy mu Min                -2.9708867
Policy log std Mean          -0.3098599
Policy log std Std           0.1409882
Policy log std Max           -0.05204512
Policy log std Min           -1.129515
Z mean eval                  0.031245004
Z variance eval              0.035206944
total_rewards                [5221.30696895 5236.84897882 1173.52419484 2902.21737858 2480.281815
 4311.06267182 2125.92266525 1223.78883717 2741.70642289 3023.11713253]
total_rewards_mean           3043.977706584557
total_rewards_std            1387.051278887498
total_rewards_max            5236.848978821629
total_rewards_min            1173.5241948370226
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               30.524326706305146
(Previous) Eval Time (s)     21.43306451383978
Sample Time (s)              19.33911715587601
Epoch Time (s)               71.29650837602094
Total Train Time (s)         17172.544718225487
Epoch                        291
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:01:54.912796 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #291 | Epoch Duration: 66.8018536567688
2020-01-10 23:01:54.912999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031281177
Z variance train             0.035212327
KL Divergence                6.0322905
KL Loss                      0.60322905
QF Loss                      1167.6483
VF Loss                      389.62323
Policy Loss                  -2209.7234
Q Predictions Mean           2211.393
Q Predictions Std            730.85974
Q Predictions Max            2604.8293
Q Predictions Min            21.870785
V Predictions Mean           2209.5005
V Predictions Std            724.48773
V Predictions Max            2625.0203
V Predictions Min            32.553455
Log Pis Mean                 -3.2282348
Log Pis Std                  4.990443
Log Pis Max                  15.320194
Log Pis Min                  -12.218042
Policy mu Mean               0.39047822
Policy mu Std                0.7119281
Policy mu Max                3.3343885
Policy mu Min                -2.5186741
Policy log std Mean          -0.30322266
Policy log std Std           0.14223526
Policy log std Max           -0.010537423
Policy log std Min           -0.9715104
Z mean eval                  0.026281008
Z variance eval              0.035317052
total_rewards                [5130.09803717 4570.47709511 4247.62537977 5244.99349779 1299.04218058
 5261.76048996 5225.59923582 5118.33772024 1658.51474302 3182.17771612]
total_rewards_mean           4093.8626095579916
total_rewards_std            1446.276697229511
total_rewards_max            5261.760489958773
total_rewards_min            1299.0421805837598
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               30.04119637887925
(Previous) Eval Time (s)     16.938079012092203
Sample Time (s)              19.686759483534843
Epoch Time (s)               66.6660348745063
Total Train Time (s)         17245.697632013354
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:03:08.071224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #292 | Epoch Duration: 73.15803980827332
2020-01-10 23:03:08.071533 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02641496
Z variance train             0.035324406
KL Divergence                6.0333824
KL Loss                      0.60333824
QF Loss                      1439.956
VF Loss                      558.59924
Policy Loss                  -2181.91
Q Predictions Mean           2177.6785
Q Predictions Std            740.7075
Q Predictions Max            2626.0725
Q Predictions Min            20.729769
V Predictions Mean           2180.6643
V Predictions Std            736.02563
V Predictions Max            2621.886
V Predictions Min            32.90861
Log Pis Mean                 -3.459555
Log Pis Std                  6.002577
Log Pis Max                  25.745512
Log Pis Min                  -13.190149
Policy mu Mean               0.41699624
Policy mu Std                0.72212386
Policy mu Max                3.3445656
Policy mu Min                -5.9236083
Policy log std Mean          -0.30457154
Policy log std Std           0.14414468
Policy log std Max           -0.01998204
Policy log std Min           -1.2160697
Z mean eval                  0.026790682
Z variance eval              0.035777785
total_rewards                [3158.065545   2487.13543605 2069.78560595 4049.7228758  1943.00401493
 4237.06968436 5127.22433906 5290.37337198 5246.26721008 3002.28447172]
total_rewards_mean           3661.0932554921756
total_rewards_std            1238.9102418592015
total_rewards_max            5290.373371984131
total_rewards_min            1943.004014927284
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               30.516876671928912
(Previous) Eval Time (s)     23.429741096217185
Sample Time (s)              18.965374300722033
Epoch Time (s)               72.91199206886813
Total Train Time (s)         17315.677032388747
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:04:18.052850 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #293 | Epoch Duration: 69.98109889030457
2020-01-10 23:04:18.053067 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027063686
Z variance train             0.03576401
KL Divergence                5.987089
KL Loss                      0.5987089
QF Loss                      1136.9819
VF Loss                      381.45227
Policy Loss                  -2259.3005
Q Predictions Mean           2254.351
Q Predictions Std            701.6812
Q Predictions Max            2626.6658
Q Predictions Min            23.817457
V Predictions Mean           2250.604
V Predictions Std            698.4832
V Predictions Max            2617.084
V Predictions Min            32.887733
Log Pis Mean                 -3.387772
Log Pis Std                  5.5081344
Log Pis Max                  26.076153
Log Pis Min                  -13.516915
Policy mu Mean               0.38774547
Policy mu Std                0.71780664
Policy mu Max                2.6764987
Policy mu Min                -3.4683206
Policy log std Mean          -0.30487204
Policy log std Std           0.14066525
Policy log std Max           -0.027122594
Policy log std Min           -0.9101244
Z mean eval                  0.02734754
Z variance eval              0.035451133
total_rewards                [3924.41114334 5201.43147665 3197.01919381 5089.09826706 5293.38347116
 1574.28657186 5303.79191258 5253.33072825 5292.14865548 1961.61326138]
total_rewards_mean           4209.051468156809
total_rewards_std            1396.2573424698205
total_rewards_max            5303.791912580759
total_rewards_min            1574.286571861554
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               31.66114181978628
(Previous) Eval Time (s)     20.498580549377948
Sample Time (s)              19.68418070860207
Epoch Time (s)               71.8439030777663
Total Train Time (s)         17390.078725750092
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:05:32.460885 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #294 | Epoch Duration: 74.4076452255249
2020-01-10 23:05:32.461197 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027508024
Z variance train             0.035460435
KL Divergence                6.019426
KL Loss                      0.6019426
QF Loss                      1586.8982
VF Loss                      412.8592
Policy Loss                  -2220.3616
Q Predictions Mean           2220.1074
Q Predictions Std            733.3611
Q Predictions Max            2616.8613
Q Predictions Min            19.798525
V Predictions Mean           2213.9934
V Predictions Std            728.0203
V Predictions Max            2613.454
V Predictions Min            29.144802
Log Pis Mean                 -4.220626
Log Pis Std                  5.50564
Log Pis Max                  24.234697
Log Pis Min                  -13.245258
Policy mu Mean               0.33440986
Policy mu Std                0.72035223
Policy mu Max                3.0683787
Policy mu Min                -2.919733
Policy log std Mean          -0.28648686
Policy log std Std           0.13890404
Policy log std Max           -0.066102214
Policy log std Min           -1.071769
Z mean eval                  0.0263547
Z variance eval              0.03450904
total_rewards                [ 862.66277826 1367.54032062 5287.77251589 3325.04424199 4941.43321352
 5299.04929647 4869.50433662 4795.29710769 5043.89608946 5315.90115974]
total_rewards_mean           4110.810106025802
total_rewards_std            1598.3597560411963
total_rewards_max            5315.901159739006
total_rewards_min            862.6627782565694
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               30.491787836886942
(Previous) Eval Time (s)     23.06199363898486
Sample Time (s)              19.43550750007853
Epoch Time (s)               72.98928897595033
Total Train Time (s)         17463.295676828828
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:06:45.683379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #295 | Epoch Duration: 73.22189831733704
2020-01-10 23:06:45.683716 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025897484
Z variance train             0.03450795
KL Divergence                6.062248
KL Loss                      0.60622483
QF Loss                      1735.8347
VF Loss                      873.3866
Policy Loss                  -2223.9382
Q Predictions Mean           2222.7173
Q Predictions Std            708.05804
Q Predictions Max            2617.296
Q Predictions Min            21.298681
V Predictions Mean           2237.8794
V Predictions Std            706.31885
V Predictions Max            2630.6226
V Predictions Min            31.675152
Log Pis Mean                 -3.7562542
Log Pis Std                  5.444943
Log Pis Max                  15.99234
Log Pis Min                  -14.408057
Policy mu Mean               0.37485442
Policy mu Std                0.7016383
Policy mu Max                2.7302456
Policy mu Min                -2.8279307
Policy log std Mean          -0.2997582
Policy log std Std           0.14806424
Policy log std Max           0.0033944398
Policy log std Min           -1.0879779
Z mean eval                  0.028139973
Z variance eval              0.034593195
total_rewards                [5323.67087626 4292.61124745 5203.86851642 4160.67824564 2298.05224588
 1913.02207777 2855.62662817 2627.59643249 1527.27261766 1089.97843114]
total_rewards_mean           3129.2377318886697
total_rewards_std            1440.776345207776
total_rewards_max            5323.67087626335
total_rewards_min            1089.9784311370436
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               32.54464835207909
(Previous) Eval Time (s)     23.294286811724305
Sample Time (s)              19.588486397638917
Epoch Time (s)               75.42742156144232
Total Train Time (s)         17533.451802802272
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:07:55.841888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #296 | Epoch Duration: 70.1579225063324
2020-01-10 23:07:55.842110 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028464204
Z variance train             0.034589447
KL Divergence                6.0406218
KL Loss                      0.6040622
QF Loss                      1209.5071
VF Loss                      354.51917
Policy Loss                  -2309.3303
Q Predictions Mean           2308.2756
Q Predictions Std            615.29346
Q Predictions Max            2626.6672
Q Predictions Min            23.105623
V Predictions Mean           2304.7314
V Predictions Std            612.9021
V Predictions Max            2623.5256
V Predictions Min            31.770786
Log Pis Mean                 -3.3981557
Log Pis Std                  5.0733023
Log Pis Max                  17.324192
Log Pis Min                  -14.205215
Policy mu Mean               0.39487052
Policy mu Std                0.717073
Policy mu Max                2.7784045
Policy mu Min                -2.9194613
Policy log std Mean          -0.3061893
Policy log std Std           0.14253913
Policy log std Max           0.022776008
Policy log std Min           -0.9954275
Z mean eval                  0.024079261
Z variance eval              0.03426664
total_rewards                [5146.31574212 2454.80194469 5197.83135291 1271.13575537 1183.25166381
 1973.13881165 1228.0461801  1369.2664834  5104.63897936 1211.92147078]
total_rewards_mean           2614.0348384209565
total_rewards_std            1703.3647870125844
total_rewards_max            5197.831352913966
total_rewards_min            1183.2516638129957
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               30.624872886110097
(Previous) Eval Time (s)     18.02446510596201
Sample Time (s)              20.059012663550675
Epoch Time (s)               68.70835065562278
Total Train Time (s)         17599.22385956114
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:09:01.619701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #297 | Epoch Duration: 65.7774121761322
2020-01-10 23:09:01.620003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024075663
Z variance train             0.034272145
KL Divergence                6.0740614
KL Loss                      0.60740614
QF Loss                      1894.2416
VF Loss                      498.89975
Policy Loss                  -2234.3162
Q Predictions Mean           2236.5112
Q Predictions Std            721.3841
Q Predictions Max            2643.04
Q Predictions Min            20.261707
V Predictions Mean           2226.692
V Predictions Std            713.7745
V Predictions Max            2625.471
V Predictions Min            31.30316
Log Pis Mean                 -3.1537793
Log Pis Std                  5.568202
Log Pis Max                  21.446651
Log Pis Min                  -14.314697
Policy mu Mean               0.360063
Policy mu Std                0.7571569
Policy mu Max                2.8150299
Policy mu Min                -3.6395137
Policy log std Mean          -0.3238057
Policy log std Std           0.14826
Policy log std Max           -0.047675952
Policy log std Min           -1.3476084
Z mean eval                  0.026474107
Z variance eval              0.032834698
total_rewards                [5193.96728683 1770.61124231 5336.42864902 5176.64291786 4317.78247779
 5076.12883469 2833.91098925 5232.87317093 5205.50573787 2078.83418515]
total_rewards_mean           4222.2685491693155
total_rewards_std            1354.8110608605155
total_rewards_max            5336.428649016424
total_rewards_min            1770.6112423098111
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               32.7050615507178
(Previous) Eval Time (s)     15.093220954760909
Sample Time (s)              19.781650598160923
Epoch Time (s)               67.57993310363963
Total Train Time (s)         17676.52426893264
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:10:18.924640 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #298 | Epoch Duration: 77.30440998077393
2020-01-10 23:10:18.924930 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #298 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026175594
Z variance train             0.032827068
KL Divergence                6.2010384
KL Loss                      0.62010384
QF Loss                      1288.5591
VF Loss                      754.94763
Policy Loss                  -2211.2563
Q Predictions Mean           2208.3672
Q Predictions Std            756.53455
Q Predictions Max            2646.4949
Q Predictions Min            19.175747
V Predictions Mean           2213.7756
V Predictions Std            754.4317
V Predictions Max            2645.293
V Predictions Min            32.095165
Log Pis Mean                 -3.9067812
Log Pis Std                  5.788307
Log Pis Max                  25.854189
Log Pis Min                  -15.016595
Policy mu Mean               0.36206126
Policy mu Std                0.7252928
Policy mu Max                3.0538921
Policy mu Min                -3.0390024
Policy log std Mean          -0.30316487
Policy log std Std           0.14267693
Policy log std Max           -0.045913428
Policy log std Min           -1.0156341
Z mean eval                  0.025295088
Z variance eval              0.03225626
total_rewards                [4131.37916599 1296.23971307 2140.99897306 1651.53248699 1610.2040208
 5125.21469197 4830.88073356 4376.56174406 2400.36493455 1269.38961889]
total_rewards_mean           2883.276608293938
total_rewards_std            1471.479295749183
total_rewards_max            5125.214691967808
total_rewards_min            1269.389618889601
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               30.300939603243023
(Previous) Eval Time (s)     24.817346253897995
Sample Time (s)              19.351118290331215
Epoch Time (s)               74.46940414747223
Total Train Time (s)         17742.22479476733
Epoch                        299
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:11:24.627843 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #299 | Epoch Duration: 65.70269989967346
2020-01-10 23:11:24.628053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025214395
Z variance train             0.03225872
KL Divergence                6.2110906
KL Loss                      0.62110907
QF Loss                      1239.0695
VF Loss                      286.99796
Policy Loss                  -2272.4673
Q Predictions Mean           2267.0908
Q Predictions Std            679.2472
Q Predictions Max            2631.6704
Q Predictions Min            20.829382
V Predictions Mean           2278.9526
V Predictions Std            678.96735
V Predictions Max            2646.7776
V Predictions Min            28.525723
Log Pis Mean                 -3.3177404
Log Pis Std                  5.449566
Log Pis Max                  18.66275
Log Pis Min                  -13.781292
Policy mu Mean               0.36839762
Policy mu Std                0.75333965
Policy mu Max                2.803789
Policy mu Min                -3.1385138
Policy log std Mean          -0.31440386
Policy log std Std           0.14352034
Policy log std Max           0.037221223
Policy log std Min           -1.0112567
Z mean eval                  0.024854295
Z variance eval              0.033109747
total_rewards                [1091.68345346 5146.22413084 2962.41280123 5162.14027984 1501.15329911
 2417.57961963 5347.4509306  3661.89810237 4012.98789417 5191.98702107]
total_rewards_mean           3649.5517532320955
total_rewards_std            1518.8936803986178
total_rewards_max            5347.45093059859
total_rewards_min            1091.6834534565219
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               32.47448695125058
(Previous) Eval Time (s)     16.050346865784377
Sample Time (s)              19.07185355015099
Epoch Time (s)               67.59668736718595
Total Train Time (s)         17814.523754208814
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:12:36.930021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #300 | Epoch Duration: 72.30181908607483
2020-01-10 23:12:36.930209 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024526482
Z variance train             0.03310614
KL Divergence                6.1444654
KL Loss                      0.6144466
QF Loss                      1105.0292
VF Loss                      480.17453
Policy Loss                  -2252.819
Q Predictions Mean           2254.2837
Q Predictions Std            727.2667
Q Predictions Max            2660.0247
Q Predictions Min            17.174883
V Predictions Mean           2248.7378
V Predictions Std            719.9463
V Predictions Max            2650.9065
V Predictions Min            30.161516
Log Pis Mean                 -3.6464999
Log Pis Std                  5.1917033
Log Pis Max                  21.88206
Log Pis Min                  -13.226996
Policy mu Mean               0.35447648
Policy mu Std                0.7283005
Policy mu Max                2.5531218
Policy mu Min                -2.536634
Policy log std Mean          -0.3075276
Policy log std Std           0.14024287
Policy log std Max           -0.020574093
Policy log std Min           -0.99635524
Z mean eval                  0.02444635
Z variance eval              0.03357396
total_rewards                [2666.60886068 3277.87159661  820.22791688 3120.2639622  5327.01743351
 5377.42624165 2500.65166716 5259.40606328 2231.66176544 3587.97383907]
total_rewards_mean           3416.9109346477862
total_rewards_std            1434.3490447367792
total_rewards_max            5377.426241653297
total_rewards_min            820.2279168821531
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               30.577103154733777
(Previous) Eval Time (s)     20.75515061011538
Sample Time (s)              19.510322967078537
Epoch Time (s)               70.84257673192769
Total Train Time (s)         17884.185916346963
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:13:46.598075 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #301 | Epoch Duration: 69.66768622398376
2020-01-10 23:13:46.598363 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024282787
Z variance train             0.033566914
KL Divergence                6.1091876
KL Loss                      0.61091876
QF Loss                      779.53534
VF Loss                      624.79614
Policy Loss                  -2265.032
Q Predictions Mean           2263.7273
Q Predictions Std            711.225
Q Predictions Max            2654.0583
Q Predictions Min            18.416597
V Predictions Mean           2275.04
V Predictions Std            710.5818
V Predictions Max            2665.6604
V Predictions Min            27.221159
Log Pis Mean                 -3.8620613
Log Pis Std                  5.347317
Log Pis Max                  24.204206
Log Pis Min                  -15.949123
Policy mu Mean               0.35785824
Policy mu Std                0.712165
Policy mu Max                3.1767218
Policy mu Min                -2.7736313
Policy log std Mean          -0.30990005
Policy log std Std           0.14618883
Policy log std Max           -0.049032547
Policy log std Min           -1.0545851
Z mean eval                  0.025652856
Z variance eval              0.03359996
total_rewards                [5096.35583101 5367.64651487 1310.25579765 5232.60317181 1074.37127616
 5121.17523577 5290.4006047  5163.51228087 4945.33251074 1609.60922747]
total_rewards_mean           4021.1262451070215
total_rewards_std            1768.1877122461708
total_rewards_max            5367.646514869861
total_rewards_min            1074.3712761615084
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               30.07850739872083
(Previous) Eval Time (s)     19.579949777573347
Sample Time (s)              19.450290152337402
Epoch Time (s)               69.10874732863158
Total Train Time (s)         17956.31921792822
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:14:58.733003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #302 | Epoch Duration: 72.13443541526794
2020-01-10 23:14:58.733197 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025574496
Z variance train             0.03359681
KL Divergence                6.093503
KL Loss                      0.6093503
QF Loss                      986.8185
VF Loss                      541.1786
Policy Loss                  -2250.103
Q Predictions Mean           2245.7676
Q Predictions Std            751.28955
Q Predictions Max            2645.637
Q Predictions Min            19.015676
V Predictions Mean           2239.2634
V Predictions Std            742.6628
V Predictions Max            2626.142
V Predictions Min            27.112001
Log Pis Mean                 -4.2762904
Log Pis Std                  4.936101
Log Pis Max                  18.173704
Log Pis Min                  -14.115304
Policy mu Mean               0.32418704
Policy mu Std                0.69027734
Policy mu Max                2.4814186
Policy mu Min                -3.93434
Policy log std Mean          -0.29301
Policy log std Std           0.14246194
Policy log std Max           -0.046828263
Policy log std Min           -1.0490096
Z mean eval                  0.024015516
Z variance eval              0.030971896
total_rewards                [2326.45907093 5450.25702675 5340.73769852 5187.01493296 2101.40737927
 1290.3090508  5428.57592018 2273.23262117 4278.25019216 1876.77274924]
total_rewards_mean           3555.3016641975496
total_rewards_std            1633.6508642098981
total_rewards_max            5450.257026751092
total_rewards_min            1290.3090507984025
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               29.15946770692244
(Previous) Eval Time (s)     22.6053436701186
Sample Time (s)              20.025743530131876
Epoch Time (s)               71.79055490717292
Total Train Time (s)         18025.348140732385
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:16:07.764847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #303 | Epoch Duration: 69.03152465820312
2020-01-10 23:16:07.765016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023463637
Z variance train             0.030983865
KL Divergence                6.2915106
KL Loss                      0.62915105
QF Loss                      1305.6206
VF Loss                      552.7652
Policy Loss                  -2329.2524
Q Predictions Mean           2323.8591
Q Predictions Std            591.8919
Q Predictions Max            2631.7485
Q Predictions Min            20.9174
V Predictions Mean           2337.3857
V Predictions Std            586.912
V Predictions Max            2639.5862
V Predictions Min            33.173
Log Pis Mean                 -3.6246302
Log Pis Std                  5.4233665
Log Pis Max                  36.13604
Log Pis Min                  -14.33036
Policy mu Mean               0.40162113
Policy mu Std                0.7197159
Policy mu Max                2.6440654
Policy mu Min                -3.4316053
Policy log std Mean          -0.29503846
Policy log std Std           0.1432305
Policy log std Max           0.08762626
Policy log std Min           -1.110906
Z mean eval                  0.024478951
Z variance eval              0.03186393
total_rewards                [5212.96378388 5216.07504664 5280.59925455 2284.60473438 5295.87826136
 5397.17344036 5201.00776034 2924.3517668  5286.54165733 1091.57283042]
total_rewards_mean           4319.076853605204
total_rewards_std            1511.9360281622075
total_rewards_max            5397.173440362696
total_rewards_min            1091.5728304210415
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               30.37983210477978
(Previous) Eval Time (s)     19.84601680515334
Sample Time (s)              19.249878929462284
Epoch Time (s)               69.4757278393954
Total Train Time (s)         18100.244168547448
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:17:22.666083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #304 | Epoch Duration: 74.9009165763855
2020-01-10 23:17:22.666340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02483063
Z variance train             0.03187118
KL Divergence                6.2142653
KL Loss                      0.6214265
QF Loss                      1576.4358
VF Loss                      518.23035
Policy Loss                  -2284.3052
Q Predictions Mean           2283.7969
Q Predictions Std            701.9437
Q Predictions Max            2668.851
Q Predictions Min            22.907085
V Predictions Mean           2282.2158
V Predictions Std            693.74384
V Predictions Max            2665.956
V Predictions Min            33.391098
Log Pis Mean                 -3.671021
Log Pis Std                  5.5410075
Log Pis Max                  24.910667
Log Pis Min                  -14.228443
Policy mu Mean               0.35539526
Policy mu Std                0.7286158
Policy mu Max                3.315059
Policy mu Min                -2.7447615
Policy log std Mean          -0.30569276
Policy log std Std           0.14723185
Policy log std Max           -0.0020885766
Policy log std Min           -0.9984094
Z mean eval                  0.021483833
Z variance eval              0.031213824
total_rewards                [5258.48538057  646.95056099 5314.34242813 2369.37876673 5281.33863784
 4009.20784507 5285.96417676 4484.70448301  949.52810237 5321.77252136]
total_rewards_mean           3892.1672902834753
total_rewards_std            1779.8844308229843
total_rewards_max            5321.772521356097
total_rewards_min            646.9505609944913
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               30.985376867931336
(Previous) Eval Time (s)     25.270860956981778
Sample Time (s)              19.427834012545645
Epoch Time (s)               75.68407183745876
Total Train Time (s)         18172.223980725743
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:18:34.650309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #305 | Epoch Duration: 71.98376488685608
2020-01-10 23:18:34.650546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02138317
Z variance train             0.031215753
KL Divergence                6.257465
KL Loss                      0.6257465
QF Loss                      1449.9026
VF Loss                      494.36777
Policy Loss                  -2230.2034
Q Predictions Mean           2226.2905
Q Predictions Std            751.1598
Q Predictions Max            2656.75
Q Predictions Min            16.638842
V Predictions Mean           2237.662
V Predictions Std            752.7925
V Predictions Max            2674.998
V Predictions Min            24.84134
Log Pis Mean                 -4.349391
Log Pis Std                  5.111919
Log Pis Max                  21.588518
Log Pis Min                  -12.594364
Policy mu Mean               0.3488146
Policy mu Std                0.7000432
Policy mu Max                3.561005
Policy mu Min                -3.3391058
Policy log std Mean          -0.30097318
Policy log std Std           0.1494014
Policy log std Max           -0.025157928
Policy log std Min           -1.0237594
Z mean eval                  0.019841949
Z variance eval              0.030744454
total_rewards                [4078.81151475 3705.25030676 5256.15291749 2503.74460858 5351.16075612
 2029.94043528 5294.22410112 5203.72912778 4780.59690902 5011.2324168 ]
total_rewards_mean           4321.484309368464
total_rewards_std            1154.9432809819214
total_rewards_max            5351.1607561172095
total_rewards_min            2029.9404352805275
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               31.435278099030256
(Previous) Eval Time (s)     21.570255289785564
Sample Time (s)              19.51474163495004
Epoch Time (s)               72.52027502376586
Total Train Time (s)         18247.22377580451
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:19:49.653623 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #306 | Epoch Duration: 75.00289750099182
2020-01-10 23:19:49.653849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019787982
Z variance train             0.030756596
KL Divergence                6.300247
KL Loss                      0.63002473
QF Loss                      1846.3231
VF Loss                      416.06705
Policy Loss                  -2335.6028
Q Predictions Mean           2334.9355
Q Predictions Std            609.69086
Q Predictions Max            2663.1436
Q Predictions Min            16.898996
V Predictions Mean           2331.9756
V Predictions Std            612.3803
V Predictions Max            2662.9954
V Predictions Min            24.86668
Log Pis Mean                 -3.0551383
Log Pis Std                  5.422165
Log Pis Max                  19.314268
Log Pis Min                  -13.434118
Policy mu Mean               0.3737802
Policy mu Std                0.7530291
Policy mu Max                3.4620774
Policy mu Min                -3.090894
Policy log std Mean          -0.31569725
Policy log std Std           0.14241143
Policy log std Max           0.008082271
Policy log std Min           -1.1211282
Z mean eval                  0.02230493
Z variance eval              0.031229544
total_rewards                [1434.70361295 4699.92612675 5292.70916633 5291.02385796 2373.06053909
 3144.13677007 2176.06666986 3654.16101015 2008.52029585 3810.21651609]
total_rewards_mean           3388.4524565098573
total_rewards_std            1322.7380015583028
total_rewards_max            5292.709166334211
total_rewards_min            1434.7036129486767
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               30.31813966995105
(Previous) Eval Time (s)     24.05255261901766
Sample Time (s)              20.236686183139682
Epoch Time (s)               74.6073784721084
Total Train Time (s)         18317.29600620037
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:20:59.732471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #307 | Epoch Duration: 70.07841324806213
2020-01-10 23:20:59.732794 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022137066
Z variance train             0.031232873
KL Divergence                6.267115
KL Loss                      0.62671155
QF Loss                      2029.9316
VF Loss                      734.89874
Policy Loss                  -2269.3892
Q Predictions Mean           2267.5312
Q Predictions Std            702.4858
Q Predictions Max            2674.3425
Q Predictions Min            13.889495
V Predictions Mean           2283.391
V Predictions Std            702.5579
V Predictions Max            2686.0366
V Predictions Min            26.029415
Log Pis Mean                 -3.57305
Log Pis Std                  5.59402
Log Pis Max                  22.085663
Log Pis Min                  -13.730786
Policy mu Mean               0.34351894
Policy mu Std                0.7578308
Policy mu Max                2.9076197
Policy mu Min                -3.364973
Policy log std Mean          -0.30545095
Policy log std Std           0.14456552
Policy log std Max           0.008899093
Policy log std Min           -1.0754573
Z mean eval                  0.0245759
Z variance eval              0.030449202
total_rewards                [3405.27892124 1230.11373388 5380.16022936 5308.39363467 1234.40781577
 5296.60506556 1530.7239122   429.57941402 4310.11561363 1677.55402335]
total_rewards_mean           2980.2932363675604
total_rewards_std            1868.4089435955536
total_rewards_max            5380.160229355803
total_rewards_min            429.57941402040524
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               31.44128985516727
(Previous) Eval Time (s)     19.523212103173137
Sample Time (s)              19.007456528954208
Epoch Time (s)               69.97195848729461
Total Train Time (s)         18384.589128310326
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:22:07.027952 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #308 | Epoch Duration: 67.2948842048645
2020-01-10 23:22:07.028228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024166478
Z variance train             0.030427104
KL Divergence                6.322955
KL Loss                      0.63229555
QF Loss                      1194.388
VF Loss                      571.83435
Policy Loss                  -2328.1467
Q Predictions Mean           2332.5059
Q Predictions Std            651.7787
Q Predictions Max            2670.4187
Q Predictions Min            18.966125
V Predictions Mean           2336.6174
V Predictions Std            648.7134
V Predictions Max            2676.6584
V Predictions Min            29.734596
Log Pis Mean                 -4.0893426
Log Pis Std                  5.30851
Log Pis Max                  25.055891
Log Pis Min                  -12.494718
Policy mu Mean               0.40929118
Policy mu Std                0.68090314
Policy mu Max                3.608132
Policy mu Min                -2.7568924
Policy log std Mean          -0.3041416
Policy log std Std           0.15005194
Policy log std Max           -0.051454082
Policy log std Min           -1.0851138
Z mean eval                  0.022749888
Z variance eval              0.03216954
total_rewards                [2245.20500212 1937.81041914 5232.43298133 3142.44082769 3500.16263696
 1456.49668667 2939.89506706 2358.67953523 5173.84988035 1829.462234  ]
total_rewards_mean           2981.643527055305
total_rewards_std            1258.6457264119226
total_rewards_max            5232.432981330469
total_rewards_min            1456.496686674569
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               31.0611909260042
(Previous) Eval Time (s)     16.845788937993348
Sample Time (s)              18.95009832503274
Epoch Time (s)               66.85707818903029
Total Train Time (s)         18451.541605284438
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:23:13.983147 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #309 | Epoch Duration: 66.95475268363953
2020-01-10 23:23:13.983345 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022616198
Z variance train             0.032160573
KL Divergence                6.2092257
KL Loss                      0.62092257
QF Loss                      1214.2485
VF Loss                      748.9567
Policy Loss                  -2340.8103
Q Predictions Mean           2338.654
Q Predictions Std            633.5338
Q Predictions Max            2687.6226
Q Predictions Min            23.66148
V Predictions Mean           2339.3618
V Predictions Std            635.7667
V Predictions Max            2690.6208
V Predictions Min            33.57332
Log Pis Mean                 -3.3236027
Log Pis Std                  6.0130577
Log Pis Max                  25.712826
Log Pis Min                  -14.841259
Policy mu Mean               0.34372735
Policy mu Std                0.7566646
Policy mu Max                3.1805902
Policy mu Min                -3.5832977
Policy log std Mean          -0.30495596
Policy log std Std           0.14724767
Policy log std Max           0.059461713
Policy log std Min           -1.1071664
Z mean eval                  0.02542695
Z variance eval              0.0319992
total_rewards                [5392.49217544 5167.14970145 5422.63217645 1227.85609078 5418.00021389
 4955.89942546 2519.7627821  2804.55453495 1140.53035358 5416.52111069]
total_rewards_mean           3946.5398564807665
total_rewards_std            1723.6332641517315
total_rewards_max            5422.632176453237
total_rewards_min            1140.5303535791218
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               31.212144789285958
(Previous) Eval Time (s)     16.943206263240427
Sample Time (s)              19.33342112507671
Epoch Time (s)               67.4887721776031
Total Train Time (s)         18523.67504686676
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:24:26.122068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #310 | Epoch Duration: 72.13854217529297
2020-01-10 23:24:26.122337 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0254024
Z variance train             0.032012112
KL Divergence                6.2220736
KL Loss                      0.62220734
QF Loss                      1445.4424
VF Loss                      566.8277
Policy Loss                  -2320.5798
Q Predictions Mean           2318.5786
Q Predictions Std            653.4532
Q Predictions Max            2666.5613
Q Predictions Min            20.548725
V Predictions Mean           2323.1628
V Predictions Std            652.19525
V Predictions Max            2670.7615
V Predictions Min            31.028547
Log Pis Mean                 -3.031624
Log Pis Std                  5.5103283
Log Pis Max                  16.977692
Log Pis Min                  -12.952127
Policy mu Mean               0.32327327
Policy mu Std                0.7693774
Policy mu Max                3.026872
Policy mu Min                -3.5695717
Policy log std Mean          -0.32028162
Policy log std Std           0.14510883
Policy log std Max           0.0014899969
Policy log std Min           -1.0837734
Z mean eval                  0.024641793
Z variance eval              0.031917013
total_rewards                [2919.9036586  2105.33017217 5407.27186982 5259.4772008  1337.27198735
 3894.25843491 4963.94224699 5309.59409889 5257.51081981 1610.96151066]
total_rewards_mean           3806.5521999989273
total_rewards_std            1580.6081031582487
total_rewards_max            5407.271869816001
total_rewards_min            1337.2719873502774
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               31.862440687138587
(Previous) Eval Time (s)     21.59261954575777
Sample Time (s)              18.516346820630133
Epoch Time (s)               71.97140705352649
Total Train Time (s)         18595.76006593369
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:25:38.212866 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #311 | Epoch Duration: 72.0902955532074
2020-01-10 23:25:38.213180 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #311 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024449736
Z variance train             0.03191731
KL Divergence                6.214424
KL Loss                      0.62144244
QF Loss                      2026.8142
VF Loss                      756.4277
Policy Loss                  -2382.7698
Q Predictions Mean           2376.49
Q Predictions Std            547.8715
Q Predictions Max            2659.6814
Q Predictions Min            23.239477
V Predictions Mean           2397.278
V Predictions Std            548.02856
V Predictions Max            2686.28
V Predictions Min            32.36666
Log Pis Mean                 -3.6555748
Log Pis Std                  5.0804453
Log Pis Max                  15.843869
Log Pis Min                  -15.134192
Policy mu Mean               0.4038367
Policy mu Std                0.71633714
Policy mu Max                3.106846
Policy mu Min                -3.3473017
Policy log std Mean          -0.3080246
Policy log std Std           0.14509954
Policy log std Max           -0.0013684034
Policy log std Min           -1.2559189
Z mean eval                  0.024270805
Z variance eval              0.031462934
total_rewards                [4997.71056754 1933.21385374 5260.50658315 5195.54701621 1820.6701698
 3755.88590754 5107.17225649 5188.05443365 1301.73183967 5309.0131313 ]
total_rewards_mean           3986.950575908584
total_rewards_std            1572.3892131131993
total_rewards_max            5309.013131300999
total_rewards_min            1301.7318396681148
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               30.170014621689916
(Previous) Eval Time (s)     21.71119043743238
Sample Time (s)              19.64362771064043
Epoch Time (s)               71.52483276976272
Total Train Time (s)         18669.810694494285
Epoch                        312
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:26:52.264972 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #312 | Epoch Duration: 74.05157995223999
2020-01-10 23:26:52.265156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024534546
Z variance train             0.03146795
KL Divergence                6.2578015
KL Loss                      0.62578017
QF Loss                      1159.7258
VF Loss                      725.8721
Policy Loss                  -2348.5576
Q Predictions Mean           2345.8645
Q Predictions Std            651.1431
Q Predictions Max            2689.3289
Q Predictions Min            18.982347
V Predictions Mean           2343.7935
V Predictions Std            642.1341
V Predictions Max            2685.9634
V Predictions Min            29.615768
Log Pis Mean                 -2.848918
Log Pis Std                  5.7611527
Log Pis Max                  21.952332
Log Pis Min                  -12.144859
Policy mu Mean               0.38723946
Policy mu Std                0.7466527
Policy mu Max                3.2983513
Policy mu Min                -2.9039173
Policy log std Mean          -0.31068408
Policy log std Std           0.14052652
Policy log std Max           -0.06990658
Policy log std Min           -1.0083205
Z mean eval                  0.021803834
Z variance eval              0.032272656
total_rewards                [5334.74179512 3182.29904835 1417.90186759  677.99084101 5332.37705415
 2757.32930219 2467.81279991 5306.31542784 4311.55542521 5287.26046922]
total_rewards_mean           3607.5584030594537
total_rewards_std            1665.5529124903128
total_rewards_max            5334.7417951160505
total_rewards_min            677.9908410058613
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               31.46274380525574
(Previous) Eval Time (s)     24.23762546107173
Sample Time (s)              18.99562077410519
Epoch Time (s)               74.69599004043266
Total Train Time (s)         18740.814760214183
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:28:03.271288 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #313 | Epoch Duration: 71.00601649284363
2020-01-10 23:28:03.271439 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021822985
Z variance train             0.032266222
KL Divergence                6.175435
KL Loss                      0.6175435
QF Loss                      1036.5334
VF Loss                      396.14545
Policy Loss                  -2384.482
Q Predictions Mean           2381.2913
Q Predictions Std            611.27216
Q Predictions Max            2670.5374
Q Predictions Min            16.421402
V Predictions Mean           2383.315
V Predictions Std            608.3353
V Predictions Max            2675.5938
V Predictions Min            28.870749
Log Pis Mean                 -4.17443
Log Pis Std                  5.038242
Log Pis Max                  20.436148
Log Pis Min                  -13.861921
Policy mu Mean               0.36133215
Policy mu Std                0.69393384
Policy mu Max                3.0277946
Policy mu Min                -3.528883
Policy log std Mean          -0.28852212
Policy log std Std           0.1405481
Policy log std Max           -0.013995886
Policy log std Min           -1.0096619
Z mean eval                  0.021219408
Z variance eval              0.03153681
total_rewards                [5503.64458555 2263.43549461 5415.68685693 5433.76331689 5415.22939491
 2124.09003507 5319.92010245 2163.12513074 1320.65749678 1702.16095227]
total_rewards_mean           3666.171336619313
total_rewards_std            1769.7227302483516
total_rewards_max            5503.6445855531465
total_rewards_min            1320.657496780738
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               30.83793775131926
(Previous) Eval Time (s)     20.54734066920355
Sample Time (s)              19.11953661078587
Epoch Time (s)               70.50481503130868
Total Train Time (s)         18811.18550889427
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:29:13.646140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #314 | Epoch Duration: 70.37456750869751
2020-01-10 23:29:13.646350 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02126157
Z variance train             0.031530578
KL Divergence                6.231641
KL Loss                      0.6231641
QF Loss                      720.06433
VF Loss                      421.50726
Policy Loss                  -2333.1628
Q Predictions Mean           2325.9355
Q Predictions Std            692.812
Q Predictions Max            2689.0012
Q Predictions Min            16.585161
V Predictions Mean           2333.799
V Predictions Std            693.78827
V Predictions Max            2693.5137
V Predictions Min            26.279789
Log Pis Mean                 -4.002096
Log Pis Std                  4.5532274
Log Pis Max                  16.296078
Log Pis Min                  -14.30831
Policy mu Mean               0.4223984
Policy mu Std                0.6730956
Policy mu Max                2.9692733
Policy mu Min                -2.3038106
Policy log std Mean          -0.295156
Policy log std Std           0.13923717
Policy log std Max           0.024654552
Policy log std Min           -0.9656062
Z mean eval                  0.022712681
Z variance eval              0.030560538
total_rewards                [5430.77870815 5392.03948652 3390.98543304 1831.54791187 5450.04781977
 3093.14765891 5392.44162203 1142.07702037 2039.41951306 2035.41754424]
total_rewards_mean           3519.7902717960314
total_rewards_std            1657.9224457747462
total_rewards_max            5450.047819766364
total_rewards_min            1142.0770203724521
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               32.128250932786614
(Previous) Eval Time (s)     20.416780380066484
Sample Time (s)              19.63557722652331
Epoch Time (s)               72.18060853937641
Total Train Time (s)         18882.54307799181
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:30:25.007007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #315 | Epoch Duration: 71.36049771308899
2020-01-10 23:30:25.007211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022758303
Z variance train             0.03055738
KL Divergence                6.3039513
KL Loss                      0.6303951
QF Loss                      1274.722
VF Loss                      259.82547
Policy Loss                  -2385.406
Q Predictions Mean           2380.0732
Q Predictions Std            610.9371
Q Predictions Max            2692.8752
Q Predictions Min            22.123287
V Predictions Mean           2387.1416
V Predictions Std            609.71704
V Predictions Max            2713.1465
V Predictions Min            31.383238
Log Pis Mean                 -3.1505063
Log Pis Std                  5.640636
Log Pis Max                  29.528687
Log Pis Min                  -13.0029
Policy mu Mean               0.4065406
Policy mu Std                0.74390525
Policy mu Max                2.8456144
Policy mu Min                -2.7101421
Policy log std Mean          -0.31036368
Policy log std Std           0.14024702
Policy log std Max           0.051838934
Policy log std Min           -1.0193062
Z mean eval                  0.021078296
Z variance eval              0.03142597
total_rewards                [5414.81514826 5433.23247487 5488.50874991 1650.35117179 5316.57636752
 2350.82228788 5440.19676182 5426.69022967 5444.05344276 1880.43851515]
total_rewards_mean           4384.5685149630735
total_rewards_std            1595.432202685787
total_rewards_max            5488.5087499080055
total_rewards_min            1650.3511717905496
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               31.5605485457927
(Previous) Eval Time (s)     19.59634022321552
Sample Time (s)              19.327258130535483
Epoch Time (s)               70.4841468995437
Total Train Time (s)         18956.96160074789
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:31:39.431807 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #316 | Epoch Duration: 74.42439556121826
2020-01-10 23:31:39.432116 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02107183
Z variance train             0.031426504
KL Divergence                6.233399
KL Loss                      0.6233399
QF Loss                      1173.8746
VF Loss                      502.03204
Policy Loss                  -2353.321
Q Predictions Mean           2352.561
Q Predictions Std            672.74243
Q Predictions Max            2687.582
Q Predictions Min            21.510712
V Predictions Mean           2360.3015
V Predictions Std            674.15424
V Predictions Max            2708.1975
V Predictions Min            31.190538
Log Pis Mean                 -3.5844395
Log Pis Std                  4.589694
Log Pis Max                  15.664734
Log Pis Min                  -12.334974
Policy mu Mean               0.39681867
Policy mu Std                0.6912114
Policy mu Max                2.522897
Policy mu Min                -2.8092532
Policy log std Mean          -0.29898387
Policy log std Std           0.13855292
Policy log std Max           -0.018589929
Policy log std Min           -1.192306
Z mean eval                  0.023325747
Z variance eval              0.032508653
total_rewards                [2010.87829103 1862.3205329   860.72674157 4584.83327822 1398.25995449
 5373.4416278  1525.91824275 5384.88928487 5373.19713415 3694.15547409]
total_rewards_mean           3206.862056186804
total_rewards_std            1763.6969846882437
total_rewards_max            5384.889284874783
total_rewards_min            860.7267415687505
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               28.77387972502038
(Previous) Eval Time (s)     23.53624962689355
Sample Time (s)              19.914027174934745
Epoch Time (s)               72.22415652684867
Total Train Time (s)         19023.863666813355
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:32:46.338648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #317 | Epoch Duration: 66.90629529953003
2020-01-10 23:32:46.338912 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #317 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023174921
Z variance train             0.03251087
KL Divergence                6.1542826
KL Loss                      0.61542827
QF Loss                      1270.8025
VF Loss                      376.10822
Policy Loss                  -2413.2434
Q Predictions Mean           2412.0078
Q Predictions Std            546.42804
Q Predictions Max            2735.2717
Q Predictions Min            17.6834
V Predictions Mean           2417.2751
V Predictions Std            547.6888
V Predictions Max            2727.2417
V Predictions Min            31.324192
Log Pis Mean                 -3.7137423
Log Pis Std                  5.2548637
Log Pis Max                  29.521027
Log Pis Min                  -14.600697
Policy mu Mean               0.37829715
Policy mu Std                0.717302
Policy mu Max                2.6878617
Policy mu Min                -2.9636776
Policy log std Mean          -0.3135406
Policy log std Std           0.13872077
Policy log std Max           -0.009784296
Policy log std Min           -1.1086007
Z mean eval                  0.021402843
Z variance eval              0.031456064
total_rewards                [2448.97282281 1701.59591669  987.91945556 1376.14832389 2820.9059775
 5415.66122174 5505.8916278   810.11698405 1349.68896332  625.20342552]
total_rewards_mean           2304.2104718872497
total_rewards_std            1707.0259339395916
total_rewards_max            5505.8916277954995
total_rewards_min            625.2034255171932
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               30.37630267580971
(Previous) Eval Time (s)     18.21806687489152
Sample Time (s)              19.468081578612328
Epoch Time (s)               68.06245112931356
Total Train Time (s)         19086.218090210576
Epoch                        318
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:33:48.697249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #318 | Epoch Duration: 62.35812497138977
2020-01-10 23:33:48.697503 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02148945
Z variance train             0.03145968
KL Divergence                6.2331696
KL Loss                      0.62331694
QF Loss                      1530.2526
VF Loss                      485.24393
Policy Loss                  -2401.9133
Q Predictions Mean           2397.7268
Q Predictions Std            582.63306
Q Predictions Max            2700.5261
Q Predictions Min            21.155827
V Predictions Mean           2399.275
V Predictions Std            577.29816
V Predictions Max            2699.0376
V Predictions Min            31.463144
Log Pis Mean                 -3.179788
Log Pis Std                  5.724967
Log Pis Max                  17.99012
Log Pis Min                  -15.800234
Policy mu Mean               0.4361868
Policy mu Std                0.71535635
Policy mu Max                2.9461224
Policy mu Min                -3.3801954
Policy log std Mean          -0.30312288
Policy log std Std           0.15178445
Policy log std Max           -0.03167866
Policy log std Min           -1.1787902
Z mean eval                  0.021829195
Z variance eval              0.029856369
total_rewards                [4973.37886341 5095.25015154 5485.909889   4898.65524768 4501.13893782
 4480.22888058  647.22299792 2485.60134435 1778.89439169 3187.67973895]
total_rewards_mean           3753.396044294894
total_rewards_std            1554.47305879942
total_rewards_max            5485.9098890014275
total_rewards_min            647.2229979170578
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               30.163668400142342
(Previous) Eval Time (s)     12.513405452948064
Sample Time (s)              20.06776370247826
Epoch Time (s)               62.744837555568665
Total Train Time (s)         19156.807081900537
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:34:59.290311 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #319 | Epoch Duration: 70.59259581565857
2020-01-10 23:34:59.290617 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021657895
Z variance train             0.029870149
KL Divergence                6.3601856
KL Loss                      0.6360186
QF Loss                      1063.5549
VF Loss                      417.04822
Policy Loss                  -2364.9983
Q Predictions Mean           2355.9492
Q Predictions Std            637.037
Q Predictions Max            2677.9814
Q Predictions Min            22.72818
V Predictions Mean           2366.0977
V Predictions Std            637.02734
V Predictions Max            2701.9258
V Predictions Min            35.81782
Log Pis Mean                 -2.7449856
Log Pis Std                  5.569252
Log Pis Max                  23.463757
Log Pis Min                  -12.9643955
Policy mu Mean               0.39546517
Policy mu Std                0.75844413
Policy mu Max                2.8533716
Policy mu Min                -2.4884875
Policy log std Mean          -0.31906286
Policy log std Std           0.1541866
Policy log std Max           -0.05419209
Policy log std Min           -1.0291203
Z mean eval                  0.020030772
Z variance eval              0.030504558
total_rewards                [4554.03328828 2534.95345724 1377.71782463 2907.92618141 3183.59674847
 2644.2967054  5467.62272036 5429.86259402 5412.52512691 5494.49229883]
total_rewards_mean           3900.702694554184
total_rewards_std            1461.3455233245154
total_rewards_max            5494.492298825817
total_rewards_min            1377.7178246292176
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               31.73237428208813
(Previous) Eval Time (s)     20.36077371519059
Sample Time (s)              19.170273539144546
Epoch Time (s)               71.26342153642327
Total Train Time (s)         19228.966260882095
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:36:11.453781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #320 | Epoch Duration: 72.16291308403015
2020-01-10 23:36:11.454092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020139163
Z variance train             0.030508777
KL Divergence                6.3175426
KL Loss                      0.6317543
QF Loss                      1849.4275
VF Loss                      686.6756
Policy Loss                  -2423.4993
Q Predictions Mean           2426.7915
Q Predictions Std            581.5925
Q Predictions Max            2728.9014
Q Predictions Min            22.38505
V Predictions Mean           2416.4326
V Predictions Std            573.7107
V Predictions Max            2729.7615
V Predictions Min            33.06193
Log Pis Mean                 -3.5459878
Log Pis Std                  5.0866475
Log Pis Max                  15.323067
Log Pis Min                  -17.341465
Policy mu Mean               0.3805285
Policy mu Std                0.7341206
Policy mu Max                3.1772492
Policy mu Min                -3.283011
Policy log std Mean          -0.29933918
Policy log std Std           0.1503905
Policy log std Max           -0.015296176
Policy log std Min           -1.0720731
Z mean eval                  0.01985716
Z variance eval              0.030795421
total_rewards                [2290.41300581 2206.97850141 2221.49132173 3043.08671976 1687.2667109
 1256.21870144 3956.24498059 2050.60903613 4815.44419046  825.47605459]
total_rewards_mean           2435.3229222811046
total_rewards_std            1146.9920912809102
total_rewards_max            4815.444190455361
total_rewards_min            825.4760545908192
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               31.321536132134497
(Previous) Eval Time (s)     21.25993193499744
Sample Time (s)              19.401125808712095
Epoch Time (s)               71.98259387584403
Total Train Time (s)         19293.07808832638
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:37:15.570739 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #321 | Epoch Duration: 64.11641907691956
2020-01-10 23:37:15.571008 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019811252
Z variance train             0.030787095
KL Divergence                6.287793
KL Loss                      0.62877935
QF Loss                      1842.47
VF Loss                      484.75378
Policy Loss                  -2357.2852
Q Predictions Mean           2352.144
Q Predictions Std            629.77747
Q Predictions Max            2717.7712
Q Predictions Min            20.503782
V Predictions Mean           2353.79
V Predictions Std            627.0701
V Predictions Max            2706.9648
V Predictions Min            30.973135
Log Pis Mean                 -3.485794
Log Pis Std                  6.022442
Log Pis Max                  21.820686
Log Pis Min                  -14.488286
Policy mu Mean               0.38560605
Policy mu Std                0.7446595
Policy mu Max                3.1412153
Policy mu Min                -3.545559
Policy log std Mean          -0.30955818
Policy log std Std           0.14610264
Policy log std Max           -0.02996669
Policy log std Min           -1.12082
Z mean eval                  0.01859883
Z variance eval              0.031054666
total_rewards                [1475.76445022 5350.57120334 5246.99678774 4555.6074261  4626.91170049
 1872.03532379 2435.56319684 5410.75372379 5236.30637277 5192.09346082]
total_rewards_mean           4140.260364590111
total_rewards_std            1489.001658100278
total_rewards_max            5410.753723792127
total_rewards_min            1475.7644502190356
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               30.564424181822687
(Previous) Eval Time (s)     13.393431797157973
Sample Time (s)              19.47318809805438
Epoch Time (s)               63.43104407703504
Total Train Time (s)         19366.645214278717
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:38:29.143523 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #322 | Epoch Duration: 73.57228755950928
2020-01-10 23:38:29.143867 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018376898
Z variance train             0.031049747
KL Divergence                6.2665253
KL Loss                      0.62665254
QF Loss                      1540.6542
VF Loss                      566.1602
Policy Loss                  -2376.5452
Q Predictions Mean           2370.4102
Q Predictions Std            626.63794
Q Predictions Max            2697.5908
Q Predictions Min            16.605326
V Predictions Mean           2382.9163
V Predictions Std            629.1012
V Predictions Max            2713.179
V Predictions Min            26.631104
Log Pis Mean                 -3.5049903
Log Pis Std                  6.062342
Log Pis Max                  32.940887
Log Pis Min                  -12.938523
Policy mu Mean               0.35678825
Policy mu Std                0.74213773
Policy mu Max                3.685497
Policy mu Min                -3.323392
Policy log std Mean          -0.3109658
Policy log std Std           0.15356888
Policy log std Max           -0.024111055
Policy log std Min           -1.0788698
Z mean eval                  0.017453186
Z variance eval              0.032308355
total_rewards                [1854.48693844 5305.2360783  2430.92452991 3439.58907299 5343.24196286
 2781.27830578 3027.17975486 5053.35036637 2993.20397294 2245.96977697]
total_rewards_mean           3447.446075943312
total_rewards_std            1243.6050575377362
total_rewards_max            5343.24196286419
total_rewards_min            1854.4869384418255
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               33.345718265045434
(Previous) Eval Time (s)     23.534372174646705
Sample Time (s)              19.929838039912283
Epoch Time (s)               76.80992847960442
Total Train Time (s)         19439.555853608064
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:39:42.059520 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #323 | Epoch Duration: 72.91540122032166
2020-01-10 23:39:42.059817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017603692
Z variance train             0.032302044
KL Divergence                6.1824737
KL Loss                      0.6182474
QF Loss                      1344.3428
VF Loss                      276.09152
Policy Loss                  -2421.1616
Q Predictions Mean           2417.1416
Q Predictions Std            577.1951
Q Predictions Max            2698.3076
Q Predictions Min            20.674927
V Predictions Mean           2422.35
V Predictions Std            578.2129
V Predictions Max            2700.2966
V Predictions Min            30.150503
Log Pis Mean                 -3.5356903
Log Pis Std                  5.4352794
Log Pis Max                  30.218735
Log Pis Min                  -15.781192
Policy mu Mean               0.38462615
Policy mu Std                0.7265994
Policy mu Max                3.0930572
Policy mu Min                -2.9334486
Policy log std Mean          -0.31235382
Policy log std Std           0.13824484
Policy log std Max           -0.04452084
Policy log std Min           -1.0149131
Z mean eval                  0.017444942
Z variance eval              0.0319407
total_rewards                [2224.16951339 5463.57294571 1582.71078413 5491.82877295 2410.77743828
 1036.18049272 2197.58941714  803.76462759 1900.63382215 1520.14292633]
total_rewards_mean           2463.1370740380994
total_rewards_std            1583.5552322436943
total_rewards_max            5491.82877295041
total_rewards_min            803.7646275861063
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               33.342389199882746
(Previous) Eval Time (s)     19.639515921939164
Sample Time (s)              19.103477980475873
Epoch Time (s)               72.08538310229778
Total Train Time (s)         19505.383114500437
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:40:47.891663 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #324 | Epoch Duration: 65.83161997795105
2020-01-10 23:40:47.891939 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01747394
Z variance train             0.03193874
KL Divergence                6.216809
KL Loss                      0.6216809
QF Loss                      1138.8552
VF Loss                      351.62878
Policy Loss                  -2403.362
Q Predictions Mean           2395.4368
Q Predictions Std            630.72577
Q Predictions Max            2708.1772
Q Predictions Min            22.378656
V Predictions Mean           2403.5508
V Predictions Std            626.4613
V Predictions Max            2710.3857
V Predictions Min            34.777443
Log Pis Mean                 -4.2303324
Log Pis Std                  4.7802224
Log Pis Max                  14.72613
Log Pis Min                  -15.498141
Policy mu Mean               0.38154984
Policy mu Std                0.6792828
Policy mu Max                3.0880697
Policy mu Min                -2.3957691
Policy log std Mean          -0.28463855
Policy log std Std           0.14866856
Policy log std Max           -0.0034421682
Policy log std Min           -1.0564538
Z mean eval                  0.017925614
Z variance eval              0.031456694
total_rewards                [5443.79586178 5393.66717205 5397.79039391 1643.39945325 2355.39065378
 5202.73917108 3923.26057636 5449.12779301 1085.54495575 5349.62207244]
total_rewards_mean           4124.433810341809
total_rewards_std            1671.8884749263302
total_rewards_max            5449.12779300987
total_rewards_min            1085.544955753633
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               30.693366405554116
(Previous) Eval Time (s)     13.385451220907271
Sample Time (s)              19.09482832532376
Epoch Time (s)               63.17364595178515
Total Train Time (s)         19578.42950951075
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:42:00.943156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #325 | Epoch Duration: 73.05101251602173
2020-01-10 23:42:00.943392 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01795923
Z variance train             0.031447988
KL Divergence                6.2436104
KL Loss                      0.62436104
QF Loss                      2235.6423
VF Loss                      721.2191
Policy Loss                  -2425.0476
Q Predictions Mean           2420.6445
Q Predictions Std            587.4614
Q Predictions Max            2722.065
Q Predictions Min            24.156948
V Predictions Mean           2422.0513
V Predictions Std            581.5248
V Predictions Max            2720.889
V Predictions Min            34.42951
Log Pis Mean                 -4.3272796
Log Pis Std                  5.173565
Log Pis Max                  27.953358
Log Pis Min                  -13.398078
Policy mu Mean               0.33655503
Policy mu Std                0.7067247
Policy mu Max                2.8262074
Policy mu Min                -3.0555162
Policy log std Mean          -0.2947068
Policy log std Std           0.14047845
Policy log std Max           -0.040336087
Policy log std Min           -1.0092417
Z mean eval                  0.019447364
Z variance eval              0.02996255
total_rewards                [5286.6116437  1391.61313778 5213.98886707 5285.36555007 5339.58131907
 5230.10119554 5237.60313353 2835.73427233 2841.36981458 3643.64218876]
total_rewards_mean           4230.561112243298
total_rewards_std            1368.12349242401
total_rewards_max            5339.581319069885
total_rewards_min            1391.6131377810402
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               33.746251803822815
(Previous) Eval Time (s)     23.26251716678962
Sample Time (s)              19.419114728458226
Epoch Time (s)               76.42788369907066
Total Train Time (s)         19655.06783891702
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:43:17.586038 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #326 | Epoch Duration: 76.64244651794434
2020-01-10 23:43:17.586313 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019477978
Z variance train             0.029963905
KL Divergence                6.36009
KL Loss                      0.636009
QF Loss                      1070.4629
VF Loss                      352.54724
Policy Loss                  -2480.38
Q Predictions Mean           2481.149
Q Predictions Std            522.20844
Q Predictions Max            2723.1062
Q Predictions Min            18.791763
V Predictions Mean           2476.7651
V Predictions Std            518.7148
V Predictions Max            2710.7812
V Predictions Min            28.549894
Log Pis Mean                 -3.8768425
Log Pis Std                  4.7514706
Log Pis Max                  22.853956
Log Pis Min                  -12.517551
Policy mu Mean               0.3331456
Policy mu Std                0.72956544
Policy mu Max                2.5807257
Policy mu Min                -3.1445184
Policy log std Mean          -0.3078269
Policy log std Std           0.13687095
Policy log std Max           0.0072231144
Policy log std Min           -0.9526956
Z mean eval                  0.021473812
Z variance eval              0.029076582
total_rewards                [5212.08822474 4195.76315803 5454.85592888  910.30010379 5301.95257181
 4479.11875768 5302.51414335 5373.41959518 2832.62236604 1457.71562495]
total_rewards_mean           4052.0350474440047
total_rewards_std            1627.1661250328673
total_rewards_max            5454.855928880584
total_rewards_min            910.3001037938277
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               30.553392936941236
(Previous) Eval Time (s)     23.47674634680152
Sample Time (s)              20.335283683612943
Epoch Time (s)               74.3654229673557
Total Train Time (s)         19728.749133954756
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:44:31.272429 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #327 | Epoch Duration: 73.6858925819397
2020-01-10 23:44:31.272713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021630129
Z variance train             0.029086685
KL Divergence                6.4293833
KL Loss                      0.6429383
QF Loss                      1966.811
VF Loss                      593.2332
Policy Loss                  -2402.0984
Q Predictions Mean           2403.488
Q Predictions Std            592.66327
Q Predictions Max            2729.9211
Q Predictions Min            20.636667
V Predictions Mean           2399.106
V Predictions Std            592.721
V Predictions Max            2715.3064
V Predictions Min            31.842617
Log Pis Mean                 -2.5857944
Log Pis Std                  5.4994826
Log Pis Max                  20.655603
Log Pis Min                  -12.668425
Policy mu Mean               0.40809637
Policy mu Std                0.7474652
Policy mu Max                2.754403
Policy mu Min                -3.1926587
Policy log std Mean          -0.31721362
Policy log std Std           0.14336763
Policy log std Max           -0.00883925
Policy log std Min           -1.2362945
Z mean eval                  0.016748745
Z variance eval              0.028405014
total_rewards                [3617.68414278 3461.28176794 1243.53662465 5383.16466233 2810.55464095
 5174.719351   2601.07756686 5283.95258078 5323.34080545 4133.04874403]
total_rewards_mean           3903.23608867675
total_rewards_std            1342.5044469480292
total_rewards_max            5383.164662330411
total_rewards_min            1243.536624646777
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               29.799625700805336
(Previous) Eval Time (s)     22.796871098689735
Sample Time (s)              19.49689589161426
Epoch Time (s)               72.09339269110933
Total Train Time (s)         19800.24845197657
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:45:42.774357 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #328 | Epoch Duration: 71.5014135837555
2020-01-10 23:45:42.774548 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016724786
Z variance train             0.02840129
KL Divergence                6.4891744
KL Loss                      0.64891744
QF Loss                      1379.1654
VF Loss                      478.4523
Policy Loss                  -2403.7668
Q Predictions Mean           2399.919
Q Predictions Std            612.16205
Q Predictions Max            2711.593
Q Predictions Min            20.264708
V Predictions Mean           2396.6216
V Predictions Std            607.2164
V Predictions Max            2707.4553
V Predictions Min            29.725044
Log Pis Mean                 -3.2679806
Log Pis Std                  5.5563045
Log Pis Max                  33.565914
Log Pis Min                  -12.90358
Policy mu Mean               0.36352408
Policy mu Std                0.7313682
Policy mu Max                2.8726416
Policy mu Min                -2.9449656
Policy log std Mean          -0.29988682
Policy log std Std           0.14380533
Policy log std Max           0.043703347
Policy log std Min           -0.98652077
Z mean eval                  0.02061956
Z variance eval              0.027457234
total_rewards                [3192.88225566 5304.11199268 3919.89305109 5213.85640865 5344.75837844
  449.48017998 1056.32523654 5349.69688851 3711.23282124 5250.93285856]
total_rewards_mean           3879.3170071332584
total_rewards_std            1738.851810586083
total_rewards_max            5349.69688850513
total_rewards_min            449.48017998282387
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               31.319844160228968
(Previous) Eval Time (s)     22.204573920927942
Sample Time (s)              19.082722440361977
Epoch Time (s)               72.60714052151889
Total Train Time (s)         19872.883880461566
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:46:55.413633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #329 | Epoch Duration: 72.63891506195068
2020-01-10 23:46:55.413849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020794634
Z variance train             0.02745151
KL Divergence                6.579957
KL Loss                      0.6579957
QF Loss                      2014.5171
VF Loss                      780.36993
Policy Loss                  -2454.864
Q Predictions Mean           2452.7441
Q Predictions Std            539.5244
Q Predictions Max            2723.3083
Q Predictions Min            17.013315
V Predictions Mean           2451.3562
V Predictions Std            532.3924
V Predictions Max            2710.3828
V Predictions Min            33.26338
Log Pis Mean                 -3.1548867
Log Pis Std                  5.5283065
Log Pis Max                  23.546131
Log Pis Min                  -13.423528
Policy mu Mean               0.41988346
Policy mu Std                0.7165153
Policy mu Max                3.036149
Policy mu Min                -2.3638668
Policy log std Mean          -0.30640772
Policy log std Std           0.1430217
Policy log std Max           -0.038405664
Policy log std Min           -1.0386996
Z mean eval                  0.019645719
Z variance eval              0.027617713
total_rewards                [5210.52753778 5127.20066505 5112.37049891 5237.64461683 5200.45986837
 2933.17811712 5293.96453152 1322.47466814 5278.63606362 3238.56311832]
total_rewards_mean           4395.501968565452
total_rewards_std            1325.8305984140748
total_rewards_max            5293.964531524197
total_rewards_min            1322.4746681438128
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               31.637730001937598
(Previous) Eval Time (s)     22.236058328766376
Sample Time (s)              19.963472105562687
Epoch Time (s)               73.83726043626666
Total Train Time (s)         19949.880002554506
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:48:12.413094 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #330 | Epoch Duration: 76.99908638000488
2020-01-10 23:48:12.413285 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019793253
Z variance train             0.027616683
KL Divergence                6.5626106
KL Loss                      0.6562611
QF Loss                      3328.4321
VF Loss                      876.2855
Policy Loss                  -2464.7024
Q Predictions Mean           2458.1167
Q Predictions Std            493.411
Q Predictions Max            2727.015
Q Predictions Min            24.798334
V Predictions Mean           2458.6392
V Predictions Std            492.60034
V Predictions Max            2717.6
V Predictions Min            37.24473
Log Pis Mean                 -3.283987
Log Pis Std                  5.5028386
Log Pis Max                  22.345917
Log Pis Min                  -12.972156
Policy mu Mean               0.38193625
Policy mu Std                0.7392808
Policy mu Max                2.6720078
Policy mu Min                -2.9010477
Policy log std Mean          -0.30414987
Policy log std Std           0.1423004
Policy log std Max           -0.003688693
Policy log std Min           -1.0777307
Z mean eval                  0.018264195
Z variance eval              0.028458843
total_rewards                [5429.54414377 4133.90158794 5426.76721936 2962.09045849  830.89743896
 3070.55153396 5353.22632232 5317.16171693 5395.43491148 2342.95929068]
total_rewards_mean           4026.253462389501
total_rewards_std            1559.9294545545715
total_rewards_max            5429.544143771599
total_rewards_min            830.8974389585571
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               29.5330494903028
(Previous) Eval Time (s)     25.397512178868055
Sample Time (s)              20.137665949761868
Epoch Time (s)               75.06822761893272
Total Train Time (s)         20022.518887685146
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:49:25.054465 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #331 | Epoch Duration: 72.64103770256042
2020-01-10 23:49:25.054667 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018087823
Z variance train             0.028463801
KL Divergence                6.4995575
KL Loss                      0.64995575
QF Loss                      1649.8031
VF Loss                      606.7989
Policy Loss                  -2438.8518
Q Predictions Mean           2435.7515
Q Predictions Std            559.1089
Q Predictions Max            2722.9365
Q Predictions Min            23.88629
V Predictions Mean           2444.0596
V Predictions Std            558.81525
V Predictions Max            2721.7534
V Predictions Min            32.49575
Log Pis Mean                 -3.1255355
Log Pis Std                  5.080932
Log Pis Max                  17.282364
Log Pis Min                  -17.550858
Policy mu Mean               0.43737906
Policy mu Std                0.7201955
Policy mu Max                2.8038065
Policy mu Min                -2.68672
Policy log std Mean          -0.31553677
Policy log std Std           0.143783
Policy log std Max           -0.06453725
Policy log std Min           -1.0328782
Z mean eval                  0.02003743
Z variance eval              0.028039057
total_rewards                [2195.1809123   903.77214439 5338.15805882 2924.95488667 3698.56052413
 2760.02173707 5197.37930698 5480.97326946 2111.16963131 1446.47369709]
total_rewards_mean           3205.6644168226912
total_rewards_std            1575.572444966311
total_rewards_max            5480.973269460438
total_rewards_min            903.7721443894326
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               31.930081771221012
(Previous) Eval Time (s)     22.969976343214512
Sample Time (s)              19.79678344214335
Epoch Time (s)               74.69684155657887
Total Train Time (s)         20092.310124119744
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:50:34.849488 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #332 | Epoch Duration: 69.79465794563293
2020-01-10 23:50:34.849694 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019900892
Z variance train             0.02803812
KL Divergence                6.535313
KL Loss                      0.6535313
QF Loss                      1971.6444
VF Loss                      559.9162
Policy Loss                  -2516.3018
Q Predictions Mean           2507.8022
Q Predictions Std            370.57928
Q Predictions Max            2729.1748
Q Predictions Min            31.270592
V Predictions Mean           2517.7732
V Predictions Std            367.21353
V Predictions Max            2724.4885
V Predictions Min            40.080692
Log Pis Mean                 -2.6398244
Log Pis Std                  6.076977
Log Pis Max                  34.07802
Log Pis Min                  -12.699196
Policy mu Mean               0.37406954
Policy mu Std                0.7734524
Policy mu Max                2.950269
Policy mu Min                -2.678898
Policy log std Mean          -0.32411763
Policy log std Std           0.15347691
Policy log std Max           0.14834358
Policy log std Min           -1.3893197
Z mean eval                  0.016633179
Z variance eval              0.027008552
total_rewards                [5352.3161342  1580.71531751 1674.61830654 5207.80221159 3834.87370844
 2407.15181975 2037.32010483 5310.98930243 3149.3917014  5254.28071674]
total_rewards_mean           3580.94593234466
total_rewards_std            1523.9360984515888
total_rewards_max            5352.31613420243
total_rewards_min            1580.7153175096971
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               32.99964746227488
(Previous) Eval Time (s)     18.06743088690564
Sample Time (s)              19.415889408439398
Epoch Time (s)               70.48296775761992
Total Train Time (s)         20164.687020203564
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:51:47.231226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #333 | Epoch Duration: 72.3813681602478
2020-01-10 23:51:47.231469 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016755637
Z variance train             0.02701218
KL Divergence                6.6224914
KL Loss                      0.66224915
QF Loss                      1648.2322
VF Loss                      374.63034
Policy Loss                  -2446.1367
Q Predictions Mean           2448.039
Q Predictions Std            574.7503
Q Predictions Max            2718.5403
Q Predictions Min            21.113224
V Predictions Mean           2446.2617
V Predictions Std            572.3194
V Predictions Max            2720.6016
V Predictions Min            32.015278
Log Pis Mean                 -3.9403973
Log Pis Std                  5.3565736
Log Pis Max                  25.905495
Log Pis Min                  -13.933243
Policy mu Mean               0.39071494
Policy mu Std                0.68343306
Policy mu Max                3.0629895
Policy mu Min                -2.9176617
Policy log std Mean          -0.3017304
Policy log std Std           0.13699903
Policy log std Max           0.00904493
Policy log std Min           -1.0725716
Z mean eval                  0.02042556
Z variance eval              0.027360026
total_rewards                [5169.18891739 2349.69487894 5242.30641398 5387.0161627  2779.92204845
 5432.05182909 5427.75398299 1425.24690142 5409.81334305 5414.00820736]
total_rewards_mean           4403.700268536349
total_rewards_std            1487.3499987258351
total_rewards_max            5432.051829088407
total_rewards_min            1425.2469014246549
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               31.32546585192904
(Previous) Eval Time (s)     19.965519635006785
Sample Time (s)              19.530866914894432
Epoch Time (s)               70.82185240183026
Total Train Time (s)         20239.68231703434
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:53:02.233462 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #334 | Epoch Duration: 75.00178933143616
2020-01-10 23:53:02.233727 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020421283
Z variance train             0.027361652
KL Divergence                6.5944176
KL Loss                      0.65944177
QF Loss                      1600.0946
VF Loss                      469.27292
Policy Loss                  -2479.6453
Q Predictions Mean           2477.269
Q Predictions Std            482.75128
Q Predictions Max            2719.0286
Q Predictions Min            22.549416
V Predictions Mean           2482.605
V Predictions Std            479.52878
V Predictions Max            2735.6057
V Predictions Min            35.534256
Log Pis Mean                 -3.544259
Log Pis Std                  5.484453
Log Pis Max                  35.92189
Log Pis Min                  -14.195108
Policy mu Mean               0.3830659
Policy mu Std                0.7264526
Policy mu Max                2.8758757
Policy mu Min                -3.6158266
Policy log std Mean          -0.31449497
Policy log std Std           0.14477327
Policy log std Max           -0.06646477
Policy log std Min           -1.0575838
Z mean eval                  0.019250743
Z variance eval              0.029148351
total_rewards                [5315.93696656 1550.07767724 3657.84404557 5366.79812318 1612.41694204
 5373.35507169 5339.19598869 5447.25709539 5376.75160105 2272.63225023]
total_rewards_mean           4131.226576165019
total_rewards_std            1609.3698603216267
total_rewards_max            5447.257095394256
total_rewards_min            1550.077677241125
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               30.567072823178023
(Previous) Eval Time (s)     24.145052250940353
Sample Time (s)              20.03588609304279
Epoch Time (s)               74.74801116716117
Total Train Time (s)         20312.91742641339
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:54:15.468627 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #335 | Epoch Duration: 73.23472428321838
2020-01-10 23:54:15.468777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019210268
Z variance train             0.029147455
KL Divergence                6.456545
KL Loss                      0.6456545
QF Loss                      1261.8575
VF Loss                      537.6918
Policy Loss                  -2503.4236
Q Predictions Mean           2497.5159
Q Predictions Std            458.752
Q Predictions Max            2742.2139
Q Predictions Min            21.895159
V Predictions Mean           2503.5122
V Predictions Std            454.63745
V Predictions Max            2752.0364
V Predictions Min            30.714073
Log Pis Mean                 -3.0528502
Log Pis Std                  5.8206697
Log Pis Max                  25.970772
Log Pis Min                  -13.346821
Policy mu Mean               0.37365457
Policy mu Std                0.74147207
Policy mu Max                2.9098234
Policy mu Min                -3.033593
Policy log std Mean          -0.31759173
Policy log std Std           0.13814528
Policy log std Max           -0.06151814
Policy log std Min           -1.1180503
Z mean eval                  0.015997017
Z variance eval              0.029263249
total_rewards                [1141.50276419  846.46637763 1883.83467913 3510.66537412 3150.58492973
 1135.54541198 5431.36644586 5524.12867245 3619.41518996 4526.61322834]
total_rewards_mean           3077.012307337992
total_rewards_std            1674.3617422375132
total_rewards_max            5524.128672445015
total_rewards_min            846.4663776301991
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               30.15976649383083
(Previous) Eval Time (s)     22.63144944095984
Sample Time (s)              20.091613243799657
Epoch Time (s)               72.88282917859033
Total Train Time (s)         20379.67334703915
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:55:22.227874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #336 | Epoch Duration: 66.75898241996765
2020-01-10 23:55:22.228063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01593371
Z variance train             0.029263068
KL Divergence                6.4466515
KL Loss                      0.6446652
QF Loss                      1197.3362
VF Loss                      834.5677
Policy Loss                  -2463.8079
Q Predictions Mean           2467.1575
Q Predictions Std            522.69183
Q Predictions Max            2729.4387
Q Predictions Min            14.065225
V Predictions Mean           2471.3105
V Predictions Std            516.9285
V Predictions Max            2734.4827
V Predictions Min            24.708014
Log Pis Mean                 -3.525993
Log Pis Std                  5.102271
Log Pis Max                  25.013973
Log Pis Min                  -13.159203
Policy mu Mean               0.38233906
Policy mu Std                0.72754973
Policy mu Max                2.982385
Policy mu Min                -2.8558936
Policy log std Mean          -0.30132967
Policy log std Std           0.14900126
Policy log std Max           -0.012497097
Policy log std Min           -0.9666875
Z mean eval                  0.020338994
Z variance eval              0.031269122
total_rewards                [5420.54131554 5373.04885974 5168.45912169 2101.64157576 5352.32446398
 4360.32383656 1661.01977872 5397.69009984 5371.52550268 5413.24628788]
total_rewards_mean           4561.982084239617
total_rewards_std            1377.5104966843649
total_rewards_max            5420.541315536779
total_rewards_min            1661.0197787228922
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               29.997536584269255
(Previous) Eval Time (s)     16.50722450017929
Sample Time (s)              19.201305576134473
Epoch Time (s)               65.70606666058302
Total Train Time (s)         20454.183106390294
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:56:36.740035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #337 | Epoch Duration: 74.51184749603271
2020-01-10 23:56:36.740241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020382654
Z variance train             0.03127348
KL Divergence                6.302353
KL Loss                      0.6302353
QF Loss                      1332.2465
VF Loss                      610.51013
Policy Loss                  -2487.604
Q Predictions Mean           2485.0796
Q Predictions Std            479.8121
Q Predictions Max            2753.6787
Q Predictions Min            24.122177
V Predictions Mean           2497.382
V Predictions Std            480.46902
V Predictions Max            2748.0276
V Predictions Min            35.899372
Log Pis Mean                 -4.167069
Log Pis Std                  5.2817435
Log Pis Max                  25.798073
Log Pis Min                  -13.595632
Policy mu Mean               0.36129177
Policy mu Std                0.7067898
Policy mu Max                3.2348895
Policy mu Min                -2.95695
Policy log std Mean          -0.30216593
Policy log std Std           0.14353098
Policy log std Max           -0.026088625
Policy log std Min           -1.0118855
Z mean eval                  0.022995088
Z variance eval              0.032463502
total_rewards                [3028.56459488 5407.62120296 4455.77598348 1550.66652886 1623.05690206
 3114.72005353  882.25209425 5214.1387025  2255.03110824 1868.68558452]
total_rewards_mean           2940.051275527921
total_rewards_std            1520.2834883735518
total_rewards_max            5407.621202959982
total_rewards_min            882.2520942527119
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               32.79288029810414
(Previous) Eval Time (s)     25.312685414217412
Sample Time (s)              20.012957745231688
Epoch Time (s)               78.11852345755324
Total Train Time (s)         20523.374720797874
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:57:45.935558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #338 | Epoch Duration: 69.19517207145691
2020-01-10 23:57:45.935778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022838438
Z variance train             0.032445453
KL Divergence                6.2156997
KL Loss                      0.62157
QF Loss                      1198.9023
VF Loss                      479.4288
Policy Loss                  -2535.0095
Q Predictions Mean           2536.1514
Q Predictions Std            425.07166
Q Predictions Max            2754.342
Q Predictions Min            19.096119
V Predictions Mean           2540.8735
V Predictions Std            425.67007
V Predictions Max            2760.2776
V Predictions Min            34.459896
Log Pis Mean                 -3.6373768
Log Pis Std                  5.2984457
Log Pis Max                  34.062836
Log Pis Min                  -16.645405
Policy mu Mean               0.32775834
Policy mu Std                0.7398511
Policy mu Max                2.86364
Policy mu Min                -2.9708526
Policy log std Mean          -0.3057115
Policy log std Std           0.13943559
Policy log std Max           -0.047346875
Policy log std Min           -0.96195704
Z mean eval                  0.021389829
Z variance eval              0.031658746
total_rewards                [1613.29220185 1934.24637047 1160.38301615 1171.71195809 2140.22181856
 5486.27621358 1436.68534806 2747.80805851  735.96463307  999.58246857]
total_rewards_mean           1942.6172086908532
total_rewards_std            1309.9962330019328
total_rewards_max            5486.276213581444
total_rewards_min            735.9646330737168
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               30.268252500798553
(Previous) Eval Time (s)     16.38897516671568
Sample Time (s)              19.928403643425554
Epoch Time (s)               66.58563131093979
Total Train Time (s)         20584.3241992807
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:58:46.891984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #339 | Epoch Duration: 60.95599699020386
2020-01-10 23:58:46.892286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02101055
Z variance train             0.031668004
KL Divergence                6.259652
KL Loss                      0.62596524
QF Loss                      2139.6384
VF Loss                      535.4582
Policy Loss                  -2509.4094
Q Predictions Mean           2503.9663
Q Predictions Std            479.36996
Q Predictions Max            2727.2996
Q Predictions Min            17.659649
V Predictions Mean           2525.3032
V Predictions Std            481.63925
V Predictions Max            2748.8833
V Predictions Min            26.372145
Log Pis Mean                 -3.8889656
Log Pis Std                  5.299627
Log Pis Max                  23.620518
Log Pis Min                  -12.837549
Policy mu Mean               0.35876638
Policy mu Std                0.7101021
Policy mu Max                3.1649559
Policy mu Min                -3.1403627
Policy log std Mean          -0.30531383
Policy log std Std           0.13909605
Policy log std Max           -0.030362159
Policy log std Min           -1.1125317
Z mean eval                  0.019338237
Z variance eval              0.031003807
total_rewards                [5355.54742227 3595.35783902 1426.30512031 1584.11761374 2648.33378923
 5192.30603871 2420.23983243 1766.47250279 1938.4155837  3143.36026912]
total_rewards_mean           2907.045601132869
total_rewards_std            1350.2958337924229
total_rewards_max            5355.54742226788
total_rewards_min            1426.3051203096256
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               29.909502000082284
(Previous) Eval Time (s)     10.758992438670248
Sample Time (s)              19.587690675165504
Epoch Time (s)               60.256185113918036
Total Train Time (s)         20650.839742474724
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-10 23:59:53.409725 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #340 | Epoch Duration: 66.51720809936523
2020-01-10 23:59:53.409933 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #340 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019057488
Z variance train             0.030998453
KL Divergence                6.283947
KL Loss                      0.6283947
QF Loss                      2310.382
VF Loss                      707.9503
Policy Loss                  -2405.4136
Q Predictions Mean           2404.7976
Q Predictions Std            604.36816
Q Predictions Max            2750.5867
Q Predictions Min            23.946234
V Predictions Mean           2415.6736
V Predictions Std            610.57196
V Predictions Max            2774.0557
V Predictions Min            28.856667
Log Pis Mean                 -2.6926053
Log Pis Std                  6.916603
Log Pis Max                  35.63913
Log Pis Min                  -16.505112
Policy mu Mean               0.35351253
Policy mu Std                0.7938796
Policy mu Max                3.6772091
Policy mu Min                -4.287804
Policy log std Mean          -0.32135695
Policy log std Std           0.14676408
Policy log std Max           -0.017957553
Policy log std Min           -1.0260973
Z mean eval                  0.01991253
Z variance eval              0.030382354
total_rewards                [1360.12859615 3153.22197841 3327.43328904 5427.43941317 2658.47767474
 4915.52617502 5458.84200805 3641.76519145 5267.45361576 1467.33552139]
total_rewards_mean           3667.7623463169816
total_rewards_std            1482.8120332198378
total_rewards_max            5458.842008054631
total_rewards_min            1360.128596149871
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               30.705565471202135
(Previous) Eval Time (s)     17.019679524935782
Sample Time (s)              18.606984939891845
Epoch Time (s)               66.33222993602976
Total Train Time (s)         20720.157709282357
Epoch                        341
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:01:02.731530 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #341 | Epoch Duration: 69.32143974304199
2020-01-11 00:01:02.731717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019820657
Z variance train             0.030389443
KL Divergence                6.336866
KL Loss                      0.6336866
QF Loss                      1479.7507
VF Loss                      404.02893
Policy Loss                  -2524.1218
Q Predictions Mean           2518.887
Q Predictions Std            439.62518
Q Predictions Max            2737.0022
Q Predictions Min            23.932749
V Predictions Mean           2522.9062
V Predictions Std            439.31818
V Predictions Max            2742.6284
V Predictions Min            33.219627
Log Pis Mean                 -3.1005354
Log Pis Std                  5.1567583
Log Pis Max                  21.967495
Log Pis Min                  -13.170756
Policy mu Mean               0.33737075
Policy mu Std                0.7552033
Policy mu Max                3.0427718
Policy mu Min                -2.8154404
Policy log std Mean          -0.31340575
Policy log std Std           0.14490816
Policy log std Max           -0.039371386
Policy log std Min           -1.0275317
Z mean eval                  0.02857365
Z variance eval              0.030649185
total_rewards                [ 436.22785213 2158.40473659 1447.68002915 5281.58642274 2476.95760986
 1337.50174962 3223.76556114 2804.7314838  4796.2153185  3140.3522608 ]
total_rewards_mean           2710.3423024335525
total_rewards_std            1429.3107119866238
total_rewards_max            5281.586422738846
total_rewards_min            436.22785212962293
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               31.468266579788178
(Previous) Eval Time (s)     20.008586538024247
Sample Time (s)              19.36757521610707
Epoch Time (s)               70.8444283339195
Total Train Time (s)         20786.62484918395
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:02:09.200998 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #342 | Epoch Duration: 66.46912169456482
2020-01-11 00:02:09.201236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028604085
Z variance train             0.030646766
KL Divergence                6.3251486
KL Loss                      0.6325149
QF Loss                      1668.1648
VF Loss                      738.04126
Policy Loss                  -2495.9353
Q Predictions Mean           2497.4033
Q Predictions Std            508.5439
Q Predictions Max            2754.3376
Q Predictions Min            17.121983
V Predictions Mean           2491.7334
V Predictions Std            508.23227
V Predictions Max            2752.0298
V Predictions Min            27.76513
Log Pis Mean                 -3.9301846
Log Pis Std                  5.3350344
Log Pis Max                  20.694958
Log Pis Min                  -15.675814
Policy mu Mean               0.31204513
Policy mu Std                0.7478895
Policy mu Max                3.1585004
Policy mu Min                -3.2141013
Policy log std Mean          -0.30541968
Policy log std Std           0.13884112
Policy log std Max           -0.053588904
Policy log std Min           -1.0438237
Z mean eval                  0.025265375
Z variance eval              0.029498458
total_rewards                [5356.20384701 3581.10633231 5421.02951611 5339.81288389 4161.95432578
 5324.14939714 5272.62821863 3962.87490159 5375.2519232  3659.9398133 ]
total_rewards_mean           4745.495115895901
total_rewards_std            753.5963786339029
total_rewards_max            5421.029516109859
total_rewards_min            3581.1063323124513
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               28.226871132384986
(Previous) Eval Time (s)     15.632975758984685
Sample Time (s)              18.737073800060898
Epoch Time (s)               62.59692069143057
Total Train Time (s)         20860.395335996523
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:03:22.975480 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #343 | Epoch Duration: 73.77408695220947
2020-01-11 00:03:22.975685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025411785
Z variance train             0.029501636
KL Divergence                6.4165497
KL Loss                      0.64165497
QF Loss                      942.72845
VF Loss                      511.23773
Policy Loss                  -2498.381
Q Predictions Mean           2497.2095
Q Predictions Std            529.95184
Q Predictions Max            2753.1956
Q Predictions Min            25.12306
V Predictions Mean           2488.82
V Predictions Std            528.5834
V Predictions Max            2746.6226
V Predictions Min            36.401615
Log Pis Mean                 -3.5331945
Log Pis Std                  5.2951922
Log Pis Max                  16.22271
Log Pis Min                  -15.522459
Policy mu Mean               0.29985595
Policy mu Std                0.75154394
Policy mu Max                2.608488
Policy mu Min                -2.5873046
Policy log std Mean          -0.29821467
Policy log std Std           0.13559707
Policy log std Max           0.06136352
Policy log std Min           -0.8851599
Z mean eval                  0.023604736
Z variance eval              0.029713443
total_rewards                [ 891.83790195 5172.74531872 5180.96228404 1467.0900524  1996.02091341
 2762.46450589 5180.04263962 1859.91887384 4962.47025274 5295.40353692]
total_rewards_mean           3476.8956279535223
total_rewards_std            1738.7989974744355
total_rewards_max            5295.403536919759
total_rewards_min            891.8379019507568
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               30.827524945139885
(Previous) Eval Time (s)     26.8098287708126
Sample Time (s)              19.32197776529938
Epoch Time (s)               76.95933148125187
Total Train Time (s)         20929.986183893867
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:04:32.571514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #344 | Epoch Duration: 69.59565305709839
2020-01-11 00:04:32.571773 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02421904
Z variance train             0.029718291
KL Divergence                6.3935003
KL Loss                      0.63935006
QF Loss                      2580.9604
VF Loss                      559.09033
Policy Loss                  -2458.2246
Q Predictions Mean           2459.6763
Q Predictions Std            619.628
Q Predictions Max            2753.1833
Q Predictions Min            22.120136
V Predictions Mean           2450.553
V Predictions Std            617.34393
V Predictions Max            2749.836
V Predictions Min            31.22765
Log Pis Mean                 -3.5466917
Log Pis Std                  5.1431394
Log Pis Max                  23.35006
Log Pis Min                  -13.469818
Policy mu Mean               0.2862939
Policy mu Std                0.7510291
Policy mu Max                2.8182225
Policy mu Min                -2.7202687
Policy log std Mean          -0.30898958
Policy log std Std           0.13972643
Policy log std Max           0.007288754
Policy log std Min           -0.99467266
Z mean eval                  0.024964264
Z variance eval              0.029345483
total_rewards                [1179.05501283 5438.14176457 3803.99631274 5343.78698572 3300.88223725
 2598.4489413  1561.52100373 2598.16761105 5473.07843563 5224.77626202]
total_rewards_mean           3652.185456683944
total_rewards_std            1571.4603255070544
total_rewards_max            5473.078435625018
total_rewards_min            1179.0550128293326
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               33.224433690775186
(Previous) Eval Time (s)     19.44582003587857
Sample Time (s)              19.005785007029772
Epoch Time (s)               71.67603873368353
Total Train Time (s)         21002.09762926353
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:05:44.685782 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #345 | Epoch Duration: 72.11381244659424
2020-01-11 00:05:44.686002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #345 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025059903
Z variance train             0.029346908
KL Divergence                6.401846
KL Loss                      0.6401846
QF Loss                      919.67664
VF Loss                      284.74152
Policy Loss                  -2481.4045
Q Predictions Mean           2484.142
Q Predictions Std            587.15295
Q Predictions Max            2756.899
Q Predictions Min            22.122343
V Predictions Mean           2483.891
V Predictions Std            585.74304
V Predictions Max            2762.16
V Predictions Min            33.46106
Log Pis Mean                 -3.8247652
Log Pis Std                  4.745501
Log Pis Max                  22.642029
Log Pis Min                  -12.441871
Policy mu Mean               0.35013434
Policy mu Std                0.7114023
Policy mu Max                2.6216948
Policy mu Min                -2.7228894
Policy log std Mean          -0.3004768
Policy log std Std           0.13547991
Policy log std Max           -0.058222905
Policy log std Min           -1.0311905
Z mean eval                  0.024779147
Z variance eval              0.029318977
total_rewards                [5369.01134684 5255.83787056 1072.17159796 1841.63706956 4406.90533376
 2649.51105108 5274.03437203 2866.716141   4339.85636148 5318.0914454 ]
total_rewards_mean           3839.377258967807
total_rewards_std            1522.293976526265
total_rewards_max            5369.011346836072
total_rewards_min            1072.1715979591536
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               30.387530652806163
(Previous) Eval Time (s)     19.883264258038253
Sample Time (s)              19.49782935436815
Epoch Time (s)               69.76862426521257
Total Train Time (s)         21073.128363885917
Epoch                        346
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:06:55.719659 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #346 | Epoch Duration: 71.03351140022278
2020-01-11 00:06:55.719874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024879828
Z variance train             0.029319067
KL Divergence                6.403879
KL Loss                      0.64038795
QF Loss                      1985.4412
VF Loss                      272.17685
Policy Loss                  -2538.277
Q Predictions Mean           2530.71
Q Predictions Std            460.6455
Q Predictions Max            2751.13
Q Predictions Min            28.83017
V Predictions Mean           2545.2927
V Predictions Std            464.98175
V Predictions Max            2767.0898
V Predictions Min            36.641846
Log Pis Mean                 -3.983835
Log Pis Std                  4.38123
Log Pis Max                  23.24244
Log Pis Min                  -12.829168
Policy mu Mean               0.37233722
Policy mu Std                0.68131953
Policy mu Max                2.977762
Policy mu Min                -2.630477
Policy log std Mean          -0.3065835
Policy log std Std           0.13251355
Policy log std Max           0.009204403
Policy log std Min           -0.9346714
Z mean eval                  0.025352802
Z variance eval              0.030109327
total_rewards                [5420.00151665 3865.97057453 2666.15312401 5300.8935786  2204.86574349
 5229.2771314  1252.97691879 5413.49308085 1032.66247807 5317.14921402]
total_rewards_mean           3770.3443360411356
total_rewards_std            1726.1553907394657
total_rewards_max            5420.001516652245
total_rewards_min            1032.6624780663328
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               31.92853275826201
(Previous) Eval Time (s)     21.14782413095236
Sample Time (s)              19.3572539803572
Epoch Time (s)               72.43361086957157
Total Train Time (s)         21145.575660358183
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:08:08.173163 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #347 | Epoch Duration: 72.45311903953552
2020-01-11 00:08:08.173423 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02513358
Z variance train             0.030113423
KL Divergence                6.345181
KL Loss                      0.6345181
QF Loss                      811.2191
VF Loss                      362.6266
Policy Loss                  -2520.741
Q Predictions Mean           2515.7493
Q Predictions Std            521.3639
Q Predictions Max            2751.6733
Q Predictions Min            20.919666
V Predictions Mean           2527.5068
V Predictions Std            523.0463
V Predictions Max            2768.4878
V Predictions Min            32.920895
Log Pis Mean                 -3.4700265
Log Pis Std                  4.4541802
Log Pis Max                  16.580505
Log Pis Min                  -11.990383
Policy mu Mean               0.3688621
Policy mu Std                0.71578693
Policy mu Max                2.8619752
Policy mu Min                -2.583658
Policy log std Mean          -0.3133962
Policy log std Std           0.14519568
Policy log std Max           -0.03794708
Policy log std Min           -1.0491087
Z mean eval                  0.02930263
Z variance eval              0.029342284
total_rewards                [5427.47572049 4758.77247111 4941.86348363 5399.35331636 5271.74184768
 5425.61751578 1797.49735191 5343.18726021 5288.65046774 5355.31518861]
total_rewards_mean           4900.947462350571
total_rewards_std            1055.6532418314794
total_rewards_max            5427.47572048768
total_rewards_min            1797.4973519054938
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               30.367552044335753
(Previous) Eval Time (s)     21.166989273857325
Sample Time (s)              20.585472392383963
Epoch Time (s)               72.12001371057704
Total Train Time (s)         21224.7560445657
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:09:27.359380 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #348 | Epoch Duration: 79.18571662902832
2020-01-11 00:09:27.359717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02942494
Z variance train             0.029337395
KL Divergence                6.4024506
KL Loss                      0.6402451
QF Loss                      720.9541
VF Loss                      351.3096
Policy Loss                  -2552.667
Q Predictions Mean           2546.7505
Q Predictions Std            449.6752
Q Predictions Max            2743.0674
Q Predictions Min            16.71281
V Predictions Mean           2543.891
V Predictions Std            445.23492
V Predictions Max            2740.6248
V Predictions Min            30.403894
Log Pis Mean                 -4.2091293
Log Pis Std                  4.5479803
Log Pis Max                  15.060488
Log Pis Min                  -15.245937
Policy mu Mean               0.34586927
Policy mu Std                0.7103396
Policy mu Max                2.4232435
Policy mu Min                -2.470735
Policy log std Mean          -0.3001916
Policy log std Std           0.13260767
Policy log std Max           -0.023474514
Policy log std Min           -0.83996516
Z mean eval                  0.029373804
Z variance eval              0.029595803
total_rewards                [3322.21990964 5343.41300055 1109.87228584 2128.62022574 5335.81639191
 1707.39785452 5417.0648234  5319.74315745 5441.78340551 3988.53906658]
total_rewards_mean           3911.447012114084
total_rewards_std            1640.4183605118826
total_rewards_max            5441.783405511065
total_rewards_min            1109.8722858432209
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               30.183211406692863
(Previous) Eval Time (s)     28.232322894968092
Sample Time (s)              19.39237781241536
Epoch Time (s)               77.80791211407632
Total Train Time (s)         21295.402993735857
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:10:38.011233 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #349 | Epoch Duration: 70.65123319625854
2020-01-11 00:10:38.011516 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02929244
Z variance train             0.029598797
KL Divergence                6.3855324
KL Loss                      0.63855326
QF Loss                      2313.0283
VF Loss                      891.1058
Policy Loss                  -2494.1624
Q Predictions Mean           2492.2385
Q Predictions Std            503.8196
Q Predictions Max            2760.0554
Q Predictions Min            23.490227
V Predictions Mean           2499.669
V Predictions Std            495.30148
V Predictions Max            2764.4758
V Predictions Min            33.085014
Log Pis Mean                 -3.10913
Log Pis Std                  5.508976
Log Pis Max                  17.70145
Log Pis Min                  -13.436038
Policy mu Mean               0.3793942
Policy mu Std                0.7554526
Policy mu Max                3.2324324
Policy mu Min                -2.9877741
Policy log std Mean          -0.31013736
Policy log std Std           0.15016252
Policy log std Max           -0.018961951
Policy log std Min           -1.245886
Z mean eval                  0.022822095
Z variance eval              0.03097555
total_rewards                [5385.05278823 5424.69551558 3412.20925317 1996.81415639 5370.14729437
 3953.52308821 1952.71481992 4827.42173684 2950.54446418 2119.02865803]
total_rewards_mean           3739.215177491458
total_rewards_std            1379.172576207361
total_rewards_max            5424.695515577483
total_rewards_min            1952.7148199231933
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               28.988891321700066
(Previous) Eval Time (s)     21.07536533009261
Sample Time (s)              19.902378061786294
Epoch Time (s)               69.96663471357897
Total Train Time (s)         21365.18767486699
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:11:47.802355 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #350 | Epoch Duration: 69.79060077667236
2020-01-11 00:11:47.802635 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023265969
Z variance train             0.03097566
KL Divergence                6.283615
KL Loss                      0.6283615
QF Loss                      1350.7156
VF Loss                      313.15936
Policy Loss                  -2534.4922
Q Predictions Mean           2530.3896
Q Predictions Std            478.68436
Q Predictions Max            2763.976
Q Predictions Min            15.5271845
V Predictions Mean           2536.2412
V Predictions Std            479.66037
V Predictions Max            2762.6206
V Predictions Min            25.329477
Log Pis Mean                 -3.459958
Log Pis Std                  5.6651964
Log Pis Max                  21.708775
Log Pis Min                  -14.065119
Policy mu Mean               0.32686475
Policy mu Std                0.75365
Policy mu Max                2.7920434
Policy mu Min                -2.7406628
Policy log std Mean          -0.30509603
Policy log std Std           0.13998424
Policy log std Max           0.11257321
Policy log std Min           -0.8438924
Z mean eval                  0.023552716
Z variance eval              0.031737894
total_rewards                [5475.76913849 5489.31405729 5262.71751961 5382.94192125 5278.37990077
 5366.37141222 4052.25131893 3005.58003093 4433.05146776 5336.80331368]
total_rewards_mean           4908.318008092208
total_rewards_std            782.2993493676099
total_rewards_max            5489.3140572922675
total_rewards_min            3005.580030928577
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               30.81427953299135
(Previous) Eval Time (s)     20.89902359014377
Sample Time (s)              19.748615299351513
Epoch Time (s)               71.46191842248663
Total Train Time (s)         21443.474252228625
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:13:06.093426 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #351 | Epoch Duration: 78.29057288169861
2020-01-11 00:13:06.093681 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02323597
Z variance train             0.031730797
KL Divergence                6.241067
KL Loss                      0.6241067
QF Loss                      1184.3601
VF Loss                      517.2991
Policy Loss                  -2535.9717
Q Predictions Mean           2531.4592
Q Predictions Std            491.87585
Q Predictions Max            2757.6223
Q Predictions Min            16.616014
V Predictions Mean           2548.3462
V Predictions Std            490.24875
V Predictions Max            2777.866
V Predictions Min            27.7897
Log Pis Mean                 -3.868527
Log Pis Std                  4.7723207
Log Pis Max                  24.084509
Log Pis Min                  -14.173346
Policy mu Mean               0.3763064
Policy mu Std                0.6982953
Policy mu Max                3.3069656
Policy mu Min                -2.888935
Policy log std Mean          -0.3027036
Policy log std Std           0.13750002
Policy log std Max           -0.040203772
Policy log std Min           -1.349004
Z mean eval                  0.022089703
Z variance eval              0.03177347
total_rewards                [2765.91029953 3003.69695316 3468.42793211 5445.04841951 2169.91802206
 5453.47048461 2102.71898359 5401.27795148 5423.91387439 2230.93046039]
total_rewards_mean           3746.531338083357
total_rewards_std            1429.1968628609318
total_rewards_max            5453.470484610652
total_rewards_min            2102.718983585161
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               30.868982936721295
(Previous) Eval Time (s)     27.727362843696028
Sample Time (s)              19.593194941990077
Epoch Time (s)               78.1895407224074
Total Train Time (s)         21515.102811185177
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:14:17.728201 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #352 | Epoch Duration: 71.63427758216858
2020-01-11 00:14:17.728524 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02212602
Z variance train             0.03177757
KL Divergence                6.250136
KL Loss                      0.6250136
QF Loss                      1082.6082
VF Loss                      775.9405
Policy Loss                  -2557.6182
Q Predictions Mean           2558.4202
Q Predictions Std            449.1533
Q Predictions Max            2763.642
Q Predictions Min            22.052471
V Predictions Mean           2552.7925
V Predictions Std            446.29892
V Predictions Max            2762.6667
V Predictions Min            29.67987
Log Pis Mean                 -3.6313324
Log Pis Std                  5.2908015
Log Pis Max                  24.355228
Log Pis Min                  -13.523175
Policy mu Mean               0.34325066
Policy mu Std                0.73967516
Policy mu Max                2.8966353
Policy mu Min                -2.8690674
Policy log std Mean          -0.30756143
Policy log std Std           0.14208895
Policy log std Max           -0.062144578
Policy log std Min           -1.0638278
Z mean eval                  0.02617078
Z variance eval              0.029307913
total_rewards                [3336.5890534  2204.58128146 2354.58130924 5419.55187588  909.18506313
 5538.74984807 1841.944536   1707.88974198 5444.82998745 5149.30832799]
total_rewards_mean           3390.721102459122
total_rewards_std            1729.5741996294055
total_rewards_max            5538.749848070405
total_rewards_min            909.1850631258337
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               31.3502192562446
(Previous) Eval Time (s)     21.171779872849584
Sample Time (s)              19.23499425407499
Epoch Time (s)               71.75699338316917
Total Train Time (s)         21584.303641145583
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:15:26.931273 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #353 | Epoch Duration: 69.2025396823883
2020-01-11 00:15:26.931473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026428184
Z variance train             0.029301316
KL Divergence                6.426175
KL Loss                      0.6426175
QF Loss                      1244.8923
VF Loss                      731.4222
Policy Loss                  -2508.342
Q Predictions Mean           2505.8293
Q Predictions Std            566.37524
Q Predictions Max            2785.437
Q Predictions Min            21.248386
V Predictions Mean           2494.8083
V Predictions Std            560.08466
V Predictions Max            2766.103
V Predictions Min            31.345495
Log Pis Mean                 -3.3045282
Log Pis Std                  5.2703524
Log Pis Max                  23.15195
Log Pis Min                  -13.302112
Policy mu Mean               0.3426508
Policy mu Std                0.7372144
Policy mu Max                2.9929478
Policy mu Min                -2.897037
Policy log std Mean          -0.3119318
Policy log std Std           0.14984463
Policy log std Max           0.020208254
Policy log std Min           -1.1706793
Z mean eval                  0.025427436
Z variance eval              0.028883282
total_rewards                [1343.6796794  3830.93047316 1977.31565035 5359.39845442 2232.44183008
 1564.55948178 2615.82161288 5476.48552634 3606.39801409 2050.74474301]
total_rewards_mean           3005.777546552198
total_rewards_std            1422.8550775182505
total_rewards_max            5476.485526338102
total_rewards_min            1343.6796794041118
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               30.841718554031104
(Previous) Eval Time (s)     18.616971840150654
Sample Time (s)              19.177587451413274
Epoch Time (s)               68.63627784559503
Total Train Time (s)         21651.04749733256
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:16:33.680475 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #354 | Epoch Duration: 66.74884724617004
2020-01-11 00:16:33.680728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #354 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025694609
Z variance train             0.028886024
KL Divergence                6.4520807
KL Loss                      0.64520806
QF Loss                      2687.7944
VF Loss                      930.8848
Policy Loss                  -2547.015
Q Predictions Mean           2539.3777
Q Predictions Std            452.1029
Q Predictions Max            2770.468
Q Predictions Min            22.47209
V Predictions Mean           2544.2852
V Predictions Std            449.8071
V Predictions Max            2769.5732
V Predictions Min            34.557453
Log Pis Mean                 -3.1660414
Log Pis Std                  5.8019423
Log Pis Max                  32.72104
Log Pis Min                  -12.38379
Policy mu Mean               0.3562896
Policy mu Std                0.75237286
Policy mu Max                3.5050871
Policy mu Min                -3.923742
Policy log std Mean          -0.3178708
Policy log std Std           0.15450579
Policy log std Max           -0.06370196
Policy log std Min           -1.306338
Z mean eval                  0.023229748
Z variance eval              0.030525854
total_rewards                [2588.09694932 1814.14061026 2765.99718019 5479.75103228 4414.2557458
 5377.76780127 3927.29756492 3377.91447497 5467.50247649 5256.58231243]
total_rewards_mean           4046.930614793323
total_rewards_std            1290.6023150098902
total_rewards_max            5479.75103228308
total_rewards_min            1814.1406102634985
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               29.95714853424579
(Previous) Eval Time (s)     16.72923617856577
Sample Time (s)              20.160611073486507
Epoch Time (s)               66.84699578629807
Total Train Time (s)         21723.772505051456
Epoch                        355
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:17:46.409864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #355 | Epoch Duration: 72.72894239425659
2020-01-11 00:17:46.410066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023099285
Z variance train             0.030510638
KL Divergence                6.3211274
KL Loss                      0.63211274
QF Loss                      2404.5354
VF Loss                      870.4613
Policy Loss                  -2493.9978
Q Predictions Mean           2497.4897
Q Predictions Std            579.86566
Q Predictions Max            2788.301
Q Predictions Min            21.198156
V Predictions Mean           2501.5547
V Predictions Std            576.2902
V Predictions Max            2798.0364
V Predictions Min            32.19146
Log Pis Mean                 -4.615631
Log Pis Std                  4.92338
Log Pis Max                  15.847602
Log Pis Min                  -13.487906
Policy mu Mean               0.34059632
Policy mu Std                0.6941571
Policy mu Max                2.733454
Policy mu Min                -2.4197435
Policy log std Mean          -0.29746482
Policy log std Std           0.14782222
Policy log std Max           0.005052224
Policy log std Min           -1.0104487
Z mean eval                  0.022833284
Z variance eval              0.029975574
total_rewards                [3026.00933173 2127.09396096 5505.19811544 2595.33404744 4418.99181972
 1475.80645314 3185.42261442 3002.52958801 2246.01993326 4527.89771232]
total_rewards_mean           3211.030357643591
total_rewards_std            1184.5304769583418
total_rewards_max            5505.198115435314
total_rewards_min            1475.8064531399941
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               31.248344636056572
(Previous) Eval Time (s)     22.610803805291653
Sample Time (s)              19.101318672299385
Epoch Time (s)               72.96046711364761
Total Train Time (s)         21791.301995316986
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:18:53.942745 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #356 | Epoch Duration: 67.53253149986267
2020-01-11 00:18:53.942943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023130745
Z variance train             0.029981265
KL Divergence                6.3642254
KL Loss                      0.6364226
QF Loss                      1462.1669
VF Loss                      421.56952
Policy Loss                  -2555.1028
Q Predictions Mean           2549.3162
Q Predictions Std            500.99692
Q Predictions Max            2789.9797
Q Predictions Min            19.974854
V Predictions Mean           2543.494
V Predictions Std            497.76355
V Predictions Max            2776.595
V Predictions Min            28.093204
Log Pis Mean                 -4.346155
Log Pis Std                  4.677863
Log Pis Max                  14.478532
Log Pis Min                  -15.603282
Policy mu Mean               0.33902785
Policy mu Std                0.70711595
Policy mu Max                2.9554217
Policy mu Min                -3.6156316
Policy log std Mean          -0.29705104
Policy log std Std           0.13790412
Policy log std Max           -0.05383333
Policy log std Min           -1.142407
Z mean eval                  0.02525649
Z variance eval              0.031000122
total_rewards                [1774.86025664 4149.58945047 3038.71497793 1716.14121391 1716.65591051
 4652.96953458 4254.1629861  1405.98529973 1713.8718438  4157.32155214]
total_rewards_mean           2858.027302581433
total_rewards_std            1255.2832295255978
total_rewards_max            4652.969534579444
total_rewards_min            1405.985299730341
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               28.83474346017465
(Previous) Eval Time (s)     17.18256508372724
Sample Time (s)              19.941461000591516
Epoch Time (s)               65.9587695444934
Total Train Time (s)         21855.109107699245
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:19:57.775630 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #357 | Epoch Duration: 63.832539796829224
2020-01-11 00:19:57.775865 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02502631
Z variance train             0.031003082
KL Divergence                6.292863
KL Loss                      0.6292863
QF Loss                      1402.0176
VF Loss                      390.50385
Policy Loss                  -2514.2817
Q Predictions Mean           2513.8967
Q Predictions Std            526.5272
Q Predictions Max            2770.964
Q Predictions Min            23.751356
V Predictions Mean           2520.0708
V Predictions Std            531.6147
V Predictions Max            2777.151
V Predictions Min            29.576532
Log Pis Mean                 -3.4344258
Log Pis Std                  5.645923
Log Pis Max                  38.366066
Log Pis Min                  -13.94391
Policy mu Mean               0.3103406
Policy mu Std                0.75754666
Policy mu Max                2.516854
Policy mu Min                -4.589873
Policy log std Mean          -0.30324605
Policy log std Std           0.1379824
Policy log std Max           -0.025399514
Policy log std Min           -1.153711
Z mean eval                  0.024286708
Z variance eval              0.032527514
total_rewards                [1709.09955329 4899.72208632 1870.88333497 2771.62800853 5558.96786983
 5300.79380729 5536.4762123  2586.78696534 5177.47065175 2488.04650621]
total_rewards_mean           3789.9874995830373
total_rewards_std            1543.0983051121905
total_rewards_max            5558.967869829739
total_rewards_min            1709.0995532944469
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               29.27249744301662
(Previous) Eval Time (s)     15.055994176771492
Sample Time (s)              19.441717579960823
Epoch Time (s)               63.77020919974893
Total Train Time (s)         21924.251561964862
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:21:06.902279 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #358 | Epoch Duration: 69.1262059211731
2020-01-11 00:21:06.902583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024184946
Z variance train             0.032528885
KL Divergence                6.1748705
KL Loss                      0.6174871
QF Loss                      2155.8582
VF Loss                      601.96765
Policy Loss                  -2489.0032
Q Predictions Mean           2477.6982
Q Predictions Std            548.3472
Q Predictions Max            2771.2349
Q Predictions Min            21.470823
V Predictions Mean           2494.8289
V Predictions Std            545.6895
V Predictions Max            2777.6536
V Predictions Min            31.560984
Log Pis Mean                 -3.2771192
Log Pis Std                  5.0793567
Log Pis Max                  17.199974
Log Pis Min                  -15.204506
Policy mu Mean               0.3546798
Policy mu Std                0.7532914
Policy mu Max                2.6944509
Policy mu Min                -2.5588646
Policy log std Mean          -0.30700618
Policy log std Std           0.13772191
Policy log std Max           -0.0188509
Policy log std Min           -0.98278105
Z mean eval                  0.027846968
Z variance eval              0.032176245
total_rewards                [4420.09472678 1273.42950663 3786.99871629 5293.06100999 5357.00601163
 2722.8843128  5286.67710297 2652.56055724 1208.0734075  2213.62388204]
total_rewards_mean           3421.4409233857828
total_rewards_std            1546.2972240791817
total_rewards_max            5357.006011630391
total_rewards_min            1208.0734074988698
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               32.93015168979764
(Previous) Eval Time (s)     20.411650354973972
Sample Time (s)              20.70090483268723
Epoch Time (s)               74.04270687745884
Total Train Time (s)         21996.52218812192
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:22:19.177535 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #359 | Epoch Duration: 72.27471280097961
2020-01-11 00:22:19.177791 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027635252
Z variance train             0.032169633
KL Divergence                6.194113
KL Loss                      0.6194113
QF Loss                      1804.422
VF Loss                      617.6628
Policy Loss                  -2527.1978
Q Predictions Mean           2525.6702
Q Predictions Std            495.92438
Q Predictions Max            2782.684
Q Predictions Min            23.850672
V Predictions Mean           2520.483
V Predictions Std            491.3098
V Predictions Max            2762.0015
V Predictions Min            34.365334
Log Pis Mean                 -4.212368
Log Pis Std                  5.6636276
Log Pis Max                  21.136942
Log Pis Min                  -14.032497
Policy mu Mean               0.309036
Policy mu Std                0.7411428
Policy mu Max                2.6813457
Policy mu Min                -2.9212618
Policy log std Mean          -0.30951405
Policy log std Std           0.14414878
Policy log std Max           -0.050160915
Policy log std Min           -0.96537703
Z mean eval                  0.02379344
Z variance eval              0.033541046
total_rewards                [2340.53372376 5210.60115188 5390.4266811  1798.62489493 2640.92685149
 5366.61216102 1461.45316467 1223.95432388 5484.4002705  4219.06891796]
total_rewards_mean           3513.6602141202943
total_rewards_std            1695.589924272099
total_rewards_max            5484.400270503961
total_rewards_min            1223.9543238827055
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               30.971035636030138
(Previous) Eval Time (s)     18.643298488110304
Sample Time (s)              19.273048433940858
Epoch Time (s)               68.8873825580813
Total Train Time (s)         22066.678598699626
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:23:29.336346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #360 | Epoch Duration: 70.15837001800537
2020-01-11 00:23:29.336504 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #360 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02378163
Z variance train             0.033538047
KL Divergence                6.1071796
KL Loss                      0.61071795
QF Loss                      1267.9661
VF Loss                      556.8266
Policy Loss                  -2548.6301
Q Predictions Mean           2543.5044
Q Predictions Std            498.1432
Q Predictions Max            2788.1213
Q Predictions Min            20.183369
V Predictions Mean           2549.349
V Predictions Std            499.34097
V Predictions Max            2795.8716
V Predictions Min            31.507189
Log Pis Mean                 -3.4618762
Log Pis Std                  6.019196
Log Pis Max                  27.48356
Log Pis Min                  -15.233112
Policy mu Mean               0.27467567
Policy mu Std                0.76590997
Policy mu Max                2.7754836
Policy mu Min                -3.1776226
Policy log std Mean          -0.30748862
Policy log std Std           0.14238125
Policy log std Max           -0.04484155
Policy log std Min           -1.2540137
Z mean eval                  0.026476974
Z variance eval              0.033640135
total_rewards                [3135.25947329 5276.27904582 5282.43259488 5380.09464251 4713.0855829
 5427.06090001 5308.79634534 2044.23293443 2986.59564261 1023.43878086]
total_rewards_mean           4057.727594264413
total_rewards_std            1544.749359758073
total_rewards_max            5427.060900006483
total_rewards_min            1023.4387808603468
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               31.54714347468689
(Previous) Eval Time (s)     19.91398415900767
Sample Time (s)              19.095190240535885
Epoch Time (s)               70.55631787423044
Total Train Time (s)         22140.834935029503
Epoch                        361
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:24:43.499750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #361 | Epoch Duration: 74.1630790233612
2020-01-11 00:24:43.500093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0269426
Z variance train             0.033638097
KL Divergence                6.092757
KL Loss                      0.60927576
QF Loss                      1259.6003
VF Loss                      444.156
Policy Loss                  -2494.0432
Q Predictions Mean           2494.1682
Q Predictions Std            597.9642
Q Predictions Max            2783.1377
Q Predictions Min            23.280079
V Predictions Mean           2494.2751
V Predictions Std            594.4744
V Predictions Max            2772.9927
V Predictions Min            34.37179
Log Pis Mean                 -3.9662187
Log Pis Std                  4.9932346
Log Pis Max                  15.624054
Log Pis Min                  -15.19754
Policy mu Mean               0.3325165
Policy mu Std                0.72188604
Policy mu Max                2.5271623
Policy mu Min                -2.2626777
Policy log std Mean          -0.3083198
Policy log std Std           0.13057679
Policy log std Max           -0.08250544
Policy log std Min           -0.98728997
Z mean eval                  0.02272622
Z variance eval              0.035295907
total_rewards                [5470.71038621 5493.15998398 3203.9783375  5425.29872999 5496.99951515
 5445.7936062  4010.06502233 5244.53055004 4115.48949725 5463.59300928]
total_rewards_mean           4936.961863792823
total_rewards_std            794.6316132817878
total_rewards_max            5496.999515153308
total_rewards_min            3203.9783375006755
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               31.42908567469567
(Previous) Eval Time (s)     23.520386742893606
Sample Time (s)              19.18007826944813
Epoch Time (s)               74.12955068703741
Total Train Time (s)         22217.427331751212
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:26:00.093930 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #362 | Epoch Duration: 76.59362363815308
2020-01-11 00:26:00.094151 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022970174
Z variance train             0.03529664
KL Divergence                5.9841995
KL Loss                      0.59841996
QF Loss                      1112.4111
VF Loss                      360.04333
Policy Loss                  -2582.1965
Q Predictions Mean           2580.8804
Q Predictions Std            438.81998
Q Predictions Max            2786.6162
Q Predictions Min            21.46318
V Predictions Mean           2577.4556
V Predictions Std            437.7376
V Predictions Max            2791.337
V Predictions Min            32.14607
Log Pis Mean                 -4.5434284
Log Pis Std                  4.5734177
Log Pis Max                  24.387955
Log Pis Min                  -13.026934
Policy mu Mean               0.34158343
Policy mu Std                0.6908303
Policy mu Max                2.6706634
Policy mu Min                -3.30374
Policy log std Mean          -0.29145473
Policy log std Std           0.14111243
Policy log std Max           -0.0534494
Policy log std Min           -1.113127
Z mean eval                  0.021698214
Z variance eval              0.033129048
total_rewards                [2282.21876185  518.99008268 1791.18495077 5296.92562266 5328.29252767
 5356.69149524 4245.35491239 5017.15962799 5211.92603214 5340.27959314]
total_rewards_mean           4038.9023606533665
total_rewards_std            1719.8502310312542
total_rewards_max            5356.69149524227
total_rewards_min            518.990082679162
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               32.58891788404435
(Previous) Eval Time (s)     25.984202005900443
Sample Time (s)              18.865410076919943
Epoch Time (s)               77.43852996686473
Total Train Time (s)         22291.732839219272
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:27:14.406749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #363 | Epoch Duration: 74.31242728233337
2020-01-11 00:27:14.407035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021547478
Z variance train             0.03312673
KL Divergence                6.1523657
KL Loss                      0.6152366
QF Loss                      1443.6682
VF Loss                      530.6305
Policy Loss                  -2509.3157
Q Predictions Mean           2510.103
Q Predictions Std            588.5692
Q Predictions Max            2782.8992
Q Predictions Min            24.857302
V Predictions Mean           2519.653
V Predictions Std            591.62317
V Predictions Max            2822.1733
V Predictions Min            33.309032
Log Pis Mean                 -4.3686323
Log Pis Std                  4.946107
Log Pis Max                  17.139454
Log Pis Min                  -13.8563795
Policy mu Mean               0.32141495
Policy mu Std                0.70119876
Policy mu Max                2.5080276
Policy mu Min                -2.947582
Policy log std Mean          -0.30509079
Policy log std Std           0.13376623
Policy log std Max           -0.01780641
Policy log std Min           -1.0576936
Z mean eval                  0.02181445
Z variance eval              0.033695783
total_rewards                [2505.15469523 1810.92858892 3614.81558772 2559.02220185 5511.89156036
 5435.77759896 2025.44899089 1166.54009586 1623.79237717 3414.98665203]
total_rewards_mean           2966.835834896605
total_rewards_std            1443.6177353345288
total_rewards_max            5511.891560355506
total_rewards_min            1166.540095858407
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               31.13969836710021
(Previous) Eval Time (s)     22.857766028959304
Sample Time (s)              19.403282702434808
Epoch Time (s)               73.40074709849432
Total Train Time (s)         22358.067429440096
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:28:20.742803 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #364 | Epoch Duration: 66.33556962013245
2020-01-11 00:28:20.742970 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021998135
Z variance train             0.03370789
KL Divergence                6.078127
KL Loss                      0.6078127
QF Loss                      1415.7968
VF Loss                      470.66498
Policy Loss                  -2565.4417
Q Predictions Mean           2565.3535
Q Predictions Std            464.4016
Q Predictions Max            2788.531
Q Predictions Min            21.287825
V Predictions Mean           2559.6748
V Predictions Std            462.16736
V Predictions Max            2787.7268
V Predictions Min            30.847729
Log Pis Mean                 -4.0176153
Log Pis Std                  5.2510915
Log Pis Max                  20.699615
Log Pis Min                  -15.660818
Policy mu Mean               0.3314697
Policy mu Std                0.71056384
Policy mu Max                2.905642
Policy mu Min                -2.8510065
Policy log std Mean          -0.3040209
Policy log std Std           0.14420421
Policy log std Max           -0.060731612
Policy log std Min           -1.1575294
Z mean eval                  0.02549613
Z variance eval              0.035317205
total_rewards                [2321.77000573 2918.8919595  5432.58179238 5650.37954132 4080.11727761
 1152.02694522 4881.79130418 2238.86244656 2023.93914727 5392.8088232 ]
total_rewards_mean           3609.3169242971503
total_rewards_std            1583.54743129564
total_rewards_max            5650.379541321504
total_rewards_min            1152.0269452207394
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               31.44285753276199
(Previous) Eval Time (s)     15.792269029654562
Sample Time (s)              19.340117373038083
Epoch Time (s)               66.57524393545464
Total Train Time (s)         22428.436150772497
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:29:31.117086 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #365 | Epoch Duration: 70.37396383285522
2020-01-11 00:29:31.117354 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025464082
Z variance train             0.035311393
KL Divergence                5.965408
KL Loss                      0.5965408
QF Loss                      2403.2817
VF Loss                      978.19104
Policy Loss                  -2566.927
Q Predictions Mean           2566.067
Q Predictions Std            460.37878
Q Predictions Max            2774.6882
Q Predictions Min            20.986061
V Predictions Mean           2572.3538
V Predictions Std            461.76007
V Predictions Max            2784.4507
V Predictions Min            33.196842
Log Pis Mean                 -4.1986217
Log Pis Std                  4.3706384
Log Pis Max                  14.860456
Log Pis Min                  -14.10677
Policy mu Mean               0.29016712
Policy mu Std                0.71071035
Policy mu Max                2.5849078
Policy mu Min                -2.1208758
Policy log std Mean          -0.28137782
Policy log std Std           0.13355526
Policy log std Max           0.18960635
Policy log std Min           -0.95674574
Z mean eval                  0.02828013
Z variance eval              0.034507554
total_rewards                [5499.42324742 5441.47461927 5456.33150939 5247.90825131 1656.55611473
 5401.14378109 5366.75001844 3746.36781505 1326.89194864 4066.63645805]
total_rewards_mean           4320.948376338708
total_rewards_std            1533.3438012302763
total_rewards_max            5499.423247417591
total_rewards_min            1326.8919486417417
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               29.661842074245214
(Previous) Eval Time (s)     19.59065878810361
Sample Time (s)              19.844344270415604
Epoch Time (s)               69.09684513276443
Total Train Time (s)         22502.522077854257
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:30:45.209769 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #366 | Epoch Duration: 74.09219813346863
2020-01-11 00:30:45.210082 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #366 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028431457
Z variance train             0.034516763
KL Divergence                6.0286226
KL Loss                      0.6028623
QF Loss                      1066.8837
VF Loss                      506.24496
Policy Loss                  -2573.323
Q Predictions Mean           2568.5513
Q Predictions Std            480.24625
Q Predictions Max            2786.7559
Q Predictions Min            22.090614
V Predictions Mean           2565.3167
V Predictions Std            479.70682
V Predictions Max            2782.292
V Predictions Min            34.4962
Log Pis Mean                 -4.5823946
Log Pis Std                  5.1555777
Log Pis Max                  26.3375
Log Pis Min                  -13.516001
Policy mu Mean               0.3283783
Policy mu Std                0.69198275
Policy mu Max                2.8622267
Policy mu Min                -2.9693584
Policy log std Mean          -0.29549864
Policy log std Std           0.13132735
Policy log std Max           -0.047940195
Policy log std Min           -1.0367389
Z mean eval                  0.03113478
Z variance eval              0.033382557
total_rewards                [5316.28180257 5323.54315228 5322.32084377 5372.34922594 5468.2947422
 4007.29575574 5457.43340505 5519.63255208 3840.51198797 5481.38013137]
total_rewards_mean           5110.904359897067
total_rewards_std            598.6998851075408
total_rewards_max            5519.632552083359
total_rewards_min            3840.511987968798
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               33.237442003097385
(Previous) Eval Time (s)     24.58564708987251
Sample Time (s)              19.94351544417441
Epoch Time (s)               77.7666045371443
Total Train Time (s)         22583.666115598753
Epoch                        367
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:32:06.359749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #367 | Epoch Duration: 81.14942359924316
2020-01-11 00:32:06.360053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030965945
Z variance train             0.033382587
KL Divergence                6.10249
KL Loss                      0.610249
QF Loss                      1530.0402
VF Loss                      752.70807
Policy Loss                  -2584.659
Q Predictions Mean           2586.7922
Q Predictions Std            386.82193
Q Predictions Max            2801.0728
Q Predictions Min            25.640978
V Predictions Mean           2598.2766
V Predictions Std            387.4738
V Predictions Max            2805.9177
V Predictions Min            35.36505
Log Pis Mean                 -4.207567
Log Pis Std                  5.886544
Log Pis Max                  26.90741
Log Pis Min                  -14.615836
Policy mu Mean               0.3410234
Policy mu Std                0.73732895
Policy mu Max                3.0193703
Policy mu Min                -3.48317
Policy log std Mean          -0.31501168
Policy log std Std           0.14074297
Policy log std Max           -0.032252632
Policy log std Min           -1.0582196
Z mean eval                  0.03569631
Z variance eval              0.034157317
total_rewards                [2205.2792581  1995.53316033 5704.21780493 1370.55959328 2764.74990736
 5091.59051934 2768.2770195  1260.90039795 5762.73971779 5754.07829289]
total_rewards_mean           3467.7925671482144
total_rewards_std            1792.9316849851868
total_rewards_max            5762.739717792596
total_rewards_min            1260.9003979530169
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               32.508262692950666
(Previous) Eval Time (s)     27.96816257806495
Sample Time (s)              19.728924523107708
Epoch Time (s)               80.20534979412332
Total Train Time (s)         22653.828467386775
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:33:16.527605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #368 | Epoch Duration: 70.16732835769653
2020-01-11 00:33:16.527876 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03566881
Z variance train             0.034157414
KL Divergence                6.044913
KL Loss                      0.6044913
QF Loss                      2245.1868
VF Loss                      663.1484
Policy Loss                  -2597.146
Q Predictions Mean           2592.7292
Q Predictions Std            413.4171
Q Predictions Max            2782.776
Q Predictions Min            23.407907
V Predictions Mean           2586.8896
V Predictions Std            414.30502
V Predictions Max            2780.0432
V Predictions Min            34.08241
Log Pis Mean                 -4.2882133
Log Pis Std                  4.958643
Log Pis Max                  20.630821
Log Pis Min                  -13.980745
Policy mu Mean               0.33224136
Policy mu Std                0.69727176
Policy mu Max                2.7142992
Policy mu Min                -3.9566336
Policy log std Mean          -0.29669428
Policy log std Std           0.13625579
Policy log std Max           -0.07318924
Policy log std Min           -1.1057875
Z mean eval                  0.029675424
Z variance eval              0.034615733
total_rewards                [5343.82660291 5366.33064656 5435.4899117  5385.37378721 5386.59662503
 1379.88350197 5394.20872429 5294.59096492  866.27145903 5399.77497687]
total_rewards_mean           4525.234720049664
total_rewards_std            1705.314488043448
total_rewards_max            5435.489911695181
total_rewards_min            866.2714590339812
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               28.68547239108011
(Previous) Eval Time (s)     17.92981107113883
Sample Time (s)              19.163375227712095
Epoch Time (s)               65.77865868993104
Total Train Time (s)         22726.12001019437
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:34:28.821353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #369 | Epoch Duration: 72.29329657554626
2020-01-11 00:34:28.821585 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029454809
Z variance train             0.034629323
KL Divergence                6.0155935
KL Loss                      0.60155934
QF Loss                      1384.0592
VF Loss                      607.13226
Policy Loss                  -2592.3499
Q Predictions Mean           2589.7593
Q Predictions Std            425.8406
Q Predictions Max            2790.043
Q Predictions Min            25.170273
V Predictions Mean           2590.489
V Predictions Std            431.8857
V Predictions Max            2790.553
V Predictions Min            35.857227
Log Pis Mean                 -3.9227824
Log Pis Std                  5.5255046
Log Pis Max                  24.925362
Log Pis Min                  -13.5347805
Policy mu Mean               0.27379355
Policy mu Std                0.74504405
Policy mu Max                2.8375788
Policy mu Min                -3.2107117
Policy log std Mean          -0.29050446
Policy log std Std           0.14336945
Policy log std Max           0.05405791
Policy log std Min           -0.9969285
Z mean eval                  0.03152205
Z variance eval              0.03670975
total_rewards                [5447.32367269 3352.13001482 5547.54624114 5373.82040324 2088.49253872
 5352.364582   2849.77766362 5475.19650742 2265.76248783 4178.81300593]
total_rewards_mean           4193.1227117425715
total_rewards_std            1358.1354909444415
total_rewards_max            5547.546241142513
total_rewards_min            2088.4925387229255
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               31.24153720913455
(Previous) Eval Time (s)     24.444139114115387
Sample Time (s)              19.248026018496603
Epoch Time (s)               74.93370234174654
Total Train Time (s)         22799.825626825914
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:35:42.529755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #370 | Epoch Duration: 73.7080409526825
2020-01-11 00:35:42.529916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03167703
Z variance train             0.036708713
KL Divergence                5.883834
KL Loss                      0.5883834
QF Loss                      1161.0076
VF Loss                      630.4044
Policy Loss                  -2603.6106
Q Predictions Mean           2599.6946
Q Predictions Std            399.33432
Q Predictions Max            2802.7556
Q Predictions Min            18.90234
V Predictions Mean           2599.476
V Predictions Std            393.9724
V Predictions Max            2797.336
V Predictions Min            28.780972
Log Pis Mean                 -4.3698606
Log Pis Std                  4.918896
Log Pis Max                  26.475416
Log Pis Min                  -15.121668
Policy mu Mean               0.35504195
Policy mu Std                0.68605137
Policy mu Max                2.974916
Policy mu Min                -2.3797169
Policy log std Mean          -0.29150924
Policy log std Std           0.13458277
Policy log std Max           0.005400002
Policy log std Min           -0.98374975
Z mean eval                  0.03237772
Z variance eval              0.036288127
total_rewards                [2305.91415355 5369.01469239 3494.57014901 5442.8685694  4243.16206227
 5497.50263308 5149.83111353 2452.53217902 5433.9806789  5428.78535205]
total_rewards_mean           4481.816158318953
total_rewards_std            1219.6773082549742
total_rewards_max            5497.502633080035
total_rewards_min            2305.9141535459617
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               28.7356263268739
(Previous) Eval Time (s)     23.218153388239443
Sample Time (s)              19.5427916822955
Epoch Time (s)               71.49657139740884
Total Train Time (s)         22873.108430141583
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:36:55.815688 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #371 | Epoch Duration: 73.285635471344
2020-01-11 00:36:55.815895 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03236125
Z variance train             0.036289796
KL Divergence                5.912548
KL Loss                      0.59125483
QF Loss                      1085.4232
VF Loss                      445.62036
Policy Loss                  -2611.277
Q Predictions Mean           2611.9111
Q Predictions Std            407.0414
Q Predictions Max            2797.411
Q Predictions Min            17.91984
V Predictions Mean           2606.509
V Predictions Std            407.49182
V Predictions Max            2800.4543
V Predictions Min            29.20127
Log Pis Mean                 -4.601416
Log Pis Std                  4.6966867
Log Pis Max                  22.227928
Log Pis Min                  -14.722626
Policy mu Mean               0.32391754
Policy mu Std                0.67976415
Policy mu Max                2.6753335
Policy mu Min                -3.438823
Policy log std Mean          -0.289992
Policy log std Std           0.13861446
Policy log std Max           -0.046385705
Policy log std Min           -1.2374334
Z mean eval                  0.033861928
Z variance eval              0.036079984
total_rewards                [5326.67005956 5281.19089388  536.06511005 1969.00670635 1718.81927317
 2039.1401385  2542.08323369 3402.44720403 5387.9354764  2376.09669186]
total_rewards_mean           3057.945478749095
total_rewards_std            1635.4017674956883
total_rewards_max            5387.935476401625
total_rewards_min            536.0651100535324
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               32.54697166569531
(Previous) Eval Time (s)     25.006925063207746
Sample Time (s)              19.453461003955454
Epoch Time (s)               77.00735773285851
Total Train Time (s)         22942.908715934027
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:38:05.620109 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #372 | Epoch Duration: 69.80407643318176
2020-01-11 00:38:05.620297 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033681665
Z variance train             0.03608318
KL Divergence                5.9156685
KL Loss                      0.59156686
QF Loss                      1345.4714
VF Loss                      452.58826
Policy Loss                  -2592.4534
Q Predictions Mean           2585.5068
Q Predictions Std            441.10004
Q Predictions Max            2785.3008
Q Predictions Min            20.749065
V Predictions Mean           2592.648
V Predictions Std            445.85287
V Predictions Max            2802.3816
V Predictions Min            31.59171
Log Pis Mean                 -4.564309
Log Pis Std                  4.606166
Log Pis Max                  12.421053
Log Pis Min                  -14.040489
Policy mu Mean               0.33974528
Policy mu Std                0.6838443
Policy mu Max                2.8889754
Policy mu Min                -2.5908635
Policy log std Mean          -0.30043215
Policy log std Std           0.13841227
Policy log std Max           0.04405448
Policy log std Min           -1.0203383
Z mean eval                  0.035873346
Z variance eval              0.03304938
total_rewards                [5385.25638039 4824.0950178  5088.7548928  5301.33132645 1578.37759382
 5394.32697748 5331.7628557  5206.11121074 5329.33148575 5270.36657535]
total_rewards_mean           4870.97143162937
total_rewards_std            1109.4439471181522
total_rewards_max            5394.326977482712
total_rewards_min            1578.377593818864
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               31.27976954029873
(Previous) Eval Time (s)     17.803341476246715
Sample Time (s)              19.14655790105462
Epoch Time (s)               68.22966891760007
Total Train Time (s)         23020.74321968481
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:39:23.461286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #373 | Epoch Duration: 77.84081172943115
2020-01-11 00:39:23.461572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035862934
Z variance train             0.03304402
KL Divergence                6.136815
KL Loss                      0.6136815
QF Loss                      942.7368
VF Loss                      385.95258
Policy Loss                  -2553.5317
Q Predictions Mean           2550.4158
Q Predictions Std            523.6371
Q Predictions Max            2794.8418
Q Predictions Min            27.095087
V Predictions Mean           2550.2676
V Predictions Std            524.5724
V Predictions Max            2791.735
V Predictions Min            34.538177
Log Pis Mean                 -3.822836
Log Pis Std                  5.007239
Log Pis Max                  21.718292
Log Pis Min                  -13.873421
Policy mu Mean               0.34508032
Policy mu Std                0.7054389
Policy mu Max                3.1562424
Policy mu Min                -2.2392
Policy log std Mean          -0.31331775
Policy log std Std           0.13564791
Policy log std Max           -0.0069761127
Policy log std Min           -1.0747055
Z mean eval                  0.03440581
Z variance eval              0.0330916
total_rewards                [1148.54089016 5100.76691535 3275.14837684 3032.22157233 2490.81467146
 5315.42219786 3485.64452356 5302.52991815 3356.68092466 5244.6887666 ]
total_rewards_mean           3775.2458756976907
total_rewards_std            1350.2443804913785
total_rewards_max            5315.4221978597425
total_rewards_min            1148.5408901583446
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               30.548039748333395
(Previous) Eval Time (s)     27.414102621842176
Sample Time (s)              19.378841780126095
Epoch Time (s)               77.34098415030167
Total Train Time (s)         23093.438447908964
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:40:36.163915 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #374 | Epoch Duration: 72.70212411880493
2020-01-11 00:40:36.164193 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03448369
Z variance train             0.03309218
KL Divergence                6.131646
KL Loss                      0.6131646
QF Loss                      1038.0138
VF Loss                      339.1965
Policy Loss                  -2637.411
Q Predictions Mean           2632.046
Q Predictions Std            369.02863
Q Predictions Max            2801.738
Q Predictions Min            20.900309
V Predictions Mean           2632.2021
V Predictions Std            369.2868
V Predictions Max            2806.1165
V Predictions Min            26.032948
Log Pis Mean                 -4.1395226
Log Pis Std                  5.354016
Log Pis Max                  28.655283
Log Pis Min                  -15.092499
Policy mu Mean               0.33986703
Policy mu Std                0.7087324
Policy mu Max                3.4122005
Policy mu Min                -3.1366947
Policy log std Mean          -0.30623716
Policy log std Std           0.13865043
Policy log std Max           -0.06227249
Policy log std Min           -1.1169322
Z mean eval                  0.035905123
Z variance eval              0.03497058
total_rewards                [3378.09449075 1546.4760922  3254.0413833  5423.9564531  2073.85494093
 2675.06408043 5591.84405862 1834.39216345 2774.20535099 5521.70284796]
total_rewards_mean           3407.363186174186
total_rewards_std            1482.7654974064408
total_rewards_max            5591.844058620917
total_rewards_min            1546.4760922044957
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               31.134640061762184
(Previous) Eval Time (s)     22.774930652230978
Sample Time (s)              20.163379666861147
Epoch Time (s)               74.07295038085431
Total Train Time (s)         23164.05574982334
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:41:46.785477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #375 | Epoch Duration: 70.62109565734863
2020-01-11 00:41:46.785690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03572874
Z variance train             0.034972146
KL Divergence                5.9913244
KL Loss                      0.5991325
QF Loss                      1187.3793
VF Loss                      394.75055
Policy Loss                  -2614.8699
Q Predictions Mean           2610.459
Q Predictions Std            375.91937
Q Predictions Max            2798.5383
Q Predictions Min            23.640333
V Predictions Mean           2617.5376
V Predictions Std            378.38
V Predictions Max            2793.7598
V Predictions Min            36.3561
Log Pis Mean                 -4.755408
Log Pis Std                  4.3206096
Log Pis Max                  15.706516
Log Pis Min                  -12.878944
Policy mu Mean               0.3409418
Policy mu Std                0.6743034
Policy mu Max                2.7515962
Policy mu Min                -2.6933632
Policy log std Mean          -0.28763232
Policy log std Std           0.13516997
Policy log std Max           -0.04859668
Policy log std Min           -0.97217214
Z mean eval                  0.03471776
Z variance eval              0.034232467
total_rewards                [1228.70525562 3854.02694002 3325.80037801 5307.7735757  5287.89949368
 2974.96536274 5365.40817744 5379.1137217  5353.69065849 1733.55049047]
total_rewards_mean           3981.093405387472
total_rewards_std            1526.6817610996702
total_rewards_max            5379.113721695994
total_rewards_min            1228.7052556249444
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               29.381539326626807
(Previous) Eval Time (s)     19.322720759082586
Sample Time (s)              20.375494591426104
Epoch Time (s)               69.0797546771355
Total Train Time (s)         23235.959206240717
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:42:58.695563 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #376 | Epoch Duration: 71.90968751907349
2020-01-11 00:42:58.695875 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03442512
Z variance train             0.034226954
KL Divergence                6.034198
KL Loss                      0.6034198
QF Loss                      1745.794
VF Loss                      894.57544
Policy Loss                  -2607.1335
Q Predictions Mean           2611.0024
Q Predictions Std            390.9363
Q Predictions Max            2825.2266
Q Predictions Min            25.33811
V Predictions Mean           2609.8994
V Predictions Std            381.86795
V Predictions Max            2811.7632
V Predictions Min            32.24474
Log Pis Mean                 -4.3341537
Log Pis Std                  5.665739
Log Pis Max                  29.339241
Log Pis Min                  -15.431216
Policy mu Mean               0.35324025
Policy mu Std                0.69919336
Policy mu Max                3.2572622
Policy mu Min                -3.0286167
Policy log std Mean          -0.3049732
Policy log std Std           0.14515704
Policy log std Max           -0.059119925
Policy log std Min           -0.9689003
Z mean eval                  0.0344773
Z variance eval              0.035055134
total_rewards                [1917.45003665 3141.78565587 5554.13563978 1617.9965651  3627.66658096
 2048.49118564 5403.7107064  4092.73635778 5466.5871856  4990.08257449]
total_rewards_mean           3786.064248827838
total_rewards_std            1475.2051785687188
total_rewards_max            5554.135639780113
total_rewards_min            1617.9965651020652
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               31.638960698619485
(Previous) Eval Time (s)     22.152308360207826
Sample Time (s)              19.869220132473856
Epoch Time (s)               73.66048919130117
Total Train Time (s)         23308.304849115666
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:44:11.043614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #377 | Epoch Duration: 72.3475124835968
2020-01-11 00:44:11.043859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03490265
Z variance train             0.035047084
KL Divergence                5.972063
KL Loss                      0.5972063
QF Loss                      1455.5244
VF Loss                      512.3046
Policy Loss                  -2588.0422
Q Predictions Mean           2582.7236
Q Predictions Std            430.66107
Q Predictions Max            2815.0227
Q Predictions Min            32.335392
V Predictions Mean           2582.3447
V Predictions Std            436.05167
V Predictions Max            2811.66
V Predictions Min            38.92349
Log Pis Mean                 -3.3082485
Log Pis Std                  5.6256757
Log Pis Max                  20.583788
Log Pis Min                  -13.287826
Policy mu Mean               0.35657692
Policy mu Std                0.74211925
Policy mu Max                2.8922188
Policy mu Min                -2.5979726
Policy log std Mean          -0.30316487
Policy log std Std           0.13026431
Policy log std Max           -0.0011903793
Policy log std Min           -1.0807682
Z mean eval                  0.03651859
Z variance eval              0.033555575
total_rewards                [5324.8109197  3527.62355388 4734.15540699 5185.08468916 3675.96235729
 5271.76842451 1226.65810516 5256.43193238 5442.58986216 1496.78005769]
total_rewards_mean           4114.18653089172
total_rewards_std            1520.8847786500833
total_rewards_max            5442.589862157462
total_rewards_min            1226.658105162823
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               30.163881841115654
(Previous) Eval Time (s)     20.83900963002816
Sample Time (s)              19.10004531033337
Epoch Time (s)               70.10293678147718
Total Train Time (s)         23380.57190501131
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:45:23.316349 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #378 | Epoch Duration: 72.27231669425964
2020-01-11 00:45:23.316632 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #378 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036806323
Z variance train             0.033540122
KL Divergence                6.086973
KL Loss                      0.60869735
QF Loss                      1573.1438
VF Loss                      249.82011
Policy Loss                  -2618.0867
Q Predictions Mean           2618.4695
Q Predictions Std            417.92966
Q Predictions Max            2818.3596
Q Predictions Min            22.764595
V Predictions Mean           2616.2441
V Predictions Std            416.49823
V Predictions Max            2817.1958
V Predictions Min            34.79822
Log Pis Mean                 -3.8942056
Log Pis Std                  6.0084977
Log Pis Max                  32.510586
Log Pis Min                  -20.196123
Policy mu Mean               0.32683367
Policy mu Std                0.7093562
Policy mu Max                2.6581657
Policy mu Min                -2.8155246
Policy log std Mean          -0.29743516
Policy log std Std           0.14090297
Policy log std Max           -0.07133724
Policy log std Min           -1.0901483
Z mean eval                  0.038902245
Z variance eval              0.03324526
total_rewards                [2006.55398703 5392.79850697 1843.29840809 5382.46517889 5490.2861886
 5401.89767686 1134.2291496  4179.08645073 5358.0071747  5326.29049569]
total_rewards_mean           4151.4913217161975
total_rewards_std            1681.6957132339041
total_rewards_max            5490.286188599102
total_rewards_min            1134.2291496040611
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               32.45997815672308
(Previous) Eval Time (s)     23.008082111831754
Sample Time (s)              19.434915498830378
Epoch Time (s)               74.90297576738521
Total Train Time (s)         23454.818109183107
Epoch                        379
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:46:37.564790 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #379 | Epoch Duration: 74.24797368049622
2020-01-11 00:46:37.564975 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038838398
Z variance train             0.03326615
KL Divergence                6.1073885
KL Loss                      0.6107389
QF Loss                      2072.1802
VF Loss                      415.7094
Policy Loss                  -2575.1912
Q Predictions Mean           2573.8088
Q Predictions Std            484.81317
Q Predictions Max            2799.299
Q Predictions Min            23.757652
V Predictions Mean           2582.389
V Predictions Std            485.24362
V Predictions Max            2812.721
V Predictions Min            32.755314
Log Pis Mean                 -4.197447
Log Pis Std                  5.166477
Log Pis Max                  21.01329
Log Pis Min                  -16.767696
Policy mu Mean               0.31379294
Policy mu Std                0.70504934
Policy mu Max                2.9632406
Policy mu Min                -2.9404087
Policy log std Mean          -0.2932476
Policy log std Std           0.1346168
Policy log std Max           -0.023127444
Policy log std Min           -1.1690784
Z mean eval                  0.03812673
Z variance eval              0.033836205
total_rewards                [3318.65976326 2836.12972587 5483.06692484 5480.78306318 5452.31921775
 5535.25049582 5281.23421157 2388.96420575 1378.5903155  5491.92650424]
total_rewards_mean           4264.692442778169
total_rewards_std            1526.8025308722902
total_rewards_max            5535.250495822409
total_rewards_min            1378.5903155016836
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               27.833160406909883
(Previous) Eval Time (s)     22.352727509103715
Sample Time (s)              19.66308096377179
Epoch Time (s)               69.84896887978539
Total Train Time (s)         23525.75736568682
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:47:48.510664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #380 | Epoch Duration: 70.94551634788513
2020-01-11 00:47:48.510943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038058273
Z variance train             0.03382558
KL Divergence                6.057637
KL Loss                      0.60576373
QF Loss                      780.93335
VF Loss                      226.44943
Policy Loss                  -2630.051
Q Predictions Mean           2631.651
Q Predictions Std            406.55795
Q Predictions Max            2802.611
Q Predictions Min            16.197641
V Predictions Mean           2631.8364
V Predictions Std            403.84247
V Predictions Max            2806.091
V Predictions Min            31.20272
Log Pis Mean                 -4.578801
Log Pis Std                  4.3623376
Log Pis Max                  15.187462
Log Pis Min                  -13.847429
Policy mu Mean               0.29888678
Policy mu Std                0.6950978
Policy mu Max                2.9393651
Policy mu Min                -2.8679945
Policy log std Mean          -0.28779393
Policy log std Std           0.12527545
Policy log std Max           -0.054108143
Policy log std Min           -1.0656289
Z mean eval                  0.04127594
Z variance eval              0.035144698
total_rewards                [5330.40921071 5280.1838624  4910.80536184 1077.65179127 5314.61162245
 5218.18151827 2489.09365945 5475.48514378 2281.13389523 5149.3597084 ]
total_rewards_mean           4252.691577378584
total_rewards_std            1552.018274734619
total_rewards_max            5475.485143780062
total_rewards_min            1077.6517912714721
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               28.821023758035153
(Previous) Eval Time (s)     23.44895626278594
Sample Time (s)              19.827108616009355
Epoch Time (s)               72.09708863683045
Total Train Time (s)         23599.179698209744
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:49:01.938779 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #381 | Epoch Duration: 73.42761182785034
2020-01-11 00:49:01.939039 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041157585
Z variance train             0.035152458
KL Divergence                5.9731455
KL Loss                      0.59731454
QF Loss                      1833.0305
VF Loss                      695.5192
Policy Loss                  -2581.617
Q Predictions Mean           2581.794
Q Predictions Std            512.4931
Q Predictions Max            2806.9731
Q Predictions Min            21.676271
V Predictions Mean           2580.9941
V Predictions Std            515.84454
V Predictions Max            2803.0894
V Predictions Min            31.637573
Log Pis Mean                 -3.8037393
Log Pis Std                  5.293607
Log Pis Max                  22.871828
Log Pis Min                  -12.760957
Policy mu Mean               0.34176773
Policy mu Std                0.70153826
Policy mu Max                2.7830217
Policy mu Min                -2.7079592
Policy log std Mean          -0.29656067
Policy log std Std           0.13581397
Policy log std Max           -0.030948356
Policy log std Min           -1.179637
Z mean eval                  0.040897377
Z variance eval              0.036369972
total_rewards                [5454.33783407 2568.7372759  1175.87584494 2202.23966763  738.63088589
 5214.86402743 3177.79302956 5295.28556433 5434.73920412 5436.17116161]
total_rewards_mean           3669.8674495492332
total_rewards_std            1812.9708286794641
total_rewards_max            5454.337834066056
total_rewards_min            738.6308858934987
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               31.420026472304016
(Previous) Eval Time (s)     24.77915506158024
Sample Time (s)              19.889142364263535
Epoch Time (s)               76.08832389814779
Total Train Time (s)         23671.34033601638
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:50:14.105617 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #382 | Epoch Duration: 72.166344165802
2020-01-11 00:50:14.105933 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040945824
Z variance train             0.036367334
KL Divergence                5.8846216
KL Loss                      0.5884622
QF Loss                      1222.6038
VF Loss                      817.9574
Policy Loss                  -2645.1597
Q Predictions Mean           2646.8154
Q Predictions Std            303.57404
Q Predictions Max            2801.8938
Q Predictions Min            26.08566
V Predictions Mean           2650.9048
V Predictions Std            314.38986
V Predictions Max            2824.7678
V Predictions Min            36.252625
Log Pis Mean                 -3.8109117
Log Pis Std                  5.328635
Log Pis Max                  24.828543
Log Pis Min                  -12.356688
Policy mu Mean               0.3580484
Policy mu Std                0.71511334
Policy mu Max                2.8109968
Policy mu Min                -3.2438967
Policy log std Mean          -0.3121883
Policy log std Std           0.15162976
Policy log std Max           -0.05740027
Policy log std Min           -1.3495386
Z mean eval                  0.040982746
Z variance eval              0.03709856
total_rewards                [5477.72676609 4372.59337638 5454.34490024 5449.73910713 5270.13170216
 5353.91963545 1174.22445205 5556.4493214  5353.39273307 5462.69636909]
total_rewards_mean           4892.521836306904
total_rewards_std            1280.5639351372863
total_rewards_max            5556.449321399096
total_rewards_min            1174.224452051893
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               31.006912471260875
(Previous) Eval Time (s)     20.856847723945975
Sample Time (s)              20.225799033418298
Epoch Time (s)               72.08955922862515
Total Train Time (s)         23749.71769315051
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:51:32.488832 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #383 | Epoch Duration: 78.38265180587769
2020-01-11 00:51:32.489125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040633116
Z variance train             0.037121754
KL Divergence                5.8514886
KL Loss                      0.5851489
QF Loss                      1111.1863
VF Loss                      329.29938
Policy Loss                  -2611.2366
Q Predictions Mean           2611.5574
Q Predictions Std            434.9038
Q Predictions Max            2806.6755
Q Predictions Min            20.583187
V Predictions Mean           2616.607
V Predictions Std            436.11154
V Predictions Max            2813.3008
V Predictions Min            32.06432
Log Pis Mean                 -4.374301
Log Pis Std                  4.726598
Log Pis Max                  22.990044
Log Pis Min                  -13.017181
Policy mu Mean               0.32158768
Policy mu Std                0.69964695
Policy mu Max                2.781194
Policy mu Min                -2.8745792
Policy log std Mean          -0.3028044
Policy log std Std           0.12897277
Policy log std Max           0.1090626
Policy log std Min           -1.0521998
Z mean eval                  0.04156036
Z variance eval              0.036586657
total_rewards                [3278.38511062 5660.06813718 3853.4229432  3827.34020657 1730.06870099
 5446.2550501  2257.12295019 3476.38909221 2068.78344954 1577.04587647]
total_rewards_mean           3317.4881517072413
total_rewards_std            1372.0772897722054
total_rewards_max            5660.068137183183
total_rewards_min            1577.0458764720643
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               29.23633292131126
(Previous) Eval Time (s)     27.149578604847193
Sample Time (s)              19.898111755028367
Epoch Time (s)               76.28402328118682
Total Train Time (s)         23816.390660220757
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:52:39.164588 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #384 | Epoch Duration: 66.6752417087555
2020-01-11 00:52:39.164777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04178562
Z variance train             0.036595657
KL Divergence                5.8745556
KL Loss                      0.5874556
QF Loss                      1189.675
VF Loss                      421.78458
Policy Loss                  -2596.4065
Q Predictions Mean           2595.348
Q Predictions Std            499.47543
Q Predictions Max            2819.428
Q Predictions Min            23.882187
V Predictions Mean           2604.4438
V Predictions Std            496.9286
V Predictions Max            2837.629
V Predictions Min            35.15481
Log Pis Mean                 -4.220834
Log Pis Std                  5.74918
Log Pis Max                  28.103996
Log Pis Min                  -14.462383
Policy mu Mean               0.2993879
Policy mu Std                0.7328792
Policy mu Max                3.1146524
Policy mu Min                -3.0050359
Policy log std Mean          -0.3045602
Policy log std Std           0.13750257
Policy log std Max           0.01979366
Policy log std Min           -1.101317
Z mean eval                  0.04010098
Z variance eval              0.036647886
total_rewards                [5316.83056282 5437.80884987 5398.90362856 4951.62685868 5084.19455116
 4190.04982508 2070.59700145 2002.58043776 3709.95104454 2806.09737917]
total_rewards_mean           4096.864013907815
total_rewards_std            1303.9725898952697
total_rewards_max            5437.808849867083
total_rewards_min            2002.580437759967
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               30.532317936886102
(Previous) Eval Time (s)     17.540481202304363
Sample Time (s)              18.99991593277082
Epoch Time (s)               67.07271507196128
Total Train Time (s)         23888.69524798589
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:53:51.472101 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #385 | Epoch Duration: 72.30718922615051
2020-01-11 00:53:51.472316 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040335987
Z variance train             0.036653403
KL Divergence                5.8772707
KL Loss                      0.58772707
QF Loss                      774.8616
VF Loss                      293.98325
Policy Loss                  -2647.0715
Q Predictions Mean           2642.9468
Q Predictions Std            389.6652
Q Predictions Max            2835.6084
Q Predictions Min            41.274178
V Predictions Mean           2647.0645
V Predictions Std            390.9341
V Predictions Max            2843.2126
V Predictions Min            47.8192
Log Pis Mean                 -4.6414995
Log Pis Std                  4.399825
Log Pis Max                  15.365094
Log Pis Min                  -13.8533535
Policy mu Mean               0.3248333
Policy mu Std                0.6754089
Policy mu Max                2.7835927
Policy mu Min                -2.444428
Policy log std Mean          -0.2900041
Policy log std Std           0.13831992
Policy log std Max           -0.03630869
Policy log std Min           -0.988343
Z mean eval                  0.040014684
Z variance eval              0.03654037
total_rewards                [1295.65341131  797.66801701 2927.10411989 1687.54756942 5303.16012942
 5387.64562247 3881.13542931 3836.24670115 4965.94145066 5090.89030639]
total_rewards_mean           3517.2992757024995
total_rewards_std            1659.0593025611865
total_rewards_max            5387.645622472281
total_rewards_min            797.668017007414
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               29.664692047983408
(Previous) Eval Time (s)     22.774638106115162
Sample Time (s)              19.66093481145799
Epoch Time (s)               72.10026496555656
Total Train Time (s)         23957.826704204082
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:55:00.611027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #386 | Epoch Duration: 69.13853526115417
2020-01-11 00:55:00.611353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040001094
Z variance train             0.03654685
KL Divergence                5.885106
KL Loss                      0.58851063
QF Loss                      1585.7141
VF Loss                      572.3351
Policy Loss                  -2617.6829
Q Predictions Mean           2614.2744
Q Predictions Std            416.77744
Q Predictions Max            2811.0486
Q Predictions Min            22.619177
V Predictions Mean           2617.0122
V Predictions Std            421.7591
V Predictions Max            2815.1328
V Predictions Min            32.509228
Log Pis Mean                 -3.230205
Log Pis Std                  6.539587
Log Pis Max                  31.88417
Log Pis Min                  -13.244837
Policy mu Mean               0.31538397
Policy mu Std                0.7594531
Policy mu Max                3.4282053
Policy mu Min                -3.325304
Policy log std Mean          -0.311125
Policy log std Std           0.140325
Policy log std Max           0.13958426
Policy log std Min           -1.0105168
Z mean eval                  0.041996628
Z variance eval              0.037413478
total_rewards                [5179.01436416  890.36368385 1668.93364582 5437.15214685 5229.90319281
 5334.76104117 1168.79351519 4749.54293465  642.0479011  4354.22041679]
total_rewards_mean           3465.473284238526
total_rewards_std            1974.2114756323988
total_rewards_max            5437.152146849949
total_rewards_min            642.0479011000805
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               29.617871311027557
(Previous) Eval Time (s)     19.81254763714969
Sample Time (s)              19.231872248928994
Epoch Time (s)               68.66229119710624
Total Train Time (s)         24026.664968024008
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:56:09.453258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #387 | Epoch Duration: 68.84164333343506
2020-01-11 00:56:09.453472 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04241415
Z variance train             0.03742186
KL Divergence                5.828728
KL Loss                      0.5828728
QF Loss                      1285.6296
VF Loss                      800.637
Policy Loss                  -2629.3452
Q Predictions Mean           2625.7476
Q Predictions Std            454.8191
Q Predictions Max            2830.046
Q Predictions Min            18.380476
V Predictions Mean           2612.37
V Predictions Std            453.91782
V Predictions Max            2829.2156
V Predictions Min            35.41992
Log Pis Mean                 -4.299451
Log Pis Std                  5.799985
Log Pis Max                  30.173763
Log Pis Min                  -14.99333
Policy mu Mean               0.32730108
Policy mu Std                0.7137124
Policy mu Max                2.902914
Policy mu Min                -3.0986583
Policy log std Mean          -0.31087974
Policy log std Std           0.13761592
Policy log std Max           -0.027096115
Policy log std Min           -0.96960163
Z mean eval                  0.042730577
Z variance eval              0.037939012
total_rewards                [5595.25154902 5456.15881126 3164.12831102 3340.70451919 3084.67448402
 1371.46366939 2477.66273153 2990.85618459 4413.89568697 5497.41984109]
total_rewards_mean           3739.2215788074072
total_rewards_std            1364.3682058365948
total_rewards_max            5595.251549020225
total_rewards_min            1371.4636693935781
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               32.1221014438197
(Previous) Eval Time (s)     19.99161356408149
Sample Time (s)              19.12695489730686
Epoch Time (s)               71.24066990520805
Total Train Time (s)         24098.196169822942
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:57:20.986344 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #388 | Epoch Duration: 71.53272223472595
2020-01-11 00:57:20.986495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042848237
Z variance train             0.037949927
KL Divergence                5.8235188
KL Loss                      0.58235186
QF Loss                      1881.7726
VF Loss                      360.7816
Policy Loss                  -2652.258
Q Predictions Mean           2651.8628
Q Predictions Std            346.28723
Q Predictions Max            2812.7493
Q Predictions Min            33.56317
V Predictions Mean           2648.9832
V Predictions Std            344.45175
V Predictions Max            2812.5137
V Predictions Min            41.46523
Log Pis Mean                 -3.8451905
Log Pis Std                  5.5222945
Log Pis Max                  27.530916
Log Pis Min                  -16.438793
Policy mu Mean               0.3353431
Policy mu Std                0.72417337
Policy mu Max                3.4802675
Policy mu Min                -3.544057
Policy log std Mean          -0.3030506
Policy log std Std           0.13707575
Policy log std Max           0.42476094
Policy log std Min           -1.186779
Z mean eval                  0.038908087
Z variance eval              0.03746699
total_rewards                [1287.77630165 5217.8257941  2959.17811315 5455.6666362  4158.28022015
 5422.57793728 3282.09853549 3899.16423614 3357.41764593 3139.45597098]
total_rewards_mean           3817.944139107368
total_rewards_std            1242.4921864175956
total_rewards_max            5455.6666362029955
total_rewards_min            1287.7763016537072
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               31.215226497966796
(Previous) Eval Time (s)     20.283329125959426
Sample Time (s)              20.00988671509549
Epoch Time (s)               71.50844233902171
Total Train Time (s)         24169.928186350968
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:58:32.723152 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #389 | Epoch Duration: 71.73652291297913
2020-01-11 00:58:32.723370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038984258
Z variance train             0.03746677
KL Divergence                5.8463516
KL Loss                      0.5846352
QF Loss                      2108.7778
VF Loss                      767.71216
Policy Loss                  -2626.1956
Q Predictions Mean           2622.805
Q Predictions Std            423.55493
Q Predictions Max            2819.3755
Q Predictions Min            26.09807
V Predictions Mean           2619.688
V Predictions Std            416.17545
V Predictions Max            2802.3313
V Predictions Min            35.78646
Log Pis Mean                 -4.79906
Log Pis Std                  5.4185963
Log Pis Max                  31.71635
Log Pis Min                  -15.324978
Policy mu Mean               0.29542172
Policy mu Std                0.6790082
Policy mu Max                3.101455
Policy mu Min                -3.4233289
Policy log std Mean          -0.28577995
Policy log std Std           0.13650456
Policy log std Max           -0.04607573
Policy log std Min           -1.0496888
Z mean eval                  0.03868327
Z variance eval              0.037937988
total_rewards                [3772.12279203 5543.08783754 5118.27742048 2553.40111743 3165.68506239
 1551.28984427 5350.77931556 1645.4089326  4295.49264832 4633.6436749 ]
total_rewards_mean           3762.9188645517615
total_rewards_std            1405.8432726476021
total_rewards_max            5543.087837543503
total_rewards_min            1551.28984426899
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               29.75118815386668
(Previous) Eval Time (s)     20.51107255090028
Sample Time (s)              19.569015284534544
Epoch Time (s)               69.8312759893015
Total Train Time (s)         24239.84032783797
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:59:42.657674 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #390 | Epoch Duration: 69.93410205841064
2020-01-11 00:59:42.658014 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038893152
Z variance train             0.037939783
KL Divergence                5.808688
KL Loss                      0.58086884
QF Loss                      2130.6406
VF Loss                      563.8473
Policy Loss                  -2622.4756
Q Predictions Mean           2621.7876
Q Predictions Std            415.29413
Q Predictions Max            2828.025
Q Predictions Min            24.461126
V Predictions Mean           2615.4756
V Predictions Std            414.93002
V Predictions Max            2818.5776
V Predictions Min            35.895187
Log Pis Mean                 -4.2834225
Log Pis Std                  5.801298
Log Pis Max                  23.867292
Log Pis Min                  -14.168593
Policy mu Mean               0.27203393
Policy mu Std                0.736943
Policy mu Max                3.440902
Policy mu Min                -3.0257463
Policy log std Mean          -0.30830732
Policy log std Std           0.14451258
Policy log std Max           -0.08000241
Policy log std Min           -1.3167171
Z mean eval                  0.043338865
Z variance eval              0.03703825
total_rewards                [3081.60252724 5199.61229187 3036.91463117 5561.82339559 3868.18444129
  959.61209573 5530.73680109 5518.55993577 4875.55709738 3210.99643047]
total_rewards_mean           4084.359964759458
total_rewards_std            1444.916036490439
total_rewards_max            5561.82339558715
total_rewards_min            959.6120957302613
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               30.647953517269343
(Previous) Eval Time (s)     20.61355267232284
Sample Time (s)              19.944996372330934
Epoch Time (s)               71.20650256192312
Total Train Time (s)         24313.18740270473
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:00:56.008823 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #391 | Epoch Duration: 73.35057067871094
2020-01-11 01:00:56.009061 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043515753
Z variance train             0.037037212
KL Divergence                5.852549
KL Loss                      0.5852549
QF Loss                      1431.9572
VF Loss                      255.85898
Policy Loss                  -2657.6238
Q Predictions Mean           2652.625
Q Predictions Std            332.90372
Q Predictions Max            2821.091
Q Predictions Min            31.13648
V Predictions Mean           2653.82
V Predictions Std            337.08905
V Predictions Max            2828.1716
V Predictions Min            40.77441
Log Pis Mean                 -4.1061106
Log Pis Std                  4.5051517
Log Pis Max                  17.65881
Log Pis Min                  -14.806942
Policy mu Mean               0.352314
Policy mu Std                0.6809574
Policy mu Max                3.148341
Policy mu Min                -2.593377
Policy log std Mean          -0.31087577
Policy log std Std           0.13695793
Policy log std Max           0.05749856
Policy log std Min           -1.1217878
Z mean eval                  0.040655937
Z variance eval              0.035992198
total_rewards                [5385.4122629  5495.50903275 5288.5470142  4483.21784573 3643.84474899
 5364.27014683 5313.32959106 3931.44084192 5314.93874562 5077.86520273]
total_rewards_mean           4929.8375432713265
total_rewards_std            633.4240759485505
total_rewards_max            5495.50903274704
total_rewards_min            3643.844748990607
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               29.09758970187977
(Previous) Eval Time (s)     22.75731223402545
Sample Time (s)              20.25454733381048
Epoch Time (s)               72.1094492697157
Total Train Time (s)         24389.558581236284
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:02:12.382468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #392 | Epoch Duration: 76.37323117256165
2020-01-11 01:02:12.382638 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040411685
Z variance train             0.035992455
KL Divergence                5.918415
KL Loss                      0.5918415
QF Loss                      2003.4197
VF Loss                      715.991
Policy Loss                  -2633.2966
Q Predictions Mean           2632.7063
Q Predictions Std            353.41077
Q Predictions Max            2825.9194
Q Predictions Min            23.946224
V Predictions Mean           2641.5208
V Predictions Std            340.63245
V Predictions Max            2823.0676
V Predictions Min            34.64351
Log Pis Mean                 -4.0838284
Log Pis Std                  5.476398
Log Pis Max                  24.336239
Log Pis Min                  -13.10268
Policy mu Mean               0.3098255
Policy mu Std                0.71315074
Policy mu Max                2.7306979
Policy mu Min                -2.7595572
Policy log std Mean          -0.30106646
Policy log std Std           0.1411419
Policy log std Max           -0.045982823
Policy log std Min           -1.1455851
Z mean eval                  0.042631485
Z variance eval              0.03464716
total_rewards                [3081.26287046 2455.67648806  914.16022269 2676.88347532 5539.96199367
 5641.02821915 1151.01722785 3197.02987766 2322.39594428  836.81675684]
total_rewards_mean           2781.623307598221
total_rewards_std            1621.839814990162
total_rewards_max            5641.028219147928
total_rewards_min            836.8167568411824
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               32.41910632699728
(Previous) Eval Time (s)     27.020735053811222
Sample Time (s)              18.806497051380575
Epoch Time (s)               78.24633843218908
Total Train Time (s)         24455.96758809965
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:03:18.794667 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #393 | Epoch Duration: 66.41189765930176
2020-01-11 01:03:18.794860 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04265422
Z variance train             0.034646016
KL Divergence                6.0232115
KL Loss                      0.60232115
QF Loss                      1078.8219
VF Loss                      375.2756
Policy Loss                  -2628.0867
Q Predictions Mean           2624.7305
Q Predictions Std            433.88187
Q Predictions Max            2830.6782
Q Predictions Min            22.952389
V Predictions Mean           2626.6553
V Predictions Std            433.1089
V Predictions Max            2837.449
V Predictions Min            36.1055
Log Pis Mean                 -4.1165237
Log Pis Std                  4.766012
Log Pis Max                  18.92225
Log Pis Min                  -12.52367
Policy mu Mean               0.32471576
Policy mu Std                0.70701516
Policy mu Max                3.2134714
Policy mu Min                -3.2348025
Policy log std Mean          -0.3000061
Policy log std Std           0.13448322
Policy log std Max           -0.06518947
Policy log std Min           -1.1453991
Z mean eval                  0.041816384
Z variance eval              0.03507408
total_rewards                [5359.59737048 2199.36670767 5171.93539514 5405.4783419  5200.10630596
 5266.95551837 5472.22420013 3707.29566691 5387.06909916 2501.47611946]
total_rewards_mean           4567.1504725183895
total_rewards_std            1212.0675095900706
total_rewards_max            5472.224200132792
total_rewards_min            2199.366707670518
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               29.835186404176056
(Previous) Eval Time (s)     15.186015159823
Sample Time (s)              19.26525446679443
Epoch Time (s)               64.28645603079349
Total Train Time (s)         24530.998990969732
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:04:33.829696 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #394 | Epoch Duration: 75.03470802307129
2020-01-11 01:04:33.829909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04190305
Z variance train             0.035069156
KL Divergence                6.0017242
KL Loss                      0.60017246
QF Loss                      1523.9222
VF Loss                      413.13727
Policy Loss                  -2643.912
Q Predictions Mean           2647.0977
Q Predictions Std            378.14236
Q Predictions Max            2830.3162
Q Predictions Min            25.91904
V Predictions Mean           2649.5874
V Predictions Std            374.3811
V Predictions Max            2826.472
V Predictions Min            35.81817
Log Pis Mean                 -4.189522
Log Pis Std                  4.93123
Log Pis Max                  17.88768
Log Pis Min                  -12.83265
Policy mu Mean               0.34956408
Policy mu Std                0.711706
Policy mu Max                2.8860955
Policy mu Min                -2.7955704
Policy log std Mean          -0.30323556
Policy log std Std           0.13797918
Policy log std Max           -0.043213427
Policy log std Min           -1.0969536
Z mean eval                  0.04098412
Z variance eval              0.03558333
total_rewards                [5600.87479964 1783.22716561 5594.99233706 5557.47765023 2800.47328064
 5516.94989824 2128.48652909 4668.14084933 5342.90229786 5682.81163427]
total_rewards_mean           4467.633644198177
total_rewards_std            1502.7982115521058
total_rewards_max            5682.811634271753
total_rewards_min            1783.2271656071794
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               31.6749829063192
(Previous) Eval Time (s)     25.933950202073902
Sample Time (s)              19.710941834840924
Epoch Time (s)               77.31987494323403
Total Train Time (s)         24606.324616087135
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:05:49.159179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #395 | Epoch Duration: 75.3291015625
2020-01-11 01:05:49.159448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041004375
Z variance train             0.035593893
KL Divergence                5.9647574
KL Loss                      0.5964758
QF Loss                      1081.3291
VF Loss                      718.8241
Policy Loss                  -2648.74
Q Predictions Mean           2646.4424
Q Predictions Std            407.94534
Q Predictions Max            2834.0623
Q Predictions Min            25.961092
V Predictions Mean           2645.0137
V Predictions Std            400.98563
V Predictions Max            2828.514
V Predictions Min            31.66527
Log Pis Mean                 -4.4963465
Log Pis Std                  5.222484
Log Pis Max                  29.198711
Log Pis Min                  -14.150301
Policy mu Mean               0.34236652
Policy mu Std                0.6792013
Policy mu Max                3.0385842
Policy mu Min                -2.9735868
Policy log std Mean          -0.2900559
Policy log std Std           0.1321143
Policy log std Max           -0.02241923
Policy log std Min           -0.95201135
Z mean eval                  0.04258002
Z variance eval              0.0381713
total_rewards                [5291.11434166 5366.33239853 5355.07036352 5369.04223792 5105.25588435
 5320.34318837 5291.90238654 4482.69749435 5270.27415709 5272.97892562]
total_rewards_mean           5212.50113779515
total_rewards_std            253.71634670812708
total_rewards_max            5369.042237917023
total_rewards_min            4482.697494354883
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               33.229873335920274
(Previous) Eval Time (s)     23.942809735424817
Sample Time (s)              19.767685886472464
Epoch Time (s)               76.94036895781755
Total Train Time (s)         24688.27882737806
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:07:11.116527 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #396 | Epoch Duration: 81.95687317848206
2020-01-11 01:07:11.116772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042750627
Z variance train             0.03817052
KL Divergence                5.7896614
KL Loss                      0.57896614
QF Loss                      1307.605
VF Loss                      476.70038
Policy Loss                  -2675.9758
Q Predictions Mean           2667.6023
Q Predictions Std            316.8248
Q Predictions Max            2821.6382
Q Predictions Min            14.566181
V Predictions Mean           2676.9849
V Predictions Std            312.03256
V Predictions Max            2820.0195
V Predictions Min            22.562017
Log Pis Mean                 -4.421183
Log Pis Std                  4.957734
Log Pis Max                  18.460066
Log Pis Min                  -14.232303
Policy mu Mean               0.36836195
Policy mu Std                0.67579865
Policy mu Max                3.079616
Policy mu Min                -3.0542932
Policy log std Mean          -0.29163265
Policy log std Std           0.13258366
Policy log std Max           -0.049511343
Policy log std Min           -1.1952997
Z mean eval                  0.04306327
Z variance eval              0.037600502
total_rewards                [5152.04002529 5351.16195384 5222.86578592 5082.91450486 5392.84590837
 1121.98831385 5137.01194013 2560.1351015  5458.83894283 3474.00254093]
total_rewards_mean           4395.380501751557
total_rewards_std            1423.0792123069805
total_rewards_max            5458.838942831577
total_rewards_min            1121.988313850106
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               30.746734661981463
(Previous) Eval Time (s)     28.958981491159648
Sample Time (s)              20.41419585701078
Epoch Time (s)               80.1199120101519
Total Train Time (s)         24764.098373065237
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:08:26.943425 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #397 | Epoch Duration: 75.82644867897034
2020-01-11 01:08:26.943738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04319171
Z variance train             0.03759712
KL Divergence                5.8544717
KL Loss                      0.5854472
QF Loss                      857.5703
VF Loss                      291.3475
Policy Loss                  -2669.8313
Q Predictions Mean           2666.4
Q Predictions Std            370.0266
Q Predictions Max            2827.9954
Q Predictions Min            31.423267
V Predictions Mean           2669.624
V Predictions Std            369.8449
V Predictions Max            2833.1335
V Predictions Min            44.39318
Log Pis Mean                 -4.431754
Log Pis Std                  4.656123
Log Pis Max                  19.216934
Log Pis Min                  -15.708776
Policy mu Mean               0.33556578
Policy mu Std                0.70294285
Policy mu Max                3.1742077
Policy mu Min                -2.8121424
Policy log std Mean          -0.3027796
Policy log std Std           0.1287663
Policy log std Max           0.07746878
Policy log std Min           -1.0110841
Z mean eval                  0.04403698
Z variance eval              0.03694383
total_rewards                [5334.59387357 1378.98461555 5489.16741186 5348.9046151  5246.17781873
 1137.95218923 5349.22056104 2619.51109782 1921.64097777 5368.69568671]
total_rewards_mean           3919.4848847386284
total_rewards_std            1796.845166470461
total_rewards_max            5489.1674118616575
total_rewards_min            1137.952189232052
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               34.67122284695506
(Previous) Eval Time (s)     24.665161652024835
Sample Time (s)              19.525769614614546
Epoch Time (s)               78.86215411359444
Total Train Time (s)         24839.610722296406
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:09:42.461738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #398 | Epoch Duration: 75.51773357391357
2020-01-11 01:09:42.461997 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043837104
Z variance train             0.03692684
KL Divergence                5.902482
KL Loss                      0.5902482
QF Loss                      1464.0709
VF Loss                      668.51636
Policy Loss                  -2658.2236
Q Predictions Mean           2655.739
Q Predictions Std            290.0351
Q Predictions Max            2818.0464
Q Predictions Min            78.14002
V Predictions Mean           2669.2751
V Predictions Std            288.56262
V Predictions Max            2831.1448
V Predictions Min            90.79938
Log Pis Mean                 -4.0554323
Log Pis Std                  5.122757
Log Pis Max                  17.685274
Log Pis Min                  -15.26842
Policy mu Mean               0.35444316
Policy mu Std                0.7073461
Policy mu Max                3.650819
Policy mu Min                -2.9127986
Policy log std Mean          -0.3032886
Policy log std Std           0.14666261
Policy log std Max           0.011782065
Policy log std Min           -1.2171465
Z mean eval                  0.04732321
Z variance eval              0.03483174
total_rewards                [2131.64323801 2354.53212411 1222.18853333 5319.48921986 1029.85098705
 3095.81906512 4413.51053566 5267.62449713 2643.36617303 5484.30748145]
total_rewards_mean           3296.23318547621
total_rewards_std            1617.5150003938297
total_rewards_max            5484.307481454133
total_rewards_min            1029.8509870544988
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               33.90063401311636
(Previous) Eval Time (s)     21.320446759928018
Sample Time (s)              19.9587266407907
Epoch Time (s)               75.17980741383508
Total Train Time (s)         24912.783067482058
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:10:55.641200 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #399 | Epoch Duration: 73.17897701263428
2020-01-11 01:10:55.641525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047375936
Z variance train             0.03482343
KL Divergence                6.0421395
KL Loss                      0.60421395
QF Loss                      630.1387
VF Loss                      365.9726
Policy Loss                  -2652.9348
Q Predictions Mean           2649.5603
Q Predictions Std            441.29953
Q Predictions Max            2837.7888
Q Predictions Min            19.2089
V Predictions Mean           2645.449
V Predictions Std            439.03152
V Predictions Max            2836.1536
V Predictions Min            29.586971
Log Pis Mean                 -4.92289
Log Pis Std                  4.410322
Log Pis Max                  13.995659
Log Pis Min                  -19.06099
Policy mu Mean               0.3414933
Policy mu Std                0.674085
Policy mu Max                2.4398851
Policy mu Min                -2.7116838
Policy log std Mean          -0.29926258
Policy log std Std           0.13139693
Policy log std Max           -0.09535704
Policy log std Min           -1.0509896
Z mean eval                  0.048000555
Z variance eval              0.036556304
total_rewards                [5542.71036735 5498.51556797 2347.96492033 5454.82356427 5467.97371055
 2012.82361649 5427.50385203 5314.97815429 5480.66613994 5385.36430928]
total_rewards_mean           4793.332420250408
total_rewards_std            1309.9553609824272
total_rewards_max            5542.710367354535
total_rewards_min            2012.8236164874545
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               32.821844916790724
(Previous) Eval Time (s)     19.31929396186024
Sample Time (s)              19.710419477894902
Epoch Time (s)               71.85155835654587
Total Train Time (s)         24991.585149263497
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:12:14.447399 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #400 | Epoch Duration: 78.80564522743225
2020-01-11 01:12:14.447643 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047810063
Z variance train             0.036547463
KL Divergence                5.9233904
KL Loss                      0.59233904
QF Loss                      997.0029
VF Loss                      582.87494
Policy Loss                  -2653.392
Q Predictions Mean           2656.7935
Q Predictions Std            406.57095
Q Predictions Max            2832.9456
Q Predictions Min            23.98758
V Predictions Mean           2666.9038
V Predictions Std            403.0945
V Predictions Max            2843.5981
V Predictions Min            33.66292
Log Pis Mean                 -4.6160955
Log Pis Std                  5.0577726
Log Pis Max                  19.097923
Log Pis Min                  -14.248523
Policy mu Mean               0.38592285
Policy mu Std                0.67112184
Policy mu Max                2.7079353
Policy mu Min                -2.57391
Policy log std Mean          -0.30375227
Policy log std Std           0.13539912
Policy log std Max           -0.0035604686
Policy log std Min           -1.204612
Z mean eval                  0.045659043
Z variance eval              0.038193356
total_rewards                [5248.66122776  790.07264918 3025.51592925 3007.10164206 5251.64400391
 2201.45956529 5037.38345615 5206.49802558  447.33012031 5383.66107361]
total_rewards_mean           3559.9327693089886
total_rewards_std            1836.5948575190025
total_rewards_max            5383.66107361134
total_rewards_min            447.3301203058746
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               31.144438223913312
(Previous) Eval Time (s)     26.273039714898914
Sample Time (s)              19.003957801964134
Epoch Time (s)               76.42143574077636
Total Train Time (s)         25062.71436911542
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:13:25.582072 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #401 | Epoch Duration: 71.13422536849976
2020-01-11 01:13:25.582355 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045439903
Z variance train             0.03818848
KL Divergence                5.803503
KL Loss                      0.58035034
QF Loss                      1465.7532
VF Loss                      273.14233
Policy Loss                  -2692.9373
Q Predictions Mean           2690.6267
Q Predictions Std            236.54668
Q Predictions Max            2839.2017
Q Predictions Min            24.000557
V Predictions Mean           2697.4436
V Predictions Std            236.05043
V Predictions Max            2842.8872
V Predictions Min            34.545033
Log Pis Mean                 -4.165827
Log Pis Std                  4.7356453
Log Pis Max                  14.432759
Log Pis Min                  -17.194893
Policy mu Mean               0.33961824
Policy mu Std                0.70296264
Policy mu Max                2.9642735
Policy mu Min                -2.38902
Policy log std Mean          -0.29656544
Policy log std Std           0.1305487
Policy log std Max           -0.06915724
Policy log std Min           -0.91434157
Z mean eval                  0.048474282
Z variance eval              0.03837647
total_rewards                [4495.48403253 3099.11494563 3889.00196332 5347.36779888 1912.49991054
 2479.7155492  4273.62496613 5333.48091869 5259.1702195  5422.50808135]
total_rewards_mean           4151.196838576923
total_rewards_std            1216.026986457073
total_rewards_max            5422.5080813456
total_rewards_min            1912.4999105419004
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               29.596922458149493
(Previous) Eval Time (s)     20.985508199315518
Sample Time (s)              19.87110555358231
Epoch Time (s)               70.45353621104732
Total Train Time (s)         25135.332717106678
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:14:38.203633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #402 | Epoch Duration: 72.62110161781311
2020-01-11 01:14:38.203830 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #402 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04873876
Z variance train             0.038360503
KL Divergence                5.7843795
KL Loss                      0.578438
QF Loss                      1118.5376
VF Loss                      433.19098
Policy Loss                  -2629.091
Q Predictions Mean           2624.0361
Q Predictions Std            486.89154
Q Predictions Max            2825.195
Q Predictions Min            25.857365
V Predictions Mean           2630.852
V Predictions Std            482.5993
V Predictions Max            2830.1743
V Predictions Min            35.90326
Log Pis Mean                 -4.794874
Log Pis Std                  4.723263
Log Pis Max                  18.43067
Log Pis Min                  -14.194331
Policy mu Mean               0.34605268
Policy mu Std                0.6497414
Policy mu Max                2.8101315
Policy mu Min                -2.7776284
Policy log std Mean          -0.28510678
Policy log std Std           0.13264729
Policy log std Max           0.13438612
Policy log std Min           -1.3563046
Z mean eval                  0.045803826
Z variance eval              0.0387994
total_rewards                [1500.52915177 5204.11518888 4901.22925135 3747.56890029 3148.0690948
 3125.24256083 5126.84957986 3187.54017583 4674.53642704 5029.27615894]
total_rewards_mean           3964.4956489586475
total_rewards_std            1161.7165976395231
total_rewards_max            5204.115188876305
total_rewards_min            1500.5291517703743
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               32.72960554715246
(Previous) Eval Time (s)     23.15279327100143
Sample Time (s)              19.239430140703917
Epoch Time (s)               75.1218289588578
Total Train Time (s)         25210.84999932442
Epoch                        403
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:15:53.724651 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #403 | Epoch Duration: 75.52067995071411
2020-01-11 01:15:53.724842 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04616938
Z variance train             0.03877973
KL Divergence                5.7518134
KL Loss                      0.57518137
QF Loss                      1012.82214
VF Loss                      207.26399
Policy Loss                  -2690.3066
Q Predictions Mean           2688.6353
Q Predictions Std            353.83408
Q Predictions Max            2838.7856
Q Predictions Min            24.602621
V Predictions Mean           2683.637
V Predictions Std            351.65027
V Predictions Max            2836.5264
V Predictions Min            32.984425
Log Pis Mean                 -4.7191353
Log Pis Std                  4.2571583
Log Pis Max                  19.586246
Log Pis Min                  -13.215547
Policy mu Mean               0.33635274
Policy mu Std                0.66370875
Policy mu Max                2.1956148
Policy mu Min                -2.1253672
Policy log std Mean          -0.2943389
Policy log std Std           0.13029973
Policy log std Max           -0.08013339
Policy log std Min           -0.9647056
Z mean eval                  0.04386998
Z variance eval              0.03881244
total_rewards                [2341.32329575 1742.44420336 4918.46464647 1108.14416738 5345.27106329
 5393.39133156 3634.31022791  704.05064083 2667.40295606 4503.37486522]
total_rewards_mean           3235.8177397833033
total_rewards_std            1673.0790399731106
total_rewards_max            5393.391331556233
total_rewards_min            704.0506408343819
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               30.20079327886924
(Previous) Eval Time (s)     23.551305117551237
Sample Time (s)              19.51060475036502
Epoch Time (s)               73.2627031467855
Total Train Time (s)         25278.7929143128
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:17:01.672571 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #404 | Epoch Duration: 67.94757390022278
2020-01-11 01:17:01.673655 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043935668
Z variance train             0.03882106
KL Divergence                5.7347984
KL Loss                      0.57347983
QF Loss                      1692.688
VF Loss                      365.6126
Policy Loss                  -2682.3354
Q Predictions Mean           2674.9797
Q Predictions Std            305.64288
Q Predictions Max            2830.204
Q Predictions Min            24.23449
V Predictions Mean           2683.045
V Predictions Std            303.0209
V Predictions Max            2837.4836
V Predictions Min            31.579226
Log Pis Mean                 -4.3172894
Log Pis Std                  4.973567
Log Pis Max                  25.645554
Log Pis Min                  -15.048219
Policy mu Mean               0.29512697
Policy mu Std                0.72323173
Policy mu Max                2.8330908
Policy mu Min                -3.3591194
Policy log std Mean          -0.2980865
Policy log std Std           0.12779415
Policy log std Max           -0.0795512
Policy log std Min           -0.902484
Z mean eval                  0.044685695
Z variance eval              0.03683212
total_rewards                [5349.50924359  785.44337853 5298.84255131 5264.33807991 2261.40164437
 5082.19202196 5147.06210402 5183.83063686 4012.10613253  966.29539112]
total_rewards_mean           3935.102118420133
total_rewards_std            1775.1776065641975
total_rewards_max            5349.5092435875595
total_rewards_min            785.4433785265427
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               33.38609055476263
(Previous) Eval Time (s)     18.23584759607911
Sample Time (s)              20.08985456265509
Epoch Time (s)               71.71179271349683
Total Train Time (s)         25354.4677231689
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:18:17.354144 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #405 | Epoch Duration: 75.68027138710022
2020-01-11 01:18:17.354448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044515613
Z variance train             0.036838394
KL Divergence                5.8630505
KL Loss                      0.5863051
QF Loss                      1624.0927
VF Loss                      754.948
Policy Loss                  -2642.9536
Q Predictions Mean           2645.8027
Q Predictions Std            460.45334
Q Predictions Max            2842.899
Q Predictions Min            17.034714
V Predictions Mean           2656.3074
V Predictions Std            463.6078
V Predictions Max            2861.4216
V Predictions Min            29.636911
Log Pis Mean                 -4.3815727
Log Pis Std                  5.2290444
Log Pis Max                  27.94828
Log Pis Min                  -14.008179
Policy mu Mean               0.32085222
Policy mu Std                0.70340693
Policy mu Max                2.7079318
Policy mu Min                -3.4789207
Policy log std Mean          -0.3062234
Policy log std Std           0.13660976
Policy log std Max           0.016452238
Policy log std Min           -1.1961074
Z mean eval                  0.044551548
Z variance eval              0.035907906
total_rewards                [ 678.20691667 2627.86181078 5365.56927147 5311.95005103 3867.35875371
 2209.81887269 5384.45800573 5313.93270173 4746.53943297 5380.57952558]
total_rewards_mean           4088.627534235805
total_rewards_std            1604.7841819600333
total_rewards_max            5384.458005729353
total_rewards_min            678.2069166656546
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               30.623487845994532
(Previous) Eval Time (s)     22.20398914022371
Sample Time (s)              18.868574435357004
Epoch Time (s)               71.69605142157525
Total Train Time (s)         25426.882939516567
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:19:29.775340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #406 | Epoch Duration: 72.42064332962036
2020-01-11 01:19:29.775616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044422287
Z variance train             0.03590991
KL Divergence                5.915743
KL Loss                      0.5915743
QF Loss                      1423.4445
VF Loss                      491.1913
Policy Loss                  -2674.3372
Q Predictions Mean           2672.9014
Q Predictions Std            379.9324
Q Predictions Max            2851.0383
Q Predictions Min            26.023275
V Predictions Mean           2676.775
V Predictions Std            377.91638
V Predictions Max            2846.2393
V Predictions Min            35.0272
Log Pis Mean                 -4.646416
Log Pis Std                  4.298831
Log Pis Max                  15.827457
Log Pis Min                  -15.0889635
Policy mu Mean               0.35818896
Policy mu Std                0.68240577
Policy mu Max                2.849367
Policy mu Min                -3.2451098
Policy log std Mean          -0.2973287
Policy log std Std           0.12560847
Policy log std Max           -0.04209046
Policy log std Min           -0.96434784
Z mean eval                  0.04453159
Z variance eval              0.035846375
total_rewards                [2255.36275973 1673.45217775 5563.18849471 4319.46516199 5386.85087404
 2977.51240433 5357.57033857 4314.01204383 1676.50413554 2187.52027804]
total_rewards_mean           3571.143866853205
total_rewards_std            1508.5482124319594
total_rewards_max            5563.188494707743
total_rewards_min            1673.4521777514162
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               32.095640402287245
(Previous) Eval Time (s)     22.92830810882151
Sample Time (s)              19.44364458275959
Epoch Time (s)               74.46759309386835
Total Train Time (s)         25497.833048332483
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:20:40.728711 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #407 | Epoch Duration: 70.95290327072144
2020-01-11 01:20:40.728877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #407 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044685557
Z variance train             0.035846844
KL Divergence                5.9216223
KL Loss                      0.59216225
QF Loss                      1354.334
VF Loss                      388.27274
Policy Loss                  -2684.0598
Q Predictions Mean           2674.9888
Q Predictions Std            358.1339
Q Predictions Max            2838.5176
Q Predictions Min            26.295385
V Predictions Mean           2678.6877
V Predictions Std            356.6261
V Predictions Max            2848.625
V Predictions Min            34.236538
Log Pis Mean                 -4.4048166
Log Pis Std                  4.867658
Log Pis Max                  35.374702
Log Pis Min                  -15.36981
Policy mu Mean               0.2993892
Policy mu Std                0.6978332
Policy mu Max                2.9967175
Policy mu Min                -2.7906976
Policy log std Mean          -0.2988343
Policy log std Std           0.13677078
Policy log std Max           -0.016918391
Policy log std Min           -1.0964398
Z mean eval                  0.042629868
Z variance eval              0.038334496
total_rewards                [2302.39804688 2533.85779405 5214.93097212 5191.76265259 5232.0598965
 4029.72149755 1890.47830077 5159.09690665  995.94240456 5247.72711651]
total_rewards_mean           3779.7975588172803
total_rewards_std            1591.7448628454533
total_rewards_max            5247.727116510542
total_rewards_min            995.9424045564186
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               31.308664282783866
(Previous) Eval Time (s)     19.41329269297421
Sample Time (s)              19.31658584717661
Epoch Time (s)               70.03854282293469
Total Train Time (s)         25569.852241247892
Epoch                        408
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:21:52.750340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #408 | Epoch Duration: 72.02132654190063
2020-01-11 01:21:52.750529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042983614
Z variance train             0.03832624
KL Divergence                5.7583895
KL Loss                      0.575839
QF Loss                      1263.2234
VF Loss                      584.7471
Policy Loss                  -2653.6177
Q Predictions Mean           2652.0862
Q Predictions Std            443.7784
Q Predictions Max            2843.82
Q Predictions Min            22.38018
V Predictions Mean           2650.044
V Predictions Std            435.21066
V Predictions Max            2838.223
V Predictions Min            35.05657
Log Pis Mean                 -4.705393
Log Pis Std                  5.2766848
Log Pis Max                  30.997313
Log Pis Min                  -18.011337
Policy mu Mean               0.31233886
Policy mu Std                0.69761425
Policy mu Max                3.32146
Policy mu Min                -3.150533
Policy log std Mean          -0.2938366
Policy log std Std           0.1358394
Policy log std Max           -0.04760968
Policy log std Min           -1.1334915
Z mean eval                  0.046889614
Z variance eval              0.039325297
total_rewards                [2237.0918438  2219.26050692 5526.5578099  5427.03901559 5447.32420015
 2211.80293592 5404.830036   2018.23969676 4163.92509159 5321.03967179]
total_rewards_mean           3997.7110808426123
total_rewards_std            1536.5864660624386
total_rewards_max            5526.557809900562
total_rewards_min            2018.2396967552604
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               33.98358857491985
(Previous) Eval Time (s)     21.395790689159185
Sample Time (s)              19.134202134795487
Epoch Time (s)               74.51358139887452
Total Train Time (s)         25644.489982630592
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:23:07.393133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #409 | Epoch Duration: 74.64246678352356
2020-01-11 01:23:07.393353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04687684
Z variance train             0.039298635
KL Divergence                5.7024593
KL Loss                      0.5702459
QF Loss                      1118.6104
VF Loss                      340.7392
Policy Loss                  -2660.8826
Q Predictions Mean           2650.1682
Q Predictions Std            428.0728
Q Predictions Max            2837.509
Q Predictions Min            24.601534
V Predictions Mean           2659.8892
V Predictions Std            423.3688
V Predictions Max            2845.2507
V Predictions Min            32.744526
Log Pis Mean                 -4.19386
Log Pis Std                  5.0275564
Log Pis Max                  17.926382
Log Pis Min                  -14.584716
Policy mu Mean               0.36071086
Policy mu Std                0.68993676
Policy mu Max                2.4487348
Policy mu Min                -2.5649447
Policy log std Mean          -0.29309794
Policy log std Std           0.12944016
Policy log std Max           -0.056479007
Policy log std Min           -1.0491017
Z mean eval                  0.045270704
Z variance eval              0.039316516
total_rewards                [3206.07234766 5452.84598626 5093.06364653 3564.77082541 5330.42313678
 5190.31121206 2701.16675136 5315.73010048 1457.13080725 1015.26413327]
total_rewards_mean           3832.6778947054563
total_rewards_std            1607.02023050596
total_rewards_max            5452.8459862552145
total_rewards_min            1015.2641332729987
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               31.30213367100805
(Previous) Eval Time (s)     21.52438952215016
Sample Time (s)              20.497252673842013
Epoch Time (s)               73.32377586700022
Total Train Time (s)         25717.929977229796
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:24:20.836400 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #410 | Epoch Duration: 73.44289302825928
2020-01-11 01:24:20.836594 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045301877
Z variance train             0.039311953
KL Divergence                5.7192154
KL Loss                      0.5719215
QF Loss                      1443.0928
VF Loss                      529.7431
Policy Loss                  -2671.9226
Q Predictions Mean           2666.1992
Q Predictions Std            354.5374
Q Predictions Max            2838.9656
Q Predictions Min            19.91095
V Predictions Mean           2677.6753
V Predictions Std            357.0203
V Predictions Max            2866.4797
V Predictions Min            25.052307
Log Pis Mean                 -3.9794338
Log Pis Std                  5.6638856
Log Pis Max                  32.987762
Log Pis Min                  -15.013809
Policy mu Mean               0.30852628
Policy mu Std                0.7319998
Policy mu Max                3.0838993
Policy mu Min                -3.417488
Policy log std Mean          -0.30696648
Policy log std Std           0.14129342
Policy log std Max           -0.052225217
Policy log std Min           -1.1520491
Z mean eval                  0.046744566
Z variance eval              0.03904017
total_rewards                [5397.72644047 5178.91023789 5336.93467579 2184.7820649  5368.04542674
 5269.23858066 3729.68999314 5232.86622082 3236.11775268 5250.13446346]
total_rewards_mean           4618.444585655353
total_rewards_std            1087.3378372131174
total_rewards_max            5397.72644046844
total_rewards_min            2184.782064902314
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               30.006112546194345
(Previous) Eval Time (s)     21.643185046035796
Sample Time (s)              20.281863579526544
Epoch Time (s)               71.93116117175668
Total Train Time (s)         25793.852515610866
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:25:36.761751 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #411 | Epoch Duration: 75.92503881454468
2020-01-11 01:25:36.761931 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046456832
Z variance train             0.039059836
KL Divergence                5.722473
KL Loss                      0.5722473
QF Loss                      1631.1837
VF Loss                      438.6853
Policy Loss                  -2637.3137
Q Predictions Mean           2636.8828
Q Predictions Std            458.65594
Q Predictions Max            2851.8748
Q Predictions Min            16.49738
V Predictions Mean           2645.4976
V Predictions Std            464.00516
V Predictions Max            2855.9382
V Predictions Min            21.701145
Log Pis Mean                 -4.977452
Log Pis Std                  4.3724995
Log Pis Max                  15.515686
Log Pis Min                  -13.731924
Policy mu Mean               0.29549894
Policy mu Std                0.67248607
Policy mu Max                2.7074764
Policy mu Min                -2.7119086
Policy log std Mean          -0.294474
Policy log std Std           0.12973551
Policy log std Max           0.0016639084
Policy log std Min           -0.93926203
Z mean eval                  0.046992697
Z variance eval              0.038597543
total_rewards                [5250.83977356  858.11815551 1896.82945031 4241.90353814 5309.19636785
 2476.69615486 1903.09720323 5459.70465333 5152.47188663 2073.51470615]
total_rewards_mean           3462.237188956072
total_rewards_std            1691.97230244572
total_rewards_max            5459.704653329977
total_rewards_min            858.1181555141495
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               32.89344344008714
(Previous) Eval Time (s)     25.63670545304194
Sample Time (s)              20.000980326905847
Epoch Time (s)               78.53112922003493
Total Train Time (s)         25865.888459573034
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:26:48.805443 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #412 | Epoch Duration: 72.04335117340088
2020-01-11 01:26:48.805687 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04730891
Z variance train             0.038583122
KL Divergence                5.746803
KL Loss                      0.57468027
QF Loss                      827.85913
VF Loss                      376.76495
Policy Loss                  -2650.626
Q Predictions Mean           2644.3735
Q Predictions Std            443.02905
Q Predictions Max            2836.9827
Q Predictions Min            24.752338
V Predictions Mean           2643.8298
V Predictions Std            440.1901
V Predictions Max            2841.8274
V Predictions Min            33.904667
Log Pis Mean                 -4.8188863
Log Pis Std                  5.4221253
Log Pis Max                  26.742794
Log Pis Min                  -13.354433
Policy mu Mean               0.31484497
Policy mu Std                0.6775159
Policy mu Max                2.6291916
Policy mu Min                -2.577015
Policy log std Mean          -0.29967952
Policy log std Std           0.13553807
Policy log std Max           0.0114172995
Policy log std Min           -1.0742859
Z mean eval                  0.044640552
Z variance eval              0.03685508
total_rewards                [1464.38303757 3997.48851565 5490.1058115  3543.1936844  2210.66028473
 1770.65023548 4673.42173481 5389.67142401 3126.74118671 1201.25390011]
total_rewards_mean           3286.75698149702
total_rewards_std            1514.0433338648215
total_rewards_max            5490.1058115010965
total_rewards_min            1201.2539001105945
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               29.32990616513416
(Previous) Eval Time (s)     19.148593062069267
Sample Time (s)              19.72104914067313
Epoch Time (s)               68.19954836787656
Total Train Time (s)         25932.761474934407
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:27:55.685404 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #413 | Epoch Duration: 66.87951302528381
2020-01-11 01:27:55.685690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #413 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04435967
Z variance train             0.036858737
KL Divergence                5.8582907
KL Loss                      0.5858291
QF Loss                      1227.6819
VF Loss                      354.61594
Policy Loss                  -2648.9448
Q Predictions Mean           2650.6345
Q Predictions Std            464.39816
Q Predictions Max            2848.3777
Q Predictions Min            21.517385
V Predictions Mean           2653.3633
V Predictions Std            463.85165
V Predictions Max            2864.517
V Predictions Min            31.795881
Log Pis Mean                 -5.125896
Log Pis Std                  5.0090957
Log Pis Max                  20.40056
Log Pis Min                  -15.149467
Policy mu Mean               0.33113497
Policy mu Std                0.6711197
Policy mu Max                2.898416
Policy mu Min                -2.548377
Policy log std Mean          -0.28866163
Policy log std Std           0.12781
Policy log std Max           -0.06626762
Policy log std Min           -0.9434105
Z mean eval                  0.04632144
Z variance eval              0.03683153
total_rewards                [1633.17703173 5262.48223292 3319.97714976 5259.39350462 1771.9173403
 5410.72666528 5374.39565786 1169.57944616 5271.35591375 4958.35491218]
total_rewards_mean           3943.135985455883
total_rewards_std            1691.1953246756905
total_rewards_max            5410.726665280402
total_rewards_min            1169.5794461593189
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               31.315489168278873
(Previous) Eval Time (s)     17.828111551702023
Sample Time (s)              19.722994942218065
Epoch Time (s)               68.86659566219896
Total Train Time (s)         26005.57784653455
Epoch                        414
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:29:08.503519 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #414 | Epoch Duration: 72.81764268875122
2020-01-11 01:29:08.503671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046610374
Z variance train             0.03682726
KL Divergence                5.8610797
KL Loss                      0.58610797
QF Loss                      1685.1583
VF Loss                      732.37915
Policy Loss                  -2645.1165
Q Predictions Mean           2641.3076
Q Predictions Std            452.11926
Q Predictions Max            2860.2556
Q Predictions Min            25.72887
V Predictions Mean           2636.771
V Predictions Std            456.31522
V Predictions Max            2870.7202
V Predictions Min            33.204533
Log Pis Mean                 -4.305208
Log Pis Std                  5.5966334
Log Pis Max                  29.47888
Log Pis Min                  -15.907612
Policy mu Mean               0.31938013
Policy mu Std                0.71328866
Policy mu Max                2.993977
Policy mu Min                -2.660296
Policy log std Mean          -0.30804235
Policy log std Std           0.13538107
Policy log std Max           -0.038091704
Policy log std Min           -1.1449295
Z mean eval                  0.04213415
Z variance eval              0.037404217
total_rewards                [5607.68122138 5362.72556873 5576.93964597 1799.86626364 1727.63068395
 5354.35880213 1376.33019503 4287.42590133 5512.28372761 5399.40417959]
total_rewards_mean           4200.464618935457
total_rewards_std            1719.7868313837118
total_rewards_max            5607.681221375059
total_rewards_min            1376.3301950316948
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               30.95749858999625
(Previous) Eval Time (s)     21.77885932987556
Sample Time (s)              19.720760255586356
Epoch Time (s)               72.45711817545816
Total Train Time (s)         26079.697750936262
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:30:22.628717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #415 | Epoch Duration: 74.12489724159241
2020-01-11 01:30:22.628962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04185976
Z variance train             0.03741204
KL Divergence                5.8356094
KL Loss                      0.58356094
QF Loss                      1551.9922
VF Loss                      283.51535
Policy Loss                  -2656.0325
Q Predictions Mean           2654.5693
Q Predictions Std            436.37296
Q Predictions Max            2849.098
Q Predictions Min            23.21966
V Predictions Mean           2662.2126
V Predictions Std            438.45044
V Predictions Max            2855.2014
V Predictions Min            33.650085
Log Pis Mean                 -4.2527733
Log Pis Std                  4.4491935
Log Pis Max                  19.099234
Log Pis Min                  -16.272537
Policy mu Mean               0.37547916
Policy mu Std                0.6733264
Policy mu Max                2.5670857
Policy mu Min                -2.497017
Policy log std Mean          -0.3024955
Policy log std Std           0.13730203
Policy log std Max           -0.07227364
Policy log std Min           -1.0328579
Z mean eval                  0.04309278
Z variance eval              0.03854982
total_rewards                [5510.43692106 1289.80219067 3550.76216591 5357.62343184 5340.42313126
 3696.05742986 5423.35837688 5511.93691963 5099.86762559 5165.54638548]
total_rewards_mean           4594.581457818032
total_rewards_std            1300.2115796258752
total_rewards_max            5511.93691963498
total_rewards_min            1289.8021906651495
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               30.569871336221695
(Previous) Eval Time (s)     23.446299664210528
Sample Time (s)              19.771830946672708
Epoch Time (s)               73.78800194710493
Total Train Time (s)         26155.335411598906
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:31:38.274210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #416 | Epoch Duration: 75.64504218101501
2020-01-11 01:31:38.274522 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043460023
Z variance train             0.038552366
KL Divergence                5.761429
KL Loss                      0.5761429
QF Loss                      1151.99
VF Loss                      335.88037
Policy Loss                  -2669.8342
Q Predictions Mean           2669.1326
Q Predictions Std            418.1574
Q Predictions Max            2854.8374
Q Predictions Min            25.791267
V Predictions Mean           2665.3467
V Predictions Std            417.849
V Predictions Max            2867.1208
V Predictions Min            35.788475
Log Pis Mean                 -4.227111
Log Pis Std                  4.923641
Log Pis Max                  16.79394
Log Pis Min                  -19.7886
Policy mu Mean               0.3150592
Policy mu Std                0.6980036
Policy mu Max                2.9311209
Policy mu Min                -3.128408
Policy log std Mean          -0.3070123
Policy log std Std           0.1344693
Policy log std Max           -0.08751166
Policy log std Min           -1.0195792
Z mean eval                  0.043197043
Z variance eval              0.04050981
total_rewards                [5533.99498787 5523.47213409 5148.0428311  5438.11572523 5406.98777122
 5483.63137768 5451.85115089  651.72480706 5511.28636413  732.04168116]
total_rewards_mean           4488.11488304203
total_rewards_std            1901.0749325094068
total_rewards_max            5533.994987871199
total_rewards_min            651.7248070588024
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               32.612098078243434
(Previous) Eval Time (s)     25.30298599600792
Sample Time (s)              19.15527566196397
Epoch Time (s)               77.07035973621532
Total Train Time (s)         26231.451890353113
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:32:54.395846 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #417 | Epoch Duration: 76.12112522125244
2020-01-11 01:32:54.396011 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04335863
Z variance train             0.040507153
KL Divergence                5.6602216
KL Loss                      0.56602216
QF Loss                      1356.1985
VF Loss                      645.4804
Policy Loss                  -2609.1938
Q Predictions Mean           2605.5837
Q Predictions Std            545.45654
Q Predictions Max            2844.337
Q Predictions Min            27.411072
V Predictions Mean           2600.0518
V Predictions Std            547.9676
V Predictions Max            2853.4414
V Predictions Min            38.293118
Log Pis Mean                 -4.6939187
Log Pis Std                  4.6708994
Log Pis Max                  24.487328
Log Pis Min                  -15.119491
Policy mu Mean               0.3430094
Policy mu Std                0.6737886
Policy mu Max                2.616308
Policy mu Min                -2.9416065
Policy log std Mean          -0.28723377
Policy log std Std           0.12939078
Policy log std Max           -0.01877734
Policy log std Min           -1.0717477
Z mean eval                  0.042909823
Z variance eval              0.040111132
total_rewards                [5681.33322096 5428.28394738 2218.64607378 4822.05759658 5437.55099402
  676.92665969 4126.30768236 2267.46233858 5551.94647627 5215.5500467 ]
total_rewards_mean           4142.606503631234
total_rewards_std            1688.9529369887362
total_rewards_max            5681.333220957583
total_rewards_min            676.9266596854077
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               31.590235503856093
(Previous) Eval Time (s)     24.353438074700534
Sample Time (s)              19.79757041623816
Epoch Time (s)               75.74124399479479
Total Train Time (s)         26305.467988678254
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:34:08.416387 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #418 | Epoch Duration: 74.02024626731873
2020-01-11 01:34:08.416594 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043053277
Z variance train             0.040115338
KL Divergence                5.679472
KL Loss                      0.5679472
QF Loss                      1181.6809
VF Loss                      403.7344
Policy Loss                  -2693.6003
Q Predictions Mean           2695.5566
Q Predictions Std            323.52414
Q Predictions Max            2855.7737
Q Predictions Min            290.59064
V Predictions Mean           2688.5068
V Predictions Std            323.14438
V Predictions Max            2855.0442
V Predictions Min            291.497
Log Pis Mean                 -5.0006475
Log Pis Std                  4.4565406
Log Pis Max                  15.617477
Log Pis Min                  -14.843012
Policy mu Mean               0.31175354
Policy mu Std                0.6762491
Policy mu Max                2.5443163
Policy mu Min                -2.5507705
Policy log std Mean          -0.29425022
Policy log std Std           0.12940598
Policy log std Max           -0.073836036
Policy log std Min           -1.0555611
Z mean eval                  0.043531403
Z variance eval              0.041401893
total_rewards                [5432.66444807 5469.14169173 2685.20167126 1355.64548115 5212.82589888
 2622.93551242 5432.80882609  549.75367559 5564.46204289 5567.77900102]
total_rewards_mean           3989.3218249109727
total_rewards_std            1875.1249701918289
total_rewards_max            5567.7790010178915
total_rewards_min            549.7536755945221
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               30.950405173934996
(Previous) Eval Time (s)     22.63210081588477
Sample Time (s)              19.101515369024128
Epoch Time (s)               72.68402135884389
Total Train Time (s)         26377.363594224676
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:35:20.316095 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #419 | Epoch Duration: 71.89935278892517
2020-01-11 01:35:20.316300 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043430917
Z variance train             0.04139094
KL Divergence                5.6135054
KL Loss                      0.5613505
QF Loss                      1758.8054
VF Loss                      557.9828
Policy Loss                  -2707.2605
Q Predictions Mean           2704.2139
Q Predictions Std            245.44081
Q Predictions Max            2869.2363
Q Predictions Min            515.84375
V Predictions Mean           2700.7588
V Predictions Std            246.17903
V Predictions Max            2865.6035
V Predictions Min            525.7895
Log Pis Mean                 -4.212721
Log Pis Std                  5.512172
Log Pis Max                  19.003714
Log Pis Min                  -13.23705
Policy mu Mean               0.28490874
Policy mu Std                0.71651024
Policy mu Max                2.962205
Policy mu Min                -2.7097764
Policy log std Mean          -0.29856515
Policy log std Std           0.13922241
Policy log std Max           -0.07429921
Policy log std Min           -1.406203
Z mean eval                  0.043592155
Z variance eval              0.039877586
total_rewards                [4527.22943576 2549.68059859 5513.87534695 5525.55218999 2705.96169399
 5489.27885633 5315.44509634 3443.54969774 5300.33758166 1387.85174005]
total_rewards_mean           4175.876223740445
total_rewards_std            1453.8884613937375
total_rewards_max            5525.5521899934
total_rewards_min            1387.8517400455307
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               31.74677978316322
(Previous) Eval Time (s)     21.847139528021216
Sample Time (s)              18.865784518420696
Epoch Time (s)               72.45970382960513
Total Train Time (s)         26451.327056468
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:36:34.286597 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #420 | Epoch Duration: 73.97012233734131
2020-01-11 01:36:34.286902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043540873
Z variance train             0.039891966
KL Divergence                5.697623
KL Loss                      0.5697623
QF Loss                      1250.5916
VF Loss                      270.58368
Policy Loss                  -2687.8103
Q Predictions Mean           2688.7922
Q Predictions Std            387.30533
Q Predictions Max            2862.1235
Q Predictions Min            35.5024
V Predictions Mean           2688.5635
V Predictions Std            385.91934
V Predictions Max            2869.3516
V Predictions Min            36.680878
Log Pis Mean                 -4.6692176
Log Pis Std                  4.4966125
Log Pis Max                  15.08288
Log Pis Min                  -13.433646
Policy mu Mean               0.31919932
Policy mu Std                0.68436104
Policy mu Max                2.5184917
Policy mu Min                -2.4847474
Policy log std Mean          -0.29189333
Policy log std Std           0.1282337
Policy log std Max           -0.06677063
Policy log std Min           -1.2591367
Z mean eval                  0.046723317
Z variance eval              0.04183986
total_rewards                [2171.52830997 4849.42849446 5142.09725285 5486.86825656 5547.59686962
 1589.97235428 5452.62851501 5463.62059372 1574.35574428 1457.21850608]
total_rewards_mean           3873.5314896827185
total_rewards_std            1795.1364835265524
total_rewards_max            5547.596869620837
total_rewards_min            1457.218506083995
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               30.391362885944545
(Previous) Eval Time (s)     23.357230693101883
Sample Time (s)              19.12789043271914
Epoch Time (s)               72.87648401176557
Total Train Time (s)         26522.061935325153
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:37:45.023697 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #421 | Epoch Duration: 70.73658776283264
2020-01-11 01:37:45.023881 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04682776
Z variance train             0.041852057
KL Divergence                5.5826263
KL Loss                      0.55826265
QF Loss                      1481.232
VF Loss                      605.0339
Policy Loss                  -2658.297
Q Predictions Mean           2653.583
Q Predictions Std            433.84396
Q Predictions Max            2869.1267
Q Predictions Min            24.15924
V Predictions Mean           2646.106
V Predictions Std            433.64133
V Predictions Max            2871.814
V Predictions Min            31.871462
Log Pis Mean                 -4.6871576
Log Pis Std                  5.280843
Log Pis Max                  21.417965
Log Pis Min                  -13.631061
Policy mu Mean               0.32920286
Policy mu Std                0.67943776
Policy mu Max                3.17503
Policy mu Min                -2.5303824
Policy log std Mean          -0.29029083
Policy log std Std           0.13234203
Policy log std Max           -0.037860125
Policy log std Min           -1.0036993
Z mean eval                  0.04372992
Z variance eval              0.041089624
total_rewards                [5504.13871677 2037.59949137 3989.1409012  5576.12208957 5403.53019362
 1820.2636686  3993.48081464 5228.95956909 4847.56688518 1219.33754464]
total_rewards_mean           3962.013987469733
total_rewards_std            1589.505688632431
total_rewards_max            5576.122089571349
total_rewards_min            1219.3375446410632
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               32.31311529641971
(Previous) Eval Time (s)     21.217063821852207
Sample Time (s)              19.234849297441542
Epoch Time (s)               72.76502841571346
Total Train Time (s)         26595.24172357237
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:38:58.212306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #422 | Epoch Duration: 73.18824934959412
2020-01-11 01:38:58.212637 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043809306
Z variance train             0.04109578
KL Divergence                5.646761
KL Loss                      0.5646761
QF Loss                      2471.8916
VF Loss                      911.655
Policy Loss                  -2655.614
Q Predictions Mean           2655.9404
Q Predictions Std            401.57925
Q Predictions Max            2854.9753
Q Predictions Min            24.561996
V Predictions Mean           2661.4045
V Predictions Std            407.77753
V Predictions Max            2870.6614
V Predictions Min            33.651333
Log Pis Mean                 -4.1023135
Log Pis Std                  5.898494
Log Pis Max                  27.13126
Log Pis Min                  -17.179611
Policy mu Mean               0.3090695
Policy mu Std                0.70621985
Policy mu Max                2.7770646
Policy mu Min                -3.5586193
Policy log std Mean          -0.30422187
Policy log std Std           0.14259496
Policy log std Max           -0.065792456
Policy log std Min           -1.1821916
Z mean eval                  0.044340197
Z variance eval              0.040419523
total_rewards                [5609.37309662 5555.99617899 1738.20966321 4192.94485849 2374.52038071
 5411.88158718 5533.85217535 3073.24473242 5574.58332024 4447.26585908]
total_rewards_mean           4351.187185228306
total_rewards_std            1394.8955351683742
total_rewards_max            5609.373096623866
total_rewards_min            1738.2096632078697
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               33.01512590330094
(Previous) Eval Time (s)     21.639954532962292
Sample Time (s)              19.60822468297556
Epoch Time (s)               74.2633051192388
Total Train Time (s)         26670.74270252837
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:40:13.718304 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #423 | Epoch Duration: 75.5053915977478
2020-01-11 01:40:13.718605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04417568
Z variance train             0.04042158
KL Divergence                5.6904645
KL Loss                      0.56904644
QF Loss                      1408.1282
VF Loss                      495.43622
Policy Loss                  -2639.638
Q Predictions Mean           2639.2686
Q Predictions Std            462.1458
Q Predictions Max            2868.8066
Q Predictions Min            16.838217
V Predictions Mean           2645.211
V Predictions Std            459.75854
V Predictions Max            2869.3743
V Predictions Min            20.599285
Log Pis Mean                 -4.4039454
Log Pis Std                  5.042459
Log Pis Max                  23.864937
Log Pis Min                  -14.70997
Policy mu Mean               0.3526725
Policy mu Std                0.69065624
Policy mu Max                3.4532192
Policy mu Min                -2.8615808
Policy log std Mean          -0.3064436
Policy log std Std           0.13318017
Policy log std Max           -0.035809547
Policy log std Min           -1.0841382
Z mean eval                  0.045857932
Z variance eval              0.041038856
total_rewards                [5424.61233571 3323.39453679 5404.5297809  5509.01378874 4350.97286859
 2390.07657846 5493.40200848 2609.32051527 5416.34062825 1713.14966547]
total_rewards_mean           4163.481270665334
total_rewards_std            1434.7424896120815
total_rewards_max            5509.013788737969
total_rewards_min            1713.149665472454
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               30.94472621427849
(Previous) Eval Time (s)     22.881729411892593
Sample Time (s)              20.308580214623362
Epoch Time (s)               74.13503584079444
Total Train Time (s)         26744.5225258898
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:41:27.503907 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #424 | Epoch Duration: 73.78501415252686
2020-01-11 01:41:27.504193 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046041176
Z variance train             0.04103599
KL Divergence                5.643731
KL Loss                      0.56437314
QF Loss                      1454.9105
VF Loss                      366.46912
Policy Loss                  -2688.4534
Q Predictions Mean           2686.1353
Q Predictions Std            418.3432
Q Predictions Max            2874.456
Q Predictions Min            22.909826
V Predictions Mean           2687.9648
V Predictions Std            422.65372
V Predictions Max            2879.2695
V Predictions Min            30.205835
Log Pis Mean                 -5.3970485
Log Pis Std                  4.4148784
Log Pis Max                  16.648287
Log Pis Min                  -15.41066
Policy mu Mean               0.2775446
Policy mu Std                0.6738796
Policy mu Max                2.5412974
Policy mu Min                -2.8529747
Policy log std Mean          -0.29346967
Policy log std Std           0.1342673
Policy log std Max           0.00245744
Policy log std Min           -1.2291335
Z mean eval                  0.046485383
Z variance eval              0.039279543
total_rewards                [5418.4459166  3758.88704206 5362.29722646 5418.62459849 1995.57365599
  864.21208917 5249.34208383 5226.19459083 5405.78491565 3303.72166399]
total_rewards_mean           4200.308378307542
total_rewards_std            1578.4034229189456
total_rewards_max            5418.624598492829
total_rewards_min            864.2120891708834
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               31.853353136219084
(Previous) Eval Time (s)     22.531362389679998
Sample Time (s)              19.163989991880953
Epoch Time (s)               73.54870551778004
Total Train Time (s)         26818.215646188706
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:42:41.203738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #425 | Epoch Duration: 73.6992928981781
2020-01-11 01:42:41.204112 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04649927
Z variance train             0.039285142
KL Divergence                5.7313604
KL Loss                      0.57313603
QF Loss                      1359.0673
VF Loss                      788.6483
Policy Loss                  -2699.2642
Q Predictions Mean           2695.029
Q Predictions Std            308.98636
Q Predictions Max            2875.9822
Q Predictions Min            310.0366
V Predictions Mean           2718.453
V Predictions Std            315.30084
V Predictions Max            2902.7996
V Predictions Min            333.59552
Log Pis Mean                 -4.81444
Log Pis Std                  4.737952
Log Pis Max                  19.676025
Log Pis Min                  -14.172894
Policy mu Mean               0.27403182
Policy mu Std                0.70631737
Policy mu Max                2.5816326
Policy mu Min                -3.0730171
Policy log std Mean          -0.29782936
Policy log std Std           0.1336998
Policy log std Max           -0.0730382
Policy log std Min           -1.1530995
Z mean eval                  0.045337737
Z variance eval              0.040182587
total_rewards                [1019.81759502 1835.33387547 5461.57543232 5537.14120918 4234.80982593
 5451.05232047 1963.61578635  899.51602228 5366.67819936 3031.83514431]
total_rewards_mean           3480.1375410695437
total_rewards_std            1846.3316391737199
total_rewards_max            5537.141209180795
total_rewards_min            899.51602227748
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               32.98511708108708
(Previous) Eval Time (s)     22.68159282533452
Sample Time (s)              19.623905597254634
Epoch Time (s)               75.29061550367624
Total Train Time (s)         26889.17472037999
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:43:52.167734 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #426 | Epoch Duration: 70.96336722373962
2020-01-11 01:43:52.168051 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04577478
Z variance train             0.04017601
KL Divergence                5.681967
KL Loss                      0.5681967
QF Loss                      1756.1028
VF Loss                      759.3158
Policy Loss                  -2679.2693
Q Predictions Mean           2675.9478
Q Predictions Std            431.58984
Q Predictions Max            2891.5574
Q Predictions Min            27.449764
V Predictions Mean           2661.6309
V Predictions Std            424.85764
V Predictions Max            2883.2795
V Predictions Min            37.848827
Log Pis Mean                 -4.5516515
Log Pis Std                  5.600805
Log Pis Max                  31.610743
Log Pis Min                  -14.561569
Policy mu Mean               0.29781732
Policy mu Std                0.7009593
Policy mu Max                2.9026644
Policy mu Min                -3.6644204
Policy log std Mean          -0.29189622
Policy log std Std           0.13363437
Policy log std Max           0.016407795
Policy log std Min           -1.3800135
Z mean eval                  0.045764506
Z variance eval              0.037477795
total_rewards                [5046.17161116 5384.7698863  5277.51695078 1630.67407613 4092.47959155
 5419.31238297 5470.49903449 5512.5394309  5477.36983507 5270.27715684]
total_rewards_mean           4858.160995618206
total_rewards_std            1147.2917400379179
total_rewards_max            5512.539430899369
total_rewards_min            1630.6740761267017
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               33.3280812590383
(Previous) Eval Time (s)     18.354033433366567
Sample Time (s)              18.8635056912899
Epoch Time (s)               70.54562038369477
Total Train Time (s)         26968.60812406754
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:45:11.605788 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #427 | Epoch Duration: 79.43753361701965
2020-01-11 01:45:11.605997 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045560528
Z variance train             0.03747429
KL Divergence                5.8517733
KL Loss                      0.58517736
QF Loss                      1155.9701
VF Loss                      364.16473
Policy Loss                  -2659.181
Q Predictions Mean           2659.602
Q Predictions Std            432.7617
Q Predictions Max            2866.3386
Q Predictions Min            22.458223
V Predictions Mean           2662.9126
V Predictions Std            427.38205
V Predictions Max            2864.7327
V Predictions Min            30.473547
Log Pis Mean                 -4.0377064
Log Pis Std                  5.9554935
Log Pis Max                  38.91307
Log Pis Min                  -17.072983
Policy mu Mean               0.32323456
Policy mu Std                0.7299836
Policy mu Max                2.8238642
Policy mu Min                -3.1476083
Policy log std Mean          -0.3074595
Policy log std Std           0.13936253
Policy log std Max           -0.07890993
Policy log std Min           -1.0916457
Z mean eval                  0.04259661
Z variance eval              0.03706137
total_rewards                [5430.58168256 2733.22754768 4574.20195707 5429.07600402 4235.38735238
 5647.53806124 5306.99561075 5646.63292442 2298.70268428 5133.01688008]
total_rewards_mean           4643.536070447503
total_rewards_std            1151.0613345844786
total_rewards_max            5647.538061238707
total_rewards_min            2298.7026842797177
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               30.20048509677872
(Previous) Eval Time (s)     27.24560977704823
Sample Time (s)              19.542859853245318
Epoch Time (s)               76.98895472707227
Total Train Time (s)         27043.36866502557
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:46:26.368803 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #428 | Epoch Duration: 74.76266551017761
2020-01-11 01:46:26.368957 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042976327
Z variance train             0.03706784
KL Divergence                5.8831997
KL Loss                      0.58831996
QF Loss                      1230.6348
VF Loss                      366.2374
Policy Loss                  -2677.2021
Q Predictions Mean           2673.0117
Q Predictions Std            419.45813
Q Predictions Max            2865.7576
Q Predictions Min            15.496827
V Predictions Mean           2670.6313
V Predictions Std            423.24686
V Predictions Max            2879.6392
V Predictions Min            24.609926
Log Pis Mean                 -3.9495916
Log Pis Std                  5.1689825
Log Pis Max                  28.528822
Log Pis Min                  -13.228877
Policy mu Mean               0.34620574
Policy mu Std                0.7192203
Policy mu Max                2.624022
Policy mu Min                -3.127211
Policy log std Mean          -0.30763602
Policy log std Std           0.13438426
Policy log std Max           -0.03511651
Policy log std Min           -0.92029923
Z mean eval                  0.043967884
Z variance eval              0.038746566
total_rewards                [5264.53542779 5229.56373089 2968.16992388 2064.86265745 3767.61135686
 2464.46926746 2661.23983784  951.88375908 4296.57561443  865.36867294]
total_rewards_mean           3053.4280248616187
total_rewards_std            1495.63841784881
total_rewards_max            5264.5354277862825
total_rewards_min            865.3686729380877
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               29.110376083292067
(Previous) Eval Time (s)     25.01902747992426
Sample Time (s)              20.073942011222243
Epoch Time (s)               74.20334557443857
Total Train Time (s)         27108.692749896087
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:47:31.695963 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #429 | Epoch Duration: 65.32688689231873
2020-01-11 01:47:31.696135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04385333
Z variance train             0.038749386
KL Divergence                5.7810264
KL Loss                      0.57810265
QF Loss                      1358.7168
VF Loss                      313.4115
Policy Loss                  -2680.289
Q Predictions Mean           2676.3108
Q Predictions Std            406.33792
Q Predictions Max            2856.2913
Q Predictions Min            19.90255
V Predictions Mean           2686.17
V Predictions Std            405.28687
V Predictions Max            2867.116
V Predictions Min            26.794756
Log Pis Mean                 -4.904213
Log Pis Std                  4.7972627
Log Pis Max                  20.75561
Log Pis Min                  -14.402569
Policy mu Mean               0.2924131
Policy mu Std                0.6765755
Policy mu Max                2.563503
Policy mu Min                -2.690346
Policy log std Mean          -0.28643227
Policy log std Std           0.12695082
Policy log std Max           -0.059175216
Policy log std Min           -1.0856805
Z mean eval                  0.045027632
Z variance eval              0.037988454
total_rewards                [3273.80031447 1741.15468594 2246.0003972  5656.57750746 5494.19695537
 5515.53781529 3891.73175268 5427.79083762 5565.18267937 1078.97107126]
total_rewards_mean           3989.0944016655035
total_rewards_std            1703.270893982564
total_rewards_max            5656.577507458232
total_rewards_min            1078.9710712607505
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               32.47724931174889
(Previous) Eval Time (s)     16.142258980777115
Sample Time (s)              19.362964790314436
Epoch Time (s)               67.98247308284044
Total Train Time (s)         27181.952495981008
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:48:44.958571 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #430 | Epoch Duration: 73.26230335235596
2020-01-11 01:48:44.958770 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04477916
Z variance train             0.038008187
KL Divergence                5.8250513
KL Loss                      0.58250517
QF Loss                      1684.2582
VF Loss                      601.4925
Policy Loss                  -2685.3958
Q Predictions Mean           2689.8484
Q Predictions Std            407.2555
Q Predictions Max            2864.4775
Q Predictions Min            16.098598
V Predictions Mean           2703.7366
V Predictions Std            407.22968
V Predictions Max            2896.8481
V Predictions Min            27.222858
Log Pis Mean                 -4.6918516
Log Pis Std                  4.857489
Log Pis Max                  16.356607
Log Pis Min                  -14.671423
Policy mu Mean               0.3479942
Policy mu Std                0.6618257
Policy mu Max                2.775735
Policy mu Min                -2.8038392
Policy log std Mean          -0.28919202
Policy log std Std           0.12949288
Policy log std Max           0.02774027
Policy log std Min           -1.04115
Z mean eval                  0.043659173
Z variance eval              0.037959762
total_rewards                [1656.67563208 4277.05827578 1568.64498049 4095.3671754  1610.79222725
 2630.81416936 3972.2755813  5588.4635351  3568.58607207  834.51526535]
total_rewards_mean           2980.3192914177275
total_rewards_std            1463.0244456057126
total_rewards_max            5588.463535095467
total_rewards_min            834.5152653529117
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               30.86424561869353
(Previous) Eval Time (s)     21.421785053331405
Sample Time (s)              19.264269928913563
Epoch Time (s)               71.5503006009385
Total Train Time (s)         27247.4558358714
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:49:50.467299 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #431 | Epoch Duration: 65.50837779045105
2020-01-11 01:49:50.467523 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043394197
Z variance train             0.037959635
KL Divergence                5.823798
KL Loss                      0.5823798
QF Loss                      1229.4198
VF Loss                      673.05457
Policy Loss                  -2680.053
Q Predictions Mean           2674.983
Q Predictions Std            370.28503
Q Predictions Max            2874.3367
Q Predictions Min            21.297749
V Predictions Mean           2687.3591
V Predictions Std            374.2401
V Predictions Max            2887.2087
V Predictions Min            28.193502
Log Pis Mean                 -4.1021132
Log Pis Std                  5.701672
Log Pis Max                  17.435051
Log Pis Min                  -14.124586
Policy mu Mean               0.32003716
Policy mu Std                0.71114975
Policy mu Max                2.8762941
Policy mu Min                -2.7081003
Policy log std Mean          -0.30509573
Policy log std Std           0.13457552
Policy log std Max           -0.07755613
Policy log std Min           -1.2097957
Z mean eval                  0.044548634
Z variance eval              0.03903628
total_rewards                [3638.3737544  5616.83960657 3201.06119903 5341.86293687 1574.17413454
 5488.4562797  3058.47309611 5550.15893681 5477.7486778  5581.79777723]
total_rewards_mean           4452.894639905656
total_rewards_std            1385.934049092746
total_rewards_max            5616.839606568414
total_rewards_min            1574.1741345442176
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               33.911926181055605
(Previous) Eval Time (s)     15.379545016214252
Sample Time (s)              18.93016953393817
Epoch Time (s)               68.22164073120803
Total Train Time (s)         27324.76808274025
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:51:07.786541 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #432 | Epoch Duration: 77.31881284713745
2020-01-11 01:51:07.786836 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04459287
Z variance train             0.03903547
KL Divergence                5.7440186
KL Loss                      0.57440186
QF Loss                      1155.9353
VF Loss                      366.37427
Policy Loss                  -2679.5261
Q Predictions Mean           2679.6465
Q Predictions Std            421.67056
Q Predictions Max            2855.6755
Q Predictions Min            19.95137
V Predictions Mean           2686.3833
V Predictions Std            420.7849
V Predictions Max            2875.0696
V Predictions Min            31.512115
Log Pis Mean                 -4.3156447
Log Pis Std                  5.142363
Log Pis Max                  18.350105
Log Pis Min                  -15.178669
Policy mu Mean               0.3722285
Policy mu Std                0.6720854
Policy mu Max                3.197177
Policy mu Min                -2.6809535
Policy log std Mean          -0.2983652
Policy log std Std           0.13261414
Policy log std Max           -0.014107324
Policy log std Min           -0.8818927
Z mean eval                  0.046010263
Z variance eval              0.038378056
total_rewards                [3093.58522917  876.30553924 5504.52624828 5433.65325546  944.4394663
 5332.63753508 5621.65450377 2469.16162443 2809.08323457 5360.56876759]
total_rewards_mean           3744.5615403909733
total_rewards_std            1833.0455584462009
total_rewards_max            5621.654503772775
total_rewards_min            876.3055392403114
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               31.66048562992364
(Previous) Eval Time (s)     24.47640210390091
Sample Time (s)              19.578589724376798
Epoch Time (s)               75.71547745820135
Total Train Time (s)         27396.143656700384
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:52:19.165286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #433 | Epoch Duration: 71.37825584411621
2020-01-11 01:52:19.165458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045920026
Z variance train             0.038390655
KL Divergence                5.776152
KL Loss                      0.5776152
QF Loss                      1897.3164
VF Loss                      557.6889
Policy Loss                  -2678.5947
Q Predictions Mean           2673.9744
Q Predictions Std            402.6046
Q Predictions Max            2867.9045
Q Predictions Min            23.873222
V Predictions Mean           2679.6396
V Predictions Std            404.1093
V Predictions Max            2871.7454
V Predictions Min            33.68164
Log Pis Mean                 -3.909542
Log Pis Std                  5.1724358
Log Pis Max                  25.937462
Log Pis Min                  -13.222872
Policy mu Mean               0.27310956
Policy mu Std                0.73168707
Policy mu Max                3.2563202
Policy mu Min                -2.9748726
Policy log std Mean          -0.3016973
Policy log std Std           0.14043829
Policy log std Max           0.12859294
Policy log std Min           -0.9776196
Z mean eval                  0.041313548
Z variance eval              0.037533253
total_rewards                [5371.87147372 1509.32980361 5325.28027467 1101.80508859 5503.10307288
 5346.8432059  1315.49911935 5438.62016583 1051.05513932 5482.66252759]
total_rewards_mean           3744.606987146433
total_rewards_std            2045.3155599860158
total_rewards_max            5503.103072884149
total_rewards_min            1051.0551393158814
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               31.737476135138422
(Previous) Eval Time (s)     20.138895095326006
Sample Time (s)              18.911423903889954
Epoch Time (s)               70.78779513435438
Total Train Time (s)         27467.240428884048
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:53:30.267023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #434 | Epoch Duration: 71.10142302513123
2020-01-11 01:53:30.267275 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04145922
Z variance train             0.03753636
KL Divergence                5.8326354
KL Loss                      0.5832636
QF Loss                      1592.5388
VF Loss                      592.23956
Policy Loss                  -2634.9988
Q Predictions Mean           2631.857
Q Predictions Std            497.2904
Q Predictions Max            2862.3442
Q Predictions Min            20.457241
V Predictions Mean           2626.9375
V Predictions Std            496.73306
V Predictions Max            2867.091
V Predictions Min            31.971245
Log Pis Mean                 -4.0761814
Log Pis Std                  5.2719097
Log Pis Max                  20.745451
Log Pis Min                  -13.115685
Policy mu Mean               0.30942968
Policy mu Std                0.6993496
Policy mu Max                2.8474436
Policy mu Min                -3.3390534
Policy log std Mean          -0.29738927
Policy log std Std           0.13692042
Policy log std Max           -0.039104223
Policy log std Min           -1.1363055
Z mean eval                  0.039344374
Z variance eval              0.037374545
total_rewards                [5454.33525413 4093.64975109 5476.16548856 5443.58557445 5532.55024516
 5326.48253722 5515.16063251 5407.11092343 5498.99772792 5574.57512431]
total_rewards_mean           5332.261325880288
total_rewards_std            418.0768879513306
total_rewards_max            5574.575124312998
total_rewards_min            4093.6497510944864
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               34.72763691097498
(Previous) Eval Time (s)     20.45219877921045
Sample Time (s)              18.96974050393328
Epoch Time (s)               74.14957619411871
Total Train Time (s)         27550.396351195406
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:54:53.428168 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #435 | Epoch Duration: 83.16069173812866
2020-01-11 01:54:53.428406 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03922965
Z variance train             0.037377514
KL Divergence                5.8634424
KL Loss                      0.58634424
QF Loss                      1704.2687
VF Loss                      350.85086
Policy Loss                  -2659.0146
Q Predictions Mean           2659.06
Q Predictions Std            446.68658
Q Predictions Max            2881.4097
Q Predictions Min            20.261303
V Predictions Mean           2661.0933
V Predictions Std            442.1282
V Predictions Max            2867.1235
V Predictions Min            30.629456
Log Pis Mean                 -4.8004837
Log Pis Std                  5.6037006
Log Pis Max                  28.611431
Log Pis Min                  -16.389622
Policy mu Mean               0.27329153
Policy mu Std                0.7046481
Policy mu Max                2.8686292
Policy mu Min                -2.897065
Policy log std Mean          -0.30666474
Policy log std Std           0.14065772
Policy log std Max           -0.08743893
Policy log std Min           -1.1494143
Z mean eval                  0.04032287
Z variance eval              0.037714664
total_rewards                [2647.97854917 5652.86927339 2153.56481833 5598.70146585 5534.81179994
 3424.85489543 5345.14391259 5351.99653567  698.34167861 5621.00758024]
total_rewards_mean           4202.9270509212265
total_rewards_std            1731.0596001422073
total_rewards_max            5652.869273387007
total_rewards_min            698.3416786141432
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               32.54325381433591
(Previous) Eval Time (s)     29.462990314234048
Sample Time (s)              19.55294719617814
Epoch Time (s)               81.5591913247481
Total Train Time (s)         27625.143799739424
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:56:08.178241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #436 | Epoch Duration: 74.74967169761658
2020-01-11 01:56:08.178409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040374275
Z variance train             0.03770848
KL Divergence                5.838052
KL Loss                      0.5838052
QF Loss                      2271.6523
VF Loss                      887.8236
Policy Loss                  -2676.7598
Q Predictions Mean           2671.361
Q Predictions Std            370.86993
Q Predictions Max            2871.165
Q Predictions Min            22.76883
V Predictions Mean           2676.469
V Predictions Std            368.74295
V Predictions Max            2879.7805
V Predictions Min            31.040588
Log Pis Mean                 -4.0594053
Log Pis Std                  5.6851625
Log Pis Max                  21.02102
Log Pis Min                  -14.220173
Policy mu Mean               0.31139112
Policy mu Std                0.71434337
Policy mu Max                4.004871
Policy mu Min                -3.0108213
Policy log std Mean          -0.30914244
Policy log std Std           0.14021383
Policy log std Max           -0.0432524
Policy log std Min           -0.9519061
Z mean eval                  0.04040339
Z variance eval              0.03919982
total_rewards                [5535.79900692 4735.77033165 2867.65580696 5586.98568131 1552.57098417
 3651.34411924 1338.21902204 4837.74839823 5252.42733686 3989.01455415]
total_rewards_mean           3934.7535241534993
total_rewards_std            1487.4561320204573
total_rewards_max            5586.985681312022
total_rewards_min            1338.2190220448765
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               31.039542351849377
(Previous) Eval Time (s)     22.653153356164694
Sample Time (s)              19.22925917711109
Epoch Time (s)               72.92195488512516
Total Train Time (s)         27697.351120823994
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:57:20.389370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #437 | Epoch Duration: 72.21084237098694
2020-01-11 01:57:20.389566 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040686384
Z variance train             0.03919476
KL Divergence                5.7593865
KL Loss                      0.57593864
QF Loss                      1540.9143
VF Loss                      405.56702
Policy Loss                  -2741.5679
Q Predictions Mean           2747.1885
Q Predictions Std            278.7419
Q Predictions Max            2913.3809
Q Predictions Min            436.2447
V Predictions Mean           2747.3945
V Predictions Std            279.88968
V Predictions Max            2887.994
V Predictions Min            407.15457
Log Pis Mean                 -5.4738135
Log Pis Std                  3.8222482
Log Pis Max                  14.14314
Log Pis Min                  -15.130704
Policy mu Mean               0.35887688
Policy mu Std                0.63098365
Policy mu Max                2.4843972
Policy mu Min                -2.4286106
Policy log std Mean          -0.2912571
Policy log std Std           0.124896735
Policy log std Max           -0.06286578
Policy log std Min           -0.92073077
Z mean eval                  0.04026388
Z variance eval              0.037558008
total_rewards                [4700.02952146 5508.20580958 2643.17773878 4228.96244668 1676.84815859
 4970.38368599 5448.30835688 5335.82983191 4053.55061625 5547.15579945]
total_rewards_mean           4411.245196556349
total_rewards_std            1248.3655945896194
total_rewards_max            5547.155799446907
total_rewards_min            1676.848158588776
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               32.5209794100374
(Previous) Eval Time (s)     21.941640825010836
Sample Time (s)              20.288174519315362
Epoch Time (s)               74.7507947543636
Total Train Time (s)         27773.72728382889
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:58:36.768505 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #438 | Epoch Duration: 76.37878847122192
2020-01-11 01:58:36.768706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04043279
Z variance train             0.03756277
KL Divergence                5.88027
KL Loss                      0.588027
QF Loss                      718.41284
VF Loss                      270.77325
Policy Loss                  -2711.4773
Q Predictions Mean           2710.945
Q Predictions Std            302.74454
Q Predictions Max            2879.298
Q Predictions Min            433.31577
V Predictions Mean           2710.8213
V Predictions Std            305.84158
V Predictions Max            2883.011
V Predictions Min            413.74512
Log Pis Mean                 -4.2639337
Log Pis Std                  4.693018
Log Pis Max                  13.195558
Log Pis Min                  -18.089134
Policy mu Mean               0.33849978
Policy mu Std                0.70655835
Policy mu Max                2.6739213
Policy mu Min                -2.4020677
Policy log std Mean          -0.3154147
Policy log std Std           0.13706343
Policy log std Max           -0.040326744
Policy log std Min           -1.1992533
Z mean eval                  0.040455204
Z variance eval              0.037773363
total_rewards                [5452.08489459 3902.89375996 5459.83847091 5399.66659624 2692.61693442
 5221.71022119 5110.84154252 5364.66301156 2487.19379219 5275.07720706]
total_rewards_mean           4636.6586430644375
total_rewards_std            1112.0853270156374
total_rewards_max            5459.838470909059
total_rewards_min            2487.193792191318
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               29.275898728054017
(Previous) Eval Time (s)     23.569327536970377
Sample Time (s)              18.846061777789146
Epoch Time (s)               71.69128804281354
Total Train Time (s)         27847.315821312368
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:59:50.363440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #439 | Epoch Duration: 73.59456205368042
2020-01-11 01:59:50.363726 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040556468
Z variance train             0.037768424
KL Divergence                5.8676195
KL Loss                      0.58676195
QF Loss                      1213.9783
VF Loss                      437.33173
Policy Loss                  -2660.4177
Q Predictions Mean           2659.1016
Q Predictions Std            466.77188
Q Predictions Max            2883.3914
Q Predictions Min            21.176931
V Predictions Mean           2654.2825
V Predictions Std            465.01263
V Predictions Max            2873.701
V Predictions Min            31.278898
Log Pis Mean                 -3.8998182
Log Pis Std                  5.7384686
Log Pis Max                  23.74785
Log Pis Min                  -14.724319
Policy mu Mean               0.34378308
Policy mu Std                0.7117651
Policy mu Max                2.9958105
Policy mu Min                -3.0613031
Policy log std Mean          -0.30557352
Policy log std Std           0.13767037
Policy log std Max           -0.07229484
Policy log std Min           -0.9736343
Z mean eval                  0.041212253
Z variance eval              0.03801363
total_rewards                [5382.22746951  676.8071744  4468.06633122 5450.00900335 3296.99160138
 5416.65909416 5483.92181899 2795.1412802  5455.32604224 5539.83950188]
total_rewards_mean           4396.49893173326
total_rewards_std            1560.371538546804
total_rewards_max            5539.83950187888
total_rewards_min            676.807174400025
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               32.67906639305875
(Previous) Eval Time (s)     25.47228936292231
Sample Time (s)              19.41588995512575
Epoch Time (s)               77.5672457111068
Total Train Time (s)         27923.705667139962
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:01:06.756385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #440 | Epoch Duration: 76.39245653152466
2020-01-11 02:01:06.756573 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041116357
Z variance train             0.03801609
KL Divergence                5.869359
KL Loss                      0.58693594
QF Loss                      1054.1354
VF Loss                      902.0743
Policy Loss                  -2703.84
Q Predictions Mean           2698.0234
Q Predictions Std            398.92917
Q Predictions Max            2868.008
Q Predictions Min            24.789547
V Predictions Mean           2702.3198
V Predictions Std            392.3654
V Predictions Max            2877.986
V Predictions Min            34.397903
Log Pis Mean                 -5.0446615
Log Pis Std                  5.084833
Log Pis Max                  23.798498
Log Pis Min                  -13.248677
Policy mu Mean               0.32703218
Policy mu Std                0.6548541
Policy mu Max                2.725773
Policy mu Min                -2.9639003
Policy log std Mean          -0.29386437
Policy log std Std           0.12366625
Policy log std Max           0.018322356
Policy log std Min           -0.950799
Z mean eval                  0.040819444
Z variance eval              0.036728837
total_rewards                [5462.9186558  5313.95153465 1351.87487048 5498.87088585 5422.25629468
 5503.33544066 5134.82709249 5639.83712971 5434.09688945 5542.82504614]
total_rewards_mean           5030.479383992072
total_rewards_std            1233.0277540539957
total_rewards_max            5639.837129709851
total_rewards_min            1351.8748704826241
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               30.52558677876368
(Previous) Eval Time (s)     24.297194506041706
Sample Time (s)              20.88728430774063
Epoch Time (s)               75.71006559254602
Total Train Time (s)         28002.244176926557
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:02:25.299430 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #441 | Epoch Duration: 78.54272794723511
2020-01-11 02:02:25.299620 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040936034
Z variance train             0.03674233
KL Divergence                5.94108
KL Loss                      0.59410805
QF Loss                      3690.9136
VF Loss                      724.69507
Policy Loss                  -2636.2292
Q Predictions Mean           2633.5024
Q Predictions Std            538.40753
Q Predictions Max            2888.0493
Q Predictions Min            21.80093
V Predictions Mean           2637.9624
V Predictions Std            543.9059
V Predictions Max            2898.3127
V Predictions Min            30.099163
Log Pis Mean                 -4.024988
Log Pis Std                  5.3969755
Log Pis Max                  17.941956
Log Pis Min                  -14.2012415
Policy mu Mean               0.35905182
Policy mu Std                0.699
Policy mu Max                2.614656
Policy mu Min                -3.168426
Policy log std Mean          -0.29467222
Policy log std Std           0.13821152
Policy log std Max           0.033678025
Policy log std Min           -1.2154826
Z mean eval                  0.041261144
Z variance eval              0.036923233
total_rewards                [1867.20714214 1971.91528305 5670.62986716 5036.61685815 2870.13898256
 5672.81268505 3687.57358856 5622.26183024 5691.20468168 5591.85230426]
total_rewards_mean           4368.221322285361
total_rewards_std            1528.7263056463808
total_rewards_max            5691.204681677811
total_rewards_min            1867.2071421420417
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               32.67703753570095
(Previous) Eval Time (s)     27.12950651999563
Sample Time (s)              19.01129008922726
Epoch Time (s)               78.81783414492384
Total Train Time (s)         28076.768991210498
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:03:39.827613 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #442 | Epoch Duration: 74.52784895896912
2020-01-11 02:03:39.827810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04092248
Z variance train             0.03692283
KL Divergence                5.9211645
KL Loss                      0.5921165
QF Loss                      1404.3801
VF Loss                      407.41943
Policy Loss                  -2677.4265
Q Predictions Mean           2676.5098
Q Predictions Std            425.31543
Q Predictions Max            2876.7188
Q Predictions Min            22.898026
V Predictions Mean           2688.4795
V Predictions Std            427.33344
V Predictions Max            2894.6484
V Predictions Min            30.916227
Log Pis Mean                 -4.580988
Log Pis Std                  5.1434374
Log Pis Max                  20.686726
Log Pis Min                  -14.460699
Policy mu Mean               0.34683913
Policy mu Std                0.6758745
Policy mu Max                2.8105524
Policy mu Min                -3.025548
Policy log std Mean          -0.291291
Policy log std Std           0.12513481
Policy log std Max           -0.021927252
Policy log std Min           -1.138897
Z mean eval                  0.039096616
Z variance eval              0.037220754
total_rewards                [5258.65338523 4621.65073336 5319.05374195 4103.97248161 3682.57745672
 2298.08391612  670.21242317 5434.39102615 3135.17070997 5541.72487628]
total_rewards_mean           4006.5490750569325
total_rewards_std            1516.1802587747102
total_rewards_max            5541.724876281853
total_rewards_min            670.2124231671896
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               32.12047502072528
(Previous) Eval Time (s)     22.83920949837193
Sample Time (s)              19.17014964716509
Epoch Time (s)               74.1298341662623
Total Train Time (s)         28150.617846725043
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:04:53.684948 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #443 | Epoch Duration: 73.85696220397949
2020-01-11 02:04:53.685272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039202
Z variance train             0.03722503
KL Divergence                5.8806686
KL Loss                      0.5880669
QF Loss                      2094.415
VF Loss                      367.003
Policy Loss                  -2709.0598
Q Predictions Mean           2705.626
Q Predictions Std            360.87454
Q Predictions Max            2869.9104
Q Predictions Min            19.064297
V Predictions Mean           2707.7983
V Predictions Std            366.1135
V Predictions Max            2883.422
V Predictions Min            24.10067
Log Pis Mean                 -4.891106
Log Pis Std                  5.0423894
Log Pis Max                  23.257872
Log Pis Min                  -14.666994
Policy mu Mean               0.3025261
Policy mu Std                0.68515426
Policy mu Max                3.0476646
Policy mu Min                -2.6088548
Policy log std Mean          -0.2915894
Policy log std Std           0.13174237
Policy log std Max           -0.056060024
Policy log std Min           -0.89025676
Z mean eval                  0.039016113
Z variance eval              0.038209222
total_rewards                [5527.63780072 5610.93813047 5587.65140987 5600.48418025 1734.98601268
 5509.64729302 5622.20662163 2924.76265832 4170.76882812 5418.55544277]
total_rewards_mean           4770.763837784681
total_rewards_std            1315.6249882717946
total_rewards_max            5622.206621629997
total_rewards_min            1734.9860126828362
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               29.602154219988734
(Previous) Eval Time (s)     22.566007198765874
Sample Time (s)              19.29946392867714
Epoch Time (s)               71.46762534743175
Total Train Time (s)         28225.36728847772
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:06:08.438077 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #444 | Epoch Duration: 74.75257301330566
2020-01-11 02:06:08.438286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039055966
Z variance train             0.038200293
KL Divergence                5.8161573
KL Loss                      0.58161575
QF Loss                      1375.4321
VF Loss                      658.4811
Policy Loss                  -2662.2263
Q Predictions Mean           2660.0664
Q Predictions Std            465.28342
Q Predictions Max            2887.541
Q Predictions Min            23.311113
V Predictions Mean           2655.2754
V Predictions Std            470.03702
V Predictions Max            2877.9292
V Predictions Min            29.542955
Log Pis Mean                 -4.939447
Log Pis Std                  5.237638
Log Pis Max                  20.165148
Log Pis Min                  -15.27021
Policy mu Mean               0.33231828
Policy mu Std                0.66784686
Policy mu Max                2.9112103
Policy mu Min                -2.6106515
Policy log std Mean          -0.29619038
Policy log std Std           0.12699336
Policy log std Max           -0.05009649
Policy log std Min           -1.2589538
Z mean eval                  0.03604649
Z variance eval              0.037324905
total_rewards                [5506.40432643 5457.9247687  5585.17409765 3997.47512396 5412.23066618
 5450.95745255 5524.34246319 5440.32823402 5371.94735829 5476.64622484]
total_rewards_mean           5322.343071580339
total_rewards_std            445.22263069337544
total_rewards_max            5585.1740976513665
total_rewards_min            3997.4751239597786
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               29.014061300083995
(Previous) Eval Time (s)     25.850680063012987
Sample Time (s)              18.8558100592345
Epoch Time (s)               73.72055142233148
Total Train Time (s)         28301.205820405856
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:07:24.284000 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #445 | Epoch Duration: 75.84552216529846
2020-01-11 02:07:24.284306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036217067
Z variance train             0.037324354
KL Divergence                5.8749733
KL Loss                      0.58749735
QF Loss                      1728.767
VF Loss                      423.043
Policy Loss                  -2620.4749
Q Predictions Mean           2612.6826
Q Predictions Std            582.16077
Q Predictions Max            2877.306
Q Predictions Min            19.81858
V Predictions Mean           2609.6987
V Predictions Std            581.3702
V Predictions Max            2882.757
V Predictions Min            32.966686
Log Pis Mean                 -4.809939
Log Pis Std                  5.667042
Log Pis Max                  38.03887
Log Pis Min                  -15.848378
Policy mu Mean               0.28255466
Policy mu Std                0.678363
Policy mu Max                3.4969447
Policy mu Min                -3.921978
Policy log std Mean          -0.29234818
Policy log std Std           0.13279326
Policy log std Max           -0.01519011
Policy log std Min           -1.1120824
Z mean eval                  0.034954306
Z variance eval              0.03541947
total_rewards                [4476.6821729  5613.55001529 1602.13329688 5585.00059295 5728.31208318
 5651.309637   5196.64485417 3111.98073768 1425.19053238 5594.21519028]
total_rewards_mean           4398.501911270297
total_rewards_std            1631.2667647375056
total_rewards_max            5728.3120831815
total_rewards_min            1425.190532376396
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               31.671634710859507
(Previous) Eval Time (s)     27.975348089821637
Sample Time (s)              19.20930166123435
Epoch Time (s)               78.8562844619155
Total Train Time (s)         28375.725530368276
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:08:38.805218 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #446 | Epoch Duration: 74.52070689201355
2020-01-11 02:08:38.805370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03489929
Z variance train             0.035423934
KL Divergence                6.007922
KL Loss                      0.6007922
QF Loss                      1208.0774
VF Loss                      331.8092
Policy Loss                  -2695.5955
Q Predictions Mean           2693.0557
Q Predictions Std            428.2015
Q Predictions Max            2890.9236
Q Predictions Min            19.964745
V Predictions Mean           2697.2441
V Predictions Std            433.63812
V Predictions Max            2890.767
V Predictions Min            23.21469
Log Pis Mean                 -5.0120187
Log Pis Std                  4.6741924
Log Pis Max                  22.184643
Log Pis Min                  -13.714876
Policy mu Mean               0.36333525
Policy mu Std                0.64619726
Policy mu Max                2.7819614
Policy mu Min                -2.4101481
Policy log std Mean          -0.29517427
Policy log std Std           0.1277841
Policy log std Max           -0.032690838
Policy log std Min           -1.0986135
Z mean eval                  0.036635734
Z variance eval              0.03648787
total_rewards                [5361.93603395 5453.48486342 5562.16491534 3695.53632998 5471.2645082
 5528.09487143 5604.68253266 5503.36657779 1740.18739307 5553.16835413]
total_rewards_mean           4947.388637997495
total_rewards_std            1199.124192298559
total_rewards_max            5604.682532662396
total_rewards_min            1740.1873930673953
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               31.002454278990626
(Previous) Eval Time (s)     23.63948119431734
Sample Time (s)              18.87198798172176
Epoch Time (s)               73.51392345502973
Total Train Time (s)         28452.09310613619
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:09:55.180319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #447 | Epoch Duration: 76.37478566169739
2020-01-11 02:09:55.180640 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036487296
Z variance train             0.036493678
KL Divergence                5.959995
KL Loss                      0.5959995
QF Loss                      1542.0701
VF Loss                      435.04495
Policy Loss                  -2651.8845
Q Predictions Mean           2650.544
Q Predictions Std            451.1947
Q Predictions Max            2886.0579
Q Predictions Min            25.936508
V Predictions Mean           2652.6465
V Predictions Std            449.1079
V Predictions Max            2886.6633
V Predictions Min            35.0873
Log Pis Mean                 -3.5338595
Log Pis Std                  5.453296
Log Pis Max                  25.431295
Log Pis Min                  -13.57851
Policy mu Mean               0.31961703
Policy mu Std                0.7179729
Policy mu Max                2.8359392
Policy mu Min                -2.8370411
Policy log std Mean          -0.31679922
Policy log std Std           0.13567293
Policy log std Max           0.03806986
Policy log std Min           -1.0955998
Z mean eval                  0.033965804
Z variance eval              0.036794815
total_rewards                [4533.41638045 1733.98305759  475.82820702 5559.7711667  5429.18877569
 5523.2502551  5605.67532463 5532.86128737 5512.77728594 5522.01384715]
total_rewards_mean           4542.876558762701
total_rewards_std            1766.9363116701036
total_rewards_max            5605.675324627483
total_rewards_min            475.8282070189708
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               30.51133255288005
(Previous) Eval Time (s)     26.500001289881766
Sample Time (s)              20.017498542554677
Epoch Time (s)               77.02883238531649
Total Train Time (s)         28527.117093477398
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:11:10.208792 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #448 | Epoch Duration: 75.02791142463684
2020-01-11 02:11:10.209028 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03408766
Z variance train             0.036797523
KL Divergence                5.9698243
KL Loss                      0.5969824
QF Loss                      1482.5947
VF Loss                      533.2509
Policy Loss                  -2683.274
Q Predictions Mean           2676.0625
Q Predictions Std            423.5562
Q Predictions Max            2882.2588
Q Predictions Min            22.68348
V Predictions Mean           2672.2078
V Predictions Std            423.01767
V Predictions Max            2873.8994
V Predictions Min            35.55115
Log Pis Mean                 -4.2155685
Log Pis Std                  5.5353527
Log Pis Max                  21.996067
Log Pis Min                  -13.582539
Policy mu Mean               0.3365356
Policy mu Std                0.6947056
Policy mu Max                3.1356926
Policy mu Min                -2.6331198
Policy log std Mean          -0.3093494
Policy log std Std           0.13308537
Policy log std Max           -0.05269251
Policy log std Min           -1.1825926
Z mean eval                  0.035985645
Z variance eval              0.036368586
total_rewards                [5589.9737818  5486.73931288 5428.65589774 5461.93060554 5519.10825722
 5470.83627901 5431.17842805 5484.34517887 5486.10812149 5444.05736094]
total_rewards_mean           5480.293322353649
total_rewards_std            45.21786038398335
total_rewards_max            5589.973781797656
total_rewards_min            5428.655897741126
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               32.69355080509558
(Previous) Eval Time (s)     24.498765117954463
Sample Time (s)              19.338022225070745
Epoch Time (s)               76.53033814812079
Total Train Time (s)         28609.814326154068
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:12:32.911217 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #449 | Epoch Duration: 82.70200967788696
2020-01-11 02:12:32.911458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035907004
Z variance train             0.036366917
KL Divergence                6.0030813
KL Loss                      0.6003081
QF Loss                      1228.506
VF Loss                      619.72925
Policy Loss                  -2704.7678
Q Predictions Mean           2699.5496
Q Predictions Std            368.24628
Q Predictions Max            2909.6335
Q Predictions Min            26.38171
V Predictions Mean           2691.742
V Predictions Std            363.85254
V Predictions Max            2903.7922
V Predictions Min            36.146
Log Pis Mean                 -3.6576793
Log Pis Std                  5.9729085
Log Pis Max                  38.949535
Log Pis Min                  -14.832974
Policy mu Mean               0.3169017
Policy mu Std                0.7403628
Policy mu Max                3.9366148
Policy mu Min                -3.8706605
Policy log std Mean          -0.32174903
Policy log std Std           0.14278027
Policy log std Max           0.6140765
Policy log std Min           -1.1738224
Z mean eval                  0.03693352
Z variance eval              0.03577597
total_rewards                [1344.79015733 2403.71982455 1320.72640843 2217.33070207 4194.62035361
 5404.27637535 5605.43248161 5595.73878961 5433.33198056 5536.64602322]
total_rewards_mean           3905.661309634449
total_rewards_std            1772.4292694382113
total_rewards_max            5605.432481611671
total_rewards_min            1320.7264084342369
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               29.952579519245774
(Previous) Eval Time (s)     30.67010228894651
Sample Time (s)              20.597624704707414
Epoch Time (s)               81.2203065128997
Total Train Time (s)         28682.07268084027
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:13:45.173327 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #450 | Epoch Duration: 72.26169228553772
2020-01-11 02:13:45.173531 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036807902
Z variance train             0.0357802
KL Divergence                6.0392013
KL Loss                      0.60392016
QF Loss                      2212.9172
VF Loss                      526.31177
Policy Loss                  -2687.2224
Q Predictions Mean           2680.9233
Q Predictions Std            422.29062
Q Predictions Max            2887.902
Q Predictions Min            20.738163
V Predictions Mean           2692.9697
V Predictions Std            425.5076
V Predictions Max            2912.9734
V Predictions Min            32.281033
Log Pis Mean                 -4.0873604
Log Pis Std                  5.6702614
Log Pis Max                  27.360462
Log Pis Min                  -13.4257965
Policy mu Mean               0.27405256
Policy mu Std                0.7405927
Policy mu Max                3.2430308
Policy mu Min                -2.8510163
Policy log std Mean          -0.30761433
Policy log std Std           0.13874978
Policy log std Max           -0.0019288063
Policy log std Min           -1.2032511
Z mean eval                  0.0392286
Z variance eval              0.036928415
total_rewards                [2619.19577694 5560.93197668 2788.26202707 4989.95870559 2791.46326029
 5615.48359508 5565.02261961 5615.08159206 5585.45521749 5441.85349996]
total_rewards_mean           4657.270827077118
total_rewards_std            1272.4837562393889
total_rewards_max            5615.483595080081
total_rewards_min            2619.1957769420465
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               32.13547127926722
(Previous) Eval Time (s)     21.71112686302513
Sample Time (s)              18.96144616883248
Epoch Time (s)               72.80804431112483
Total Train Time (s)         28758.054185256828
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:15:01.159272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #451 | Epoch Duration: 75.98559069633484
2020-01-11 02:15:01.159483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039083328
Z variance train             0.036942244
KL Divergence                5.9478
KL Loss                      0.59478
QF Loss                      1621.103
VF Loss                      474.18707
Policy Loss                  -2681.3708
Q Predictions Mean           2682.931
Q Predictions Std            438.72327
Q Predictions Max            2897.6794
Q Predictions Min            23.888264
V Predictions Mean           2690.977
V Predictions Std            437.01794
V Predictions Max            2892.0557
V Predictions Min            34.739357
Log Pis Mean                 -3.9963512
Log Pis Std                  5.455356
Log Pis Max                  19.490246
Log Pis Min                  -14.435638
Policy mu Mean               0.3393519
Policy mu Std                0.71189404
Policy mu Max                2.670246
Policy mu Min                -2.548156
Policy log std Mean          -0.30808252
Policy log std Std           0.13967271
Policy log std Max           -0.014002234
Policy log std Min           -1.0794165
Z mean eval                  0.037346397
Z variance eval              0.035459794
total_rewards                [5606.63505443 5476.93074283 1528.50215202 1642.27856837 2450.39615556
 5587.73822539 3228.15082249 2274.08184356 2864.0270001  1042.64357182]
total_rewards_mean           3170.13841365598
total_rewards_std            1675.5945552700864
total_rewards_max            5606.635054433322
total_rewards_min            1042.6435718207113
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               30.58113359892741
(Previous) Eval Time (s)     24.888344903010875
Sample Time (s)              19.08984888717532
Epoch Time (s)               74.5593273891136
Total Train Time (s)         28825.643531897105
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:16:08.752150 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #452 | Epoch Duration: 67.59251546859741
2020-01-11 02:16:08.752335 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037565034
Z variance train             0.035461683
KL Divergence                6.0395412
KL Loss                      0.60395414
QF Loss                      1628.3708
VF Loss                      774.42285
Policy Loss                  -2666.9666
Q Predictions Mean           2663.1008
Q Predictions Std            480.01846
Q Predictions Max            2883.268
Q Predictions Min            20.251259
V Predictions Mean           2677.435
V Predictions Std            473.96127
V Predictions Max            2892.757
V Predictions Min            32.175686
Log Pis Mean                 -4.7021427
Log Pis Std                  4.9411793
Log Pis Max                  20.409641
Log Pis Min                  -14.385047
Policy mu Mean               0.30600947
Policy mu Std                0.6928396
Policy mu Max                2.8324716
Policy mu Min                -2.595717
Policy log std Mean          -0.2964426
Policy log std Std           0.1306414
Policy log std Max           0.14216128
Policy log std Min           -0.9705618
Z mean eval                  0.037412386
Z variance eval              0.036899626
total_rewards                [5569.94054729 5322.04711422 5459.7564187  1084.22452049 3797.71557746
 5462.0682114  5444.13594365 5398.71484243 5443.39875946 1922.12555077]
total_rewards_mean           4490.412748586577
total_rewards_std            1583.084558242469
total_rewards_max            5569.940547290989
total_rewards_min            1084.224520491903
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               32.1156439371407
(Previous) Eval Time (s)     17.921263029798865
Sample Time (s)              20.1433735974133
Epoch Time (s)               70.18028056435287
Total Train Time (s)         28902.894082087558
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:17:26.005695 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #453 | Epoch Duration: 77.2532069683075
2020-01-11 02:17:26.005895 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03753737
Z variance train             0.036889926
KL Divergence                5.964521
KL Loss                      0.5964521
QF Loss                      1052.336
VF Loss                      619.44794
Policy Loss                  -2625.8384
Q Predictions Mean           2622.8174
Q Predictions Std            563.2793
Q Predictions Max            2882.5051
Q Predictions Min            18.50939
V Predictions Mean           2612.8926
V Predictions Std            559.2065
V Predictions Max            2867.1443
V Predictions Min            28.94412
Log Pis Mean                 -4.2691455
Log Pis Std                  4.5170603
Log Pis Max                  15.455009
Log Pis Min                  -14.768021
Policy mu Mean               0.33791822
Policy mu Std                0.6841986
Policy mu Max                2.5723362
Policy mu Min                -2.8583276
Policy log std Mean          -0.30472934
Policy log std Std           0.13394812
Policy log std Max           -0.084605776
Policy log std Min           -1.0046022
Z mean eval                  0.038209863
Z variance eval              0.036070473
total_rewards                [5606.92250585 5694.75008152 5665.22468356 5580.0500331  5687.67059421
 5438.05720067 5578.61695395 5646.62684486 5672.59600018 2595.87755149]
total_rewards_mean           5316.639244938514
total_rewards_std            909.797194434875
total_rewards_max            5694.750081517888
total_rewards_min            2595.87755149034
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               32.38192982971668
(Previous) Eval Time (s)     24.993815581314266
Sample Time (s)              19.23863353487104
Epoch Time (s)               76.61437894590199
Total Train Time (s)         28983.315840557218
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:18:46.432649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #454 | Epoch Duration: 80.42660427093506
2020-01-11 02:18:46.432863 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038315207
Z variance train             0.036075357
KL Divergence                5.9942102
KL Loss                      0.599421
QF Loss                      1532.9666
VF Loss                      770.0908
Policy Loss                  -2672.7021
Q Predictions Mean           2669.8794
Q Predictions Std            470.1767
Q Predictions Max            2882.0544
Q Predictions Min            22.097115
V Predictions Mean           2669.6885
V Predictions Std            469.1897
V Predictions Max            2880.6743
V Predictions Min            30.503092
Log Pis Mean                 -3.8221476
Log Pis Std                  5.873418
Log Pis Max                  24.577587
Log Pis Min                  -14.14617
Policy mu Mean               0.30744523
Policy mu Std                0.7401224
Policy mu Max                3.2822506
Policy mu Min                -3.951142
Policy log std Mean          -0.29965675
Policy log std Std           0.13878195
Policy log std Max           0.06316744
Policy log std Min           -1.1241199
Z mean eval                  0.03653703
Z variance eval              0.03700305
total_rewards                [5482.86809052 5474.00689372 5508.97206169 5493.29189274 5454.69174981
 5433.47408118 5574.14274399 5581.42325853 5527.84430504  619.46143561]
total_rewards_mean           5015.017651280896
total_rewards_std            1465.8803930594995
total_rewards_max            5581.42325852514
total_rewards_min            619.4614356083835
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               30.94588881218806
(Previous) Eval Time (s)     28.80572008434683
Sample Time (s)              20.003696710336953
Epoch Time (s)               79.75530560687184
Total Train Time (s)         29061.0956539372
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:20:04.215468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #455 | Epoch Duration: 77.78245496749878
2020-01-11 02:20:04.215637 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #455 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03614348
Z variance train             0.03701922
KL Divergence                5.90463
KL Loss                      0.59046304
QF Loss                      1106.314
VF Loss                      469.30927
Policy Loss                  -2670.3948
Q Predictions Mean           2670.675
Q Predictions Std            481.7427
Q Predictions Max            2881.8508
Q Predictions Min            14.64863
V Predictions Mean           2673.5708
V Predictions Std            482.34653
V Predictions Max            2889.3882
V Predictions Min            22.495094
Log Pis Mean                 -4.5781627
Log Pis Std                  4.5543733
Log Pis Max                  13.67258
Log Pis Min                  -13.751898
Policy mu Mean               0.32277057
Policy mu Std                0.6873074
Policy mu Max                2.529059
Policy mu Min                -3.2525814
Policy log std Mean          -0.29141897
Policy log std Std           0.12570141
Policy log std Max           -0.064787515
Policy log std Min           -1.0468023
Z mean eval                  0.03941712
Z variance eval              0.036167424
total_rewards                [5463.65685408 5454.74597676 5469.09319417 4548.15375182 5390.9242836
 5490.38722854 5419.16269145 5421.71155065 5431.53107142 5453.30976933]
total_rewards_mean           5354.267637179973
total_rewards_std            270.0884460383887
total_rewards_max            5490.387228535858
total_rewards_min            4548.153751815366
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               32.48659309698269
(Previous) Eval Time (s)     26.832511555869132
Sample Time (s)              19.51705246279016
Epoch Time (s)               78.83615711564198
Total Train Time (s)         29142.719329325482
Epoch                        456
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:21:25.846271 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #456 | Epoch Duration: 81.63047480583191
2020-01-11 02:21:25.846547 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039954416
Z variance train             0.036156368
KL Divergence                5.992076
KL Loss                      0.5992076
QF Loss                      1191.7029
VF Loss                      450.8928
Policy Loss                  -2732.1182
Q Predictions Mean           2729.1816
Q Predictions Std            293.00183
Q Predictions Max            2883.0874
Q Predictions Min            29.066883
V Predictions Mean           2721.5098
V Predictions Std            292.88617
V Predictions Max            2877.7876
V Predictions Min            35.727787
Log Pis Mean                 -5.0365667
Log Pis Std                  5.198951
Log Pis Max                  22.856228
Log Pis Min                  -13.83916
Policy mu Mean               0.31771255
Policy mu Std                0.6692602
Policy mu Max                3.5518842
Policy mu Min                -3.1646028
Policy log std Mean          -0.2982183
Policy log std Std           0.13375317
Policy log std Max           -0.064127915
Policy log std Min           -1.5000801
Z mean eval                  0.038359445
Z variance eval              0.036688343
total_rewards                [5463.09713665 5500.8254013  3643.19489661 5633.91802526 4419.26907738
 5386.97059191 5444.00701583 1141.39430837 5641.07699339 5552.62639691]
total_rewards_mean           4782.637984361794
total_rewards_std            1361.063743422188
total_rewards_max            5641.076993390808
total_rewards_min            1141.394308366638
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               31.04471500404179
(Previous) Eval Time (s)     29.626510506961495
Sample Time (s)              20.165446259081364
Epoch Time (s)               80.83667177008465
Total Train Time (s)         29218.75108148018
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:22:41.880089 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #457 | Epoch Duration: 76.03333020210266
2020-01-11 02:22:41.880254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03800014
Z variance train             0.03667984
KL Divergence                5.9336977
KL Loss                      0.5933698
QF Loss                      1315.6409
VF Loss                      432.21082
Policy Loss                  -2716.1042
Q Predictions Mean           2716.602
Q Predictions Std            351.25446
Q Predictions Max            2888.0886
Q Predictions Min            26.355333
V Predictions Mean           2726.2324
V Predictions Std            351.6582
V Predictions Max            2915.4941
V Predictions Min            32.743633
Log Pis Mean                 -4.986125
Log Pis Std                  4.996598
Log Pis Max                  26.788445
Log Pis Min                  -14.530391
Policy mu Mean               0.3077432
Policy mu Std                0.6833027
Policy mu Max                2.979209
Policy mu Min                -3.087303
Policy log std Mean          -0.3004017
Policy log std Std           0.13372962
Policy log std Max           0.104033634
Policy log std Min           -1.155752
Z mean eval                  0.036749814
Z variance eval              0.039185736
total_rewards                [4010.53170224 4897.76318132 5521.69860825 2118.98967643 5398.45728919
 5509.67402863 5590.04268719 5390.0900022  5162.73901876 5640.23730951]
total_rewards_mean           4924.022350372755
total_rewards_std            1042.0848324065967
total_rewards_max            5640.237309513577
total_rewards_min            2118.989676430165
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               32.09087324002758
(Previous) Eval Time (s)     24.822818947024643
Sample Time (s)              19.316340868826956
Epoch Time (s)               76.23003305587918
Total Train Time (s)         29295.84064566437
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:23:58.972853 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #458 | Epoch Duration: 77.09248280525208
2020-01-11 02:23:58.973021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03724483
Z variance train             0.03917858
KL Divergence                5.7617025
KL Loss                      0.57617027
QF Loss                      1706.1426
VF Loss                      390.3004
Policy Loss                  -2714.3608
Q Predictions Mean           2710.5312
Q Predictions Std            306.9534
Q Predictions Max            2891.5586
Q Predictions Min            579.023
V Predictions Mean           2707.7075
V Predictions Std            302.15567
V Predictions Max            2876.171
V Predictions Min            582.74365
Log Pis Mean                 -3.681698
Log Pis Std                  5.919974
Log Pis Max                  20.924805
Log Pis Min                  -12.660707
Policy mu Mean               0.33052474
Policy mu Std                0.7293474
Policy mu Max                3.3237925
Policy mu Min                -3.2642934
Policy log std Mean          -0.3105672
Policy log std Std           0.14285164
Policy log std Max           -0.03817755
Policy log std Min           -1.359668
Z mean eval                  0.03879019
Z variance eval              0.03946503
total_rewards                [5529.69761698 4046.56028711 4658.82962223 1668.05418655 5568.31030131
 5677.33848515 5344.61749064 1456.97805833 5665.11830638 5692.37590674]
total_rewards_mean           4530.788026143225
total_rewards_std            1567.8515456410696
total_rewards_max            5692.37590674499
total_rewards_min            1456.9780583252739
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               30.884610986337066
(Previous) Eval Time (s)     25.684953475371003
Sample Time (s)              20.030091276858002
Epoch Time (s)               76.59965573856607
Total Train Time (s)         29371.26844836073
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:25:14.404929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #459 | Epoch Duration: 75.4317786693573
2020-01-11 02:25:14.405132 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039028157
Z variance train             0.03946594
KL Divergence                5.7417054
KL Loss                      0.57417053
QF Loss                      1207.0981
VF Loss                      285.92957
Policy Loss                  -2709.3735
Q Predictions Mean           2705.2712
Q Predictions Std            379.33768
Q Predictions Max            2893.8662
Q Predictions Min            26.24677
V Predictions Mean           2708.1118
V Predictions Std            381.13803
V Predictions Max            2890.8193
V Predictions Min            35.73666
Log Pis Mean                 -4.7169247
Log Pis Std                  5.7779202
Log Pis Max                  26.017136
Log Pis Min                  -13.479579
Policy mu Mean               0.3372348
Policy mu Std                0.6904802
Policy mu Max                2.8543773
Policy mu Min                -2.6911187
Policy log std Mean          -0.29480135
Policy log std Std           0.13153294
Policy log std Max           -0.040716887
Policy log std Min           -1.119382
Z mean eval                  0.038676005
Z variance eval              0.03804005
total_rewards                [5590.30614038 5617.57333192 3945.65261061 2962.12281892 2930.14260441
 2799.09218537 4038.30525994 1054.79144525 5504.2935802  5115.39784468]
total_rewards_mean           3955.7677821684856
total_rewards_std            1448.2990565640257
total_rewards_max            5617.573331917063
total_rewards_min            1054.7914452534906
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               30.03463320666924
(Previous) Eval Time (s)     24.51674216799438
Sample Time (s)              19.26837542327121
Epoch Time (s)               73.81975079793483
Total Train Time (s)         29441.07468092488
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:26:24.217671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #460 | Epoch Duration: 69.81236505508423
2020-01-11 02:26:24.217931 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #460 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039031718
Z variance train             0.038047172
KL Divergence                5.837001
KL Loss                      0.5837001
QF Loss                      1920.1246
VF Loss                      515.32825
Policy Loss                  -2686.5847
Q Predictions Mean           2676.226
Q Predictions Std            463.28082
Q Predictions Max            2886.71
Q Predictions Min            22.594332
V Predictions Mean           2675.6274
V Predictions Std            461.80795
V Predictions Max            2895.797
V Predictions Min            30.247936
Log Pis Mean                 -4.604992
Log Pis Std                  5.27465
Log Pis Max                  21.376019
Log Pis Min                  -19.199944
Policy mu Mean               0.2938483
Policy mu Std                0.70366085
Policy mu Max                2.6134362
Policy mu Min                -2.9380841
Policy log std Mean          -0.3043513
Policy log std Std           0.13691495
Policy log std Max           -0.02368813
Policy log std Min           -1.1991943
Z mean eval                  0.037053175
Z variance eval              0.037402853
total_rewards                [5593.011241   1565.05461681 5629.88935622 5496.84789102 5445.9900024
 5419.4418291  5319.26963301 2720.63752286 4965.43275539 3264.68281774]
total_rewards_mean           4542.0257665552
total_rewards_std            1392.1749929087218
total_rewards_max            5629.889356224959
total_rewards_min            1565.054616809849
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               29.65402132831514
(Previous) Eval Time (s)     20.509049104060978
Sample Time (s)              19.888629043009132
Epoch Time (s)               70.05169947538525
Total Train Time (s)         29515.20876337355
Epoch                        461
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:27:38.355020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #461 | Epoch Duration: 74.13689756393433
2020-01-11 02:27:38.355203 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036955245
Z variance train             0.03740427
KL Divergence                5.8727074
KL Loss                      0.58727074
QF Loss                      1336.5034
VF Loss                      473.46957
Policy Loss                  -2728.1199
Q Predictions Mean           2722.3374
Q Predictions Std            332.81174
Q Predictions Max            2895.7886
Q Predictions Min            29.49162
V Predictions Mean           2728.9697
V Predictions Std            331.79398
V Predictions Max            2894.116
V Predictions Min            33.72999
Log Pis Mean                 -4.27125
Log Pis Std                  4.887315
Log Pis Max                  26.056873
Log Pis Min                  -15.934809
Policy mu Mean               0.3676183
Policy mu Std                0.6789589
Policy mu Max                2.837531
Policy mu Min                -2.612484
Policy log std Mean          -0.30219454
Policy log std Std           0.12756453
Policy log std Max           -0.046731457
Policy log std Min           -1.0996953
Z mean eval                  0.036687676
Z variance eval              0.037324477
total_rewards                [5465.78925797 3005.57850233 5581.36558769 5621.89483073 1381.51887176
 5657.83919903 3403.96629209 5713.93336675 2357.15965074 2689.20970195]
total_rewards_mean           4087.8255261052195
total_rewards_std            1597.0702117098099
total_rewards_max            5713.933366753063
total_rewards_min            1381.5188717645722
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               31.42984202504158
(Previous) Eval Time (s)     24.593971396330744
Sample Time (s)              19.354484104551375
Epoch Time (s)               75.3782975259237
Total Train Time (s)         29588.110714273527
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:28:51.264534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #462 | Epoch Duration: 72.90916562080383
2020-01-11 02:28:51.264810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036456805
Z variance train             0.037331898
KL Divergence                5.918188
KL Loss                      0.5918188
QF Loss                      1386.4143
VF Loss                      441.4601
Policy Loss                  -2717.8054
Q Predictions Mean           2716.1875
Q Predictions Std            390.2616
Q Predictions Max            2904.359
Q Predictions Min            22.299318
V Predictions Mean           2726.8918
V Predictions Std            393.59842
V Predictions Max            2907.151
V Predictions Min            33.328136
Log Pis Mean                 -5.2808957
Log Pis Std                  5.1765532
Log Pis Max                  33.578697
Log Pis Min                  -13.08322
Policy mu Mean               0.33951393
Policy mu Std                0.6457582
Policy mu Max                2.8648217
Policy mu Min                -3.130644
Policy log std Mean          -0.29181468
Policy log std Std           0.12983224
Policy log std Max           -0.046708502
Policy log std Min           -1.1730144
Z mean eval                  0.037359573
Z variance eval              0.037729867
total_rewards                [2312.08972836 5292.08326174 5455.34433424 5445.77169901 1165.63681023
 5585.11298392 5270.00758863 4373.59230523 5438.07318159 4261.08161811]
total_rewards_mean           4459.879351106695
total_rewards_std            1450.7521992892541
total_rewards_max            5585.112983920706
total_rewards_min            1165.6368102285492
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               33.54833262087777
(Previous) Eval Time (s)     22.124478850048035
Sample Time (s)              19.82067421497777
Epoch Time (s)               75.49348568590358
Total Train Time (s)         29666.27824275894
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:30:09.434851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #463 | Epoch Duration: 78.16984558105469
2020-01-11 02:30:09.435001 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03751804
Z variance train             0.037733056
KL Divergence                5.9193935
KL Loss                      0.5919394
QF Loss                      2092.1172
VF Loss                      518.46655
Policy Loss                  -2716.287
Q Predictions Mean           2713.419
Q Predictions Std            313.5183
Q Predictions Max            2905.7773
Q Predictions Min            78.60829
V Predictions Mean           2706.878
V Predictions Std            310.66718
V Predictions Max            2878.4358
V Predictions Min            95.3158
Log Pis Mean                 -3.7692146
Log Pis Std                  5.2769556
Log Pis Max                  17.28674
Log Pis Min                  -14.314757
Policy mu Mean               0.3573268
Policy mu Std                0.7279534
Policy mu Max                2.5549397
Policy mu Min                -2.5985346
Policy log std Mean          -0.3209675
Policy log std Std           0.13047129
Policy log std Max           -0.077562705
Policy log std Min           -0.9652255
Z mean eval                  0.03463756
Z variance eval              0.03751068
total_rewards                [5686.89755708 1582.29149385 5615.86086326 5687.85245311  881.86385924
 2622.09730429 1222.06193101 2263.58308154 1855.15546589 4337.37070699]
total_rewards_mean           3175.503471624217
total_rewards_std            1855.276106113304
total_rewards_max            5687.852453105292
total_rewards_min            881.8638592353897
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               33.17140446975827
(Previous) Eval Time (s)     24.800490263383836
Sample Time (s)              19.813326424453408
Epoch Time (s)               77.78522115759552
Total Train Time (s)         29736.46636171546
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:31:19.631445 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #464 | Epoch Duration: 70.19628882408142
2020-01-11 02:31:19.631765 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03447897
Z variance train             0.037508864
KL Divergence                5.9224815
KL Loss                      0.59224814
QF Loss                      1697.8049
VF Loss                      327.48154
Policy Loss                  -2685.593
Q Predictions Mean           2681.7803
Q Predictions Std            423.50012
Q Predictions Max            2881.0767
Q Predictions Min            31.431433
V Predictions Mean           2696.0918
V Predictions Std            421.096
V Predictions Max            2897.848
V Predictions Min            40.55778
Log Pis Mean                 -4.4017444
Log Pis Std                  4.8976707
Log Pis Max                  16.355083
Log Pis Min                  -14.315931
Policy mu Mean               0.3064344
Policy mu Std                0.70296514
Policy mu Max                2.874003
Policy mu Min                -2.5394447
Policy log std Mean          -0.29963112
Policy log std Std           0.12466162
Policy log std Max           -0.00083292276
Policy log std Min           -0.95282686
Z mean eval                  0.036222782
Z variance eval              0.038504686
total_rewards                [4086.42997148 3806.58921389 2513.06971659 5527.44191444 5374.07654818
 3809.70652848 5843.28488903 4948.73197989 5683.43838633 5797.93511076]
total_rewards_mean           4739.07042590598
total_rewards_std            1068.423716404703
total_rewards_max            5843.284889025469
total_rewards_min            2513.0697165883234
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               29.737962454091758
(Previous) Eval Time (s)     17.211181041784585
Sample Time (s)              19.291240551043302
Epoch Time (s)               66.24038404691964
Total Train Time (s)         29809.983186090365
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:32:33.152426 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #465 | Epoch Duration: 73.5204119682312
2020-01-11 02:32:33.152614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036382057
Z variance train             0.03851243
KL Divergence                5.874361
KL Loss                      0.58743614
QF Loss                      1460.387
VF Loss                      557.30786
Policy Loss                  -2737.8586
Q Predictions Mean           2730.2666
Q Predictions Std            338.62524
Q Predictions Max            2898.0942
Q Predictions Min            23.74593
V Predictions Mean           2736.468
V Predictions Std            334.34833
V Predictions Max            2895.1375
V Predictions Min            32.99009
Log Pis Mean                 -4.2196703
Log Pis Std                  4.932835
Log Pis Max                  22.998394
Log Pis Min                  -15.502653
Policy mu Mean               0.33107173
Policy mu Std                0.7050841
Policy mu Max                3.1841805
Policy mu Min                -3.604476
Policy log std Mean          -0.29594544
Policy log std Std           0.12639086
Policy log std Max           -0.032618314
Policy log std Min           -1.0601894
Z mean eval                  0.037676338
Z variance eval              0.03698113
total_rewards                [5504.31505608 1451.38575927 3742.3318327  1374.72303094 2793.21180265
 4995.20686139 4002.67220618 3066.42646363 5275.47808685 4927.11449698]
total_rewards_mean           3713.286559667028
total_rewards_std            1438.7338598685915
total_rewards_max            5504.3150560810045
total_rewards_min            1374.7230309371594
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               30.589541363995522
(Previous) Eval Time (s)     24.490921646356583
Sample Time (s)              19.65240973001346
Epoch Time (s)               74.73287274036556
Total Train Time (s)         29880.849360465072
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:33:44.025853 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #466 | Epoch Duration: 70.87306356430054
2020-01-11 02:33:44.026153 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037692953
Z variance train             0.036979456
KL Divergence                5.9672027
KL Loss                      0.5967203
QF Loss                      761.9048
VF Loss                      256.13998
Policy Loss                  -2711.3308
Q Predictions Mean           2709.3467
Q Predictions Std            406.19855
Q Predictions Max            2892.0962
Q Predictions Min            20.662542
V Predictions Mean           2708.9272
V Predictions Std            408.08557
V Predictions Max            2897.8987
V Predictions Min            30.09396
Log Pis Mean                 -4.7907267
Log Pis Std                  4.761014
Log Pis Max                  21.355953
Log Pis Min                  -15.462413
Policy mu Mean               0.34395003
Policy mu Std                0.67120534
Policy mu Max                2.8407433
Policy mu Min                -2.8819046
Policy log std Mean          -0.29445785
Policy log std Std           0.12479767
Policy log std Max           -0.03505481
Policy log std Min           -0.936181
Z mean eval                  0.031346075
Z variance eval              0.03649946
total_rewards                [5506.97450381 5409.51220697 2293.86708549 5454.34537356 3188.27646608
 1553.92930126 3917.8798445  1685.90072982 5503.66047041 1903.75128787]
total_rewards_mean           3641.809726977625
total_rewards_std            1632.7863813659915
total_rewards_max            5506.974503812189
total_rewards_min            1553.9293012625033
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               31.40740526514128
(Previous) Eval Time (s)     20.63075556186959
Sample Time (s)              19.518051190301776
Epoch Time (s)               71.55621201731265
Total Train Time (s)         29951.26376140816
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:34:54.447605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #467 | Epoch Duration: 70.421217918396
2020-01-11 02:34:54.447922 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031026363
Z variance train             0.036493037
KL Divergence                6.015515
KL Loss                      0.6015515
QF Loss                      1495.7227
VF Loss                      674.02136
Policy Loss                  -2699.572
Q Predictions Mean           2695.473
Q Predictions Std            423.10657
Q Predictions Max            2891.563
Q Predictions Min            20.831928
V Predictions Mean           2718.739
V Predictions Std            425.12042
V Predictions Max            2920.8477
V Predictions Min            31.123148
Log Pis Mean                 -4.2876554
Log Pis Std                  5.11123
Log Pis Max                  18.655867
Log Pis Min                  -17.390965
Policy mu Mean               0.3196237
Policy mu Std                0.73489183
Policy mu Max                2.8394294
Policy mu Min                -3.4493513
Policy log std Mean          -0.3053522
Policy log std Std           0.12930126
Policy log std Max           0.0028851181
Policy log std Min           -1.0101919
Z mean eval                  0.03309378
Z variance eval              0.035895433
total_rewards                [1523.34710942 1805.2335297  5436.44864136 5541.74581776 3042.7291746
 2605.09549146 5548.77271603 5464.81670406 1360.38078159 5602.09782408]
total_rewards_mean           3793.0667790071448
total_rewards_std            1786.162889144044
total_rewards_max            5602.09782408386
total_rewards_min            1360.3807815879861
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               30.311223477125168
(Previous) Eval Time (s)     19.495444741100073
Sample Time (s)              20.06239968771115
Epoch Time (s)               69.86906790593639
Total Train Time (s)         30021.72070159344
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:36:04.908491 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #468 | Epoch Duration: 70.46035480499268
2020-01-11 02:36:04.908692 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03338865
Z variance train             0.035897616
KL Divergence                6.0002155
KL Loss                      0.60002154
QF Loss                      1040.8475
VF Loss                      298.43555
Policy Loss                  -2715.0093
Q Predictions Mean           2709.79
Q Predictions Std            394.94812
Q Predictions Max            2923.8801
Q Predictions Min            19.026377
V Predictions Mean           2710.6973
V Predictions Std            392.3389
V Predictions Max            2923.0894
V Predictions Min            27.652824
Log Pis Mean                 -4.2471266
Log Pis Std                  4.7311883
Log Pis Max                  18.440548
Log Pis Min                  -13.983469
Policy mu Mean               0.3483645
Policy mu Std                0.6980789
Policy mu Max                2.5214245
Policy mu Min                -2.6793838
Policy log std Mean          -0.31495744
Policy log std Std           0.1427288
Policy log std Max           -0.051385373
Policy log std Min           -1.1200433
Z mean eval                  0.03399126
Z variance eval              0.03704943
total_rewards                [5549.53633229 3713.44413654 5410.9948347  4235.10168495 4799.00850029
 5565.32454843 5458.93112352 1390.2946435  5555.47722773 5601.24457503]
total_rewards_mean           4727.935760698403
total_rewards_std            1274.4270402090078
total_rewards_max            5601.2445750313755
total_rewards_min            1390.2946435027557
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               31.501400297041982
(Previous) Eval Time (s)     20.086389504838735
Sample Time (s)              18.81380237126723
Epoch Time (s)               70.40159217314795
Total Train Time (s)         30098.358128516935
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:37:21.552412 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #469 | Epoch Duration: 76.64354872703552
2020-01-11 02:37:21.552709 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03394275
Z variance train             0.03705004
KL Divergence                5.9239483
KL Loss                      0.5923948
QF Loss                      2333.9644
VF Loss                      741.97107
Policy Loss                  -2745.837
Q Predictions Mean           2745.8755
Q Predictions Std            275.80154
Q Predictions Max            2899.2441
Q Predictions Min            34.86496
V Predictions Mean           2749.2725
V Predictions Std            276.5105
V Predictions Max            2918.3462
V Predictions Min            45.04825
Log Pis Mean                 -4.0905437
Log Pis Std                  5.6832995
Log Pis Max                  25.05382
Log Pis Min                  -14.0344925
Policy mu Mean               0.3085554
Policy mu Std                0.72906214
Policy mu Max                3.1796246
Policy mu Min                -3.1652782
Policy log std Mean          -0.312976
Policy log std Std           0.13744853
Policy log std Max           -0.066947676
Policy log std Min           -1.2341154
Z mean eval                  0.037303902
Z variance eval              0.03628975
total_rewards                [1732.83365385 3561.01560773  774.36987237 5472.16247978 5303.78509142
 5531.20581612 1011.25783447 5572.08094887 5376.763089   5489.06196423]
total_rewards_mean           3982.4536357835723
total_rewards_std            1935.5327708467476
total_rewards_max            5572.080948870471
total_rewards_min            774.3698723712653
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               32.01471980381757
(Previous) Eval Time (s)     26.328025424852967
Sample Time (s)              19.10328495502472
Epoch Time (s)               77.44603018369526
Total Train Time (s)         30171.201039578766
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:38:34.402358 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #470 | Epoch Duration: 72.84942269325256
2020-01-11 02:38:34.402625 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03688187
Z variance train             0.036308303
KL Divergence                5.9744563
KL Loss                      0.59744567
QF Loss                      1987.1218
VF Loss                      928.5196
Policy Loss                  -2709.199
Q Predictions Mean           2710.1724
Q Predictions Std            389.88388
Q Predictions Max            2907.673
Q Predictions Min            219.01527
V Predictions Mean           2720.019
V Predictions Std            384.2773
V Predictions Max            2916.0176
V Predictions Min            235.45892
Log Pis Mean                 -4.43405
Log Pis Std                  5.4656544
Log Pis Max                  21.764849
Log Pis Min                  -16.791637
Policy mu Mean               0.32431424
Policy mu Std                0.7124758
Policy mu Max                2.6270456
Policy mu Min                -2.6693158
Policy log std Mean          -0.30574366
Policy log std Std           0.13498855
Policy log std Max           0.14863275
Policy log std Min           -0.9388198
Z mean eval                  0.035768982
Z variance eval              0.036283173
total_rewards                [5381.83663085 2355.19471308 5578.27939137 5596.37871651 1222.95122395
 4725.64315837 3366.22587293 5738.65580437 5616.08558594 5335.36974016]
total_rewards_mean           4491.662083752877
total_rewards_std            1526.2708873630252
total_rewards_max            5738.655804369517
total_rewards_min            1222.9512239477956
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               31.428330074064434
(Previous) Eval Time (s)     21.73115633195266
Sample Time (s)              20.237783506512642
Epoch Time (s)               73.39726991252974
Total Train Time (s)         30247.19989164034
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:39:50.405210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #471 | Epoch Duration: 76.00238990783691
2020-01-11 02:39:50.405392 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03560672
Z variance train             0.036281783
KL Divergence                5.9926004
KL Loss                      0.59926003
QF Loss                      2166.4792
VF Loss                      369.6776
Policy Loss                  -2601.9714
Q Predictions Mean           2599.3584
Q Predictions Std            641.9522
Q Predictions Max            2923.739
Q Predictions Min            21.276234
V Predictions Mean           2600.5493
V Predictions Std            640.8295
V Predictions Max            2919.8315
V Predictions Min            31.779057
Log Pis Mean                 -4.752788
Log Pis Std                  5.5139666
Log Pis Max                  30.978086
Log Pis Min                  -14.425747
Policy mu Mean               0.30642065
Policy mu Std                0.69030654
Policy mu Max                2.7117743
Policy mu Min                -3.2489507
Policy log std Mean          -0.29177824
Policy log std Std           0.13053356
Policy log std Max           0.154066
Policy log std Min           -1.0299411
Z mean eval                  0.033390477
Z variance eval              0.03690773
total_rewards                [3846.38262087 3133.89334146 5494.23130634 5538.31244782 1838.04399622
 5552.37669076 3140.16776796 5509.19768428 5475.75835583 5411.12501097]
total_rewards_mean           4493.948922252995
total_rewards_std            1311.6046980834033
total_rewards_max            5552.376690755581
total_rewards_min            1838.043996220888
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               28.453983685933053
(Previous) Eval Time (s)     24.335908436216414
Sample Time (s)              20.03539204504341
Epoch Time (s)               72.82528416719288
Total Train Time (s)         30320.981333252043
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:41:04.194924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #472 | Epoch Duration: 73.78935384750366
2020-01-11 02:41:04.195236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032996558
Z variance train             0.03692033
KL Divergence                5.9415817
KL Loss                      0.5941582
QF Loss                      1886.7749
VF Loss                      392.91983
Policy Loss                  -2672.8489
Q Predictions Mean           2666.7305
Q Predictions Std            506.01544
Q Predictions Max            2897.5164
Q Predictions Min            21.414982
V Predictions Mean           2681.5034
V Predictions Std            507.32593
V Predictions Max            2914.4795
V Predictions Min            28.726936
Log Pis Mean                 -4.163163
Log Pis Std                  4.9918585
Log Pis Max                  16.047276
Log Pis Min                  -12.739212
Policy mu Mean               0.34924585
Policy mu Std                0.6748549
Policy mu Max                2.8930862
Policy mu Min                -2.5943317
Policy log std Mean          -0.3045716
Policy log std Std           0.13406274
Policy log std Max           -0.04794503
Policy log std Min           -1.033561
Z mean eval                  0.035924144
Z variance eval              0.03612288
total_rewards                [3161.46694063 3099.82273522 5597.54908412 5646.25939593 5117.28820716
 5498.34093822 5502.9247598  2754.68341418 3508.32094089 2654.37469519]
total_rewards_mean           4254.10311113476
total_rewards_std            1244.4081508616246
total_rewards_max            5646.259395934047
total_rewards_min            2654.374695192613
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               32.20330407191068
(Previous) Eval Time (s)     25.299604495987296
Sample Time (s)              19.993851841893047
Epoch Time (s)               77.49676040979102
Total Train Time (s)         30396.29530081246
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:42:19.512984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #473 | Epoch Duration: 75.3175299167633
2020-01-11 02:42:19.513180 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03594558
Z variance train             0.036121853
KL Divergence                6.005596
KL Loss                      0.60055965
QF Loss                      959.5713
VF Loss                      550.29913
Policy Loss                  -2727.3943
Q Predictions Mean           2721.4746
Q Predictions Std            357.1439
Q Predictions Max            2902.3364
Q Predictions Min            30.867956
V Predictions Mean           2721.8066
V Predictions Std            357.54297
V Predictions Max            2907.4363
V Predictions Min            37.63821
Log Pis Mean                 -4.647414
Log Pis Std                  5.058338
Log Pis Max                  27.748787
Log Pis Min                  -16.679964
Policy mu Mean               0.31855172
Policy mu Std                0.6879926
Policy mu Max                3.3091502
Policy mu Min                -3.3383858
Policy log std Mean          -0.2993834
Policy log std Std           0.13722377
Policy log std Max           -0.014867768
Policy log std Min           -1.0641716
Z mean eval                  0.03713051
Z variance eval              0.03564293
total_rewards                [5414.98331328 5301.46393219 5415.3278008  5436.39788326 5500.75315016
 5430.06927771 2251.9707189  5281.42069576 5423.12431248 5434.22362559]
total_rewards_mean           5088.973471014497
total_rewards_std            947.6829291251132
total_rewards_max            5500.753150157345
total_rewards_min            2251.970718900166
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               31.23417479498312
(Previous) Eval Time (s)     23.120074230711907
Sample Time (s)              19.023327187635005
Epoch Time (s)               73.37757621333003
Total Train Time (s)         30474.551279626787
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:43:37.773888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #474 | Epoch Duration: 78.26055335998535
2020-01-11 02:43:37.774102 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037114955
Z variance train             0.03564643
KL Divergence                6.0282593
KL Loss                      0.60282594
QF Loss                      2487.93
VF Loss                      420.05698
Policy Loss                  -2738.634
Q Predictions Mean           2733.457
Q Predictions Std            301.2858
Q Predictions Max            2910.3274
Q Predictions Min            28.790705
V Predictions Mean           2744.6875
V Predictions Std            304.15775
V Predictions Max            2934.8567
V Predictions Min            38.92727
Log Pis Mean                 -4.1061654
Log Pis Std                  4.841161
Log Pis Max                  21.054358
Log Pis Min                  -15.3761425
Policy mu Mean               0.35576522
Policy mu Std                0.7035019
Policy mu Max                2.6000412
Policy mu Min                -2.5595236
Policy log std Mean          -0.31988874
Policy log std Std           0.13730301
Policy log std Max           -0.06730181
Policy log std Min           -1.143746
Z mean eval                  0.037327386
Z variance eval              0.035130106
total_rewards                [5475.05537061 3941.74680898 5482.88592774 5581.40446783 5213.92505252
  403.7015655  5342.7043589  5540.61032731 5475.74357357 5433.92465673]
total_rewards_mean           4789.170210968932
total_rewards_std            1531.938216201517
total_rewards_max            5581.40446782546
total_rewards_min            403.7015655048847
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               31.01231661112979
(Previous) Eval Time (s)     28.002759478986263
Sample Time (s)              19.833444648887962
Epoch Time (s)               78.84852073900402
Total Train Time (s)         30551.130766639486
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:44:54.356864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #475 | Epoch Duration: 76.5826063156128
2020-01-11 02:44:54.357025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03732194
Z variance train             0.03512042
KL Divergence                6.0676317
KL Loss                      0.6067632
QF Loss                      1939.7346
VF Loss                      426.46185
Policy Loss                  -2735.8506
Q Predictions Mean           2737.143
Q Predictions Std            313.169
Q Predictions Max            2905.6345
Q Predictions Min            24.128742
V Predictions Mean           2730.1743
V Predictions Std            316.7001
V Predictions Max            2910.0913
V Predictions Min            35.385777
Log Pis Mean                 -3.7956991
Log Pis Std                  5.50396
Log Pis Max                  23.36824
Log Pis Min                  -16.7142
Policy mu Mean               0.35897395
Policy mu Std                0.7127179
Policy mu Max                3.053513
Policy mu Min                -3.1655722
Policy log std Mean          -0.31634802
Policy log std Std           0.13219625
Policy log std Max           0.017839357
Policy log std Min           -1.2561436
Z mean eval                  0.03711876
Z variance eval              0.03561674
total_rewards                [5352.61536183 5539.83444923 5574.27998855 5547.8655397  5450.93484371
 5549.82667208 5459.6256459  5361.34920197 5488.43169442 5607.47128216]
total_rewards_mean           5493.223467955889
total_rewards_std            82.51457380176159
total_rewards_max            5607.4712821633575
total_rewards_min            5352.6153618333365
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               30.080233500804752
(Previous) Eval Time (s)     25.736497839912772
Sample Time (s)              19.20473642833531
Epoch Time (s)               75.02146776905283
Total Train Time (s)         30630.18962248601
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:46:13.420542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #476 | Epoch Duration: 79.06336832046509
2020-01-11 02:46:13.420758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036846325
Z variance train             0.03561736
KL Divergence                6.0152826
KL Loss                      0.6015283
QF Loss                      2209.2512
VF Loss                      629.881
Policy Loss                  -2730.4617
Q Predictions Mean           2732.269
Q Predictions Std            388.45917
Q Predictions Max            2927.9736
Q Predictions Min            22.384275
V Predictions Mean           2746.5427
V Predictions Std            391.29117
V Predictions Max            2947.797
V Predictions Min            31.725595
Log Pis Mean                 -4.137735
Log Pis Std                  4.909922
Log Pis Max                  16.962835
Log Pis Min                  -13.603334
Policy mu Mean               0.32690912
Policy mu Std                0.6942258
Policy mu Max                2.5613859
Policy mu Min                -2.5270824
Policy log std Mean          -0.31394663
Policy log std Std           0.13875
Policy log std Max           -0.08229078
Policy log std Min           -1.2162322
Z mean eval                  0.036087293
Z variance eval              0.036586888
total_rewards                [4186.41375562 5457.86911014 5398.20374521 5577.74203232 5661.33601064
 2940.6718853  5476.42608895 5540.77334393 5603.79641028 5590.27548742]
total_rewards_mean           5143.350786980785
total_rewards_std            840.7755219556426
total_rewards_max            5661.336010639975
total_rewards_min            2940.6718853037432
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               31.76061797887087
(Previous) Eval Time (s)     29.77810158394277
Sample Time (s)              19.261293671559542
Epoch Time (s)               80.80001323437318
Total Train Time (s)         30708.43220079923
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:47:31.670960 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #477 | Epoch Duration: 78.25000715255737
2020-01-11 02:47:31.671247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036150355
Z variance train             0.036585845
KL Divergence                5.9595356
KL Loss                      0.5959536
QF Loss                      1086.7727
VF Loss                      503.21286
Policy Loss                  -2713.718
Q Predictions Mean           2706.2017
Q Predictions Std            416.4503
Q Predictions Max            2895.438
Q Predictions Min            17.901802
V Predictions Mean           2702.0012
V Predictions Std            416.0115
V Predictions Max            2898.0134
V Predictions Min            29.969011
Log Pis Mean                 -4.2766795
Log Pis Std                  4.8691745
Log Pis Max                  18.133137
Log Pis Min                  -18.962591
Policy mu Mean               0.3292651
Policy mu Std                0.71209544
Policy mu Max                2.7637153
Policy mu Min                -3.0353878
Policy log std Mean          -0.3003439
Policy log std Std           0.1299981
Policy log std Max           -0.009397902
Policy log std Min           -0.99166757
Z mean eval                  0.037535798
Z variance eval              0.03538452
total_rewards                [5490.0576767  5512.10901339 5378.60856344 3159.13409569 5415.57443044
 5540.7210044  5534.12390381 5340.47798951 5493.52673192 5538.55441361]
total_rewards_mean           5240.288782290918
total_rewards_std            696.9262020075137
total_rewards_max            5540.721004403947
total_rewards_min            3159.1340956879735
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               32.09638545010239
(Previous) Eval Time (s)     27.227768673095852
Sample Time (s)              19.71371013438329
Epoch Time (s)               79.03786425758153
Total Train Time (s)         30788.693881744053
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:48:51.935553 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #478 | Epoch Duration: 80.26406025886536
2020-01-11 02:48:51.935709 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03762486
Z variance train             0.035384595
KL Divergence                6.02826
KL Loss                      0.60282606
QF Loss                      1366.6941
VF Loss                      659.9212
Policy Loss                  -2683.0378
Q Predictions Mean           2678.6719
Q Predictions Std            509.403
Q Predictions Max            2908.3198
Q Predictions Min            22.319458
V Predictions Mean           2679.237
V Predictions Std            507.2268
V Predictions Max            2901.4397
V Predictions Min            30.805017
Log Pis Mean                 -4.895649
Log Pis Std                  5.1042786
Log Pis Max                  26.708273
Log Pis Min                  -17.316631
Policy mu Mean               0.30657846
Policy mu Std                0.68506676
Policy mu Max                3.345655
Policy mu Min                -3.7754638
Policy log std Mean          -0.30030417
Policy log std Std           0.13425453
Policy log std Max           -0.007863916
Policy log std Min           -1.2325783
Z mean eval                  0.03871145
Z variance eval              0.036250886
total_rewards                [5729.72170944 5632.73553308 5510.43311322 5657.69303073 5496.68143605
 4573.68927479 2219.68593606 5691.91259848 5562.59100802 5478.50335197]
total_rewards_mean           5155.36469918472
total_rewards_std            1027.9768936035496
total_rewards_max            5729.721709439554
total_rewards_min            2219.6859360612384
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               29.461386275012046
(Previous) Eval Time (s)     28.45366272702813
Sample Time (s)              19.3025148534216
Epoch Time (s)               77.21756385546178
Total Train Time (s)         30865.018540795892
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:50:08.269562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #479 | Epoch Duration: 76.33363962173462
2020-01-11 02:50:08.269858 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038602944
Z variance train             0.036250256
KL Divergence                5.9830256
KL Loss                      0.59830254
QF Loss                      2926.0312
VF Loss                      782.0966
Policy Loss                  -2726.1226
Q Predictions Mean           2730.542
Q Predictions Std            365.11713
Q Predictions Max            2910.6235
Q Predictions Min            27.229721
V Predictions Mean           2725.1428
V Predictions Std            369.23706
V Predictions Max            2911.0984
V Predictions Min            37.75028
Log Pis Mean                 -4.6195183
Log Pis Std                  5.599109
Log Pis Max                  20.930803
Log Pis Min                  -15.4980135
Policy mu Mean               0.24418004
Policy mu Std                0.72893643
Policy mu Max                3.0666087
Policy mu Min                -4.066982
Policy log std Mean          -0.312987
Policy log std Std           0.13182795
Policy log std Max           0.010569915
Policy log std Min           -1.19043
Z mean eval                  0.03636504
Z variance eval              0.03600625
total_rewards                [5564.3166417  5420.31480675 5651.72677398 5500.17957416 5513.77024462
 1168.55944314 5365.29414257 1790.2159418  5435.21294923 5426.44323881]
total_rewards_mean           4683.603375677287
total_rewards_std            1609.9779882755295
total_rewards_max            5651.726773981297
total_rewards_min            1168.5594431424909
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               29.857517438940704
(Previous) Eval Time (s)     27.56938197510317
Sample Time (s)              19.845366931986064
Epoch Time (s)               77.27226634602994
Total Train Time (s)         30939.970234921668
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:51:23.226355 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #480 | Epoch Duration: 74.95623540878296
2020-01-11 02:51:23.226583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036705337
Z variance train             0.036011428
KL Divergence                6.0082073
KL Loss                      0.6008207
QF Loss                      1141.4257
VF Loss                      544.36694
Policy Loss                  -2717.5107
Q Predictions Mean           2715.46
Q Predictions Std            468.9845
Q Predictions Max            2923.0952
Q Predictions Min            21.809067
V Predictions Mean           2707.651
V Predictions Std            473.32196
V Predictions Max            2919.6711
V Predictions Min            31.871666
Log Pis Mean                 -4.553033
Log Pis Std                  4.6667523
Log Pis Max                  13.217104
Log Pis Min                  -14.84268
Policy mu Mean               0.3047463
Policy mu Std                0.69532216
Policy mu Max                2.6645103
Policy mu Min                -3.086676
Policy log std Mean          -0.30966926
Policy log std Std           0.13800117
Policy log std Max           0.08125447
Policy log std Min           -1.2948809
Z mean eval                  0.041280843
Z variance eval              0.037012372
total_rewards                [4971.29482591 4432.6419229  5225.28094976 1275.05395098 5257.68179584
 3794.57240383 2283.3663503  5168.31920368 5129.2376214  2626.91433314]
total_rewards_mean           4016.436335775606
total_rewards_std            1383.8656805064766
total_rewards_max            5257.68179584282
total_rewards_min            1275.0539509809787
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               32.954261530190706
(Previous) Eval Time (s)     25.253041389863938
Sample Time (s)              19.914213862270117
Epoch Time (s)               78.12151678232476
Total Train Time (s)         31016.071686711162
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:52:39.335087 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #481 | Epoch Duration: 76.10830330848694
2020-01-11 02:52:39.335385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041549683
Z variance train             0.037010632
KL Divergence                5.9357524
KL Loss                      0.59357524
QF Loss                      1509.7557
VF Loss                      552.4067
Policy Loss                  -2711.2625
Q Predictions Mean           2709.0283
Q Predictions Std            401.24905
Q Predictions Max            2923.0776
Q Predictions Min            15.749563
V Predictions Mean           2707.9883
V Predictions Std            398.0269
V Predictions Max            2921.7864
V Predictions Min            29.107414
Log Pis Mean                 -3.8472862
Log Pis Std                  5.8906817
Log Pis Max                  38.685555
Log Pis Min                  -14.103808
Policy mu Mean               0.2798294
Policy mu Std                0.7551509
Policy mu Max                3.271802
Policy mu Min                -3.6394227
Policy log std Mean          -0.3081035
Policy log std Std           0.13450307
Policy log std Max           -0.019942246
Policy log std Min           -1.0509138
Z mean eval                  0.04184975
Z variance eval              0.036473252
total_rewards                [1039.46333479 5511.66497268 5620.38932765 2906.92106287 1681.56279585
 1190.94672864 5576.60785579 3897.31524328 5568.91100054 2338.94784058]
total_rewards_mean           3533.27301626771
total_rewards_std            1835.0693322950979
total_rewards_max            5620.389327650182
total_rewards_min            1039.4633347904798
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               32.29400617396459
(Previous) Eval Time (s)     23.23946291487664
Sample Time (s)              20.16702971374616
Epoch Time (s)               75.70049880258739
Total Train Time (s)         31087.818566557486
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:53:51.089153 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #482 | Epoch Duration: 71.75354051589966
2020-01-11 02:53:51.089435 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04160794
Z variance train             0.036457304
KL Divergence                5.9583626
KL Loss                      0.5958363
QF Loss                      1529.0161
VF Loss                      414.20285
Policy Loss                  -2707.5532
Q Predictions Mean           2704.5042
Q Predictions Std            434.74823
Q Predictions Max            2913.7112
Q Predictions Min            23.812716
V Predictions Mean           2721.6504
V Predictions Std            439.78406
V Predictions Max            2934.569
V Predictions Min            30.324097
Log Pis Mean                 -4.236246
Log Pis Std                  5.1775246
Log Pis Max                  23.808502
Log Pis Min                  -16.310658
Policy mu Mean               0.36111754
Policy mu Std                0.6846224
Policy mu Max                2.7343135
Policy mu Min                -3.75817
Policy log std Mean          -0.30140284
Policy log std Std           0.13561243
Policy log std Max           0.02339881
Policy log std Min           -1.0193332
Z mean eval                  0.04116934
Z variance eval              0.03707185
total_rewards                [2117.84326562 2489.37380001 4440.6087796  5766.99156197 5718.96775309
 4764.22775698 4770.37937204 4444.93430666 1250.76024179 5658.84010508]
total_rewards_mean           4142.292694282494
total_rewards_std            1535.5404102222133
total_rewards_max            5766.991561967872
total_rewards_min            1250.7602417932815
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               31.406257866881788
(Previous) Eval Time (s)     19.292165184859186
Sample Time (s)              19.59489080356434
Epoch Time (s)               70.29331385530531
Total Train Time (s)         31161.119627477136
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:55:04.397741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #483 | Epoch Duration: 73.30806994438171
2020-01-11 02:55:04.398031 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040907927
Z variance train             0.037068006
KL Divergence                5.901831
KL Loss                      0.59018314
QF Loss                      928.97424
VF Loss                      331.56873
Policy Loss                  -2749.4978
Q Predictions Mean           2745.1855
Q Predictions Std            347.1449
Q Predictions Max            2910.8264
Q Predictions Min            24.905947
V Predictions Mean           2759.339
V Predictions Std            349.25146
V Predictions Max            2922.6917
V Predictions Min            35.47615
Log Pis Mean                 -4.5865307
Log Pis Std                  4.8047543
Log Pis Max                  17.904305
Log Pis Min                  -13.96867
Policy mu Mean               0.35579896
Policy mu Std                0.66890305
Policy mu Max                2.695564
Policy mu Min                -2.4387002
Policy log std Mean          -0.29617187
Policy log std Std           0.13420177
Policy log std Max           -0.038202554
Policy log std Min           -0.96503896
Z mean eval                  0.040479902
Z variance eval              0.03793333
total_rewards                [5632.41265461 3091.31402344 5486.70608234 5574.40206786 5574.75394582
 5488.39657907 5479.21783585 5621.56478241 2025.15610148 5539.35090292]
total_rewards_mean           4951.327497581298
total_rewards_std            1221.1314339872051
total_rewards_max            5632.4126546126945
total_rewards_min            2025.1561014782244
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               31.817463683430105
(Previous) Eval Time (s)     22.306617283727974
Sample Time (s)              19.49273769231513
Epoch Time (s)               73.61681865947321
Total Train Time (s)         31238.56363551505
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:56:21.848575 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #484 | Epoch Duration: 77.45032739639282
2020-01-11 02:56:21.848800 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040282693
Z variance train             0.03794384
KL Divergence                5.8194947
KL Loss                      0.5819495
QF Loss                      1334.3767
VF Loss                      893.1137
Policy Loss                  -2712.007
Q Predictions Mean           2713.3901
Q Predictions Std            442.48026
Q Predictions Max            2908.585
Q Predictions Min            23.856657
V Predictions Mean           2713.2808
V Predictions Std            442.1408
V Predictions Max            2909.3252
V Predictions Min            29.620306
Log Pis Mean                 -3.7667255
Log Pis Std                  5.730466
Log Pis Max                  23.37125
Log Pis Min                  -12.767569
Policy mu Mean               0.28044683
Policy mu Std                0.7353079
Policy mu Max                3.1705027
Policy mu Min                -3.1882014
Policy log std Mean          -0.31065547
Policy log std Std           0.1427117
Policy log std Max           0.04703866
Policy log std Min           -1.3631735
Z mean eval                  0.041167002
Z variance eval              0.037803184
total_rewards                [5699.93629741 5661.56471442 5699.06235941 5559.56020305 5534.75102672
 5517.57787104 5589.02117789 5729.40713953 5589.3757672  5594.31427066]
total_rewards_mean           5617.4570827331645
total_rewards_std            70.88123055214811
total_rewards_max            5729.407139525413
total_rewards_min            5517.577871041696
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               33.04167764959857
(Previous) Eval Time (s)     26.139790375716984
Sample Time (s)              20.184817366767675
Epoch Time (s)               79.36628539208323
Total Train Time (s)         31321.849368033
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:57:45.136966 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #485 | Epoch Duration: 83.28799390792847
2020-01-11 02:57:45.137119 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04103646
Z variance train             0.03780017
KL Divergence                5.842179
KL Loss                      0.5842179
QF Loss                      1259.8135
VF Loss                      381.04068
Policy Loss                  -2680.074
Q Predictions Mean           2676.3281
Q Predictions Std            485.87982
Q Predictions Max            2912.008
Q Predictions Min            20.214014
V Predictions Mean           2681.002
V Predictions Std            487.7801
V Predictions Max            2914.0037
V Predictions Min            33.130196
Log Pis Mean                 -4.279606
Log Pis Std                  5.374944
Log Pis Max                  20.978523
Log Pis Min                  -13.400396
Policy mu Mean               0.34563798
Policy mu Std                0.6917085
Policy mu Max                3.1077669
Policy mu Min                -3.1683304
Policy log std Mean          -0.31799945
Policy log std Std           0.13979982
Policy log std Max           0.14596659
Policy log std Min           -0.9933375
Z mean eval                  0.038744032
Z variance eval              0.038112517
total_rewards                [2751.65910062 5691.58605869 4418.06966921 5542.04775198  724.33270455
 5607.78485014 5628.77811015 2418.57354142 5629.18165124 5521.06510991]
total_rewards_mean           4393.307854791635
total_rewards_std            1698.8899104556967
total_rewards_max            5691.586058690151
total_rewards_min            724.3327045493411
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               31.593985029961914
(Previous) Eval Time (s)     30.06113355886191
Sample Time (s)              19.770034471526742
Epoch Time (s)               81.42515306035057
Total Train Time (s)         31396.990445259493
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:59:00.282252 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #486 | Epoch Duration: 75.14501404762268
2020-01-11 02:59:00.282453 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038641714
Z variance train             0.038120415
KL Divergence                5.8136535
KL Loss                      0.58136535
QF Loss                      1502.8423
VF Loss                      453.11554
Policy Loss                  -2743.5713
Q Predictions Mean           2739.4224
Q Predictions Std            311.31653
Q Predictions Max            2904.1475
Q Predictions Min            286.2601
V Predictions Mean           2744.7302
V Predictions Std            307.5333
V Predictions Max            2907.6733
V Predictions Min            284.55228
Log Pis Mean                 -4.163316
Log Pis Std                  6.2844954
Log Pis Max                  38.743538
Log Pis Min                  -15.191955
Policy mu Mean               0.36788586
Policy mu Std                0.6884985
Policy mu Max                3.1761496
Policy mu Min                -3.9373555
Policy log std Mean          -0.3107889
Policy log std Std           0.13818815
Policy log std Max           0.056685716
Policy log std Min           -1.3646119
Z mean eval                  0.04033474
Z variance eval              0.038151685
total_rewards                [5516.36733106 5485.39636966 4552.21414396 5545.54649581 5349.63280522
 5541.28082301 5237.90460968 5505.01774624 5475.64355786 5575.96042797]
total_rewards_mean           5378.496431046678
total_rewards_std            291.99645356919876
total_rewards_max            5575.960427974569
total_rewards_min            4552.214143955553
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               29.49036880629137
(Previous) Eval Time (s)     23.780649254098535
Sample Time (s)              19.735813598614186
Epoch Time (s)               73.00683165900409
Total Train Time (s)         31474.84763625916
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:00:18.143737 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #487 | Epoch Duration: 77.86113691329956
2020-01-11 03:00:18.143961 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040650103
Z variance train             0.03813371
KL Divergence                5.801001
KL Loss                      0.5801001
QF Loss                      1780.9802
VF Loss                      708.64996
Policy Loss                  -2730.1365
Q Predictions Mean           2724.3535
Q Predictions Std            417.6548
Q Predictions Max            2932.0525
Q Predictions Min            17.385746
V Predictions Mean           2725.5703
V Predictions Std            419.56268
V Predictions Max            2922.487
V Predictions Min            20.692547
Log Pis Mean                 -4.6541357
Log Pis Std                  4.953452
Log Pis Max                  17.753294
Log Pis Min                  -15.104097
Policy mu Mean               0.28919804
Policy mu Std                0.690829
Policy mu Max                2.774557
Policy mu Min                -2.4655404
Policy log std Mean          -0.3013203
Policy log std Std           0.13569675
Policy log std Max           0.0064121857
Policy log std Min           -1.1664548
Z mean eval                  0.045181394
Z variance eval              0.037095647
total_rewards                [5615.15397181 5600.2826652  3756.75298926 5574.5048604  5167.71355888
 5512.07933555 1181.0536887  5416.00349919 5612.15512897 3654.86421996]
total_rewards_mean           4709.0563917908685
total_rewards_std            1378.4004466134222
total_rewards_max            5615.153971805134
total_rewards_min            1181.0536886984391
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               31.86805485188961
(Previous) Eval Time (s)     28.634595266077667
Sample Time (s)              19.96292294980958
Epoch Time (s)               80.46557306777686
Total Train Time (s)         31551.258406898938
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:01:34.560974 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #488 | Epoch Duration: 76.4168381690979
2020-01-11 03:01:34.561219 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045116957
Z variance train             0.03709206
KL Divergence                5.8585887
KL Loss                      0.5858589
QF Loss                      1194.5063
VF Loss                      603.6268
Policy Loss                  -2709.3909
Q Predictions Mean           2706.4521
Q Predictions Std            488.93564
Q Predictions Max            2923.6611
Q Predictions Min            22.507978
V Predictions Mean           2697.7183
V Predictions Std            492.27695
V Predictions Max            2921.326
V Predictions Min            32.39066
Log Pis Mean                 -4.7757893
Log Pis Std                  5.136963
Log Pis Max                  35.831463
Log Pis Min                  -14.200153
Policy mu Mean               0.32079247
Policy mu Std                0.65683866
Policy mu Max                3.1455977
Policy mu Min                -3.6631567
Policy log std Mean          -0.29220837
Policy log std Std           0.13133532
Policy log std Max           0.010835625
Policy log std Min           -1.0073868
Z mean eval                  0.046631455
Z variance eval              0.035114802
total_rewards                [ 762.03180033 5546.3631692  4844.51756409 5660.05680144 1989.30688405
 5669.20691025 5702.72571578 5617.09249849 3067.11223606 5684.32694588]
total_rewards_mean           4454.274052557957
total_rewards_std            1741.5988296175985
total_rewards_max            5702.725715777084
total_rewards_min            762.0318003331965
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               32.36793262604624
(Previous) Eval Time (s)     24.585522880777717
Sample Time (s)              19.792562746442854
Epoch Time (s)               76.74601825326681
Total Train Time (s)         31626.155765139963
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:02:49.466154 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #489 | Epoch Duration: 74.9047360420227
2020-01-11 03:02:49.466422 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046631224
Z variance train             0.035113987
KL Divergence                6.007309
KL Loss                      0.6007309
QF Loss                      1413.467
VF Loss                      395.09885
Policy Loss                  -2759.228
Q Predictions Mean           2759.6123
Q Predictions Std            296.84872
Q Predictions Max            2951.959
Q Predictions Min            29.826975
V Predictions Mean           2753.2065
V Predictions Std            296.09375
V Predictions Max            2931.9504
V Predictions Min            33.75459
Log Pis Mean                 -4.5704265
Log Pis Std                  5.5068264
Log Pis Max                  21.927584
Log Pis Min                  -14.800752
Policy mu Mean               0.3127924
Policy mu Std                0.69426
Policy mu Max                4.3044243
Policy mu Min                -3.0631466
Policy log std Mean          -0.30154097
Policy log std Std           0.12751144
Policy log std Max           -0.07486793
Policy log std Min           -0.9605763
Z mean eval                  0.046030324
Z variance eval              0.037385613
total_rewards                [ 989.61433794 5482.71727852 5509.38055267 5541.96172828 5456.55443228
 5460.59958933 5502.57732157 5549.40029388 5522.09395745 5572.18062402]
total_rewards_mean           5058.708011594905
total_rewards_std            1356.831796167167
total_rewards_max            5572.180624024679
total_rewards_min            989.6143379352325
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               31.79750581085682
(Previous) Eval Time (s)     22.743915356695652
Sample Time (s)              19.416956163942814
Epoch Time (s)               73.95837733149529
Total Train Time (s)         31704.33221264975
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:04:07.675273 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #490 | Epoch Duration: 78.20862221717834
2020-01-11 03:04:07.675574 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04610359
Z variance train             0.037400924
KL Divergence                5.852235
KL Loss                      0.5852235
QF Loss                      1830.8916
VF Loss                      899.1086
Policy Loss                  -2714.148
Q Predictions Mean           2710.8687
Q Predictions Std            441.619
Q Predictions Max            2941.127
Q Predictions Min            21.840445
V Predictions Mean           2720.5222
V Predictions Std            433.80875
V Predictions Max            2930.178
V Predictions Min            32.306805
Log Pis Mean                 -4.4665613
Log Pis Std                  5.122477
Log Pis Max                  21.015741
Log Pis Min                  -16.124859
Policy mu Mean               0.2694839
Policy mu Std                0.704626
Policy mu Max                2.9947355
Policy mu Min                -3.1926374
Policy log std Mean          -0.3166508
Policy log std Std           0.13448045
Policy log std Max           -0.03415961
Policy log std Min           -1.5550392
Z mean eval                  0.0442466
Z variance eval              0.0367988
total_rewards                [2433.23570771 5526.93423898 5569.92790083 5537.91235036 5417.01907996
  247.30118922 1532.36109931 5542.64003051 5659.45570319 3306.7887195 ]
total_rewards_mean           4077.3576019567167
total_rewards_std            1932.622340209269
total_rewards_max            5659.455703188111
total_rewards_min            247.30118921880168
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               30.009207881055772
(Previous) Eval Time (s)     26.993801242671907
Sample Time (s)              20.395893364213407
Epoch Time (s)               77.39890248794109
Total Train Time (s)         31776.944143049885
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:05:20.268338 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #491 | Epoch Duration: 72.59247875213623
2020-01-11 03:05:20.268638 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044193957
Z variance train             0.036795232
KL Divergence                5.8833914
KL Loss                      0.58833915
QF Loss                      1337.4957
VF Loss                      548.76587
Policy Loss                  -2768.8662
Q Predictions Mean           2765.7961
Q Predictions Std            300.8679
Q Predictions Max            2944.9465
Q Predictions Min            25.979183
V Predictions Mean           2769.1309
V Predictions Std            300.44562
V Predictions Max            2949.19
V Predictions Min            33.421017
Log Pis Mean                 -4.9647083
Log Pis Std                  4.666768
Log Pis Max                  15.706306
Log Pis Min                  -16.262669
Policy mu Mean               0.30934262
Policy mu Std                0.6755263
Policy mu Max                2.7015011
Policy mu Min                -2.7026312
Policy log std Mean          -0.298696
Policy log std Std           0.12594482
Policy log std Max           0.04976538
Policy log std Min           -1.0664815
Z mean eval                  0.045412496
Z variance eval              0.036677487
total_rewards                [5528.20001432 5423.41296109 5486.27520689 3613.98421735 5532.38671903
 5470.78739619 5230.91947737 3527.87822971 5463.7364335  5497.27215846]
total_rewards_mean           5077.485281389197
total_rewards_std            757.8661630499538
total_rewards_max            5532.386719030025
total_rewards_min            3527.8782297055727
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               32.21600359631702
(Previous) Eval Time (s)     22.18698224099353
Sample Time (s)              19.366404846310616
Epoch Time (s)               73.76939068362117
Total Train Time (s)         31855.891621650197
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:06:39.221648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #492 | Epoch Duration: 78.95280718803406
2020-01-11 03:06:39.221936 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045898948
Z variance train             0.036684036
KL Divergence                5.8808002
KL Loss                      0.58808005
QF Loss                      1747.2341
VF Loss                      1157.225
Policy Loss                  -2726.3303
Q Predictions Mean           2722.4111
Q Predictions Std            448.7461
Q Predictions Max            2927.4983
Q Predictions Min            26.179602
V Predictions Mean           2708.9165
V Predictions Std            449.10214
V Predictions Max            2938.19
V Predictions Min            35.914684
Log Pis Mean                 -4.8028393
Log Pis Std                  5.859808
Log Pis Max                  44.75468
Log Pis Min                  -14.1545925
Policy mu Mean               0.29332355
Policy mu Std                0.6955156
Policy mu Max                4.879919
Policy mu Min                -3.2955952
Policy log std Mean          -0.29594544
Policy log std Std           0.13897258
Policy log std Max           0.040679857
Policy log std Min           -1.1429486
Z mean eval                  0.04336967
Z variance eval              0.03499118
total_rewards                [5429.80788757 5011.15614028 5496.43051916 5485.08830264 2763.61053241
 5483.84705166 5425.77485114 2693.6317     5421.00016855 2320.59207329]
total_rewards_mean           4553.093922669703
total_rewards_std            1294.6812557823193
total_rewards_max            5496.430519161263
total_rewards_min            2320.5920732861205
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               28.821756469085813
(Previous) Eval Time (s)     27.37008803198114
Sample Time (s)              19.1509073455818
Epoch Time (s)               75.34275184664875
Total Train Time (s)         31928.63942333823
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:07:51.973817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #493 | Epoch Duration: 72.75162935256958
2020-01-11 03:07:51.974071 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04317501
Z variance train             0.03499817
KL Divergence                5.9906187
KL Loss                      0.5990619
QF Loss                      2222.6294
VF Loss                      561.6264
Policy Loss                  -2723.285
Q Predictions Mean           2722.247
Q Predictions Std            422.65274
Q Predictions Max            2916.166
Q Predictions Min            26.105988
V Predictions Mean           2729.3772
V Predictions Std            421.52127
V Predictions Max            2934.4634
V Predictions Min            35.42201
Log Pis Mean                 -4.541625
Log Pis Std                  5.9171147
Log Pis Max                  26.775564
Log Pis Min                  -14.822134
Policy mu Mean               0.286439
Policy mu Std                0.7050682
Policy mu Max                3.305591
Policy mu Min                -3.2473683
Policy log std Mean          -0.29464963
Policy log std Std           0.1334746
Policy log std Max           -0.010133624
Policy log std Min           -1.1603467
Z mean eval                  0.047232926
Z variance eval              0.035093687
total_rewards                [1816.52090724 1047.75428653 2000.32250705 3009.04804659 5133.88062618
 4600.67717946 5562.02917152 5641.36117765 5555.68823081 1503.20933926]
total_rewards_mean           3587.0491472306867
total_rewards_std            1794.2512910559449
total_rewards_max            5641.361177653052
total_rewards_min            1047.7542865250402
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               32.535681072156876
(Previous) Eval Time (s)     24.77866714214906
Sample Time (s)              19.029133828822523
Epoch Time (s)               76.34348204312846
Total Train Time (s)         31998.59157267306
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:09:01.932286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #494 | Epoch Duration: 69.9580352306366
2020-01-11 03:09:01.932565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047272086
Z variance train             0.035099138
KL Divergence                5.9797735
KL Loss                      0.59797734
QF Loss                      1486.8052
VF Loss                      414.2725
Policy Loss                  -2705.1877
Q Predictions Mean           2702.859
Q Predictions Std            493.5922
Q Predictions Max            2924.065
Q Predictions Min            18.186659
V Predictions Mean           2698.7273
V Predictions Std            490.0307
V Predictions Max            2929.4714
V Predictions Min            24.290445
Log Pis Mean                 -4.2136526
Log Pis Std                  4.6065536
Log Pis Max                  19.170212
Log Pis Min                  -13.416446
Policy mu Mean               0.33820057
Policy mu Std                0.6886091
Policy mu Max                2.5837612
Policy mu Min                -2.9549856
Policy log std Mean          -0.30523193
Policy log std Std           0.13136014
Policy log std Max           -0.0043094456
Policy log std Min           -1.3542631
Z mean eval                  0.04725466
Z variance eval              0.035808552
total_rewards                [5580.4419328  5454.41122483 5595.45498462 5611.49052375 5620.49495107
 5569.65302648 5539.8052017  5521.72694541 5596.92007969 3041.87767429]
total_rewards_mean           5313.227654463852
total_rewards_std            758.5801146183044
total_rewards_max            5620.494951070175
total_rewards_min            3041.877674291408
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               32.94226002506912
(Previous) Eval Time (s)     18.392918994184583
Sample Time (s)              19.731580194551498
Epoch Time (s)               71.0667592138052
Total Train Time (s)         32080.19765431527
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:10:23.546114 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #495 | Epoch Duration: 81.61332559585571
2020-01-11 03:10:23.546409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047338083
Z variance train             0.035788428
KL Divergence                5.944559
KL Loss                      0.5944559
QF Loss                      1264.7622
VF Loss                      609.0159
Policy Loss                  -2721.4548
Q Predictions Mean           2716.483
Q Predictions Std            452.75818
Q Predictions Max            2934.1394
Q Predictions Min            20.670332
V Predictions Mean           2721.9568
V Predictions Std            457.31024
V Predictions Max            2948.9219
V Predictions Min            34.019497
Log Pis Mean                 -3.839324
Log Pis Std                  5.9831305
Log Pis Max                  24.905828
Log Pis Min                  -17.72991
Policy mu Mean               0.31509706
Policy mu Std                0.7326799
Policy mu Max                2.9885936
Policy mu Min                -3.1534128
Policy log std Mean          -0.31511128
Policy log std Std           0.13304998
Policy log std Max           -0.04047288
Policy log std Min           -1.1253307
Z mean eval                  0.043357544
Z variance eval              0.034319572
total_rewards                [5659.33194628 5652.01710534 5569.38026818 5540.61665092 5601.40982374
 5588.40623264 3517.02917827 3516.24486119 2765.2950258  5591.66234961]
total_rewards_mean           4900.139344196868
total_rewards_std            1087.6213388275926
total_rewards_max            5659.33194628181
total_rewards_min            2765.2950258017463
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               29.343972472008318
(Previous) Eval Time (s)     28.939154313877225
Sample Time (s)              20.25920268986374
Epoch Time (s)               78.54232947574928
Total Train Time (s)         32156.915460674092
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:11:40.271190 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #496 | Epoch Duration: 76.72454261779785
2020-01-11 03:11:40.271485 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043304436
Z variance train             0.03432818
KL Divergence                6.040364
KL Loss                      0.6040364
QF Loss                      1482.0188
VF Loss                      576.5177
Policy Loss                  -2729.8938
Q Predictions Mean           2723.4585
Q Predictions Std            445.391
Q Predictions Max            2915.0703
Q Predictions Min            21.519392
V Predictions Mean           2733.5972
V Predictions Std            443.81277
V Predictions Max            2925.8188
V Predictions Min            30.38075
Log Pis Mean                 -4.8476076
Log Pis Std                  5.45749
Log Pis Max                  28.257437
Log Pis Min                  -15.113647
Policy mu Mean               0.22755516
Policy mu Std                0.7158712
Policy mu Max                2.7289078
Policy mu Min                -3.1779883
Policy log std Mean          -0.30380845
Policy log std Std           0.13370985
Policy log std Max           -0.07175194
Policy log std Min           -1.090986
Z mean eval                  0.04279068
Z variance eval              0.034116227
total_rewards                [5591.40146412 4497.13936783 1184.38328974 5577.01347546 4101.70087606
 2940.19093154  771.30928848 2341.29625894 5605.77157152 5636.89987875]
total_rewards_mean           3824.7106402442905
total_rewards_std            1801.5086796773926
total_rewards_max            5636.899878753611
total_rewards_min            771.309288478256
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               31.946435179095715
(Previous) Eval Time (s)     27.121050361078233
Sample Time (s)              19.91284481342882
Epoch Time (s)               78.98033035360277
Total Train Time (s)         32229.161813613027
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:12:52.541479 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #497 | Epoch Duration: 72.26977372169495
2020-01-11 03:12:52.541730 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04257941
Z variance train             0.03411479
KL Divergence                6.0479755
KL Loss                      0.60479754
QF Loss                      1263.2202
VF Loss                      442.7076
Policy Loss                  -2752.1594
Q Predictions Mean           2753.5166
Q Predictions Std            358.14413
Q Predictions Max            2928.475
Q Predictions Min            26.525108
V Predictions Mean           2758.2466
V Predictions Std            361.76495
V Predictions Max            2942.6138
V Predictions Min            36.37277
Log Pis Mean                 -4.771398
Log Pis Std                  4.9071155
Log Pis Max                  20.35107
Log Pis Min                  -16.427242
Policy mu Mean               0.2544836
Policy mu Std                0.71694416
Policy mu Max                2.782845
Policy mu Min                -2.716321
Policy log std Mean          -0.30845872
Policy log std Std           0.12752555
Policy log std Max           0.09519616
Policy log std Min           -1.0698482
Z mean eval                  0.04605601
Z variance eval              0.035068322
total_rewards                [5276.09729498 5375.7889994  5294.21559537 5398.67820677 5319.44715688
 5612.52554067 5268.34487533 5351.70700091 5247.24842419 5355.24857102]
total_rewards_mean           5349.9301665519615
total_rewards_std            99.35650151726391
total_rewards_max            5612.525540665871
total_rewards_min            5247.248424190533
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               32.03306670486927
(Previous) Eval Time (s)     20.410178993828595
Sample Time (s)              20.241992361843586
Epoch Time (s)               72.68523806054145
Total Train Time (s)         32312.41825700784
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:14:15.801561 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #498 | Epoch Duration: 83.2596492767334
2020-01-11 03:14:15.801772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045883548
Z variance train             0.03507176
KL Divergence                5.9914875
KL Loss                      0.59914875
QF Loss                      951.3255
VF Loss                      591.7318
Policy Loss                  -2731.6458
Q Predictions Mean           2728.81
Q Predictions Std            447.19397
Q Predictions Max            2925.925
Q Predictions Min            13.662062
V Predictions Mean           2734.9531
V Predictions Std            450.9166
V Predictions Max            2945.3542
V Predictions Min            25.970102
Log Pis Mean                 -4.4203415
Log Pis Std                  5.3333316
Log Pis Max                  19.187576
Log Pis Min                  -15.170809
Policy mu Mean               0.24865809
Policy mu Std                0.7197956
Policy mu Max                3.4841042
Policy mu Min                -3.2808492
Policy log std Mean          -0.2932106
Policy log std Std           0.12427328
Policy log std Max           0.060363054
Policy log std Min           -0.9647664
Z mean eval                  0.044976037
Z variance eval              0.03351447
total_rewards                [4495.71573139 5257.53619692 3971.00791305 5597.13718934  873.26604807
 5624.30568624 3825.55409008 4841.60576016 5720.71887319 3269.47006814]
total_rewards_mean           4347.631755658143
total_rewards_std            1407.780308201846
total_rewards_max            5720.718873187191
total_rewards_min            873.266048068031
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               31.172312955837697
(Previous) Eval Time (s)     30.984246184118092
Sample Time (s)              20.008403926622123
Epoch Time (s)               82.16496306657791
Total Train Time (s)         32386.870821377262
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:15:30.258902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #499 | Epoch Duration: 74.45696711540222
2020-01-11 03:15:30.259152 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Iteration #499 | Started Training: True
2020-01-11 03:15:31.247258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] Variant:
2020-01-11 03:15:31.247680 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] {
  "env_name": "Ant-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 3000
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0007111436
Z variance train             0.69280326
KL Divergence                0.1495356
KL Loss                      0.01495356
QF Loss                      69.50569
VF Loss                      29.639257
Policy Loss                  -5.4038105
Q Predictions Mean           0.0033121614
Q Predictions Std            0.0017587668
Q Predictions Max            0.008227947
Q Predictions Min            -0.0015977039
V Predictions Mean           -0.00029463152
V Predictions Std            0.0020243167
V Predictions Max            0.004122844
V Predictions Min            -0.006428632
Log Pis Mean                 -5.422134
Log Pis Std                  0.6595036
Log Pis Max                  -3.5287657
Log Pis Min                  -7.012924
Policy mu Mean               0.0015601738
Policy mu Std                0.001667595
Policy mu Max                0.0055234022
Policy mu Min                -0.0032934812
Policy log std Mean          0.00043443142
Policy log std Std           0.0017997469
Policy log std Max           0.005979537
Policy log std Min           -0.0037199063
Z mean eval                  0.18768252
Z variance eval              0.14730497
total_rewards                [  14.00028753  -31.55095684 -226.86372544   -3.98702791   53.89787073
  -74.96443857  -12.16322149  -30.99285471   12.30646493  -53.08923595]
total_rewards_mean           -35.34068377127018
total_rewards_std            72.65531124277545
total_rewards_max            53.897870730937704
total_rewards_min            -226.8637254375447
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               30.07871193718165
(Previous) Eval Time (s)     0
Sample Time (s)              22.95115672517568
Epoch Time (s)               53.02986866235733
Total Train Time (s)         57.862271438818425
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:16:29.199706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #0 | Epoch Duration: 57.8650336265564
2020-01-11 03:16:29.199895 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.18722084
Z variance train             0.14853871
KL Divergence                2.7861366
KL Loss                      0.27861366
QF Loss                      48.19011
VF Loss                      4.1835685
Policy Loss                  -9.512016
Q Predictions Mean           3.6318457
Q Predictions Std            8.760866
Q Predictions Max            29.975864
Q Predictions Min            -23.36469
V Predictions Mean           10.310211
V Predictions Std            8.521749
V Predictions Max            34.14213
V Predictions Min            -13.94922
Log Pis Mean                 -5.2847686
Log Pis Std                  0.5802789
Log Pis Max                  -3.918102
Log Pis Min                  -7.654071
Policy mu Mean               -0.0133898165
Policy mu Std                0.14630279
Policy mu Max                0.44273037
Policy mu Min                -0.55860287
Policy log std Mean          -0.2799964
Policy log std Std           0.029475626
Policy log std Max           -0.19588062
Policy log std Min           -0.41837108
Z mean eval                  0.14425269
Z variance eval              0.03420157
total_rewards                [ 47.96509837  14.07117867 173.66179988  16.13680027  52.80957115
  87.54043317 306.37415648 238.40122172 280.50058111 447.02988885]
total_rewards_mean           166.4490729658226
total_rewards_std            139.833210977617
total_rewards_max            447.0298888459089
total_rewards_min            14.07117867156966
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               29.249305265024304
(Previous) Eval Time (s)     4.8348440788686275
Sample Time (s)              15.75704830000177
Epoch Time (s)               49.8411976438947
Total Train Time (s)         116.66827899916098
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:17:28.007307 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #1 | Epoch Duration: 58.80724906921387
2020-01-11 03:17:28.007495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.13958915
Z variance train             0.034409728
KL Divergence                6.1003313
KL Loss                      0.61003315
QF Loss                      82.67131
VF Loss                      11.706245
Policy Loss                  -22.653818
Q Predictions Mean           17.357052
Q Predictions Std            15.013961
Q Predictions Max            57.756996
Q Predictions Min            -32.1553
V Predictions Mean           24.27089
V Predictions Std            14.021844
V Predictions Max            62.20539
V Predictions Min            -22.829952
Log Pis Mean                 -3.7396107
Log Pis Std                  1.285501
Log Pis Max                  -0.8504703
Log Pis Min                  -9.2934
Policy mu Mean               0.011537545
Policy mu Std                0.21715458
Policy mu Max                0.6880044
Policy mu Min                -0.74749595
Policy log std Mean          -0.6653442
Policy log std Std           0.106234394
Policy log std Max           -0.34577504
Policy log std Min           -1.0635878
Z mean eval                  0.20194706
Z variance eval              0.019815784
total_rewards                [298.66488095 377.97489911 188.71140318 377.27829558 287.60327572
 358.84028923   8.82174145   3.23773512 289.1894981  327.9222451 ]
total_rewards_mean           251.82442635314933
total_rewards_std            133.63947488151322
total_rewards_max            377.97489910669213
total_rewards_min            3.2377351183449252
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               27.1356070949696
(Previous) Eval Time (s)     13.800593433901668
Sample Time (s)              18.643156186211854
Epoch Time (s)               59.57935671508312
Total Train Time (s)         185.00775074306875
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:18:36.347122 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #2 | Epoch Duration: 68.33947658538818
2020-01-11 03:18:36.347303 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.19896053
Z variance train             0.020200843
KL Divergence                7.5326552
KL Loss                      0.75326556
QF Loss                      112.58616
VF Loss                      12.693346
Policy Loss                  -43.681957
Q Predictions Mean           40.023003
Q Predictions Std            15.565252
Q Predictions Max            73.52837
Q Predictions Min            -27.113647
V Predictions Mean           42.693695
V Predictions Std            14.684568
V Predictions Max            75.33157
V Predictions Min            -23.203854
Log Pis Mean                 -3.0951161
Log Pis Std                  1.4846718
Log Pis Max                  -0.2341809
Log Pis Min                  -7.691781
Policy mu Mean               0.004568341
Policy mu Std                0.21790825
Policy mu Max                0.9716887
Policy mu Min                -0.69259274
Policy log std Mean          -0.7961521
Policy log std Std           0.11852843
Policy log std Max           -0.43446904
Policy log std Min           -1.1741184
Z mean eval                  0.21762693
Z variance eval              0.013804589
total_rewards                [214.6942854  210.90843858 276.89681978 236.76517041 179.246178
 204.07881529   7.22038409 235.86616231  58.24339253 200.87165342]
total_rewards_mean           182.4791299818242
total_rewards_std            79.70151890255684
total_rewards_max            276.8968197817103
total_rewards_min            7.220384091456773
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               28.182227700948715
(Previous) Eval Time (s)     22.56042685592547
Sample Time (s)              18.19216518336907
Epoch Time (s)               68.93481974024326
Total Train Time (s)         251.7596828932874
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:19:43.099507 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #3 | Epoch Duration: 66.75206208229065
2020-01-11 03:19:43.099696 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.22463217
Z variance train             0.014188205
KL Divergence                8.463063
KL Loss                      0.8463063
QF Loss                      108.58185
VF Loss                      18.436272
Policy Loss                  -57.473396
Q Predictions Mean           52.912117
Q Predictions Std            20.455147
Q Predictions Max            103.359474
Q Predictions Min            -21.327036
V Predictions Mean           58.025932
V Predictions Std            19.029228
V Predictions Max            98.53959
V Predictions Min            -13.60782
Log Pis Mean                 -3.2443657
Log Pis Std                  1.5840989
Log Pis Max                  -0.16876617
Log Pis Min                  -9.885862
Policy mu Mean               0.022113647
Policy mu Std                0.2537919
Policy mu Max                0.8153246
Policy mu Min                -0.78958535
Policy log std Mean          -0.7594018
Policy log std Std           0.108144365
Policy log std Max           -0.4079075
Policy log std Min           -1.0856087
Z mean eval                  0.29892033
Z variance eval              0.013701287
total_rewards                [158.95969706 181.3274048  127.98129476  29.31454848 306.65043237
 158.20926517  67.59949787  41.93972695  75.63325891  53.91713384]
total_rewards_mean           120.15322602031384
total_rewards_std            80.64684097378489
total_rewards_max            306.6504323699024
total_rewards_min            29.314548476198578
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               26.87611459195614
(Previous) Eval Time (s)     20.377358423080295
Sample Time (s)              17.928523713257164
Epoch Time (s)               65.1819967282936
Total Train Time (s)         310.9865999035537
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:20:42.330258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #4 | Epoch Duration: 59.23035669326782
2020-01-11 03:20:42.330550 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.30578932
Z variance train             0.01215495
KL Divergence                9.109398
KL Loss                      0.9109398
QF Loss                      145.23572
VF Loss                      16.488611
Policy Loss                  -74.223434
Q Predictions Mean           70.19043
Q Predictions Std            20.767406
Q Predictions Max            113.55323
Q Predictions Min            -23.025692
V Predictions Mean           73.45296
V Predictions Std            19.39197
V Predictions Max            124.43048
V Predictions Min            -11.286664
Log Pis Mean                 -3.0350795
Log Pis Std                  1.5637962
Log Pis Max                  0.96182406
Log Pis Min                  -8.495542
Policy mu Mean               0.03747923
Policy mu Std                0.2613341
Policy mu Max                0.97027767
Policy mu Min                -0.8806474
Policy log std Mean          -0.77577466
Policy log std Std           0.10570175
Policy log std Max           -0.4187682
Policy log std Min           -1.0943424
Z mean eval                  0.32748044
Z variance eval              0.01574593
total_rewards                [ 94.05598754 113.63772341  70.84445821  34.73149022  93.14444108
  39.46521679  76.11159621 217.92909419  28.35957557  90.81832159]
total_rewards_mean           85.90979048123187
total_rewards_std            51.72237631353141
total_rewards_max            217.92909418665312
total_rewards_min            28.359575567968875
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               28.468368031084538
(Previous) Eval Time (s)     14.425354977604002
Sample Time (s)              18.173614399507642
Epoch Time (s)               61.06733740819618
Total Train Time (s)         380.7155390540138
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:21:52.058852 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #5 | Epoch Duration: 69.72808051109314
2020-01-11 03:21:52.059046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.32936147
Z variance train             0.015748452
KL Divergence                8.420627
KL Loss                      0.84206265
QF Loss                      154.15768
VF Loss                      27.507387
Policy Loss                  -94.3253
Q Predictions Mean           90.96997
Q Predictions Std            22.255493
Q Predictions Max            139.42342
Q Predictions Min            -30.076017
V Predictions Mean           93.16261
V Predictions Std            21.139242
V Predictions Max            146.12671
V Predictions Min            -24.818361
Log Pis Mean                 -3.6114368
Log Pis Std                  1.4335512
Log Pis Max                  -0.3939123
Log Pis Min                  -9.466815
Policy mu Mean               0.06584862
Policy mu Std                0.27868098
Policy mu Max                0.99131376
Policy mu Min                -0.95145416
Policy log std Mean          -0.6747285
Policy log std Std           0.11750259
Policy log std Max           -0.34635544
Policy log std Min           -1.0904018
Z mean eval                  0.26609927
Z variance eval              0.012010933
total_rewards                [ -4.80026783  15.38829441  89.6193241   -0.10354879 -28.39134502
 -20.50840603  96.33554517 -15.08998181  -1.31664611  45.35398492]
total_rewards_mean           17.64869530236571
total_rewards_std            42.39143451487798
total_rewards_max            96.33554517308197
total_rewards_min            -28.391345020852953
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               24.82856333302334
(Previous) Eval Time (s)     23.0858018361032
Sample Time (s)              17.834485481493175
Epoch Time (s)               65.74885065061972
Total Train Time (s)         439.63256664481014
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:22:50.980352 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #6 | Epoch Duration: 58.921141386032104
2020-01-11 03:22:50.980633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35418946
Z variance train             0.01135229
KL Divergence                9.546211
KL Loss                      0.95462114
QF Loss                      227.18376
VF Loss                      40.33774
Policy Loss                  -97.3167
Q Predictions Mean           93.209366
Q Predictions Std            23.542912
Q Predictions Max            150.00052
Q Predictions Min            -8.637249
V Predictions Mean           95.42553
V Predictions Std            22.818138
V Predictions Max            159.47981
V Predictions Min            -2.2414496
Log Pis Mean                 -3.9486437
Log Pis Std                  1.4011819
Log Pis Max                  -1.178171
Log Pis Min                  -9.871375
Policy mu Mean               0.004853488
Policy mu Std                0.28635484
Policy mu Max                1.107944
Policy mu Min                -0.9432404
Policy log std Mean          -0.59874105
Policy log std Std           0.112378635
Policy log std Max           -0.29864386
Policy log std Min           -0.95232606
Z mean eval                  0.51611984
Z variance eval              0.017133329
total_rewards                [ 58.9230366   64.91746744 -90.18703978 -16.93030133 123.43967777
  11.64982738  83.68769434  -9.44510361 -13.04985555  76.53903657]
total_rewards_mean           28.954443983386994
total_rewards_std            60.18087432431614
total_rewards_max            123.43967777435226
total_rewards_min            -90.18703977741289
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               28.159306711982936
(Previous) Eval Time (s)     16.257794691249728
Sample Time (s)              18.320272703655064
Epoch Time (s)               62.73737410688773
Total Train Time (s)         507.13103967299685
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:23:58.475731 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #7 | Epoch Duration: 67.49489831924438
2020-01-11 03:23:58.475889 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5034417
Z variance train             0.01786727
KL Divergence                8.807041
KL Loss                      0.8807041
QF Loss                      188.02
VF Loss                      32.8407
Policy Loss                  -114.19888
Q Predictions Mean           110.690475
Q Predictions Std            27.263206
Q Predictions Max            155.89728
Q Predictions Min            -12.47857
V Predictions Mean           117.06068
V Predictions Std            25.54699
V Predictions Max            161.93475
V Predictions Min            -16.065434
Log Pis Mean                 -3.2456832
Log Pis Std                  1.631841
Log Pis Max                  3.5598595
Log Pis Min                  -7.593236
Policy mu Mean               0.009642176
Policy mu Std                0.32874343
Policy mu Max                1.0842344
Policy mu Min                -1.0483272
Policy log std Mean          -0.70162904
Policy log std Std           0.14981861
Policy log std Max           -0.34593722
Policy log std Min           -1.2650514
Z mean eval                  0.54885375
Z variance eval              0.0142388595
total_rewards                [  7.91550698  66.6498799  114.08832991 -40.2615703   27.21515304
 -68.30886235  -1.09655134  94.3517987   60.57018587  43.85456066]
total_rewards_mean           30.497843106939683
total_rewards_std            54.53715975819693
total_rewards_max            114.08832991479257
total_rewards_min            -68.30886234863344
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               26.61880941130221
(Previous) Eval Time (s)     21.01503843208775
Sample Time (s)              18.567066584248096
Epoch Time (s)               66.20091442763805
Total Train Time (s)         569.4529223539867
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:25:00.801203 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #8 | Epoch Duration: 62.32512378692627
2020-01-11 03:25:00.801480 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.20044012
Z variance train             0.02119305
KL Divergence                7.3962517
KL Loss                      0.73962516
QF Loss                      244.30061
VF Loss                      20.876696
Policy Loss                  -115.610054
Q Predictions Mean           112.66367
Q Predictions Std            22.676142
Q Predictions Max            162.06639
Q Predictions Min            -36.56254
V Predictions Mean           117.426216
V Predictions Std            22.78295
V Predictions Max            165.24786
V Predictions Min            -20.412582
Log Pis Mean                 -3.3146615
Log Pis Std                  1.5929854
Log Pis Max                  1.8636954
Log Pis Min                  -8.249573
Policy mu Mean               0.027097441
Policy mu Std                0.3258119
Policy mu Max                1.1779407
Policy mu Min                -1.0195366
Policy log std Mean          -0.7119627
Policy log std Std           0.12863982
Policy log std Max           -0.36608803
Policy log std Min           -1.3362197
Z mean eval                  0.5433329
Z variance eval              0.016662344
total_rewards                [  1.36539742 -39.78129557 -15.20043885  21.16950838 122.70415198
 -12.7601363  105.49676608 103.44073389  77.14992112 146.28225743]
total_rewards_mean           50.98668655740536
total_rewards_std            63.77028100337434
total_rewards_max            146.28225742810832
total_rewards_min            -39.781295574254635
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               29.525174090173095
(Previous) Eval Time (s)     17.13894143514335
Sample Time (s)              18.02102380571887
Epoch Time (s)               64.68513933103532
Total Train Time (s)         640.6399309765548
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:26:11.989899 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #9 | Epoch Duration: 71.1881856918335
2020-01-11 03:26:11.990209 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.54553485
Z variance train             0.015634373
KL Divergence                9.232988
KL Loss                      0.92329884
QF Loss                      214.75227
VF Loss                      21.24357
Policy Loss                  -143.40146
Q Predictions Mean           139.8292
Q Predictions Std            25.807838
Q Predictions Max            187.6023
Q Predictions Min            -26.11967
V Predictions Mean           143.36987
V Predictions Std            25.044538
V Predictions Max            192.82747
V Predictions Min            -53.040443
Log Pis Mean                 -3.2694788
Log Pis Std                  1.7068185
Log Pis Max                  4.738654
Log Pis Min                  -8.930595
Policy mu Mean               0.06982015
Policy mu Std                0.32872978
Policy mu Max                1.4110968
Policy mu Min                -1.2271042
Policy log std Mean          -0.70314467
Policy log std Std           0.1436817
Policy log std Max           -0.39803433
Policy log std Min           -1.5892609
Z mean eval                  0.57717735
Z variance eval              0.02215753
total_rewards                [ 70.66703855 113.96616177   5.55028387  49.15753449  76.52246067
  36.44158213  27.94920307  58.83616892  44.8505133   74.12351887]
total_rewards_mean           55.80644656555906
total_rewards_std            28.66737456889748
total_rewards_max            113.96616177424664
total_rewards_min            5.550283874486045
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               26.18080514203757
(Previous) Eval Time (s)     23.641721657011658
Sample Time (s)              18.85543723590672
Epoch Time (s)               68.67796403495595
Total Train Time (s)         711.0938390330411
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:27:22.443437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #10 | Epoch Duration: 70.45301127433777
2020-01-11 03:27:22.443648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.5812179
Z variance train             0.023214545
KL Divergence                8.728807
KL Loss                      0.87288076
QF Loss                      201.6477
VF Loss                      44.7297
Policy Loss                  -153.33871
Q Predictions Mean           148.3994
Q Predictions Std            29.909353
Q Predictions Max            220.3124
Q Predictions Min            -5.4840345
V Predictions Mean           152.16708
V Predictions Std            23.96081
V Predictions Max            226.97108
V Predictions Min            12.218166
Log Pis Mean                 -3.235735
Log Pis Std                  1.7110013
Log Pis Max                  4.1791124
Log Pis Min                  -8.300232
Policy mu Mean               0.055269033
Policy mu Std                0.33789483
Policy mu Max                1.3588798
Policy mu Min                -1.2473369
Policy log std Mean          -0.7119409
Policy log std Std           0.14773114
Policy log std Max           -0.38511634
Policy log std Min           -1.3798723
Z mean eval                  0.60608304
Z variance eval              0.013422793
total_rewards                [143.68586168  58.03274245  60.87477969  33.3288478    4.77619137
  25.11201399  17.61253695 250.35080818   5.57475357 119.56483374]
total_rewards_mean           71.89133694159321
total_rewards_std            74.23766892714623
total_rewards_max            250.3508081787017
total_rewards_min            4.776191366281468
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               26.675670464988798
(Previous) Eval Time (s)     25.416499115061015
Sample Time (s)              18.177351393271238
Epoch Time (s)               70.26952097332105
Total Train Time (s)         770.2186742620543
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:28:21.569574 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #11 | Epoch Duration: 59.125765800476074
2020-01-11 03:28:21.569783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #11 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6069572
Z variance train             0.013817665
KL Divergence                10.12755
KL Loss                      1.012755
QF Loss                      237.9425
VF Loss                      32.709206
Policy Loss                  -167.34221
Q Predictions Mean           162.30997
Q Predictions Std            28.307238
Q Predictions Max            209.97751
Q Predictions Min            -18.696152
V Predictions Mean           166.75073
V Predictions Std            26.508955
V Predictions Max            211.31908
V Predictions Min            -54.912685
Log Pis Mean                 -3.3113174
Log Pis Std                  1.7729657
Log Pis Max                  3.2222211
Log Pis Min                  -8.4787445
Policy mu Mean               0.037758883
Policy mu Std                0.3474832
Policy mu Max                1.1453158
Policy mu Min                -1.4719917
Policy log std Mean          -0.6538307
Policy log std Std           0.14762701
Policy log std Max           -0.33877504
Policy log std Min           -1.4539844
Z mean eval                  0.654648
Z variance eval              0.0107842265
total_rewards                [ 130.99459617   37.07599952  -54.94227907   91.06887775 -187.55035145
   13.85582252    2.34506808  -49.56595881   43.00519135   29.83689445]
total_rewards_mean           5.612386050482222
total_rewards_std            83.72604626829403
total_rewards_max            130.99459616947462
total_rewards_min            -187.55035145496333
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               29.566403006669134
(Previous) Eval Time (s)     14.272446635179222
Sample Time (s)              18.81917978776619
Epoch Time (s)               62.658029429614544
Total Train Time (s)         840.1090457998216
Epoch                        12
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:29:31.462241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #12 | Epoch Duration: 69.89228010177612
2020-01-11 03:29:31.462493 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6484249
Z variance train             0.010893333
KL Divergence                11.196309
KL Loss                      1.1196309
QF Loss                      214.59839
VF Loss                      62.04062
Policy Loss                  -173.96155
Q Predictions Mean           171.7445
Q Predictions Std            28.09185
Q Predictions Max            223.21835
Q Predictions Min            11.70386
V Predictions Mean           179.85933
V Predictions Std            24.175901
V Predictions Max            229.71165
V Predictions Min            61.383648
Log Pis Mean                 -3.0406108
Log Pis Std                  1.6995105
Log Pis Max                  3.2174013
Log Pis Min                  -7.761197
Policy mu Mean               0.021149555
Policy mu Std                0.36804366
Policy mu Max                1.3824763
Policy mu Min                -1.5050123
Policy log std Mean          -0.67290133
Policy log std Std           0.14514771
Policy log std Max           -0.4122878
Policy log std Min           -1.5782896
Z mean eval                  0.6505477
Z variance eval              0.0089729
total_rewards                [-30.21452651 -41.69801503 118.36332107  39.95807862 229.84921408
 -46.67255674 197.73300803  -4.79803572  62.22236033 108.23096024]
total_rewards_mean           63.29738083760706
total_rewards_std            93.7595312164279
total_rewards_max            229.84921407889644
total_rewards_min            -46.67255674008302
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               26.44997218903154
(Previous) Eval Time (s)     21.50635995203629
Sample Time (s)              18.171491474844515
Epoch Time (s)               66.12782361591235
Total Train Time (s)         909.4373334730044
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:30:40.792237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #13 | Epoch Duration: 69.32953691482544
2020-01-11 03:30:40.792474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.35296655
Z variance train             0.021226514
KL Divergence                7.8010893
KL Loss                      0.7801089
QF Loss                      265.97226
VF Loss                      37.18196
Policy Loss                  -164.77693
Q Predictions Mean           161.66232
Q Predictions Std            30.790628
Q Predictions Max            203.54988
Q Predictions Min            -3.23198
V Predictions Mean           165.60953
V Predictions Std            27.078503
V Predictions Max            208.47821
V Predictions Min            3.9660437
Log Pis Mean                 -3.1487572
Log Pis Std                  1.8365537
Log Pis Max                  3.7875195
Log Pis Min                  -9.948297
Policy mu Mean               0.050780382
Policy mu Std                0.34758723
Policy mu Max                1.1877016
Policy mu Min                -1.5764284
Policy log std Mean          -0.691293
Policy log std Std           0.14364557
Policy log std Max           -0.3624735
Policy log std Min           -1.5587778
Z mean eval                  0.67162335
Z variance eval              0.010211244
total_rewards                [ 46.43514769 184.18421549  13.28445187 125.7873351    2.04232179
 218.97361196 151.4899056  156.17309448 183.04691048   8.44064705]
total_rewards_mean           108.98576415127334
total_rewards_std            78.84812448153275
total_rewards_max            218.97361195664305
total_rewards_min            2.04232179123409
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               29.366876787040383
(Previous) Eval Time (s)     24.707781281787902
Sample Time (s)              18.52231630962342
Epoch Time (s)               72.5969743784517
Total Train Time (s)         979.6874375357293
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:31:51.042574 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #14 | Epoch Duration: 70.24991536140442
2020-01-11 03:31:51.042787 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6690649
Z variance train             0.010235261
KL Divergence                11.790938
KL Loss                      1.1790938
QF Loss                      304.55713
VF Loss                      36.62172
Policy Loss                  -193.53809
Q Predictions Mean           191.94504
Q Predictions Std            25.46615
Q Predictions Max            255.48216
Q Predictions Min            13.120646
V Predictions Mean           192.58087
V Predictions Std            25.380335
V Predictions Max            270.90552
V Predictions Min            36.681244
Log Pis Mean                 -2.9276276
Log Pis Std                  1.7975532
Log Pis Max                  4.4996424
Log Pis Min                  -8.409382
Policy mu Mean               0.05749204
Policy mu Std                0.3699249
Policy mu Max                1.5180372
Policy mu Min                -1.5089194
Policy log std Mean          -0.71429354
Policy log std Std           0.13474534
Policy log std Max           -0.42689556
Policy log std Min           -1.6738021
Z mean eval                  0.6902353
Z variance eval              0.014196296
total_rewards                [-31.85465628 117.06543695 100.57184375 108.06075617 168.86524871
  49.06330367  97.62048149  88.91188785  39.59237926  23.25849689]
total_rewards_mean           76.11551784575391
total_rewards_std            53.8900865028662
total_rewards_max            168.86524871050403
total_rewards_min            -31.854656276321684
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               27.95773120317608
(Previous) Eval Time (s)     22.360426841769367
Sample Time (s)              19.1163699189201
Epoch Time (s)               69.43452796386555
Total Train Time (s)         1048.5641627577133
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:32:59.922619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #15 | Epoch Duration: 68.87966132164001
2020-01-11 03:32:59.922816 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.6923238
Z variance train             0.014213341
KL Divergence                11.64362
KL Loss                      1.164362
QF Loss                      172.50627
VF Loss                      44.48893
Policy Loss                  -205.8193
Q Predictions Mean           200.77193
Q Predictions Std            23.84222
Q Predictions Max            282.10364
Q Predictions Min            29.684013
V Predictions Mean           203.37166
V Predictions Std            19.13233
V Predictions Max            272.70828
V Predictions Min            129.88678
Log Pis Mean                 -3.3298812
Log Pis Std                  1.7665997
Log Pis Max                  2.6907642
Log Pis Min                  -9.186504
Policy mu Mean               0.08369846
Policy mu Std                0.34483203
Policy mu Max                1.4590036
Policy mu Min                -1.2146711
Policy log std Mean          -0.7027419
Policy log std Std           0.12603186
Policy log std Max           -0.40591824
Policy log std Min           -1.5213488
Z mean eval                  0.6945084
Z variance eval              0.01150859
total_rewards                [182.3608812   94.46364337 143.47784022  19.90357579 177.09730596
 116.50978876 240.9201372   20.79882263 127.15831342 101.24064704]
total_rewards_mean           122.39309555864193
total_rewards_std            65.72078129545694
total_rewards_max            240.92013720077537
total_rewards_min            19.903575786521003
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               24.828399889171124
(Previous) Eval Time (s)     21.805228765122592
Sample Time (s)              18.85377375688404
Epoch Time (s)               65.48740241117775
Total Train Time (s)         1113.607843842823
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:34:04.964926 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #16 | Epoch Duration: 65.04195523262024
2020-01-11 03:34:04.965119 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.69392526
Z variance train             0.01152909
KL Divergence                12.443283
KL Loss                      1.2443284
QF Loss                      233.98004
VF Loss                      35.488136
Policy Loss                  -208.77776
Q Predictions Mean           206.01566
Q Predictions Std            32.38121
Q Predictions Max            259.89194
Q Predictions Min            -30.990711
V Predictions Mean           208.38412
V Predictions Std            32.25189
V Predictions Max            265.0374
V Predictions Min            -110.498055
Log Pis Mean                 -3.2332573
Log Pis Std                  1.7271649
Log Pis Max                  3.2953906
Log Pis Min                  -8.970548
Policy mu Mean               0.053399127
Policy mu Std                0.33935666
Policy mu Max                1.4635673
Policy mu Min                -1.7957724
Policy log std Mean          -0.7222102
Policy log std Std           0.1412551
Policy log std Max           -0.26181477
Policy log std Min           -1.6006993
Z mean eval                  0.71026254
Z variance eval              0.009848932
total_rewards                [210.34923685  83.13503295  65.24515202 101.6459953  330.45727328
 322.16998538 277.20218544  32.565091   382.91847755 226.27780952]
total_rewards_mean           203.19662392951662
total_rewards_std            118.98892673180261
total_rewards_max            382.9184775499112
total_rewards_min            32.565090999306676
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               28.449849078897387
(Previous) Eval Time (s)     21.359467243310064
Sample Time (s)              18.08360978960991
Epoch Time (s)               67.89292611181736
Total Train Time (s)         1180.1226809867658
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:35:11.481671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #17 | Epoch Duration: 66.51638913154602
2020-01-11 03:35:11.481889 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7109053
Z variance train             0.009838758
KL Divergence                12.4456415
KL Loss                      1.2445642
QF Loss                      185.30629
VF Loss                      28.986546
Policy Loss                  -222.26201
Q Predictions Mean           219.27486
Q Predictions Std            27.078827
Q Predictions Max            273.61908
Q Predictions Min            -48.352512
V Predictions Mean           220.71852
V Predictions Std            26.383245
V Predictions Max            271.82047
V Predictions Min            -61.301167
Log Pis Mean                 -3.0656972
Log Pis Std                  2.0124834
Log Pis Max                  14.894779
Log Pis Min                  -10.005009
Policy mu Mean               0.03598152
Policy mu Std                0.33536142
Policy mu Max                2.2286584
Policy mu Min                -2.5230548
Policy log std Mean          -0.7267268
Policy log std Std           0.13806933
Policy log std Max           -0.39144304
Policy log std Min           -1.6582252
Z mean eval                  0.7193595
Z variance eval              0.010459467
total_rewards                [ 36.96947051  78.54057899  37.7533013    4.54891089  16.20566784
  24.83375482 143.87058763  79.88123891  56.15764637  34.87728003]
total_rewards_mean           51.36384372968655
total_rewards_std            38.6369350389794
total_rewards_max            143.87058762832316
total_rewards_min            4.548910894629974
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               26.770887195132673
(Previous) Eval Time (s)     19.98260773019865
Sample Time (s)              19.801727114245296
Epoch Time (s)               66.55522203957662
Total Train Time (s)         1246.276926830411
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:17.637471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #18 | Epoch Duration: 66.15541195869446
2020-01-11 03:36:17.637665 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72472054
Z variance train             0.010450283
KL Divergence                12.833864
KL Loss                      1.2833865
QF Loss                      236.22527
VF Loss                      76.334435
Policy Loss                  -232.2547
Q Predictions Mean           225.35959
Q Predictions Std            25.552698
Q Predictions Max            288.91867
Q Predictions Min            1.5154634
V Predictions Mean           226.27019
V Predictions Std            23.444933
V Predictions Max            292.5475
V Predictions Min            61.232388
Log Pis Mean                 -3.01473
Log Pis Std                  1.8805358
Log Pis Max                  8.33905
Log Pis Min                  -8.687319
Policy mu Mean               0.014879188
Policy mu Std                0.36196807
Policy mu Max                2.1950548
Policy mu Min                -1.2122825
Policy log std Mean          -0.73605955
Policy log std Std           0.14597315
Policy log std Max           -0.3454131
Policy log std Min           -1.6585814
Z mean eval                  0.7293374
Z variance eval              0.012279026
total_rewards                [ 67.81308932 167.01725478  91.08097111 172.92004223 306.58120793
 301.67379042 237.41620852  74.06614161 331.83282391  63.52524691]
total_rewards_mean           181.39267767248933
total_rewards_std            101.31992397526702
total_rewards_max            331.8328239101088
total_rewards_min            63.52524691370002
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               27.8594450391829
(Previous) Eval Time (s)     19.582483114674687
Sample Time (s)              17.964899419806898
Epoch Time (s)               65.40682757366449
Total Train Time (s)         1317.667057198938
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:37:29.028680 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #19 | Epoch Duration: 71.39084911346436
2020-01-11 03:37:29.028903 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.72803175
Z variance train             0.012268839
KL Divergence                12.727528
KL Loss                      1.2727528
QF Loss                      156.61862
VF Loss                      48.11882
Policy Loss                  -233.22481
Q Predictions Mean           230.65811
Q Predictions Std            30.903418
Q Predictions Max            297.40674
Q Predictions Min            -9.352205
V Predictions Mean           234.67012
V Predictions Std            27.117731
V Predictions Max            295.58344
V Predictions Min            19.175674
Log Pis Mean                 -2.9144242
Log Pis Std                  1.8515092
Log Pis Max                  3.3475566
Log Pis Min                  -9.624564
Policy mu Mean               0.034603864
Policy mu Std                0.33342487
Policy mu Max                1.5425142
Policy mu Min                -1.402113
Policy log std Mean          -0.768944
Policy log std Std           0.12126361
Policy log std Max           -0.39748865
Policy log std Min           -1.3821671
Z mean eval                  0.748752
Z variance eval              0.014075378
total_rewards                [285.8004526  105.27294428  55.68544619  11.9612765  141.99221693
 279.19107335 128.92930601 162.64663554 333.29914618 228.10933157]
total_rewards_mean           173.28878291584675
total_rewards_std            100.01326752960613
total_rewards_max            333.29914618485793
total_rewards_min            11.961276501660977
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               28.32223001914099
(Previous) Eval Time (s)     25.566187248099595
Sample Time (s)              18.014545517973602
Epoch Time (s)               71.90296278521419
Total Train Time (s)         1387.1957493536174
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:38:38.558104 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #20 | Epoch Duration: 69.52903413772583
2020-01-11 03:38:38.558303 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7451602
Z variance train             0.014067242
KL Divergence                12.673101
KL Loss                      1.2673101
QF Loss                      197.9515
VF Loss                      79.746666
Policy Loss                  -234.4805
Q Predictions Mean           231.6966
Q Predictions Std            37.157845
Q Predictions Max            283.7031
Q Predictions Min            -17.691284
V Predictions Mean           237.48476
V Predictions Std            31.311888
V Predictions Max            285.87686
V Predictions Min            27.934252
Log Pis Mean                 -2.8665183
Log Pis Std                  1.8115149
Log Pis Max                  3.5061545
Log Pis Min                  -8.313202
Policy mu Mean               -0.0006065613
Policy mu Std                0.3210416
Policy mu Max                1.1892976
Policy mu Min                -1.2198368
Policy log std Mean          -0.7571856
Policy log std Std           0.15314043
Policy log std Max           -0.41159606
Policy log std Min           -1.6240695
Z mean eval                  0.7580375
Z variance eval              0.018518653
total_rewards                [162.82046148  16.65744174 116.85255595 374.35972847 305.90886798
  90.7011549   92.67959118  87.07266002 416.6362295   90.09157319]
total_rewards_mean           175.37802644076106
total_rewards_std            131.41290143529054
total_rewards_max            416.6362294975662
total_rewards_min            16.657441738619212
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               28.588295630179346
(Previous) Eval Time (s)     23.19198343111202
Sample Time (s)              18.85999903595075
Epoch Time (s)               70.64027809724212
Total Train Time (s)         1460.0477204890922
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:39:51.412863 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #21 | Epoch Duration: 72.85439991950989
2020-01-11 03:39:51.413147 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7606193
Z variance train             0.018565113
KL Divergence                13.043941
KL Loss                      1.3043941
QF Loss                      165.19003
VF Loss                      52.61403
Policy Loss                  -249.91528
Q Predictions Mean           247.29309
Q Predictions Std            31.09944
Q Predictions Max            306.60385
Q Predictions Min            -12.391284
V Predictions Mean           248.25667
V Predictions Std            29.070091
V Predictions Max            305.3214
V Predictions Min            -3.0749936
Log Pis Mean                 -3.1697474
Log Pis Std                  1.5416833
Log Pis Max                  1.9370449
Log Pis Min                  -7.5658283
Policy mu Mean               0.045888465
Policy mu Std                0.32297447
Policy mu Max                1.0278764
Policy mu Min                -1.7198079
Policy log std Mean          -0.72098887
Policy log std Std           0.12221545
Policy log std Max           -0.35186893
Policy log std Min           -1.5748951
Z mean eval                  0.76344836
Z variance eval              0.015128831
total_rewards                [204.31602316 103.05691785 -30.92436493 131.02246692 123.66251747
 362.1187438   23.90046009  80.51399952  76.87177353 369.18851955]
total_rewards_mean           144.37270569574645
total_rewards_std            125.59448984770096
total_rewards_max            369.1885195498377
total_rewards_min            -30.924364930484234
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               28.244730638805777
(Previous) Eval Time (s)     25.40576889924705
Sample Time (s)              18.55090286117047
Epoch Time (s)               72.2014023992233
Total Train Time (s)         1528.1538036484271
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:40:59.520135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #22 | Epoch Duration: 68.10676980018616
2020-01-11 03:40:59.520353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #22 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75995666
Z variance train             0.015054673
KL Divergence                13.184206
KL Loss                      1.3184206
QF Loss                      405.34247
VF Loss                      61.547997
Policy Loss                  -249.15596
Q Predictions Mean           246.17238
Q Predictions Std            29.106161
Q Predictions Max            298.52466
Q Predictions Min            -20.918173
V Predictions Mean           252.4101
V Predictions Std            26.064615
V Predictions Max            298.70825
V Predictions Min            18.406628
Log Pis Mean                 -2.906857
Log Pis Std                  1.6232436
Log Pis Max                  1.7773979
Log Pis Min                  -7.7317166
Policy mu Mean               0.0069695185
Policy mu Std                0.32273653
Policy mu Max                1.0825757
Policy mu Min                -1.2719525
Policy log std Mean          -0.75098616
Policy log std Std           0.13049361
Policy log std Max           -0.4243511
Policy log std Min           -1.7053806
Z mean eval                  0.739631
Z variance eval              0.014698912
total_rewards                [355.36089997 116.94542552  55.27625328 188.52924141 158.3982388
 189.37969432  81.93391652  82.57953375  95.67789694 275.31604009]
total_rewards_mean           159.93971405959084
total_rewards_std            90.65849001968445
total_rewards_max            355.3608999741153
total_rewards_min            55.27625328107531
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               27.786528019234538
(Previous) Eval Time (s)     21.310829661786556
Sample Time (s)              18.693867267575115
Epoch Time (s)               67.79122494859621
Total Train Time (s)         1599.1637954819016
Epoch                        23
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:10.531927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #23 | Epoch Duration: 71.0114016532898
2020-01-11 03:42:10.532124 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.74161875
Z variance train             0.0146800475
KL Divergence                12.693905
KL Loss                      1.2693905
QF Loss                      174.94424
VF Loss                      58.60338
Policy Loss                  -256.6574
Q Predictions Mean           252.08908
Q Predictions Std            29.561289
Q Predictions Max            306.6537
Q Predictions Min            -9.410652
V Predictions Mean           258.20245
V Predictions Std            30.1722
V Predictions Max            316.4161
V Predictions Min            24.670963
Log Pis Mean                 -2.7622693
Log Pis Std                  1.520641
Log Pis Max                  3.8383126
Log Pis Min                  -8.559996
Policy mu Mean               0.011537492
Policy mu Std                0.3416359
Policy mu Max                2.1310303
Policy mu Min                -1.5964568
Policy log std Mean          -0.7411953
Policy log std Std           0.12994018
Policy log std Max           -0.39049596
Policy log std Min           -1.4497437
Z mean eval                  0.7485394
Z variance eval              0.015585186
total_rewards                [265.27969066 306.96841571 121.91733363  80.50578446  80.94463564
   9.01189208  23.67835925  29.26754493 334.01247403 151.65401159]
total_rewards_mean           140.32401419871317
total_rewards_std            114.74032623584272
total_rewards_max            334.0124740324415
total_rewards_min            9.011892082345208
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               28.629480347968638
(Previous) Eval Time (s)     24.530726076103747
Sample Time (s)              17.757304337807
Epoch Time (s)               70.91751076187938
Total Train Time (s)         1664.2884180345573
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:43:15.656841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #24 | Epoch Duration: 65.12452387809753
2020-01-11 03:43:15.657148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.75126064
Z variance train             0.015575742
KL Divergence                13.6505575
KL Loss                      1.3650558
QF Loss                      352.50134
VF Loss                      47.772385
Policy Loss                  -253.19876
Q Predictions Mean           250.65405
Q Predictions Std            42.312073
Q Predictions Max            321.40988
Q Predictions Min            -29.354832
V Predictions Mean           249.70818
V Predictions Std            40.526394
V Predictions Max            315.51523
V Predictions Min            -30.268946
Log Pis Mean                 -2.5805027
Log Pis Std                  1.828088
Log Pis Max                  8.943451
Log Pis Min                  -7.941637
Policy mu Mean               0.025180906
Policy mu Std                0.33519953
Policy mu Max                2.126047
Policy mu Min                -1.7749556
Policy log std Mean          -0.779299
Policy log std Std           0.13995592
Policy log std Max           -0.4512185
Policy log std Min           -1.6189661
Z mean eval                  0.7652315
Z variance eval              0.013945426
total_rewards                [150.62512464 177.06131979 158.53774804 111.8102991  150.49759813
 269.53489721 212.73601121 461.0063713  116.69506522 203.72082234]
total_rewards_mean           201.22252569923592
total_rewards_std            97.45323781014369
total_rewards_max            461.0063712975957
total_rewards_min            111.81029910050478
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               30.10825598007068
(Previous) Eval Time (s)     18.737423228099942
Sample Time (s)              18.657793413382024
Epoch Time (s)               67.50347262155265
Total Train Time (s)         1737.755612990819
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:29.126075 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #25 | Epoch Duration: 73.46868205070496
2020-01-11 03:44:29.126333 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7671998
Z variance train             0.013943056
KL Divergence                14.452051
KL Loss                      1.4452051
QF Loss                      125.30353
VF Loss                      57.41455
Policy Loss                  -268.5525
Q Predictions Mean           264.02426
Q Predictions Std            40.324284
Q Predictions Max            338.7571
Q Predictions Min            -6.264393
V Predictions Mean           265.84335
V Predictions Std            34.314533
V Predictions Max            328.62518
V Predictions Min            13.52258
Log Pis Mean                 -3.0505385
Log Pis Std                  2.0271177
Log Pis Max                  10.56304
Log Pis Min                  -10.020205
Policy mu Mean               0.034904655
Policy mu Std                0.34602568
Policy mu Max                1.8879055
Policy mu Min                -2.4926836
Policy log std Mean          -0.7365954
Policy log std Std           0.14738698
Policy log std Max           -0.41419873
Policy log std Min           -1.8539121
Z mean eval                  0.7759563
Z variance eval              0.01866042
total_rewards                [219.72985544 -71.74920805 213.28855865 181.63845249 189.12837537
 149.45783177 277.15021392 242.33216753 238.33432962 200.72515692]
total_rewards_mean           184.00357336583482
total_rewards_std            91.69443408659173
total_rewards_max            277.1502139195471
total_rewards_min            -71.74920804843367
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               26.763115728273988
(Previous) Eval Time (s)     24.702343795914203
Sample Time (s)              18.184475107118487
Epoch Time (s)               69.64993463130668
Total Train Time (s)         1810.9634965872392
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:45:42.334294 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #26 | Epoch Duration: 73.20777440071106
2020-01-11 03:45:42.334494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77781254
Z variance train             0.018764269
KL Divergence                14.789951
KL Loss                      1.4789952
QF Loss                      154.86755
VF Loss                      44.472855
Policy Loss                  -277.54874
Q Predictions Mean           274.6021
Q Predictions Std            31.11767
Q Predictions Max            328.51895
Q Predictions Min            -5.77285
V Predictions Mean           274.04694
V Predictions Std            29.622057
V Predictions Max            333.7296
V Predictions Min            -3.580032
Log Pis Mean                 -2.8420212
Log Pis Std                  1.8740761
Log Pis Max                  5.676107
Log Pis Min                  -9.852439
Policy mu Mean               0.054800574
Policy mu Std                0.34094942
Policy mu Max                1.7994422
Policy mu Min                -1.8188704
Policy log std Mean          -0.754624
Policy log std Std           0.15707599
Policy log std Max           -0.42197204
Policy log std Min           -1.8445907
Z mean eval                  0.784774
Z variance eval              0.017804269
total_rewards                [228.70116868 274.25057621 246.35571382 158.96786416  65.51500837
  98.11993687 308.11686734 327.4726165  250.30073903  95.66983938]
total_rewards_mean           205.34703303638517
total_rewards_std            89.27637865956473
total_rewards_max            327.4726164986696
total_rewards_min            65.51500836871367
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               27.873672848101705
(Previous) Eval Time (s)     28.259893426205963
Sample Time (s)              18.32898649573326
Epoch Time (s)               74.46255277004093
Total Train Time (s)         1882.463045461569
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:46:53.833984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #27 | Epoch Duration: 71.49934959411621
2020-01-11 03:46:53.834137 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7850268
Z variance train             0.01778864
KL Divergence                15.229598
KL Loss                      1.5229598
QF Loss                      388.01218
VF Loss                      97.185844
Policy Loss                  -282.4482
Q Predictions Mean           278.28503
Q Predictions Std            32.75839
Q Predictions Max            330.7655
Q Predictions Min            8.865522
V Predictions Mean           280.69135
V Predictions Std            28.489902
V Predictions Max            334.3245
V Predictions Min            35.119953
Log Pis Mean                 -2.7555573
Log Pis Std                  1.7200489
Log Pis Max                  3.9272196
Log Pis Min                  -7.513995
Policy mu Mean               0.047942042
Policy mu Std                0.3584079
Policy mu Max                1.8640476
Policy mu Min                -1.2806234
Policy log std Mean          -0.7513478
Policy log std Std           0.1265368
Policy log std Max           -0.44503015
Policy log std Min           -1.3245828
Z mean eval                  0.7786517
Z variance eval              0.015273402
total_rewards                [322.65398276 162.57982948 256.54174474  19.74189226 185.41627771
 226.20205376  89.72408786 218.85954913 140.48663003 146.06524545]
total_rewards_mean           176.82712931699945
total_rewards_std            81.62774927495961
total_rewards_max            322.6539827591292
total_rewards_min            19.741892260041293
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               26.68394313706085
(Previous) Eval Time (s)     25.296388660091907
Sample Time (s)              17.699599695857614
Epoch Time (s)               69.67993149301037
Total Train Time (s)         1952.1252978867851
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:48:03.498622 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #28 | Epoch Duration: 69.66435146331787
2020-01-11 03:48:03.498816 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7809794
Z variance train             0.015278704
KL Divergence                14.738406
KL Loss                      1.4738406
QF Loss                      136.45888
VF Loss                      47.273197
Policy Loss                  -288.73328
Q Predictions Mean           283.6267
Q Predictions Std            33.44206
Q Predictions Max            340.58917
Q Predictions Min            -38.949596
V Predictions Mean           285.34955
V Predictions Std            27.578405
V Predictions Max            350.3904
V Predictions Min            59.84125
Log Pis Mean                 -2.9582672
Log Pis Std                  1.5484574
Log Pis Max                  2.5507705
Log Pis Min                  -8.625285
Policy mu Mean               0.046379216
Policy mu Std                0.3209607
Policy mu Max                1.1426018
Policy mu Min                -1.4782823
Policy log std Mean          -0.7394495
Policy log std Std           0.13637923
Policy log std Max           -0.36781466
Policy log std Min           -1.6526048
Z mean eval                  0.7699901
Z variance eval              0.013746428
total_rewards                [246.66360295 198.01772681 188.41250238 451.02907144 426.07026893
 250.1201469  341.91748431 261.45930937 460.02969632 333.17969841]
total_rewards_mean           315.6899507821487
total_rewards_std            97.14912694136119
total_rewards_max            460.0296963193616
total_rewards_min            188.41250237533598
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               25.926625015679747
(Previous) Eval Time (s)     25.28052101098001
Sample Time (s)              19.019168213009834
Epoch Time (s)               70.22631423966959
Total Train Time (s)         2021.0735512236133
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:49:12.448410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #29 | Epoch Duration: 68.94942569732666
2020-01-11 03:49:12.448651 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7658783
Z variance train             0.0137972785
KL Divergence                14.860693
KL Loss                      1.4860693
QF Loss                      162.3968
VF Loss                      31.86914
Policy Loss                  -281.66705
Q Predictions Mean           279.57898
Q Predictions Std            33.1799
Q Predictions Max            343.11212
Q Predictions Min            -19.590673
V Predictions Mean           283.51834
V Predictions Std            32.1938
V Predictions Max            343.18594
V Predictions Min            -24.702333
Log Pis Mean                 -2.9646575
Log Pis Std                  1.7400949
Log Pis Max                  7.8213367
Log Pis Min                  -9.93593
Policy mu Mean               0.053396158
Policy mu Std                0.3204567
Policy mu Max                1.7102147
Policy mu Min                -1.6427199
Policy log std Mean          -0.7392926
Policy log std Std           0.13603288
Policy log std Max           -0.23520611
Policy log std Min           -1.6357927
Z mean eval                  0.7738697
Z variance eval              0.02026751
total_rewards                [ 54.55975132 433.86749084 535.2733309  184.46343164 213.97248889
 141.55532036 165.39954972 394.88310947 367.85811088 254.94852482]
total_rewards_mean           274.67811088467937
total_rewards_std            143.77467525012491
total_rewards_max            535.2733308981489
total_rewards_min            54.55975131777895
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               24.487768333870918
(Previous) Eval Time (s)     24.003323103301227
Sample Time (s)              18.0525656118989
Epoch Time (s)               66.54365704907104
Total Train Time (s)         2084.4483446185477
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:15.823069 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #30 | Epoch Duration: 63.37422823905945
2020-01-11 03:50:15.823254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.77263224
Z variance train             0.020372901
KL Divergence                14.40239
KL Loss                      1.440239
QF Loss                      117.51446
VF Loss                      68.321045
Policy Loss                  -293.63455
Q Predictions Mean           290.57843
Q Predictions Std            39.236668
Q Predictions Max            341.0071
Q Predictions Min            -13.509363
V Predictions Mean           291.88507
V Predictions Std            37.814137
V Predictions Max            343.72836
V Predictions Min            -41.970776
Log Pis Mean                 -2.8492913
Log Pis Std                  1.6587346
Log Pis Max                  4.0810885
Log Pis Min                  -7.394895
Policy mu Mean               0.094547614
Policy mu Std                0.34680784
Policy mu Max                2.4639869
Policy mu Min                -2.2069185
Policy log std Mean          -0.74679935
Policy log std Std           0.15543489
Policy log std Max           0.01631555
Policy log std Min           -1.7076864
Z mean eval                  0.7985636
Z variance eval              0.016128482
total_rewards                [239.64708349 226.44496784 334.24396764 516.68411483 320.11940186
 353.46401003 478.51475961 209.23942832 201.41039963 239.91803593]
total_rewards_mean           311.9686169178049
total_rewards_std            106.03911424414076
total_rewards_max            516.6841148295854
total_rewards_min            201.41039962678082
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               26.230613856576383
(Previous) Eval Time (s)     20.83361671678722
Sample Time (s)              19.155642635654658
Epoch Time (s)               66.21987320901826
Total Train Time (s)         2156.641087961849
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:51:28.018149 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #31 | Epoch Duration: 72.19473576545715
2020-01-11 03:51:28.018358 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.796374
Z variance train             0.016122315
KL Divergence                15.027939
KL Loss                      1.5027939
QF Loss                      156.96738
VF Loss                      50.340324
Policy Loss                  -297.0927
Q Predictions Mean           295.10446
Q Predictions Std            21.458134
Q Predictions Max            363.33072
Q Predictions Min            226.10008
V Predictions Mean           302.11597
V Predictions Std            22.42754
V Predictions Max            367.20236
V Predictions Min            220.77332
Log Pis Mean                 -2.9117777
Log Pis Std                  1.6610363
Log Pis Max                  2.6073208
Log Pis Min                  -9.355399
Policy mu Mean               0.02291039
Policy mu Std                0.31791502
Policy mu Max                1.1057758
Policy mu Min                -1.0338318
Policy log std Mean          -0.77831364
Policy log std Std           0.1477217
Policy log std Max           -0.33850408
Policy log std Min           -1.5744648
Z mean eval                  0.81349814
Z variance eval              0.014644829
total_rewards                [256.97508517 231.03154218 180.60297095 186.67219733 372.56212197
 397.95959293 150.22484902 155.50275539 181.3563338   28.33417146]
total_rewards_mean           214.122162019577
total_rewards_std            102.96049590941092
total_rewards_max            397.9595929273419
total_rewards_min            28.334171461525862
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               27.5904444437474
(Previous) Eval Time (s)     26.80814232910052
Sample Time (s)              19.245804839767516
Epoch Time (s)               73.64439161261544
Total Train Time (s)         2229.246109861415
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:40.626941 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #32 | Epoch Duration: 72.60826778411865
2020-01-11 03:52:40.627391 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81126225
Z variance train             0.014692453
KL Divergence                14.8645
KL Loss                      1.4864501
QF Loss                      94.33034
VF Loss                      54.623405
Policy Loss                  -301.4431
Q Predictions Mean           300.48248
Q Predictions Std            33.928215
Q Predictions Max            358.8151
Q Predictions Min            -13.603962
V Predictions Mean           306.88742
V Predictions Std            29.111578
V Predictions Max            366.88916
V Predictions Min            56.27022
Log Pis Mean                 -3.159423
Log Pis Std                  1.6764936
Log Pis Max                  5.0393066
Log Pis Min                  -9.460457
Policy mu Mean               0.061121017
Policy mu Std                0.29598722
Policy mu Max                1.3468851
Policy mu Min                -1.4158834
Policy log std Mean          -0.75133514
Policy log std Std           0.12773114
Policy log std Max           -0.3566537
Policy log std Min           -1.4091214
Z mean eval                  0.79580534
Z variance eval              0.0118832365
total_rewards                [316.34061312  44.72056029 200.31792138  47.01018111 295.43119991
 539.78931339 536.00526097 177.71493012 231.0851563  413.63402648]
total_rewards_mean           280.20491630463926
total_rewards_std            167.7171362089707
total_rewards_max            539.7893133924937
total_rewards_min            44.720560286652955
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               25.725533698685467
(Previous) Eval Time (s)     25.771705746185035
Sample Time (s)              18.984671857208014
Epoch Time (s)               70.48191130207852
Total Train Time (s)         2296.080437990371
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:53:47.461712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #33 | Epoch Duration: 66.83406281471252
2020-01-11 03:53:47.461944 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.79991406
Z variance train             0.011840081
KL Divergence                15.390139
KL Loss                      1.5390139
QF Loss                      302.37915
VF Loss                      94.49457
Policy Loss                  -308.41412
Q Predictions Mean           303.8765
Q Predictions Std            34.93788
Q Predictions Max            391.10727
Q Predictions Min            -2.4655972
V Predictions Mean           301.9819
V Predictions Std            34.58567
V Predictions Max            394.09283
V Predictions Min            15.07126
Log Pis Mean                 -2.829511
Log Pis Std                  1.5562015
Log Pis Max                  6.277613
Log Pis Min                  -8.520113
Policy mu Mean               0.029291047
Policy mu Std                0.328224
Policy mu Max                1.155629
Policy mu Min                -3.037689
Policy log std Mean          -0.7708024
Policy log std Std           0.13806044
Policy log std Max           -0.3984789
Policy log std Min           -1.7296336
Z mean eval                  0.7997624
Z variance eval              0.011469017
total_rewards                [613.62049689 204.33169356 474.81927735 102.48343758 217.87224871
 273.01423844 322.80671268 285.76910522 284.26520713 276.52315761]
total_rewards_mean           305.55055751748057
total_rewards_std            136.29795868105407
total_rewards_max            613.6204968937537
total_rewards_min            102.48343758005977
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               27.72141413995996
(Previous) Eval Time (s)     22.123562355991453
Sample Time (s)              18.45872044097632
Epoch Time (s)               68.30369693692774
Total Train Time (s)         2365.585138650611
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:54:56.969721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #34 | Epoch Duration: 69.50745248794556
2020-01-11 03:54:56.970142 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7988483
Z variance train             0.01149949
KL Divergence                15.380762
KL Loss                      1.5380763
QF Loss                      162.1677
VF Loss                      38.29681
Policy Loss                  -308.3271
Q Predictions Mean           305.653
Q Predictions Std            38.80897
Q Predictions Max            373.50406
Q Predictions Min            0.24111721
V Predictions Mean           307.42456
V Predictions Std            35.298454
V Predictions Max            369.7358
V Predictions Min            -9.853882
Log Pis Mean                 -2.759622
Log Pis Std                  1.9448377
Log Pis Max                  8.825727
Log Pis Min                  -8.228796
Policy mu Mean               0.051096562
Policy mu Std                0.32848912
Policy mu Max                1.6467946
Policy mu Min                -1.8291388
Policy log std Mean          -0.7750391
Policy log std Std           0.142983
Policy log std Max           -0.37977204
Policy log std Min           -1.8589388
Z mean eval                  0.7863915
Z variance eval              0.014677035
total_rewards                [ 45.42789095  57.74303645 129.28560598 295.98736002 309.27049057
 133.33979033 294.45675153 347.4381112  188.12374443 222.39329683]
total_rewards_mean           202.34660782963434
total_rewards_std            102.94407078328433
total_rewards_max            347.4381112027812
total_rewards_min            45.42789094730747
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               28.903704093769193
(Previous) Eval Time (s)     23.326994626782835
Sample Time (s)              18.512391277123243
Epoch Time (s)               70.74308999767527
Total Train Time (s)         2431.3872176506557
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:56:02.774772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #35 | Epoch Duration: 65.8043463230133
2020-01-11 03:56:02.775109 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7817628
Z variance train             0.014581867
KL Divergence                15.103876
KL Loss                      1.5103877
QF Loss                      163.1334
VF Loss                      58.873985
Policy Loss                  -310.9073
Q Predictions Mean           307.81152
Q Predictions Std            34.372643
Q Predictions Max            394.34625
Q Predictions Min            -1.195832
V Predictions Mean           316.51532
V Predictions Std            31.102024
V Predictions Max            399.46677
V Predictions Min            28.62391
Log Pis Mean                 -3.081427
Log Pis Std                  1.8621163
Log Pis Max                  6.7654676
Log Pis Min                  -10.327641
Policy mu Mean               0.06354298
Policy mu Std                0.31919622
Policy mu Max                1.2899609
Policy mu Min                -1.4253762
Policy log std Mean          -0.7758134
Policy log std Std           0.13305938
Policy log std Max           -0.4254352
Policy log std Min           -1.9822227
Z mean eval                  0.8120845
Z variance eval              0.01190261
total_rewards                [562.957137   574.08100413 228.13345458 232.80350897 242.24291575
 256.71578652   7.82587268  95.4400667  178.3115125  229.17575981]
total_rewards_mean           260.7687018640612
total_rewards_std            170.52862687615837
total_rewards_max            574.0810041313963
total_rewards_min            7.825872676862154
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               30.29506926704198
(Previous) Eval Time (s)     18.387960937805474
Sample Time (s)              19.088959247339517
Epoch Time (s)               67.77198945218697
Total Train Time (s)         2501.7840570546687
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:57:13.171645 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #36 | Epoch Duration: 70.39615535736084
2020-01-11 03:57:13.172011 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81133974
Z variance train             0.011868821
KL Divergence                15.486149
KL Loss                      1.5486149
QF Loss                      130.61353
VF Loss                      41.77863
Policy Loss                  -316.76913
Q Predictions Mean           311.59702
Q Predictions Std            44.480675
Q Predictions Max            369.1749
Q Predictions Min            -24.94041
V Predictions Mean           317.10315
V Predictions Std            34.655445
V Predictions Max            377.9884
V Predictions Min            22.854246
Log Pis Mean                 -2.9062238
Log Pis Std                  1.7159638
Log Pis Max                  6.569688
Log Pis Min                  -7.122958
Policy mu Mean               0.044092387
Policy mu Std                0.31266814
Policy mu Max                1.1552476
Policy mu Min                -1.6050397
Policy log std Mean          -0.76144445
Policy log std Std           0.15449
Policy log std Max           -0.3784804
Policy log std Min           -1.9403936
Z mean eval                  0.7899966
Z variance eval              0.015322109
total_rewards                [ 71.78107232  52.17822558 259.90110502 195.36848702 260.41572054
 248.18817227 537.55232662 126.55112909 344.49930133 425.06950693]
total_rewards_mean           252.15050467329792
total_rewards_std            145.4472455712616
total_rewards_max            537.5523266249579
total_rewards_min            52.17822558209087
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               26.654523170087487
(Previous) Eval Time (s)     21.01183094503358
Sample Time (s)              18.40460590366274
Epoch Time (s)               66.07096001878381
Total Train Time (s)         2568.8169862418436
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:58:20.205346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #37 | Epoch Duration: 67.033123254776
2020-01-11 03:58:20.205581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7898148
Z variance train             0.015410727
KL Divergence                15.478196
KL Loss                      1.5478196
QF Loss                      109.59188
VF Loss                      82.6082
Policy Loss                  -319.04422
Q Predictions Mean           316.33594
Q Predictions Std            34.28622
Q Predictions Max            396.79272
Q Predictions Min            31.516495
V Predictions Mean           324.83624
V Predictions Std            29.43903
V Predictions Max            402.11508
V Predictions Min            112.826454
Log Pis Mean                 -2.7948074
Log Pis Std                  1.7569478
Log Pis Max                  4.8748126
Log Pis Min                  -7.731574
Policy mu Mean               0.05564673
Policy mu Std                0.32502094
Policy mu Max                2.196056
Policy mu Min                -1.7143375
Policy log std Mean          -0.7788903
Policy log std Std           0.14874274
Policy log std Max           -0.37732953
Policy log std Min           -1.9650885
Z mean eval                  0.7974572
Z variance eval              0.016433844
total_rewards                [536.71314164 373.74217949 197.56421407 628.89521622 279.18873869
 455.13693211 192.76406104 315.65564778 375.76890744 216.61326418]
total_rewards_mean           357.20423026537543
total_rewards_std            140.12581190152017
total_rewards_max            628.8952162185373
total_rewards_min            192.76406104015865
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               25.172023478895426
(Previous) Eval Time (s)     21.97370264073834
Sample Time (s)              17.87066791485995
Epoch Time (s)               65.01639403449371
Total Train Time (s)         2637.585715209134
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:59:28.975094 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #38 | Epoch Duration: 68.76926612854004
2020-01-11 03:59:28.975346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7983228
Z variance train             0.016434748
KL Divergence                15.439045
KL Loss                      1.5439045
QF Loss                      166.85406
VF Loss                      35.512405
Policy Loss                  -322.5543
Q Predictions Mean           317.89627
Q Predictions Std            37.074757
Q Predictions Max            396.14148
Q Predictions Min            -5.249235
V Predictions Mean           319.91785
V Predictions Std            33.430374
V Predictions Max            393.24738
V Predictions Min            0.78805536
Log Pis Mean                 -2.8286085
Log Pis Std                  1.6550952
Log Pis Max                  1.6653223
Log Pis Min                  -9.006538
Policy mu Mean               0.044833552
Policy mu Std                0.3074588
Policy mu Max                1.9553895
Policy mu Min                -1.6371406
Policy log std Mean          -0.8154963
Policy log std Std           0.14278194
Policy log std Max           -0.48251134
Policy log std Min           -1.5990126
Z mean eval                  0.8081606
Z variance eval              0.014622383
total_rewards                [345.06697124  47.19311089 174.00043865 483.69279695 633.43899052
 166.92123444 500.33033638 171.31981944  64.10140449 241.50263285]
total_rewards_mean           282.7567735846487
total_rewards_std            189.0080526671105
total_rewards_max            633.4389905222487
total_rewards_min            47.1931108947941
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               28.036943424958736
(Previous) Eval Time (s)     25.726241477765143
Sample Time (s)              19.01010990748182
Epoch Time (s)               72.7732948102057
Total Train Time (s)         2700.247945719864
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:00:31.637588 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #39 | Epoch Duration: 62.66209578514099
2020-01-11 04:00:31.637748 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8079885
Z variance train             0.014617458
KL Divergence                16.042326
KL Loss                      1.6042327
QF Loss                      167.35788
VF Loss                      57.86468
Policy Loss                  -326.64975
Q Predictions Mean           325.07526
Q Predictions Std            29.81944
Q Predictions Max            398.6382
Q Predictions Min            8.82721
V Predictions Mean           328.19287
V Predictions Std            29.824434
V Predictions Max            396.4111
V Predictions Min            14.335817
Log Pis Mean                 -2.7607412
Log Pis Std                  1.6911871
Log Pis Max                  7.8218927
Log Pis Min                  -9.400939
Policy mu Mean               0.021489475
Policy mu Std                0.30881
Policy mu Max                1.4851677
Policy mu Min                -1.5512114
Policy log std Mean          -0.8194401
Policy log std Std           0.15004666
Policy log std Max           -0.3715225
Policy log std Min           -1.8778483
Z mean eval                  0.8223106
Z variance eval              0.018016908
total_rewards                [540.41390684 431.21243277 348.37967472 293.56634132 249.90750478
 175.3651696  482.62280222 451.98019292 114.454731   140.48736145]
total_rewards_mean           322.8390117627205
total_rewards_std            143.7166740810801
total_rewards_max            540.4139068448112
total_rewards_min            114.45473099683792
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               29.03519000299275
(Previous) Eval Time (s)     15.614734085276723
Sample Time (s)              19.301058046519756
Epoch Time (s)               63.95098213478923
Total Train Time (s)         2773.10077460343
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:01:44.491513 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #40 | Epoch Duration: 72.85361576080322
2020-01-11 04:01:44.491708 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #40 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8193482
Z variance train             0.017992038
KL Divergence                16.006649
KL Loss                      1.600665
QF Loss                      161.56693
VF Loss                      24.728008
Policy Loss                  -336.85867
Q Predictions Mean           334.33038
Q Predictions Std            43.966064
Q Predictions Max            403.11295
Q Predictions Min            -8.226973
V Predictions Mean           335.48346
V Predictions Std            42.162888
V Predictions Max            405.11862
V Predictions Min            10.233463
Log Pis Mean                 -2.8226914
Log Pis Std                  1.8026079
Log Pis Max                  6.9778595
Log Pis Min                  -7.835019
Policy mu Mean               -0.0381509
Policy mu Std                0.3290929
Policy mu Max                1.9216088
Policy mu Min                -2.406027
Policy log std Mean          -0.7865526
Policy log std Std           0.14197198
Policy log std Max           -0.40670907
Policy log std Min           -1.8371272
Z mean eval                  0.80505645
Z variance eval              0.019476179
total_rewards                [283.9381733  373.83402489 310.91622822 296.18495913   6.59562442
 249.87479839 272.39814875 273.40140045 187.59148502 161.18304408]
total_rewards_mean           241.5917886645015
total_rewards_std            96.79969276625931
total_rewards_max            373.83402488904153
total_rewards_min            6.595624421566688
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               28.013907020911574
(Previous) Eval Time (s)     24.51706035900861
Sample Time (s)              18.56665640231222
Epoch Time (s)               71.0976237822324
Total Train Time (s)         2843.3488158369437
Epoch                        41
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:02:54.741840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #41 | Epoch Duration: 70.2499487400055
2020-01-11 04:02:54.742063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #41 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80466795
Z variance train             0.01948788
KL Divergence                15.912004
KL Loss                      1.5912005
QF Loss                      144.39706
VF Loss                      42.652977
Policy Loss                  -333.73587
Q Predictions Mean           330.41544
Q Predictions Std            40.99793
Q Predictions Max            417.51883
Q Predictions Min            -29.792728
V Predictions Mean           333.12418
V Predictions Std            35.858604
V Predictions Max            412.97647
V Predictions Min            11.747393
Log Pis Mean                 -2.883854
Log Pis Std                  1.4496377
Log Pis Max                  0.33044976
Log Pis Min                  -8.31875
Policy mu Mean               0.0137185
Policy mu Std                0.30322617
Policy mu Max                1.9117794
Policy mu Min                -1.1377403
Policy log std Mean          -0.77417314
Policy log std Std           0.13503987
Policy log std Max           -0.43046707
Policy log std Min           -1.5060688
Z mean eval                  0.80447114
Z variance eval              0.014865798
total_rewards                [408.62420141 368.68903947 264.63955903 511.62359111 365.47792879
 313.99455755  58.54559514 563.18343605 440.2217012  320.11120427]
total_rewards_mean           361.51108140318837
total_rewards_std            132.97808785098442
total_rewards_max            563.1834360542979
total_rewards_min            58.54559514307448
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               28.422670356929302
(Previous) Eval Time (s)     23.66909060627222
Sample Time (s)              18.180722386110574
Epoch Time (s)               70.2724833493121
Total Train Time (s)         2914.514129581861
Epoch                        42
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:04:05.910801 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #42 | Epoch Duration: 71.16855001449585
2020-01-11 04:04:05.911068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #42 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8047541
Z variance train             0.014865035
KL Divergence                16.736244
KL Loss                      1.6736244
QF Loss                      127.78496
VF Loss                      40.17981
Policy Loss                  -326.85928
Q Predictions Mean           323.7555
Q Predictions Std            56.507496
Q Predictions Max            413.1879
Q Predictions Min            -17.320232
V Predictions Mean           325.77597
V Predictions Std            55.91823
V Predictions Max            410.69055
V Predictions Min            -15.517127
Log Pis Mean                 -2.7433496
Log Pis Std                  1.90336
Log Pis Max                  7.45051
Log Pis Min                  -9.23304
Policy mu Mean               0.03163413
Policy mu Std                0.33421305
Policy mu Max                1.7226882
Policy mu Min                -1.506763
Policy log std Mean          -0.7825661
Policy log std Std           0.15049206
Policy log std Max           -0.280898
Policy log std Min           -1.477716
Z mean eval                  0.81466657
Z variance eval              0.013608192
total_rewards                [ 49.79803576 209.27814045 218.2297276  153.68945515 166.1919987
  88.33252521 381.57950853 417.77242348 180.57350969 253.06679913]
total_rewards_mean           211.85121236984727
total_rewards_std            109.96418374024914
total_rewards_max            417.77242348311506
total_rewards_min            49.798035762160204
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               29.331219749059528
(Previous) Eval Time (s)     24.564867781940848
Sample Time (s)              18.967769879847765
Epoch Time (s)               72.86385741084814
Total Train Time (s)         2984.001841260586
Epoch                        43
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:05:15.397010 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #43 | Epoch Duration: 69.48574686050415
2020-01-11 04:05:15.397159 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #43 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8160682
Z variance train             0.013625774
KL Divergence                16.32885
KL Loss                      1.632885
QF Loss                      255.94595
VF Loss                      44.688625
Policy Loss                  -342.26056
Q Predictions Mean           337.87164
Q Predictions Std            41.254486
Q Predictions Max            411.46725
Q Predictions Min            -0.6582997
V Predictions Mean           338.075
V Predictions Std            39.200317
V Predictions Max            405.34903
V Predictions Min            28.975967
Log Pis Mean                 -2.9625201
Log Pis Std                  1.7323954
Log Pis Max                  6.698341
Log Pis Min                  -7.926832
Policy mu Mean               0.017039597
Policy mu Std                0.3164579
Policy mu Max                1.5591819
Policy mu Min                -1.4768586
Policy log std Mean          -0.7645022
Policy log std Std           0.15865351
Policy log std Max           -0.43566164
Policy log std Min           -1.8523582
Z mean eval                  0.80745
Z variance eval              0.0133001935
total_rewards                [354.11550925 228.64433135 538.22651482 277.80450944 189.3347526
 353.43339702 258.86359118 237.88790688 217.86319425 306.07016222]
total_rewards_mean           296.2243869019182
total_rewards_std            96.20676809973236
total_rewards_max            538.2265148209417
total_rewards_min            189.33475259994094
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               27.89505500625819
(Previous) Eval Time (s)     21.186477091163397
Sample Time (s)              17.728863310534507
Epoch Time (s)               66.8103954079561
Total Train Time (s)         3054.738431226928
Epoch                        44
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:06:26.136825 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #44 | Epoch Duration: 70.73952651023865
2020-01-11 04:06:26.137029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #44 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80768555
Z variance train             0.013281028
KL Divergence                15.95775
KL Loss                      1.595775
QF Loss                      149.64413
VF Loss                      26.272923
Policy Loss                  -344.98923
Q Predictions Mean           342.93982
Q Predictions Std            25.082594
Q Predictions Max            409.33603
Q Predictions Min            258.07874
V Predictions Mean           346.7558
V Predictions Std            25.051443
V Predictions Max            403.9058
V Predictions Min            278.45062
Log Pis Mean                 -2.9411578
Log Pis Std                  1.6731529
Log Pis Max                  3.4907334
Log Pis Min                  -9.002154
Policy mu Mean               0.028811894
Policy mu Std                0.31374604
Policy mu Max                1.1324953
Policy mu Min                -1.0065082
Policy log std Mean          -0.7649702
Policy log std Std           0.13746597
Policy log std Max           -0.3206239
Policy log std Min           -1.6561513
Z mean eval                  0.8091407
Z variance eval              0.012542789
total_rewards                [241.74422359 550.88150603 339.62393306 359.95970935 367.1793015
 414.01205891 330.05686164 595.56996895 487.79204563 197.60972812]
total_rewards_mean           388.4429336768436
total_rewards_std            120.33512079738715
total_rewards_max            595.5699689460167
total_rewards_min            197.60972811652198
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               26.81837469385937
(Previous) Eval Time (s)     25.115316424984485
Sample Time (s)              18.93168356223032
Epoch Time (s)               70.86537468107417
Total Train Time (s)         3127.171344930306
Epoch                        45
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:07:38.569058 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #45 | Epoch Duration: 72.43187808990479
2020-01-11 04:07:38.569259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.80856675
Z variance train             0.0125403255
KL Divergence                16.21865
KL Loss                      1.6218652
QF Loss                      139.58688
VF Loss                      28.012146
Policy Loss                  -350.12186
Q Predictions Mean           348.65607
Q Predictions Std            26.126358
Q Predictions Max            416.1751
Q Predictions Min            244.68503
V Predictions Mean           352.50037
V Predictions Std            26.278131
V Predictions Max            417.64362
V Predictions Min            222.86711
Log Pis Mean                 -2.8541505
Log Pis Std                  1.716267
Log Pis Max                  1.8113286
Log Pis Min                  -8.604999
Policy mu Mean               0.023205679
Policy mu Std                0.31586716
Policy mu Max                1.2589817
Policy mu Min                -1.6372228
Policy log std Mean          -0.7945501
Policy log std Std           0.15248863
Policy log std Max           -0.37793043
Policy log std Min           -1.863426
Z mean eval                  0.8111132
Z variance eval              0.010555501
total_rewards                [249.56712657 152.07501166 194.50436514 228.89942055 291.49648855
 573.4394406  309.79550791 660.84034873 744.46120664  97.68934437]
total_rewards_mean           350.2768260728431
total_rewards_std            214.23137447338863
total_rewards_max            744.4612066404208
total_rewards_min            97.68934437385919
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               28.66368319839239
(Previous) Eval Time (s)     26.681495619937778
Sample Time (s)              18.397144082468003
Epoch Time (s)               73.74232290079817
Total Train Time (s)         3196.7352440180257
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:08:48.136468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #46 | Epoch Duration: 69.5670690536499
2020-01-11 04:08:48.136682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #46 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8118909
Z variance train             0.010583001
KL Divergence                15.769209
KL Loss                      1.5769209
QF Loss                      117.72101
VF Loss                      78.06004
Policy Loss                  -342.88007
Q Predictions Mean           339.09918
Q Predictions Std            46.152805
Q Predictions Max            404.5696
Q Predictions Min            -15.46731
V Predictions Mean           340.13678
V Predictions Std            43.8095
V Predictions Max            400.7169
V Predictions Min            11.976256
Log Pis Mean                 -2.7085493
Log Pis Std                  1.9521893
Log Pis Max                  8.936626
Log Pis Min                  -10.183688
Policy mu Mean               0.020117454
Policy mu Std                0.33511204
Policy mu Max                1.3021035
Policy mu Min                -1.915746
Policy log std Mean          -0.8023311
Policy log std Std           0.16438335
Policy log std Max           -0.39728487
Policy log std Min           -1.9137367
Z mean eval                  0.82143945
Z variance eval              0.01807115
total_rewards                [615.19150152 135.12793738 633.09307315 159.1462093  119.19813569
 276.27779596 303.39894628 499.77617544 246.71191014 657.1564983 ]
total_rewards_mean           364.5078183158213
total_rewards_std            204.76356955480554
total_rewards_max            657.15649830361
total_rewards_min            119.19813568984974
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               25.682717863004655
(Previous) Eval Time (s)     22.50592914223671
Sample Time (s)              17.555466641671956
Epoch Time (s)               65.74411364691332
Total Train Time (s)         3265.559481624514
Epoch                        47
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:09:56.960741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #47 | Epoch Duration: 68.82388639450073
2020-01-11 04:09:56.960947 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8214429
Z variance train             0.018125918
KL Divergence                15.560294
KL Loss                      1.5560294
QF Loss                      179.20407
VF Loss                      63.21602
Policy Loss                  -351.1158
Q Predictions Mean           348.93915
Q Predictions Std            48.579987
Q Predictions Max            417.58456
Q Predictions Min            -30.448668
V Predictions Mean           349.12338
V Predictions Std            44.253365
V Predictions Max            418.45035
V Predictions Min            18.444342
Log Pis Mean                 -2.6299314
Log Pis Std                  2.077522
Log Pis Max                  7.7849517
Log Pis Min                  -8.790115
Policy mu Mean               0.053459365
Policy mu Std                0.35244325
Policy mu Max                1.4417102
Policy mu Min                -1.3777083
Policy log std Mean          -0.80529803
Policy log std Std           0.17368759
Policy log std Max           -0.3838036
Policy log std Min           -2.0088515
Z mean eval                  0.81672823
Z variance eval              0.017194733
total_rewards                [727.83264865 258.0930308  304.6647673  339.52254177 236.49704929
 199.44752781 662.90212461 265.94563619 302.68272629 317.99428068]
total_rewards_mean           361.55823333928436
total_rewards_std            171.99379845557598
total_rewards_max            727.8326486489648
total_rewards_min            199.44752780897386
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               26.925372815225273
(Previous) Eval Time (s)     25.58542653499171
Sample Time (s)              18.476802026387304
Epoch Time (s)               70.98760137660429
Total Train Time (s)         3338.6976445335895
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:11:10.101632 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #48 | Epoch Duration: 73.14047741889954
2020-01-11 04:11:10.101902 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #48 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8158151
Z variance train             0.017109035
KL Divergence                15.817215
KL Loss                      1.5817215
QF Loss                      110.25838
VF Loss                      20.09011
Policy Loss                  -355.70767
Q Predictions Mean           352.1467
Q Predictions Std            33.769714
Q Predictions Max            432.2449
Q Predictions Min            37.913918
V Predictions Mean           357.67252
V Predictions Std            31.377342
V Predictions Max            435.64667
V Predictions Min            102.11248
Log Pis Mean                 -2.9049096
Log Pis Std                  1.5759073
Log Pis Max                  1.6533121
Log Pis Min                  -7.8071785
Policy mu Mean               0.029004619
Policy mu Std                0.32637748
Policy mu Max                1.058201
Policy mu Min                -1.1328586
Policy log std Mean          -0.79439384
Policy log std Std           0.14301819
Policy log std Max           -0.4222151
Policy log std Min           -1.5190759
Z mean eval                  0.81187755
Z variance eval              0.012928223
total_rewards                [210.47871588 396.48877058 597.46306046 430.42108332 512.4578254
 530.48121644 458.78676676 391.11437051 417.79445135 691.92866502]
total_rewards_mean           463.74149257157006
total_rewards_std            124.08219305123683
total_rewards_max            691.9286650189233
total_rewards_min            210.47871587896597
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               30.39946267893538
(Previous) Eval Time (s)     27.738010487053543
Sample Time (s)              19.733163479249924
Epoch Time (s)               77.87063664523885
Total Train Time (s)         3415.9294491847977
Epoch                        49
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:12:27.334150 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #49 | Epoch Duration: 77.2320442199707
2020-01-11 04:12:27.334364 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #49 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8113245
Z variance train             0.012908128
KL Divergence                15.4984045
KL Loss                      1.5498405
QF Loss                      194.04723
VF Loss                      31.30147
Policy Loss                  -360.51608
Q Predictions Mean           357.312
Q Predictions Std            40.16957
Q Predictions Max            431.6584
Q Predictions Min            13.899
V Predictions Mean           357.53558
V Predictions Std            38.863045
V Predictions Max            428.07556
V Predictions Min            23.052252
Log Pis Mean                 -2.7640061
Log Pis Std                  1.8062696
Log Pis Max                  4.8727636
Log Pis Min                  -8.365217
Policy mu Mean               0.08199888
Policy mu Std                0.3201614
Policy mu Max                1.2813345
Policy mu Min                -1.3649118
Policy log std Mean          -0.81012154
Policy log std Std           0.16022435
Policy log std Max           -0.42266536
Policy log std Min           -1.7561952
Z mean eval                  0.8316635
Z variance eval              0.012104737
total_rewards                [ 54.0296543  491.79148091 708.82644542 289.20677933 664.72353513
 811.45767175 258.83968129 550.36202224 107.6636794  450.38516043]
total_rewards_mean           438.7286110190477
total_rewards_std            243.0393264122654
total_rewards_max            811.4576717460009
total_rewards_min            54.029654295447585
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               28.772571854293346
(Previous) Eval Time (s)     27.09911274118349
Sample Time (s)              18.30313781509176
Epoch Time (s)               74.1748224105686
Total Train Time (s)         3485.8598514515907
Epoch                        50
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:37.266541 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #50 | Epoch Duration: 69.93200588226318
2020-01-11 04:13:37.266770 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8266894
Z variance train             0.012080883
KL Divergence                15.675956
KL Loss                      1.5675956
QF Loss                      188.996
VF Loss                      31.42228
Policy Loss                  -360.41672
Q Predictions Mean           357.58374
Q Predictions Std            32.11384
Q Predictions Max            426.88705
Q Predictions Min            200.05238
V Predictions Mean           363.2622
V Predictions Std            30.579529
V Predictions Max            434.6431
V Predictions Min            271.17343
Log Pis Mean                 -2.8963144
Log Pis Std                  1.7817934
Log Pis Max                  5.642202
Log Pis Min                  -9.486546
Policy mu Mean               0.057754714
Policy mu Std                0.33287537
Policy mu Max                1.3287252
Policy mu Min                -1.0251387
Policy log std Mean          -0.78318745
Policy log std Std           0.17157407
Policy log std Max           -0.36391857
Policy log std Min           -1.9735897
Z mean eval                  0.81960773
Z variance eval              0.014349001
total_rewards                [178.29719185 140.63071294   8.16026862 129.70734493 264.18297455
 630.19615637 352.05349031 234.65925999 530.82445788 441.35391988]
total_rewards_mean           291.00657773188294
total_rewards_std            185.50567217332545
total_rewards_max            630.1961563668647
total_rewards_min            8.160268622085578
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               27.097180482931435
(Previous) Eval Time (s)     22.8559861429967
Sample Time (s)              18.228359398897737
Epoch Time (s)               68.18152602482587
Total Train Time (s)         3551.5646804757416
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:14:42.975483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #51 | Epoch Duration: 65.70852708816528
2020-01-11 04:14:42.975715 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #51 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81719697
Z variance train             0.014450093
KL Divergence                15.140713
KL Loss                      1.5140713
QF Loss                      279.7078
VF Loss                      54.09053
Policy Loss                  -364.2611
Q Predictions Mean           362.17166
Q Predictions Std            45.573833
Q Predictions Max            476.99286
Q Predictions Min            -20.259342
V Predictions Mean           370.0345
V Predictions Std            38.979935
V Predictions Max            485.88107
V Predictions Min            21.019634
Log Pis Mean                 -2.679289
Log Pis Std                  1.8405964
Log Pis Max                  5.0956354
Log Pis Min                  -8.898292
Policy mu Mean               0.06348329
Policy mu Std                0.33507285
Policy mu Max                1.2487913
Policy mu Min                -2.2944024
Policy log std Mean          -0.7961225
Policy log std Std           0.14486061
Policy log std Max           -0.392954
Policy log std Min           -1.5724276
Z mean eval                  0.8213089
Z variance eval              0.011591291
total_rewards                [610.01486088 176.98900544 625.56804753 396.62098791  54.49295519
 321.32888739 384.81939572 374.14092264 283.07823274  89.70129437]
total_rewards_mean           331.6754589805428
total_rewards_std            182.8850647793886
total_rewards_max            625.5680475260699
total_rewards_min            54.492955187967546
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               26.443884385749698
(Previous) Eval Time (s)     20.38270544121042
Sample Time (s)              18.224346722941846
Epoch Time (s)               65.05093654990196
Total Train Time (s)         3616.714787494391
Epoch                        52
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:15:48.122921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #52 | Epoch Duration: 65.14703702926636
2020-01-11 04:15:48.123073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #52 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82217824
Z variance train             0.011541474
KL Divergence                15.766862
KL Loss                      1.5766863
QF Loss                      384.86478
VF Loss                      89.37344
Policy Loss                  -368.6933
Q Predictions Mean           362.84222
Q Predictions Std            45.695724
Q Predictions Max            455.681
Q Predictions Min            -56.865784
V Predictions Mean           369.2723
V Predictions Std            30.01864
V Predictions Max            460.087
V Predictions Min            262.13165
Log Pis Mean                 -2.636076
Log Pis Std                  1.8560567
Log Pis Max                  8.459513
Log Pis Min                  -10.605503
Policy mu Mean               0.077479325
Policy mu Std                0.34189698
Policy mu Max                1.4084789
Policy mu Min                -1.0579523
Policy log std Mean          -0.7975232
Policy log std Std           0.16050014
Policy log std Max           -0.40379748
Policy log std Min           -2.2999294
Z mean eval                  0.8234863
Z variance eval              0.010827424
total_rewards                [362.69668146 791.50071402 108.53654518 355.3558383  270.0546105
 280.56813654 537.0329339  244.24199729 638.06402947 527.73382066]
total_rewards_mean           411.5785307318205
total_rewards_std            196.83661633210136
total_rewards_max            791.500714018416
total_rewards_min            108.53654517903833
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               29.874001041986048
(Previous) Eval Time (s)     20.478517852257937
Sample Time (s)              19.172903404105455
Epoch Time (s)               69.52542229834944
Total Train Time (s)         3687.3005087384954
Epoch                        53
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:16:58.709989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #53 | Epoch Duration: 70.58679699897766
2020-01-11 04:16:58.710180 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8229575
Z variance train             0.010826922
KL Divergence                15.964656
KL Loss                      1.5964656
QF Loss                      171.93033
VF Loss                      94.37228
Policy Loss                  -372.12515
Q Predictions Mean           369.00922
Q Predictions Std            42.976505
Q Predictions Max            445.91312
Q Predictions Min            -4.534584
V Predictions Mean           380.12738
V Predictions Std            39.41678
V Predictions Max            459.49484
V Predictions Min            -7.5415864
Log Pis Mean                 -2.6565177
Log Pis Std                  1.7526478
Log Pis Max                  5.7456512
Log Pis Min                  -7.8003125
Policy mu Mean               0.020326216
Policy mu Std                0.32380596
Policy mu Max                1.4918844
Policy mu Min                -1.3271695
Policy log std Mean          -0.8066346
Policy log std Std           0.14453734
Policy log std Max           -0.3550755
Policy log std Min           -2.0086493
Z mean eval                  0.8141901
Z variance eval              0.010475473
total_rewards                [318.99647745 374.33723022 322.41768702 793.45745503 411.06814331
 674.67842136 331.97921791 783.06794305 333.26549971 335.11271918]
total_rewards_mean           467.8380794240367
total_rewards_std            189.11117098407422
total_rewards_max            793.4574550261502
total_rewards_min            318.9964774529009
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               29.574626437854022
(Previous) Eval Time (s)     21.53958335891366
Sample Time (s)              17.532171356026083
Epoch Time (s)               68.64638115279377
Total Train Time (s)         3762.1726420549676
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:13.586371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #54 | Epoch Duration: 74.87602186203003
2020-01-11 04:18:13.586678 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #54 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.815654
Z variance train             0.010481994
KL Divergence                15.876492
KL Loss                      1.5876492
QF Loss                      183.3064
VF Loss                      113.64712
Policy Loss                  -370.25305
Q Predictions Mean           366.13324
Q Predictions Std            55.75505
Q Predictions Max            425.95453
Q Predictions Min            -37.47028
V Predictions Mean           361.41504
V Predictions Std            51.241642
V Predictions Max            423.9448
V Predictions Min            0.11735469
Log Pis Mean                 -2.6045291
Log Pis Std                  1.8372096
Log Pis Max                  7.5218086
Log Pis Min                  -10.328311
Policy mu Mean               0.036826774
Policy mu Std                0.3533193
Policy mu Max                1.7458032
Policy mu Min                -2.0753982
Policy log std Mean          -0.8012195
Policy log std Std           0.14225343
Policy log std Max           -0.4298404
Policy log std Min           -1.4865692
Z mean eval                  0.81977236
Z variance eval              0.010752186
total_rewards                [ 35.11648474 626.15006835  23.90444815 366.3985364  756.82788181
 527.3074976  489.49354924 115.14830195  67.4880357  356.52938523]
total_rewards_mean           336.43641891671894
total_rewards_std            251.31539733443165
total_rewards_max            756.8278818107461
total_rewards_min            23.904448149459267
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               31.736543694045395
(Previous) Eval Time (s)     27.768924822099507
Sample Time (s)              17.94925923086703
Epoch Time (s)               77.45472774701193
Total Train Time (s)         3828.825454398524
Epoch                        55
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:19:20.238393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #55 | Epoch Duration: 66.65149855613708
2020-01-11 04:19:20.238604 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8218919
Z variance train             0.010781242
KL Divergence                15.723259
KL Loss                      1.572326
QF Loss                      126.047745
VF Loss                      24.756767
Policy Loss                  -383.44342
Q Predictions Mean           379.53662
Q Predictions Std            47.893337
Q Predictions Max            460.86032
Q Predictions Min            19.332478
V Predictions Mean           381.24426
V Predictions Std            45.99956
V Predictions Max            459.09232
V Predictions Min            13.815419
Log Pis Mean                 -2.5722017
Log Pis Std                  1.963226
Log Pis Max                  10.714093
Log Pis Min                  -8.676916
Policy mu Mean               0.05173993
Policy mu Std                0.3470544
Policy mu Max                1.7817911
Policy mu Min                -3.2501433
Policy log std Mean          -0.8172071
Policy log std Std           0.15480001
Policy log std Max           -0.33378327
Policy log std Min           -1.9699277
Z mean eval                  0.82508194
Z variance eval              0.012128641
total_rewards                [138.78504026 309.71567463 597.90323074 490.88451951 420.25055564
 234.08755351 514.55974122 251.22572041 503.12331095 254.10954605]
total_rewards_mean           371.46448929284327
total_rewards_std            145.182861524131
total_rewards_max            597.9032307412066
total_rewards_min            138.78504026430122
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               28.267299289349467
(Previous) Eval Time (s)     16.9654313409701
Sample Time (s)              18.250169344246387
Epoch Time (s)               63.48289997456595
Total Train Time (s)         3900.562148041092
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:31.978281 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #56 | Epoch Duration: 71.73953056335449
2020-01-11 04:20:31.978537 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8294733
Z variance train             0.012168719
KL Divergence                15.378234
KL Loss                      1.5378234
QF Loss                      270.92993
VF Loss                      79.93054
Policy Loss                  -384.49094
Q Predictions Mean           380.00385
Q Predictions Std            46.406197
Q Predictions Max            456.5685
Q Predictions Min            -36.683548
V Predictions Mean           377.65118
V Predictions Std            37.77099
V Predictions Max            452.91803
V Predictions Min            13.330762
Log Pis Mean                 -2.7456024
Log Pis Std                  1.8595928
Log Pis Max                  5.9009466
Log Pis Min                  -9.40719
Policy mu Mean               0.07588927
Policy mu Std                0.32940856
Policy mu Max                1.1787354
Policy mu Min                -0.97790885
Policy log std Mean          -0.80016506
Policy log std Std           0.15999217
Policy log std Max           -0.42780262
Policy log std Min           -1.9731579
Z mean eval                  0.82338274
Z variance eval              0.009714234
total_rewards                [241.05433968 570.66894708 324.22649419 822.41786896 372.81451113
 807.97763614 477.20305533 454.689322   739.25941305 326.79786035]
total_rewards_mean           513.7109447907636
total_rewards_std            201.45963408558333
total_rewards_max            822.4178689585283
total_rewards_min            241.0543396788887
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               29.339919089805335
(Previous) Eval Time (s)     25.22174333734438
Sample Time (s)              17.490504308138043
Epoch Time (s)               72.05216673528776
Total Train Time (s)         3970.7330453707837
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:42.152279 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #57 | Epoch Duration: 70.17351388931274
2020-01-11 04:21:42.152613 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8244692
Z variance train             0.009706795
KL Divergence                15.951052
KL Loss                      1.5951052
QF Loss                      223.91428
VF Loss                      25.050236
Policy Loss                  -376.42566
Q Predictions Mean           373.89185
Q Predictions Std            49.037125
Q Predictions Max            450.82178
Q Predictions Min            -23.850327
V Predictions Mean           374.55676
V Predictions Std            48.026653
V Predictions Max            455.68216
V Predictions Min            53.922993
Log Pis Mean                 -2.2123842
Log Pis Std                  1.8962841
Log Pis Max                  7.1404395
Log Pis Min                  -8.239906
Policy mu Mean               0.10076999
Policy mu Std                0.339512
Policy mu Max                2.1643429
Policy mu Min                -1.3728828
Policy log std Mean          -0.8335068
Policy log std Std           0.17080231
Policy log std Max           -0.39104778
Policy log std Min           -1.9118208
Z mean eval                  0.82513255
Z variance eval              0.012572715
total_rewards                [368.90885452 647.00137676 213.67339957 647.22561074 439.62405042
  27.00261417 239.37965872 630.17013486 102.07657917 188.90391246]
total_rewards_mean           350.3966191399728
total_rewards_std            220.4549190266164
total_rewards_max            647.2256107417542
total_rewards_min            27.00261416723076
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               29.598319325130433
(Previous) Eval Time (s)     23.342791280709207
Sample Time (s)              18.021445692982525
Epoch Time (s)               70.96255629882216
Total Train Time (s)         4043.0587264583446
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:22:54.479468 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #58 | Epoch Duration: 72.32659435272217
2020-01-11 04:22:54.479747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83060616
Z variance train             0.012618229
KL Divergence                15.955157
KL Loss                      1.5955157
QF Loss                      164.91211
VF Loss                      21.745995
Policy Loss                  -385.51056
Q Predictions Mean           385.2481
Q Predictions Std            41.117558
Q Predictions Max            464.0515
Q Predictions Min            96.103485
V Predictions Mean           388.07242
V Predictions Std            39.4396
V Predictions Max            455.17737
V Predictions Min            168.94597
Log Pis Mean                 -2.479903
Log Pis Std                  1.8069555
Log Pis Max                  8.388687
Log Pis Min                  -8.564295
Policy mu Mean               0.07150719
Policy mu Std                0.3476705
Policy mu Max                1.4615638
Policy mu Min                -2.1107488
Policy log std Mean          -0.8306477
Policy log std Std           0.15899397
Policy log std Max           -0.36675587
Policy log std Min           -2.3543298
Z mean eval                  0.8515193
Z variance eval              0.0073999176
total_rewards                [446.34936356 681.64850662 463.22828551 575.02116167 332.25897189
 743.52583015 277.85298072  38.4007201  435.65237003 313.82429598]
total_rewards_mean           430.7762486232876
total_rewards_std            195.85778334756935
total_rewards_max            743.5258301542261
total_rewards_min            38.400720102281
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               29.125379905104637
(Previous) Eval Time (s)     24.706534212920815
Sample Time (s)              18.00436883419752
Epoch Time (s)               71.83628295222297
Total Train Time (s)         4114.679358037654
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:24:06.102246 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #59 | Epoch Duration: 71.62226223945618
2020-01-11 04:24:06.102476 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #59 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8519375
Z variance train             0.0073975213
KL Divergence                16.874706
KL Loss                      1.6874707
QF Loss                      491.11786
VF Loss                      63.360203
Policy Loss                  -390.0825
Q Predictions Mean           387.7329
Q Predictions Std            47.7412
Q Predictions Max            468.43832
Q Predictions Min            12.584836
V Predictions Mean           392.90988
V Predictions Std            41.76241
V Predictions Max            464.64505
V Predictions Min            47.81738
Log Pis Mean                 -2.4641416
Log Pis Std                  1.9516811
Log Pis Max                  5.515826
Log Pis Min                  -8.703466
Policy mu Mean               0.03110159
Policy mu Std                0.35070953
Policy mu Max                1.3209782
Policy mu Min                -1.5677104
Policy log std Mean          -0.80660903
Policy log std Std           0.15912214
Policy log std Max           -0.44339174
Policy log std Min           -1.8821325
Z mean eval                  0.8298019
Z variance eval              0.0067842766
total_rewards                [145.47391992 236.96418196  23.79040821 388.04411419 242.18835832
 461.91728669 589.17210775 194.26041394 410.90625942 517.75727711]
total_rewards_mean           321.0474327505891
total_rewards_std            170.74676450189156
total_rewards_max            589.1721077499247
total_rewards_min            23.790408213911903
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               27.45120234414935
(Previous) Eval Time (s)     24.492237322963774
Sample Time (s)              18.861433901824057
Epoch Time (s)               70.80487356893718
Total Train Time (s)         4181.514639220666
Epoch                        60
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:25:12.938419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #60 | Epoch Duration: 66.83575654029846
2020-01-11 04:25:12.938655 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8285214
Z variance train             0.006796471
KL Divergence                16.569044
KL Loss                      1.6569045
QF Loss                      218.9649
VF Loss                      51.164642
Policy Loss                  -387.95618
Q Predictions Mean           386.92865
Q Predictions Std            52.132378
Q Predictions Max            471.78928
Q Predictions Min            11.795907
V Predictions Mean           393.12357
V Predictions Std            53.811855
V Predictions Max            470.24222
V Predictions Min            -35.636135
Log Pis Mean                 -2.5605555
Log Pis Std                  1.7180625
Log Pis Max                  3.1372554
Log Pis Min                  -8.488198
Policy mu Mean               0.07915558
Policy mu Std                0.32531354
Policy mu Max                1.3710002
Policy mu Min                -1.2180191
Policy log std Mean          -0.8120457
Policy log std Std           0.15938206
Policy log std Max           -0.36883348
Policy log std Min           -2.1072457
Z mean eval                  0.8429557
Z variance eval              0.009306221
total_rewards                [310.23113309 486.92933728 394.23421628 327.88200602 181.95402881
 494.47216091 282.94824833 583.34448551 348.64386904 392.78978036]
total_rewards_mean           380.3429265631209
total_rewards_std            111.11264115105168
total_rewards_max            583.3444855134767
total_rewards_min            181.95402880533055
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               30.152096850331873
(Previous) Eval Time (s)     20.522795835975558
Sample Time (s)              18.20627854531631
Epoch Time (s)               68.88117123162374
Total Train Time (s)         4257.134144000243
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:26:28.558172 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #61 | Epoch Duration: 75.6193528175354
2020-01-11 04:26:28.558368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #61 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8393904
Z variance train             0.009258442
KL Divergence                16.728
KL Loss                      1.6728001
QF Loss                      280.4834
VF Loss                      68.614395
Policy Loss                  -393.39825
Q Predictions Mean           388.95282
Q Predictions Std            43.047195
Q Predictions Max            481.51376
Q Predictions Min            117.65945
V Predictions Mean           390.44415
V Predictions Std            42.21963
V Predictions Max            484.89893
V Predictions Min            175.50656
Log Pis Mean                 -2.3964663
Log Pis Std                  1.745255
Log Pis Max                  2.4782515
Log Pis Min                  -7.710405
Policy mu Mean               0.052155495
Policy mu Std                0.3777953
Policy mu Max                1.4375519
Policy mu Min                -1.2046444
Policy log std Mean          -0.8221817
Policy log std Std           0.15371157
Policy log std Max           -0.38313463
Policy log std Min           -1.6672883
Z mean eval                  0.82505625
Z variance eval              0.007879742
total_rewards                [ 75.01757223 710.20462102 491.75435451  19.50058944 444.48991626
 250.14153921 163.2977258  486.6860986   70.50135462 282.29139996]
total_rewards_mean           299.3885171650187
total_rewards_std            215.45683385234153
total_rewards_max            710.2046210225742
total_rewards_min            19.500589443738917
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               28.376864572055638
(Previous) Eval Time (s)     27.260662491898984
Sample Time (s)              19.015454946551472
Epoch Time (s)               74.6529820105061
Total Train Time (s)         4320.871291828342
Epoch                        62
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:27:32.298866 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #62 | Epoch Duration: 63.74034285545349
2020-01-11 04:27:32.299156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82351047
Z variance train             0.007921049
KL Divergence                16.949303
KL Loss                      1.6949303
QF Loss                      316.5742
VF Loss                      54.854122
Policy Loss                  -393.5977
Q Predictions Mean           391.0834
Q Predictions Std            53.379986
Q Predictions Max            495.21957
Q Predictions Min            -26.315838
V Predictions Mean           397.92188
V Predictions Std            50.14628
V Predictions Max            493.50244
V Predictions Min            6.9701204
Log Pis Mean                 -2.1641374
Log Pis Std                  1.6734922
Log Pis Max                  3.8049052
Log Pis Min                  -9.059922
Policy mu Mean               0.04013084
Policy mu Std                0.35459864
Policy mu Max                1.3729464
Policy mu Min                -1.2819135
Policy log std Mean          -0.82703316
Policy log std Std           0.16481116
Policy log std Max           -0.403619
Policy log std Min           -1.8935874
Z mean eval                  0.83482087
Z variance eval              0.008805775
total_rewards                [134.51839008 733.82610973 792.7636523  160.06558347 324.42939184
 383.23740833 441.94114436 813.13090426 204.03831279 371.4852417 ]
total_rewards_mean           435.94361388639254
total_rewards_std            244.63746912245415
total_rewards_max            813.1309042602071
total_rewards_min            134.5183900783568
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               29.68661061488092
(Previous) Eval Time (s)     16.347669503185898
Sample Time (s)              18.31430963613093
Epoch Time (s)               64.34858975419775
Total Train Time (s)         4392.12222475186
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:28:43.560425 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #63 | Epoch Duration: 71.26103830337524
2020-01-11 04:28:43.560728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #63 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8354723
Z variance train             0.008811386
KL Divergence                17.294899
KL Loss                      1.7294899
QF Loss                      200.36882
VF Loss                      32.01487
Policy Loss                  -399.8387
Q Predictions Mean           394.98193
Q Predictions Std            59.56516
Q Predictions Max            476.77304
Q Predictions Min            15.22739
V Predictions Mean           402.25146
V Predictions Std            56.10442
V Predictions Max            476.51404
V Predictions Min            -18.084686
Log Pis Mean                 -2.395779
Log Pis Std                  1.845495
Log Pis Max                  5.079619
Log Pis Min                  -8.5970335
Policy mu Mean               0.007030852
Policy mu Std                0.37304667
Policy mu Max                2.455512
Policy mu Min                -1.723046
Policy log std Mean          -0.81091845
Policy log std Std           0.1651433
Policy log std Max           0.35296315
Policy log std Min           -1.5760994
Z mean eval                  0.8534643
Z variance eval              0.008191782
total_rewards                [942.21624566 238.3128602  151.27414029 883.57704243 605.62533239
 982.76759642 419.90659125 704.75183705 664.3989789  217.06366444]
total_rewards_mean           580.9894289031824
total_rewards_std            294.41859485581847
total_rewards_max            982.7675964203404
total_rewards_min            151.2741402878324
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               29.27872125338763
(Previous) Eval Time (s)     23.259806677233428
Sample Time (s)              19.211734858341515
Epoch Time (s)               71.75026278896257
Total Train Time (s)         4465.017082509585
Epoch                        64
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:56.449242 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #64 | Epoch Duration: 72.88828229904175
2020-01-11 04:29:56.449494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #64 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8517602
Z variance train             0.008179852
KL Divergence                17.242907
KL Loss                      1.7242907
QF Loss                      175.18745
VF Loss                      35.014107
Policy Loss                  -403.177
Q Predictions Mean           401.53238
Q Predictions Std            55.300526
Q Predictions Max            485.26593
Q Predictions Min            0.5503644
V Predictions Mean           401.7685
V Predictions Std            55.24972
V Predictions Max            485.13684
V Predictions Min            -27.65972
Log Pis Mean                 -2.7480278
Log Pis Std                  1.795467
Log Pis Max                  3.8670526
Log Pis Min                  -8.811529
Policy mu Mean               0.030107556
Policy mu Std                0.3484083
Policy mu Max                1.1884176
Policy mu Min                -1.6760955
Policy log std Mean          -0.79382217
Policy log std Std           0.16412227
Policy log std Max           -0.21749607
Policy log std Min           -1.788944
Z mean eval                  0.8539375
Z variance eval              0.013584213
total_rewards                [301.89907963 172.94177789 363.24891493 920.04243867 153.87203233
 336.84554515 720.84099284 792.78203643  20.65868762 349.25387236]
total_rewards_mean           413.23853778483783
total_rewards_std            282.7508711693058
total_rewards_max            920.0424386746483
total_rewards_min            20.65868762059067
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               28.188089677132666
(Previous) Eval Time (s)     24.397499246988446
Sample Time (s)              17.994373274967074
Epoch Time (s)               70.57996219908819
Total Train Time (s)         4535.437931260094
Epoch                        65
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:31:06.871663 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #65 | Epoch Duration: 70.42195153236389
2020-01-11 04:31:06.871879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85547066
Z variance train             0.013652215
KL Divergence                16.984009
KL Loss                      1.6984009
QF Loss                      211.30432
VF Loss                      121.861725
Policy Loss                  -408.81824
Q Predictions Mean           405.6739
Q Predictions Std            57.07861
Q Predictions Max            481.3181
Q Predictions Min            -37.072903
V Predictions Mean           409.67725
V Predictions Std            51.62461
V Predictions Max            487.72217
V Predictions Min            -8.63447
Log Pis Mean                 -2.4191892
Log Pis Std                  1.7235364
Log Pis Max                  4.3656664
Log Pis Min                  -8.044631
Policy mu Mean               0.05874502
Policy mu Std                0.36997
Policy mu Max                1.3620276
Policy mu Min                -2.300598
Policy log std Mean          -0.82116
Policy log std Std           0.17130487
Policy log std Max           -0.067070425
Policy log std Min           -1.8818092
Z mean eval                  0.83851415
Z variance eval              0.011162552
total_rewards                [ 156.84360039  659.98323137  630.26815312  470.95069455  356.72436309
  231.69618392  746.93331124 1039.75321391   10.78813207  112.49286037]
total_rewards_mean           441.6433744034297
total_rewards_std            310.06839862030796
total_rewards_max            1039.753213910388
total_rewards_min            10.788132072212498
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               28.72139036701992
(Previous) Eval Time (s)     24.239208452403545
Sample Time (s)              18.27974511915818
Epoch Time (s)               71.24034393858165
Total Train Time (s)         4602.759003023617
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:14.194480 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #66 | Epoch Duration: 67.32242774963379
2020-01-11 04:32:14.194728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #66 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8368112
Z variance train             0.0111677265
KL Divergence                17.003735
KL Loss                      1.7003735
QF Loss                      128.47092
VF Loss                      88.440125
Policy Loss                  -405.85986
Q Predictions Mean           402.5008
Q Predictions Std            53.96933
Q Predictions Max            505.89307
Q Predictions Min            25.360115
V Predictions Mean           407.6702
V Predictions Std            54.582314
V Predictions Max            512.01117
V Predictions Min            29.2672
Log Pis Mean                 -2.5501022
Log Pis Std                  2.0528276
Log Pis Max                  6.2108912
Log Pis Min                  -9.508582
Policy mu Mean               0.09444634
Policy mu Std                0.3471666
Policy mu Max                1.7570431
Policy mu Min                -1.3920761
Policy log std Mean          -0.8303436
Policy log std Std           0.19086693
Policy log std Max           -0.4046596
Policy log std Min           -2.168085
Z mean eval                  0.8468239
Z variance eval              0.014052736
total_rewards                [206.0162676  300.64497409 246.88024859 134.7018364  434.40840451
 279.11470379 186.9647246  378.42580129 213.3208934  368.96813043]
total_rewards_mean           274.9445984704198
total_rewards_std            90.77449118231199
total_rewards_max            434.4084045055824
total_rewards_min            134.70183640474255
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               28.462805191986263
(Previous) Eval Time (s)     20.321001078933477
Sample Time (s)              18.033664270769805
Epoch Time (s)               66.81747054168954
Total Train Time (s)         4672.0001046145335
Epoch                        67
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:33:23.438713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #67 | Epoch Duration: 69.24377584457397
2020-01-11 04:33:23.439017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #67 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8441876
Z variance train             0.014046376
KL Divergence                16.573364
KL Loss                      1.6573365
QF Loss                      825.82983
VF Loss                      56.095135
Policy Loss                  -412.98703
Q Predictions Mean           408.39594
Q Predictions Std            53.239212
Q Predictions Max            495.04453
Q Predictions Min            -29.534798
V Predictions Mean           411.37146
V Predictions Std            45.800312
V Predictions Max            492.74963
V Predictions Min            25.5616
Log Pis Mean                 -2.4290934
Log Pis Std                  1.817199
Log Pis Max                  7.674161
Log Pis Min                  -7.655017
Policy mu Mean               0.08161472
Policy mu Std                0.3548014
Policy mu Max                1.368913
Policy mu Min                -1.4664874
Policy log std Mean          -0.83379173
Policy log std Std           0.18394679
Policy log std Max           -0.43712375
Policy log std Min           -2.372582
Z mean eval                  0.84082824
Z variance eval              0.009663815
total_rewards                [ 100.09202181  867.10392418  464.11840652  497.0091961   995.99720724
  676.68554305  285.98172585  148.53473851 1099.36735219  398.43203945]
total_rewards_mean           553.3322154887093
total_rewards_std            329.1906437965655
total_rewards_max            1099.3673521916558
total_rewards_min            100.09202181104159
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               29.701967519242316
(Previous) Eval Time (s)     22.74698934983462
Sample Time (s)              18.057226441334933
Epoch Time (s)               70.50618331041187
Total Train Time (s)         4745.17149411561
Epoch                        68
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:34:36.612384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #68 | Epoch Duration: 73.17313194274902
2020-01-11 04:34:36.612664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83975136
Z variance train             0.009660794
KL Divergence                17.289356
KL Loss                      1.7289356
QF Loss                      553.2752
VF Loss                      322.8106
Policy Loss                  -410.4813
Q Predictions Mean           406.88318
Q Predictions Std            64.020004
Q Predictions Max            518.00745
Q Predictions Min            -3.736102
V Predictions Mean           413.0754
V Predictions Std            55.962517
V Predictions Max            515.7039
V Predictions Min            26.253078
Log Pis Mean                 -2.3719845
Log Pis Std                  1.9176445
Log Pis Max                  7.737073
Log Pis Min                  -7.9933333
Policy mu Mean               0.031534966
Policy mu Std                0.3638374
Policy mu Max                1.2620324
Policy mu Min                -1.8897243
Policy log std Mean          -0.8413021
Policy log std Std           0.17741968
Policy log std Max           -0.44679552
Policy log std Min           -2.329609
Z mean eval                  0.85174286
Z variance eval              0.010183555
total_rewards                [ 446.58068763  540.71577102 1194.8908828  1086.38510411  344.77164732
   12.25340649  586.66805572  459.05239894   86.52423712 1190.66922875]
total_rewards_mean           594.8511419898808
total_rewards_std            407.48394616182327
total_rewards_max            1194.8908827996436
total_rewards_min            12.253406487156498
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               26.36977033223957
(Previous) Eval Time (s)     25.413659621030092
Sample Time (s)              18.025646137539297
Epoch Time (s)               69.80907609080896
Total Train Time (s)         4810.447018534876
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:35:41.890007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #69 | Epoch Duration: 65.27708673477173
2020-01-11 04:35:41.890349 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #69 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8516408
Z variance train             0.010175725
KL Divergence                15.792585
KL Loss                      1.5792586
QF Loss                      236.08167
VF Loss                      268.08154
Policy Loss                  -417.18613
Q Predictions Mean           414.6903
Q Predictions Std            55.270428
Q Predictions Max            511.88654
Q Predictions Min            6.821334
V Predictions Mean           413.49124
V Predictions Std            51.376465
V Predictions Max            502.63312
V Predictions Min            90.6395
Log Pis Mean                 -2.6766286
Log Pis Std                  1.9603842
Log Pis Max                  10.04716
Log Pis Min                  -9.2784605
Policy mu Mean               0.02980247
Policy mu Std                0.35822383
Policy mu Max                1.5350894
Policy mu Min                -1.1630728
Policy log std Mean          -0.821041
Policy log std Std           0.18904957
Policy log std Max           -0.4134515
Policy log std Min           -2.2575736
Z mean eval                  0.875069
Z variance eval              0.010857786
total_rewards                [ 103.86579954 1097.51041926  430.36174349  874.41344021  213.28488153
  296.73801961  277.73670313  296.79760723  253.87202244  743.80851735]
total_rewards_mean           458.83891537900973
total_rewards_std            312.45292763228196
total_rewards_max            1097.5104192552903
total_rewards_min            103.86579954203171
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               25.175520881079137
(Previous) Eval Time (s)     20.881400536745787
Sample Time (s)              17.8567828675732
Epoch Time (s)               63.913704285398126
Total Train Time (s)         4878.051630072296
Epoch                        70
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:36:49.499545 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #70 | Epoch Duration: 67.6089117527008
2020-01-11 04:36:49.499882 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #70 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86877596
Z variance train             0.010877983
KL Divergence                16.63936
KL Loss                      1.663936
QF Loss                      358.44333
VF Loss                      118.60812
Policy Loss                  -425.98532
Q Predictions Mean           423.19324
Q Predictions Std            49.89845
Q Predictions Max            515.0443
Q Predictions Min            25.544865
V Predictions Mean           432.2786
V Predictions Std            49.734688
V Predictions Max            522.12006
V Predictions Min            14.270392
Log Pis Mean                 -2.4258356
Log Pis Std                  1.8317683
Log Pis Max                  6.922211
Log Pis Min                  -7.982917
Policy mu Mean               0.09911648
Policy mu Std                0.36085728
Policy mu Max                2.419844
Policy mu Min                -1.067773
Policy log std Mean          -0.80934966
Policy log std Std           0.17855637
Policy log std Max           -0.3976169
Policy log std Min           -1.6673486
Z mean eval                  0.8610252
Z variance eval              0.010639413
total_rewards                [112.22701103 295.52550857 818.0740548  252.47572436 197.63967664
 437.74874333 376.7981158  840.16227986 425.4320337   11.49592369]
total_rewards_mean           376.7579071769693
total_rewards_std            259.44433405501235
total_rewards_max            840.1622798553227
total_rewards_min            11.495923685090949
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               31.221636600326747
(Previous) Eval Time (s)     24.576305048074573
Sample Time (s)              18.772111660800874
Epoch Time (s)               74.5700533092022
Total Train Time (s)         4945.698341366369
Epoch                        71
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:37:57.142938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #71 | Epoch Duration: 67.64282417297363
2020-01-11 04:37:57.143087 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #71 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85944575
Z variance train             0.010635066
KL Divergence                16.81318
KL Loss                      1.6813182
QF Loss                      168.88153
VF Loss                      37.635365
Policy Loss                  -430.04987
Q Predictions Mean           428.30774
Q Predictions Std            58.378113
Q Predictions Max            519.06696
Q Predictions Min            -22.471199
V Predictions Mean           431.38818
V Predictions Std            56.903416
V Predictions Max            512.8858
V Predictions Min            41.714676
Log Pis Mean                 -2.6603408
Log Pis Std                  1.9885412
Log Pis Max                  11.460071
Log Pis Min                  -10.7600765
Policy mu Mean               0.04871077
Policy mu Std                0.37712482
Policy mu Max                2.913679
Policy mu Min                -2.2351704
Policy log std Mean          -0.7969511
Policy log std Std           0.17499743
Policy log std Max           -0.397489
Policy log std Min           -2.01026
Z mean eval                  0.87266237
Z variance eval              0.0125981
total_rewards                [215.16153248 179.33238021 992.96822315 512.91597725 893.28552246
 183.10588717 427.36084448 669.4791428  334.97903146 707.82427761]
total_rewards_mean           511.6412819076796
total_rewards_std            280.2334437806979
total_rewards_max            992.9682231518893
total_rewards_min            179.33238020564988
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               29.546486858278513
(Previous) Eval Time (s)     17.648739993106574
Sample Time (s)              17.89322559442371
Epoch Time (s)               65.0884524458088
Total Train Time (s)         5017.6182788587175
Epoch                        72
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:39:09.077135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #72 | Epoch Duration: 71.93387818336487
2020-01-11 04:39:09.077457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #72 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8744956
Z variance train             0.012673335
KL Divergence                16.848217
KL Loss                      1.6848217
QF Loss                      416.09586
VF Loss                      76.381294
Policy Loss                  -434.5811
Q Predictions Mean           431.69977
Q Predictions Std            55.52825
Q Predictions Max            533.0361
Q Predictions Min            29.705553
V Predictions Mean           428.64734
V Predictions Std            53.933575
V Predictions Max            522.42535
V Predictions Min            3.5056965
Log Pis Mean                 -2.2849455
Log Pis Std                  1.8358706
Log Pis Max                  5.665387
Log Pis Min                  -7.1369405
Policy mu Mean               0.055713966
Policy mu Std                0.3673371
Policy mu Max                1.2504508
Policy mu Min                -1.5459917
Policy log std Mean          -0.84322715
Policy log std Std           0.17575192
Policy log std Max           -0.3724923
Policy log std Min           -2.120945
Z mean eval                  0.90165645
Z variance eval              0.008477689
total_rewards                [427.92560381 665.79542889 888.3970435  259.34490921 307.25747806
 367.13813038 441.68314209 290.88523703 586.50985815 368.18389057]
total_rewards_mean           460.3120721705013
total_rewards_std            187.74714411318485
total_rewards_max            888.397043504485
total_rewards_min            259.3449092138384
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               26.531149704940617
(Previous) Eval Time (s)     24.49380048410967
Sample Time (s)              17.54757996229455
Epoch Time (s)               68.57253015134484
Total Train Time (s)         5087.204788014293
Epoch                        73
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:18.654419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #73 | Epoch Duration: 69.57671070098877
2020-01-11 04:40:18.654659 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #73 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89845675
Z variance train             0.0084323315
KL Divergence                17.096127
KL Loss                      1.7096127
QF Loss                      125.44207
VF Loss                      31.024075
Policy Loss                  -427.49246
Q Predictions Mean           424.15033
Q Predictions Std            51.053448
Q Predictions Max            526.397
Q Predictions Min            88.32458
V Predictions Mean           430.10608
V Predictions Std            47.146706
V Predictions Max            532.7788
V Predictions Min            269.35886
Log Pis Mean                 -2.2575445
Log Pis Std                  1.8603485
Log Pis Max                  5.3433127
Log Pis Min                  -7.189107
Policy mu Mean               0.060424335
Policy mu Std                0.36292365
Policy mu Max                1.3975424
Policy mu Min                -1.7881044
Policy log std Mean          -0.8450152
Policy log std Std           0.1811259
Policy log std Max           -0.3101557
Policy log std Min           -1.8915792
Z mean eval                  0.84945667
Z variance eval              0.009644638
total_rewards                [ 274.79973208 1247.05694114  143.31341709  154.56915758  442.96797453
  995.97069091  845.876161    753.03605467  119.38461755  290.64307794]
total_rewards_mean           526.761782447999
total_rewards_std            383.37848418562885
total_rewards_max            1247.0569411449849
total_rewards_min            119.38461754927896
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               27.566517051309347
(Previous) Eval Time (s)     25.497675474733114
Sample Time (s)              18.488395570311695
Epoch Time (s)               71.55258809635416
Total Train Time (s)         5160.319834402762
Epoch                        74
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:41:31.772361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #74 | Epoch Duration: 73.11750221252441
2020-01-11 04:41:31.772595 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #74 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8492104
Z variance train             0.009642283
KL Divergence                17.04586
KL Loss                      1.704586
QF Loss                      201.81566
VF Loss                      149.92984
Policy Loss                  -438.33066
Q Predictions Mean           434.3266
Q Predictions Std            57.603077
Q Predictions Max            526.42834
Q Predictions Min            10.857303
V Predictions Mean           439.6697
V Predictions Std            53.636997
V Predictions Max            534.58563
V Predictions Min            5.057658
Log Pis Mean                 -1.9489195
Log Pis Std                  1.9028152
Log Pis Max                  8.679107
Log Pis Min                  -8.247655
Policy mu Mean               0.13461742
Policy mu Std                0.38048416
Policy mu Max                2.0154834
Policy mu Min                -1.0894544
Policy log std Mean          -0.8574904
Policy log std Std           0.17850843
Policy log std Max           -0.38698658
Policy log std Min           -2.2637224
Z mean eval                  0.86273134
Z variance eval              0.0083673345
total_rewards                [ 508.42059677  149.97036833  435.6727781   902.78429328  144.86803548
  267.76429015  441.35780658  520.96299147 1185.88748589  364.31756558]
total_rewards_mean           492.20062116139604
total_rewards_std            310.0223188905692
total_rewards_max            1185.8874858859676
total_rewards_min            144.86803547922176
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               28.245735192205757
(Previous) Eval Time (s)     27.062303002923727
Sample Time (s)              17.81864973437041
Epoch Time (s)               73.1266879294999
Total Train Time (s)         5231.063923754264
Epoch                        75
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:42:42.516142 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #75 | Epoch Duration: 70.74337339401245
2020-01-11 04:42:42.516374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #75 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8619796
Z variance train             0.008373566
KL Divergence                16.829872
KL Loss                      1.6829872
QF Loss                      191.9412
VF Loss                      43.163147
Policy Loss                  -423.99747
Q Predictions Mean           419.90912
Q Predictions Std            70.27014
Q Predictions Max            526.99756
Q Predictions Min            -3.9518807
V Predictions Mean           426.1836
V Predictions Std            71.94922
V Predictions Max            526.5449
V Predictions Min            -12.281841
Log Pis Mean                 -2.4959111
Log Pis Std                  1.8525425
Log Pis Max                  4.459488
Log Pis Min                  -8.447972
Policy mu Mean               0.08325386
Policy mu Std                0.35506862
Policy mu Max                1.8182597
Policy mu Min                -1.3392097
Policy log std Mean          -0.848264
Policy log std Std           0.18281245
Policy log std Max           -0.06951004
Policy log std Min           -2.0138073
Z mean eval                  0.85716885
Z variance eval              0.009443477
total_rewards                [ 304.97090297 1221.6446047    87.49214106  841.59848379  384.52767816
  166.8297687   485.38148895   53.01830923  983.95041525  603.6730395 ]
total_rewards_mean           513.3086832311905
total_rewards_std            375.92379918340026
total_rewards_max            1221.6446046968692
total_rewards_min            53.018309225123375
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               25.47545846598223
(Previous) Eval Time (s)     24.678714827168733
Sample Time (s)              18.128396009560674
Epoch Time (s)               68.28256930271164
Total Train Time (s)         5295.629320138134
Epoch                        76
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:43:47.083542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #76 | Epoch Duration: 64.56704306602478
2020-01-11 04:43:47.083712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #76 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.854722
Z variance train             0.009425341
KL Divergence                17.15297
KL Loss                      1.715297
QF Loss                      181.87695
VF Loss                      21.330187
Policy Loss                  -443.3067
Q Predictions Mean           439.2075
Q Predictions Std            47.36776
Q Predictions Max            520.71716
Q Predictions Min            259.37607
V Predictions Mean           443.55145
V Predictions Std            46.770325
V Predictions Max            526.11176
V Predictions Min            277.72824
Log Pis Mean                 -2.3790102
Log Pis Std                  1.6983881
Log Pis Max                  2.254385
Log Pis Min                  -8.736387
Policy mu Mean               0.049428105
Policy mu Std                0.35566762
Policy mu Max                1.1785556
Policy mu Min                -1.7098535
Policy log std Mean          -0.848078
Policy log std Std           0.1674599
Policy log std Max           -0.40492204
Policy log std Min           -1.4296153
Z mean eval                  0.8648082
Z variance eval              0.007964576
total_rewards                [1063.92091403  360.90229658  183.07833852  221.41740861  372.07232397
  571.97894391  367.62643177  570.77396771 1123.61157037  403.43462874]
total_rewards_mean           523.881682421695
total_rewards_std            308.54394450703865
total_rewards_max            1123.6115703720798
total_rewards_min            183.07833852425176
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               25.81782181886956
(Previous) Eval Time (s)     20.962886189110577
Sample Time (s)              17.889411052688956
Epoch Time (s)               64.6701190606691
Total Train Time (s)         5365.589900386054
Epoch                        77
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:44:57.047228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #77 | Epoch Duration: 69.963303565979
2020-01-11 04:44:57.047518 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86391944
Z variance train             0.007964113
KL Divergence                17.89368
KL Loss                      1.789368
QF Loss                      192.72893
VF Loss                      95.149536
Policy Loss                  -444.94608
Q Predictions Mean           441.27115
Q Predictions Std            59.05033
Q Predictions Max            553.9316
Q Predictions Min            48.16522
V Predictions Mean           440.28625
V Predictions Std            59.905674
V Predictions Max            551.38556
V Predictions Min            11.91044
Log Pis Mean                 -2.2350185
Log Pis Std                  1.8498296
Log Pis Max                  8.144057
Log Pis Min                  -8.8538265
Policy mu Mean               0.07382614
Policy mu Std                0.36646047
Policy mu Max                1.9363172
Policy mu Min                -1.131041
Policy log std Mean          -0.84392715
Policy log std Std           0.16694668
Policy log std Max           -0.39685184
Policy log std Min           -1.7520131
Z mean eval                  0.88922757
Z variance eval              0.012825638
total_rewards                [ 667.57136108  607.22473132  158.64199993  659.28165511  313.16575434
 1198.54966013  487.73154816 1279.53734341 1045.39055474  133.09738907]
total_rewards_mean           655.0191997287395
total_rewards_std            387.80661957788516
total_rewards_max            1279.5373434097833
total_rewards_min            133.0973890744845
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               29.12621673103422
(Previous) Eval Time (s)     26.25577829219401
Sample Time (s)              18.207861001137644
Epoch Time (s)               73.58985602436587
Total Train Time (s)         5439.657263092231
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:46:11.118646 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #78 | Epoch Duration: 74.07076096534729
2020-01-11 04:46:11.119093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8811839
Z variance train             0.012742428
KL Divergence                15.966177
KL Loss                      1.5966177
QF Loss                      369.10712
VF Loss                      86.50034
Policy Loss                  -445.7383
Q Predictions Mean           442.85388
Q Predictions Std            58.42456
Q Predictions Max            550.65466
Q Predictions Min            217.09685
V Predictions Mean           450.5399
V Predictions Std            56.436455
V Predictions Max            542.1175
V Predictions Min            232.0763
Log Pis Mean                 -2.2513807
Log Pis Std                  1.9754605
Log Pis Max                  6.239049
Log Pis Min                  -10.544867
Policy mu Mean               0.04016282
Policy mu Std                0.38580635
Policy mu Max                1.4558257
Policy mu Min                -1.1502542
Policy log std Mean          -0.87321347
Policy log std Std           0.19835667
Policy log std Max           -0.3758534
Policy log std Min           -2.108231
Z mean eval                  0.90974426
Z variance eval              0.01159615
total_rewards                [ 431.76312648  278.02589813  840.76132977  623.49130624  481.94158819
  297.03928966  525.9386442   202.69162373 1134.60380314  314.25571748]
total_rewards_mean           513.0512327028018
total_rewards_std            274.11694185753765
total_rewards_max            1134.6038031431822
total_rewards_min            202.6916237327428
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               29.019479902926832
(Previous) Eval Time (s)     26.73637876380235
Sample Time (s)              18.116218315903097
Epoch Time (s)               73.87207698263228
Total Train Time (s)         5511.4137733038515
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:47:22.876319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #79 | Epoch Duration: 71.75696611404419
2020-01-11 04:47:22.876567 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #79 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9040292
Z variance train             0.011685118
KL Divergence                16.225798
KL Loss                      1.6225798
QF Loss                      251.62955
VF Loss                      42.43947
Policy Loss                  -450.9991
Q Predictions Mean           448.0122
Q Predictions Std            56.58887
Q Predictions Max            535.96185
Q Predictions Min            214.18678
V Predictions Mean           454.43365
V Predictions Std            56.636303
V Predictions Max            535.30396
V Predictions Min            142.31627
Log Pis Mean                 -2.0942025
Log Pis Std                  1.9565873
Log Pis Max                  3.3991585
Log Pis Min                  -11.731694
Policy mu Mean               0.073094085
Policy mu Std                0.38739422
Policy mu Max                1.3174396
Policy mu Min                -1.1157053
Policy log std Mean          -0.8526318
Policy log std Std           0.19408534
Policy log std Max           -0.3792996
Policy log std Min           -1.8399961
Z mean eval                  0.8834025
Z variance eval              0.013711542
total_rewards                [614.74823057 750.64179949 400.27315586 694.73278344 686.9075298
 537.90059862 186.03693215  56.34266116 464.46453075 674.27578618]
total_rewards_mean           506.63240080307577
total_rewards_std            220.64116176092298
total_rewards_max            750.6417994948641
total_rewards_min            56.342661159907
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               27.825790111906826
(Previous) Eval Time (s)     24.620958198793232
Sample Time (s)              18.255790230818093
Epoch Time (s)               70.70253854151815
Total Train Time (s)         5576.860112561844
Epoch                        80
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:48:28.322614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #80 | Epoch Duration: 65.44581937789917
2020-01-11 04:48:28.322853 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #80 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8833731
Z variance train             0.01373761
KL Divergence                15.903759
KL Loss                      1.5903759
QF Loss                      324.50745
VF Loss                      29.568558
Policy Loss                  -464.4799
Q Predictions Mean           461.19595
Q Predictions Std            50.9667
Q Predictions Max            559.7302
Q Predictions Min            283.34222
V Predictions Mean           466.5335
V Predictions Std            50.226368
V Predictions Max            557.3526
V Predictions Min            294.02017
Log Pis Mean                 -1.7819204
Log Pis Std                  1.9025948
Log Pis Max                  3.5249252
Log Pis Min                  -8.458919
Policy mu Mean               0.109536834
Policy mu Std                0.39904493
Policy mu Max                1.4544164
Policy mu Min                -1.3747395
Policy log std Mean          -0.8739649
Policy log std Std           0.18586002
Policy log std Max           -0.33763626
Policy log std Min           -1.8437177
Z mean eval                  0.9006885
Z variance eval              0.012483658
total_rewards                [110.99123128  23.10657991 381.17679645 364.84023542 398.67100392
 447.66019614 422.0548361  126.28716951 503.6177394  861.29316546]
total_rewards_mean           363.9698953599858
total_rewards_std            227.0220179751767
total_rewards_max            861.2931654641694
total_rewards_min            23.106579911221242
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               30.366204699035734
(Previous) Eval Time (s)     19.36390263494104
Sample Time (s)              18.141428847797215
Epoch Time (s)               67.87153618177399
Total Train Time (s)         5647.361463692971
Epoch                        81
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:49:38.827229 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #81 | Epoch Duration: 70.50420641899109
2020-01-11 04:49:38.827517 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9026538
Z variance train             0.012428687
KL Divergence                16.249985
KL Loss                      1.6249985
QF Loss                      281.86002
VF Loss                      27.162075
Policy Loss                  -454.73895
Q Predictions Mean           453.3988
Q Predictions Std            60.783203
Q Predictions Max            578.1537
Q Predictions Min            279.47076
V Predictions Mean           455.8061
V Predictions Std            59.71038
V Predictions Max            575.1079
V Predictions Min            279.30923
Log Pis Mean                 -2.2376766
Log Pis Std                  1.9015914
Log Pis Max                  4.506604
Log Pis Min                  -8.472146
Policy mu Mean               0.087317124
Policy mu Std                0.36840415
Policy mu Max                1.1849056
Policy mu Min                -1.2683777
Policy log std Mean          -0.8414929
Policy log std Std           0.2138206
Policy log std Max           -0.34404635
Policy log std Min           -2.0555825
Z mean eval                  0.9025505
Z variance eval              0.009696717
total_rewards                [ 586.87003542 1148.18197421 1201.79931242  960.27925155  220.70515883
 1082.58940376  597.92621038 1155.13576747  269.56452162 1268.63354428]
total_rewards_mean           849.1685179925335
total_rewards_std            375.8969902441001
total_rewards_max            1268.633544279458
total_rewards_min            220.7051588300596
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               29.295200848020613
(Previous) Eval Time (s)     21.99627081817016
Sample Time (s)              18.829626403283328
Epoch Time (s)               70.1210980694741
Total Train Time (s)         5719.625093003735
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:50:51.093976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #82 | Epoch Duration: 72.26613235473633
2020-01-11 04:50:51.094361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89982873
Z variance train             0.009691484
KL Divergence                17.160618
KL Loss                      1.7160618
QF Loss                      253.74275
VF Loss                      44.91256
Policy Loss                  -457.94745
Q Predictions Mean           455.5437
Q Predictions Std            67.04488
Q Predictions Max            556.33185
Q Predictions Min            9.926513
V Predictions Mean           454.57892
V Predictions Std            67.315765
V Predictions Max            545.6175
V Predictions Min            27.088644
Log Pis Mean                 -1.840441
Log Pis Std                  1.6549108
Log Pis Max                  4.809725
Log Pis Min                  -7.0056896
Policy mu Mean               0.110546544
Policy mu Std                0.38209772
Policy mu Max                1.4448639
Policy mu Min                -0.9225507
Policy log std Mean          -0.8849955
Policy log std Std           0.19113588
Policy log std Max           -0.42737123
Policy log std Min           -1.9273899
Z mean eval                  0.90514964
Z variance eval              0.0103235515
total_rewards                [ 306.94880887  631.57777785  726.26075403 1111.19639948   80.02162875
  155.31803594  381.96364822 1104.17747244  303.98814153  228.41827961]
total_rewards_mean           502.9870946721624
total_rewards_std            355.74920673817775
total_rewards_max            1111.1963994841044
total_rewards_min            80.02162875491024
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               29.23836149321869
(Previous) Eval Time (s)     24.14093925943598
Sample Time (s)              18.684030572883785
Epoch Time (s)               72.06333132553846
Total Train Time (s)         5785.505091770552
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:51:56.974259 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #83 | Epoch Duration: 65.87968420982361
2020-01-11 04:51:56.974477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90323126
Z variance train             0.010347493
KL Divergence                16.776651
KL Loss                      1.6776651
QF Loss                      320.80322
VF Loss                      47.909958
Policy Loss                  -458.73944
Q Predictions Mean           456.70193
Q Predictions Std            72.80827
Q Predictions Max            617.7209
Q Predictions Min            -6.78412
V Predictions Mean           460.7031
V Predictions Std            74.52164
V Predictions Max            614.05145
V Predictions Min            -3.4085107
Log Pis Mean                 -2.0315218
Log Pis Std                  1.6838819
Log Pis Max                  2.6819592
Log Pis Min                  -9.690501
Policy mu Mean               -0.0180435
Policy mu Std                0.39147934
Policy mu Max                1.4155022
Policy mu Min                -1.2754046
Policy log std Mean          -0.84819394
Policy log std Std           0.19703184
Policy log std Max           0.2512148
Policy log std Min           -1.4471748
Z mean eval                  0.91897166
Z variance eval              0.006199686
total_rewards                [ 987.93121195  118.06750999  187.48187108  415.67113326   38.62591939
 1211.58477106  367.89354454 1065.8432061   582.71698111  189.81758228]
total_rewards_mean           516.5633730763448
total_rewards_std            405.6956481470694
total_rewards_max            1211.584771056713
total_rewards_min            38.625919394011376
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               25.955029351171106
(Previous) Eval Time (s)     17.956975222099572
Sample Time (s)              18.23685678699985
Epoch Time (s)               62.14886136027053
Total Train Time (s)         5851.056542440318
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:53:02.529510 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #84 | Epoch Duration: 65.55485701560974
2020-01-11 04:53:02.529746 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #84 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9178213
Z variance train             0.00619878
KL Divergence                17.184883
KL Loss                      1.7184883
QF Loss                      577.52
VF Loss                      83.589806
Policy Loss                  -460.991
Q Predictions Mean           455.26624
Q Predictions Std            85.81974
Q Predictions Max            571.4563
Q Predictions Min            -75.254875
V Predictions Mean           459.42706
V Predictions Std            79.97525
V Predictions Max            569.4476
V Predictions Min            18.154758
Log Pis Mean                 -1.9205747
Log Pis Std                  2.2508512
Log Pis Max                  9.621165
Log Pis Min                  -8.97917
Policy mu Mean               0.07638605
Policy mu Std                0.41982308
Policy mu Max                1.961801
Policy mu Min                -1.5184747
Policy log std Mean          -0.8611712
Policy log std Std           0.23078708
Policy log std Max           -0.34424883
Policy log std Min           -2.3094468
Z mean eval                  0.9334629
Z variance eval              0.00734737
total_rewards                [148.11155441 233.65799319 184.37627435 879.64946506 101.54358612
 504.18986421 407.14978792 131.96828084 639.64422074 379.18019442]
total_rewards_mean           360.9471221263981
total_rewards_std            241.26957485652764
total_rewards_max            879.6494650618624
total_rewards_min            101.54358612353448
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               29.133178636897355
(Previous) Eval Time (s)     21.362665604799986
Sample Time (s)              17.63824003515765
Epoch Time (s)               68.13408427685499
Total Train Time (s)         5920.1637005591765
Epoch                        85
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:54:11.635609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #85 | Epoch Duration: 69.10569906234741
2020-01-11 04:54:11.635841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93276435
Z variance train             0.007302965
KL Divergence                17.34316
KL Loss                      1.7343161
QF Loss                      212.94394
VF Loss                      154.04158
Policy Loss                  -480.51068
Q Predictions Mean           476.89587
Q Predictions Std            75.61508
Q Predictions Max            591.67316
Q Predictions Min            -1.7431338
V Predictions Mean           476.4356
V Predictions Std            69.90902
V Predictions Max            592.3153
V Predictions Min            86.05953
Log Pis Mean                 -1.7114418
Log Pis Std                  2.0624304
Log Pis Max                  11.328944
Log Pis Min                  -9.031583
Policy mu Mean               0.04747865
Policy mu Std                0.4126232
Policy mu Max                2.78327
Policy mu Min                -1.743125
Policy log std Mean          -0.8798177
Policy log std Std           0.20818955
Policy log std Max           -0.2522965
Policy log std Min           -1.8112411
Z mean eval                  0.89300555
Z variance eval              0.008531142
total_rewards                [ 210.26877015  732.29502326 1462.97179421  468.15314424 1461.87454177
 1146.57785942  177.18273732  716.44324995   66.72193675  467.57437686]
total_rewards_mean           691.0063433917622
total_rewards_std            488.313972658534
total_rewards_max            1462.9717942097695
total_rewards_min            66.72193675411708
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               26.499555798247457
(Previous) Eval Time (s)     22.333968597929925
Sample Time (s)              18.211380708497018
Epoch Time (s)               67.0449051046744
Total Train Time (s)         5990.744422904681
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:55:22.220023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #86 | Epoch Duration: 70.5839536190033
2020-01-11 04:55:22.220330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #86 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89293754
Z variance train             0.0085148625
KL Divergence                17.389822
KL Loss                      1.7389822
QF Loss                      256.98694
VF Loss                      109.39192
Policy Loss                  -483.8801
Q Predictions Mean           480.27643
Q Predictions Std            73.41438
Q Predictions Max            586.5225
Q Predictions Min            40.14512
V Predictions Mean           482.69467
V Predictions Std            76.100624
V Predictions Max            585.44666
V Predictions Min            -17.694658
Log Pis Mean                 -2.1331635
Log Pis Std                  1.9013506
Log Pis Max                  2.372901
Log Pis Min                  -8.337246
Policy mu Mean               0.070909455
Policy mu Std                0.39352974
Policy mu Max                1.6094208
Policy mu Min                -1.4642345
Policy log std Mean          -0.87087107
Policy log std Std           0.19539982
Policy log std Max           -0.24049857
Policy log std Min           -1.6992462
Z mean eval                  0.89754355
Z variance eval              0.01025573
total_rewards                [708.57037109 837.38704972  99.73982868 684.18865596 295.49970089
 236.76222723 309.01399264  91.45417895 222.30358953 121.27778029]
total_rewards_mean           360.6197374981506
total_rewards_std            263.10499184616464
total_rewards_max            837.3870497234502
total_rewards_min            91.4541789469804
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               28.818040571641177
(Previous) Eval Time (s)     25.87273733690381
Sample Time (s)              17.95398585917428
Epoch Time (s)               72.64476376771927
Total Train Time (s)         6057.90303584747
Epoch                        87
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:56:29.378001 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #87 | Epoch Duration: 67.15750861167908
2020-01-11 04:56:29.378156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8972801
Z variance train             0.010277376
KL Divergence                18.054447
KL Loss                      1.8054447
QF Loss                      269.6501
VF Loss                      88.12098
Policy Loss                  -492.2021
Q Predictions Mean           489.50854
Q Predictions Std            66.09299
Q Predictions Max            609.55096
Q Predictions Min            279.7827
V Predictions Mean           492.22397
V Predictions Std            65.884766
V Predictions Max            609.0162
V Predictions Min            301.29355
Log Pis Mean                 -2.0014515
Log Pis Std                  2.087426
Log Pis Max                  8.848779
Log Pis Min                  -7.468706
Policy mu Mean               0.048163682
Policy mu Std                0.4039579
Policy mu Max                1.2509172
Policy mu Min                -1.3989217
Policy log std Mean          -0.84425026
Policy log std Std           0.22469379
Policy log std Max           -0.28560334
Policy log std Min           -2.3912401
Z mean eval                  0.8847739
Z variance eval              0.007933907
total_rewards                [ 285.98101534  103.71490822  914.63836912   10.75266022  183.16059107
   52.09028476  135.1871068   433.39926096 1496.24896844 1122.91706626]
total_rewards_mean           473.80902311740994
total_rewards_std            492.579574465438
total_rewards_max            1496.2489684425777
total_rewards_min            10.752660216676613
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               28.633769399952143
(Previous) Eval Time (s)     20.38518377300352
Sample Time (s)              18.25331967556849
Epoch Time (s)               67.27227284852415
Total Train Time (s)         6127.735314706806
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:57:39.215390 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #88 | Epoch Duration: 69.83706784248352
2020-01-11 04:57:39.215680 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8846471
Z variance train             0.007912212
KL Divergence                18.269672
KL Loss                      1.8269672
QF Loss                      233.30402
VF Loss                      73.07487
Policy Loss                  -479.98953
Q Predictions Mean           478.0838
Q Predictions Std            76.85981
Q Predictions Max            594.4571
Q Predictions Min            -12.315158
V Predictions Mean           484.29358
V Predictions Std            75.52486
V Predictions Max            599.62915
V Predictions Min            11.912041
Log Pis Mean                 -1.9916635
Log Pis Std                  2.0558898
Log Pis Max                  11.38641
Log Pis Min                  -8.062626
Policy mu Mean               0.04366938
Policy mu Std                0.40903455
Policy mu Max                2.15427
Policy mu Min                -2.1585953
Policy log std Mean          -0.87204635
Policy log std Std           0.20895275
Policy log std Max           -0.27306196
Policy log std Min           -2.2204509
Z mean eval                  0.8870834
Z variance eval              0.0068728095
total_rewards                [  54.0559803   519.96249784 1517.78691471  771.55895468  421.35370636
  165.45432078  244.67435184  370.43430986   71.919989   1348.57880055]
total_rewards_mean           548.5779825912756
total_rewards_std            488.7457230441332
total_rewards_max            1517.7869147093172
total_rewards_min            54.05598029900706
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               28.23309324402362
(Previous) Eval Time (s)     22.94962474424392
Sample Time (s)              18.04565510293469
Epoch Time (s)               69.22837309120223
Total Train Time (s)         6193.647983376402
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:58:45.126685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #89 | Epoch Duration: 65.91076302528381
2020-01-11 04:58:45.126839 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #89 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8877093
Z variance train             0.0068745934
KL Divergence                18.34193
KL Loss                      1.8341931
QF Loss                      171.38467
VF Loss                      216.57437
Policy Loss                  -490.93222
Q Predictions Mean           486.89603
Q Predictions Std            74.73307
Q Predictions Max            601.9922
Q Predictions Min            -12.439505
V Predictions Mean           488.7293
V Predictions Std            68.60335
V Predictions Max            594.7116
V Predictions Min            260.03757
Log Pis Mean                 -2.1914973
Log Pis Std                  2.0944068
Log Pis Max                  4.030856
Log Pis Min                  -8.535101
Policy mu Mean               0.045841657
Policy mu Std                0.4110616
Policy mu Max                2.8978827
Policy mu Min                -1.3687036
Policy log std Mean          -0.85840344
Policy log std Std           0.2156091
Policy log std Max           -0.28884676
Policy log std Min           -1.9897163
Z mean eval                  0.91662425
Z variance eval              0.010734266
total_rewards                [455.98758735 384.98861594  52.34462864 124.53144065 909.22975152
  57.39330634 367.54448442 426.54107371 115.6078139  780.89698501]
total_rewards_mean           367.5065687490085
total_rewards_std            281.77338579491914
total_rewards_max            909.2297515189948
total_rewards_min            52.34462864078665
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               29.554285410791636
(Previous) Eval Time (s)     19.631756325252354
Sample Time (s)              18.251148050650954
Epoch Time (s)               67.43718978669494
Total Train Time (s)         6259.381939907093
Epoch                        90
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:59:50.863539 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #90 | Epoch Duration: 65.73654747009277
2020-01-11 04:59:50.863758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9177659
Z variance train             0.010599058
KL Divergence                18.110287
KL Loss                      1.8110287
QF Loss                      193.90836
VF Loss                      48.58844
Policy Loss                  -502.3267
Q Predictions Mean           499.4413
Q Predictions Std            65.27203
Q Predictions Max            603.5955
Q Predictions Min            307.42026
V Predictions Mean           505.37048
V Predictions Std            64.68487
V Predictions Max            614.42487
V Predictions Min            310.98553
Log Pis Mean                 -2.0507026
Log Pis Std                  2.1493714
Log Pis Max                  7.3512197
Log Pis Min                  -12.869061
Policy mu Mean               0.08987801
Policy mu Std                0.39834833
Policy mu Max                1.44141
Policy mu Min                -1.2959312
Policy log std Mean          -0.86183524
Policy log std Std           0.20270754
Policy log std Max           -0.24611598
Policy log std Min           -2.0127895
Z mean eval                  0.88944197
Z variance eval              0.0063047213
total_rewards                [1115.81110168 1085.48487105  445.79657595   84.88103355  399.04564603
  257.14468393   84.37815749  515.1365728  1132.38755058  363.04755986]
total_rewards_mean           548.3113752917557
total_rewards_std            391.75870478718275
total_rewards_max            1132.387550578258
total_rewards_min            84.37815748565238
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               27.4229132020846
(Previous) Eval Time (s)     17.930801848880947
Sample Time (s)              17.897048613522202
Epoch Time (s)               63.25076366448775
Total Train Time (s)         6328.080064993817
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:00:59.563198 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #91 | Epoch Duration: 68.69926762580872
2020-01-11 05:00:59.563389 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8892003
Z variance train             0.0062986994
KL Divergence                18.970448
KL Loss                      1.8970448
QF Loss                      237.7117
VF Loss                      36.76718
Policy Loss                  -499.32098
Q Predictions Mean           497.1927
Q Predictions Std            65.47815
Q Predictions Max            602.02423
Q Predictions Min            296.51855
V Predictions Mean           500.4242
V Predictions Std            65.521965
V Predictions Max            603.37885
V Predictions Min            299.30966
Log Pis Mean                 -1.9147346
Log Pis Std                  2.180499
Log Pis Max                  2.599475
Log Pis Min                  -12.513306
Policy mu Mean               0.014839868
Policy mu Std                0.42083845
Policy mu Max                1.4306606
Policy mu Min                -1.2667437
Policy log std Mean          -0.8684852
Policy log std Std           0.20337415
Policy log std Max           -0.3027559
Policy log std Min           -1.671807
Z mean eval                  0.9113016
Z variance eval              0.006300895
total_rewards                [1318.00537961 1440.98750318 1086.13193845 1236.61491244  793.45831334
  189.9249415   358.12492377  167.58484675  238.831483    415.24394141]
total_rewards_mean           724.4908183456621
total_rewards_std            482.1894300139166
total_rewards_max            1440.9875031817535
total_rewards_min            167.58484675258237
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               28.448352068196982
(Previous) Eval Time (s)     23.379019473213702
Sample Time (s)              18.66235516499728
Epoch Time (s)               70.48972670640796
Total Train Time (s)         6399.757570562884
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:02:11.243422 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #92 | Epoch Duration: 71.67986750602722
2020-01-11 05:02:11.243701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91219074
Z variance train             0.0062771305
KL Divergence                19.43486
KL Loss                      1.9434861
QF Loss                      386.51633
VF Loss                      105.53774
Policy Loss                  -482.93738
Q Predictions Mean           479.21487
Q Predictions Std            102.071754
Q Predictions Max            615.1769
Q Predictions Min            24.755444
V Predictions Mean           486.96387
V Predictions Std            104.058876
V Predictions Max            621.4715
V Predictions Min            -7.811308
Log Pis Mean                 -1.715427
Log Pis Std                  2.3907008
Log Pis Max                  8.789402
Log Pis Min                  -7.67487
Policy mu Mean               0.08134042
Policy mu Std                0.4212352
Policy mu Max                1.5517304
Policy mu Min                -2.4150648
Policy log std Mean          -0.88528055
Policy log std Std           0.2612167
Policy log std Max           -0.089518845
Policy log std Min           -2.5376537
Z mean eval                  0.9056331
Z variance eval              0.0068972083
total_rewards                [ 698.89071246  656.08813038  453.98250012  433.77446595 -178.12716543
   13.0944061   -31.91643725  311.91519515   74.71559452  267.03810467]
total_rewards_mean           269.9455506661457
total_rewards_std            281.34614359393646
total_rewards_max            698.8907124645934
total_rewards_min            -178.1271654289865
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               25.40580704435706
(Previous) Eval Time (s)     24.568839707877487
Sample Time (s)              18.40154157113284
Epoch Time (s)               68.37618832336739
Total Train Time (s)         6468.328667748719
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:03:19.817370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #93 | Epoch Duration: 68.57345342636108
2020-01-11 05:03:19.817564 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9057374
Z variance train             0.0068964697
KL Divergence                19.525084
KL Loss                      1.9525083
QF Loss                      237.93059
VF Loss                      126.02294
Policy Loss                  -493.3954
Q Predictions Mean           490.59827
Q Predictions Std            88.61154
Q Predictions Max            631.1925
Q Predictions Min            -32.63671
V Predictions Mean           493.65378
V Predictions Std            81.59534
V Predictions Max            631.7113
V Predictions Min            16.93399
Log Pis Mean                 -2.1137276
Log Pis Std                  2.2702
Log Pis Max                  8.194191
Log Pis Min                  -12.692665
Policy mu Mean               0.07677892
Policy mu Std                0.41471082
Policy mu Max                1.5696093
Policy mu Min                -1.3577975
Policy log std Mean          -0.84690833
Policy log std Std           0.22169943
Policy log std Max           -0.31154573
Policy log std Min           -2.119537
Z mean eval                  0.89785194
Z variance eval              0.01152737
total_rewards                [ 335.81589778  212.51217276 1102.44388957  272.52269952  179.51947171
    1.54531047  618.27947395 1040.05871796  394.88712869  225.67158187]
total_rewards_mean           438.3256344288716
total_rewards_std            350.6245933898691
total_rewards_max            1102.4438895706437
total_rewards_min            1.5453104730182687
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               27.5991197838448
(Previous) Eval Time (s)     24.765818940009922
Sample Time (s)              18.823250792454928
Epoch Time (s)               71.18818951630965
Total Train Time (s)         6538.087598172948
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:04:29.578575 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #94 | Epoch Duration: 69.7608437538147
2020-01-11 05:04:29.578879 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9007139
Z variance train             0.0114909215
KL Divergence                17.698414
KL Loss                      1.7698414
QF Loss                      322.78326
VF Loss                      65.643036
Policy Loss                  -504.89322
Q Predictions Mean           502.8559
Q Predictions Std            81.10711
Q Predictions Max            658.49817
Q Predictions Min            291.4068
V Predictions Mean           508.01862
V Predictions Std            79.07506
V Predictions Max            653.9051
V Predictions Min            307.80606
Log Pis Mean                 -1.7897561
Log Pis Std                  1.9429353
Log Pis Max                  7.565667
Log Pis Min                  -8.576189
Policy mu Mean               0.13285075
Policy mu Std                0.41623408
Policy mu Max                1.5596377
Policy mu Min                -1.1109052
Policy log std Mean          -0.8710474
Policy log std Std           0.21070729
Policy log std Max           -0.29001224
Policy log std Min           -1.8853605
Z mean eval                  0.93662757
Z variance eval              0.011960267
total_rewards                [1461.7694244   719.88378985  209.93637079  349.01276667  243.23739139
 1624.32649159  942.30307002   42.94961311 1372.18889421  769.91954249]
total_rewards_mean           773.5527354510043
total_rewards_std            538.5263740088138
total_rewards_max            1624.32649159495
total_rewards_min            42.94961310740236
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               30.860288931056857
(Previous) Eval Time (s)     23.33815606124699
Sample Time (s)              19.36579220322892
Epoch Time (s)               73.56423719553277
Total Train Time (s)         6614.018606635742
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:05:45.509016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #95 | Epoch Duration: 75.9299144744873
2020-01-11 05:05:45.509168 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #95 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93688357
Z variance train             0.011967393
KL Divergence                16.977098
KL Loss                      1.6977099
QF Loss                      760.291
VF Loss                      132.15764
Policy Loss                  -502.21213
Q Predictions Mean           500.3396
Q Predictions Std            101.759125
Q Predictions Max            634.07776
Q Predictions Min            -29.80446
V Predictions Mean           495.34683
V Predictions Std            99.49116
V Predictions Max            627.2562
V Predictions Min            -3.5114155
Log Pis Mean                 -1.8242346
Log Pis Std                  2.1431136
Log Pis Max                  7.2286444
Log Pis Min                  -7.4501247
Policy mu Mean               0.047625583
Policy mu Std                0.41631305
Policy mu Max                1.8153497
Policy mu Min                -1.4379361
Policy log std Mean          -0.8868216
Policy log std Std           0.23737128
Policy log std Max           -0.3266527
Policy log std Min           -2.2010956
Z mean eval                  0.905454
Z variance eval              0.0088762045
total_rewards                [ 540.64777711  473.95837893 1455.14195925 1656.21055608  660.2323245
  926.44924629  381.24414031  341.21228212   51.81095289  143.9931654 ]
total_rewards_mean           663.09007828831
total_rewards_std            505.9574906075624
total_rewards_max            1656.2105560768464
total_rewards_min            51.81095288642811
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               28.920072271022946
(Previous) Eval Time (s)     25.703523639123887
Sample Time (s)              17.563963770400733
Epoch Time (s)               72.18755968054757
Total Train Time (s)         6686.594522649888
Epoch                        96
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:58.089220 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #96 | Epoch Duration: 72.57988023757935
2020-01-11 05:06:58.089572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90561354
Z variance train             0.008880566
KL Divergence                16.682642
KL Loss                      1.6682643
QF Loss                      318.3013
VF Loss                      37.02369
Policy Loss                  -513.06726
Q Predictions Mean           511.49243
Q Predictions Std            92.46176
Q Predictions Max            651.31006
Q Predictions Min            9.766531
V Predictions Mean           512.67004
V Predictions Std            93.33987
V Predictions Max            651.3563
V Predictions Min            -6.329755
Log Pis Mean                 -1.6890821
Log Pis Std                  2.0293374
Log Pis Max                  5.301417
Log Pis Min                  -7.1690903
Policy mu Mean               0.070195615
Policy mu Std                0.43034208
Policy mu Max                1.8652425
Policy mu Min                -1.6901947
Policy log std Mean          -0.8578613
Policy log std Std           0.23587285
Policy log std Max           0.28897074
Policy log std Min           -1.9726245
Z mean eval                  0.9428237
Z variance eval              0.010647838
total_rewards                [ 882.57760025  253.91288126  298.36029069   84.71204379   80.51720021
  431.52900384 1274.82953655   70.62816093  856.08136138  586.65915289]
total_rewards_mean           481.9807231780307
total_rewards_std            389.4199576332249
total_rewards_max            1274.8295365469057
total_rewards_min            70.62816092969646
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               29.111507419962436
(Previous) Eval Time (s)     26.095522550866008
Sample Time (s)              18.251847735140473
Epoch Time (s)               73.45887770596892
Total Train Time (s)         6758.267804927193
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:08:09.762664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #97 | Epoch Duration: 71.67285776138306
2020-01-11 05:08:09.762876 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #97 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9442105
Z variance train             0.010630313
KL Divergence                16.696247
KL Loss                      1.6696247
QF Loss                      206.35913
VF Loss                      30.941462
Policy Loss                  -522.108
Q Predictions Mean           519.71783
Q Predictions Std            76.37246
Q Predictions Max            663.9742
Q Predictions Min            293.34735
V Predictions Mean           523.8466
V Predictions Std            75.08536
V Predictions Max            655.66705
V Predictions Min            305.08087
Log Pis Mean                 -1.9483061
Log Pis Std                  1.9345322
Log Pis Max                  3.6533742
Log Pis Min                  -10.318398
Policy mu Mean               0.053976353
Policy mu Std                0.43597484
Policy mu Max                1.5487082
Policy mu Min                -1.655339
Policy log std Mean          -0.82376283
Policy log std Std           0.21410835
Policy log std Max           -0.19745076
Policy log std Min           -1.6112531
Z mean eval                  0.9228816
Z variance eval              0.008249254
total_rewards                [1125.30742343  216.17455967 1606.47092639  531.05072773  170.13296593
  578.68486883  939.64562411  265.54513782 1560.06524277   23.49006381]
total_rewards_mean           701.6567540480639
total_rewards_std            548.1071804541584
total_rewards_max            1606.4709263925897
total_rewards_min            23.49006380554987
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               27.755437857005745
(Previous) Eval Time (s)     24.309221672359854
Sample Time (s)              17.798044360242784
Epoch Time (s)               69.86270388960838
Total Train Time (s)         6822.010434662923
Epoch                        98
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:09:13.506139 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #98 | Epoch Duration: 63.74311375617981
2020-01-11 05:09:13.506343 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9234649
Z variance train             0.00824218
KL Divergence                16.99391
KL Loss                      1.699391
QF Loss                      274.4343
VF Loss                      91.39545
Policy Loss                  -525.0156
Q Predictions Mean           522.05994
Q Predictions Std            92.59448
Q Predictions Max            637.14197
Q Predictions Min            -39.99301
V Predictions Mean           527.34467
V Predictions Std            87.05605
V Predictions Max            633.77167
V Predictions Min            -2.2198257
Log Pis Mean                 -1.9091476
Log Pis Std                  2.284147
Log Pis Max                  11.390927
Log Pis Min                  -13.559205
Policy mu Mean               0.0025878875
Policy mu Std                0.41426212
Policy mu Max                1.3333538
Policy mu Min                -1.8108767
Policy log std Mean          -0.88368845
Policy log std Std           0.21527727
Policy log std Max           -0.32223663
Policy log std Min           -2.4940262
Z mean eval                  0.9221649
Z variance eval              0.010485623
total_rewards                [ -12.69384207   19.95412632  -73.61949518  265.83454441  133.18005168
  179.86679337 1498.25134646  609.37125064  677.08518015  463.0540157 ]
total_rewards_mean           376.0283971467949
total_rewards_std            447.4054482986671
total_rewards_max            1498.2513464560197
total_rewards_min            -73.61949518051671
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               28.83786243200302
(Previous) Eval Time (s)     18.189358382020146
Sample Time (s)              17.913510717917234
Epoch Time (s)               64.9407315319404
Total Train Time (s)         6892.4540448198095
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:10:23.952134 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #99 | Epoch Duration: 70.44566297531128
2020-01-11 05:10:23.952344 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9217187
Z variance train             0.010440041
KL Divergence                16.61567
KL Loss                      1.661567
QF Loss                      400.36438
VF Loss                      65.689285
Policy Loss                  -526.5787
Q Predictions Mean           521.3028
Q Predictions Std            96.41591
Q Predictions Max            649.63007
Q Predictions Min            -29.513443
V Predictions Mean           524.86066
V Predictions Std            93.21393
V Predictions Max            651.2118
V Predictions Min            -4.9777985
Log Pis Mean                 -1.6687546
Log Pis Std                  2.1531925
Log Pis Max                  5.6738586
Log Pis Min                  -6.987944
Policy mu Mean               0.09685783
Policy mu Std                0.4353304
Policy mu Max                1.5600476
Policy mu Min                -1.2897761
Policy log std Mean          -0.88300073
Policy log std Std           0.22715952
Policy log std Max           -0.23195612
Policy log std Min           -1.8728244
Z mean eval                  0.9265027
Z variance eval              0.0063894144
total_rewards                [ 858.66245426 1188.37252771 1543.10233327  114.93838585 1709.74580543
 1574.46296833  876.49071841 1626.43082839  429.510502    584.12385812]
total_rewards_mean           1050.5840381756648
total_rewards_std            533.6661349121695
total_rewards_max            1709.745805430865
total_rewards_min            114.9383858454425
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               25.852392442058772
(Previous) Eval Time (s)     23.693976424634457
Sample Time (s)              17.40713031310588
Epoch Time (s)               66.95349917979911
Total Train Time (s)         6962.912882679142
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:34.412395 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #100 | Epoch Duration: 70.45991277694702
2020-01-11 05:11:34.412597 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #100 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9246933
Z variance train             0.006387399
KL Divergence                17.825367
KL Loss                      1.7825367
QF Loss                      798.2456
VF Loss                      51.99299
Policy Loss                  -534.2751
Q Predictions Mean           531.7572
Q Predictions Std            80.09182
Q Predictions Max            668.1297
Q Predictions Min            312.82498
V Predictions Mean           533.17645
V Predictions Std            79.80223
V Predictions Max            663.993
V Predictions Min            309.47998
Log Pis Mean                 -1.5746208
Log Pis Std                  1.9797586
Log Pis Max                  4.109961
Log Pis Min                  -9.486864
Policy mu Mean               0.03110494
Policy mu Std                0.44574216
Policy mu Max                1.6616849
Policy mu Min                -1.6434928
Policy log std Mean          -0.8820347
Policy log std Std           0.2237427
Policy log std Max           -0.14067352
Policy log std Min           -1.4745376
Z mean eval                  0.9319478
Z variance eval              0.0073543303
total_rewards                [1252.90316743 1216.26646775 1619.94302742 1489.08073841  587.6126338
  304.22008113 1581.06820192   44.95542837 1607.24033357  318.3107624 ]
total_rewards_mean           1002.1600842206332
total_rewards_std            589.2010121546733
total_rewards_max            1619.943027419027
total_rewards_min            44.955428367154724
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               29.18674149317667
(Previous) Eval Time (s)     27.20008089626208
Sample Time (s)              17.75314277363941
Epoch Time (s)               74.13996516307816
Total Train Time (s)         7033.686132376082
Epoch                        101
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:12:45.186504 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #101 | Epoch Duration: 70.77375149726868
2020-01-11 05:12:45.186673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9313362
Z variance train             0.0073435334
KL Divergence                17.880499
KL Loss                      1.7880499
QF Loss                      273.82507
VF Loss                      52.981216
Policy Loss                  -531.13617
Q Predictions Mean           527.2717
Q Predictions Std            87.608055
Q Predictions Max            657.96344
Q Predictions Min            305.03906
V Predictions Mean           530.53687
V Predictions Std            88.31984
V Predictions Max            656.48773
V Predictions Min            307.77222
Log Pis Mean                 -1.9419544
Log Pis Std                  2.1529524
Log Pis Max                  2.8582006
Log Pis Min                  -10.853488
Policy mu Mean               0.1405366
Policy mu Std                0.44034222
Policy mu Max                1.5635219
Policy mu Min                -1.7372617
Policy log std Mean          -0.8457171
Policy log std Std           0.2107821
Policy log std Max           -0.2669426
Policy log std Min           -1.676594
Z mean eval                  0.91090715
Z variance eval              0.007478288
total_rewards                [ 727.35096465 1450.98613497  721.56422669  -97.50645605 1098.04513958
  284.67849772  120.96001052  993.7023587   979.9078038  1548.34087273]
total_rewards_mean           782.8029553300742
total_rewards_std            517.9920272251637
total_rewards_max            1548.340872730088
total_rewards_min            -97.5064560504042
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               28.538359474856406
(Previous) Eval Time (s)     23.833598298951983
Sample Time (s)              17.839291350450367
Epoch Time (s)               70.21124912425876
Total Train Time (s)         7103.611421211623
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:13:55.113059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #102 | Epoch Duration: 69.92622017860413
2020-01-11 05:13:55.113262 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9089426
Z variance train             0.0074722967
KL Divergence                17.65146
KL Loss                      1.7651461
QF Loss                      323.5187
VF Loss                      108.858574
Policy Loss                  -532.9915
Q Predictions Mean           530.4663
Q Predictions Std            91.951035
Q Predictions Max            666.5521
Q Predictions Min            256.3717
V Predictions Mean           538.084
V Predictions Std            90.909775
V Predictions Max            665.9169
V Predictions Min            299.8719
Log Pis Mean                 -1.9553893
Log Pis Std                  1.9356816
Log Pis Max                  4.274516
Log Pis Min                  -8.181858
Policy mu Mean               0.071098566
Policy mu Std                0.42678615
Policy mu Max                1.5285197
Policy mu Min                -1.7630622
Policy log std Mean          -0.8328217
Policy log std Std           0.22153625
Policy log std Max           -0.28056914
Policy log std Min           -1.9371855
Z mean eval                  0.94323957
Z variance eval              0.005651037
total_rewards                [ 745.05811646   57.71248903  193.01383426 1052.81579754  732.25975462
 1840.70770001  782.15173674 -117.08642487  763.99466311    6.65009082]
total_rewards_mean           605.7277757713189
total_rewards_std            562.9092478260684
total_rewards_max            1840.7077000054064
total_rewards_min            -117.08642487388741
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               26.311430297326297
(Previous) Eval Time (s)     23.548331582453102
Sample Time (s)              19.448542480822653
Epoch Time (s)               69.30830436060205
Total Train Time (s)         7174.945170136169
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:15:06.450599 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #103 | Epoch Duration: 71.33716893196106
2020-01-11 05:15:06.450862 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9456436
Z variance train             0.00563155
KL Divergence                18.200489
KL Loss                      1.8200489
QF Loss                      258.89798
VF Loss                      548.7111
Policy Loss                  -535.905
Q Predictions Mean           531.2195
Q Predictions Std            109.23093
Q Predictions Max            678.8071
Q Predictions Min            -22.144768
V Predictions Mean           534.9568
V Predictions Std            106.531494
V Predictions Max            685.22064
V Predictions Min            27.477531
Log Pis Mean                 -1.839635
Log Pis Std                  2.0682263
Log Pis Max                  8.329306
Log Pis Min                  -9.040285
Policy mu Mean               0.04804217
Policy mu Std                0.43348682
Policy mu Max                2.129143
Policy mu Min                -2.063205
Policy log std Mean          -0.86717904
Policy log std Std           0.24033666
Policy log std Max           -0.21132433
Policy log std Min           -2.1040478
Z mean eval                  0.9509605
Z variance eval              0.0099251885
total_rewards                [ -14.94437098  -94.83277465  493.73010623  -19.9664555  1573.15966445
  835.00912007 1079.2012047   749.83888503  112.26369334  946.41871721]
total_rewards_mean           565.9877789898529
total_rewards_std            534.535282853877
total_rewards_max            1573.1596644462193
total_rewards_min            -94.83277465316115
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               29.3484818469733
(Previous) Eval Time (s)     25.57682876707986
Sample Time (s)              17.973638800904155
Epoch Time (s)               72.89894941495731
Total Train Time (s)         7246.035560521297
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:16:17.544978 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #104 | Epoch Duration: 71.09378170967102
2020-01-11 05:16:17.545389 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9506505
Z variance train             0.00997875
KL Divergence                17.593203
KL Loss                      1.7593203
QF Loss                      394.25308
VF Loss                      122.285
Policy Loss                  -537.1396
Q Predictions Mean           532.775
Q Predictions Std            117.51915
Q Predictions Max            696.36597
Q Predictions Min            -29.977383
V Predictions Mean           530.6958
V Predictions Std            116.497154
V Predictions Max            686.75543
V Predictions Min            -18.305641
Log Pis Mean                 -1.6802607
Log Pis Std                  2.0464013
Log Pis Max                  4.449562
Log Pis Min                  -7.062427
Policy mu Mean               0.008111075
Policy mu Std                0.44899172
Policy mu Max                1.7564147
Policy mu Min                -1.8301798
Policy log std Mean          -0.8749069
Policy log std Std           0.23340757
Policy log std Max           -0.13692078
Policy log std Min           -1.9243739
Z mean eval                  0.9458065
Z variance eval              0.00739088
total_rewards                [1030.04194024  741.81078068   52.9980295   368.63059168 1458.59216094
  -61.4480189   610.30363318  174.62886075   68.20936072  230.68099083]
total_rewards_mean           467.44483296172893
total_rewards_std            464.4372045490932
total_rewards_max            1458.5921609422655
total_rewards_min            -61.44801890162736
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               30.83392773894593
(Previous) Eval Time (s)     23.771356279030442
Sample Time (s)              18.527797822840512
Epoch Time (s)               73.13308184081689
Total Train Time (s)         7317.371266911272
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:17:28.882481 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #105 | Epoch Duration: 71.33684229850769
2020-01-11 05:17:28.882754 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9474775
Z variance train             0.007391387
KL Divergence                18.038973
KL Loss                      1.8038973
QF Loss                      346.71973
VF Loss                      98.81651
Policy Loss                  -539.8336
Q Predictions Mean           536.6523
Q Predictions Std            100.99715
Q Predictions Max            661.8718
Q Predictions Min            78.81863
V Predictions Mean           545.1063
V Predictions Std            100.422104
V Predictions Max            674.8026
V Predictions Min            12.379625
Log Pis Mean                 -1.6773162
Log Pis Std                  2.0769258
Log Pis Max                  6.2671237
Log Pis Min                  -8.04653
Policy mu Mean               0.06198241
Policy mu Std                0.45783705
Policy mu Max                1.4306692
Policy mu Min                -1.4268115
Policy log std Mean          -0.8509433
Policy log std Std           0.23783992
Policy log std Max           -0.13900283
Policy log std Min           -1.8811239
Z mean eval                  0.9274756
Z variance eval              0.009034363
total_rewards                [ 787.60816385  169.24394727  900.68248665 1554.76665253  390.64279109
   76.42848884  199.39408199  655.65232832 1564.17746233 1747.0594478 ]
total_rewards_mean           804.5655850680089
total_rewards_std            594.2381290187642
total_rewards_max            1747.0594477977527
total_rewards_min            76.42848884233075
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               28.76650984492153
(Previous) Eval Time (s)     21.9748192303814
Sample Time (s)              19.099209067877382
Epoch Time (s)               69.84053814318031
Total Train Time (s)         7387.803015490528
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:18:39.318924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #106 | Epoch Duration: 70.43582081794739
2020-01-11 05:18:39.319364 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92636174
Z variance train             0.009008432
KL Divergence                17.132687
KL Loss                      1.7132686
QF Loss                      714.8854
VF Loss                      313.5257
Policy Loss                  -536.4504
Q Predictions Mean           532.22217
Q Predictions Std            107.08333
Q Predictions Max            680.3342
Q Predictions Min            -44.91931
V Predictions Mean           540.1336
V Predictions Std            105.03403
V Predictions Max            686.77716
V Predictions Min            20.064234
Log Pis Mean                 -1.7353334
Log Pis Std                  2.0639389
Log Pis Max                  7.5238204
Log Pis Min                  -7.0903177
Policy mu Mean               0.0562478
Policy mu Std                0.44785368
Policy mu Max                1.6351734
Policy mu Min                -1.5075179
Policy log std Mean          -0.8491298
Policy log std Std           0.24542692
Policy log std Max           -0.2207247
Policy log std Min           -2.0503242
Z mean eval                  0.9345024
Z variance eval              0.008168327
total_rewards                [ 796.21668062  959.96474533  159.76007025   67.21583853 1425.22909589
  265.43632188 1802.94413747  644.76807275  311.81709611 1452.29708032]
total_rewards_mean           788.5649139153538
total_rewards_std            578.070314696691
total_rewards_max            1802.9441374665644
total_rewards_min            67.21583852805662
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               27.80497053777799
(Previous) Eval Time (s)     22.5697408108972
Sample Time (s)              18.635151321534067
Epoch Time (s)               69.00986267020926
Total Train Time (s)         7459.351647661999
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:19:50.869301 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #107 | Epoch Duration: 71.54964828491211
2020-01-11 05:19:50.869587 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9356332
Z variance train             0.008163562
KL Divergence                17.632345
KL Loss                      1.7632345
QF Loss                      496.1282
VF Loss                      66.47643
Policy Loss                  -570.6298
Q Predictions Mean           568.3616
Q Predictions Std            89.03212
Q Predictions Max            698.8895
Q Predictions Min            245.97456
V Predictions Mean           572.34454
V Predictions Std            88.56373
V Predictions Max            689.52466
V Predictions Min            228.95636
Log Pis Mean                 -1.5631096
Log Pis Std                  2.2365322
Log Pis Max                  7.1943684
Log Pis Min                  -8.670519
Policy mu Mean               0.10226431
Policy mu Std                0.4789023
Policy mu Max                1.5495156
Policy mu Min                -1.8652332
Policy log std Mean          -0.87709904
Policy log std Std           0.2292549
Policy log std Max           -0.17622912
Policy log std Min           -2.258147
Z mean eval                  0.93591416
Z variance eval              0.009675875
total_rewards                [1565.63553236   40.02724233  231.89762916  859.32523506 1026.38341408
  186.65453621  187.63561893  820.71157214  908.06597689  243.12692937]
total_rewards_mean           606.9463686520609
total_rewards_std            473.4940535022991
total_rewards_max            1565.6355323635169
total_rewards_min            40.02724233287769
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               30.154253859072924
(Previous) Eval Time (s)     25.10922080092132
Sample Time (s)              18.23837898718193
Epoch Time (s)               73.50185364717618
Total Train Time (s)         7535.042568687815
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:21:06.560805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #108 | Epoch Duration: 75.69101691246033
2020-01-11 05:21:06.560966 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93608224
Z variance train             0.009671235
KL Divergence                17.764137
KL Loss                      1.7764138
QF Loss                      194.7917
VF Loss                      64.84381
Policy Loss                  -556.4995
Q Predictions Mean           555.53955
Q Predictions Std            97.67214
Q Predictions Max            711.8715
Q Predictions Min            305.7707
V Predictions Mean           561.9948
V Predictions Std            98.1311
V Predictions Max            726.71545
V Predictions Min            310.04224
Log Pis Mean                 -1.6498089
Log Pis Std                  1.8926964
Log Pis Max                  3.1932325
Log Pis Min                  -7.8599963
Policy mu Mean               0.007290663
Policy mu Std                0.46618193
Policy mu Max                1.4464076
Policy mu Min                -1.6392533
Policy log std Mean          -0.85117793
Policy log std Std           0.22142354
Policy log std Max           -0.22625408
Policy log std Min           -1.6794343
Z mean eval                  0.9211758
Z variance eval              0.0063700425
total_rewards                [1178.60655304 1367.71059327 1413.83654627 1346.70218043 1544.12296453
  244.89048069 1643.29325411 1286.81365538  544.74965906  153.88966092]
total_rewards_mean           1072.4615547711028
total_rewards_std            518.8035996540342
total_rewards_max            1643.2932541097937
total_rewards_min            153.8896609216666
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               28.16576306009665
(Previous) Eval Time (s)     27.298114887904376
Sample Time (s)              18.19211560720578
Epoch Time (s)               73.6559935552068
Total Train Time (s)         7608.330847520381
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:19.851714 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #109 | Epoch Duration: 73.29058504104614
2020-01-11 05:22:19.851971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #109 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9211893
Z variance train             0.006370564
KL Divergence                17.861292
KL Loss                      1.7861292
QF Loss                      381.39624
VF Loss                      60.694958
Policy Loss                  -550.3099
Q Predictions Mean           547.02966
Q Predictions Std            107.51134
Q Predictions Max            694.77026
Q Predictions Min            119.4753
V Predictions Mean           548.9729
V Predictions Std            106.457634
V Predictions Max            705.09534
V Predictions Min            106.38616
Log Pis Mean                 -1.586061
Log Pis Std                  2.108911
Log Pis Max                  3.7704253
Log Pis Min                  -13.572044
Policy mu Mean               0.026321728
Policy mu Std                0.4573756
Policy mu Max                1.4551425
Policy mu Min                -1.8048828
Policy log std Mean          -0.8624879
Policy log std Std           0.21943974
Policy log std Max           -0.30807748
Policy log std Min           -1.9048293
Z mean eval                  0.9253346
Z variance eval              0.0051375898
total_rewards                [ 7.97223290e+02  3.98145625e+02 -1.11344663e+00  3.16377526e+02
  1.10573893e+03  3.22259592e+02  1.44670673e+03  8.36770585e+02
  1.11458466e+03  1.05425708e+02]
total_rewards_mean           644.2119204182914
total_rewards_std            460.1260329169641
total_rewards_max            1446.7067310364218
total_rewards_min            -1.11344662650691
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               27.848459581378847
(Previous) Eval Time (s)     26.932418541051447
Sample Time (s)              19.736338697373867
Epoch Time (s)               74.51721681980416
Total Train Time (s)         7681.01406596601
Epoch                        110
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:23:32.538370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #110 | Epoch Duration: 72.68617653846741
2020-01-11 05:23:32.538682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9233754
Z variance train             0.005137729
KL Divergence                17.927814
KL Loss                      1.7927815
QF Loss                      298.4376
VF Loss                      53.374943
Policy Loss                  -557.88043
Q Predictions Mean           555.7134
Q Predictions Std            104.47747
Q Predictions Max            702.4659
Q Predictions Min            41.38307
V Predictions Mean           559.16974
V Predictions Std            102.044846
V Predictions Max            704.693
V Predictions Min            278.61313
Log Pis Mean                 -1.6755912
Log Pis Std                  2.2006388
Log Pis Max                  6.8382545
Log Pis Min                  -8.163701
Policy mu Mean               0.049754255
Policy mu Std                0.44695705
Policy mu Max                1.7117772
Policy mu Min                -1.6770167
Policy log std Mean          -0.86086357
Policy log std Std           0.24028242
Policy log std Max           -0.27076834
Policy log std Min           -1.8846439
Z mean eval                  0.934618
Z variance eval              0.005353306
total_rewards                [  80.51471877  235.76816394  734.35094287 1503.44025267  651.03471466
  669.76351979  114.79121642  824.74844432  -87.43902626 1693.72812092]
total_rewards_mean           642.0701068093498
total_rewards_std            564.0310142127778
total_rewards_max            1693.7281209237751
total_rewards_min            -87.43902626040912
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               29.725862396880984
(Previous) Eval Time (s)     25.10104104829952
Sample Time (s)              19.19725398812443
Epoch Time (s)               74.02415743330494
Total Train Time (s)         7758.339970597532
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:24:49.866738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #111 | Epoch Duration: 77.32780170440674
2020-01-11 05:24:49.866979 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93373835
Z variance train             0.0053522643
KL Divergence                17.966564
KL Loss                      1.7966565
QF Loss                      415.03595
VF Loss                      90.33437
Policy Loss                  -567.2175
Q Predictions Mean           563.2324
Q Predictions Std            110.702576
Q Predictions Max            697.09924
Q Predictions Min            -41.999992
V Predictions Mean           573.8457
V Predictions Std            109.30191
V Predictions Max            707.7017
V Predictions Min            36.808857
Log Pis Mean                 -1.8731169
Log Pis Std                  2.227248
Log Pis Max                  8.7775545
Log Pis Min                  -6.7852035
Policy mu Mean               0.016563015
Policy mu Std                0.44016066
Policy mu Max                1.5232313
Policy mu Min                -1.7856113
Policy log std Mean          -0.861519
Policy log std Std           0.24363509
Policy log std Max           -0.16526729
Policy log std Min           -2.1305523
Z mean eval                  0.92993575
Z variance eval              0.011091021
total_rewards                [1868.87674685  531.10801333 1667.89445146  321.74167109  -19.54145183
 1673.37608027  907.15894705  225.5221862  1793.67905816 1640.08354031]
total_rewards_mean           1060.9899242893553
total_rewards_std            706.0237244857826
total_rewards_max            1868.876746850444
total_rewards_min            -19.541451830972047
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               27.85778199089691
(Previous) Eval Time (s)     28.404383037239313
Sample Time (s)              18.84402336133644
Epoch Time (s)               75.10618838947266
Total Train Time (s)         7829.962251307908
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:26:01.491755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #112 | Epoch Duration: 71.62457036972046
2020-01-11 05:26:01.492055 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #112 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9282193
Z variance train             0.011081201
KL Divergence                16.006176
KL Loss                      1.6006176
QF Loss                      354.03253
VF Loss                      88.23481
Policy Loss                  -546.4563
Q Predictions Mean           543.3008
Q Predictions Std            124.87236
Q Predictions Max            707.4615
Q Predictions Min            -42.027477
V Predictions Mean           550.30096
V Predictions Std            123.70221
V Predictions Max            709.3335
V Predictions Min            -11.272998
Log Pis Mean                 -1.6145395
Log Pis Std                  2.3033268
Log Pis Max                  9.009993
Log Pis Min                  -12.723944
Policy mu Mean               0.039035566
Policy mu Std                0.45824483
Policy mu Max                1.9101868
Policy mu Min                -1.8295166
Policy log std Mean          -0.86663175
Policy log std Std           0.22987835
Policy log std Max           -0.15431434
Policy log std Min           -1.9634264
Z mean eval                  0.9161803
Z variance eval              0.007636045
total_rewards                [ 610.82774752  155.80071447 1643.33530171  218.62602825  713.80485178
  782.89045915 1260.21577446  157.24986321  275.61486154  595.4676744 ]
total_rewards_mean           641.3833276471773
total_rewards_std            468.8132231783175
total_rewards_max            1643.33530170607
total_rewards_min            155.8007144674824
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               29.393971015233546
(Previous) Eval Time (s)     24.92244157800451
Sample Time (s)              18.377691863570362
Epoch Time (s)               72.69410445680842
Total Train Time (s)         7894.806881075725
Epoch                        113
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:27:06.339883 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #113 | Epoch Duration: 64.84757542610168
2020-01-11 05:27:06.340148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91562384
Z variance train             0.0076542795
KL Divergence                16.927475
KL Loss                      1.6927475
QF Loss                      365.92786
VF Loss                      59.384453
Policy Loss                  -572.1737
Q Predictions Mean           568.54395
Q Predictions Std            112.521416
Q Predictions Max            711.4239
Q Predictions Min            188.7344
V Predictions Mean           569.688
V Predictions Std            115.41657
V Predictions Max            711.0171
V Predictions Min            40.39295
Log Pis Mean                 -1.8047633
Log Pis Std                  2.2897348
Log Pis Max                  5.8924203
Log Pis Min                  -7.435878
Policy mu Mean               0.0531661
Policy mu Std                0.460349
Policy mu Max                1.5776783
Policy mu Min                -1.7546841
Policy log std Mean          -0.84764385
Policy log std Std           0.25891972
Policy log std Max           -0.22153339
Policy log std Min           -2.652592
Z mean eval                  0.9537897
Z variance eval              0.0077698156
total_rewards                [ 869.48111776  -52.54355708  602.4314882  1243.7071344   601.40266744
  872.68789653  289.40103016  597.73274825  340.30294829  455.95759418]
total_rewards_mean           582.0561068145867
total_rewards_std            341.8488570872726
total_rewards_max            1243.7071343975038
total_rewards_min            -52.54355707603433
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               27.15873744804412
(Previous) Eval Time (s)     17.075596934184432
Sample Time (s)              17.938863972667605
Epoch Time (s)               62.17319835489616
Total Train Time (s)         7966.247430819552
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:28:17.782195 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #114 | Epoch Duration: 71.44182968139648
2020-01-11 05:28:17.782460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9533638
Z variance train             0.0077377246
KL Divergence                16.63058
KL Loss                      1.6630582
QF Loss                      311.76114
VF Loss                      140.95381
Policy Loss                  -572.1971
Q Predictions Mean           570.8267
Q Predictions Std            114.061615
Q Predictions Max            723.68805
Q Predictions Min            305.59128
V Predictions Mean           577.4499
V Predictions Std            113.518074
V Predictions Max            734.57294
V Predictions Min            318.24268
Log Pis Mean                 -1.542867
Log Pis Std                  2.287833
Log Pis Max                  5.411988
Log Pis Min                  -8.755628
Policy mu Mean               0.008277988
Policy mu Std                0.45850083
Policy mu Max                1.5245247
Policy mu Min                -1.6164142
Policy log std Mean          -0.879087
Policy log std Std           0.25145158
Policy log std Max           -0.18966246
Policy log std Min           -2.3329828
Z mean eval                  0.93285215
Z variance eval              0.010292156
total_rewards                [ 637.31652813  936.13993687 1129.01841761   28.05002719  180.50926974
  757.48788045  393.91251291 1020.8736614    13.5984883   -27.35763315]
total_rewards_mean           506.95490894543946
total_rewards_std            423.3936557829409
total_rewards_max            1129.018417610857
total_rewards_min            -27.357633151091747
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               27.177924289833754
(Previous) Eval Time (s)     26.34390235831961
Sample Time (s)              18.49580220831558
Epoch Time (s)               72.01762885646895
Total Train Time (s)         8037.183885743376
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:29:28.722369 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #115 | Epoch Duration: 70.93968415260315
2020-01-11 05:29:28.722635 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93229026
Z variance train             0.010283263
KL Divergence                16.674381
KL Loss                      1.6674381
QF Loss                      536.92737
VF Loss                      132.05301
Policy Loss                  -576.97894
Q Predictions Mean           575.1394
Q Predictions Std            122.7784
Q Predictions Max            751.34534
Q Predictions Min            -69.4539
V Predictions Mean           579.2433
V Predictions Std            115.84004
V Predictions Max            730.6713
V Predictions Min            -9.08072
Log Pis Mean                 -1.5774386
Log Pis Std                  2.2662401
Log Pis Max                  7.689188
Log Pis Min                  -7.1172314
Policy mu Mean               0.03629465
Policy mu Std                0.49120852
Policy mu Max                2.531624
Policy mu Min                -1.7312338
Policy log std Mean          -0.8431407
Policy log std Std           0.24782886
Policy log std Max           -0.0871315
Policy log std Min           -2.6306756
Z mean eval                  0.94343597
Z variance eval              0.006873826
total_rewards                [1602.49712733  358.97492833  -52.00947991  388.45524468  666.79952726
 1594.69384727 1666.59123616  -60.95267191  597.03772727 1649.8898642 ]
total_rewards_mean           841.1977350677267
total_rewards_std            679.8403102978657
total_rewards_max            1666.5912361574847
total_rewards_min            -60.9526719142986
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               29.060352549888194
(Previous) Eval Time (s)     25.265624797903
Sample Time (s)              17.97158039174974
Epoch Time (s)               72.29755773954093
Total Train Time (s)         8108.555500312243
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:30:40.096253 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #116 | Epoch Duration: 71.37339973449707
2020-01-11 05:30:40.096538 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9407573
Z variance train             0.0068937526
KL Divergence                17.99228
KL Loss                      1.799228
QF Loss                      400.43195
VF Loss                      115.97214
Policy Loss                  -574.84143
Q Predictions Mean           571.379
Q Predictions Std            124.56507
Q Predictions Max            733.96606
Q Predictions Min            124.484566
V Predictions Mean           573.31586
V Predictions Std            122.13378
V Predictions Max            735.953
V Predictions Min            159.64833
Log Pis Mean                 -1.8840573
Log Pis Std                  2.1550813
Log Pis Max                  7.1960793
Log Pis Min                  -7.8575335
Policy mu Mean               0.07259525
Policy mu Std                0.46518773
Policy mu Max                2.2190075
Policy mu Min                -1.4040923
Policy log std Mean          -0.8230223
Policy log std Std           0.23280749
Policy log std Max           -0.09776986
Policy log std Min           -1.7668021
Z mean eval                  0.92332065
Z variance eval              0.0044443947
total_rewards                [  49.88695657  161.78167311  473.40392182  625.1317527  1753.69707904
  401.24401318  256.53309779  679.35045107  150.7638645   554.59804125]
total_rewards_mean           510.63908510254385
total_rewards_std            461.5328207458067
total_rewards_max            1753.6970790436537
total_rewards_min            49.88695656890174
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               29.55249900696799
(Previous) Eval Time (s)     24.341188246849924
Sample Time (s)              17.4481344637461
Epoch Time (s)               71.34182171756402
Total Train Time (s)         8177.910752178635
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:31:49.455138 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #117 | Epoch Duration: 69.35835123062134
2020-01-11 05:31:49.455436 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92551214
Z variance train             0.004424981
KL Divergence                18.92207
KL Loss                      1.892207
QF Loss                      298.6646
VF Loss                      115.85767
Policy Loss                  -594.6694
Q Predictions Mean           588.3955
Q Predictions Std            106.39401
Q Predictions Max            733.4352
Q Predictions Min            282.24014
V Predictions Mean           586.7746
V Predictions Std            105.09987
V Predictions Max            718.18414
V Predictions Min            277.93304
Log Pis Mean                 -1.5937026
Log Pis Std                  2.0473685
Log Pis Max                  5.6574802
Log Pis Min                  -8.344028
Policy mu Mean               0.06315845
Policy mu Std                0.46364865
Policy mu Max                1.6655357
Policy mu Min                -1.8443837
Policy log std Mean          -0.86543536
Policy log std Std           0.21423362
Policy log std Max           -0.16028169
Policy log std Min           -1.6414402
Z mean eval                  0.91275537
Z variance eval              0.0048040827
total_rewards                [ 620.22397498  542.60303513  349.65363293 1318.45943407   13.14409393
 1705.522451    108.03928479    6.00810814   63.80864784  609.32685422]
total_rewards_mean           533.6789517023203
total_rewards_std            546.5890121076394
total_rewards_max            1705.5224510006883
total_rewards_min            6.008108139783602
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               26.592080089263618
(Previous) Eval Time (s)     22.357420743908733
Sample Time (s)              17.683137335348874
Epoch Time (s)               66.63263816852123
Total Train Time (s)         8248.548113573343
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:33:00.092170 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #118 | Epoch Duration: 70.63651394844055
2020-01-11 05:33:00.092409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #118 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91496944
Z variance train             0.00480944
KL Divergence                19.255348
KL Loss                      1.9255348
QF Loss                      328.88745
VF Loss                      80.24624
Policy Loss                  -584.7823
Q Predictions Mean           580.8489
Q Predictions Std            116.170074
Q Predictions Max            736.8417
Q Predictions Min            282.6449
V Predictions Mean           580.7568
V Predictions Std            113.77155
V Predictions Max            730.25323
V Predictions Min            277.35403
Log Pis Mean                 -1.7827002
Log Pis Std                  2.2746358
Log Pis Max                  6.7317867
Log Pis Min                  -8.391139
Policy mu Mean               0.05589692
Policy mu Std                0.46951807
Policy mu Max                1.8012033
Policy mu Min                -1.6942004
Policy log std Mean          -0.8433738
Policy log std Std           0.23627877
Policy log std Max           -0.16739535
Policy log std Min           -1.8536198
Z mean eval                  0.9395053
Z variance eval              0.005618044
total_rewards                [7.92962751e+02 1.59718981e+02 1.30173982e+02 8.92861467e+01
 6.76870723e-01 5.07496937e+02 1.73382113e+03 1.20111055e+03
 8.46591742e+02 3.39076850e+02]
total_rewards_mean           580.0915941142248
total_rewards_std            534.0600468959486
total_rewards_max            1733.821128442882
total_rewards_min            0.6768707231070898
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               32.422123988159
(Previous) Eval Time (s)     26.361012667883188
Sample Time (s)              17.44400376966223
Epoch Time (s)               76.22714042570442
Total Train Time (s)         8323.096208659466
Epoch                        119
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:34:14.644528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #119 | Epoch Duration: 74.55196738243103
2020-01-11 05:34:14.644802 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9383742
Z variance train             0.00567486
KL Divergence                19.324652
KL Loss                      1.9324652
QF Loss                      287.05954
VF Loss                      97.73711
Policy Loss                  -578.86383
Q Predictions Mean           575.3991
Q Predictions Std            129.45155
Q Predictions Max            739.61957
Q Predictions Min            -44.065582
V Predictions Mean           582.6773
V Predictions Std            128.5334
V Predictions Max            743.0028
V Predictions Min            -4.251669
Log Pis Mean                 -2.0668674
Log Pis Std                  2.0090969
Log Pis Max                  4.4077682
Log Pis Min                  -8.061613
Policy mu Mean               0.04339601
Policy mu Std                0.46051052
Policy mu Max                2.1221783
Policy mu Min                -2.8012545
Policy log std Mean          -0.81090844
Policy log std Std           0.21949492
Policy log std Max           -0.08966583
Policy log std Min           -1.4631684
Z mean eval                  0.9392377
Z variance eval              0.0063231466
total_rewards                [ 361.82852548 1681.29415033  487.87664034 1605.57691569  111.45997177
  681.9167269  1711.33612766 1331.32667584  614.91595821  244.41450166]
total_rewards_mean           883.1946193874892
total_rewards_std            599.1359849536444
total_rewards_max            1711.3361276581288
total_rewards_min            111.45997176709442
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               28.932871445082128
(Previous) Eval Time (s)     24.68553935131058
Sample Time (s)              17.833680057432503
Epoch Time (s)               71.45209085382521
Total Train Time (s)         8393.523124356288
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:35:25.074073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #120 | Epoch Duration: 70.4290554523468
2020-01-11 05:35:25.074306 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #120 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93978167
Z variance train             0.006312574
KL Divergence                19.125546
KL Loss                      1.9125546
QF Loss                      412.12653
VF Loss                      60.414017
Policy Loss                  -584.21594
Q Predictions Mean           580.9603
Q Predictions Std            118.297935
Q Predictions Max            741.43713
Q Predictions Min            268.48798
V Predictions Mean           581.4363
V Predictions Std            117.204956
V Predictions Max            738.0497
V Predictions Min            261.79486
Log Pis Mean                 -1.7907848
Log Pis Std                  2.1331217
Log Pis Max                  4.204361
Log Pis Min                  -9.360911
Policy mu Mean               0.01155327
Policy mu Std                0.47582847
Policy mu Max                1.5303793
Policy mu Min                -1.5980283
Policy log std Mean          -0.8221741
Policy log std Std           0.21486324
Policy log std Max           -0.1379947
Policy log std Min           -1.7666773
Z mean eval                  0.93001926
Z variance eval              0.014714694
total_rewards                [ 362.5348143   958.31427487  267.45553093  658.61443461   96.41467044
 1032.84751597 1609.69387388 -128.1012668  1109.21426843  178.96214747]
total_rewards_mean           614.5950264105654
total_rewards_std            521.9013830417191
total_rewards_max            1609.6938738759623
total_rewards_min            -128.1012667952574
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               27.14835422579199
(Previous) Eval Time (s)     23.662231401074678
Sample Time (s)              17.84651780175045
Epoch Time (s)               68.65710342861712
Total Train Time (s)         8461.68147663027
Epoch                        121
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:36:33.232292 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #121 | Epoch Duration: 68.15779256820679
2020-01-11 05:36:33.232519 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93251514
Z variance train             0.014671823
KL Divergence                18.034428
KL Loss                      1.8034428
QF Loss                      501.80392
VF Loss                      233.3757
Policy Loss                  -589.69415
Q Predictions Mean           586.8684
Q Predictions Std            126.418106
Q Predictions Max            787.57404
Q Predictions Min            -4.6905065
V Predictions Mean           579.71515
V Predictions Std            124.86651
V Predictions Max            776.0843
V Predictions Min            -2.2315085
Log Pis Mean                 -1.7126689
Log Pis Std                  2.3084404
Log Pis Max                  7.8014393
Log Pis Min                  -7.6947584
Policy mu Mean               0.11122786
Policy mu Std                0.4834446
Policy mu Max                1.6993474
Policy mu Min                -1.9233183
Policy log std Mean          -0.8218816
Policy log std Std           0.25126553
Policy log std Max           -0.24429405
Policy log std Min           -2.3495564
Z mean eval                  0.9338705
Z variance eval              0.0074159494
total_rewards                [ 518.71530997  439.82546137 1350.31154762 1551.24297514 1286.66248667
 1890.8429329  1913.71768832  289.93866584 1709.93354675  595.9927782 ]
total_rewards_mean           1154.7183392778588
total_rewards_std            601.2246601867479
total_rewards_max            1913.7176883182385
total_rewards_min            289.93866583938774
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               29.92198373703286
(Previous) Eval Time (s)     23.162637814879417
Sample Time (s)              17.736866601742804
Epoch Time (s)               70.82148815365508
Total Train Time (s)         8534.061844027601
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:37:45.616191 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #122 | Epoch Duration: 72.38353300094604
2020-01-11 05:37:45.616410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93293446
Z variance train             0.0074134893
KL Divergence                19.148727
KL Loss                      1.9148728
QF Loss                      352.3419
VF Loss                      56.82625
Policy Loss                  -601.51
Q Predictions Mean           598.95996
Q Predictions Std            119.23402
Q Predictions Max            745.8651
Q Predictions Min            279.31924
V Predictions Mean           603.66003
V Predictions Std            118.598694
V Predictions Max            751.5461
V Predictions Min            255.37276
Log Pis Mean                 -1.5589592
Log Pis Std                  2.1117842
Log Pis Max                  5.5799623
Log Pis Min                  -7.1270285
Policy mu Mean               0.03885386
Policy mu Std                0.47654995
Policy mu Max                1.8606839
Policy mu Min                -1.5619774
Policy log std Mean          -0.8358262
Policy log std Std           0.22709921
Policy log std Max           -0.1614669
Policy log std Min           -1.8453732
Z mean eval                  0.9185494
Z variance eval              0.009443773
total_rewards                [ 271.93353966  118.04975115  882.27410836  110.76591963 1716.56459419
   74.08239101 1918.08877235 1778.36947519 1678.43969723   58.49675643]
total_rewards_mean           860.7065005219904
total_rewards_std            780.0467875672554
total_rewards_max            1918.0887723542278
total_rewards_min            58.49675643406991
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               29.47455327026546
(Previous) Eval Time (s)     24.72436079988256
Sample Time (s)              17.924384823534638
Epoch Time (s)               72.12329889368266
Total Train Time (s)         8603.878644882701
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:38:55.435531 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #123 | Epoch Duration: 69.81892824172974
2020-01-11 05:38:55.435817 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91766226
Z variance train             0.009444478
KL Divergence                19.044281
KL Loss                      1.9044281
QF Loss                      420.94165
VF Loss                      47.634186
Policy Loss                  -587.4625
Q Predictions Mean           585.8115
Q Predictions Std            134.48749
Q Predictions Max            730.6852
Q Predictions Min            -47.56726
V Predictions Mean           588.3467
V Predictions Std            133.55463
V Predictions Max            735.30865
V Predictions Min            -7.051205
Log Pis Mean                 -1.8133187
Log Pis Std                  2.3666909
Log Pis Max                  8.223674
Log Pis Min                  -7.570896
Policy mu Mean               0.043090887
Policy mu Std                0.46301743
Policy mu Max                1.4785199
Policy mu Min                -2.5397434
Policy log std Mean          -0.82477343
Policy log std Std           0.2517493
Policy log std Max           0.44145662
Policy log std Min           -2.0565896
Z mean eval                  0.929797
Z variance eval              0.010721324
total_rewards                [1167.42544852 1663.57846867 1825.06802294  528.7323575   547.90949909
  154.5389332   246.56725463  231.99729975 1658.18817304  502.09088171]
total_rewards_mean           852.6096339034409
total_rewards_std            625.4409120878734
total_rewards_max            1825.068022938739
total_rewards_min            154.53893319535067
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               27.15427488507703
(Previous) Eval Time (s)     22.41965516936034
Sample Time (s)              18.406266757752746
Epoch Time (s)               67.98019681219012
Total Train Time (s)         8673.135308921803
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:40:04.700957 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #124 | Epoch Duration: 69.2649154663086
2020-01-11 05:40:04.701164 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9272634
Z variance train             0.010748374
KL Divergence                18.632656
KL Loss                      1.8632656
QF Loss                      524.6518
VF Loss                      128.64157
Policy Loss                  -588.96014
Q Predictions Mean           586.9171
Q Predictions Std            144.15097
Q Predictions Max            765.19586
Q Predictions Min            -0.586463
V Predictions Mean           591.74194
V Predictions Std            139.79918
V Predictions Max            765.42145
V Predictions Min            80.75149
Log Pis Mean                 -1.6057677
Log Pis Std                  2.2381794
Log Pis Max                  8.917685
Log Pis Min                  -7.148918
Policy mu Mean               0.037810963
Policy mu Std                0.50464386
Policy mu Max                1.933537
Policy mu Min                -1.6187979
Policy log std Mean          -0.8144204
Policy log std Std           0.2506722
Policy log std Max           -0.13655692
Policy log std Min           -2.3056564
Z mean eval                  0.9321602
Z variance eval              0.013728115
total_rewards                [1590.66100769  996.66346737  456.00902291 1321.15298761 1577.76263289
 1790.92371536 1709.5430289  1721.15415515 1637.69762176 1775.42474345]
total_rewards_mean           1457.6992383088827
total_rewards_std            405.4500528990742
total_rewards_max            1790.9237153619679
total_rewards_min            456.0090229131713
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               30.70042227813974
(Previous) Eval Time (s)     23.70405373442918
Sample Time (s)              17.94996698619798
Epoch Time (s)               72.3544429987669
Total Train Time (s)         8749.205912117846
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:41:20.766312 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #125 | Epoch Duration: 76.06498742103577
2020-01-11 05:41:20.766502 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9323524
Z variance train             0.013734673
KL Divergence                18.289227
KL Loss                      1.8289226
QF Loss                      394.44232
VF Loss                      90.56522
Policy Loss                  -584.741
Q Predictions Mean           582.28723
Q Predictions Std            140.697
Q Predictions Max            747.2014
Q Predictions Min            -71.64131
V Predictions Mean           583.5115
V Predictions Std            137.73273
V Predictions Max            753.5011
V Predictions Min            1.9490318
Log Pis Mean                 -1.6476173
Log Pis Std                  2.0764523
Log Pis Max                  7.5368443
Log Pis Min                  -6.8133674
Policy mu Mean               0.102437325
Policy mu Std                0.45170245
Policy mu Max                1.9834675
Policy mu Min                -1.3687713
Policy log std Mean          -0.8581947
Policy log std Std           0.24064074
Policy log std Max           -0.22262546
Policy log std Min           -2.1563585
Z mean eval                  0.930313
Z variance eval              0.01272313
total_rewards                [  82.50057338   96.77479322 1840.26916577  722.89647664  107.27103405
  253.34399556 1501.16850723 1153.92368904  988.55339954  541.91909396]
total_rewards_mean           728.8620728397211
total_rewards_std            595.3648932890351
total_rewards_max            1840.269165772421
total_rewards_min            82.50057337846384
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               28.369376676157117
(Previous) Eval Time (s)     27.414276191033423
Sample Time (s)              18.541628325823694
Epoch Time (s)               74.32528119301423
Total Train Time (s)         8820.435884302016
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:42:31.997586 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #126 | Epoch Duration: 71.23093676567078
2020-01-11 05:42:31.997762 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.928185
Z variance train             0.012692327
KL Divergence                18.358612
KL Loss                      1.8358612
QF Loss                      349.56665
VF Loss                      130.91824
Policy Loss                  -605.8388
Q Predictions Mean           601.458
Q Predictions Std            134.38809
Q Predictions Max            766.88306
Q Predictions Min            -70.76646
V Predictions Mean           602.4508
V Predictions Std            128.71379
V Predictions Max            763.0793
V Predictions Min            -0.47446483
Log Pis Mean                 -1.4604111
Log Pis Std                  2.130357
Log Pis Max                  4.6127567
Log Pis Min                  -8.203983
Policy mu Mean               0.050987177
Policy mu Std                0.47734678
Policy mu Max                1.5213798
Policy mu Min                -1.8028384
Policy log std Mean          -0.85378563
Policy log std Std           0.23925236
Policy log std Max           -0.2787561
Policy log std Min           -1.9103261
Z mean eval                  0.922623
Z variance eval              0.010802831
total_rewards                [ 527.44360748  108.27950348 1143.74344334 1852.29130737 1374.70929929
 1803.93831712 1710.03256058 1885.49891544 1059.20039863  515.05806739]
total_rewards_mean           1198.0195420120401
total_rewards_std            607.2126527167025
total_rewards_max            1885.4989154438736
total_rewards_min            108.27950348286257
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               31.081621384248137
(Previous) Eval Time (s)     24.3195859240368
Sample Time (s)              17.734809149522334
Epoch Time (s)               73.13601645780727
Total Train Time (s)         8891.761330638546
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:43:43.326040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #127 | Epoch Duration: 71.32812404632568
2020-01-11 05:43:43.326224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92348033
Z variance train             0.010809407
KL Divergence                17.917023
KL Loss                      1.7917023
QF Loss                      445.812
VF Loss                      98.763245
Policy Loss                  -631.2636
Q Predictions Mean           627.2639
Q Predictions Std            100.20642
Q Predictions Max            752.69165
Q Predictions Min            254.93416
V Predictions Mean           625.6181
V Predictions Std            98.66254
V Predictions Max            740.41895
V Predictions Min            237.06084
Log Pis Mean                 -1.6096487
Log Pis Std                  2.1639252
Log Pis Max                  6.793354
Log Pis Min                  -8.449963
Policy mu Mean               0.0261508
Policy mu Std                0.4741408
Policy mu Max                1.517068
Policy mu Min                -1.6196196
Policy log std Mean          -0.8822725
Policy log std Std           0.23524833
Policy log std Max           -0.27767715
Policy log std Min           -2.448907
Z mean eval                  0.9320487
Z variance eval              0.018525943
total_rewards                [1888.78686047 1862.49799425   99.5790784  1840.61683674 1723.41681381
  320.19780703 1828.58934802  860.06960997  245.46247604 1456.91119725]
total_rewards_mean           1212.6128021973211
total_rewards_std            711.9617817073704
total_rewards_max            1888.7868604681046
total_rewards_min            99.57907839587618
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               26.33798607904464
(Previous) Eval Time (s)     22.511397717054933
Sample Time (s)              17.984405836090446
Epoch Time (s)               66.83378963219002
Total Train Time (s)         8960.60968115693
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:44:52.175184 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #128 | Epoch Duration: 68.84881472587585
2020-01-11 05:44:52.175368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9325325
Z variance train             0.018584544
KL Divergence                17.267946
KL Loss                      1.7267946
QF Loss                      1954.2333
VF Loss                      105.0964
Policy Loss                  -570.00354
Q Predictions Mean           567.0167
Q Predictions Std            131.49936
Q Predictions Max            735.45233
Q Predictions Min            31.443651
V Predictions Mean           572.9037
V Predictions Std            130.41536
V Predictions Max            742.8759
V Predictions Min            2.3555362
Log Pis Mean                 -1.4757204
Log Pis Std                  2.3463037
Log Pis Max                  7.2162485
Log Pis Min                  -8.57498
Policy mu Mean               -0.0019380865
Policy mu Std                0.50112206
Policy mu Max                1.3944246
Policy mu Min                -1.5521566
Policy log std Mean          -0.87187207
Policy log std Std           0.25397688
Policy log std Max           -0.18504876
Policy log std Min           -2.2483377
Z mean eval                  0.9495449
Z variance eval              0.017732408
total_rewards                [1001.80973102 1962.98049838 1889.45899009 1480.23188023  486.04088029
  923.41274415  182.37223109 1145.1614591  1930.59372811  587.05839683]
total_rewards_mean           1158.912053929565
total_rewards_std            607.6755974194995
total_rewards_max            1962.9804983758152
total_rewards_min            182.37223108684773
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               29.33234988618642
(Previous) Eval Time (s)     24.526102629955858
Sample Time (s)              18.311002573929727
Epoch Time (s)               72.169455090072
Total Train Time (s)         9033.424598601181
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:46:04.992128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #129 | Epoch Duration: 72.81661486625671
2020-01-11 05:46:04.992319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9479321
Z variance train             0.01778176
KL Divergence                16.91266
KL Loss                      1.6912661
QF Loss                      311.5598
VF Loss                      54.80452
Policy Loss                  -614.46173
Q Predictions Mean           611.6501
Q Predictions Std            129.83775
Q Predictions Max            769.46954
Q Predictions Min            274.45676
V Predictions Mean           617.7069
V Predictions Std            130.48961
V Predictions Max            767.93384
V Predictions Min            281.38727
Log Pis Mean                 -1.7140651
Log Pis Std                  2.290611
Log Pis Max                  4.587346
Log Pis Min                  -10.829669
Policy mu Mean               0.03296018
Policy mu Std                0.5082161
Policy mu Max                1.5027554
Policy mu Min                -1.6868204
Policy log std Mean          -0.81218404
Policy log std Std           0.23653871
Policy log std Max           -0.13360924
Policy log std Min           -1.6743766
Z mean eval                  0.9438853
Z variance eval              0.01686069
total_rewards                [1569.10451065  296.03607957  234.70024589 1078.58533353 1723.06640993
  604.90967592   30.81194754  420.75549186  558.15020187   29.5783007 ]
total_rewards_mean           654.5698197458734
total_rewards_std            575.2221324387681
total_rewards_max            1723.0664099272144
total_rewards_min            29.57830069830018
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               28.86149015603587
(Previous) Eval Time (s)     25.17295277863741
Sample Time (s)              18.455036654602736
Epoch Time (s)               72.48947958927602
Total Train Time (s)         9108.005001373123
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:47:19.576959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #130 | Epoch Duration: 74.58446455001831
2020-01-11 05:47:19.577247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93988484
Z variance train             0.016879803
KL Divergence                16.239616
KL Loss                      1.6239617
QF Loss                      391.141
VF Loss                      67.07724
Policy Loss                  -594.6142
Q Predictions Mean           592.228
Q Predictions Std            147.0053
Q Predictions Max            765.7836
Q Predictions Min            -14.760094
V Predictions Mean           590.80066
V Predictions Std            147.3336
V Predictions Max            759.9931
V Predictions Min            6.0946136
Log Pis Mean                 -1.4341555
Log Pis Std                  2.5201948
Log Pis Max                  8.7747555
Log Pis Min                  -8.553055
Policy mu Mean               -0.018358238
Policy mu Std                0.4934931
Policy mu Max                1.6619216
Policy mu Min                -1.8303086
Policy log std Mean          -0.85910815
Policy log std Std           0.26545608
Policy log std Max           -0.032764375
Policy log std Min           -2.1276364
Z mean eval                  0.9599248
Z variance eval              0.012054667
total_rewards                [ 595.2129721  1722.59343407 1538.37883313 1528.36518867 1595.24540497
 1593.15296746 1686.02571407  406.14310337 1600.38132877 1477.86556249]
total_rewards_mean           1374.3364509081055
total_rewards_std            444.07157411988675
total_rewards_max            1722.5934340696901
total_rewards_min            406.14310336967617
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               29.614381862338632
(Previous) Eval Time (s)     27.267592686694115
Sample Time (s)              18.331947466358542
Epoch Time (s)               75.21392201539129
Total Train Time (s)         9183.55745117087
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:48:35.131982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #131 | Epoch Duration: 75.55449891090393
2020-01-11 05:48:35.132244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9599142
Z variance train             0.012048892
KL Divergence                16.523834
KL Loss                      1.6523834
QF Loss                      658.43695
VF Loss                      62.705807
Policy Loss                  -616.90784
Q Predictions Mean           613.37946
Q Predictions Std            140.44853
Q Predictions Max            779.4036
Q Predictions Min            -29.928007
V Predictions Mean           615.42426
V Predictions Std            137.59193
V Predictions Max            773.9059
V Predictions Min            35.00443
Log Pis Mean                 -1.4662322
Log Pis Std                  2.2660909
Log Pis Max                  10.8426695
Log Pis Min                  -7.181153
Policy mu Mean               0.021306185
Policy mu Std                0.5147457
Policy mu Max                1.7396464
Policy mu Min                -2.8540013
Policy log std Mean          -0.81264335
Policy log std Std           0.23238827
Policy log std Max           -0.14009604
Policy log std Min           -1.64065
Z mean eval                  0.9272725
Z variance eval              0.01558467
total_rewards                [1817.29347194 1890.00279539 1349.58138687  874.505863     62.18686765
  683.97063542 1100.0214828   219.42622055  580.97680619 1139.52447702]
total_rewards_mean           971.7490006846976
total_rewards_std            581.7012634699877
total_rewards_max            1890.0027953857896
total_rewards_min            62.186867650540606
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               28.519165951292962
(Previous) Eval Time (s)     27.607852045912296
Sample Time (s)              18.332689722068608
Epoch Time (s)               74.45970771927387
Total Train Time (s)         9255.594023917336
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:49:47.170158 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #132 | Epoch Duration: 72.03773140907288
2020-01-11 05:49:47.170343 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9285264
Z variance train             0.015506836
KL Divergence                16.82597
KL Loss                      1.682597
QF Loss                      408.0681
VF Loss                      295.50977
Policy Loss                  -614.3654
Q Predictions Mean           609.24207
Q Predictions Std            143.69841
Q Predictions Max            787.2321
Q Predictions Min            14.35407
V Predictions Mean           613.85956
V Predictions Std            142.07922
V Predictions Max            785.93695
V Predictions Min            21.292439
Log Pis Mean                 -1.5237851
Log Pis Std                  2.471336
Log Pis Max                  9.4638
Log Pis Min                  -7.7910385
Policy mu Mean               0.048613288
Policy mu Std                0.50475997
Policy mu Max                1.6300956
Policy mu Min                -1.7266674
Policy log std Mean          -0.8362593
Policy log std Std           0.26224133
Policy log std Max           -0.093515694
Policy log std Min           -2.5465417
Z mean eval                  0.9459686
Z variance eval              0.010901848
total_rewards                [1723.49204541 1830.51225832 1877.71639268  248.63453708 1344.96811032
 1752.99621713 1840.98676548  103.69684484 1599.77341729 1174.70611874]
total_rewards_mean           1349.7482707270933
total_rewards_std            625.4409414870605
total_rewards_max            1877.7163926764815
total_rewards_min            103.69684483667237
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               30.52769614942372
(Previous) Eval Time (s)     25.185590866021812
Sample Time (s)              17.82089738594368
Epoch Time (s)               73.53418440138921
Total Train Time (s)         9330.712644591462
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:51:02.289778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #133 | Epoch Duration: 75.11929631233215
2020-01-11 05:51:02.289959 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.945666
Z variance train             0.010883558
KL Divergence                17.568356
KL Loss                      1.7568356
QF Loss                      464.03375
VF Loss                      76.57423
Policy Loss                  -622.8328
Q Predictions Mean           619.5637
Q Predictions Std            136.5143
Q Predictions Max            788.4484
Q Predictions Min            43.910103
V Predictions Mean           619.2096
V Predictions Std            132.18068
V Predictions Max            782.1267
V Predictions Min            125.69851
Log Pis Mean                 -1.729158
Log Pis Std                  2.437623
Log Pis Max                  4.9716425
Log Pis Min                  -7.732907
Policy mu Mean               0.074693926
Policy mu Std                0.48519778
Policy mu Max                2.1606472
Policy mu Min                -1.7605885
Policy log std Mean          -0.84857315
Policy log std Std           0.24001229
Policy log std Max           -0.22770134
Policy log std Min           -2.000152
Z mean eval                  0.91918737
Z variance eval              0.01051235
total_rewards                [  49.96979001 1901.54414577  121.22798402 1434.07471134  603.08084641
   -6.05247443 1523.15594145 1749.36582203  225.18282719 1543.67108951]
total_rewards_mean           914.5220683299891
total_rewards_std            741.8748657742692
total_rewards_max            1901.5441457681366
total_rewards_min            -6.0524744324720565
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               29.08489962760359
(Previous) Eval Time (s)     26.770401720888913
Sample Time (s)              19.838583051692694
Epoch Time (s)               75.6938844001852
Total Train Time (s)         9403.823047568556
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:52:15.401771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #134 | Epoch Duration: 73.11169075965881
2020-01-11 05:52:15.401984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #134 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9186031
Z variance train             0.010492741
KL Divergence                17.625233
KL Loss                      1.7625233
QF Loss                      490.44766
VF Loss                      91.17157
Policy Loss                  -619.77344
Q Predictions Mean           615.4346
Q Predictions Std            132.11887
Q Predictions Max            770.6629
Q Predictions Min            -20.750174
V Predictions Mean           614.1891
V Predictions Std            129.86707
V Predictions Max            764.3712
V Predictions Min            -14.134573
Log Pis Mean                 -1.7180107
Log Pis Std                  2.1829348
Log Pis Max                  6.5231485
Log Pis Min                  -7.9608836
Policy mu Mean               0.016135775
Policy mu Std                0.5104664
Policy mu Max                2.3355143
Policy mu Min                -1.7539515
Policy log std Mean          -0.822973
Policy log std Std           0.23386031
Policy log std Max           -0.29776126
Policy log std Min           -2.3085666
Z mean eval                  0.901194
Z variance eval              0.007522373
total_rewards                [1038.72980211 1979.0409154  1032.04429372   92.84142411  384.89555777
 1333.64603133 1291.49162828  131.27315726  628.94943948  701.366222  ]
total_rewards_mean           861.427847144595
total_rewards_std            561.0837470699469
total_rewards_max            1979.0409154013712
total_rewards_min            92.84142411272106
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               28.89182218303904
(Previous) Eval Time (s)     24.18790235929191
Sample Time (s)              19.067602030467242
Epoch Time (s)               72.14732657279819
Total Train Time (s)         9479.674215978011
Epoch                        135
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:53:31.256805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #135 | Epoch Duration: 75.85463333129883
2020-01-11 05:53:31.257187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9012583
Z variance train             0.0075200596
KL Divergence                18.028666
KL Loss                      1.8028666
QF Loss                      384.039
VF Loss                      57.551105
Policy Loss                  -624.37946
Q Predictions Mean           620.12085
Q Predictions Std            140.20262
Q Predictions Max            786.6228
Q Predictions Min            246.22581
V Predictions Mean           621.50305
V Predictions Std            140.60127
V Predictions Max            788.9514
V Predictions Min            242.99313
Log Pis Mean                 -1.4573505
Log Pis Std                  2.3482819
Log Pis Max                  7.485525
Log Pis Min                  -8.524056
Policy mu Mean               0.023633918
Policy mu Std                0.50201106
Policy mu Max                1.8015378
Policy mu Min                -1.4821355
Policy log std Mean          -0.82407403
Policy log std Std           0.24680708
Policy log std Max           -0.21921584
Policy log std Min           -2.468577
Z mean eval                  0.9241473
Z variance eval              0.009922966
total_rewards                [ 206.03174591 1761.60127488 1627.07957869 1060.47813961 1551.32663562
 1853.76440632 1224.85777095 1693.49258031  537.058625   1836.57025941]
total_rewards_mean           1335.2261016687014
total_rewards_std            544.2495120574645
total_rewards_max            1853.764406323
total_rewards_min            206.03174590540448
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               27.966662431135774
(Previous) Eval Time (s)     27.8948365887627
Sample Time (s)              18.90930665563792
Epoch Time (s)               74.7708056755364
Total Train Time (s)         9550.144697886426
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:54:41.730750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #136 | Epoch Duration: 70.47328639030457
2020-01-11 05:54:41.731033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #136 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9236954
Z variance train             0.009910343
KL Divergence                17.750977
KL Loss                      1.7750977
QF Loss                      361.69293
VF Loss                      67.85152
Policy Loss                  -639.7775
Q Predictions Mean           636.9262
Q Predictions Std            133.47603
Q Predictions Max            807.1732
Q Predictions Min            273.8186
V Predictions Mean           645.13684
V Predictions Std            133.90244
V Predictions Max            815.0414
V Predictions Min            269.05127
Log Pis Mean                 -1.6239429
Log Pis Std                  2.245696
Log Pis Max                  6.7256155
Log Pis Min                  -11.315355
Policy mu Mean               0.06255646
Policy mu Std                0.5084589
Policy mu Max                1.8444197
Policy mu Min                -2.0426433
Policy log std Mean          -0.8459985
Policy log std Std           0.21757518
Policy log std Max           -0.29776555
Policy log std Min           -1.5406699
Z mean eval                  0.9082568
Z variance eval              0.0076393983
total_rewards                [1735.75599786 1920.49900858   23.41311187  667.82479898 1902.691088
 1780.76937748 1819.7071479  1973.90915452  864.01222109 1409.40583635]
total_rewards_mean           1409.7987742621187
total_rewards_std            632.7988589711126
total_rewards_max            1973.9091545215579
total_rewards_min            23.413111867850237
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               28.981465303804725
(Previous) Eval Time (s)     23.597023084759712
Sample Time (s)              19.203291514422745
Epoch Time (s)               71.78177990298718
Total Train Time (s)         9625.52886929363
Epoch                        137
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:55:57.118370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #137 | Epoch Duration: 75.38712310791016
2020-01-11 05:55:57.118584 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90853655
Z variance train             0.007637997
KL Divergence                18.423914
KL Loss                      1.8423914
QF Loss                      395.03027
VF Loss                      81.978195
Policy Loss                  -608.94727
Q Predictions Mean           605.93164
Q Predictions Std            157.13176
Q Predictions Max            861.59955
Q Predictions Min            -6.241667
V Predictions Mean           609.8098
V Predictions Std            152.3219
V Predictions Max            862.4472
V Predictions Min            254.71857
Log Pis Mean                 -1.3556722
Log Pis Std                  2.486811
Log Pis Max                  8.817165
Log Pis Min                  -8.340255
Policy mu Mean               0.11268709
Policy mu Std                0.5125263
Policy mu Max                2.0374002
Policy mu Min                -1.904864
Policy log std Mean          -0.8243618
Policy log std Std           0.245731
Policy log std Max           -0.24120533
Policy log std Min           -2.31642
Z mean eval                  0.9204157
Z variance eval              0.00854682
total_rewards                [1691.66469952   -1.94486599  543.98681289  669.69153061  308.99447898
  560.61908126 1276.63729202  853.3263151  1233.35643965 1040.20497197]
total_rewards_mean           817.653675602426
total_rewards_std            478.6962203007225
total_rewards_max            1691.6646995237254
total_rewards_min            -1.9448659871621459
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               28.07877901615575
(Previous) Eval Time (s)     27.202037318143994
Sample Time (s)              18.29703260678798
Epoch Time (s)               73.57784894108772
Total Train Time (s)         9696.895501424558
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:57:08.489161 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #138 | Epoch Duration: 71.37038135528564
2020-01-11 05:57:08.489448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #138 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92057484
Z variance train             0.00854736
KL Divergence                18.425297
KL Loss                      1.8425297
QF Loss                      350.51962
VF Loss                      132.88945
Policy Loss                  -638.0074
Q Predictions Mean           634.8308
Q Predictions Std            142.52472
Q Predictions Max            806.1523
Q Predictions Min            269.72568
V Predictions Mean           633.3617
V Predictions Std            139.86047
V Predictions Max            800.72266
V Predictions Min            269.2627
Log Pis Mean                 -1.3647679
Log Pis Std                  2.1125517
Log Pis Max                  7.1362724
Log Pis Min                  -6.77959
Policy mu Mean               0.05853194
Policy mu Std                0.49389848
Policy mu Max                1.6362002
Policy mu Min                -1.6674223
Policy log std Mean          -0.842612
Policy log std Std           0.24365227
Policy log std Max           -0.09224659
Policy log std Min           -2.1876867
Z mean eval                  0.9251506
Z variance eval              0.013192644
total_rewards                [ 660.20154884 1816.81904954  721.66616398  285.83458178 1010.0662638
 2012.50430449 2024.86118653  448.58114976  247.03855007  667.94545054]
total_rewards_mean           989.5518249318923
total_rewards_std            665.2779372225956
total_rewards_max            2024.861186526312
total_rewards_min            247.03855007064254
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               27.822292170021683
(Previous) Eval Time (s)     24.994215907063335
Sample Time (s)              18.720075080171227
Epoch Time (s)               71.53658315725625
Total Train Time (s)         9760.151200733613
Epoch                        139
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:58:11.744908 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #139 | Epoch Duration: 63.255260944366455
2020-01-11 05:58:11.745059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9247104
Z variance train             0.012985548
KL Divergence                17.088428
KL Loss                      1.7088429
QF Loss                      314.86826
VF Loss                      62.476032
Policy Loss                  -633.7744
Q Predictions Mean           629.71594
Q Predictions Std            150.2704
Q Predictions Max            801.55756
Q Predictions Min            256.61642
V Predictions Mean           637.933
V Predictions Std            151.18481
V Predictions Max            813.40137
V Predictions Min            272.35608
Log Pis Mean                 -1.8380275
Log Pis Std                  2.1348042
Log Pis Max                  3.9868977
Log Pis Min                  -8.357658
Policy mu Mean               0.028512698
Policy mu Std                0.48503232
Policy mu Max                1.6408877
Policy mu Min                -1.542851
Policy log std Mean          -0.80684394
Policy log std Std           0.22353147
Policy log std Max           -0.2341192
Policy log std Min           -1.62058
Z mean eval                  0.90486133
Z variance eval              0.018021524
total_rewards                [  24.59544164  495.62904107 1684.80815138 1807.75065892  421.11287332
 1377.4709615   567.12535489 1228.74215441 1931.09536355  229.18830167]
total_rewards_mean           976.7518302357861
total_rewards_std            670.8360446485635
total_rewards_max            1931.0953635535213
total_rewards_min            24.595441641105303
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               30.410462585277855
(Previous) Eval Time (s)     16.71258370531723
Sample Time (s)              18.119282532017678
Epoch Time (s)               65.24232882261276
Total Train Time (s)         9830.267237536144
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:59:21.863419 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #140 | Epoch Duration: 70.11823987960815
2020-01-11 05:59:21.863580 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9051405
Z variance train             0.017994132
KL Divergence                16.755068
KL Loss                      1.6755068
QF Loss                      364.55322
VF Loss                      238.68216
Policy Loss                  -596.56854
Q Predictions Mean           593.87305
Q Predictions Std            154.05687
Q Predictions Max            798.2194
Q Predictions Min            160.28125
V Predictions Mean           604.773
V Predictions Std            157.05525
V Predictions Max            818.3068
V Predictions Min            140.7622
Log Pis Mean                 -1.7491469
Log Pis Std                  2.3560505
Log Pis Max                  5.0092735
Log Pis Min                  -9.979656
Policy mu Mean               0.05041992
Policy mu Std                0.46379966
Policy mu Max                1.4834678
Policy mu Min                -1.4813888
Policy log std Mean          -0.82741636
Policy log std Std           0.25784835
Policy log std Max           -0.22695494
Policy log std Min           -2.0793512
Z mean eval                  0.917424
Z variance eval              0.011448516
total_rewards                [1448.43901648  288.70085901 1044.69534995 1502.63568382 1503.70932206
 1944.91596972 1836.63878622 1947.7163177  1133.66295126 1714.51494878]
total_rewards_mean           1436.5629205002256
total_rewards_std            482.58987078717456
total_rewards_max            1947.7163176968131
total_rewards_min            288.7008590061935
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               30.997672335710377
(Previous) Eval Time (s)     21.588199437130243
Sample Time (s)              17.80849422328174
Epoch Time (s)               70.39436599612236
Total Train Time (s)         9902.273371849675
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:00:33.870673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #141 | Epoch Duration: 72.00692439079285
2020-01-11 06:00:33.870880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.917425
Z variance train             0.011449711
KL Divergence                17.676369
KL Loss                      1.7676369
QF Loss                      473.34973
VF Loss                      323.5993
Policy Loss                  -626.0733
Q Predictions Mean           625.00684
Q Predictions Std            161.81921
Q Predictions Max            812.94086
Q Predictions Min            199.162
V Predictions Mean           632.95776
V Predictions Std            163.77701
V Predictions Max            824.781
V Predictions Min            169.13756
Log Pis Mean                 -1.5609127
Log Pis Std                  2.4143474
Log Pis Max                  8.155786
Log Pis Min                  -11.658497
Policy mu Mean               0.06290851
Policy mu Std                0.46876803
Policy mu Max                1.8997895
Policy mu Min                -1.5678461
Policy log std Mean          -0.8614733
Policy log std Std           0.2630684
Policy log std Max           -0.27542853
Policy log std Min           -2.3097134
Z mean eval                  0.908568
Z variance eval              0.013539565
total_rewards                [ 761.94945078 2057.58677184  124.01460794 1367.42071029  134.32021599
  723.58933298  453.47678151  524.15031745   45.78716213  161.67653496]
total_rewards_mean           635.397188586411
total_rewards_std            609.2936397610074
total_rewards_max            2057.5867718401373
total_rewards_min            45.787162125388406
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               30.394436572212726
(Previous) Eval Time (s)     23.200424344278872
Sample Time (s)              17.665865031071007
Epoch Time (s)               71.2607259475626
Total Train Time (s)         9976.106280725915
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:01:47.708495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #142 | Epoch Duration: 73.83742952346802
2020-01-11 06:01:47.708803 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9095706
Z variance train             0.013467049
KL Divergence                17.664955
KL Loss                      1.7664956
QF Loss                      408.8717
VF Loss                      124.08498
Policy Loss                  -650.91235
Q Predictions Mean           645.69196
Q Predictions Std            143.30312
Q Predictions Max            823.6267
Q Predictions Min            255.3677
V Predictions Mean           643.565
V Predictions Std            141.96007
V Predictions Max            810.9438
V Predictions Min            247.37363
Log Pis Mean                 -1.5302296
Log Pis Std                  2.314149
Log Pis Max                  5.4921875
Log Pis Min                  -7.5824695
Policy mu Mean               0.021701457
Policy mu Std                0.50995195
Policy mu Max                2.0500832
Policy mu Min                -1.8308868
Policy log std Mean          -0.8323365
Policy log std Std           0.22407083
Policy log std Max           -0.24733943
Policy log std Min           -1.7905512
Z mean eval                  0.89017373
Z variance eval              0.012604618
total_rewards                [1968.89059904 1993.41671501  587.63849443   32.90153989  520.37626785
 2054.33841165  486.67835838  592.7756872   457.8001292   612.25459548]
total_rewards_mean           930.7070798148554
total_rewards_std            720.9894919859797
total_rewards_max            2054.338411652913
total_rewards_min            32.90153989279237
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               29.195325307082385
(Previous) Eval Time (s)     25.776809541042894
Sample Time (s)              17.787635514046997
Epoch Time (s)               72.75977036217228
Total Train Time (s)         10046.505752534606
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:02:58.111269 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #143 | Epoch Duration: 70.40221309661865
2020-01-11 06:02:58.111529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8903147
Z variance train             0.012617876
KL Divergence                18.048744
KL Loss                      1.8048744
QF Loss                      366.0871
VF Loss                      77.30139
Policy Loss                  -643.3987
Q Predictions Mean           640.03125
Q Predictions Std            165.94196
Q Predictions Max            840.25867
Q Predictions Min            187.35776
V Predictions Mean           639.43884
V Predictions Std            165.1104
V Predictions Max            839.4346
V Predictions Min            182.12556
Log Pis Mean                 -1.6191585
Log Pis Std                  2.2381902
Log Pis Max                  6.2417235
Log Pis Min                  -8.650156
Policy mu Mean               -0.035209376
Policy mu Std                0.5044118
Policy mu Max                1.5565891
Policy mu Min                -1.9885725
Policy log std Mean          -0.8417373
Policy log std Std           0.25326136
Policy log std Max           -0.12587422
Policy log std Min           -1.8342724
Z mean eval                  0.8996881
Z variance eval              0.011662972
total_rewards                [ 591.45149753  345.67937023  951.62817071  857.26456438 2079.00825088
  532.4808096  1518.4072794   564.63668933 2074.41127575 1903.48196269]
total_rewards_mean           1141.8449870498791
total_rewards_std            650.2553471673391
total_rewards_max            2079.0082508825335
total_rewards_min            345.67937023390846
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               28.220627430826426
(Previous) Eval Time (s)     23.41894706292078
Sample Time (s)              19.156648965086788
Epoch Time (s)               70.79622345883399
Total Train Time (s)         10114.577296478208
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:04:06.182528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #144 | Epoch Duration: 68.07081747055054
2020-01-11 06:04:06.182706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89797103
Z variance train             0.011631569
KL Divergence                18.377655
KL Loss                      1.8377656
QF Loss                      419.43402
VF Loss                      62.713215
Policy Loss                  -642.8635
Q Predictions Mean           640.34143
Q Predictions Std            150.05637
Q Predictions Max            818.9276
Q Predictions Min            261.22467
V Predictions Mean           644.25903
V Predictions Std            149.90411
V Predictions Max            820.58527
V Predictions Min            260.35464
Log Pis Mean                 -1.5542231
Log Pis Std                  2.2507882
Log Pis Max                  4.4429245
Log Pis Min                  -9.99245
Policy mu Mean               0.07058515
Policy mu Std                0.5210765
Policy mu Max                1.6544337
Policy mu Min                -2.3840227
Policy log std Mean          -0.8276099
Policy log std Std           0.25305334
Policy log std Max           -0.25579002
Policy log std Min           -1.7333331
Z mean eval                  0.9091851
Z variance eval              0.011651826
total_rewards                [ 106.77788512 1601.61189791  764.34090545  421.52936821 1788.03167952
  728.62032858 1908.47831193  353.48679286  510.19957029  679.6644748 ]
total_rewards_mean           886.2741214668519
total_rewards_std            608.3652424590794
total_rewards_max            1908.4783119254962
total_rewards_min            106.7778851217985
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               26.81197093706578
(Previous) Eval Time (s)     20.693224384449422
Sample Time (s)              17.731096330098808
Epoch Time (s)               65.23629165161401
Total Train Time (s)         10182.041289628018
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:05:13.651264 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #145 | Epoch Duration: 67.46835803985596
2020-01-11 06:05:13.651582 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #145 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9084271
Z variance train             0.011655411
KL Divergence                19.069817
KL Loss                      1.9069817
QF Loss                      1230.5527
VF Loss                      218.75893
Policy Loss                  -622.1475
Q Predictions Mean           620.1351
Q Predictions Std            180.2072
Q Predictions Max            831.0746
Q Predictions Min            11.8205185
V Predictions Mean           622.7031
V Predictions Std            178.66995
V Predictions Max            827.1804
V Predictions Min            16.867277
Log Pis Mean                 -1.9277898
Log Pis Std                  2.2445226
Log Pis Max                  4.107145
Log Pis Min                  -8.620928
Policy mu Mean               0.040712908
Policy mu Std                0.48362207
Policy mu Max                1.9210367
Policy mu Min                -1.6639516
Policy log std Mean          -0.79881394
Policy log std Std           0.2562126
Policy log std Max           -0.19149134
Policy log std Min           -2.1063666
Z mean eval                  0.89827156
Z variance eval              0.013001548
total_rewards                [-1.33231948e+00  1.90658576e+03  4.53228518e+02  9.32341489e+02
  1.81228684e+03  2.88470283e+02  1.92052751e+03  1.67524576e+03
  1.92566741e+03  7.25867022e+02]
total_rewards_mean           1163.888828010688
total_rewards_std            725.3224552398417
total_rewards_max            1925.667413808008
total_rewards_min            -1.3323194802410472
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               27.530126952100545
(Previous) Eval Time (s)     22.924964776728302
Sample Time (s)              17.944698134902865
Epoch Time (s)               68.39978986373171
Total Train Time (s)         10249.548463187646
Epoch                        146
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:06:21.174672 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #146 | Epoch Duration: 67.52282691001892
2020-01-11 06:06:21.174953 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89835215
Z variance train             0.013000285
KL Divergence                18.62936
KL Loss                      1.862936
QF Loss                      466.75122
VF Loss                      108.71352
Policy Loss                  -676.6872
Q Predictions Mean           674.88324
Q Predictions Std            145.16856
Q Predictions Max            837.8988
Q Predictions Min            3.6540985
V Predictions Mean           677.9096
V Predictions Std            145.30048
V Predictions Max            841.486
V Predictions Min            54.31743
Log Pis Mean                 -1.5749726
Log Pis Std                  2.1676018
Log Pis Max                  4.443273
Log Pis Min                  -9.006422
Policy mu Mean               0.092131004
Policy mu Std                0.5058444
Policy mu Max                1.9665378
Policy mu Min                -1.4605763
Policy log std Mean          -0.8425616
Policy log std Std           0.22823821
Policy log std Max           -0.25582
Policy log std Min           -1.8779831
Z mean eval                  0.880006
Z variance eval              0.012387248
total_rewards                [1779.53577771 1871.84593643  338.78805029 1989.29747092  402.53832391
 1957.48856785   17.05251797  713.57660601  816.03424067 -115.87843033]
total_rewards_mean           977.0279061424577
total_rewards_std            798.7128345015045
total_rewards_max            1989.2974709185803
total_rewards_min            -115.87843033262719
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               29.859377013053745
(Previous) Eval Time (s)     22.047685915138572
Sample Time (s)              18.20669518550858
Epoch Time (s)               70.1137581137009
Total Train Time (s)         10319.748274452519
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:07:31.361143 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #147 | Epoch Duration: 70.1860032081604
2020-01-11 06:07:31.361326 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.879134
Z variance train             0.0123890955
KL Divergence                18.676178
KL Loss                      1.8676178
QF Loss                      379.21143
VF Loss                      275.96436
Policy Loss                  -652.8471
Q Predictions Mean           650.3395
Q Predictions Std            160.8327
Q Predictions Max            844.0251
Q Predictions Min            14.758818
V Predictions Mean           655.22546
V Predictions Std            161.24026
V Predictions Max            846.11096
V Predictions Min            9.25386
Log Pis Mean                 -1.555784
Log Pis Std                  2.509221
Log Pis Max                  12.944628
Log Pis Min                  -8.957582
Policy mu Mean               0.038894054
Policy mu Std                0.52852
Policy mu Max                1.9196326
Policy mu Min                -2.0956552
Policy log std Mean          -0.80721885
Policy log std Std           0.25073934
Policy log std Max           -0.24950168
Policy log std Min           -2.3141239
Z mean eval                  0.9124463
Z variance eval              0.015449459
total_rewards                [  53.82588795  980.70627416  883.0612138   154.92564634  365.75981048
 1705.50805931 1543.59213319 1947.44634563  874.37811575 1444.43186687]
total_rewards_mean           995.363535346742
total_rewards_std            626.8714254149498
total_rewards_max            1947.446345634622
total_rewards_min            53.82588795458246
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               29.72472459077835
(Previous) Eval Time (s)     22.119629006832838
Sample Time (s)              18.433625378180295
Epoch Time (s)               70.27797897579148
Total Train Time (s)         10391.109975380357
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:08:42.724747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #148 | Epoch Duration: 71.36326217651367
2020-01-11 06:08:42.724935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #148 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90357286
Z variance train             0.015358025
KL Divergence                18.63355
KL Loss                      1.863355
QF Loss                      426.25763
VF Loss                      255.50893
Policy Loss                  -649.53156
Q Predictions Mean           648.90497
Q Predictions Std            135.12512
Q Predictions Max            822.77277
Q Predictions Min            223.03157
V Predictions Mean           662.6289
V Predictions Std            132.87671
V Predictions Max            829.4267
V Predictions Min            246.29543
Log Pis Mean                 -1.4258556
Log Pis Std                  2.0725584
Log Pis Max                  5.4326577
Log Pis Min                  -7.1637306
Policy mu Mean               0.086065024
Policy mu Std                0.5150606
Policy mu Max                1.8590984
Policy mu Min                -1.6856395
Policy log std Mean          -0.8258761
Policy log std Std           0.23422629
Policy log std Max           -0.23406172
Policy log std Min           -1.7017121
Z mean eval                  0.85630214
Z variance eval              0.011521732
total_rewards                [ 929.88185917  521.78217654 1969.97539039 1730.2948863   347.44828731
  607.519506    596.2633091  1774.11557935 1743.93182222  144.0548688 ]
total_rewards_mean           1036.526768519325
total_rewards_std            657.4685708461914
total_rewards_max            1969.975390394198
total_rewards_min            144.0548687973281
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               26.853410922922194
(Previous) Eval Time (s)     23.204610178712755
Sample Time (s)              17.58566414192319
Epoch Time (s)               67.64368524355814
Total Train Time (s)         10454.678124137688
Epoch                        149
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:46.294116 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #149 | Epoch Duration: 63.56903696060181
2020-01-11 06:09:46.294335 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85504675
Z variance train             0.011547072
KL Divergence                18.80973
KL Loss                      1.8809731
QF Loss                      1388.336
VF Loss                      181.08945
Policy Loss                  -637.11633
Q Predictions Mean           634.2253
Q Predictions Std            173.19899
Q Predictions Max            830.1429
Q Predictions Min            -13.317922
V Predictions Mean           645.04395
V Predictions Std            176.48724
V Predictions Max            847.74066
V Predictions Min            1.9697835
Log Pis Mean                 -1.6051924
Log Pis Std                  2.407291
Log Pis Max                  12.324188
Log Pis Min                  -9.368057
Policy mu Mean               0.00784995
Policy mu Std                0.48987573
Policy mu Max                3.2286918
Policy mu Min                -1.6747029
Policy log std Mean          -0.8331885
Policy log std Std           0.27647358
Policy log std Max           0.10874951
Policy log std Min           -2.617632
Z mean eval                  0.85994005
Z variance eval              0.023715867
total_rewards                [ 623.48470914 1734.36845019 1703.88166538  204.05588348  366.27581258
 1846.52375868 1530.09795422  351.39927188 1939.76895728 1817.55475914]
total_rewards_mean           1211.7411221979123
total_rewards_std            687.9790138252583
total_rewards_max            1939.7689572758545
total_rewards_min            204.05588348234082
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               29.32195745781064
(Previous) Eval Time (s)     19.12965409224853
Sample Time (s)              17.806370487902313
Epoch Time (s)               66.25798203796148
Total Train Time (s)         10526.650386486668
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:10:58.293681 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #150 | Epoch Duration: 71.99916338920593
2020-01-11 06:10:58.294039 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85647994
Z variance train             0.023713771
KL Divergence                17.747902
KL Loss                      1.7747902
QF Loss                      709.91754
VF Loss                      124.25536
Policy Loss                  -653.227
Q Predictions Mean           647.17285
Q Predictions Std            162.72675
Q Predictions Max            864.3616
Q Predictions Min            244.9196
V Predictions Mean           651.0779
V Predictions Std            161.62405
V Predictions Max            862.8964
V Predictions Min            242.18436
Log Pis Mean                 -1.4750034
Log Pis Std                  2.0765362
Log Pis Max                  7.4247293
Log Pis Min                  -7.229202
Policy mu Mean               0.047685772
Policy mu Std                0.5416347
Policy mu Max                2.0861592
Policy mu Min                -2.0827558
Policy log std Mean          -0.81985325
Policy log std Std           0.25548357
Policy log std Max           -0.22441661
Policy log std Min           -2.2744262
Z mean eval                  0.8640095
Z variance eval              0.017216139
total_rewards                [1857.83656392 2032.58782334  233.20690308 1146.31297328 1219.41741856
 1170.3962345  2056.75744645 1873.75925602  129.57978106 1916.1831151 ]
total_rewards_mean           1363.6037515308358
total_rewards_std            681.4555537978547
total_rewards_max            2056.7574464458403
total_rewards_min            129.5797810575071
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               28.707666736096144
(Previous) Eval Time (s)     24.87046319618821
Sample Time (s)              17.617588182911277
Epoch Time (s)               71.19571811519563
Total Train Time (s)         10598.755681519397
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:10.377053 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #151 | Epoch Duration: 72.08277988433838
2020-01-11 06:12:10.377266 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86073047
Z variance train             0.017210923
KL Divergence                18.478731
KL Loss                      1.8478731
QF Loss                      369.6625
VF Loss                      63.347923
Policy Loss                  -683.8194
Q Predictions Mean           680.3884
Q Predictions Std            152.70874
Q Predictions Max            833.2236
Q Predictions Min            249.95857
V Predictions Mean           685.5464
V Predictions Std            151.01556
V Predictions Max            836.1672
V Predictions Min            271.19467
Log Pis Mean                 -1.4237335
Log Pis Std                  2.3517842
Log Pis Max                  6.0113673
Log Pis Min                  -8.730392
Policy mu Mean               0.08503021
Policy mu Std                0.51419574
Policy mu Max                1.6406927
Policy mu Min                -1.5027243
Policy log std Mean          -0.84222937
Policy log std Std           0.24615228
Policy log std Max           -0.1696893
Policy log std Min           -1.7917128
Z mean eval                  0.83359766
Z variance eval              0.01284537
total_rewards                [-233.12312117 1748.79979532 1734.61229418 -203.3531843  1641.69858642
 1616.4203643  1652.8198267  1892.21193026  980.46890096 1824.17470788]
total_rewards_mean           1265.4730100552583
total_rewards_std            778.3226254311963
total_rewards_max            1892.2119302583815
total_rewards_min            -233.1231211700349
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               29.444951817858964
(Previous) Eval Time (s)     25.7572530368343
Sample Time (s)              18.244487741030753
Epoch Time (s)               73.44669259572402
Total Train Time (s)         10673.145579653326
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:13:24.771247 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #152 | Epoch Duration: 74.3938422203064
2020-01-11 06:13:24.771448 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8358003
Z variance train             0.012814531
KL Divergence                19.161572
KL Loss                      1.9161571
QF Loss                      524.028
VF Loss                      167.21095
Policy Loss                  -667.7607
Q Predictions Mean           665.30676
Q Predictions Std            156.0321
Q Predictions Max            838.50085
Q Predictions Min            136.14018
V Predictions Mean           660.2969
V Predictions Std            154.16377
V Predictions Max            839.9037
V Predictions Min            242.2048
Log Pis Mean                 -1.3958502
Log Pis Std                  2.1240273
Log Pis Max                  9.002701
Log Pis Min                  -6.7675886
Policy mu Mean               0.08300631
Policy mu Std                0.49723852
Policy mu Max                2.1460521
Policy mu Min                -1.6199809
Policy log std Mean          -0.8609295
Policy log std Std           0.25580567
Policy log std Max           -0.26068568
Policy log std Min           -2.271402
Z mean eval                  0.88277894
Z variance eval              0.016129224
total_rewards                [ 546.35789106  706.9707542   992.66237776  208.54343479 1491.48531546
 1981.6405239  1598.15747284  781.13825202  691.99817411  954.12451663]
total_rewards_mean           995.3078712787217
total_rewards_std            512.4190591448593
total_rewards_max            1981.6405239029493
total_rewards_min            208.543434785733
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               28.30528148636222
(Previous) Eval Time (s)     26.704110990744084
Sample Time (s)              18.485154449939728
Epoch Time (s)               73.49454692704603
Total Train Time (s)         10739.89920715196
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:14:31.528690 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #153 | Epoch Duration: 66.75704646110535
2020-01-11 06:14:31.529012 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #153 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8835473
Z variance train             0.016122717
KL Divergence                19.187675
KL Loss                      1.9187676
QF Loss                      776.55334
VF Loss                      213.54031
Policy Loss                  -651.98553
Q Predictions Mean           650.0544
Q Predictions Std            159.85634
Q Predictions Max            822.1803
Q Predictions Min            -25.30179
V Predictions Mean           656.0431
V Predictions Std            161.00763
V Predictions Max            833.8243
V Predictions Min            8.457481
Log Pis Mean                 -1.687397
Log Pis Std                  2.3711977
Log Pis Max                  7.687954
Log Pis Min                  -8.727292
Policy mu Mean               0.089260414
Policy mu Std                0.49155602
Policy mu Max                2.115038
Policy mu Min                -1.6012601
Policy log std Mean          -0.8330164
Policy log std Std           0.24957313
Policy log std Max           -0.17461342
Policy log std Min           -2.4209518
Z mean eval                  0.8392459
Z variance eval              0.02388299
total_rewards                [1827.43659151 2115.3991638   961.56829298  282.44688361  201.220357
  436.23092682 1882.49971879  604.79303935 1718.74368808   15.17625159]
total_rewards_mean           1004.5514913551136
total_rewards_std            763.0378761061654
total_rewards_max            2115.3991638044126
total_rewards_min            15.17625159494655
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               29.112132034264505
(Previous) Eval Time (s)     19.96628424525261
Sample Time (s)              17.840877323411405
Epoch Time (s)               66.91929360292852
Total Train Time (s)         10807.424677927978
Epoch                        154
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:15:39.054581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #154 | Epoch Duration: 67.52534508705139
2020-01-11 06:15:39.054777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #154 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.83940065
Z variance train             0.023942556
KL Divergence                17.654251
KL Loss                      1.7654251
QF Loss                      404.1903
VF Loss                      139.67285
Policy Loss                  -674.8828
Q Predictions Mean           670.26624
Q Predictions Std            158.59286
Q Predictions Max            868.25653
Q Predictions Min            -27.719616
V Predictions Mean           669.99927
V Predictions Std            159.84239
V Predictions Max            861.7731
V Predictions Min            -2.7180939
Log Pis Mean                 -1.5462672
Log Pis Std                  2.5222745
Log Pis Max                  13.4037895
Log Pis Min                  -10.527397
Policy mu Mean               0.111161366
Policy mu Std                0.5013446
Policy mu Max                2.3691034
Policy mu Min                -1.873896
Policy log std Mean          -0.8345094
Policy log std Std           0.24211667
Policy log std Max           -0.14097744
Policy log std Min           -2.7480762
Z mean eval                  0.8500563
Z variance eval              0.015989978
total_rewards                [ 587.9549107  1320.87376877 1453.19544931 1317.65778249  906.3274405
 1388.66158957  124.11613689 1686.31781337  156.3621917   610.19383398]
total_rewards_mean           955.1660917281795
total_rewards_std            531.0973150669297
total_rewards_max            1686.3178133707336
total_rewards_min            124.11613689081646
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               29.13166152499616
(Previous) Eval Time (s)     20.572052797768265
Sample Time (s)              18.410617765504867
Epoch Time (s)               68.1143320882693
Total Train Time (s)         10873.459612285718
Epoch                        155
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:16:45.091070 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #155 | Epoch Duration: 66.03616285324097
2020-01-11 06:16:45.091245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85039604
Z variance train             0.015976965
KL Divergence                18.406199
KL Loss                      1.8406199
QF Loss                      445.0116
VF Loss                      70.54905
Policy Loss                  -706.28516
Q Predictions Mean           704.35864
Q Predictions Std            144.6762
Q Predictions Max            862.34204
Q Predictions Min            204.42072
V Predictions Mean           705.51733
V Predictions Std            143.06686
V Predictions Max            861.85016
V Predictions Min            189.39597
Log Pis Mean                 -1.3102605
Log Pis Std                  2.1395104
Log Pis Max                  6.1136093
Log Pis Min                  -5.799201
Policy mu Mean               0.0819083
Policy mu Std                0.5230206
Policy mu Max                2.2022932
Policy mu Min                -1.4978125
Policy log std Mean          -0.8318039
Policy log std Std           0.22289382
Policy log std Max           -0.23646879
Policy log std Min           -1.7228558
Z mean eval                  0.8239563
Z variance eval              0.01223985
total_rewards                [1164.86788653   79.35925941  310.43788202  -32.85977666  340.27621296
 1080.69783318 1821.00807936   68.66315957  830.89032353  640.42438302]
total_rewards_mean           630.3765242924649
total_rewards_std            564.9711308803119
total_rewards_max            1821.0080793623679
total_rewards_min            -32.85977666274139
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               27.92843603203073
(Previous) Eval Time (s)     18.493584422860295
Sample Time (s)              17.416934304405004
Epoch Time (s)               63.83895475929603
Total Train Time (s)         10938.21437683003
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:17:49.847326 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #156 | Epoch Duration: 64.75594353675842
2020-01-11 06:17:49.847519 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81929505
Z variance train             0.012208215
KL Divergence                18.870152
KL Loss                      1.8870152
QF Loss                      1843.17
VF Loss                      225.20175
Policy Loss                  -678.17206
Q Predictions Mean           676.22314
Q Predictions Std            162.50578
Q Predictions Max            878.7579
Q Predictions Min            98.33727
V Predictions Mean           689.2041
V Predictions Std            165.29251
V Predictions Max            897.5724
V Predictions Min            77.32502
Log Pis Mean                 -1.4177811
Log Pis Std                  2.479952
Log Pis Max                  11.606152
Log Pis Min                  -8.3928995
Policy mu Mean               0.005645452
Policy mu Std                0.5322652
Policy mu Max                1.7613058
Policy mu Min                -1.6533433
Policy log std Mean          -0.8355279
Policy log std Std           0.2757006
Policy log std Max           -0.27688462
Policy log std Min           -2.9816594
Z mean eval                  0.82134944
Z variance eval              0.018221855
total_rewards                [ 366.96136426 1913.77541472 2031.45585385 1996.90954789 2019.56999251
  528.07695084 1742.0768972  2051.30527029 1986.62395896 1962.9645395 ]
total_rewards_mean           1659.971979001591
total_rewards_std            612.9197243258919
total_rewards_max            2051.305270289362
total_rewards_min            366.96136426320726
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               27.886773185338825
(Previous) Eval Time (s)     19.410297045018524
Sample Time (s)              18.38802718091756
Epoch Time (s)               65.68509741127491
Total Train Time (s)         11011.31378668407
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:19:02.948323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #157 | Epoch Duration: 73.1006727218628
2020-01-11 06:19:02.948544 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.82063067
Z variance train             0.018218134
KL Divergence                18.624554
KL Loss                      1.8624554
QF Loss                      302.99762
VF Loss                      125.69975
Policy Loss                  -679.37915
Q Predictions Mean           677.77966
Q Predictions Std            160.37462
Q Predictions Max            885.9108
Q Predictions Min            51.52686
V Predictions Mean           688.3916
V Predictions Std            162.4301
V Predictions Max            895.68915
V Predictions Min            12.905504
Log Pis Mean                 -1.3377583
Log Pis Std                  2.2561507
Log Pis Max                  4.98987
Log Pis Min                  -7.9197288
Policy mu Mean               0.013239624
Policy mu Std                0.53496367
Policy mu Max                1.8540194
Policy mu Min                -2.142886
Policy log std Mean          -0.82945037
Policy log std Std           0.23860341
Policy log std Max           0.0014126301
Policy log std Min           -1.8130844
Z mean eval                  0.859046
Z variance eval              0.015188031
total_rewards                [ 522.12453671 2017.49083459 2042.95701632 1953.49648948 1931.20499183
 1808.49064269 1124.14865884  983.99207259 1799.76216636 1774.98288851]
total_rewards_mean           1595.8650297911927
total_rewards_std            498.6685384622348
total_rewards_max            2042.9570163162387
total_rewards_min            522.1245367095037
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               27.03338007396087
(Previous) Eval Time (s)     26.825535694137216
Sample Time (s)              17.658912940882146
Epoch Time (s)               71.51782870898023
Total Train Time (s)         11082.953349633142
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:20:14.589385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #158 | Epoch Duration: 71.6407253742218
2020-01-11 06:20:14.589581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8589137
Z variance train             0.015205884
KL Divergence                19.211285
KL Loss                      1.9211285
QF Loss                      670.8261
VF Loss                      201.34457
Policy Loss                  -667.2383
Q Predictions Mean           663.7522
Q Predictions Std            172.48964
Q Predictions Max            865.90564
Q Predictions Min            35.59107
V Predictions Mean           661.73926
V Predictions Std            167.18927
V Predictions Max            854.0969
V Predictions Min            -10.345655
Log Pis Mean                 -1.6343888
Log Pis Std                  2.666569
Log Pis Max                  10.662579
Log Pis Min                  -9.115431
Policy mu Mean               0.0043432796
Policy mu Std                0.5039334
Policy mu Max                1.5973685
Policy mu Min                -1.9595082
Policy log std Mean          -0.8711726
Policy log std Std           0.25066125
Policy log std Max           -0.22747415
Policy log std Min           -2.2192645
Z mean eval                  0.8372712
Z variance eval              0.01930528
total_rewards                [ 343.82068129  906.48481054 1643.33481385 1930.03758832  255.87709216
 1424.41124566 1080.97283427 1626.05379322 1008.89964939 1813.41765226]
total_rewards_mean           1203.331016095517
total_rewards_std            556.6688608457655
total_rewards_max            1930.0375883166207
total_rewards_min            255.87709216487784
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               29.234118363820016
(Previous) Eval Time (s)     26.948137484956533
Sample Time (s)              18.345661351457238
Epoch Time (s)               74.52791720023379
Total Train Time (s)         11154.534230449703
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:21:26.175432 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #159 | Epoch Duration: 71.58568024635315
2020-01-11 06:21:26.175731 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8383981
Z variance train             0.019275973
KL Divergence                18.27675
KL Loss                      1.8276751
QF Loss                      507.7168
VF Loss                      55.441467
Policy Loss                  -693.8158
Q Predictions Mean           692.8254
Q Predictions Std            159.94984
Q Predictions Max            894.0006
Q Predictions Min            -20.397339
V Predictions Mean           694.00586
V Predictions Std            160.23997
V Predictions Max            896.4122
V Predictions Min            3.85586
Log Pis Mean                 -1.3495185
Log Pis Std                  2.2379127
Log Pis Max                  4.7451878
Log Pis Min                  -10.6568575
Policy mu Mean               0.106793776
Policy mu Std                0.5166639
Policy mu Max                1.7742065
Policy mu Min                -1.8012741
Policy log std Mean          -0.85483146
Policy log std Std           0.25441787
Policy log std Max           -0.19163638
Policy log std Min           -1.8324256
Z mean eval                  0.81971425
Z variance eval              0.016213765
total_rewards                [ 760.13971962 2110.10422067 2123.87195519  102.66048465 2249.00601045
 1551.16476154  444.8590491  1612.45784576 1836.16259859 2053.80233456]
total_rewards_mean           1484.4228980146559
total_rewards_std            732.6845992265396
total_rewards_max            2249.006010454035
total_rewards_min            102.66048465472345
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               29.040245671290904
(Previous) Eval Time (s)     24.005552266724408
Sample Time (s)              18.28751004813239
Epoch Time (s)               71.3333079861477
Total Train Time (s)         11221.872854422312
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:22:33.517871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #160 | Epoch Duration: 67.34189176559448
2020-01-11 06:22:33.518125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.81859475
Z variance train             0.016160341
KL Divergence                18.338444
KL Loss                      1.8338444
QF Loss                      1436.306
VF Loss                      75.17243
Policy Loss                  -655.32416
Q Predictions Mean           651.75696
Q Predictions Std            186.61226
Q Predictions Max            855.7373
Q Predictions Min            142.566
V Predictions Mean           658.76
V Predictions Std            186.10435
V Predictions Max            864.2512
V Predictions Min            218.54579
Log Pis Mean                 -1.6641235
Log Pis Std                  2.39077
Log Pis Max                  7.6026297
Log Pis Min                  -9.53433
Policy mu Mean               0.07262607
Policy mu Std                0.49408624
Policy mu Max                1.8856342
Policy mu Min                -2.3359969
Policy log std Mean          -0.83355355
Policy log std Std           0.2591551
Policy log std Max           -0.17919415
Policy log std Min           -2.238822
Z mean eval                  0.85721254
Z variance eval              0.018971283
total_rewards                [2035.14872987  875.48997486  555.30740494  881.19463226  282.85953535
  615.90903404 1870.83475449 2251.46905335  582.56907012  651.65760566]
total_rewards_mean           1060.2439794945117
total_rewards_std            674.1323141910816
total_rewards_max            2251.469053353365
total_rewards_min            282.85953535125316
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               29.600194244179875
(Previous) Eval Time (s)     20.013828482013196
Sample Time (s)              17.674477976746857
Epoch Time (s)               67.28850070293993
Total Train Time (s)         11286.944368782453
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:23:38.591572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #161 | Epoch Duration: 65.07324743270874
2020-01-11 06:23:38.591780 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8589817
Z variance train             0.018972555
KL Divergence                16.738398
KL Loss                      1.6738398
QF Loss                      359.05762
VF Loss                      84.37394
Policy Loss                  -686.3024
Q Predictions Mean           681.5365
Q Predictions Std            175.04514
Q Predictions Max            883.4891
Q Predictions Min            245.21808
V Predictions Mean           688.334
V Predictions Std            173.04872
V Predictions Max            894.43024
V Predictions Min            255.1423
Log Pis Mean                 -1.5097852
Log Pis Std                  2.3671343
Log Pis Max                  8.928699
Log Pis Min                  -12.937976
Policy mu Mean               0.08868053
Policy mu Std                0.5127865
Policy mu Max                2.0093558
Policy mu Min                -1.6403543
Policy log std Mean          -0.8332268
Policy log std Std           0.2507778
Policy log std Max           -0.22605261
Policy log std Min           -2.060954
Z mean eval                  0.85218287
Z variance eval              0.027251292
total_rewards                [ 585.84817935 1306.78241052   91.44106495  325.41634325  936.29309634
 1823.65489956  100.16225018  258.99003511 1845.35963445 1161.7243738 ]
total_rewards_mean           843.5672287494265
total_rewards_std            639.0246395086347
total_rewards_max            1845.359634448304
total_rewards_min            91.44106495205617
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               28.412486587185413
(Previous) Eval Time (s)     17.798308444209397
Sample Time (s)              17.93325679237023
Epoch Time (s)               64.14405182376504
Total Train Time (s)         11353.447631548624
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:24:45.095026 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #162 | Epoch Duration: 66.50306868553162
2020-01-11 06:24:45.095197 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8504039
Z variance train             0.027313258
KL Divergence                16.637985
KL Loss                      1.6637986
QF Loss                      418.01624
VF Loss                      124.23507
Policy Loss                  -685.4981
Q Predictions Mean           683.4579
Q Predictions Std            169.43224
Q Predictions Max            874.25165
Q Predictions Min            212.3936
V Predictions Mean           685.5866
V Predictions Std            167.85205
V Predictions Max            867.69946
V Predictions Min            203.65747
Log Pis Mean                 -1.3207201
Log Pis Std                  2.3097928
Log Pis Max                  6.185344
Log Pis Min                  -7.9579554
Policy mu Mean               0.062515885
Policy mu Std                0.55408514
Policy mu Max                1.8206956
Policy mu Min                -1.5519388
Policy log std Mean          -0.830903
Policy log std Std           0.24614589
Policy log std Max           -0.1944567
Policy log std Min           -2.0572631
Z mean eval                  0.8568629
Z variance eval              0.029809928
total_rewards                [ 142.67514326 1808.72447904 1852.48042485  310.29570105  222.70174002
   46.88924047   80.4851718   172.2236538   649.10816451  154.43906513]
total_rewards_mean           544.0022783937324
total_rewards_std            662.8385282191495
total_rewards_max            1852.4804248502946
total_rewards_min            46.88924047391596
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               27.881848933175206
(Previous) Eval Time (s)     20.157012501731515
Sample Time (s)              18.879665868822485
Epoch Time (s)               66.9185273037292
Total Train Time (s)         11420.810725977179
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:25:52.462223 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #163 | Epoch Duration: 67.36682963371277
2020-01-11 06:25:52.462527 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8581769
Z variance train             0.029800754
KL Divergence                17.315815
KL Loss                      1.7315816
QF Loss                      652.584
VF Loss                      157.25107
Policy Loss                  -721.72845
Q Predictions Mean           720.10077
Q Predictions Std            155.57018
Q Predictions Max            907.26385
Q Predictions Min            261.29297
V Predictions Mean           724.0337
V Predictions Std            154.35606
V Predictions Max            897.2245
V Predictions Min            271.29312
Log Pis Mean                 -1.2240045
Log Pis Std                  2.21259
Log Pis Max                  6.932263
Log Pis Min                  -8.127363
Policy mu Mean               0.049534492
Policy mu Std                0.53461844
Policy mu Max                2.0804791
Policy mu Min                -1.8455963
Policy log std Mean          -0.82787937
Policy log std Std           0.25278488
Policy log std Max           -0.19142976
Policy log std Min           -1.9381236
Z mean eval                  0.8382813
Z variance eval              0.027647907
total_rewards                [1852.04776444 2091.81513941 1901.41943292  182.28244726 2039.11227947
  923.10064689 1612.0814742  2205.25314896 2081.34998883 1647.62102268]
total_rewards_mean           1653.6083345042975
total_rewards_std            602.403821670194
total_rewards_max            2205.253148956153
total_rewards_min            182.28244725571454
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               29.706959596835077
(Previous) Eval Time (s)     20.604984725359827
Sample Time (s)              19.19059603707865
Epoch Time (s)               69.50254035927355
Total Train Time (s)         11494.411059441045
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:27:06.066720 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #164 | Epoch Duration: 73.603919506073
2020-01-11 06:27:06.067051 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #164 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.839214
Z variance train             0.027578663
KL Divergence                16.90505
KL Loss                      1.690505
QF Loss                      746.7398
VF Loss                      87.03931
Policy Loss                  -680.4221
Q Predictions Mean           675.121
Q Predictions Std            178.70526
Q Predictions Max            876.3501
Q Predictions Min            10.266909
V Predictions Mean           678.54865
V Predictions Std            177.75647
V Predictions Max            881.5423
V Predictions Min            -4.708802
Log Pis Mean                 -1.2749817
Log Pis Std                  2.6396494
Log Pis Max                  9.768925
Log Pis Min                  -7.236408
Policy mu Mean               0.01721117
Policy mu Std                0.51277006
Policy mu Max                1.6643797
Policy mu Min                -2.1986485
Policy log std Mean          -0.86633
Policy log std Std           0.28708795
Policy log std Max           0.3494112
Policy log std Min           -2.525789
Z mean eval                  0.892186
Z variance eval              0.026422957
total_rewards                [ -24.57983964  128.61130523   12.78801489  738.24718417 1632.7330469
 1635.82456805  195.97484927 1733.84005181  252.89606792  371.54847907]
total_rewards_mean           667.788372767837
total_rewards_std            684.9274229236449
total_rewards_max            1733.840051809805
total_rewards_min            -24.57983963725237
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               30.84274872392416
(Previous) Eval Time (s)     24.706053988076746
Sample Time (s)              18.808499751146883
Epoch Time (s)               74.35730246314779
Total Train Time (s)         11565.020014057867
Epoch                        165
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:28:16.679707 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #165 | Epoch Duration: 70.61229825019836
2020-01-11 06:28:16.680113 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89628905
Z variance train             0.026472379
KL Divergence                16.658329
KL Loss                      1.6658329
QF Loss                      596.56226
VF Loss                      109.80812
Policy Loss                  -697.94305
Q Predictions Mean           692.01184
Q Predictions Std            180.13072
Q Predictions Max            876.5499
Q Predictions Min            26.875193
V Predictions Mean           691.3163
V Predictions Std            179.96864
V Predictions Max            882.24066
V Predictions Min            15.583972
Log Pis Mean                 -1.499231
Log Pis Std                  2.427178
Log Pis Max                  6.425311
Log Pis Min                  -11.05109
Policy mu Mean               -0.019551676
Policy mu Std                0.5507241
Policy mu Max                1.8044037
Policy mu Min                -1.8308594
Policy log std Mean          -0.8236116
Policy log std Std           0.23662171
Policy log std Max           -0.2843007
Policy log std Min           -1.7155436
Z mean eval                  0.84702367
Z variance eval              0.026544679
total_rewards                [1077.40314247  100.88654648  775.6848584   670.68585783 1053.50974314
   18.1571009   841.04183378  869.4235102   261.89983614  234.41504435]
total_rewards_mean           590.3107473683992
total_rewards_std            378.7898314581747
total_rewards_max            1077.403142465769
total_rewards_min            18.15710089620944
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               28.51159847807139
(Previous) Eval Time (s)     20.96070344839245
Sample Time (s)              18.449741607066244
Epoch Time (s)               67.92204353353009
Total Train Time (s)         11633.16342164483
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:29:24.823693 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #166 | Epoch Duration: 68.14334225654602
2020-01-11 06:29:24.823937 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84481496
Z variance train             0.026529152
KL Divergence                16.891838
KL Loss                      1.6891838
QF Loss                      518.12695
VF Loss                      81.167534
Policy Loss                  -708.0543
Q Predictions Mean           703.9048
Q Predictions Std            160.00446
Q Predictions Max            884.7737
Q Predictions Min            235.79633
V Predictions Mean           704.31036
V Predictions Std            157.06717
V Predictions Max            876.1826
V Predictions Min            252.71864
Log Pis Mean                 -1.4891322
Log Pis Std                  2.3003564
Log Pis Max                  6.4874797
Log Pis Min                  -7.446602
Policy mu Mean               0.072967455
Policy mu Std                0.50085604
Policy mu Max                1.9078966
Policy mu Min                -1.5741192
Policy log std Mean          -0.83470976
Policy log std Std           0.23365209
Policy log std Max           -0.20122176
Policy log std Min           -1.8578936
Z mean eval                  0.870463
Z variance eval              0.030650835
total_rewards                [  84.03175381 1736.69693773 1871.12017407  345.86100482  469.62324468
  213.83742735  324.27006806 1859.97658563  459.28056768  706.02875626]
total_rewards_mean           807.0726520087037
total_rewards_std            683.4162078372583
total_rewards_max            1871.120174065453
total_rewards_min            84.0317538099378
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               27.983199211768806
(Previous) Eval Time (s)     21.18171532638371
Sample Time (s)              18.14640617929399
Epoch Time (s)               67.3113207174465
Total Train Time (s)         11701.012787937652
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:30:32.678985 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #167 | Epoch Duration: 67.85484385490417
2020-01-11 06:30:32.679284 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8691641
Z variance train             0.030689854
KL Divergence                16.488808
KL Loss                      1.6488808
QF Loss                      350.76242
VF Loss                      112.307724
Policy Loss                  -682.3855
Q Predictions Mean           680.4442
Q Predictions Std            189.66057
Q Predictions Max            918.0946
Q Predictions Min            232.34802
V Predictions Mean           686.78
V Predictions Std            186.346
V Predictions Max            910.0638
V Predictions Min            207.90962
Log Pis Mean                 -1.2944736
Log Pis Std                  2.3472505
Log Pis Max                  8.338856
Log Pis Min                  -7.7377386
Policy mu Mean               0.11312613
Policy mu Std                0.5333121
Policy mu Max                1.7683764
Policy mu Min                -2.5891182
Policy log std Mean          -0.8158159
Policy log std Std           0.23595595
Policy log std Max           -0.26914334
Policy log std Min           -1.7107108
Z mean eval                  0.8395545
Z variance eval              0.03394622
total_rewards                [ 825.29173369 1939.1491775  2056.93881562 2070.85551949 2050.19006289
  112.28631772 1757.08400022 1417.97884857  770.12684288  238.64935378]
total_rewards_mean           1323.8550672364304
total_rewards_std            734.7698986599058
total_rewards_max            2070.855519489429
total_rewards_min            112.28631771780181
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               30.89216466108337
(Previous) Eval Time (s)     21.72492211777717
Sample Time (s)              17.6157740582712
Epoch Time (s)               70.23286083713174
Total Train Time (s)         11772.715725000016
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:31:44.382711 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #168 | Epoch Duration: 71.70319199562073
2020-01-11 06:31:44.382935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.840114
Z variance train             0.033917565
KL Divergence                16.13276
KL Loss                      1.6132759
QF Loss                      906.88
VF Loss                      565.3959
Policy Loss                  -705.5114
Q Predictions Mean           699.3705
Q Predictions Std            181.24774
Q Predictions Max            929.7482
Q Predictions Min            -4.4322705
V Predictions Mean           708.90857
V Predictions Std            175.4598
V Predictions Max            928.9248
V Predictions Min            245.98099
Log Pis Mean                 -1.2583615
Log Pis Std                  2.6365347
Log Pis Max                  13.351006
Log Pis Min                  -9.634598
Policy mu Mean               0.0241085
Policy mu Std                0.5295954
Policy mu Max                1.7060848
Policy mu Min                -2.265985
Policy log std Mean          -0.8614832
Policy log std Std           0.2743311
Policy log std Max           -0.21921939
Policy log std Min           -2.845683
Z mean eval                  0.85675776
Z variance eval              0.034800533
total_rewards                [2040.06058546  113.74814724    4.89136893  464.38804256 1821.85913285
 2012.85059414  158.70931897  793.32203818 1957.81357392 2021.31917001]
total_rewards_mean           1138.8961972268962
total_rewards_std            858.1184316915886
total_rewards_max            2040.0605854586183
total_rewards_min            4.891368933198978
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               28.57452674722299
(Previous) Eval Time (s)     23.194986963178962
Sample Time (s)              17.769222935196012
Epoch Time (s)               69.53873664559796
Total Train Time (s)         11841.898914819118
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:32:53.571938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #169 | Epoch Duration: 69.18865942955017
2020-01-11 06:32:53.572369 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.85928345
Z variance train             0.034847748
KL Divergence                16.64136
KL Loss                      1.6641359
QF Loss                      348.17383
VF Loss                      149.27103
Policy Loss                  -727.5866
Q Predictions Mean           724.46405
Q Predictions Std            168.20879
Q Predictions Max            898.45245
Q Predictions Min            6.564848
V Predictions Mean           717.26074
V Predictions Std            167.27638
V Predictions Max            887.7491
V Predictions Min            3.7743044
Log Pis Mean                 -1.5036134
Log Pis Std                  2.2249968
Log Pis Max                  5.9708424
Log Pis Min                  -7.5427976
Policy mu Mean               0.011917435
Policy mu Std                0.50822943
Policy mu Max                1.7471153
Policy mu Min                -1.8906325
Policy log std Mean          -0.84347904
Policy log std Std           0.25301343
Policy log std Max           -0.27984264
Policy log std Min           -1.8337873
Z mean eval                  0.84158504
Z variance eval              0.02618215
total_rewards                [  -7.74200268   25.23024193  294.57849251  715.70336717  793.88924929
 2077.29385121 1288.55451498 1304.49705267 1009.23324179  523.70428773]
total_rewards_mean           802.4942296602969
total_rewards_std            613.1922631297936
total_rewards_max            2077.293851213811
total_rewards_min            -7.742002684540969
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               30.06943271169439
(Previous) Eval Time (s)     22.844591620843858
Sample Time (s)              18.217409506905824
Epoch Time (s)               71.13143383944407
Total Train Time (s)         11907.439108082093
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:33:59.113258 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #170 | Epoch Duration: 65.54063630104065
2020-01-11 06:33:59.113500 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8407677
Z variance train             0.026149089
KL Divergence                17.07975
KL Loss                      1.707975
QF Loss                      936.65625
VF Loss                      802.1537
Policy Loss                  -711.9905
Q Predictions Mean           708.79175
Q Predictions Std            172.28856
Q Predictions Max            906.95856
Q Predictions Min            7.415257
V Predictions Mean           716.3684
V Predictions Std            165.439
V Predictions Max            906.4319
V Predictions Min            18.610523
Log Pis Mean                 -0.9547513
Log Pis Std                  2.564943
Log Pis Max                  9.866013
Log Pis Min                  -7.3819647
Policy mu Mean               0.07058053
Policy mu Std                0.55858856
Policy mu Max                1.8992869
Policy mu Min                -1.7835675
Policy log std Mean          -0.86715734
Policy log std Std           0.2642844
Policy log std Max           -0.3284905
Policy log std Min           -2.7509356
Z mean eval                  0.83967626
Z variance eval              0.029775133
total_rewards                [-119.79434458 2032.77403649   59.05693092 1631.11277824 2149.40279482
 2010.64738102 2187.83776496 2015.67558629 1259.24956783  856.67567613]
total_rewards_mean           1408.2638172112638
total_rewards_std            825.2446851965815
total_rewards_max            2187.83776496264
total_rewards_min            -119.79434458371934
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               27.261728992685676
(Previous) Eval Time (s)     17.253469021990895
Sample Time (s)              17.72076769405976
Epoch Time (s)               62.23596570873633
Total Train Time (s)         11977.017407105304
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:35:08.692999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #171 | Epoch Duration: 69.57932877540588
2020-01-11 06:35:08.693192 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8412026
Z variance train             0.02978054
KL Divergence                16.855568
KL Loss                      1.6855568
QF Loss                      479.73364
VF Loss                      86.770325
Policy Loss                  -694.1629
Q Predictions Mean           690.0977
Q Predictions Std            188.15797
Q Predictions Max            930.3285
Q Predictions Min            -0.67645985
V Predictions Mean           691.1305
V Predictions Std            185.35548
V Predictions Max            919.86676
V Predictions Min            68.09013
Log Pis Mean                 -1.457758
Log Pis Std                  2.377034
Log Pis Max                  8.070157
Log Pis Min                  -11.5057335
Policy mu Mean               0.063185245
Policy mu Std                0.51950675
Policy mu Max                2.3425202
Policy mu Min                -2.2377992
Policy log std Mean          -0.835044
Policy log std Std           0.25034952
Policy log std Max           0.00073844194
Policy log std Min           -1.7164302
Z mean eval                  0.8407365
Z variance eval              0.025280306
total_rewards                [-130.75253838 1899.32523884 1274.71905524 1869.01741466 2039.09649255
 1956.2257999  1940.15552883 1004.7848722   969.54075568   48.19422722]
total_rewards_mean           1287.030684674425
total_rewards_std            766.7495995682775
total_rewards_max            2039.0964925463657
total_rewards_min            -130.75253837970652
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               26.65781770274043
(Previous) Eval Time (s)     24.59654729999602
Sample Time (s)              17.988059483934194
Epoch Time (s)               69.24242448667064
Total Train Time (s)         12046.31554286601
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:36:17.993855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #172 | Epoch Duration: 69.3005256652832
2020-01-11 06:36:17.994083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8411976
Z variance train             0.025193473
KL Divergence                17.80541
KL Loss                      1.7805411
QF Loss                      707.7095
VF Loss                      171.95027
Policy Loss                  -718.5083
Q Predictions Mean           715.6007
Q Predictions Std            166.4117
Q Predictions Max            911.3505
Q Predictions Min            231.57767
V Predictions Mean           721.2289
V Predictions Std            166.62042
V Predictions Max            908.9998
V Predictions Min            242.43852
Log Pis Mean                 -1.0402656
Log Pis Std                  2.2490914
Log Pis Max                  5.935773
Log Pis Min                  -7.7202973
Policy mu Mean               0.07919889
Policy mu Std                0.5325241
Policy mu Max                1.9077272
Policy mu Min                -1.6626987
Policy log std Mean          -0.86430943
Policy log std Std           0.25962403
Policy log std Max           -0.19115394
Policy log std Min           -2.1532793
Z mean eval                  0.8605944
Z variance eval              0.050263762
total_rewards                [1108.14728764  439.85065309 1985.09560761  550.16610989 1406.78691856
 2279.23308591  240.24499661 1024.86021637  514.65569579 2157.95961168]
total_rewards_mean           1170.7000183144278
total_rewards_std            718.542287247133
total_rewards_max            2279.233085912082
total_rewards_min            240.2449966053982
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               28.575186701025814
(Previous) Eval Time (s)     24.654290392063558
Sample Time (s)              17.891711182892323
Epoch Time (s)               71.1211882759817
Total Train Time (s)         12115.34684197884
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:37:27.027477 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #173 | Epoch Duration: 69.03322052955627
2020-01-11 06:37:27.027679 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #173 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8610811
Z variance train             0.050257016
KL Divergence                17.181091
KL Loss                      1.7181091
QF Loss                      545.1564
VF Loss                      86.07829
Policy Loss                  -734.63446
Q Predictions Mean           733.2798
Q Predictions Std            204.54573
Q Predictions Max            955.97626
Q Predictions Min            -0.17340088
V Predictions Mean           739.78546
V Predictions Std            203.56535
V Predictions Max            953.6128
V Predictions Min            36.648212
Log Pis Mean                 -1.556454
Log Pis Std                  2.5158002
Log Pis Max                  8.9661045
Log Pis Min                  -10.198595
Policy mu Mean               0.049106747
Policy mu Std                0.5622167
Policy mu Max                1.7762742
Policy mu Min                -2.0176435
Policy log std Mean          -0.81311595
Policy log std Std           0.26167572
Policy log std Max           -0.15886694
Policy log std Min           -2.1550412
Z mean eval                  0.8566271
Z variance eval              0.04794312
total_rewards                [2185.52931298 1271.78234092  532.16847465 1793.23744674 1363.7803126
 2103.91029543 2232.56287672 2245.36489692  377.06015225  958.48884511]
total_rewards_mean           1506.3884954310831
total_rewards_std            676.3150560473216
total_rewards_max            2245.3648969175742
total_rewards_min            377.0601522461853
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               28.419509518891573
(Previous) Eval Time (s)     22.56601796578616
Sample Time (s)              18.05018411995843
Epoch Time (s)               69.03571160463616
Total Train Time (s)         12183.718220593873
Epoch                        174
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:38:35.402409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #174 | Epoch Duration: 68.37455677986145
2020-01-11 06:38:35.402636 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8568085
Z variance train             0.04788716
KL Divergence                17.35931
KL Loss                      1.735931
QF Loss                      652.12
VF Loss                      440.83813
Policy Loss                  -727.83624
Q Predictions Mean           724.21924
Q Predictions Std            171.79634
Q Predictions Max            925.35626
Q Predictions Min            28.965996
V Predictions Mean           723.21344
V Predictions Std            175.2356
V Predictions Max            926.7712
V Predictions Min            -7.995717
Log Pis Mean                 -0.8621923
Log Pis Std                  2.4835079
Log Pis Max                  13.417464
Log Pis Min                  -8.019941
Policy mu Mean               0.07686843
Policy mu Std                0.5464167
Policy mu Max                1.7751083
Policy mu Min                -2.0091054
Policy log std Mean          -0.8790087
Policy log std Std           0.29353985
Policy log std Max           -0.100274086
Policy log std Min           -2.8746662
Z mean eval                  0.8457901
Z variance eval              0.02643313
total_rewards                [1874.75804599  672.28584647 1963.75547135  809.12349459  593.71717439
  260.49134757 1225.67272089 1900.91122633 1026.73173149 1013.04729292]
total_rewards_mean           1134.049435199861
total_rewards_std            568.6437335423357
total_rewards_max            1963.755471349753
total_rewards_min            260.4913475712446
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               29.48955184686929
(Previous) Eval Time (s)     21.90450272196904
Sample Time (s)              18.812772476579994
Epoch Time (s)               70.20682704541832
Total Train Time (s)         12254.052187489346
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:45.738697 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #175 | Epoch Duration: 70.33580875396729
2020-01-11 06:39:45.739003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.84643924
Z variance train             0.026472684
KL Divergence                18.12807
KL Loss                      1.8128071
QF Loss                      371.21344
VF Loss                      105.77424
Policy Loss                  -732.6789
Q Predictions Mean           728.72327
Q Predictions Std            159.90356
Q Predictions Max            926.8915
Q Predictions Min            220.51965
V Predictions Mean           738.0039
V Predictions Std            160.37701
V Predictions Max            929.3978
V Predictions Min            222.03004
Log Pis Mean                 -1.2926075
Log Pis Std                  2.243682
Log Pis Max                  4.9958982
Log Pis Min                  -8.383234
Policy mu Mean               0.17146835
Policy mu Std                0.5460621
Policy mu Max                1.921153
Policy mu Min                -1.5716945
Policy log std Mean          -0.8062627
Policy log std Std           0.24410155
Policy log std Max           -0.2278493
Policy log std Min           -1.9379048
Z mean eval                  0.9204925
Z variance eval              0.02550289
total_rewards                [1898.16792314 1987.4370985  1899.6505527  1871.12681316 2035.79924365
 1008.15061324 1085.71927349 2039.47080867  914.58107199 2166.61493366]
total_rewards_mean           1690.671833219879
total_rewards_std            459.21406004928633
total_rewards_max            2166.614933660819
total_rewards_min            914.5810719875202
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               29.20315606612712
(Previous) Eval Time (s)     22.033164065796882
Sample Time (s)              19.123558080289513
Epoch Time (s)               70.35987821221352
Total Train Time (s)         12327.862378204241
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:40:59.553177 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #176 | Epoch Duration: 73.81397151947021
2020-01-11 06:40:59.553458 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.919098
Z variance train             0.025507282
KL Divergence                18.126266
KL Loss                      1.8126267
QF Loss                      662.5781
VF Loss                      226.05968
Policy Loss                  -713.4545
Q Predictions Mean           708.75507
Q Predictions Std            185.58939
Q Predictions Max            913.1171
Q Predictions Min            -32.447357
V Predictions Mean           714.6035
V Predictions Std            178.45241
V Predictions Max            923.3242
V Predictions Min            -10.161637
Log Pis Mean                 -0.91810936
Log Pis Std                  2.5736651
Log Pis Max                  14.69406
Log Pis Min                  -8.370752
Policy mu Mean               0.06999507
Policy mu Std                0.5464093
Policy mu Max                2.4320307
Policy mu Min                -2.0773475
Policy log std Mean          -0.8695598
Policy log std Std           0.26716492
Policy log std Max           -0.30698383
Policy log std Min           -2.4641707
Z mean eval                  0.8552531
Z variance eval              0.025018254
total_rewards                [2329.18059166 1405.57573284 2378.3683995   604.98978841 2201.52289254
 2498.44096816 2136.8231797  2098.12471606 1095.02013729 1502.7649366 ]
total_rewards_mean           1825.0811342773109
total_rewards_std            602.3773974168325
total_rewards_max            2498.4409681629336
total_rewards_min            604.9897884101707
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               27.331809140276164
(Previous) Eval Time (s)     25.48692612396553
Sample Time (s)              18.69181605707854
Epoch Time (s)               71.51055132132024
Total Train Time (s)         12399.40685383603
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:42:11.101578 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #177 | Epoch Duration: 71.54778933525085
2020-01-11 06:42:11.101966 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8556145
Z variance train             0.024952829
KL Divergence                17.962946
KL Loss                      1.7962946
QF Loss                      481.80185
VF Loss                      85.99346
Policy Loss                  -696.53815
Q Predictions Mean           691.49634
Q Predictions Std            191.83244
Q Predictions Max            901.43933
Q Predictions Min            -3.9948504
V Predictions Mean           701.3196
V Predictions Std            193.8325
V Predictions Max            913.71124
V Predictions Min            -3.1759353
Log Pis Mean                 -1.429558
Log Pis Std                  2.625893
Log Pis Max                  10.055319
Log Pis Min                  -9.64174
Policy mu Mean               0.07324208
Policy mu Std                0.57043743
Policy mu Max                2.3322566
Policy mu Min                -2.5309603
Policy log std Mean          -0.8037821
Policy log std Std           0.25952414
Policy log std Max           0.34999764
Policy log std Min           -2.614459
Z mean eval                  0.8708495
Z variance eval              0.030618599
total_rewards                [2069.21194855 2101.87828211 2010.78370359  314.20028187 2148.42183099
 1337.13594912 2202.06466508 2063.47002013 2077.17874152  998.14823338]
total_rewards_mean           1732.2493656329923
total_rewards_std            604.6686957879214
total_rewards_max            2202.064665077902
total_rewards_min            314.20028187228996
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               27.34305260423571
(Previous) Eval Time (s)     25.523855725303292
Sample Time (s)              17.883623816538602
Epoch Time (s)               70.7505321460776
Total Train Time (s)         12470.33214721037
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:43:22.027585 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #178 | Epoch Duration: 70.92540144920349
2020-01-11 06:43:22.027787 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.868755
Z variance train             0.030600185
KL Divergence                17.900427
KL Loss                      1.7900428
QF Loss                      682.70874
VF Loss                      236.09634
Policy Loss                  -743.08704
Q Predictions Mean           737.5663
Q Predictions Std            176.9481
Q Predictions Max            972.55066
Q Predictions Min            244.26822
V Predictions Mean           743.1163
V Predictions Std            176.83263
V Predictions Max            974.67694
V Predictions Min            233.17052
Log Pis Mean                 -1.1787941
Log Pis Std                  2.4707072
Log Pis Max                  9.467156
Log Pis Min                  -9.718966
Policy mu Mean               0.0465495
Policy mu Std                0.5561664
Policy mu Max                2.1083717
Policy mu Min                -2.3338141
Policy log std Mean          -0.85436124
Policy log std Std           0.2587233
Policy log std Max           -0.21161407
Policy log std Min           -2.5709107
Z mean eval                  0.8676276
Z variance eval              0.02520902
total_rewards                [2142.47450581   60.97555794 2076.44226707 1328.66403883  438.57497257
  596.08346265  178.23996317  837.66648739 1594.99403586 1366.23176101]
total_rewards_mean           1062.034705230497
total_rewards_std            712.9804920849298
total_rewards_max            2142.4745058107865
total_rewards_min            60.97555793698825
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               28.09499430283904
(Previous) Eval Time (s)     25.698440115898848
Sample Time (s)              18.378966903313994
Epoch Time (s)               72.17240132205188
Total Train Time (s)         12532.743869298603
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:44:24.440699 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #179 | Epoch Duration: 62.41274833679199
2020-01-11 06:44:24.440911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8682227
Z variance train             0.025201404
KL Divergence                18.294306
KL Loss                      1.8294306
QF Loss                      825.3965
VF Loss                      122.49331
Policy Loss                  -736.4164
Q Predictions Mean           733.349
Q Predictions Std            177.53261
Q Predictions Max            926.8512
Q Predictions Min            243.92854
V Predictions Mean           730.9352
V Predictions Std            177.85379
V Predictions Max            924.5342
V Predictions Min            252.8749
Log Pis Mean                 -1.1313009
Log Pis Std                  2.5030136
Log Pis Max                  9.620572
Log Pis Min                  -7.7574105
Policy mu Mean               0.053234003
Policy mu Std                0.5128173
Policy mu Max                2.4192913
Policy mu Min                -1.8367319
Policy log std Mean          -0.8800797
Policy log std Std           0.27451918
Policy log std Max           -0.17440629
Policy log std Min           -2.0780408
Z mean eval                  0.8739525
Z variance eval              0.02013875
total_rewards                [1740.95647144 2316.10811653 2119.7278062  2238.90364986  626.83119461
  741.870367   1115.62567221 2238.8758663   268.93566494 1261.38441521]
total_rewards_mean           1466.921922429197
total_rewards_std            724.3282620176321
total_rewards_max            2316.1081165286582
total_rewards_min            268.935664939743
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               28.56016511004418
(Previous) Eval Time (s)     15.938420477788895
Sample Time (s)              17.881663914304227
Epoch Time (s)               62.3802495021373
Total Train Time (s)         12602.556869996246
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:45:34.259433 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #180 | Epoch Duration: 69.81833338737488
2020-01-11 06:45:34.259702 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8741754
Z variance train             0.02016257
KL Divergence                19.160942
KL Loss                      1.9160942
QF Loss                      411.91693
VF Loss                      58.059483
Policy Loss                  -759.9483
Q Predictions Mean           757.73083
Q Predictions Std            171.66335
Q Predictions Max            966.8772
Q Predictions Min            240.449
V Predictions Mean           757.6356
V Predictions Std            170.49353
V Predictions Max            970.70514
V Predictions Min            248.57509
Log Pis Mean                 -1.2127361
Log Pis Std                  2.4416635
Log Pis Max                  5.9788218
Log Pis Min                  -8.283618
Policy mu Mean               0.03156731
Policy mu Std                0.5467192
Policy mu Max                1.8892338
Policy mu Min                -1.8510666
Policy log std Mean          -0.82565343
Policy log std Std           0.2384649
Policy log std Max           -0.23432305
Policy log std Min           -1.9782104
Z mean eval                  0.87306595
Z variance eval              0.02190827
total_rewards                [2188.74503894 2230.19269002 2115.3571283  2106.53630665 2183.84440608
  179.30388586 2232.24038882 2080.84639711 2271.31268019 1347.67333456]
total_rewards_mean           1893.6052256519263
total_rewards_std            625.1733862339848
total_rewards_max            2271.312680185492
total_rewards_min            179.30388585970067
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               29.235582598950714
(Previous) Eval Time (s)     23.376185717061162
Sample Time (s)              17.38278878806159
Epoch Time (s)               69.99455710407346
Total Train Time (s)         12672.578340969048
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:46:44.283968 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #181 | Epoch Duration: 70.02400326728821
2020-01-11 06:46:44.284293 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8726398
Z variance train             0.021892166
KL Divergence                18.180283
KL Loss                      1.8180283
QF Loss                      465.25778
VF Loss                      76.83553
Policy Loss                  -762.1639
Q Predictions Mean           759.17316
Q Predictions Std            165.87518
Q Predictions Max            963.8808
Q Predictions Min            221.17044
V Predictions Mean           760.33655
V Predictions Std            164.19884
V Predictions Max            958.2248
V Predictions Min            227.80829
Log Pis Mean                 -1.2216116
Log Pis Std                  2.5828168
Log Pis Max                  6.160179
Log Pis Min                  -12.202311
Policy mu Mean               0.05528848
Policy mu Std                0.5525125
Policy mu Max                2.1214824
Policy mu Min                -1.8841625
Policy log std Mean          -0.85996276
Policy log std Std           0.22529174
Policy log std Max           -0.32111496
Policy log std Min           -1.7585512
Z mean eval                  0.8799903
Z variance eval              0.018881489
total_rewards                [1843.32896117 1977.52508967 1810.26342374  663.75607002 1849.83860432
 2020.99535434 2008.79007029 2099.54077611 1976.82414834 2010.23500122]
total_rewards_mean           1826.109749922943
total_rewards_std            397.22000333586453
total_rewards_max            2099.540776109031
total_rewards_min            663.7560700232461
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               31.623645420651883
(Previous) Eval Time (s)     23.405321639031172
Sample Time (s)              19.240056965965778
Epoch Time (s)               74.26902402564883
Total Train Time (s)         12748.37468412472
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:48:00.083767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #182 | Epoch Duration: 75.799143075943
2020-01-11 06:48:00.084137 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8793726
Z variance train             0.01886909
KL Divergence                18.458748
KL Loss                      1.8458748
QF Loss                      906.72876
VF Loss                      437.86304
Policy Loss                  -730.36926
Q Predictions Mean           726.8118
Q Predictions Std            192.54695
Q Predictions Max            929.32043
Q Predictions Min            38.868187
V Predictions Mean           734.83057
V Predictions Std            191.97173
V Predictions Max            919.7631
V Predictions Min            -6.9750156
Log Pis Mean                 -1.1821618
Log Pis Std                  2.4251003
Log Pis Max                  12.569532
Log Pis Min                  -6.593288
Policy mu Mean               0.055929463
Policy mu Std                0.5393329
Policy mu Max                1.9315346
Policy mu Min                -1.5320044
Policy log std Mean          -0.8428937
Policy log std Std           0.25400668
Policy log std Max           -0.24941438
Policy log std Min           -2.5510762
Z mean eval                  0.8743399
Z variance eval              0.017366495
total_rewards                [1594.58361656 1525.14282588 1390.65828932 1301.3159428   311.38976028
   97.99512525 2156.43095359   54.43820317   59.37601346  322.20109184]
total_rewards_mean           881.3531822154175
total_rewards_std            748.0200899494829
total_rewards_max            2156.430953594225
total_rewards_min            54.43820316924995
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               29.084878670983016
(Previous) Eval Time (s)     24.935098596848547
Sample Time (s)              18.813554979860783
Epoch Time (s)               72.83353224769235
Total Train Time (s)         12813.502388271969
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:49:05.211749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #183 | Epoch Duration: 65.12742185592651
2020-01-11 06:49:05.221432 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8737136
Z variance train             0.017404102
KL Divergence                18.447975
KL Loss                      1.8447975
QF Loss                      492.07953
VF Loss                      129.45131
Policy Loss                  -755.9767
Q Predictions Mean           751.91626
Q Predictions Std            173.53044
Q Predictions Max            929.8318
Q Predictions Min            -19.637028
V Predictions Mean           747.60583
V Predictions Std            169.18918
V Predictions Max            919.3156
V Predictions Min            -1.6032854
Log Pis Mean                 -1.2698572
Log Pis Std                  2.6983123
Log Pis Max                  8.03458
Log Pis Min                  -9.241719
Policy mu Mean               0.04592763
Policy mu Std                0.56265277
Policy mu Max                2.2447019
Policy mu Min                -2.120943
Policy log std Mean          -0.84001726
Policy log std Std           0.261182
Policy log std Max           -0.31261447
Policy log std Min           -2.1280737
Z mean eval                  0.90394175
Z variance eval              0.022685822
total_rewards                [2191.71915023 2200.73636151 2370.27578387 2217.17972223 1152.13299132
  906.56167094  957.73041537 2315.32599332 2407.75863454  909.72497761]
total_rewards_mean           1762.9145700954257
total_rewards_std            644.5491787284456
total_rewards_max            2407.7586345449386
total_rewards_min            906.5616709379423
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               26.224016495049
(Previous) Eval Time (s)     17.228648360818624
Sample Time (s)              17.286542269401252
Epoch Time (s)               60.73920712526888
Total Train Time (s)         12880.015577212442
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:50:11.729346 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #184 | Epoch Duration: 66.5076699256897
2020-01-11 06:50:11.729610 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.902372
Z variance train             0.022583509
KL Divergence                19.122757
KL Loss                      1.9122757
QF Loss                      697.23755
VF Loss                      86.28881
Policy Loss                  -739.5411
Q Predictions Mean           736.4267
Q Predictions Std            189.18413
Q Predictions Max            942.12885
Q Predictions Min            43.218746
V Predictions Mean           741.395
V Predictions Std            185.36818
V Predictions Max            938.04083
V Predictions Min            204.72293
Log Pis Mean                 -1.2023066
Log Pis Std                  2.502295
Log Pis Max                  7.022338
Log Pis Min                  -7.1060915
Policy mu Mean               -0.028083827
Policy mu Std                0.565167
Policy mu Max                2.0255067
Policy mu Min                -2.3577187
Policy log std Mean          -0.8419125
Policy log std Std           0.25021097
Policy log std Max           -0.23205328
Policy log std Min           -2.1697662
Z mean eval                  0.89414656
Z variance eval              0.019970123
total_rewards                [ -10.93413727 1215.43233948 2233.73100218  371.02669357 2093.91891594
  859.77551684  910.71542488 2148.00703608  335.93869044 1620.60436092]
total_rewards_mean           1177.8215843047333
total_rewards_std            777.0607412878763
total_rewards_max            2233.731002183781
total_rewards_min            -10.934137265943635
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               31.012923560105264
(Previous) Eval Time (s)     22.99685845617205
Sample Time (s)              18.93228387553245
Epoch Time (s)               72.94206589180976
Total Train Time (s)         12948.552953191102
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:51:20.267935 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #185 | Epoch Duration: 68.53817796707153
2020-01-11 06:51:20.268118 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #185 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8962326
Z variance train             0.020012388
KL Divergence                18.743097
KL Loss                      1.8743098
QF Loss                      285.50848
VF Loss                      163.62527
Policy Loss                  -750.8156
Q Predictions Mean           747.11475
Q Predictions Std            186.96844
Q Predictions Max            956.2516
Q Predictions Min            239.73314
V Predictions Mean           739.81995
V Predictions Std            184.81636
V Predictions Max            945.30505
V Predictions Min            244.19284
Log Pis Mean                 -1.210207
Log Pis Std                  2.5027776
Log Pis Max                  5.491795
Log Pis Min                  -9.11908
Policy mu Mean               0.02901471
Policy mu Std                0.53416604
Policy mu Max                1.9860158
Policy mu Min                -2.164637
Policy log std Mean          -0.8492007
Policy log std Std           0.24213395
Policy log std Max           -0.24086457
Policy log std Min           -1.9544163
Z mean eval                  0.8636014
Z variance eval              0.019201482
total_rewards                [1713.20687616 1902.99410399  105.95723974  157.66477887 1489.90185773
 1120.54437305 1771.77854086 1997.98024548  864.25197074 1864.13807761]
total_rewards_mean           1298.841806424154
total_rewards_std            674.6215855220277
total_rewards_max            1997.9802454796381
total_rewards_min            105.95723973972969
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               28.97566079488024
(Previous) Eval Time (s)     18.592617864254862
Sample Time (s)              18.268889965955168
Epoch Time (s)               65.83716862509027
Total Train Time (s)         13016.183401833288
Epoch                        186
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:52:27.901115 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #186 | Epoch Duration: 67.63283824920654
2020-01-11 06:52:27.901319 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8647753
Z variance train             0.019235719
KL Divergence                18.521847
KL Loss                      1.8521847
QF Loss                      3249.751
VF Loss                      254.05707
Policy Loss                  -738.25775
Q Predictions Mean           736.5505
Q Predictions Std            198.88306
Q Predictions Max            973.5285
Q Predictions Min            1.8749263
V Predictions Mean           724.7416
V Predictions Std            197.72264
V Predictions Max            946.7163
V Predictions Min            0.91933554
Log Pis Mean                 -1.3147349
Log Pis Std                  2.5389647
Log Pis Max                  9.1434
Log Pis Min                  -6.4438047
Policy mu Mean               0.053190686
Policy mu Std                0.5426712
Policy mu Max                2.368954
Policy mu Min                -1.937347
Policy log std Mean          -0.83365476
Policy log std Std           0.27345642
Policy log std Max           -0.26366305
Policy log std Min           -2.2092574
Z mean eval                  0.8751733
Z variance eval              0.019587966
total_rewards                [1385.66425975 2059.56285801 2308.39448125  244.15675527 2108.14762408
 1770.61747447 2089.08138464  450.81543173 1974.44429459 2148.30328223]
total_rewards_mean           1653.9187846027046
total_rewards_std            696.8639927773589
total_rewards_max            2308.3944812502236
total_rewards_min            244.15675526680482
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               32.11724514234811
(Previous) Eval Time (s)     20.387987199705094
Sample Time (s)              17.47785374522209
Epoch Time (s)               69.9830860872753
Total Train Time (s)         13088.752103735693
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:53:40.474780 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #187 | Epoch Duration: 72.57326745986938
2020-01-11 06:53:40.475088 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8775104
Z variance train             0.019617941
KL Divergence                19.007753
KL Loss                      1.9007753
QF Loss                      403.2577
VF Loss                      41.3908
Policy Loss                  -782.3217
Q Predictions Mean           782.86383
Q Predictions Std            165.3155
Q Predictions Max            964.0278
Q Predictions Min            19.003048
V Predictions Mean           783.05225
V Predictions Std            164.55417
V Predictions Max            951.9716
V Predictions Min            -5.1851244
Log Pis Mean                 -1.4493183
Log Pis Std                  2.5068314
Log Pis Max                  7.756547
Log Pis Min                  -10.317197
Policy mu Mean               0.050269663
Policy mu Std                0.5237905
Policy mu Max                3.1015553
Policy mu Min                -3.5315585
Policy log std Mean          -0.86250275
Policy log std Std           0.2350915
Policy log std Max           0.24803722
Policy log std Min           -1.8725421
Z mean eval                  0.8731159
Z variance eval              0.024157632
total_rewards                [  20.90108074   87.96816631   53.89642629  -64.31493235  585.16481846
 1125.38772275 2115.98686081   26.90402392  754.68003853 2128.77235249]
total_rewards_mean           683.5346557961481
total_rewards_std            808.162949794226
total_rewards_max            2128.772352487796
total_rewards_min            -64.31493234801457
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               26.264216877985746
(Previous) Eval Time (s)     22.977845061570406
Sample Time (s)              18.86725711915642
Epoch Time (s)               68.10931905871257
Total Train Time (s)         13155.072982177138
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:54:46.796248 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #188 | Epoch Duration: 66.32093214988708
2020-01-11 06:54:46.796457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87364113
Z variance train             0.024209276
KL Divergence                18.877565
KL Loss                      1.8877566
QF Loss                      533.1825
VF Loss                      83.53441
Policy Loss                  -751.4411
Q Predictions Mean           749.03906
Q Predictions Std            198.52193
Q Predictions Max            952.40326
Q Predictions Min            18.196493
V Predictions Mean           749.43396
V Predictions Std            199.21477
V Predictions Max            955.26874
V Predictions Min            -10.198326
Log Pis Mean                 -1.3018508
Log Pis Std                  2.7328053
Log Pis Max                  13.272774
Log Pis Min                  -8.555173
Policy mu Mean               0.024094678
Policy mu Std                0.52759826
Policy mu Max                2.2832208
Policy mu Min                -2.2932255
Policy log std Mean          -0.8753852
Policy log std Std           0.27389798
Policy log std Max           0.5049715
Policy log std Min           -2.1921206
Z mean eval                  0.88190097
Z variance eval              0.024216924
total_rewards                [ -17.29082887  -53.50291856 2286.58190064 1271.61650908 2124.00090916
 2137.42238827  318.28405535 1938.03225469  866.84234911  739.04772564]
total_rewards_mean           1161.1034344507898
total_rewards_std            871.8859043312906
total_rewards_max            2286.5819006426427
total_rewards_min            -53.502918564965384
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               29.00051109213382
(Previous) Eval Time (s)     21.189141983166337
Sample Time (s)              18.0175939979963
Epoch Time (s)               68.20724707329646
Total Train Time (s)         13223.319765531924
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:55:55.047951 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #189 | Epoch Duration: 68.25133395195007
2020-01-11 06:55:55.048211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87979734
Z variance train             0.024113659
KL Divergence                19.197378
KL Loss                      1.9197378
QF Loss                      1353.0837
VF Loss                      172.51352
Policy Loss                  -739.0921
Q Predictions Mean           734.66833
Q Predictions Std            204.25272
Q Predictions Max            949.8206
Q Predictions Min            210.83197
V Predictions Mean           732.07275
V Predictions Std            200.93326
V Predictions Max            929.8687
V Predictions Min            215.44904
Log Pis Mean                 -1.4036326
Log Pis Std                  2.5675552
Log Pis Max                  8.591467
Log Pis Min                  -8.693478
Policy mu Mean               0.08655454
Policy mu Std                0.5629345
Policy mu Max                1.9513339
Policy mu Min                -1.6992968
Policy log std Mean          -0.81590986
Policy log std Std           0.24232693
Policy log std Max           -0.21062109
Policy log std Min           -2.080449
Z mean eval                  0.8852352
Z variance eval              0.02279171
total_rewards                [1224.85399158  -90.43909451   49.28727995  287.12299295  789.94408461
  329.79890503 1627.130255    805.17127828  113.19223459  408.25760271]
total_rewards_mean           554.4319530201545
total_rewards_std            522.2534686412735
total_rewards_max            1627.1302550009182
total_rewards_min            -90.4390945119713
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               26.825892340857536
(Previous) Eval Time (s)     21.232864140998572
Sample Time (s)              17.342768262140453
Epoch Time (s)               65.40152474399656
Total Train Time (s)         13288.13678842457
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:56:59.867033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #190 | Epoch Duration: 64.81863927841187
2020-01-11 06:56:59.867283 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88910085
Z variance train             0.022963423
KL Divergence                20.010227
KL Loss                      2.0010228
QF Loss                      532.71216
VF Loss                      581.77704
Policy Loss                  -766.92004
Q Predictions Mean           762.4806
Q Predictions Std            199.51477
Q Predictions Max            978.70276
Q Predictions Min            236.89261
V Predictions Mean           760.0293
V Predictions Std            199.62852
V Predictions Max            969.9219
V Predictions Min            244.38753
Log Pis Mean                 -1.3203142
Log Pis Std                  2.4146914
Log Pis Max                  6.9748588
Log Pis Min                  -8.40484
Policy mu Mean               0.063762575
Policy mu Std                0.53212416
Policy mu Max                1.9847884
Policy mu Min                -1.8779364
Policy log std Mean          -0.8381679
Policy log std Std           0.2640294
Policy log std Max           -0.14890596
Policy log std Min           -2.6090004
Z mean eval                  0.88088
Z variance eval              0.021960767
total_rewards                [ 391.77148418   75.69023205 1367.23868495  982.39873554 1841.24140633
  775.71138943 1667.80479728   28.11800085    7.74795832 2206.05412794]
total_rewards_mean           934.3776816889509
total_rewards_std            768.3776851281269
total_rewards_max            2206.054127936799
total_rewards_min            7.747958323033578
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               30.01040680380538
(Previous) Eval Time (s)     20.649663225281984
Sample Time (s)              18.583789599128067
Epoch Time (s)               69.24385962821543
Total Train Time (s)         13356.54096602602
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:58:08.274079 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #191 | Epoch Duration: 68.40657711029053
2020-01-11 06:58:08.274313 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #191 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88125527
Z variance train             0.02192007
KL Divergence                19.933834
KL Loss                      1.9933834
QF Loss                      944.901
VF Loss                      79.104355
Policy Loss                  -769.0296
Q Predictions Mean           766.2587
Q Predictions Std            171.3724
Q Predictions Max            944.64575
Q Predictions Min            225.16934
V Predictions Mean           764.8581
V Predictions Std            170.71083
V Predictions Max            942.0686
V Predictions Min            240.30284
Log Pis Mean                 -1.374546
Log Pis Std                  2.2841647
Log Pis Max                  6.2473736
Log Pis Min                  -7.7369633
Policy mu Mean               0.1125497
Policy mu Std                0.5264177
Policy mu Max                3.5909023
Policy mu Min                -1.954858
Policy log std Mean          -0.8274686
Policy log std Std           0.23638877
Policy log std Max           -0.20421499
Policy log std Min           -1.9192991
Z mean eval                  0.8925492
Z variance eval              0.020297581
total_rewards                [-143.35230564  541.42321655 2081.7666602   482.77291749 2332.21559443
 1035.67467646 1225.916201   1898.63172701  664.67614933 2014.1990676 ]
total_rewards_mean           1213.3923904421893
total_rewards_std            792.187920694563
total_rewards_max            2332.2155944309216
total_rewards_min            -143.35230564321012
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               28.50868816813454
(Previous) Eval Time (s)     19.81201552832499
Sample Time (s)              17.744069560430944
Epoch Time (s)               66.06477325689048
Total Train Time (s)         13426.20925429603
Epoch                        192
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:59:17.946455 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #192 | Epoch Duration: 69.67193841934204
2020-01-11 06:59:17.946700 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89580727
Z variance train             0.020310318
KL Divergence                20.2604
KL Loss                      2.02604
QF Loss                      783.073
VF Loss                      343.1824
Policy Loss                  -754.3293
Q Predictions Mean           753.3158
Q Predictions Std            213.16777
Q Predictions Max            969.9456
Q Predictions Min            -45.51585
V Predictions Mean           755.126
V Predictions Std            208.82748
V Predictions Max            968.6226
V Predictions Min            78.56482
Log Pis Mean                 -0.9746195
Log Pis Std                  2.621958
Log Pis Max                  11.028948
Log Pis Min                  -7.699609
Policy mu Mean               0.019951526
Policy mu Std                0.59351724
Policy mu Max                2.367992
Policy mu Min                -2.2559695
Policy log std Mean          -0.8300984
Policy log std Std           0.26013547
Policy log std Max           -0.23556647
Policy log std Min           -2.5878918
Z mean eval                  0.86791784
Z variance eval              0.022265604
total_rewards                [ 153.78306034 2271.09476251  254.06189104 2179.95489171 1003.96766703
  808.9184569    92.6672996  2054.00152968 2315.02619682 2423.78403868]
total_rewards_mean           1355.7259794311262
total_rewards_std            934.9987769048618
total_rewards_max            2423.7840386844573
total_rewards_min            92.66729960019313
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               31.358881333377212
(Previous) Eval Time (s)     23.41888768505305
Sample Time (s)              18.204966923687607
Epoch Time (s)               72.98273594211787
Total Train Time (s)         13497.695158869494
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:00:29.436252 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #193 | Epoch Duration: 71.48933839797974
2020-01-11 07:00:29.436563 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.86866647
Z variance train             0.022205573
KL Divergence                19.758121
KL Loss                      1.9758122
QF Loss                      477.93018
VF Loss                      52.057034
Policy Loss                  -748.995
Q Predictions Mean           745.5253
Q Predictions Std            207.87117
Q Predictions Max            956.8949
Q Predictions Min            3.6012578
V Predictions Mean           749.9586
V Predictions Std            206.14888
V Predictions Max            947.0319
V Predictions Min            -4.0817356
Log Pis Mean                 -1.0532839
Log Pis Std                  2.4660828
Log Pis Max                  6.4892497
Log Pis Min                  -7.482943
Policy mu Mean               0.024234308
Policy mu Std                0.55862045
Policy mu Max                1.9678422
Policy mu Min                -2.1582026
Policy log std Mean          -0.8431473
Policy log std Std           0.26111755
Policy log std Max           -0.20538437
Policy log std Min           -1.8710679
Z mean eval                  0.87206984
Z variance eval              0.029930478
total_rewards                [2050.00242065 1339.02185674 1403.8458454   284.56967114 1465.62472792
 2351.88687129 1583.20733948 2278.2144282   433.2650301   147.30323123]
total_rewards_mean           1333.6941422148634
total_rewards_std            764.5588826525651
total_rewards_max            2351.8868712903695
total_rewards_min            147.30323122644998
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               27.819790630135685
(Previous) Eval Time (s)     21.9251685612835
Sample Time (s)              18.787655923049897
Epoch Time (s)               68.53261511446908
Total Train Time (s)         13563.85675640963
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:01:35.600066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #194 | Epoch Duration: 66.1632821559906
2020-01-11 07:01:35.600249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #194 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8712457
Z variance train             0.029932851
KL Divergence                18.475334
KL Loss                      1.8475335
QF Loss                      449.6406
VF Loss                      113.92348
Policy Loss                  -744.4924
Q Predictions Mean           740.14154
Q Predictions Std            214.48346
Q Predictions Max            961.5616
Q Predictions Min            -10.077074
V Predictions Mean           740.92944
V Predictions Std            213.45663
V Predictions Max            963.89374
V Predictions Min            -0.25517833
Log Pis Mean                 -1.4537323
Log Pis Std                  2.4160001
Log Pis Max                  6.0031214
Log Pis Min                  -11.20072
Policy mu Mean               0.052930377
Policy mu Std                0.5007635
Policy mu Max                1.8068177
Policy mu Min                -1.9341162
Policy log std Mean          -0.8529836
Policy log std Std           0.2407441
Policy log std Max           -0.26996854
Policy log std Min           -1.9189122
Z mean eval                  0.8871309
Z variance eval              0.039280094
total_rewards                [2432.83567341 1419.75374769  915.0600546  2313.59913791  537.63696547
 2236.74321114 1076.73351426 2381.94907699 1444.67566188 2476.34365864]
total_rewards_mean           1723.5330701988696
total_rewards_std            690.16515419835
total_rewards_max            2476.3436586403577
total_rewards_min            537.6369654732226
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               26.59854738600552
(Previous) Eval Time (s)     19.555524681229144
Sample Time (s)              17.734105933923274
Epoch Time (s)               63.88817800115794
Total Train Time (s)         13634.633739105426
Epoch                        195
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:02:46.378933 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #195 | Epoch Duration: 70.77853441238403
2020-01-11 07:02:46.379129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.88698006
Z variance train             0.03922988
KL Divergence                18.343733
KL Loss                      1.8343734
QF Loss                      544.96045
VF Loss                      162.99254
Policy Loss                  -745.0145
Q Predictions Mean           737.7122
Q Predictions Std            207.32504
Q Predictions Max            964.263
Q Predictions Min            -59.953598
V Predictions Mean           737.6669
V Predictions Std            201.62746
V Predictions Max            952.2441
V Predictions Min            -9.183401
Log Pis Mean                 -1.1942711
Log Pis Std                  2.736752
Log Pis Max                  8.470852
Log Pis Min                  -10.039185
Policy mu Mean               0.046334222
Policy mu Std                0.55335903
Policy mu Max                2.0048935
Policy mu Min                -2.044038
Policy log std Mean          -0.86412615
Policy log std Std           0.26481628
Policy log std Max           0.64285517
Policy log std Min           -2.63751
Z mean eval                  0.8968269
Z variance eval              0.029029077
total_rewards                [ 755.72939029 1344.69581277 2292.9543006   775.00485123 2277.17023896
 1460.58866948 1881.41116794 2323.06640886  816.23621146 1909.84429449]
total_rewards_mean           1583.6701346081077
total_rewards_std            610.4433303210541
total_rewards_max            2323.0664088588414
total_rewards_min            755.7293902942895
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               27.92179656494409
(Previous) Eval Time (s)     26.445563103072345
Sample Time (s)              19.26329720998183
Epoch Time (s)               73.63065687799826
Total Train Time (s)         13706.39338889718
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:03:58.142607 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #196 | Epoch Duration: 71.7633101940155
2020-01-11 07:03:58.142824 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8979575
Z variance train             0.028978419
KL Divergence                18.65589
KL Loss                      1.865589
QF Loss                      750.35565
VF Loss                      221.05447
Policy Loss                  -804.00037
Q Predictions Mean           803.36786
Q Predictions Std            178.9386
Q Predictions Max            1000.3932
Q Predictions Min            -21.051651
V Predictions Mean           810.7643
V Predictions Std            179.99898
V Predictions Max            1007.4158
V Predictions Min            -6.6305656
Log Pis Mean                 -1.1524757
Log Pis Std                  2.417353
Log Pis Max                  5.357071
Log Pis Min                  -11.044561
Policy mu Mean               0.05485282
Policy mu Std                0.52791214
Policy mu Max                1.7546166
Policy mu Min                -1.8221585
Policy log std Mean          -0.8848065
Policy log std Std           0.24940194
Policy log std Max           -0.27564642
Policy log std Min           -2.0863433
Z mean eval                  0.9056298
Z variance eval              0.029114861
total_rewards                [2193.37316502 1601.55070983 2082.32121281 1936.69865351 1455.39021612
 2221.78575827 1913.52689851 2142.27843787 1088.44125313  854.18310669]
total_rewards_mean           1748.9549411772837
total_rewards_std            457.6076744501541
total_rewards_max            2221.785758273415
total_rewards_min            854.1831066906346
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               27.133638376835734
(Previous) Eval Time (s)     24.577912437729537
Sample Time (s)              18.144684536382556
Epoch Time (s)               69.85623535094783
Total Train Time (s)         13777.07408453431
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:05:08.827060 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #197 | Epoch Duration: 70.68402814865112
2020-01-11 07:05:08.827347 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9054338
Z variance train             0.029024068
KL Divergence                18.519707
KL Loss                      1.8519707
QF Loss                      701.00507
VF Loss                      192.76607
Policy Loss                  -759.21857
Q Predictions Mean           754.8726
Q Predictions Std            218.16666
Q Predictions Max            992.0588
Q Predictions Min            54.049484
V Predictions Mean           754.3285
V Predictions Std            214.75429
V Predictions Max            991.78186
V Predictions Min            101.56822
Log Pis Mean                 -1.2815385
Log Pis Std                  2.4552248
Log Pis Max                  8.736111
Log Pis Min                  -7.187215
Policy mu Mean               0.05136023
Policy mu Std                0.56274194
Policy mu Max                2.356771
Policy mu Min                -2.0973518
Policy log std Mean          -0.81666684
Policy log std Std           0.2589386
Policy log std Max           -0.08154011
Policy log std Min           -2.5298235
Z mean eval                  0.91253203
Z variance eval              0.031991117
total_rewards                [ 178.298219    911.16719696  323.81801532  940.20333177 2046.60847207
  483.83490665  565.56577592 2128.81320264  867.32750944  635.1905374 ]
total_rewards_mean           908.0827167146215
total_rewards_std            635.2047626336996
total_rewards_max            2128.813202635631
total_rewards_min            178.29821899814846
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               25.14725627982989
(Previous) Eval Time (s)     25.405394199304283
Sample Time (s)              18.16912735067308
Epoch Time (s)               68.72177782980725
Total Train Time (s)         13847.563493852504
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:06:19.317394 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #198 | Epoch Duration: 70.4898293018341
2020-01-11 07:06:19.317578 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9158577
Z variance train             0.03186357
KL Divergence                18.734627
KL Loss                      1.8734627
QF Loss                      1092.4833
VF Loss                      758.1558
Policy Loss                  -784.4798
Q Predictions Mean           783.2052
Q Predictions Std            185.34488
Q Predictions Max            991.52155
Q Predictions Min            118.110214
V Predictions Mean           786.8938
V Predictions Std            178.35399
V Predictions Max            994.23553
V Predictions Min            147.27306
Log Pis Mean                 -0.825767
Log Pis Std                  2.4281282
Log Pis Max                  8.106259
Log Pis Min                  -7.996271
Policy mu Mean               0.06954099
Policy mu Std                0.5195311
Policy mu Max                1.8817027
Policy mu Min                -1.8917319
Policy log std Mean          -0.8977649
Policy log std Std           0.25397813
Policy log std Max           -0.34323633
Policy log std Min           -2.1783638
Z mean eval                  0.89058465
Z variance eval              0.022910353
total_rewards                [ -19.01503335 1065.43501945  853.95413534 2459.95157911 1568.94790539
 2163.86523659  641.06718705 1219.22198012  205.18492856 2305.84526468]
total_rewards_mean           1246.4458202940398
total_rewards_std            823.4223622376807
total_rewards_max            2459.951579107579
total_rewards_min            -19.01503335203031
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               30.895132947713137
(Previous) Eval Time (s)     27.173105917871
Sample Time (s)              18.183656515087932
Epoch Time (s)               76.25189538067207
Total Train Time (s)         13918.151952947956
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:07:29.922140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #199 | Epoch Duration: 70.60444116592407
2020-01-11 07:07:29.922291 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8906479
Z variance train             0.02286815
KL Divergence                18.907333
KL Loss                      1.8907334
QF Loss                      848.42896
VF Loss                      136.0881
Policy Loss                  -772.1053
Q Predictions Mean           769.3457
Q Predictions Std            194.34763
Q Predictions Max            961.7341
Q Predictions Min            232.44545
V Predictions Mean           776.56384
V Predictions Std            197.71729
V Predictions Max            971.9921
V Predictions Min            237.56888
Log Pis Mean                 -1.5170102
Log Pis Std                  2.371862
Log Pis Max                  7.497196
Log Pis Min                  -7.2317476
Policy mu Mean               0.08358185
Policy mu Std                0.53121644
Policy mu Max                2.008035
Policy mu Min                -1.9791582
Policy log std Mean          -0.84992325
Policy log std Std           0.25137198
Policy log std Max           -0.29922295
Policy log std Min           -2.2921774
Z mean eval                  0.89058053
Z variance eval              0.023963755
total_rewards                [1091.73154989 1214.84904136 1926.4928525  2267.79332083 1965.90939677
 2124.87794718 1979.14607352  641.23194314 2103.32270476  659.92340023]
total_rewards_mean           1597.5278230175938
total_rewards_std            597.3788329326694
total_rewards_max            2267.79332082657
total_rewards_min            641.2319431424112
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               30.36908079497516
(Previous) Eval Time (s)     21.525334787089378
Sample Time (s)              17.887564107310027
Epoch Time (s)               69.78197968937457
Total Train Time (s)         13993.819289547857
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:08:45.593023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #200 | Epoch Duration: 75.67059278488159
2020-01-11 07:08:45.593242 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8945117
Z variance train             0.023934994
KL Divergence                18.859058
KL Loss                      1.8859059
QF Loss                      441.66974
VF Loss                      135.42293
Policy Loss                  -799.57855
Q Predictions Mean           794.2169
Q Predictions Std            180.22546
Q Predictions Max            1001.343
Q Predictions Min            27.275545
V Predictions Mean           792.7636
V Predictions Std            176.76263
V Predictions Max            995.7561
V Predictions Min            16.14297
Log Pis Mean                 -0.80970055
Log Pis Std                  2.348429
Log Pis Max                  6.2134476
Log Pis Min                  -8.9256115
Policy mu Mean               0.024012335
Policy mu Std                0.56122553
Policy mu Max                1.8939772
Policy mu Min                -1.694551
Policy log std Mean          -0.87410116
Policy log std Std           0.24853435
Policy log std Max           -0.22701311
Policy log std Min           -2.1445003
Z mean eval                  0.9038037
Z variance eval              0.028720671
total_rewards                [2184.11130368 2144.60661721 2222.6977667  2326.68177967 2013.33022662
 2165.11204575 2038.0306477  1526.86441514 2114.50694926 2265.92753381]
total_rewards_mean           2100.186928553695
total_rewards_std            211.49981297954895
total_rewards_max            2326.68177967016
total_rewards_min            1526.864415137425
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               30.376308771781623
(Previous) Eval Time (s)     27.413634659722447
Sample Time (s)              17.65865120338276
Epoch Time (s)               75.44859463488683
Total Train Time (s)         14069.75552587118
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:10:01.531002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #201 | Epoch Duration: 75.9375991821289
2020-01-11 07:10:01.531187 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90567684
Z variance train             0.028724033
KL Divergence                18.590467
KL Loss                      1.8590468
QF Loss                      456.96906
VF Loss                      233.41457
Policy Loss                  -803.87445
Q Predictions Mean           799.9772
Q Predictions Std            172.52011
Q Predictions Max            1019.10614
Q Predictions Min            223.27382
V Predictions Mean           795.05145
V Predictions Std            170.87495
V Predictions Max            988.5003
V Predictions Min            226.53273
Log Pis Mean                 -1.1262268
Log Pis Std                  2.2255926
Log Pis Max                  4.47002
Log Pis Min                  -7.44232
Policy mu Mean               0.011461891
Policy mu Std                0.53084695
Policy mu Max                2.0701127
Policy mu Min                -1.6301701
Policy log std Mean          -0.89333946
Policy log std Std           0.24378821
Policy log std Max           -0.27941206
Policy log std Min           -1.8930974
Z mean eval                  0.8806221
Z variance eval              0.029801458
total_rewards                [ 936.04071393 2111.24160459 1951.16666818  118.27778329 1670.07020642
  682.44120035  529.39633829 2252.99647584 1542.6841086   442.70584199]
total_rewards_mean           1223.7020941477522
total_rewards_std            732.6024154206535
total_rewards_max            2252.99647584225
total_rewards_min            118.27778328507051
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               27.910317370668054
(Previous) Eval Time (s)     27.902349766343832
Sample Time (s)              18.97931686323136
Epoch Time (s)               74.79198400024325
Total Train Time (s)         14143.055136910174
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:11:14.834290 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #202 | Epoch Duration: 73.3029522895813
2020-01-11 07:11:14.834534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8804908
Z variance train             0.029891005
KL Divergence                18.42997
KL Loss                      1.842997
QF Loss                      855.98224
VF Loss                      131.40791
Policy Loss                  -804.4717
Q Predictions Mean           803.177
Q Predictions Std            193.33957
Q Predictions Max            1009.3441
Q Predictions Min            241.07903
V Predictions Mean           810.06635
V Predictions Std            194.17552
V Predictions Max            1019.6454
V Predictions Min            250.73491
Log Pis Mean                 -1.140413
Log Pis Std                  2.3267167
Log Pis Max                  5.5854297
Log Pis Min                  -6.5538588
Policy mu Mean               0.08884521
Policy mu Std                0.5571324
Policy mu Max                2.1267245
Policy mu Min                -1.8032532
Policy log std Mean          -0.84809905
Policy log std Std           0.242117
Policy log std Max           -0.2490685
Policy log std Min           -2.0255928
Z mean eval                  0.8827019
Z variance eval              0.03518176
total_rewards                [ -20.32278301  457.82633213 2406.15677411  307.17430733  134.12598829
 1239.55279353 2303.19182458 2427.28333796 1260.96372087  863.35409986]
total_rewards_mean           1137.9306395655633
total_rewards_std            907.2701217009902
total_rewards_max            2427.283337960801
total_rewards_min            -20.322783007888873
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               26.63246754836291
(Previous) Eval Time (s)     26.4129351307638
Sample Time (s)              18.631400095298886
Epoch Time (s)               71.6768027744256
Total Train Time (s)         14210.291365849786
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:12:22.072510 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #203 | Epoch Duration: 67.23780179023743
2020-01-11 07:12:22.072691 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8829891
Z variance train             0.035297073
KL Divergence                17.860533
KL Loss                      1.7860533
QF Loss                      525.61084
VF Loss                      101.3382
Policy Loss                  -776.6174
Q Predictions Mean           774.32275
Q Predictions Std            211.98941
Q Predictions Max            983.6099
Q Predictions Min            -0.26490688
V Predictions Mean           774.6382
V Predictions Std            208.093
V Predictions Max            984.16815
V Predictions Min            225.53302
Log Pis Mean                 -1.2534204
Log Pis Std                  2.5990665
Log Pis Max                  14.839266
Log Pis Min                  -9.235204
Policy mu Mean               0.03367264
Policy mu Std                0.52562875
Policy mu Max                1.858425
Policy mu Min                -1.9017699
Policy log std Mean          -0.8803842
Policy log std Std           0.30193305
Policy log std Max           -0.2733818
Policy log std Min           -3.553193
Z mean eval                  0.89781487
Z variance eval              0.0312997
total_rewards                [1676.16929247 1225.09604315  193.06945134 2376.31286665 2202.52338983
 1981.01350095 2231.81701117  748.23539425  479.08763023 2292.27946109]
total_rewards_mean           1540.560404113962
total_rewards_std            778.5715197361307
total_rewards_max            2376.3128666519015
total_rewards_min            193.06945133606445
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               28.79831184912473
(Previous) Eval Time (s)     21.973597540985793
Sample Time (s)              17.92754489928484
Epoch Time (s)               68.69945428939536
Total Train Time (s)         14279.538690280635
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:13:31.322487 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #204 | Epoch Duration: 69.24965691566467
2020-01-11 07:13:31.322713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8973526
Z variance train             0.031276457
KL Divergence                17.96555
KL Loss                      1.7965549
QF Loss                      403.4271
VF Loss                      151.23807
Policy Loss                  -799.22906
Q Predictions Mean           797.103
Q Predictions Std            200.02907
Q Predictions Max            980.2731
Q Predictions Min            108.248314
V Predictions Mean           798.9917
V Predictions Std            200.9212
V Predictions Max            980.70374
V Predictions Min            24.288494
Log Pis Mean                 -1.2900681
Log Pis Std                  2.6066272
Log Pis Max                  8.370832
Log Pis Min                  -9.744072
Policy mu Mean               0.05669637
Policy mu Std                0.56285024
Policy mu Max                1.789504
Policy mu Min                -1.9620239
Policy log std Mean          -0.83544075
Policy log std Std           0.23489538
Policy log std Max           -0.24632272
Policy log std Min           -1.8458288
Z mean eval                  0.9031631
Z variance eval              0.027595114
total_rewards                [1398.66194004 2213.96704104 1544.30580514  408.81025422 1971.15064587
  318.14562103  706.71734744   54.79309238 2119.95999748  244.42926195]
total_rewards_mean           1098.0941006581154
total_rewards_std            799.6802009604243
total_rewards_max            2213.9670410356875
total_rewards_min            54.79309238208869
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               30.213288402184844
(Previous) Eval Time (s)     22.52349223801866
Sample Time (s)              17.914285367820412
Epoch Time (s)               70.65106600802392
Total Train Time (s)         14344.83722382877
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:14:36.623785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #205 | Epoch Duration: 65.30090117454529
2020-01-11 07:14:36.623977 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90321076
Z variance train             0.027547345
KL Divergence                17.391289
KL Loss                      1.739129
QF Loss                      824.23846
VF Loss                      97.69083
Policy Loss                  -807.2435
Q Predictions Mean           804.9173
Q Predictions Std            197.37158
Q Predictions Max            1007.78973
Q Predictions Min            -1.8903414
V Predictions Mean           808.3379
V Predictions Std            198.43568
V Predictions Max            1020.40686
V Predictions Min            0.12350327
Log Pis Mean                 -1.1462691
Log Pis Std                  2.568298
Log Pis Max                  7.062255
Log Pis Min                  -11.070309
Policy mu Mean               0.07177378
Policy mu Std                0.54421866
Policy mu Max                1.7884396
Policy mu Min                -2.2891846
Policy log std Mean          -0.8468722
Policy log std Std           0.24939147
Policy log std Max           -0.16986823
Policy log std Min           -1.9807522
Z mean eval                  0.8762329
Z variance eval              0.036821656
total_rewards                [2050.21116435 1205.41632806 1979.62513498  275.59552874 2237.35177561
 2455.00673181 1859.46104275 1447.275927   1303.44252416  740.76302332]
total_rewards_mean           1555.4149180779766
total_rewards_std            655.0422512354537
total_rewards_max            2455.0067318094684
total_rewards_min            275.5955287383438
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               28.739350656978786
(Previous) Eval Time (s)     17.17299790820107
Sample Time (s)              18.6428523985669
Epoch Time (s)               64.55520096374676
Total Train Time (s)         14415.044206094462
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:15:46.832016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #206 | Epoch Duration: 70.20790004730225
2020-01-11 07:15:46.832182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.87346154
Z variance train             0.036746852
KL Divergence                16.638008
KL Loss                      1.6638008
QF Loss                      617.9413
VF Loss                      289.8471
Policy Loss                  -799.7429
Q Predictions Mean           797.6231
Q Predictions Std            204.34491
Q Predictions Max            1003.3285
Q Predictions Min            218.59396
V Predictions Mean           814.6506
V Predictions Std            204.56708
V Predictions Max            1025.0734
V Predictions Min            234.37273
Log Pis Mean                 -1.4472255
Log Pis Std                  2.7123132
Log Pis Max                  12.335918
Log Pis Min                  -9.073878
Policy mu Mean               0.032146446
Policy mu Std                0.5343999
Policy mu Max                2.0274546
Policy mu Min                -2.5104728
Policy log std Mean          -0.8561432
Policy log std Std           0.24762134
Policy log std Max           -0.35917333
Policy log std Min           -2.0769289
Z mean eval                  0.8851673
Z variance eval              0.020749325
total_rewards                [1911.74988083  686.77878835 2058.74660245 2057.5829502  2065.60582671
 1150.42768075 2107.67467057 2600.86571624 2074.94836731  610.91417373]
total_rewards_mean           1732.5294657126901
total_rewards_std            636.9919552782229
total_rewards_max            2600.865716241743
total_rewards_min            610.9141737289619
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               26.929682314861566
(Previous) Eval Time (s)     22.8253586278297
Sample Time (s)              17.96392533974722
Epoch Time (s)               67.71896628243849
Total Train Time (s)         14483.41589210229
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:16:55.208813 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #207 | Epoch Duration: 68.37647080421448
2020-01-11 07:16:55.209092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #207 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8849479
Z variance train             0.020743672
KL Divergence                17.629402
KL Loss                      1.7629403
QF Loss                      768.5258
VF Loss                      122.129036
Policy Loss                  -794.5579
Q Predictions Mean           794.1497
Q Predictions Std            207.48384
Q Predictions Max            1033.8372
Q Predictions Min            220.02042
V Predictions Mean           799.1256
V Predictions Std            206.60397
V Predictions Max            1021.6264
V Predictions Min            223.11275
Log Pis Mean                 -1.1558583
Log Pis Std                  2.5831301
Log Pis Max                  7.7282557
Log Pis Min                  -7.8760605
Policy mu Mean               0.11762868
Policy mu Std                0.542327
Policy mu Max                2.2223527
Policy mu Min                -1.6708615
Policy log std Mean          -0.87643206
Policy log std Std           0.2591348
Policy log std Max           -0.251207
Policy log std Min           -2.4027772
Z mean eval                  0.9084314
Z variance eval              0.019732177
total_rewards                [1562.14131051  388.17810116  565.10205288  718.08914061 1489.9329919
    9.51883718  516.35605399  991.10854874   82.80864567  257.01775838]
total_rewards_mean           658.0253441022903
total_rewards_std            513.5963960019877
total_rewards_max            1562.1413105143984
total_rewards_min            9.518837183432671
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               27.40230122068897
(Previous) Eval Time (s)     23.482582970988005
Sample Time (s)              17.938337035942823
Epoch Time (s)               68.8232212276198
Total Train Time (s)         14546.780740627088
Epoch                        208
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:17:58.577382 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #208 | Epoch Duration: 63.36807584762573
2020-01-11 07:17:58.577614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9083842
Z variance train             0.019767616
KL Divergence                18.404278
KL Loss                      1.8404278
QF Loss                      856.37866
VF Loss                      135.41064
Policy Loss                  -787.02264
Q Predictions Mean           783.9774
Q Predictions Std            214.93921
Q Predictions Max            1000.36536
Q Predictions Min            221.67377
V Predictions Mean           782.78467
V Predictions Std            212.78755
V Predictions Max            988.0756
V Predictions Min            233.87428
Log Pis Mean                 -1.2592716
Log Pis Std                  2.6258624
Log Pis Max                  10.243604
Log Pis Min                  -8.943987
Policy mu Mean               0.07771649
Policy mu Std                0.5636447
Policy mu Max                2.134429
Policy mu Min                -1.9341282
Policy log std Mean          -0.8342283
Policy log std Std           0.26306245
Policy log std Max           -0.16484612
Policy log std Min           -2.3455458
Z mean eval                  0.90461886
Z variance eval              0.022450346
total_rewards                [2160.69661773 2339.47802927  138.90879441 2533.36831153  772.16253135
  447.83318548  980.77522443    7.43543659   10.89790437  421.8085942 ]
total_rewards_mean           981.3364629368155
total_rewards_std            942.6352190180471
total_rewards_max            2533.3683115296153
total_rewards_min            7.4354365918411
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               28.841260695829988
(Previous) Eval Time (s)     18.02712775580585
Sample Time (s)              17.35856654215604
Epoch Time (s)               64.22695499379188
Total Train Time (s)         14611.346849665977
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:19:03.144727 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #209 | Epoch Duration: 64.56694340705872
2020-01-11 07:19:03.144921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #209 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9024445
Z variance train             0.022607824
KL Divergence                18.031265
KL Loss                      1.8031266
QF Loss                      1686.3484
VF Loss                      393.88782
Policy Loss                  -806.0708
Q Predictions Mean           806.12476
Q Predictions Std            203.00731
Q Predictions Max            1011.66394
Q Predictions Min            205.02965
V Predictions Mean           822.8347
V Predictions Std            205.06853
V Predictions Max            1027.5499
V Predictions Min            213.97063
Log Pis Mean                 -1.0069355
Log Pis Std                  2.4699655
Log Pis Max                  5.7573524
Log Pis Min                  -8.752551
Policy mu Mean               0.031035664
Policy mu Std                0.584122
Policy mu Max                1.7856367
Policy mu Min                -1.9904797
Policy log std Mean          -0.8417694
Policy log std Std           0.23779659
Policy log std Max           -0.23152414
Policy log std Min           -2.1534355
Z mean eval                  0.89252186
Z variance eval              0.033848226
total_rewards                [2085.98798239 1887.66943398  261.93982187   22.6137016  1966.42290689
 1819.72810313  305.98611814 1176.07960971  721.98083532  125.07535387]
total_rewards_mean           1037.3483866904246
total_rewards_std            800.922542596365
total_rewards_max            2085.9879823926944
total_rewards_min            22.613701599334508
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               27.869472796097398
(Previous) Eval Time (s)     18.366830586921424
Sample Time (s)              18.04380439268425
Epoch Time (s)               64.28010777570307
Total Train Time (s)         14675.32212604722
Epoch                        210
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:20:07.121901 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #210 | Epoch Duration: 63.976848125457764
2020-01-11 07:20:07.122100 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #210 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8945365
Z variance train             0.03383287
KL Divergence                17.290298
KL Loss                      1.7290299
QF Loss                      514.4214
VF Loss                      158.9614
Policy Loss                  -788.39233
Q Predictions Mean           789.45337
Q Predictions Std            192.11093
Q Predictions Max            996.03705
Q Predictions Min            25.257902
V Predictions Mean           798.4634
V Predictions Std            192.50197
V Predictions Max            1007.32007
V Predictions Min            42.758213
Log Pis Mean                 -1.3542039
Log Pis Std                  2.6811476
Log Pis Max                  10.149639
Log Pis Min                  -8.144724
Policy mu Mean               0.043736286
Policy mu Std                0.5393474
Policy mu Max                1.9221625
Policy mu Min                -1.9893032
Policy log std Mean          -0.8561361
Policy log std Std           0.24776016
Policy log std Max           -0.27879536
Policy log std Min           -2.4199133
Z mean eval                  0.88714886
Z variance eval              0.031584736
total_rewards                [2369.9480596   141.37491813 2521.04420094 1239.30584679 1995.56970279
 2504.91331114 2353.87333408 1352.10588926 2361.52359593 2381.68692555]
total_rewards_mean           1922.1345784221025
total_rewards_std            738.7283391885023
total_rewards_max            2521.044200939252
total_rewards_min            141.37491812982532
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               29.67068298580125
(Previous) Eval Time (s)     18.06321822386235
Sample Time (s)              17.782120381481946
Epoch Time (s)               65.51602159114555
Total Train Time (s)         14747.84284120053
Epoch                        211
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:21:19.648008 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #211 | Epoch Duration: 72.52572536468506
2020-01-11 07:21:19.648340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8869726
Z variance train             0.031611077
KL Divergence                17.483042
KL Loss                      1.7483042
QF Loss                      537.842
VF Loss                      126.03917
Policy Loss                  -789.8076
Q Predictions Mean           787.5867
Q Predictions Std            211.8005
Q Predictions Max            1008.1305
Q Predictions Min            37.188503
V Predictions Mean           788.3047
V Predictions Std            213.99661
V Predictions Max            1021.5934
V Predictions Min            -2.1434934
Log Pis Mean                 -1.0111163
Log Pis Std                  2.4170465
Log Pis Max                  7.0783777
Log Pis Min                  -7.11218
Policy mu Mean               0.010273598
Policy mu Std                0.5404193
Policy mu Max                1.916156
Policy mu Min                -1.8778374
Policy log std Mean          -0.86662674
Policy log std Std           0.2603531
Policy log std Max           -0.29046428
Policy log std Min           -2.3661375
Z mean eval                  0.89198035
Z variance eval              0.036585145
total_rewards                [   5.40751882 1920.14238846 2298.41954277  428.13158812 2286.08033446
 1236.77283535 2407.84179934  889.98879787  745.9758606  2489.73738971]
total_rewards_mean           1470.849805548992
total_rewards_std            872.9168555402147
total_rewards_max            2489.737389711995
total_rewards_min            5.407518816512831
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               26.6726816999726
(Previous) Eval Time (s)     25.072553584352136
Sample Time (s)              18.100710086524487
Epoch Time (s)               69.84594537084922
Total Train Time (s)         14815.12896725582
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:22:26.936237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #212 | Epoch Duration: 67.28766989707947
2020-01-11 07:22:26.936456 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8947116
Z variance train             0.0362212
KL Divergence                17.471848
KL Loss                      1.7471848
QF Loss                      1759.3068
VF Loss                      116.052315
Policy Loss                  -832.3073
Q Predictions Mean           825.8048
Q Predictions Std            184.92119
Q Predictions Max            1006.59357
Q Predictions Min            1.7569026
V Predictions Mean           831.1207
V Predictions Std            181.17007
V Predictions Max            1007.264
V Predictions Min            95.754524
Log Pis Mean                 -0.8394961
Log Pis Std                  2.2123382
Log Pis Max                  6.7734795
Log Pis Min                  -6.8441286
Policy mu Mean               0.08837642
Policy mu Std                0.5497942
Policy mu Max                1.9524139
Policy mu Min                -1.7903124
Policy log std Mean          -0.8781552
Policy log std Std           0.2632846
Policy log std Max           -0.2673131
Policy log std Min           -2.164072
Z mean eval                  0.90413535
Z variance eval              0.018557696
total_rewards                [ 381.33556978  820.85933058  675.81176601 2290.58301071  693.56277151
 1638.3997565  1844.29456608  498.88719272  376.99002825  535.66904669]
total_rewards_mean           975.6393038827715
total_rewards_std            651.8247604409669
total_rewards_max            2290.5830107133224
total_rewards_min            376.9900282491399
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               30.140503004658967
(Previous) Eval Time (s)     22.513982620090246
Sample Time (s)              17.681880647782236
Epoch Time (s)               70.33636627253145
Total Train Time (s)         14881.749787615146
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:23:33.561474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #213 | Epoch Duration: 66.62481880187988
2020-01-11 07:23:33.561785 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.90347767
Z variance train             0.018531341
KL Divergence                18.626493
KL Loss                      1.8626493
QF Loss                      568.1511
VF Loss                      61.84188
Policy Loss                  -787.95917
Q Predictions Mean           786.8675
Q Predictions Std            227.66776
Q Predictions Max            1028.5934
Q Predictions Min            212.26985
V Predictions Mean           790.08875
V Predictions Std            225.0276
V Predictions Max            1028.7299
V Predictions Min            225.65405
Log Pis Mean                 -1.23243
Log Pis Std                  2.3765402
Log Pis Max                  5.7190523
Log Pis Min                  -12.600009
Policy mu Mean               0.083908126
Policy mu Std                0.5547246
Policy mu Max                2.013625
Policy mu Min                -1.6895576
Policy log std Mean          -0.8259723
Policy log std Std           0.23702359
Policy log std Max           -0.12667763
Policy log std Min           -1.8341922
Z mean eval                  0.8973285
Z variance eval              0.035978705
total_rewards                [ 227.62468239 2260.18836328 2594.89207597  818.01420189 1300.96147514
   56.86542161 2594.33029878  141.03938536  101.73306241 1163.0013587 ]
total_rewards_mean           1125.8650325537371
total_rewards_std            984.6955802894042
total_rewards_max            2594.892075970778
total_rewards_min            56.86542161068731
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               28.63473399821669
(Previous) Eval Time (s)     18.802097885869443
Sample Time (s)              17.973972861655056
Epoch Time (s)               65.41080474574119
Total Train Time (s)         14943.86301723402
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:24:35.677117 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #214 | Epoch Duration: 62.11510491371155
2020-01-11 07:24:35.677339 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.89784926
Z variance train             0.036065355
KL Divergence                17.290255
KL Loss                      1.7290255
QF Loss                      635.154
VF Loss                      139.5032
Policy Loss                  -788.28674
Q Predictions Mean           787.8086
Q Predictions Std            201.69826
Q Predictions Max            991.06274
Q Predictions Min            186.92863
V Predictions Mean           793.558
V Predictions Std            201.04147
V Predictions Max            998.8019
V Predictions Min            193.23799
Log Pis Mean                 -0.83330435
Log Pis Std                  2.650124
Log Pis Max                  6.5685263
Log Pis Min                  -9.885757
Policy mu Mean               0.04184378
Policy mu Std                0.5751649
Policy mu Max                2.047103
Policy mu Min                -2.0661225
Policy log std Mean          -0.8615378
Policy log std Std           0.25581637
Policy log std Max           -0.22651112
Policy log std Min           -2.0573723
Z mean eval                  0.9392789
Z variance eval              0.029702146
total_rewards                [ 530.38865555 1791.365245    961.65742118 1198.43919199  613.53996382
  303.97210199 2503.62106763 2521.7401443  1078.49201175  796.3883729 ]
total_rewards_mean           1229.9604176118673
total_rewards_std            749.4543589963122
total_rewards_max            2521.740144303598
total_rewards_min            303.972101989894
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               27.96670295810327
(Previous) Eval Time (s)     15.506105312146246
Sample Time (s)              17.84178548352793
Epoch Time (s)               61.314593753777444
Total Train Time (s)         15005.942031174432
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:25:37.759182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #215 | Epoch Duration: 62.081666231155396
2020-01-11 07:25:37.759384 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #215 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9393878
Z variance train             0.029693102
KL Divergence                17.859283
KL Loss                      1.7859284
QF Loss                      1361.7339
VF Loss                      242.82521
Policy Loss                  -847.44495
Q Predictions Mean           844.21484
Q Predictions Std            170.06021
Q Predictions Max            1035.6644
Q Predictions Min            222.5475
V Predictions Mean           848.3185
V Predictions Std            170.17303
V Predictions Max            1035.3434
V Predictions Min            222.15816
Log Pis Mean                 -1.0354838
Log Pis Std                  2.6122646
Log Pis Max                  12.907438
Log Pis Min                  -6.3273125
Policy mu Mean               0.0069793668
Policy mu Std                0.55884165
Policy mu Max                2.2465382
Policy mu Min                -2.0521688
Policy log std Mean          -0.84710485
Policy log std Std           0.24445076
Policy log std Max           -0.25978154
Policy log std Min           -2.762173
Z mean eval                  0.92467225
Z variance eval              0.024528122
total_rewards                [2418.9830316  1137.74539539  768.8388211  1637.231412    495.1942294
 1376.47833956  365.90274791 2334.728472    746.59145216  708.791052  ]
total_rewards_mean           1199.0484953097534
total_rewards_std            694.6182933748029
total_rewards_max            2418.9830315969702
total_rewards_min            365.9027479077893
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               27.764920444227755
(Previous) Eval Time (s)     16.272896519862115
Sample Time (s)              17.893636564724147
Epoch Time (s)               61.93145352881402
Total Train Time (s)         15071.82841291232
Epoch                        216
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:26:43.647410 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #216 | Epoch Duration: 65.88787865638733
2020-01-11 07:26:43.647608 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92642146
Z variance train             0.024475481
KL Divergence                18.345163
KL Loss                      1.8345164
QF Loss                      1071.9058
VF Loss                      62.374092
Policy Loss                  -809.4266
Q Predictions Mean           809.1603
Q Predictions Std            215.13521
Q Predictions Max            1008.23773
Q Predictions Min            -5.658721
V Predictions Mean           810.6455
V Predictions Std            215.60829
V Predictions Max            995.2769
V Predictions Min            8.625889
Log Pis Mean                 -1.2813556
Log Pis Std                  2.3102703
Log Pis Max                  6.7366915
Log Pis Min                  -8.328246
Policy mu Mean               0.07403428
Policy mu Std                0.5401834
Policy mu Max                1.9165871
Policy mu Min                -1.9018227
Policy log std Mean          -0.8652717
Policy log std Std           0.24876621
Policy log std Max           -0.16493535
Policy log std Min           -2.1409082
Z mean eval                  0.8957459
Z variance eval              0.018374834
total_rewards                [2460.28124683 1082.09644498  931.49396531  382.5236999    66.13985549
  565.05657017  159.02066319  878.64247496 2124.11239767 1832.8710142 ]
total_rewards_mean           1048.2238332700042
total_rewards_std            790.0900633804579
total_rewards_max            2460.2812468348807
total_rewards_min            66.13985548944619
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               28.12252569012344
(Previous) Eval Time (s)     20.22901846189052
Sample Time (s)              17.89639313099906
Epoch Time (s)               66.24793728301302
Total Train Time (s)         15136.424479247537
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:27:48.247664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #217 | Epoch Duration: 64.59987902641296
2020-01-11 07:27:48.247971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.8968312
Z variance train             0.01834917
KL Divergence                18.426125
KL Loss                      1.8426125
QF Loss                      950.63074
VF Loss                      178.8994
Policy Loss                  -816.6303
Q Predictions Mean           814.5304
Q Predictions Std            193.53888
Q Predictions Max            1026.563
Q Predictions Min            207.51018
V Predictions Mean           820.20764
V Predictions Std            190.26506
V Predictions Max            1029.8453
V Predictions Min            214.78523
Log Pis Mean                 -0.96770394
Log Pis Std                  2.434821
Log Pis Max                  8.236074
Log Pis Min                  -7.3010635
Policy mu Mean               0.06371875
Policy mu Std                0.5381957
Policy mu Max                2.472687
Policy mu Min                -1.7068977
Policy log std Mean          -0.87762904
Policy log std Std           0.27998847
Policy log std Max           -0.27224267
Policy log std Min           -2.5690274
Z mean eval                  0.9060708
Z variance eval              0.021648325
total_rewards                [2222.67593643 1491.31154983 1809.54299589 2363.1495623   669.84168996
 2364.19343261  178.27542078  499.46796152  462.10593922 2454.7994412 ]
total_rewards_mean           1451.5363929723646
total_rewards_std            866.750956489586
total_rewards_max            2454.7994411977375
total_rewards_min            178.2754207816086
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               26.688435908872634
(Previous) Eval Time (s)     18.58064903272316
Sample Time (s)              17.816187313757837
Epoch Time (s)               63.08527225535363
Total Train Time (s)         15205.229816776235
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:28:57.053754 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #218 | Epoch Duration: 68.8055830001831
2020-01-11 07:28:57.053907 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9068383
Z variance train             0.021685498
KL Divergence                18.07195
KL Loss                      1.8071951
QF Loss                      494.04956
VF Loss                      405.53973
Policy Loss                  -856.5457
Q Predictions Mean           852.7414
Q Predictions Std            194.58252
Q Predictions Max            1071.4625
Q Predictions Min            -27.493866
V Predictions Mean           838.56445
V Predictions Std            191.67322
V Predictions Max            1052.7864
V Predictions Min            -11.763226
Log Pis Mean                 -1.0623286
Log Pis Std                  2.1935651
Log Pis Max                  7.2935386
Log Pis Min                  -6.5441465
Policy mu Mean               0.09327859
Policy mu Std                0.53720707
Policy mu Max                2.1664755
Policy mu Min                -1.6611142
Policy log std Mean          -0.8879358
Policy log std Std           0.24512666
Policy log std Max           -0.07132316
Policy log std Min           -2.1211004
Z mean eval                  0.91414595
Z variance eval              0.026000211
total_rewards                [ 383.17166711   27.14714813 2009.83596025  291.10781858 1511.59444373
 1402.23308006 1182.92671367 2376.39393521 2035.33190197 1398.9627284 ]
total_rewards_mean           1261.8705397113931
total_rewards_std            758.0224955994016
total_rewards_max            2376.393935214166
total_rewards_min            27.147148134258835
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               26.771545572206378
(Previous) Eval Time (s)     24.300636899191886
Sample Time (s)              18.84773922059685
Epoch Time (s)               69.91992169199511
Total Train Time (s)         15277.303198188078
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:30:09.132281 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #219 | Epoch Duration: 72.07821106910706
2020-01-11 07:30:09.132586 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9139678
Z variance train             0.025973916
KL Divergence                17.425251
KL Loss                      1.7425251
QF Loss                      2751.239
VF Loss                      78.38382
Policy Loss                  -825.1565
Q Predictions Mean           821.9261
Q Predictions Std            233.43355
Q Predictions Max            1058.0006
Q Predictions Min            5.8307695
V Predictions Mean           827.43445
V Predictions Std            229.88484
V Predictions Max            1057.906
V Predictions Min            208.62733
Log Pis Mean                 -1.0683224
Log Pis Std                  2.6198132
Log Pis Max                  10.490007
Log Pis Min                  -7.219631
Policy mu Mean               -0.012612167
Policy mu Std                0.52553385
Policy mu Max                2.1058424
Policy mu Min                -2.1959448
Policy log std Mean          -0.8637483
Policy log std Std           0.29057425
Policy log std Max           -0.16861534
Policy log std Min           -2.4656043
Z mean eval                  0.9270501
Z variance eval              0.03876052
total_rewards                [1763.8815406   132.29180934  289.16075986 2431.29644905 2493.10053618
 1361.53759402 2390.06924898   33.05706674 2282.10112811 2005.72229954]
total_rewards_mean           1518.2218432433342
total_rewards_std            953.2778250400548
total_rewards_max            2493.100536183139
total_rewards_min            33.05706674037029
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               28.653937176335603
(Previous) Eval Time (s)     26.45857953513041
Sample Time (s)              17.938303749077022
Epoch Time (s)               73.05082046054304
Total Train Time (s)         15342.067889573518
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:31:13.898211 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #220 | Epoch Duration: 64.76540756225586
2020-01-11 07:31:13.898415 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9281769
Z variance train             0.038834848
KL Divergence                17.203314
KL Loss                      1.7203314
QF Loss                      550.9136
VF Loss                      70.49881
Policy Loss                  -794.78705
Q Predictions Mean           791.4546
Q Predictions Std            237.48991
Q Predictions Max            1029.5773
Q Predictions Min            27.317963
V Predictions Mean           794.3877
V Predictions Std            234.74466
V Predictions Max            1027.4131
V Predictions Min            121.32347
Log Pis Mean                 -1.3199965
Log Pis Std                  2.7774656
Log Pis Max                  12.639208
Log Pis Min                  -8.847277
Policy mu Mean               0.04751617
Policy mu Std                0.54268557
Policy mu Max                2.0173116
Policy mu Min                -2.4470263
Policy log std Mean          -0.8635516
Policy log std Std           0.30446765
Policy log std Max           -0.16584808
Policy log std Min           -2.9638443
Z mean eval                  0.9094385
Z variance eval              0.03164023
total_rewards                [2238.52087907 2296.61835269 1228.1168675   236.7110324  2366.73228179
 1609.43693567  714.8597745   205.52707998  555.11343965 2458.3081025 ]
total_rewards_mean           1390.9944745750875
total_rewards_std            871.6354130665395
total_rewards_max            2458.3081025003835
total_rewards_min            205.5270799845606
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               27.808329130988568
(Previous) Eval Time (s)     18.172865212894976
Sample Time (s)              17.584256776608527
Epoch Time (s)               63.56545112049207
Total Train Time (s)         15406.177709036972
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:32:18.013534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #221 | Epoch Duration: 64.11495161056519
2020-01-11 07:32:18.013819 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9091095
Z variance train             0.031555254
KL Divergence                17.029755
KL Loss                      1.7029755
QF Loss                      671.249
VF Loss                      96.49398
Policy Loss                  -819.93524
Q Predictions Mean           814.40857
Q Predictions Std            210.31802
Q Predictions Max            1022.6197
Q Predictions Min            7.084676
V Predictions Mean           821.4592
V Predictions Std            208.98848
V Predictions Max            1020.3874
V Predictions Min            0.4064145
Log Pis Mean                 -0.96458167
Log Pis Std                  2.7318428
Log Pis Max                  11.568736
Log Pis Min                  -9.027813
Policy mu Mean               0.008153314
Policy mu Std                0.58859175
Policy mu Max                2.363624
Policy mu Min                -3.0434442
Policy log std Mean          -0.8632195
Policy log std Std           0.2691812
Policy log std Max           -0.01478982
Policy log std Min           -2.1242082
Z mean eval                  0.91746825
Z variance eval              0.039557457
total_rewards                [1567.28951741 1864.49127715 2399.15086927 2519.24044955 2356.26899794
 2149.42709319 1702.77152299   45.52410238  -67.44517553 2270.87478848]
total_rewards_mean           1680.7593442830864
total_rewards_std            895.5817458955551
total_rewards_max            2519.2404495464502
total_rewards_min            -67.44517552761985
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               28.235947703011334
(Previous) Eval Time (s)     18.722053282894194
Sample Time (s)              17.824303622357547
Epoch Time (s)               64.78230460826308
Total Train Time (s)         15478.359337669332
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:33:30.198334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #222 | Epoch Duration: 72.18428659439087
2020-01-11 07:33:30.198582 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9184491
Z variance train             0.039501064
KL Divergence                17.255842
KL Loss                      1.7255843
QF Loss                      576.1752
VF Loss                      341.14944
Policy Loss                  -827.44635
Q Predictions Mean           821.38403
Q Predictions Std            217.59818
Q Predictions Max            1056.7068
Q Predictions Min            21.999746
V Predictions Mean           832.6506
V Predictions Std            211.61577
V Predictions Max            1056.3374
V Predictions Min            214.95676
Log Pis Mean                 -0.87287736
Log Pis Std                  2.754186
Log Pis Max                  6.7591324
Log Pis Min                  -7.895851
Policy mu Mean               0.0061069583
Policy mu Std                0.5619878
Policy mu Max                2.895223
Policy mu Min                -1.8646858
Policy log std Mean          -0.8649121
Policy log std Std           0.28139427
Policy log std Max           -0.21048516
Policy log std Min           -2.4031897
Z mean eval                  0.9377812
Z variance eval              0.024368484
total_rewards                [ 136.56125837  217.34120147  384.01488422  234.746271   2237.09391652
  338.14167251 1235.3972916  1229.64441655  614.53607139  304.01136536]
total_rewards_mean           693.1488349001845
total_rewards_std            639.6205656116102
total_rewards_max            2237.0939165197397
total_rewards_min            136.56125837218107
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               29.412406876683235
(Previous) Eval Time (s)     26.123737435322255
Sample Time (s)              18.456664081197232
Epoch Time (s)               73.99280839320272
Total Train Time (s)         15545.289501605555
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:34:37.129848 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #223 | Epoch Duration: 66.93108749389648
2020-01-11 07:34:37.130052 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #223 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93749046
Z variance train             0.024322769
KL Divergence                17.935135
KL Loss                      1.7935135
QF Loss                      413.14978
VF Loss                      78.57461
Policy Loss                  -840.55566
Q Predictions Mean           837.4485
Q Predictions Std            210.48456
Q Predictions Max            1075.3888
Q Predictions Min            198.44936
V Predictions Mean           842.53406
V Predictions Std            209.02586
V Predictions Max            1080.1627
V Predictions Min            221.34961
Log Pis Mean                 -1.1271112
Log Pis Std                  2.6177485
Log Pis Max                  9.421644
Log Pis Min                  -9.662814
Policy mu Mean               0.01176643
Policy mu Std                0.5727739
Policy mu Max                2.2183883
Policy mu Min                -2.865027
Policy log std Mean          -0.8589066
Policy log std Std           0.24825938
Policy log std Max           -0.27027333
Policy log std Min           -1.8763418
Z mean eval                  0.9136569
Z variance eval              0.021621902
total_rewards                [1967.37334416 1635.82432602 1183.82670483  366.23769795 1374.26606089
 1610.85584899   70.85212182   69.81080101  283.771744    437.79841369]
total_rewards_mean           900.0617063363783
total_rewards_std            688.9481304440313
total_rewards_max            1967.373344162491
total_rewards_min            69.81080101483357
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               29.149119480978698
(Previous) Eval Time (s)     19.061650540214032
Sample Time (s)              18.029907611198723
Epoch Time (s)               66.24067763239145
Total Train Time (s)         15606.506213911343
Epoch                        224
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:35:38.352558 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #224 | Epoch Duration: 61.22230815887451
2020-01-11 07:35:38.352916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91369456
Z variance train             0.021674167
KL Divergence                18.814661
KL Loss                      1.8814662
QF Loss                      971.2253
VF Loss                      79.558205
Policy Loss                  -839.0036
Q Predictions Mean           837.39075
Q Predictions Std            212.42094
Q Predictions Max            1044.7859
Q Predictions Min            215.71754
V Predictions Mean           834.9824
V Predictions Std            210.67114
V Predictions Max            1036.7474
V Predictions Min            214.86694
Log Pis Mean                 -0.8280182
Log Pis Std                  2.5967412
Log Pis Max                  8.388755
Log Pis Min                  -8.087148
Policy mu Mean               0.027600214
Policy mu Std                0.57143384
Policy mu Max                2.04182
Policy mu Min                -2.2770827
Policy log std Mean          -0.8697031
Policy log std Std           0.2547841
Policy log std Max           -0.25721276
Policy log std Min           -1.856753
Z mean eval                  0.9252744
Z variance eval              0.020353753
total_rewards                [2548.44179607 2479.65712515 2617.37575136 2386.70191591  898.53074114
 2624.33201496  637.18303835  299.74755635 2327.43908462 1946.9968275 ]
total_rewards_mean           1876.640585139877
total_rewards_std            858.5193198646183
total_rewards_max            2624.3320149604087
total_rewards_min            299.74755635482654
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               28.49449265189469
(Previous) Eval Time (s)     14.042975133284926
Sample Time (s)              17.6553426948376
Epoch Time (s)               60.192810480017215
Total Train Time (s)         15675.953453442082
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:36:47.801562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #225 | Epoch Duration: 69.4483995437622
2020-01-11 07:36:47.801810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92705756
Z variance train             0.020275984
KL Divergence                18.776077
KL Loss                      1.8776077
QF Loss                      1619.238
VF Loss                      290.6661
Policy Loss                  -854.2941
Q Predictions Mean           847.57947
Q Predictions Std            206.76564
Q Predictions Max            1066.149
Q Predictions Min            182.9307
V Predictions Mean           840.65796
V Predictions Std            204.25488
V Predictions Max            1059.8483
V Predictions Min            188.4418
Log Pis Mean                 -0.57301825
Log Pis Std                  2.6486452
Log Pis Max                  13.022369
Log Pis Min                  -8.275018
Policy mu Mean               -0.01336365
Policy mu Std                0.5733943
Policy mu Max                2.1299152
Policy mu Min                -2.025824
Policy log std Mean          -0.8901856
Policy log std Std           0.26033682
Policy log std Max           -0.15134126
Policy log std Min           -2.1268198
Z mean eval                  0.981654
Z variance eval              0.023398394
total_rewards                [2053.06612156  237.91860566  901.31203928 -115.88443666 2559.34473596
  532.7291043   392.17336859 2434.59525874 2401.69982764  757.83325865]
total_rewards_mean           1215.4787883728434
total_rewards_std            978.8342361399658
total_rewards_max            2559.3447359629267
total_rewards_min            -115.884436662653
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               30.020164217799902
(Previous) Eval Time (s)     23.29830720881
Sample Time (s)              17.94073812616989
Epoch Time (s)               71.2592095527798
Total Train Time (s)         15748.43804164324
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:38:00.287572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #226 | Epoch Duration: 72.48560118675232
2020-01-11 07:38:00.287755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98162186
Z variance train             0.023420507
KL Divergence                18.673647
KL Loss                      1.8673648
QF Loss                      450.99048
VF Loss                      102.48361
Policy Loss                  -842.3549
Q Predictions Mean           841.5033
Q Predictions Std            225.27696
Q Predictions Max            1063.1108
Q Predictions Min            219.432
V Predictions Mean           848.22424
V Predictions Std            224.8701
V Predictions Max            1063.0592
V Predictions Min            236.44518
Log Pis Mean                 -1.5547327
Log Pis Std                  2.4192765
Log Pis Max                  8.002946
Log Pis Min                  -7.2453756
Policy mu Mean               0.061014
Policy mu Std                0.5286211
Policy mu Max                1.7970911
Policy mu Min                -2.6620095
Policy log std Mean          -0.84574693
Policy log std Std           0.23530088
Policy log std Max           -0.2513343
Policy log std Min           -2.0481844
Z mean eval                  0.92845076
Z variance eval              0.03262732
total_rewards                [  47.19171256 1290.41563226 1834.51189383  673.45081675  338.22792081
 1904.51635267  351.93395575 2391.70152913  121.2325556    92.33261909]
total_rewards_mean           904.5514988460945
total_rewards_std            831.4524842108991
total_rewards_max            2391.701529130529
total_rewards_min            47.19171256383579
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               29.062598083168268
(Previous) Eval Time (s)     24.524388436693698
Sample Time (s)              18.643157300539315
Epoch Time (s)               72.23014382040128
Total Train Time (s)         15815.686804668047
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:39:07.542239 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #227 | Epoch Duration: 67.25430989265442
2020-01-11 07:39:07.542484 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9250368
Z variance train             0.032602843
KL Divergence                18.034376
KL Loss                      1.8034376
QF Loss                      2709.16
VF Loss                      250.66768
Policy Loss                  -842.9089
Q Predictions Mean           839.8943
Q Predictions Std            227.44241
Q Predictions Max            1079.2368
Q Predictions Min            175.62207
V Predictions Mean           841.7057
V Predictions Std            226.13388
V Predictions Max            1077.7185
V Predictions Min            168.42834
Log Pis Mean                 -0.8948122
Log Pis Std                  2.5300004
Log Pis Max                  10.768778
Log Pis Min                  -7.7116895
Policy mu Mean               0.0028438005
Policy mu Std                0.5550159
Policy mu Max                2.8535564
Policy mu Min                -2.002683
Policy log std Mean          -0.89320934
Policy log std Std           0.28551954
Policy log std Max           -0.29363543
Policy log std Min           -2.692379
Z mean eval                  0.91205835
Z variance eval              0.022687811
total_rewards                [2379.94772056 1205.57668326 2354.02200233 2478.54120502  610.08127508
 2356.03049641 2329.7098148  2755.0543595   133.40943484 2619.28443759]
total_rewards_mean           1922.1657429387888
total_rewards_std            876.0331729152709
total_rewards_max            2755.0543595024074
total_rewards_min            133.40943483973234
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               27.832549849990755
(Previous) Eval Time (s)     19.548228680621833
Sample Time (s)              17.930450518149883
Epoch Time (s)               65.31122904876247
Total Train Time (s)         15886.237439440563
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:40:18.094293 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #228 | Epoch Duration: 70.5516152381897
2020-01-11 07:40:18.094506 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91019475
Z variance train             0.022694202
KL Divergence                18.06128
KL Loss                      1.8061279
QF Loss                      2013.354
VF Loss                      248.75926
Policy Loss                  -858.71405
Q Predictions Mean           856.98816
Q Predictions Std            206.52283
Q Predictions Max            1072.3768
Q Predictions Min            153.83926
V Predictions Mean           867.09735
V Predictions Std            204.93277
V Predictions Max            1074.5107
V Predictions Min            29.666124
Log Pis Mean                 -0.7039119
Log Pis Std                  2.6992962
Log Pis Max                  12.091978
Log Pis Min                  -10.46785
Policy mu Mean               0.001063617
Policy mu Std                0.5560648
Policy mu Max                2.025539
Policy mu Min                -3.1367114
Policy log std Mean          -0.9100698
Policy log std Std           0.25699154
Policy log std Max           -0.16548389
Policy log std Min           -2.0650413
Z mean eval                  0.9203684
Z variance eval              0.027721401
total_rewards                [2562.63906623 1033.13131059  538.06881697 1588.82742082 2351.41257206
 2658.92404091 2660.53614542 2290.12675259 1239.23996176  556.75176959]
total_rewards_mean           1747.965785694066
total_rewards_std            816.2331476492619
total_rewards_max            2660.536145422041
total_rewards_min            538.0688169710055
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               29.800752037670463
(Previous) Eval Time (s)     24.7883133739233
Sample Time (s)              17.509353656787425
Epoch Time (s)               72.09841906838119
Total Train Time (s)         15952.60121538397
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:41:24.463964 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #229 | Epoch Duration: 66.36925101280212
2020-01-11 07:41:24.464256 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91989976
Z variance train             0.027716005
KL Divergence                18.033333
KL Loss                      1.8033333
QF Loss                      816.5305
VF Loss                      137.99306
Policy Loss                  -898.3069
Q Predictions Mean           897.17993
Q Predictions Std            169.05388
Q Predictions Max            1105.1049
Q Predictions Min            215.50974
V Predictions Mean           890.7461
V Predictions Std            167.625
V Predictions Max            1096.3989
V Predictions Min            214.943
Log Pis Mean                 -0.95398754
Log Pis Std                  2.6050642
Log Pis Max                  5.406732
Log Pis Min                  -9.362825
Policy mu Mean               -0.021483228
Policy mu Std                0.5608888
Policy mu Max                1.7009593
Policy mu Min                -1.7945235
Policy log std Mean          -0.88994515
Policy log std Std           0.23671593
Policy log std Max           -0.27770928
Policy log std Min           -1.801943
Z mean eval                  0.923089
Z variance eval              0.033486355
total_rewards                [2456.52748702 1592.00973415 2599.43455085 2440.37147677 2232.23413693
   74.21418933 2440.13234233 2494.39399912  138.30978998  309.95320689]
total_rewards_mean           1677.7580913358192
total_rewards_std            1020.4213803039936
total_rewards_max            2599.434550853751
total_rewards_min            74.21418933244863
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               28.170271749142557
(Previous) Eval Time (s)     19.05885041691363
Sample Time (s)              19.11378706758842
Epoch Time (s)               66.3429092336446
Total Train Time (s)         16019.805853934027
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:42:31.669146 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #230 | Epoch Duration: 67.20465302467346
2020-01-11 07:42:31.669338 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #230 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92314684
Z variance train             0.03350187
KL Divergence                18.132278
KL Loss                      1.8132279
QF Loss                      2694.8228
VF Loss                      151.33786
Policy Loss                  -850.9246
Q Predictions Mean           846.3528
Q Predictions Std            207.17007
Q Predictions Max            1063.4609
Q Predictions Min            93.68702
V Predictions Mean           852.8944
V Predictions Std            203.22891
V Predictions Max            1067.0903
V Predictions Min            212.91208
Log Pis Mean                 -1.0755652
Log Pis Std                  2.793683
Log Pis Max                  11.046738
Log Pis Min                  -12.295298
Policy mu Mean               0.047238827
Policy mu Std                0.5618612
Policy mu Max                2.0302832
Policy mu Min                -2.4063277
Policy log std Mean          -0.87856567
Policy log std Std           0.26683146
Policy log std Max           -0.21510988
Policy log std Min           -2.3919735
Z mean eval                  0.94813406
Z variance eval              0.025260508
total_rewards                [2453.07416568 2533.17967925 2568.70007881 2116.60023387 2116.19402886
 1259.70959882 2047.85862502 2140.52883897 2499.68365731 2715.6911649 ]
total_rewards_mean           2245.1220071499065
total_rewards_std            396.38258212753834
total_rewards_max            2715.6911649023655
total_rewards_min            1259.7095988244673
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               27.31170838791877
(Previous) Eval Time (s)     19.920290583744645
Sample Time (s)              18.586598872672766
Epoch Time (s)               65.81859784433618
Total Train Time (s)         16090.204400309362
Epoch                        231
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:43:42.071330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #231 | Epoch Duration: 70.4018383026123
2020-01-11 07:43:42.071551 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9487171
Z variance train             0.025373623
KL Divergence                19.433857
KL Loss                      1.9433857
QF Loss                      561.36487
VF Loss                      193.94096
Policy Loss                  -855.43463
Q Predictions Mean           854.9358
Q Predictions Std            213.34668
Q Predictions Max            1075.6041
Q Predictions Min            221.63835
V Predictions Mean           860.71106
V Predictions Std            213.40805
V Predictions Max            1071.6904
V Predictions Min            216.09567
Log Pis Mean                 -0.79476994
Log Pis Std                  2.4518855
Log Pis Max                  8.317295
Log Pis Min                  -9.8723545
Policy mu Mean               0.05016307
Policy mu Std                0.54279256
Policy mu Max                1.9017622
Policy mu Min                -2.3266168
Policy log std Mean          -0.90368354
Policy log std Std           0.25619972
Policy log std Max           -0.11162126
Policy log std Min           -2.153827
Z mean eval                  0.94387037
Z variance eval              0.027456308
total_rewards                [ 466.53516618  110.21934179 2504.84609365 2460.75030651 2090.31579784
 2196.97435727 2537.48825308 2371.4159792  2509.175921   2517.28193208]
total_rewards_mean           1976.500314860122
total_rewards_std            859.3639166427015
total_rewards_max            2537.4882530795185
total_rewards_min            110.21934178950758
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               29.792110482230783
(Previous) Eval Time (s)     24.503184537403286
Sample Time (s)              19.536089454311877
Epoch Time (s)               73.83138447394595
Total Train Time (s)         16163.817209887784
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:44:55.685616 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #232 | Epoch Duration: 73.61390423774719
2020-01-11 07:44:55.685771 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94447595
Z variance train             0.027416756
KL Divergence                18.951515
KL Loss                      1.8951515
QF Loss                      586.92285
VF Loss                      280.0288
Policy Loss                  -876.40826
Q Predictions Mean           874.82983
Q Predictions Std            197.70332
Q Predictions Max            1094.0547
Q Predictions Min            210.69334
V Predictions Mean           890.0152
V Predictions Std            196.78296
V Predictions Max            1110.0778
V Predictions Min            223.92195
Log Pis Mean                 -1.1550047
Log Pis Std                  2.3625703
Log Pis Max                  5.020261
Log Pis Min                  -9.083185
Policy mu Mean               0.05947338
Policy mu Std                0.56150395
Policy mu Max                1.8174933
Policy mu Min                -1.7410431
Policy log std Mean          -0.88496923
Policy log std Std           0.23535351
Policy log std Max           -0.27407044
Policy log std Min           -1.8603656
Z mean eval                  0.9547799
Z variance eval              0.03211764
total_rewards                [1018.20922969 2106.54541255  183.16494059 2351.09909373  143.52272667
 2151.76152791  864.7356517   958.23793809 1419.43744705  209.71639787]
total_rewards_mean           1140.643036583699
total_rewards_std            800.017647208707
total_rewards_max            2351.0990937270217
total_rewards_min            143.52272666981648
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               29.919786021113396
(Previous) Eval Time (s)     24.28535736259073
Sample Time (s)              18.607818891759962
Epoch Time (s)               72.81296227546409
Total Train Time (s)         16233.780147992074
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:46:05.652924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #233 | Epoch Duration: 69.96701908111572
2020-01-11 07:46:05.653128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95348614
Z variance train             0.03213029
KL Divergence                18.658949
KL Loss                      1.8658949
QF Loss                      693.5288
VF Loss                      83.65359
Policy Loss                  -872.024
Q Predictions Mean           870.979
Q Predictions Std            234.94759
Q Predictions Max            1101.5432
Q Predictions Min            209.16667
V Predictions Mean           871.2866
V Predictions Std            234.02538
V Predictions Max            1090.5815
V Predictions Min            225.36995
Log Pis Mean                 -0.9741608
Log Pis Std                  2.34593
Log Pis Max                  5.4712353
Log Pis Min                  -8.617279
Policy mu Mean               0.057672527
Policy mu Std                0.5609868
Policy mu Max                2.1191506
Policy mu Min                -2.37908
Policy log std Mean          -0.8669294
Policy log std Std           0.26083255
Policy log std Max           -0.20655382
Policy log std Min           -2.1280048
Z mean eval                  0.92606336
Z variance eval              0.020759046
total_rewards                [2449.25149704   67.48646409  168.66940601 2391.6448842  2341.50170104
  681.62137164 2464.33175506 2633.35029788 2581.13511224  536.76554066]
total_rewards_mean           1631.5758029862616
total_rewards_std            1050.5467311939788
total_rewards_max            2633.350297875907
total_rewards_min            67.48646408668391
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               28.53042808594182
(Previous) Eval Time (s)     21.43909792881459
Sample Time (s)              17.925816202070564
Epoch Time (s)               67.89534221682698
Total Train Time (s)         16300.515857206192
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:47:12.391859 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #234 | Epoch Duration: 66.73852896690369
2020-01-11 07:47:12.392107 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9226878
Z variance train             0.020677451
KL Divergence                19.307821
KL Loss                      1.9307822
QF Loss                      617.7543
VF Loss                      140.99167
Policy Loss                  -834.87604
Q Predictions Mean           830.46606
Q Predictions Std            246.76636
Q Predictions Max            1071.7705
Q Predictions Min            -42.778374
V Predictions Mean           833.8989
V Predictions Std            244.87611
V Predictions Max            1080.8641
V Predictions Min            21.176619
Log Pis Mean                 -1.0376773
Log Pis Std                  2.8892283
Log Pis Max                  12.868138
Log Pis Min                  -8.117537
Policy mu Mean               0.011214128
Policy mu Std                0.55234975
Policy mu Max                1.9714632
Policy mu Min                -2.7544994
Policy log std Mean          -0.8731276
Policy log std Std           0.30051216
Policy log std Max           -0.24227345
Policy log std Min           -2.9539776
Z mean eval                  0.92460716
Z variance eval              0.028665274
total_rewards                [2338.97943326 2559.17924558 2362.71230621 2512.71519683 2625.63051348
 2330.2878741  2658.9211787  2480.04116178 2564.4033351   211.48153675]
total_rewards_mean           2264.435178178156
total_rewards_std            693.1980679705587
total_rewards_max            2658.921178699514
total_rewards_min            211.48153675085288
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               29.92368688667193
(Previous) Eval Time (s)     20.281927614938468
Sample Time (s)              19.082693099975586
Epoch Time (s)               69.28830760158598
Total Train Time (s)         16376.853166677058
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:28.730723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #235 | Epoch Duration: 76.3384051322937
2020-01-11 07:48:28.730936 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92395514
Z variance train             0.028751556
KL Divergence                18.1916
KL Loss                      1.8191601
QF Loss                      805.85266
VF Loss                      142.9092
Policy Loss                  -875.96356
Q Predictions Mean           875.1934
Q Predictions Std            218.02007
Q Predictions Max            1087.4946
Q Predictions Min            16.324814
V Predictions Mean           876.0127
V Predictions Std            217.48543
V Predictions Max            1083.6952
V Predictions Min            40.549244
Log Pis Mean                 -0.9335752
Log Pis Std                  2.6137292
Log Pis Max                  10.710255
Log Pis Min                  -9.163162
Policy mu Mean               -0.0086597325
Policy mu Std                0.5446572
Policy mu Max                1.7443776
Policy mu Min                -3.5917652
Policy log std Mean          -0.9080618
Policy log std Std           0.25775385
Policy log std Max           -0.25101638
Policy log std Min           -2.4548185
Z mean eval                  0.9175102
Z variance eval              0.026960135
total_rewards                [2393.69915036 1432.13798542 2475.53036218 2331.12472814 2364.22929179
 2493.80751692  365.89039365 2403.68342288 1720.86917368  715.78252345]
total_rewards_mean           1869.6754548454464
total_rewards_std            747.0144594557341
total_rewards_max            2493.8075169201074
total_rewards_min            365.89039364873554
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               29.768539554905146
(Previous) Eval Time (s)     27.33171678520739
Sample Time (s)              18.039172504097223
Epoch Time (s)               75.13942884420976
Total Train Time (s)         16451.15907862829
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:49:43.039534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #236 | Epoch Duration: 74.30843305587769
2020-01-11 07:49:43.039705 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91694593
Z variance train             0.026947614
KL Divergence                18.094028
KL Loss                      1.8094028
QF Loss                      3389.8027
VF Loss                      147.08281
Policy Loss                  -847.45026
Q Predictions Mean           847.6128
Q Predictions Std            227.63483
Q Predictions Max            1082.5323
Q Predictions Min            166.2647
V Predictions Mean           848.9758
V Predictions Std            228.82222
V Predictions Max            1090.2217
V Predictions Min            95.570755
Log Pis Mean                 -1.0085747
Log Pis Std                  2.6481757
Log Pis Max                  11.157551
Log Pis Min                  -9.709049
Policy mu Mean               0.057696484
Policy mu Std                0.55623215
Policy mu Max                2.2823532
Policy mu Min                -2.8908389
Policy log std Mean          -0.8784978
Policy log std Std           0.26841566
Policy log std Max           -0.19126701
Policy log std Min           -2.5670805
Z mean eval                  0.9167549
Z variance eval              0.013845904
total_rewards                [ -27.09079031 2479.88172784 1243.16762704 1497.46654987 2491.51773265
  812.25154158  816.73318426  466.07435819  396.00684431  227.89608833]
total_rewards_mean           1040.3904863746304
total_rewards_std            841.1150396242894
total_rewards_max            2491.5177326485286
total_rewards_min            -27.090790306539375
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               30.76295567676425
(Previous) Eval Time (s)     26.500440466683358
Sample Time (s)              17.964437508024275
Epoch Time (s)               75.22783365147188
Total Train Time (s)         16515.87262905063
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:50:47.760826 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #237 | Epoch Duration: 64.72094631195068
2020-01-11 07:50:47.761128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91776884
Z variance train             0.013848138
KL Divergence                19.020594
KL Loss                      1.9020594
QF Loss                      2354.4631
VF Loss                      136.37617
Policy Loss                  -871.6082
Q Predictions Mean           871.38477
Q Predictions Std            192.63985
Q Predictions Max            1079.733
Q Predictions Min            226.7762
V Predictions Mean           868.6595
V Predictions Std            190.83728
V Predictions Max            1065.7261
V Predictions Min            234.14694
Log Pis Mean                 -0.6515087
Log Pis Std                  2.566628
Log Pis Max                  6.867543
Log Pis Min                  -8.52327
Policy mu Mean               0.036140583
Policy mu Std                0.56612414
Policy mu Max                2.1106708
Policy mu Min                -2.0340884
Policy log std Mean          -0.907969
Policy log std Std           0.25834283
Policy log std Max           -0.26996148
Policy log std Min           -2.185688
Z mean eval                  0.92575055
Z variance eval              0.020540796
total_rewards                [2423.29098922 1537.80799446 2385.87011613 2079.19721458 2525.85224761
 2321.36651056 1704.23818041  240.38452368   59.13322501 2582.88420723]
total_rewards_mean           1786.0025208887237
total_rewards_std            880.9229241163138
total_rewards_max            2582.884207228649
total_rewards_min            59.13322501232846
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               29.242495893035084
(Previous) Eval Time (s)     15.993195435963571
Sample Time (s)              18.60471291327849
Epoch Time (s)               63.840404242277145
Total Train Time (s)         16586.165507470258
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:51:58.052310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #238 | Epoch Duration: 70.29093194007874
2020-01-11 07:51:58.052508 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9259178
Z variance train             0.020543773
KL Divergence                18.582336
KL Loss                      1.8582337
QF Loss                      776.50146
VF Loss                      59.18593
Policy Loss                  -862.619
Q Predictions Mean           860.4193
Q Predictions Std            235.78293
Q Predictions Max            1082.0684
Q Predictions Min            -53.02841
V Predictions Mean           866.4869
V Predictions Std            233.88759
V Predictions Max            1089.933
V Predictions Min            24.761454
Log Pis Mean                 -1.2439322
Log Pis Std                  2.3841915
Log Pis Max                  6.399221
Log Pis Min                  -9.462927
Policy mu Mean               0.049122505
Policy mu Std                0.5589335
Policy mu Max                1.9004985
Policy mu Min                -2.2823858
Policy log std Mean          -0.8565633
Policy log std Std           0.23408434
Policy log std Max           -0.21092623
Policy log std Min           -1.8323127
Z mean eval                  0.9141979
Z variance eval              0.018110137
total_rewards                [ -25.8934468  1907.39636297  873.70382012 1712.87705017 1438.04847718
 2471.90848957 2402.90174094 2281.87302207 2543.08409753 2260.31796689]
total_rewards_mean           1786.6217580631135
total_rewards_std            784.313378313766
total_rewards_max            2543.0840975262836
total_rewards_min            -25.89344680020273
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               27.56171403825283
(Previous) Eval Time (s)     22.443370413035154
Sample Time (s)              17.96428428031504
Epoch Time (s)               67.96936873160303
Total Train Time (s)         16655.156342037953
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:07.049342 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #239 | Epoch Duration: 68.99666571617126
2020-01-11 07:53:07.049617 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9161021
Z variance train             0.018077785
KL Divergence                18.822546
KL Loss                      1.8822546
QF Loss                      675.7075
VF Loss                      354.84177
Policy Loss                  -865.1475
Q Predictions Mean           861.61554
Q Predictions Std            228.33687
Q Predictions Max            1065.7267
Q Predictions Min            148.26912
V Predictions Mean           854.80054
V Predictions Std            225.15446
V Predictions Max            1060.0963
V Predictions Min            192.72966
Log Pis Mean                 -0.79853517
Log Pis Std                  2.2763014
Log Pis Max                  7.8523026
Log Pis Min                  -6.0916386
Policy mu Mean               -0.028463943
Policy mu Std                0.5614306
Policy mu Max                2.6091104
Policy mu Min                -2.3750253
Policy log std Mean          -0.8858993
Policy log std Std           0.2552359
Policy log std Max           -0.27007908
Policy log std Min           -1.9561714
Z mean eval                  0.93567026
Z variance eval              0.024351873
total_rewards                [2317.9594825  2328.14023434 2473.93112532 1917.9322927  2556.06769913
 2379.13836659 2561.7016233  1119.67619625  475.15381843 1471.71362076]
total_rewards_mean           1960.1414459312896
total_rewards_std            676.159101008116
total_rewards_max            2561.7016232989386
total_rewards_min            475.1538184275004
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               28.466538733337075
(Previous) Eval Time (s)     23.470369229093194
Sample Time (s)              18.723596394993365
Epoch Time (s)               70.66050435742363
Total Train Time (s)         16729.246614432894
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:54:21.139962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #240 | Epoch Duration: 74.09014058113098
2020-01-11 07:54:21.140129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #240 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.934855
Z variance train             0.024463544
KL Divergence                18.718185
KL Loss                      1.8718185
QF Loss                      719.3566
VF Loss                      108.4
Policy Loss                  -886.5573
Q Predictions Mean           887.4689
Q Predictions Std            212.87627
Q Predictions Max            1089.9382
Q Predictions Min            216.155
V Predictions Mean           881.7864
V Predictions Std            210.68626
V Predictions Max            1084.747
V Predictions Min            214.82474
Log Pis Mean                 -0.76414543
Log Pis Std                  2.4371269
Log Pis Max                  6.7055864
Log Pis Min                  -6.5195947
Policy mu Mean               0.026045006
Policy mu Std                0.57097477
Policy mu Max                2.386206
Policy mu Min                -2.0089734
Policy log std Mean          -0.89183164
Policy log std Std           0.26828775
Policy log std Max           -0.28032345
Policy log std Min           -2.510981
Z mean eval                  0.96724796
Z variance eval              0.019093374
total_rewards                [1429.50274073 2402.22208869 1339.93249324 2419.99133563 2199.3008643
 2592.07530796 1439.61326462 1521.7208105  2662.26918696 1478.68896276]
total_rewards_mean           1948.531705539177
total_rewards_std            521.178056738443
total_rewards_max            2662.2691869586383
total_rewards_min            1339.9324932398656
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               30.351242681965232
(Previous) Eval Time (s)     26.899706471245736
Sample Time (s)              18.808598613832146
Epoch Time (s)               76.05954776704311
Total Train Time (s)         16804.027149961796
Epoch                        241
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:55:35.928683 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #241 | Epoch Duration: 74.78837871551514
2020-01-11 07:55:35.929007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9678152
Z variance train             0.019130567
KL Divergence                19.18555
KL Loss                      1.9185551
QF Loss                      856.3222
VF Loss                      146.04062
Policy Loss                  -859.6999
Q Predictions Mean           857.29736
Q Predictions Std            232.89159
Q Predictions Max            1054.3989
Q Predictions Min            216.98288
V Predictions Mean           862.05273
V Predictions Std            234.24654
V Predictions Max            1050.5956
V Predictions Min            214.35141
Log Pis Mean                 -1.1726682
Log Pis Std                  2.4236436
Log Pis Max                  9.41299
Log Pis Min                  -8.184031
Policy mu Mean               -0.065621495
Policy mu Std                0.5436402
Policy mu Max                2.1874952
Policy mu Min                -2.0277183
Policy log std Mean          -0.87105006
Policy log std Std           0.27296472
Policy log std Max           -0.22068033
Policy log std Min           -1.8953905
Z mean eval                  0.93447447
Z variance eval              0.024046373
total_rewards                [2682.51174065 1623.88559441 2666.73474716 1696.08418686 1129.45642895
 2068.32831666 2622.08425534 2883.42416399  496.10377874 2612.50866055]
total_rewards_mean           2048.112187330062
total_rewards_std            754.1783069564478
total_rewards_max            2883.424163988776
total_rewards_min            496.10377874155336
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               29.60092037776485
(Previous) Eval Time (s)     25.62809456884861
Sample Time (s)              19.113515711855143
Epoch Time (s)               74.3425306584686
Total Train Time (s)         16876.760841942392
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:48.666376 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #242 | Epoch Duration: 72.7371153831482
2020-01-11 07:56:48.666633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #242 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93588513
Z variance train             0.024099652
KL Divergence                19.369547
KL Loss                      1.9369547
QF Loss                      458.3742
VF Loss                      122.97567
Policy Loss                  -882.27405
Q Predictions Mean           880.3296
Q Predictions Std            208.96896
Q Predictions Max            1078.0721
Q Predictions Min            100.2208
V Predictions Mean           882.5998
V Predictions Std            206.72406
V Predictions Max            1074.4629
V Predictions Min            164.13931
Log Pis Mean                 -0.659799
Log Pis Std                  2.5024707
Log Pis Max                  8.661798
Log Pis Min                  -7.843589
Policy mu Mean               -0.01851742
Policy mu Std                0.5387945
Policy mu Max                2.0275943
Policy mu Min                -2.0359364
Policy log std Mean          -0.93394405
Policy log std Std           0.28805912
Policy log std Max           -0.22492546
Policy log std Min           -2.6974554
Z mean eval                  0.91299057
Z variance eval              0.017941229
total_rewards                [ 997.46554713  428.39627568 2355.81034688 2081.48687546  789.9118435
  416.70307239  880.20476917 1186.49874649 1041.93054144 2467.47164141]
total_rewards_mean           1264.587965955026
total_rewards_std            722.7199381503664
total_rewards_max            2467.471641409008
total_rewards_min            416.70307238584303
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               29.8542733611539
(Previous) Eval Time (s)     24.022348961792886
Sample Time (s)              18.108993301633745
Epoch Time (s)               71.98561562458053
Total Train Time (s)         16944.395703725517
Epoch                        243
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:57:56.306155 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #243 | Epoch Duration: 67.6391909122467
2020-01-11 07:57:56.306565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.91547954
Z variance train             0.017938029
KL Divergence                19.783312
KL Loss                      1.9783312
QF Loss                      442.56415
VF Loss                      213.9078
Policy Loss                  -876.2862
Q Predictions Mean           870.90076
Q Predictions Std            233.20142
Q Predictions Max            1093.7684
Q Predictions Min            -89.513336
V Predictions Mean           869.6437
V Predictions Std            229.92938
V Predictions Max            1075.3048
V Predictions Min            -9.078875
Log Pis Mean                 -1.2117219
Log Pis Std                  2.4132934
Log Pis Max                  5.6706796
Log Pis Min                  -8.137093
Policy mu Mean               0.07374394
Policy mu Std                0.52144414
Policy mu Max                1.8923658
Policy mu Min                -1.6465585
Policy log std Mean          -0.888872
Policy log std Std           0.26287088
Policy log std Max           -0.18041608
Policy log std Min           -1.9675432
Z mean eval                  0.9361016
Z variance eval              0.01661494
total_rewards                [2761.51090296 1580.17854103  142.44135687 1563.32921392 2307.94585312
  869.09087042 2462.83438896 2745.02857896 2669.82633776 1189.0748407 ]
total_rewards_mean           1829.1260884716182
total_rewards_std            857.596161607723
total_rewards_max            2761.5109029604255
total_rewards_min            142.4413568711096
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               27.074757282156497
(Previous) Eval Time (s)     19.675610238220543
Sample Time (s)              18.908982569817454
Epoch Time (s)               65.6593500901945
Total Train Time (s)         17014.89533511363
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:06.807289 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #244 | Epoch Duration: 70.50050592422485
2020-01-11 07:59:06.807483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93390894
Z variance train             0.016607486
KL Divergence                20.40672
KL Loss                      2.040672
QF Loss                      824.6384
VF Loss                      102.19244
Policy Loss                  -893.64636
Q Predictions Mean           892.29694
Q Predictions Std            228.65637
Q Predictions Max            1084.3021
Q Predictions Min            72.19458
V Predictions Mean           897.823
V Predictions Std            230.8403
V Predictions Max            1080.9226
V Predictions Min            0.55825555
Log Pis Mean                 -0.8780793
Log Pis Std                  2.656591
Log Pis Max                  13.503624
Log Pis Min                  -6.844331
Policy mu Mean               -0.019897513
Policy mu Std                0.5864003
Policy mu Max                2.36396
Policy mu Min                -2.143478
Policy log std Mean          -0.8732109
Policy log std Std           0.26942235
Policy log std Max           0.55272704
Policy log std Min           -1.9617503
Z mean eval                  0.9474513
Z variance eval              0.027131319
total_rewards                [ 348.00341875 2005.84685497  104.78258074  488.47531104 1328.04401988
 2556.40203341 2371.63879679   98.45415322 2428.87786861 2686.0906575 ]
total_rewards_mean           1441.6615694907637
total_rewards_std            1032.376941485801
total_rewards_max            2686.090657501207
total_rewards_min            98.45415322212813
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               31.09782271878794
(Previous) Eval Time (s)     24.51645251410082
Sample Time (s)              17.590647883713245
Epoch Time (s)               73.204923116602
Total Train Time (s)         17082.863311520778
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:00:14.777179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #245 | Epoch Duration: 67.96950650215149
2020-01-11 08:00:14.777444 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9495875
Z variance train             0.02734389
KL Divergence                18.446524
KL Loss                      1.8446524
QF Loss                      900.0399
VF Loss                      368.12128
Policy Loss                  -872.7542
Q Predictions Mean           871.78986
Q Predictions Std            238.32224
Q Predictions Max            1089.475
Q Predictions Min            213.83105
V Predictions Mean           886.8794
V Predictions Std            238.74405
V Predictions Max            1100.5553
V Predictions Min            213.4425
Log Pis Mean                 -0.9878991
Log Pis Std                  2.6940753
Log Pis Max                  7.7957497
Log Pis Min                  -8.419519
Policy mu Mean               0.006849708
Policy mu Std                0.56122893
Policy mu Max                1.7756138
Policy mu Min                -2.8177884
Policy log std Mean          -0.8843515
Policy log std Std           0.2681175
Policy log std Max           -0.21539813
Policy log std Min           -2.2024732
Z mean eval                  0.9252349
Z variance eval              0.03635185
total_rewards                [ -33.20314946 2132.17843261 2525.22171065 2490.80929745 2713.21927639
  641.18978179 2669.07704896 2491.0188345  1502.78370664 2464.27231353]
total_rewards_mean           1959.6567253079454
total_rewards_std            903.2411284265617
total_rewards_max            2713.2192763943603
total_rewards_min            -33.20314945938235
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               29.071815295144916
(Previous) Eval Time (s)     19.280711516272277
Sample Time (s)              18.308447387069464
Epoch Time (s)               66.66097419848666
Total Train Time (s)         17156.531640710775
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:28.447073 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #246 | Epoch Duration: 73.66947412490845
2020-01-11 08:01:28.447273 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92302144
Z variance train             0.036803864
KL Divergence                17.063265
KL Loss                      1.7063265
QF Loss                      691.8236
VF Loss                      230.6611
Policy Loss                  -893.92175
Q Predictions Mean           889.3595
Q Predictions Std            234.98196
Q Predictions Max            1120.3484
Q Predictions Min            22.20405
V Predictions Mean           884.6437
V Predictions Std            233.42838
V Predictions Max            1095.4895
V Predictions Min            13.525678
Log Pis Mean                 -1.0957136
Log Pis Std                  2.5449362
Log Pis Max                  8.295882
Log Pis Min                  -9.225952
Policy mu Mean               0.021498784
Policy mu Std                0.51721776
Policy mu Max                1.9084185
Policy mu Min                -2.0526884
Policy log std Mean          -0.90725356
Policy log std Std           0.29540712
Policy log std Max           -0.2226212
Policy log std Min           -2.5323744
Z mean eval                  0.92721385
Z variance eval              0.027410096
total_rewards                [2534.79071062 2421.03092273 1503.72348089 1635.00775249  616.13582041
  608.73404861 2811.90109014  627.3955128  1324.15952151 2861.48578586]
total_rewards_mean           1694.436464607136
total_rewards_std            866.1369816419368
total_rewards_max            2861.4857858553237
total_rewards_min            608.7340486136297
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               28.24726201593876
(Previous) Eval Time (s)     26.288922999054193
Sample Time (s)              17.74338366277516
Epoch Time (s)               72.27956867776811
Total Train Time (s)         17225.98938885238
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:02:37.908133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #247 | Epoch Duration: 69.46070528030396
2020-01-11 08:02:37.908328 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9247314
Z variance train             0.027466753
KL Divergence                17.402533
KL Loss                      1.7402533
QF Loss                      887.06024
VF Loss                      89.31756
Policy Loss                  -911.62695
Q Predictions Mean           908.6611
Q Predictions Std            216.20866
Q Predictions Max            1105.6494
Q Predictions Min            -24.318949
V Predictions Mean           908.3584
V Predictions Std            215.04579
V Predictions Max            1117.8622
V Predictions Min            58.205643
Log Pis Mean                 -0.9198636
Log Pis Std                  2.4527397
Log Pis Max                  6.6362877
Log Pis Min                  -7.6783214
Policy mu Mean               0.044838578
Policy mu Std                0.56051755
Policy mu Max                2.6646624
Policy mu Min                -2.1802428
Policy log std Mean          -0.9009171
Policy log std Std           0.25781897
Policy log std Max           -0.12001526
Policy log std Min           -2.1470733
Z mean eval                  0.93986005
Z variance eval              0.024759984
total_rewards                [2444.86364977 1223.46498136 2631.28258415 1870.81879934 2518.34443334
  380.66763683  542.65689774 -104.14213498   70.80832693  368.42775681]
total_rewards_mean           1194.7192931291218
total_rewards_std            1027.488949293791
total_rewards_max            2631.282584149887
total_rewards_min            -104.14213497736563
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               29.67462343722582
(Previous) Eval Time (s)     23.469773364253342
Sample Time (s)              18.401101747062057
Epoch Time (s)               71.54549854854122
Total Train Time (s)         17289.95708027389
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:03:41.880649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #248 | Epoch Duration: 63.97214603424072
2020-01-11 08:03:41.880910 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9365717
Z variance train             0.024676982
KL Divergence                17.996782
KL Loss                      1.7996782
QF Loss                      631.28
VF Loss                      119.38758
Policy Loss                  -912.5642
Q Predictions Mean           910.65906
Q Predictions Std            224.4157
Q Predictions Max            1125.1448
Q Predictions Min            -1.1237154
V Predictions Mean           918.9562
V Predictions Std            222.34587
V Predictions Max            1123.5726
V Predictions Min            37.523537
Log Pis Mean                 -0.70512664
Log Pis Std                  2.341211
Log Pis Max                  8.061026
Log Pis Min                  -7.6862183
Policy mu Mean               -0.0067550903
Policy mu Std                0.5478292
Policy mu Max                2.0626774
Policy mu Min                -1.9113902
Policy log std Mean          -0.91291225
Policy log std Std           0.24769886
Policy log std Max           -0.1966967
Policy log std Min           -2.1856816
Z mean eval                  0.94765884
Z variance eval              0.02200008
total_rewards                [ 392.69172248 1640.06847946 2649.51270225  920.12542629 2445.96976122
  488.15564007 2618.19472013  826.75619855  165.26975044 1853.59166844]
total_rewards_mean           1400.0336069329765
total_rewards_std            912.8136901963834
total_rewards_max            2649.512702251577
total_rewards_min            165.26975044434477
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               27.34389538085088
(Previous) Eval Time (s)     15.896087189670652
Sample Time (s)              18.442212029360235
Epoch Time (s)               61.68219459988177
Total Train Time (s)         17358.24344996875
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:50.169860 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #249 | Epoch Duration: 68.28875041007996
2020-01-11 08:04:50.170041 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94873685
Z variance train             0.021986105
KL Divergence                18.487553
KL Loss                      1.8487552
QF Loss                      864.0531
VF Loss                      212.73207
Policy Loss                  -896.11615
Q Predictions Mean           896.00006
Q Predictions Std            230.13423
Q Predictions Max            1113.6277
Q Predictions Min            184.87746
V Predictions Mean           905.3037
V Predictions Std            230.08817
V Predictions Max            1130.2028
V Predictions Min            213.85753
Log Pis Mean                 -0.77122045
Log Pis Std                  2.608098
Log Pis Max                  6.968402
Log Pis Min                  -9.727021
Policy mu Mean               0.019139115
Policy mu Std                0.55602723
Policy mu Max                1.9995441
Policy mu Min                -2.0016105
Policy log std Mean          -0.8973024
Policy log std Std           0.25918734
Policy log std Max           -0.18904263
Policy log std Min           -2.004994
Z mean eval                  0.9392859
Z variance eval              0.036138322
total_rewards                [ 789.01752322 1105.43859018 1810.52486591 1903.06109997 2558.60225392
 2595.55756882 2566.31038292 2522.48860589 1860.8929106  2614.76241758]
total_rewards_mean           2032.6656219006643
total_rewards_std            629.2103721781617
total_rewards_max            2614.762417575725
total_rewards_min            789.0175232219351
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               28.871503327973187
(Previous) Eval Time (s)     22.502339004073292
Sample Time (s)              18.20539720263332
Epoch Time (s)               69.5792395346798
Total Train Time (s)         17430.198141679168
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:06:02.128130 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #250 | Epoch Duration: 71.95792889595032
2020-01-11 08:06:02.128393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9369464
Z variance train             0.03614458
KL Divergence                17.756351
KL Loss                      1.7756351
QF Loss                      1687.636
VF Loss                      269.56427
Policy Loss                  -904.8086
Q Predictions Mean           904.0029
Q Predictions Std            239.76398
Q Predictions Max            1165.2555
Q Predictions Min            -8.975048
V Predictions Mean           909.8237
V Predictions Std            235.63187
V Predictions Max            1178.8087
V Predictions Min            49.143604
Log Pis Mean                 -1.0225815
Log Pis Std                  2.7232208
Log Pis Max                  9.105858
Log Pis Min                  -8.7782955
Policy mu Mean               -0.020806652
Policy mu Std                0.5507915
Policy mu Max                2.3486767
Policy mu Min                -2.6107872
Policy log std Mean          -0.90752137
Policy log std Std           0.2753307
Policy log std Max           -0.25930423
Policy log std Min           -2.3936028
Z mean eval                  0.9711261
Z variance eval              0.044641256
total_rewards                [2689.78305015 2632.02372201 2676.70905149 2853.25425016 1366.79502981
  639.62139005   41.26334957 2743.26762685 2798.20864909 2549.44337002]
total_rewards_mean           2099.0369489188593
total_rewards_std            976.8750696278405
total_rewards_max            2853.254250155883
total_rewards_min            41.263349569099866
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               28.745271385181695
(Previous) Eval Time (s)     24.8807053421624
Sample Time (s)              18.550352044869214
Epoch Time (s)               72.17632877221331
Total Train Time (s)         17499.37430734327
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:11.307587 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #251 | Epoch Duration: 69.17900609970093
2020-01-11 08:07:11.307808 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9692615
Z variance train             0.044568248
KL Divergence                17.773617
KL Loss                      1.7773618
QF Loss                      1060.8872
VF Loss                      208.18037
Policy Loss                  -900.7518
Q Predictions Mean           897.0504
Q Predictions Std            233.6057
Q Predictions Max            1110.1827
Q Predictions Min            220.83504
V Predictions Mean           892.5353
V Predictions Std            232.40524
V Predictions Max            1110.0829
V Predictions Min            198.45192
Log Pis Mean                 -1.0141639
Log Pis Std                  2.4278219
Log Pis Max                  7.121056
Log Pis Min                  -7.963864
Policy mu Mean               0.008327452
Policy mu Std                0.5460385
Policy mu Max                3.0509303
Policy mu Min                -1.6251389
Policy log std Mean          -0.9021312
Policy log std Std           0.26110443
Policy log std Max           -0.14059585
Policy log std Min           -2.4727058
Z mean eval                  0.95378524
Z variance eval              0.025737846
total_rewards                [ 713.87330022  677.60380713 2061.5743183  2250.75837824 2035.46133829
  494.56244176  200.05566953 1054.18198782 1572.77841841 2262.11271832]
total_rewards_mean           1332.29623780232
total_rewards_std            752.6243425046742
total_rewards_max            2262.1127183170083
total_rewards_min            200.05566953122934
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               30.217944227159023
(Previous) Eval Time (s)     21.88304568314925
Sample Time (s)              18.601145889610052
Epoch Time (s)               70.70213579991832
Total Train Time (s)         17564.76422792673
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:08:16.702721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #252 | Epoch Duration: 65.39470386505127
2020-01-11 08:08:16.703037 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #252 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9523082
Z variance train             0.025788287
KL Divergence                18.28426
KL Loss                      1.828426
QF Loss                      618.2805
VF Loss                      172.43774
Policy Loss                  -897.6215
Q Predictions Mean           895.47485
Q Predictions Std            214.39062
Q Predictions Max            1106.3302
Q Predictions Min            192.85399
V Predictions Mean           905.6917
V Predictions Std            212.40698
V Predictions Max            1123.5273
V Predictions Min            220.44884
Log Pis Mean                 -0.702381
Log Pis Std                  2.5493464
Log Pis Max                  7.9760265
Log Pis Min                  -6.8761296
Policy mu Mean               0.04831638
Policy mu Std                0.55169046
Policy mu Max                2.0295484
Policy mu Min                -2.3989275
Policy log std Mean          -0.9253608
Policy log std Std           0.27224866
Policy log std Max           -0.23610914
Policy log std Min           -2.486945
Z mean eval                  0.9448649
Z variance eval              0.029942747
total_rewards                [  41.18816205  989.11057351  311.13511585  190.38212221  271.714661
 1082.69802891  798.76201095  595.62086488 2659.23679817 1232.9856366 ]
total_rewards_mean           817.2833974121476
total_rewards_std            725.5486103385207
total_rewards_max            2659.236798168392
total_rewards_min            41.1881620544665
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               27.45206371601671
(Previous) Eval Time (s)     16.57528018997982
Sample Time (s)              18.84845507470891
Epoch Time (s)               62.87579898070544
Total Train Time (s)         17623.4816097226
Epoch                        253
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:09:15.424718 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #253 | Epoch Duration: 58.721431255340576
2020-01-11 08:09:15.425005 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #253 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94295454
Z variance train             0.029953087
KL Divergence                17.798903
KL Loss                      1.7798903
QF Loss                      1218.8525
VF Loss                      102.96335
Policy Loss                  -909.7947
Q Predictions Mean           911.30505
Q Predictions Std            222.38817
Q Predictions Max            1132.3975
Q Predictions Min            157.60432
V Predictions Mean           912.88324
V Predictions Std            225.71
V Predictions Max            1137.1237
V Predictions Min            40.556866
Log Pis Mean                 -0.6133996
Log Pis Std                  3.1183186
Log Pis Max                  12.516827
Log Pis Min                  -11.725645
Policy mu Mean               0.02742127
Policy mu Std                0.58601123
Policy mu Max                2.3689942
Policy mu Min                -2.4511094
Policy log std Mean          -0.8993959
Policy log std Std           0.28722015
Policy log std Max           -0.1872521
Policy log std Min           -2.8568451
Z mean eval                  0.93744755
Z variance eval              0.02690569
total_rewards                [2357.86865498  -26.04434143  556.55530455 1077.86008247 2596.3004861
 2463.65072367 1938.57246575  800.4428763  2729.68127686 1864.15985353]
total_rewards_mean           1635.9047382788417
total_rewards_std            916.8037345760059
total_rewards_max            2729.6812768552136
total_rewards_min            -26.04434143038262
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               28.10335302213207
(Previous) Eval Time (s)     12.420615163166076
Sample Time (s)              18.614548318088055
Epoch Time (s)               59.1385165033862
Total Train Time (s)         17694.618922865484
Epoch                        254
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:10:26.586368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #254 | Epoch Duration: 71.1611180305481
2020-01-11 08:10:26.586676 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #254 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9372778
Z variance train             0.026927466
KL Divergence                18.345335
KL Loss                      1.8345336
QF Loss                      929.20447
VF Loss                      99.8484
Policy Loss                  -912.0884
Q Predictions Mean           910.978
Q Predictions Std            228.86916
Q Predictions Max            1122.9913
Q Predictions Min            3.0897772
V Predictions Mean           907.87866
V Predictions Std            228.91576
V Predictions Max            1111.8221
V Predictions Min            3.8389404
Log Pis Mean                 -0.7919455
Log Pis Std                  2.7592142
Log Pis Max                  13.631057
Log Pis Min                  -7.789043
Policy mu Mean               0.064500436
Policy mu Std                0.5541392
Policy mu Max                2.2510757
Policy mu Min                -2.1698506
Policy log std Mean          -0.9033371
Policy log std Std           0.28052866
Policy log std Max           -0.19608164
Policy log std Min           -2.5883994
Z mean eval                  0.9554559
Z variance eval              0.028318385
total_rewards                [ 206.55123216 2544.01969103  979.54894422 2801.62218341 2907.5863429
 1118.13704425  952.6613602  1991.87794842 1496.80350125  771.62406099]
total_rewards_mean           1577.0432308830873
total_rewards_std            887.0120463907294
total_rewards_max            2907.5863428961934
total_rewards_min            206.55123216081793
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               29.554026904981583
(Previous) Eval Time (s)     24.442884634714574
Sample Time (s)              18.676864847540855
Epoch Time (s)               72.67377638723701
Total Train Time (s)         17762.281220743433
Epoch                        255
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:11:34.233828 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #255 | Epoch Duration: 67.64689326286316
2020-01-11 08:11:34.234148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9557166
Z variance train             0.02830882
KL Divergence                18.556149
KL Loss                      1.8556149
QF Loss                      551.9176
VF Loss                      70.25395
Policy Loss                  -891.6634
Q Predictions Mean           889.64136
Q Predictions Std            258.397
Q Predictions Max            1139.0432
Q Predictions Min            211.28194
V Predictions Mean           892.45984
V Predictions Std            259.70703
V Predictions Max            1126.8702
V Predictions Min            224.25919
Log Pis Mean                 -1.0996405
Log Pis Std                  2.454031
Log Pis Max                  8.873881
Log Pis Min                  -8.857151
Policy mu Mean               0.03160839
Policy mu Std                0.55124724
Policy mu Max                1.9847487
Policy mu Min                -1.9066821
Policy log std Mean          -0.87705547
Policy log std Std           0.2598276
Policy log std Max           -0.17224836
Policy log std Min           -2.1101272
Z mean eval                  0.95902216
Z variance eval              0.028317148
total_rewards                [ -28.69973504 1703.02787005 1110.54670517 1409.14340384 1298.73668489
 1413.5044823   874.59612276 1531.84023104  419.32116973  892.12294939]
total_rewards_mean           1062.4139884138299
total_rewards_std            509.9774759641445
total_rewards_max            1703.027870054469
total_rewards_min            -28.699735038920366
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               29.615179917775095
(Previous) Eval Time (s)     19.415687709115446
Sample Time (s)              19.0076373629272
Epoch Time (s)               68.03850498981774
Total Train Time (s)         17828.213258637115
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:40.166400 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #256 | Epoch Duration: 65.93203616142273
2020-01-11 08:12:40.166602 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95608366
Z variance train             0.02820541
KL Divergence                17.814482
KL Loss                      1.7814482
QF Loss                      2928.693
VF Loss                      2077.1306
Policy Loss                  -904.8279
Q Predictions Mean           900.1463
Q Predictions Std            242.3305
Q Predictions Max            1113.2496
Q Predictions Min            49.949696
V Predictions Mean           919.55566
V Predictions Std            232.49184
V Predictions Max            1137.9342
V Predictions Min            220.44789
Log Pis Mean                 -0.8812002
Log Pis Std                  2.824293
Log Pis Max                  12.02819
Log Pis Min                  -11.538235
Policy mu Mean               -0.05733068
Policy mu Std                0.54770327
Policy mu Max                2.2589426
Policy mu Min                -3.4361825
Policy log std Mean          -0.9161228
Policy log std Std           0.26949656
Policy log std Max           -0.16801363
Policy log std Min           -2.7833662
Z mean eval                  0.9743804
Z variance eval              0.025839994
total_rewards                [1581.0693333  2533.64945465 2521.91674962 1870.10757966 2593.56677903
 2388.29893387 2711.13949003 2649.54139756 2515.39766722 1367.54550296]
total_rewards_mean           2273.223288788703
total_rewards_std            458.19194163567977
total_rewards_max            2711.1394900299756
total_rewards_min            1367.5455029620603
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               31.864231899846345
(Previous) Eval Time (s)     17.308948644436896
Sample Time (s)              18.443651183042675
Epoch Time (s)               67.61683172732592
Total Train Time (s)         17903.35017370293
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:13:55.305441 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #257 | Epoch Duration: 75.1386935710907
2020-01-11 08:13:55.305596 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9797969
Z variance train             0.025819376
KL Divergence                18.32274
KL Loss                      1.8322741
QF Loss                      1017.46625
VF Loss                      566.675
Policy Loss                  -915.82446
Q Predictions Mean           918.78186
Q Predictions Std            236.59567
Q Predictions Max            1172.9167
Q Predictions Min            182.0911
V Predictions Mean           931.19635
V Predictions Std            237.79002
V Predictions Max            1182.9382
V Predictions Min            212.43553
Log Pis Mean                 -0.7309377
Log Pis Std                  2.5701873
Log Pis Max                  7.1124563
Log Pis Min                  -10.644365
Policy mu Mean               -0.013894947
Policy mu Std                0.5666858
Policy mu Max                2.4704862
Policy mu Min                -2.798747
Policy log std Mean          -0.91282326
Policy log std Std           0.25961065
Policy log std Max           -0.23753095
Policy log std Min           -2.4096613
Z mean eval                  0.94236296
Z variance eval              0.02254998
total_rewards                [1623.90878118 2753.43644334 2600.19241283 2795.36802836 2491.52994709
  120.64003533 2785.007311    263.01485697 2339.75025458  646.19177854]
total_rewards_mean           1841.9039849206947
total_rewards_std            1039.5761241606613
total_rewards_max            2795.3680283584495
total_rewards_min            120.64003533014515
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               28.966166269034147
(Previous) Eval Time (s)     24.83051085891202
Sample Time (s)              18.142430834006518
Epoch Time (s)               71.93910796195269
Total Train Time (s)         17970.864580288064
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:15:02.826609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #258 | Epoch Duration: 67.52085781097412
2020-01-11 08:15:02.826877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.942224
Z variance train             0.022569606
KL Divergence                18.836836
KL Loss                      1.8836836
QF Loss                      642.1618
VF Loss                      112.799484
Policy Loss                  -925.8782
Q Predictions Mean           926.0701
Q Predictions Std            232.56647
Q Predictions Max            1176.2289
Q Predictions Min            27.266499
V Predictions Mean           926.14233
V Predictions Std            231.08913
V Predictions Max            1172.3293
V Predictions Min            4.810712
Log Pis Mean                 -1.0211531
Log Pis Std                  2.5194926
Log Pis Max                  5.779808
Log Pis Min                  -9.526345
Policy mu Mean               0.04571762
Policy mu Std                0.57074213
Policy mu Max                1.82378
Policy mu Min                -2.5523293
Policy log std Mean          -0.9078686
Policy log std Std           0.25279802
Policy log std Max           -0.11361337
Policy log std Min           -1.9657531
Z mean eval                  0.95122087
Z variance eval              0.015711647
total_rewards                [2745.67533573 1298.58461177 2365.94112692   60.92758547   35.42328444
 1257.93296663  194.45701743 2807.29395779 2465.2225721  2596.17401672]
total_rewards_mean           1582.7632475009143
total_rewards_std            1099.7660916424613
total_rewards_max            2807.29395779026
total_rewards_min            35.42328444348435
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               30.471297970972955
(Previous) Eval Time (s)     20.411914727650583
Sample Time (s)              18.664497023448348
Epoch Time (s)               69.54770972207189
Total Train Time (s)         18041.573182887398
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:16:13.535361 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #259 | Epoch Duration: 70.70829439163208
2020-01-11 08:16:13.535560 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9479469
Z variance train             0.015701333
KL Divergence                19.665289
KL Loss                      1.9665289
QF Loss                      529.76587
VF Loss                      102.62699
Policy Loss                  -934.32587
Q Predictions Mean           933.71216
Q Predictions Std            230.26512
Q Predictions Max            1133.148
Q Predictions Min            29.49901
V Predictions Mean           931.9986
V Predictions Std            227.85965
V Predictions Max            1138.7079
V Predictions Min            5.6386595
Log Pis Mean                 -0.90521574
Log Pis Std                  2.3459744
Log Pis Max                  7.1766567
Log Pis Min                  -8.43993
Policy mu Mean               0.047162183
Policy mu Std                0.5337778
Policy mu Max                2.5592947
Policy mu Min                -1.899666
Policy log std Mean          -0.919437
Policy log std Std           0.26092398
Policy log std Max           -0.1349914
Policy log std Min           -2.0178359
Z mean eval                  0.95758504
Z variance eval              0.018248824
total_rewards                [2644.02731142 2873.60999535 3031.82620615 2677.57364495  182.46760229
 2587.31832388 2098.37098216 2986.37898594   27.05295042 2957.12315171]
total_rewards_mean           2206.5749154261
total_rewards_std            1082.3399180158237
total_rewards_max            3031.82620614799
total_rewards_min            27.052950421668136
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               29.135387738700956
(Previous) Eval Time (s)     21.572190378792584
Sample Time (s)              18.875350617337972
Epoch Time (s)               69.58292873483151
Total Train Time (s)         18110.719359093346
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:17:22.691061 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #260 | Epoch Duration: 69.15528988838196
2020-01-11 08:17:22.691373 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95863754
Z variance train             0.01821758
KL Divergence                19.866184
KL Loss                      1.9866184
QF Loss                      1189.854
VF Loss                      160.9096
Policy Loss                  -923.5161
Q Predictions Mean           923.8302
Q Predictions Std            235.56296
Q Predictions Max            1141.3666
Q Predictions Min            223.13422
V Predictions Mean           927.5819
V Predictions Std            236.59834
V Predictions Max            1152.739
V Predictions Min            151.24644
Log Pis Mean                 -0.90968966
Log Pis Std                  2.4748971
Log Pis Max                  8.393955
Log Pis Min                  -7.207617
Policy mu Mean               0.014843491
Policy mu Std                0.5447495
Policy mu Max                2.4103827
Policy mu Min                -2.553052
Policy log std Mean          -0.8872611
Policy log std Std           0.24596652
Policy log std Max           -0.1873379
Policy log std Min           -2.5966277
Z mean eval                  0.9661409
Z variance eval              0.018426586
total_rewards                [2417.47892181 2073.4993313   326.12355887 2466.40141903  865.95312419
 1746.97781979 2664.73791582 2515.00056652 2536.84246128  743.39379977]
total_rewards_mean           1835.6408918387192
total_rewards_std            827.8519102171477
total_rewards_max            2664.737915819428
total_rewards_min            326.1235588727875
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               28.850722576957196
(Previous) Eval Time (s)     21.144186593126506
Sample Time (s)              19.047022285405546
Epoch Time (s)               69.04193145548925
Total Train Time (s)         18180.52626497438
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:18:32.496157 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #261 | Epoch Duration: 69.80453610420227
2020-01-11 08:18:32.496397 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96569645
Z variance train             0.018424755
KL Divergence                20.05821
KL Loss                      2.005821
QF Loss                      481.88998
VF Loss                      134.48859
Policy Loss                  -955.27594
Q Predictions Mean           953.0349
Q Predictions Std            232.09865
Q Predictions Max            1215.4187
Q Predictions Min            208.60507
V Predictions Mean           956.2883
V Predictions Std            229.3073
V Predictions Max            1232.298
V Predictions Min            225.07124
Log Pis Mean                 -1.1542563
Log Pis Std                  2.4929826
Log Pis Max                  6.7018137
Log Pis Min                  -8.480636
Policy mu Mean               0.032985955
Policy mu Std                0.5303168
Policy mu Max                2.0935614
Policy mu Min                -1.9592499
Policy log std Mean          -0.89708984
Policy log std Std           0.25194874
Policy log std Max           -0.13511807
Policy log std Min           -2.0002584
Z mean eval                  0.9562416
Z variance eval              0.028705826
total_rewards                [2673.89588026 2638.18142864 2573.69689669 2507.09258191 2504.37492638
 2692.90799797 2793.69367195 2472.59168313 2482.99962143 2649.24305343]
total_rewards_mean           2598.867774179379
total_rewards_std            101.91632856930026
total_rewards_max            2793.693671954397
total_rewards_min            2472.5916831286895
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               28.588969186879694
(Previous) Eval Time (s)     21.906475526746362
Sample Time (s)              18.241868307814002
Epoch Time (s)               68.73731302144006
Total Train Time (s)         18254.54895925196
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:19:46.522341 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #262 | Epoch Duration: 74.02575159072876
2020-01-11 08:19:46.522562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9566061
Z variance train             0.02852979
KL Divergence                18.768143
KL Loss                      1.8768142
QF Loss                      1497.6605
VF Loss                      147.8255
Policy Loss                  -949.18085
Q Predictions Mean           945.08325
Q Predictions Std            219.85867
Q Predictions Max            1142.8955
Q Predictions Min            24.605213
V Predictions Mean           952.37366
V Predictions Std            220.35413
V Predictions Max            1161.9943
V Predictions Min            20.174118
Log Pis Mean                 -0.92969894
Log Pis Std                  2.7634943
Log Pis Max                  10.929201
Log Pis Min                  -12.921792
Policy mu Mean               0.042914666
Policy mu Std                0.5612136
Policy mu Max                2.5755172
Policy mu Min                -2.2567084
Policy log std Mean          -0.8927113
Policy log std Std           0.25580645
Policy log std Max           -0.1816293
Policy log std Min           -2.3957195
Z mean eval                  0.9422768
Z variance eval              0.023592463
total_rewards                [2311.12998609 1876.53620347 2578.76138597 2674.219349   2542.51521942
  491.88003057  714.59089295 2715.33036934  481.15718334  972.82005296]
total_rewards_mean           1735.894067310844
total_rewards_std            910.9756897708318
total_rewards_max            2715.3303693439702
total_rewards_min            481.15718334295997
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               29.770463815890253
(Previous) Eval Time (s)     27.194626914337277
Sample Time (s)              17.562837024684995
Epoch Time (s)               74.52792775491253
Total Train Time (s)         18320.48717993498
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:20:52.465351 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #263 | Epoch Duration: 65.9425859451294
2020-01-11 08:20:52.465628 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94229853
Z variance train             0.02361604
KL Divergence                19.093214
KL Loss                      1.9093214
QF Loss                      1343.4504
VF Loss                      324.5171
Policy Loss                  -932.8443
Q Predictions Mean           933.1562
Q Predictions Std            230.99886
Q Predictions Max            1141.5325
Q Predictions Min            217.40785
V Predictions Mean           939.5511
V Predictions Std            230.56235
V Predictions Max            1153.8776
V Predictions Min            217.99712
Log Pis Mean                 -1.068821
Log Pis Std                  2.5195622
Log Pis Max                  10.198889
Log Pis Min                  -9.6985
Policy mu Mean               -0.0072131553
Policy mu Std                0.5277378
Policy mu Max                2.0445693
Policy mu Min                -1.6975014
Policy log std Mean          -0.89496636
Policy log std Std           0.25325644
Policy log std Max           -0.2899487
Policy log std Min           -2.8082244
Z mean eval                  0.93767816
Z variance eval              0.022560755
total_rewards                [ 480.58611292 2316.94700398 2237.48659826 2145.21470229 2145.75820784
 2219.88649086 1540.17366325 2160.58209698 2526.94960176 2435.52428713]
total_rewards_mean           2020.9108765272322
total_rewards_std            570.6459665542699
total_rewards_max            2526.9496017616893
total_rewards_min            480.5861129238513
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               27.616259199101478
(Previous) Eval Time (s)     18.609000836964697
Sample Time (s)              18.261350391432643
Epoch Time (s)               64.48661042749882
Total Train Time (s)         18393.623733310495
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:22:05.603159 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #264 | Epoch Duration: 73.13734173774719
2020-01-11 08:22:05.603375 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.93655765
Z variance train             0.022485124
KL Divergence                19.928944
KL Loss                      1.9928944
QF Loss                      671.58984
VF Loss                      364.00177
Policy Loss                  -927.1595
Q Predictions Mean           929.21936
Q Predictions Std            251.09755
Q Predictions Max            1178.5479
Q Predictions Min            27.824406
V Predictions Mean           937.34326
V Predictions Std            251.94325
V Predictions Max            1186.6084
V Predictions Min            43.67303
Log Pis Mean                 -0.5886258
Log Pis Std                  2.9512146
Log Pis Max                  14.817766
Log Pis Min                  -7.9653544
Policy mu Mean               -0.028695853
Policy mu Std                0.55096203
Policy mu Max                1.9703089
Policy mu Min                -2.5072446
Policy log std Mean          -0.9422263
Policy log std Std           0.3024558
Policy log std Max           -0.16707164
Policy log std Min           -3.200778
Z mean eval                  0.9350117
Z variance eval              0.019623805
total_rewards                [2705.4835373  2772.54010091 1704.68980366 2668.50541348 2715.39705883
 2639.93563577 2848.43321871 2583.35819394   78.58540037 2709.26746287]
total_rewards_mean           2342.6195825845894
total_rewards_std            814.3157693073841
total_rewards_max            2848.4332187129257
total_rewards_min            78.58540037322302
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               28.598074399400502
(Previous) Eval Time (s)     27.259424154181033
Sample Time (s)              18.259149289689958
Epoch Time (s)               74.1166478432715
Total Train Time (s)         18464.477830617223
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:16.459263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #265 | Epoch Duration: 70.85575151443481
2020-01-11 08:23:16.459449 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9346911
Z variance train             0.01965185
KL Divergence                19.912933
KL Loss                      1.9912933
QF Loss                      877.54834
VF Loss                      254.60023
Policy Loss                  -940.7421
Q Predictions Mean           941.505
Q Predictions Std            217.9322
Q Predictions Max            1192.389
Q Predictions Min            217.17151
V Predictions Mean           942.2827
V Predictions Std            215.67148
V Predictions Max            1166.7902
V Predictions Min            212.58684
Log Pis Mean                 -1.0352967
Log Pis Std                  2.4439616
Log Pis Max                  9.812263
Log Pis Min                  -7.0683756
Policy mu Mean               0.040859863
Policy mu Std                0.5374054
Policy mu Max                1.9172431
Policy mu Min                -2.4562085
Policy log std Mean          -0.9089472
Policy log std Std           0.24512118
Policy log std Max           -0.20901263
Policy log std Min           -2.1651902
Z mean eval                  0.9613374
Z variance eval              0.020611543
total_rewards                [2680.14739566 2536.52402795 1949.01509215 2516.72350792 2382.86782997
 2407.38702888  252.28407178 2658.380261   2241.39581776  707.59915006]
total_rewards_mean           2033.2324183125195
total_rewards_std            808.5862117722824
total_rewards_max            2680.1473956610107
total_rewards_min            252.2840717782916
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               26.430531528778374
(Previous) Eval Time (s)     23.998253948055208
Sample Time (s)              18.647133784368634
Epoch Time (s)               69.07591926120222
Total Train Time (s)         18536.592202575877
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:24:28.576989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #266 | Epoch Duration: 72.11740326881409
2020-01-11 08:24:28.577149 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.960807
Z variance train             0.02060557
KL Divergence                19.985966
KL Loss                      1.9985965
QF Loss                      848.369
VF Loss                      90.53276
Policy Loss                  -945.1085
Q Predictions Mean           944.59845
Q Predictions Std            237.18134
Q Predictions Max            1175.7645
Q Predictions Min            157.97496
V Predictions Mean           946.76355
V Predictions Std            236.71411
V Predictions Max            1162.2561
V Predictions Min            167.97229
Log Pis Mean                 -1.0641508
Log Pis Std                  2.5813777
Log Pis Max                  11.421577
Log Pis Min                  -9.829818
Policy mu Mean               0.005550222
Policy mu Std                0.5447575
Policy mu Max                2.9853616
Policy mu Min                -1.9979098
Policy log std Mean          -0.8969818
Policy log std Std           0.24545677
Policy log std Max           -0.14156938
Policy log std Min           -1.9388577
Z mean eval                  0.97309196
Z variance eval              0.018782884
total_rewards                [ 189.86782478 1984.9485672   169.390612    710.19842791 2621.10821352
 1847.49814351 2744.62611879 2746.91371919 2189.5445928  2665.22773077]
total_rewards_mean           1786.9323950472312
total_rewards_std            991.835737290704
total_rewards_max            2746.9137191923583
total_rewards_min            169.39061199952283
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               28.390909078065306
(Previous) Eval Time (s)     27.03944656299427
Sample Time (s)              17.81749355746433
Epoch Time (s)               73.24784919852391
Total Train Time (s)         18603.635010964237
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:25:35.621091 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #267 | Epoch Duration: 67.04381585121155
2020-01-11 08:25:35.621250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9730695
Z variance train             0.018711997
KL Divergence                20.780556
KL Loss                      2.0780556
QF Loss                      1632.5986
VF Loss                      541.0375
Policy Loss                  -954.1827
Q Predictions Mean           952.113
Q Predictions Std            220.11331
Q Predictions Max            1230.9729
Q Predictions Min            163.06963
V Predictions Mean           937.4934
V Predictions Std            213.63902
V Predictions Max            1210.862
V Predictions Min            162.02379
Log Pis Mean                 -0.9475565
Log Pis Std                  2.7196786
Log Pis Max                  8.868357
Log Pis Min                  -10.539837
Policy mu Mean               -0.012185356
Policy mu Std                0.54432154
Policy mu Max                1.9378135
Policy mu Min                -2.4087427
Policy log std Mean          -0.9466716
Policy log std Std           0.27746677
Policy log std Max           -0.25460112
Policy log std Min           -2.2659364
Z mean eval                  0.97276336
Z variance eval              0.017586034
total_rewards                [2118.88200635  120.5940651   329.50211996 2326.20381677  466.47801754
 1697.53646997 2394.63603113   33.50403503 1788.2756482  2518.88318757]
total_rewards_mean           1379.4495397605426
total_rewards_std            968.1181621215087
total_rewards_max            2518.883187566143
total_rewards_min            33.50403503151371
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               29.834383898880333
(Previous) Eval Time (s)     20.835119815077633
Sample Time (s)              17.9646168127656
Epoch Time (s)               68.63412052672356
Total Train Time (s)         18675.349455229472
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:26:47.340377 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #268 | Epoch Duration: 71.7190055847168
2020-01-11 08:26:47.340572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97230065
Z variance train             0.017570833
KL Divergence                20.717579
KL Loss                      2.071758
QF Loss                      596.39453
VF Loss                      245.22083
Policy Loss                  -951.20544
Q Predictions Mean           949.2621
Q Predictions Std            241.83994
Q Predictions Max            1188.2013
Q Predictions Min            211.91777
V Predictions Mean           961.394
V Predictions Std            239.36082
V Predictions Max            1201.4502
V Predictions Min            223.86209
Log Pis Mean                 -0.9304898
Log Pis Std                  2.75157
Log Pis Max                  9.401225
Log Pis Min                  -8.143623
Policy mu Mean               0.024979781
Policy mu Std                0.5215995
Policy mu Max                1.9342264
Policy mu Min                -2.1527903
Policy log std Mean          -0.93968385
Policy log std Std           0.2694295
Policy log std Max           -0.2599188
Policy log std Min           -1.9815333
Z mean eval                  0.94810647
Z variance eval              0.020062488
total_rewards                [2770.01899255 2787.94925448 2747.60794526 1028.91994683 2710.94018341
 1458.22553726 2762.06632807 2827.7981631  1359.95149886  932.56037185]
total_rewards_mean           2138.6038221688914
total_rewards_std            783.4307266399943
total_rewards_max            2827.798163103256
total_rewards_min            932.5603718521982
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               31.75892403628677
(Previous) Eval Time (s)     23.91973400488496
Sample Time (s)              18.408568614162505
Epoch Time (s)               74.08722665533423
Total Train Time (s)         18750.266314502805
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:28:02.258844 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #269 | Epoch Duration: 74.9181261062622
2020-01-11 08:28:02.259086 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94911146
Z variance train             0.020023603
KL Divergence                20.824099
KL Loss                      2.0824099
QF Loss                      1281.7631
VF Loss                      93.952774
Policy Loss                  -975.1322
Q Predictions Mean           974.3658
Q Predictions Std            199.88245
Q Predictions Max            1166.4221
Q Predictions Min            -31.952728
V Predictions Mean           976.9514
V Predictions Std            197.24785
V Predictions Max            1165.0695
V Predictions Min            27.624989
Log Pis Mean                 -0.93354267
Log Pis Std                  2.4731035
Log Pis Max                  8.485842
Log Pis Min                  -8.36191
Policy mu Mean               -0.0031338627
Policy mu Std                0.55512494
Policy mu Max                2.2712328
Policy mu Min                -1.8365124
Policy log std Mean          -0.9092028
Policy log std Std           0.26113936
Policy log std Max           -0.20468473
Policy log std Min           -2.8673708
Z mean eval                  0.9840268
Z variance eval              0.017936615
total_rewards                [ 558.98559429 1067.98359828 1400.31502007  613.64153043  585.80703615
  188.49335824  860.552264   2443.59770402  234.89846713  582.8014091 ]
total_rewards_mean           853.7075981723258
total_rewards_std            631.4728539315911
total_rewards_max            2443.597704015351
total_rewards_min            188.49335824351155
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               28.919176320079714
(Previous) Eval Time (s)     24.750281310174614
Sample Time (s)              18.591629980131984
Epoch Time (s)               72.26108761038631
Total Train Time (s)         18809.965902919415
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:29:01.961064 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #270 | Epoch Duration: 59.70177984237671
2020-01-11 08:29:01.961241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #270 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97856176
Z variance train             0.017903369
KL Divergence                20.889008
KL Loss                      2.0889008
QF Loss                      604.50397
VF Loss                      406.5916
Policy Loss                  -974.7683
Q Predictions Mean           970.25
Q Predictions Std            205.47226
Q Predictions Max            1148.0773
Q Predictions Min            201.18466
V Predictions Mean           957.1553
V Predictions Std            201.8206
V Predictions Max            1134.1938
V Predictions Min            185.1465
Log Pis Mean                 -0.814245
Log Pis Std                  2.2504127
Log Pis Max                  8.664513
Log Pis Min                  -7.1079226
Policy mu Mean               0.016407836
Policy mu Std                0.52810484
Policy mu Max                2.1576633
Policy mu Min                -2.419011
Policy log std Mean          -0.9317478
Policy log std Std           0.25369886
Policy log std Max           -0.28760326
Policy log std Min           -2.1760304
Z mean eval                  0.96157044
Z variance eval              0.018411702
total_rewards                [ 724.62354845 2448.75235289 1090.76516313 2777.7195147  1070.66569208
 2770.04637958 2235.41778433 2178.07902307  298.72112767 1901.97477906]
total_rewards_mean           1749.6765364948417
total_rewards_std            841.4646240515457
total_rewards_max            2777.719514695438
total_rewards_min            298.72112767087657
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               28.27397532714531
(Previous) Eval Time (s)     12.190696700941771
Sample Time (s)              17.389723810832947
Epoch Time (s)               57.85439583892003
Total Train Time (s)         18878.89904190181
Epoch                        271
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:30:10.895864 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #271 | Epoch Duration: 68.9344642162323
2020-01-11 08:30:10.896040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96388274
Z variance train             0.018394046
KL Divergence                21.228397
KL Loss                      2.1228397
QF Loss                      842.16315
VF Loss                      95.63217
Policy Loss                  -945.97003
Q Predictions Mean           945.38385
Q Predictions Std            238.84924
Q Predictions Max            1241.5853
Q Predictions Min            25.553167
V Predictions Mean           951.07996
V Predictions Std            240.26776
V Predictions Max            1237.9379
V Predictions Min            9.523024
Log Pis Mean                 -0.9939533
Log Pis Std                  2.7943068
Log Pis Max                  9.7239065
Log Pis Min                  -12.136492
Policy mu Mean               0.016068427
Policy mu Std                0.5811491
Policy mu Max                2.2883022
Policy mu Min                -2.6678658
Policy log std Mean          -0.88006943
Policy log std Std           0.25522658
Policy log std Max           -0.2343775
Policy log std Min           -2.4360814
Z mean eval                  0.94661725
Z variance eval              0.017932173
total_rewards                [2643.81661764 2592.11422213 1907.20418241 2778.57784015 2699.87921409
 2498.24431953 2830.23376493 2422.25524592 2612.87922146 2578.11420457]
total_rewards_mean           2556.3318832835175
total_rewards_std            245.0193562930265
total_rewards_max            2830.2337649290344
total_rewards_min            1907.2041824074274
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               26.906636844854802
(Previous) Eval Time (s)     23.27047092700377
Sample Time (s)              17.50559878302738
Epoch Time (s)               67.68270655488595
Total Train Time (s)         18949.28200466791
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:21.281999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #272 | Epoch Duration: 70.38579964637756
2020-01-11 08:31:21.282171 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9476099
Z variance train             0.017984526
KL Divergence                21.434166
KL Loss                      2.1434166
QF Loss                      1259.5568
VF Loss                      331.2734
Policy Loss                  -952.659
Q Predictions Mean           951.494
Q Predictions Std            248.72667
Q Predictions Max            1195.1526
Q Predictions Min            61.474785
V Predictions Mean           964.6294
V Predictions Std            251.23184
V Predictions Max            1205.0487
V Predictions Min            11.611884
Log Pis Mean                 -0.6042479
Log Pis Std                  2.5802462
Log Pis Max                  9.855669
Log Pis Min                  -11.8867035
Policy mu Mean               0.061376624
Policy mu Std                0.5479968
Policy mu Max                3.0108676
Policy mu Min                -1.9970524
Policy log std Mean          -0.9368279
Policy log std Std           0.26901367
Policy log std Max           -0.16654408
Policy log std Min           -2.4300387
Z mean eval                  0.9845239
Z variance eval              0.029411893
total_rewards                [1957.94386817 2455.67712336 1327.17467798 2425.1599182  2327.03106003
 1386.01366687  646.53991737 2234.2483797   826.39706223 1456.84278006]
total_rewards_mean           1704.302845397929
total_rewards_std            633.3652822701233
total_rewards_max            2455.677123363509
total_rewards_min            646.5399173747008
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               29.613697161898017
(Previous) Eval Time (s)     25.97328896773979
Sample Time (s)              19.21489203348756
Epoch Time (s)               74.80187816312537
Total Train Time (s)         19018.243637294974
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:32:30.245560 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #273 | Epoch Duration: 68.96322798728943
2020-01-11 08:32:30.245790 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9834347
Z variance train             0.02943967
KL Divergence                21.31956
KL Loss                      2.1319559
QF Loss                      1264.8815
VF Loss                      252.52661
Policy Loss                  -970.0892
Q Predictions Mean           969.9731
Q Predictions Std            253.18262
Q Predictions Max            1177.8267
Q Predictions Min            27.10243
V Predictions Mean           971.15076
V Predictions Std            252.24634
V Predictions Max            1184.4899
V Predictions Min            121.64522
Log Pis Mean                 -0.64262843
Log Pis Std                  2.9535525
Log Pis Max                  12.361588
Log Pis Min                  -10.93326
Policy mu Mean               0.040661514
Policy mu Std                0.568814
Policy mu Max                2.924331
Policy mu Min                -2.1224544
Policy log std Mean          -0.91623235
Policy log std Std           0.28145573
Policy log std Max           0.04530078
Policy log std Min           -2.6083484
Z mean eval                  0.9413112
Z variance eval              0.02506803
total_rewards                [2748.00553297  101.42249601 1142.09011423 2956.24659172 2938.79909345
 2829.5584564  1806.3086598  3047.07633022  790.57475491   87.3320663 ]
total_rewards_mean           1844.7414096016662
total_rewards_std            1157.4920141599582
total_rewards_max            3047.0763302198056
total_rewards_min            87.33206630156067
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               27.75840541580692
(Previous) Eval Time (s)     20.134307294152677
Sample Time (s)              17.95676493551582
Epoch Time (s)               65.84947764547542
Total Train Time (s)         19081.374750651885
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:33.379572 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #274 | Epoch Duration: 63.13360095024109
2020-01-11 08:33:33.379769 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9420477
Z variance train             0.025109794
KL Divergence                21.160007
KL Loss                      2.116001
QF Loss                      609.8369
VF Loss                      165.52493
Policy Loss                  -963.55695
Q Predictions Mean           961.8228
Q Predictions Std            256.38867
Q Predictions Max            1194.0923
Q Predictions Min            192.20062
V Predictions Mean           960.4851
V Predictions Std            257.50616
V Predictions Max            1185.6235
V Predictions Min            189.03493
Log Pis Mean                 -0.6180699
Log Pis Std                  2.8699381
Log Pis Max                  8.320943
Log Pis Min                  -9.18242
Policy mu Mean               0.01849006
Policy mu Std                0.58698756
Policy mu Max                2.0264938
Policy mu Min                -3.0681586
Policy log std Mean          -0.920218
Policy log std Std           0.25651285
Policy log std Max           -0.22916245
Policy log std Min           -2.2610042
Z mean eval                  0.9607369
Z variance eval              0.023676531
total_rewards                [2787.7601588  2591.79667255 2385.82477972 2608.86573367    5.65514661
 1004.12976302 2926.11938001 1530.81425021 2650.92575052 2744.28008078]
total_rewards_mean           2123.6171715895057
total_rewards_std            914.4514218327171
total_rewards_max            2926.119380014972
total_rewards_min            5.655146611401172
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               28.94559695199132
(Previous) Eval Time (s)     17.418141006026417
Sample Time (s)              17.694401894696057
Epoch Time (s)               64.0581398527138
Total Train Time (s)         19151.671235559974
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:34:43.678046 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #275 | Epoch Duration: 70.29811120033264
2020-01-11 08:34:43.678210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.96206367
Z variance train             0.023673156
KL Divergence                21.225895
KL Loss                      2.1225896
QF Loss                      612.12366
VF Loss                      96.99818
Policy Loss                  -951.90497
Q Predictions Mean           949.9511
Q Predictions Std            262.55035
Q Predictions Max            1169.5952
Q Predictions Min            46.80893
V Predictions Mean           955.66315
V Predictions Std            261.17352
V Predictions Max            1173.6406
V Predictions Min            43.6692
Log Pis Mean                 -0.9899842
Log Pis Std                  2.547952
Log Pis Max                  10.013716
Log Pis Min                  -8.898963
Policy mu Mean               -0.0044309366
Policy mu Std                0.5395897
Policy mu Max                1.8894162
Policy mu Min                -2.727322
Policy log std Mean          -0.9306141
Policy log std Std           0.2782037
Policy log std Max           -0.24921727
Policy log std Min           -3.1583633
Z mean eval                  0.9411913
Z variance eval              0.01900946
total_rewards                [2473.12049841 1094.67684958  839.526845   2284.49411419 2404.98721218
 2853.31058717 2938.84879781  257.83229776 2784.54997784  729.6461021 ]
total_rewards_mean           1866.0993282038767
total_rewards_std            965.9115187137352
total_rewards_max            2938.8487978085386
total_rewards_min            257.83229776187045
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               27.214037312660366
(Previous) Eval Time (s)     23.657817136030644
Sample Time (s)              17.427150243427604
Epoch Time (s)               68.29900469211861
Total Train Time (s)         19216.881542794872
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:35:48.890612 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #276 | Epoch Duration: 65.21225476264954
2020-01-11 08:35:48.890805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.94131726
Z variance train             0.01895076
KL Divergence                20.969387
KL Loss                      2.0969388
QF Loss                      688.0587
VF Loss                      290.23523
Policy Loss                  -965.6133
Q Predictions Mean           964.79083
Q Predictions Std            241.15952
Q Predictions Max            1157.556
Q Predictions Min            -13.843012
V Predictions Mean           974.4971
V Predictions Std            242.74596
V Predictions Max            1180.0726
V Predictions Min            15.781375
Log Pis Mean                 -0.9325637
Log Pis Std                  2.3628807
Log Pis Max                  6.875214
Log Pis Min                  -8.764905
Policy mu Mean               -0.0025807477
Policy mu Std                0.5530358
Policy mu Max                1.8832563
Policy mu Min                -1.795576
Policy log std Mean          -0.93661064
Policy log std Std           0.26013044
Policy log std Max           -0.22256637
Policy log std Min           -2.2319117
Z mean eval                  0.9665712
Z variance eval              0.018633017
total_rewards                [2749.35707921  686.36090638 1099.03044294 2482.08710882  328.11385861
 2679.42332113 1585.42713021 2459.70932354 2609.53769395 1871.62007758]
total_rewards_mean           1855.0666942354285
total_rewards_std            845.5366013891415
total_rewards_max            2749.3570792099663
total_rewards_min            328.1138586147534
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               30.134988063015044
(Previous) Eval Time (s)     20.5707746129483
Sample Time (s)              18.03553053177893
Epoch Time (s)               68.74129320774227
Total Train Time (s)         19288.395596046932
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:37:00.407721 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #277 | Epoch Duration: 71.51675629615784
2020-01-11 08:37:00.407914 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9659751
Z variance train             0.018577872
KL Divergence                21.342896
KL Loss                      2.1342895
QF Loss                      674.29065
VF Loss                      287.6961
Policy Loss                  -969.2947
Q Predictions Mean           968.3994
Q Predictions Std            248.41695
Q Predictions Max            1201.7563
Q Predictions Min            0.96247566
V Predictions Mean           980.1164
V Predictions Std            244.24626
V Predictions Max            1208.7864
V Predictions Min            6.0451813
Log Pis Mean                 -0.44868708
Log Pis Std                  2.9203372
Log Pis Max                  10.719087
Log Pis Min                  -12.413293
Policy mu Mean               0.05370553
Policy mu Std                0.58334374
Policy mu Max                2.7794292
Policy mu Min                -2.9407995
Policy log std Mean          -0.9143796
Policy log std Std           0.25854474
Policy log std Max           -0.19749957
Policy log std Min           -1.8903401
Z mean eval                  0.9817233
Z variance eval              0.013863939
total_rewards                [2564.60923081 2527.82046308  416.5956276   135.79511109 1288.20614402
 2509.00365213 2711.09890859  861.56968375 2725.226881    695.11905839]
total_rewards_mean           1643.5044760469657
total_rewards_std            1005.2365625994341
total_rewards_max            2725.2268810006813
total_rewards_min            135.795111092296
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               26.916435678955168
(Previous) Eval Time (s)     23.345904739107937
Sample Time (s)              18.035858403425664
Epoch Time (s)               68.29819882148877
Total Train Time (s)         19351.935573165305
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:38:03.949473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #278 | Epoch Duration: 63.54137420654297
2020-01-11 08:38:03.949641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9816324
Z variance train             0.013869239
KL Divergence                21.434872
KL Loss                      2.1434872
QF Loss                      471.97577
VF Loss                      83.84941
Policy Loss                  -1017.2503
Q Predictions Mean           1016.02264
Q Predictions Std            186.81361
Q Predictions Max            1231.208
Q Predictions Min            197.51277
V Predictions Mean           1016.30774
V Predictions Std            185.22737
V Predictions Max            1215.5858
V Predictions Min            202.81985
Log Pis Mean                 -0.33598834
Log Pis Std                  2.6981494
Log Pis Max                  8.769824
Log Pis Min                  -7.336196
Policy mu Mean               -0.000827322
Policy mu Std                0.5666678
Policy mu Max                2.382897
Policy mu Min                -2.2416494
Policy log std Mean          -0.9437562
Policy log std Std           0.25680655
Policy log std Max           -0.2794544
Policy log std Min           -2.4850667
Z mean eval                  1.0034134
Z variance eval              0.013064869
total_rewards                [2699.42816611 1222.20132363 2772.91826125 2785.61883157  118.23092954
 1702.04660164 1129.01841665  634.59467924  142.43857271  -44.14110322]
total_rewards_mean           1316.2354679112743
total_rewards_std            1073.0913172176186
total_rewards_max            2785.618831574092
total_rewards_min            -44.14110322497466
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               28.214889065828174
(Previous) Eval Time (s)     18.588782225269824
Sample Time (s)              18.44725735904649
Epoch Time (s)               65.25092865014449
Total Train Time (s)         19414.048739335965
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:39:06.064657 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #279 | Epoch Duration: 62.11488127708435
2020-01-11 08:39:06.064850 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.00324
Z variance train             0.013069252
KL Divergence                21.890858
KL Loss                      2.1890857
QF Loss                      1217.9052
VF Loss                      84.050476
Policy Loss                  -984.87854
Q Predictions Mean           981.9866
Q Predictions Std            238.74878
Q Predictions Max            1197.3895
Q Predictions Min            66.39337
V Predictions Mean           981.7793
V Predictions Std            233.32538
V Predictions Max            1187.1978
V Predictions Min            203.93323
Log Pis Mean                 -1.083596
Log Pis Std                  2.8087487
Log Pis Max                  9.799165
Log Pis Min                  -9.629069
Policy mu Mean               0.048304453
Policy mu Std                0.5501197
Policy mu Max                2.2579613
Policy mu Min                -1.7856241
Policy log std Mean          -0.91756916
Policy log std Std           0.2615818
Policy log std Max           -0.17663443
Policy log std Min           -2.2849445
Z mean eval                  0.9725062
Z variance eval              0.018030861
total_rewards                [2723.11805861 3019.20253593 2672.02604322  462.66381342 2682.74947059
 1213.52823829  346.92597061 2717.06575985 2751.31612838 2960.77607325]
total_rewards_mean           2154.93720921386
total_rewards_std            997.7839451072631
total_rewards_max            3019.2025359322497
total_rewards_min            346.9259706109066
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               28.39891829714179
(Previous) Eval Time (s)     15.452423000242561
Sample Time (s)              18.006762318313122
Epoch Time (s)               61.85810361569747
Total Train Time (s)         19482.796999422833
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:40:14.815767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #280 | Epoch Duration: 68.75079321861267
2020-01-11 08:40:14.815943 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97250384
Z variance train             0.018100059
KL Divergence                20.451563
KL Loss                      2.0451562
QF Loss                      965.86646
VF Loss                      180.21439
Policy Loss                  -999.5759
Q Predictions Mean           997.17175
Q Predictions Std            209.71596
Q Predictions Max            1215.5778
Q Predictions Min            186.88666
V Predictions Mean           991.49316
V Predictions Std            206.88573
V Predictions Max            1217.4894
V Predictions Min            196.11752
Log Pis Mean                 -0.5740268
Log Pis Std                  2.4754252
Log Pis Max                  12.710774
Log Pis Min                  -7.1575313
Policy mu Mean               0.0007742818
Policy mu Std                0.5809941
Policy mu Max                1.9940453
Policy mu Min                -3.5542603
Policy log std Mean          -0.91457456
Policy log std Std           0.25755316
Policy log std Max           -0.15064347
Policy log std Min           -2.531649
Z mean eval                  0.98456347
Z variance eval              0.01333523
total_rewards                [1498.73083882 2780.5673771  2743.59852653  188.36265347  585.94620545
   78.74244782  275.07372816 1795.6138714  1368.48739427  750.51643075]
total_rewards_mean           1206.5639473782646
total_rewards_std            952.2634908305721
total_rewards_max            2780.5673771045213
total_rewards_min            78.7424478171285
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               29.398831170983613
(Previous) Eval Time (s)     22.344789501279593
Sample Time (s)              18.054657140746713
Epoch Time (s)               69.79827781300992
Total Train Time (s)         19547.40380659001
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:19.425027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #281 | Epoch Duration: 64.60894560813904
2020-01-11 08:41:19.425210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98316395
Z variance train             0.013319841
KL Divergence                21.13892
KL Loss                      2.113892
QF Loss                      1097.8367
VF Loss                      170.1114
Policy Loss                  -977.745
Q Predictions Mean           976.5045
Q Predictions Std            240.53084
Q Predictions Max            1206.1165
Q Predictions Min            187.35388
V Predictions Mean           976.7007
V Predictions Std            235.86725
V Predictions Max            1196.5977
V Predictions Min            192.52643
Log Pis Mean                 -0.59395635
Log Pis Std                  2.5288472
Log Pis Max                  9.159933
Log Pis Min                  -7.7777705
Policy mu Mean               0.00093196565
Policy mu Std                0.57756716
Policy mu Max                2.3353224
Policy mu Min                -2.9391282
Policy log std Mean          -0.9078336
Policy log std Std           0.27221707
Policy log std Max           -0.24292979
Policy log std Min           -2.7346108
Z mean eval                  0.9891645
Z variance eval              0.012197351
total_rewards                [1429.48783107  536.21369272 1281.89997937  451.33097444 1222.97288966
 2085.95209523  632.17533606  206.5228879  2003.30347524  301.29791586]
total_rewards_mean           1015.1157077545179
total_rewards_std            653.1837587471001
total_rewards_max            2085.9520952292614
total_rewards_min            206.52288790371244
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               26.604722534306347
(Previous) Eval Time (s)     17.155190762598068
Sample Time (s)              17.677926021628082
Epoch Time (s)               61.4378393185325
Total Train Time (s)         19606.636247057468
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:42:18.664179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #282 | Epoch Duration: 59.23879361152649
2020-01-11 08:42:18.664454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98751765
Z variance train             0.012199576
KL Divergence                21.708883
KL Loss                      2.1708884
QF Loss                      785.8716
VF Loss                      142.16093
Policy Loss                  -985.7951
Q Predictions Mean           983.2407
Q Predictions Std            246.9486
Q Predictions Max            1244.2126
Q Predictions Min            189.71196
V Predictions Mean           984.02893
V Predictions Std            242.29588
V Predictions Max            1242.8679
V Predictions Min            204.53743
Log Pis Mean                 -0.928576
Log Pis Std                  2.4446416
Log Pis Max                  6.6338334
Log Pis Min                  -8.163437
Policy mu Mean               0.0046418835
Policy mu Std                0.5543156
Policy mu Max                2.0014572
Policy mu Min                -2.2173867
Policy log std Mean          -0.889307
Policy log std Std           0.257624
Policy log std Max           -0.16574174
Policy log std Min           -2.3974257
Z mean eval                  0.9948322
Z variance eval              0.012822755
total_rewards                [2699.70729982 1504.44859205 1762.67179006 2716.26600341 2432.39734827
  791.6969955   402.8677789  2604.73577124 1696.99249457 1024.48677434]
total_rewards_mean           1763.6270848152028
total_rewards_std            797.0408724686304
total_rewards_max            2716.2660034090477
total_rewards_min            402.8677789024126
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               30.072708372958004
(Previous) Eval Time (s)     14.955827474128455
Sample Time (s)              17.804980455432087
Epoch Time (s)               62.83351630251855
Total Train Time (s)         19677.204993563704
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:43:29.235173 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #283 | Epoch Duration: 70.57050085067749
2020-01-11 08:43:29.235417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9971854
Z variance train             0.012848785
KL Divergence                21.699654
KL Loss                      2.1699655
QF Loss                      898.6343
VF Loss                      163.88783
Policy Loss                  -994.92535
Q Predictions Mean           993.7029
Q Predictions Std            242.70284
Q Predictions Max            1226.5186
Q Predictions Min            153.05249
V Predictions Mean           993.5508
V Predictions Std            239.93051
V Predictions Max            1225.629
V Predictions Min            208.95844
Log Pis Mean                 -0.7192426
Log Pis Std                  2.4939601
Log Pis Max                  9.487399
Log Pis Min                  -7.852015
Policy mu Mean               0.044583343
Policy mu Std                0.5687089
Policy mu Max                2.0252037
Policy mu Min                -1.8942013
Policy log std Mean          -0.92668605
Policy log std Std           0.26300696
Policy log std Max           -0.022086322
Policy log std Min           -2.4736533
Z mean eval                  0.9706335
Z variance eval              0.008642638
total_rewards                [2467.80041285  587.95463136  882.19724784 2762.14012742  175.42332907
 2662.32534308 1958.09438381 2728.22393296 2816.90644963   32.81364111]
total_rewards_mean           1707.3879499120376
total_rewards_std            1096.5314031433863
total_rewards_max            2816.906449627369
total_rewards_min            32.813641114243815
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               27.451157657895237
(Previous) Eval Time (s)     22.692499585915357
Sample Time (s)              18.536211075261235
Epoch Time (s)               68.67986831907183
Total Train Time (s)         19742.32780171372
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:44:34.363958 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #284 | Epoch Duration: 65.12831902503967
2020-01-11 08:44:34.364282 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.970693
Z variance train             0.008618806
KL Divergence                22.765413
KL Loss                      2.2765415
QF Loss                      1331.8992
VF Loss                      155.51062
Policy Loss                  -992.31055
Q Predictions Mean           991.55927
Q Predictions Std            248.14049
Q Predictions Max            1234.3345
Q Predictions Min            -37.054924
V Predictions Mean           990.41516
V Predictions Std            242.96033
V Predictions Max            1228.0107
V Predictions Min            48.16532
Log Pis Mean                 -0.93615496
Log Pis Std                  2.3824651
Log Pis Max                  6.7202396
Log Pis Min                  -9.345359
Policy mu Mean               0.02586007
Policy mu Std                0.5279806
Policy mu Max                1.740595
Policy mu Min                -1.7286052
Policy log std Mean          -0.94259536
Policy log std Std           0.26272786
Policy log std Max           -0.25017303
Policy log std Min           -2.2158425
Z mean eval                  0.95114404
Z variance eval              0.017058374
total_rewards                [ 332.99439752 1642.49913357   27.070355   1077.52011488  309.80611934
 2739.95030839 1943.51510007  683.92907002 2839.34482115  279.96415068]
total_rewards_mean           1187.6593570613284
total_rewards_std            992.6580463874773
total_rewards_max            2839.3448211478626
total_rewards_min            27.07035500297172
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               27.93633846612647
(Previous) Eval Time (s)     19.14062048867345
Sample Time (s)              17.75099237728864
Epoch Time (s)               64.82795133208856
Total Train Time (s)         19800.618681967724
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:45:32.656063 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #285 | Epoch Duration: 58.29156565666199
2020-01-11 08:45:32.656238 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #285 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95248014
Z variance train             0.017053977
KL Divergence                21.107704
KL Loss                      2.1107705
QF Loss                      1206.1846
VF Loss                      140.18236
Policy Loss                  -992.99304
Q Predictions Mean           989.87305
Q Predictions Std            237.9048
Q Predictions Max            1223.4258
Q Predictions Min            163.29108
V Predictions Mean           988.4863
V Predictions Std            235.45836
V Predictions Max            1224.2012
V Predictions Min            177.5927
Log Pis Mean                 -0.81303906
Log Pis Std                  2.6881888
Log Pis Max                  7.3159285
Log Pis Min                  -11.50816
Policy mu Mean               0.04995314
Policy mu Std                0.5570719
Policy mu Max                2.3145258
Policy mu Min                -2.0927672
Policy log std Mean          -0.90815794
Policy log std Std           0.26572114
Policy log std Max           -0.087248385
Policy log std Min           -2.2150912
Z mean eval                  0.9889906
Z variance eval              0.019622155
total_rewards                [ 406.4961589  2735.2403834  2256.54527646 2681.63750842 2734.5834724
 2667.71993843 3003.22224094  419.0213502  2667.17918206 2885.03424668]
total_rewards_mean           2245.6679757892043
total_rewards_std            934.1614084381222
total_rewards_max            3003.2222409421006
total_rewards_min            406.496158900822
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               27.558294726070017
(Previous) Eval Time (s)     12.60396349336952
Sample Time (s)              17.731458948459476
Epoch Time (s)               57.89371716789901
Total Train Time (s)         19870.875338524114
Epoch                        286
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:46:42.916172 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #286 | Epoch Duration: 70.2597599029541
2020-01-11 08:46:42.916350 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #286 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98837614
Z variance train             0.01967522
KL Divergence                20.933096
KL Loss                      2.0933096
QF Loss                      719.3629
VF Loss                      447.44626
Policy Loss                  -1040.2999
Q Predictions Mean           1039.502
Q Predictions Std            205.80202
Q Predictions Max            1251.9819
Q Predictions Min            -20.169662
V Predictions Mean           1027.4536
V Predictions Std            203.28615
V Predictions Max            1228.1858
V Predictions Min            83.012344
Log Pis Mean                 -0.5114736
Log Pis Std                  2.63809
Log Pis Max                  10.702351
Log Pis Min                  -8.33171
Policy mu Mean               -0.004221846
Policy mu Std                0.56447
Policy mu Max                1.8380836
Policy mu Min                -2.8506522
Policy log std Mean          -0.97039473
Policy log std Std           0.27283934
Policy log std Max           -0.27633703
Policy log std Min           -2.8501194
Z mean eval                  0.9845462
Z variance eval              0.018725166
total_rewards                [2928.93013424 2720.69585193 1367.54376988 1497.81386086 2965.9145651
 2823.08764161  726.98358529 3161.61636713  894.99426944 3056.83636711]
total_rewards_mean           2214.4416412597975
total_rewards_std            921.5737459552788
total_rewards_max            3161.6163671322174
total_rewards_min            726.9835852940932
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               27.176779748871922
(Previous) Eval Time (s)     24.969716851133853
Sample Time (s)              17.410834246315062
Epoch Time (s)               69.55733084632084
Total Train Time (s)         19940.23902124772
Epoch                        287
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:47:52.281096 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #287 | Epoch Duration: 69.3646068572998
2020-01-11 08:47:52.281250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9850215
Z variance train             0.018688682
KL Divergence                20.70414
KL Loss                      2.070414
QF Loss                      709.7019
VF Loss                      108.89184
Policy Loss                  -979.53485
Q Predictions Mean           977.0354
Q Predictions Std            265.1939
Q Predictions Max            1191.0099
Q Predictions Min            49.783646
V Predictions Mean           979.60785
V Predictions Std            260.8798
V Predictions Max            1192.9882
V Predictions Min            153.99817
Log Pis Mean                 -0.7638339
Log Pis Std                  2.5294235
Log Pis Max                  12.705559
Log Pis Min                  -9.052983
Policy mu Mean               -0.027720567
Policy mu Std                0.57078594
Policy mu Max                2.1787262
Policy mu Min                -2.119836
Policy log std Mean          -0.92665136
Policy log std Std           0.27204382
Policy log std Max           -0.25070179
Policy log std Min           -2.7723763
Z mean eval                  0.9585146
Z variance eval              0.01313054
total_rewards                [ 173.46733619 2711.57495616 3093.06830189  637.65057556 2832.87590981
 2417.67244897 1631.93738465 2896.83091811 2857.00666904 2813.49608625]
total_rewards_mean           2206.558058663878
total_rewards_std            983.4041434954028
total_rewards_max            3093.068301885775
total_rewards_min            173.46733619451743
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               28.780223749112338
(Previous) Eval Time (s)     24.776719061192125
Sample Time (s)              17.826332496013492
Epoch Time (s)               71.38327530631796
Total Train Time (s)         20010.33339024894
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:02.379807 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #288 | Epoch Duration: 70.09841060638428
2020-01-11 08:49:02.380007 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #288 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.95845044
Z variance train             0.013111906
KL Divergence                20.81727
KL Loss                      2.081727
QF Loss                      646.1208
VF Loss                      200.48392
Policy Loss                  -996.09894
Q Predictions Mean           995.6133
Q Predictions Std            244.66774
Q Predictions Max            1224.1925
Q Predictions Min            196.79826
V Predictions Mean           995.9641
V Predictions Std            244.56224
V Predictions Max            1207.1105
V Predictions Min            197.73965
Log Pis Mean                 -0.7080251
Log Pis Std                  2.7925863
Log Pis Max                  9.470972
Log Pis Min                  -9.027713
Policy mu Mean               -0.031487748
Policy mu Std                0.5478889
Policy mu Max                1.9953502
Policy mu Min                -2.0607772
Policy log std Mean          -0.9604434
Policy log std Std           0.27524307
Policy log std Max           -0.18056703
Policy log std Min           -2.6511383
Z mean eval                  0.9918542
Z variance eval              0.015914151
total_rewards                [ 175.1280809  2916.09860516 2658.63312517 2514.3688019  2824.065807
  996.62272491 2117.53112209 2317.38034675 2749.10655149 2044.71302201]
total_rewards_mean           2131.3648187370677
total_rewards_std            840.1639135807231
total_rewards_max            2916.098605160666
total_rewards_min            175.12808090034164
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               28.847811996005476
(Previous) Eval Time (s)     23.49155746260658
Sample Time (s)              17.597696573473513
Epoch Time (s)               69.93706603208557
Total Train Time (s)         20079.25471341377
Epoch                        289
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:50:11.305794 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #289 | Epoch Duration: 68.92560172080994
2020-01-11 08:50:11.306083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9934894
Z variance train             0.015923847
KL Divergence                20.458597
KL Loss                      2.0458598
QF Loss                      1241.4775
VF Loss                      183.3079
Policy Loss                  -1010.36523
Q Predictions Mean           1007.79565
Q Predictions Std            217.00061
Q Predictions Max            1220.8066
Q Predictions Min            178.89714
V Predictions Mean           1007.571
V Predictions Std            216.96475
V Predictions Max            1218.4756
V Predictions Min            151.69254
Log Pis Mean                 -0.51056874
Log Pis Std                  2.7699246
Log Pis Max                  11.811334
Log Pis Min                  -8.23887
Policy mu Mean               0.019389648
Policy mu Std                0.5457267
Policy mu Max                3.127679
Policy mu Min                -2.108801
Policy log std Mean          -0.9753953
Policy log std Std           0.26657647
Policy log std Max           -0.099070966
Policy log std Min           -2.4155777
Z mean eval                  0.96355516
Z variance eval              0.015808854
total_rewards                [ -68.9823651   460.16492087 2655.48731578 2951.56464719  783.13901203
 2949.71229195  862.86310531 2528.00028379 2807.94684815 2675.23755519]
total_rewards_mean           1860.5133615153204
total_rewards_std            1133.8274276808754
total_rewards_max            2951.564647191349
total_rewards_min            -68.98236510066928
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               26.626282849814743
(Previous) Eval Time (s)     22.47982009127736
Sample Time (s)              17.621487942989916
Epoch Time (s)               66.72759088408202
Total Train Time (s)         20144.424559214152
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:51:16.477759 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #290 | Epoch Duration: 65.17147517204285
2020-01-11 08:51:16.477952 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9626733
Z variance train             0.015825724
KL Divergence                20.707602
KL Loss                      2.0707603
QF Loss                      2185.0244
VF Loss                      194.93944
Policy Loss                  -1025.5912
Q Predictions Mean           1024.2404
Q Predictions Std            189.85712
Q Predictions Max            1208.8654
Q Predictions Min            184.60144
V Predictions Mean           1028.6564
V Predictions Std            187.37125
V Predictions Max            1213.5773
V Predictions Min            196.70107
Log Pis Mean                 -0.4822239
Log Pis Std                  2.6981933
Log Pis Max                  16.139519
Log Pis Min                  -6.839864
Policy mu Mean               0.039995044
Policy mu Std                0.5623378
Policy mu Max                3.024603
Policy mu Min                -2.620271
Policy log std Mean          -0.9427496
Policy log std Std           0.25161842
Policy log std Max           -0.24505255
Policy log std Min           -2.473021
Z mean eval                  0.9883525
Z variance eval              0.022509474
total_rewards                [  -8.47007751 1791.93701403  884.84843609 2841.53444638 2704.59417001
 2883.44003365 2845.76471514 1144.46259465  632.74019097 2950.6745771 ]
total_rewards_mean           1867.1526100516032
total_rewards_std            1065.3574134016267
total_rewards_max            2950.6745771025962
total_rewards_min            -8.470077514965151
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               28.75298480130732
(Previous) Eval Time (s)     20.923448436893523
Sample Time (s)              19.132541581522673
Epoch Time (s)               68.80897481972352
Total Train Time (s)         20209.910300896503
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:21.965794 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #291 | Epoch Duration: 65.48771262168884
2020-01-11 08:52:21.965973 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98841065
Z variance train             0.022491682
KL Divergence                20.451347
KL Loss                      2.0451348
QF Loss                      674.43176
VF Loss                      130.64
Policy Loss                  -1003.15424
Q Predictions Mean           1001.9164
Q Predictions Std            240.91226
Q Predictions Max            1231.6685
Q Predictions Min            174.65114
V Predictions Mean           996.5497
V Predictions Std            237.06786
V Predictions Max            1228.6523
V Predictions Min            177.61948
Log Pis Mean                 -0.57096475
Log Pis Std                  2.566654
Log Pis Max                  7.6027565
Log Pis Min                  -8.184429
Policy mu Mean               0.055970725
Policy mu Std                0.5325196
Policy mu Max                2.0776591
Policy mu Min                -1.9488724
Policy log std Mean          -0.9462828
Policy log std Std           0.26630655
Policy log std Max           -0.22602636
Policy log std Min           -2.255158
Z mean eval                  1.0062072
Z variance eval              0.018455029
total_rewards                [2652.67525419 1418.48994409  360.73408203 2749.02153333 2762.89996925
 2785.15988748 2750.59822665 2785.13683016 2532.12198297 2802.60331712]
total_rewards_mean           2359.9441027270273
total_rewards_std            776.0427314418394
total_rewards_max            2802.603317123706
total_rewards_min            360.7340820271248
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               25.911016115918756
(Previous) Eval Time (s)     17.601829512044787
Sample Time (s)              18.252729852683842
Epoch Time (s)               61.765575480647385
Total Train Time (s)         20276.338876459282
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:53:28.397927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #292 | Epoch Duration: 66.43180418014526
2020-01-11 08:53:28.398133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0068252
Z variance train             0.018499652
KL Divergence                20.740566
KL Loss                      2.0740566
QF Loss                      3644.1084
VF Loss                      913.843
Policy Loss                  -1040.1288
Q Predictions Mean           1038.3839
Q Predictions Std            222.88094
Q Predictions Max            1235.9335
Q Predictions Min            192.49425
V Predictions Mean           1030.4087
V Predictions Std            218.46826
V Predictions Max            1222.0157
V Predictions Min            182.03763
Log Pis Mean                 -0.66768134
Log Pis Std                  2.60504
Log Pis Max                  10.854344
Log Pis Min                  -9.150272
Policy mu Mean               0.0466723
Policy mu Std                0.56529564
Policy mu Max                2.17443
Policy mu Min                -2.6273994
Policy log std Mean          -0.9448849
Policy log std Std           0.2845296
Policy log std Max           -0.18558556
Policy log std Min           -2.975766
Z mean eval                  0.9796325
Z variance eval              0.015150445
total_rewards                [ 569.80748132  623.33920323  152.53973074  750.27249412 2531.67834375
 2627.67182987  458.16253188 2731.16781594 1825.35656875  830.08686451]
total_rewards_mean           1310.00828641145
total_rewards_std            956.1594134945669
total_rewards_max            2731.1678159407156
total_rewards_min            152.53973073905468
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               31.104777714703232
(Previous) Eval Time (s)     22.26776241278276
Sample Time (s)              17.60227844817564
Epoch Time (s)               70.97481857566163
Total Train Time (s)         20338.26529416954
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:54:30.329960 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #293 | Epoch Duration: 61.93164253234863
2020-01-11 08:54:30.330228 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9791769
Z variance train             0.01514214
KL Divergence                20.034925
KL Loss                      2.0034926
QF Loss                      719.5033
VF Loss                      115.81386
Policy Loss                  -1003.71356
Q Predictions Mean           1002.64636
Q Predictions Std            243.11014
Q Predictions Max            1273.7958
Q Predictions Min            181.99736
V Predictions Mean           1003.2544
V Predictions Std            243.20854
V Predictions Max            1273.9158
V Predictions Min            174.48927
Log Pis Mean                 -0.6012325
Log Pis Std                  2.9178607
Log Pis Max                  19.126907
Log Pis Min                  -6.6868396
Policy mu Mean               0.04281719
Policy mu Std                0.5643686
Policy mu Max                3.366173
Policy mu Min                -4.378579
Policy log std Mean          -0.9440088
Policy log std Std           0.28387585
Policy log std Max           -0.23371673
Policy log std Min           -2.8292577
Z mean eval                  1.012339
Z variance eval              0.014743145
total_rewards                [ 752.7806644  2807.67197286 2434.34237801 1122.35859333 2753.14999045
 1268.64485868  124.50133193 2306.98728434  991.25512423  694.38750721]
total_rewards_mean           1525.6079705443694
total_rewards_std            913.912564417465
total_rewards_max            2807.671972863221
total_rewards_min            124.50133193252728
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               28.249680125620216
(Previous) Eval Time (s)     13.224280964583158
Sample Time (s)              17.689317076466978
Epoch Time (s)               59.16327816667035
Total Train Time (s)         20401.578219010495
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:55:33.646450 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #294 | Epoch Duration: 63.31600499153137
2020-01-11 08:55:33.646701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #294 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.014199
Z variance train             0.014645775
KL Divergence                20.644096
KL Loss                      2.0644097
QF Loss                      643.27844
VF Loss                      231.60207
Policy Loss                  -1070.6542
Q Predictions Mean           1068.0854
Q Predictions Std            197.62715
Q Predictions Max            1278.5927
Q Predictions Min            -62.931873
V Predictions Mean           1058.1372
V Predictions Std            188.49379
V Predictions Max            1256.3541
V Predictions Min            -3.317434
Log Pis Mean                 -0.2672299
Log Pis Std                  2.830993
Log Pis Max                  20.9891
Log Pis Min                  -6.8864107
Policy mu Mean               0.023029428
Policy mu Std                0.6090449
Policy mu Max                2.054446
Policy mu Min                -3.196817
Policy log std Mean          -0.9357914
Policy log std Std           0.24300279
Policy log std Max           -0.22364318
Policy log std Min           -2.6083837
Z mean eval                  0.98116094
Z variance eval              0.020908691
total_rewards                [2915.35188468  952.37607084 3183.16685483 3274.68853424  126.14950054
 2193.17668745 2794.66449498 3129.51198426 3058.74375515 2227.876807  ]
total_rewards_mean           2385.570657397904
total_rewards_std            1005.0990202098066
total_rewards_max            3274.688534243922
total_rewards_min            126.14950054189484
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               31.445467167999595
(Previous) Eval Time (s)     17.376690763048828
Sample Time (s)              17.398818348534405
Epoch Time (s)               66.22097627958283
Total Train Time (s)         20476.63697717944
Epoch                        295
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:56:48.707194 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #295 | Epoch Duration: 75.06030321121216
2020-01-11 08:56:48.707367 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98099434
Z variance train             0.020935306
KL Divergence                20.43367
KL Loss                      2.0433671
QF Loss                      1733.4856
VF Loss                      303.79425
Policy Loss                  -1009.3521
Q Predictions Mean           1008.0818
Q Predictions Std            271.49478
Q Predictions Max            1240.0647
Q Predictions Min            9.2720785
V Predictions Mean           998.53613
V Predictions Std            265.36163
V Predictions Max            1226.1014
V Predictions Min            159.82417
Log Pis Mean                 -0.6731702
Log Pis Std                  2.4474409
Log Pis Max                  10.403327
Log Pis Min                  -7.7080727
Policy mu Mean               0.0019396106
Policy mu Std                0.5173705
Policy mu Max                1.692059
Policy mu Min                -1.8655103
Policy log std Mean          -0.9721993
Policy log std Std           0.30363813
Policy log std Max           -0.13763654
Policy log std Min           -2.708753
Z mean eval                  1.0203621
Z variance eval              0.015834445
total_rewards                [  74.44250899 2597.50346452 3093.62722267 2657.71473621 2312.02586743
  414.22663678  405.31989716  109.45159763 2068.16369417 1633.15588055]
total_rewards_mean           1536.563150611233
total_rewards_std            1114.1853604634698
total_rewards_max            3093.6272226703495
total_rewards_min            74.44250898974366
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               28.72117742104456
(Previous) Eval Time (s)     26.215742751024663
Sample Time (s)              18.446811047382653
Epoch Time (s)               73.38373121945187
Total Train Time (s)         20543.16864346806
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:57:55.243741 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #296 | Epoch Duration: 66.53622388839722
2020-01-11 08:57:55.243965 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0218171
Z variance train             0.01584483
KL Divergence                21.281424
KL Loss                      2.1281424
QF Loss                      7941.8164
VF Loss                      255.9177
Policy Loss                  -1013.5749
Q Predictions Mean           1015.9099
Q Predictions Std            253.49915
Q Predictions Max            1254.2598
Q Predictions Min            -14.918844
V Predictions Mean           1024.1212
V Predictions Std            251.16422
V Predictions Max            1260.8378
V Predictions Min            5.0513434
Log Pis Mean                 -0.8360374
Log Pis Std                  2.7956026
Log Pis Max                  11.445609
Log Pis Min                  -11.703376
Policy mu Mean               0.028285515
Policy mu Std                0.5517872
Policy mu Max                2.0793483
Policy mu Min                -2.085218
Policy log std Mean          -0.92284966
Policy log std Std           0.26031077
Policy log std Max           -0.18233222
Policy log std Min           -2.215471
Z mean eval                  1.0061617
Z variance eval              0.013323833
total_rewards                [3093.43755615 2886.20232327 2423.96372768 2729.14742816 2844.77289667
  533.5924521  2641.8788851  1864.05170912 2341.85772469 2956.88990029]
total_rewards_mean           2431.579460322486
total_rewards_std            718.1045136517845
total_rewards_max            3093.437556152457
total_rewards_min            533.5924520962541
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               28.527733487077057
(Previous) Eval Time (s)     19.367927559651434
Sample Time (s)              18.35458673769608
Epoch Time (s)               66.25024778442457
Total Train Time (s)         20615.036079605576
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:59:07.112403 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #297 | Epoch Duration: 71.86828088760376
2020-01-11 08:59:07.112610 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0061135
Z variance train             0.013313946
KL Divergence                21.242277
KL Loss                      2.1242278
QF Loss                      1160.8334
VF Loss                      141.23807
Policy Loss                  -1052.7239
Q Predictions Mean           1048.9817
Q Predictions Std            197.95969
Q Predictions Max            1260.3365
Q Predictions Min            45.098785
V Predictions Mean           1059.7166
V Predictions Std            194.4307
V Predictions Max            1254.0142
V Predictions Min            191.63202
Log Pis Mean                 -0.2333852
Log Pis Std                  2.614247
Log Pis Max                  13.2809105
Log Pis Min                  -8.200191
Policy mu Mean               -0.0016814738
Policy mu Std                0.5642091
Policy mu Max                1.974562
Policy mu Min                -2.044259
Policy log std Mean          -0.9796079
Policy log std Std           0.28237224
Policy log std Max           -0.17808956
Policy log std Min           -2.9520044
Z mean eval                  1.0069494
Z variance eval              0.025677016
total_rewards                [2912.43392646 2805.28728411 2876.39001051 3021.71382266  431.75149965
    5.85752725 2708.58110965  710.81308168 2995.0803427  2854.3674384 ]
total_rewards_mean           2132.2276043069774
total_rewards_std            1159.2396965549456
total_rewards_max            3021.713822661875
total_rewards_min            5.857527246786799
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               28.183228339999914
(Previous) Eval Time (s)     24.985637047793716
Sample Time (s)              17.3959924983792
Epoch Time (s)               70.56485788617283
Total Train Time (s)         20683.694337628316
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:15.777619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #298 | Epoch Duration: 68.66482782363892
2020-01-11 09:00:15.777911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #298 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0057617
Z variance train             0.025836026
KL Divergence                19.829573
KL Loss                      1.9829572
QF Loss                      4567.0127
VF Loss                      189.60066
Policy Loss                  -1033.5544
Q Predictions Mean           1030.2817
Q Predictions Std            235.61568
Q Predictions Max            1201.6774
Q Predictions Min            172.0043
V Predictions Mean           1037.1929
V Predictions Std            235.4988
V Predictions Max            1207.4465
V Predictions Min            170.61995
Log Pis Mean                 -0.60154045
Log Pis Std                  2.630797
Log Pis Max                  8.961423
Log Pis Min                  -8.553708
Policy mu Mean               0.045447223
Policy mu Std                0.5616901
Policy mu Max                1.9632881
Policy mu Min                -2.4202948
Policy log std Mean          -0.94319475
Policy log std Std           0.26335096
Policy log std Max           -0.1349113
Policy log std Min           -2.056931
Z mean eval                  0.99307954
Z variance eval              0.020947676
total_rewards                [2790.10892499 2693.53489233 1688.2942517  2959.65491308 2990.93220755
 2770.01966561 2887.01168752 2141.37762698 2852.43866473 2651.29056886]
total_rewards_mean           2642.4663403352915
total_rewards_std            390.9240560678031
total_rewards_max            2990.932207551882
total_rewards_min            1688.294251700738
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               28.33671235991642
(Previous) Eval Time (s)     23.085308710113168
Sample Time (s)              17.737847020849586
Epoch Time (s)               69.15986809087917
Total Train Time (s)         20756.971401505172
Epoch                        299
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:01:29.056998 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #299 | Epoch Duration: 73.27887082099915
2020-01-11 09:01:29.057207 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9926506
Z variance train             0.021014784
KL Divergence                20.328236
KL Loss                      2.0328236
QF Loss                      1622.7433
VF Loss                      249.09515
Policy Loss                  -1053.3785
Q Predictions Mean           1052.5216
Q Predictions Std            237.02556
Q Predictions Max            1274.7701
Q Predictions Min            74.2307
V Predictions Mean           1055.4099
V Predictions Std            234.5965
V Predictions Max            1267.1003
V Predictions Min            81.902725
Log Pis Mean                 -0.40585116
Log Pis Std                  2.6753666
Log Pis Max                  9.8624325
Log Pis Min                  -9.818968
Policy mu Mean               0.0047626486
Policy mu Std                0.56891555
Policy mu Max                2.0737352
Policy mu Min                -2.6034935
Policy log std Mean          -0.95753485
Policy log std Std           0.2792751
Policy log std Max           -0.26344126
Policy log std Min           -2.6404853
Z mean eval                  0.98853046
Z variance eval              0.030718114
total_rewards                [2397.30429474 2986.10400615 2873.76965494 1066.81986145 3036.15833092
 3031.8148493  2815.58087241  818.39795359 2834.53814709 3062.92445615]
total_rewards_mean           2492.34124267447
total_rewards_std            797.8994451665416
total_rewards_max            3062.924456145404
total_rewards_min            818.3979535923171
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               27.884153217077255
(Previous) Eval Time (s)     27.20401699002832
Sample Time (s)              18.392523063346744
Epoch Time (s)               73.48069327045232
Total Train Time (s)         20826.045789769385
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:02:38.138766 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #300 | Epoch Duration: 69.08136248588562
2020-01-11 09:02:38.139066 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98808277
Z variance train             0.03067493
KL Divergence                19.887707
KL Loss                      1.9887707
QF Loss                      584.20355
VF Loss                      100.844185
Policy Loss                  -1036.4213
Q Predictions Mean           1035.9457
Q Predictions Std            216.26062
Q Predictions Max            1303.0645
Q Predictions Min            168.20717
V Predictions Mean           1031.2152
V Predictions Std            213.4179
V Predictions Max            1285.3353
V Predictions Min            167.57693
Log Pis Mean                 -0.33005565
Log Pis Std                  2.8552094
Log Pis Max                  11.172192
Log Pis Min                  -6.9492397
Policy mu Mean               0.037132524
Policy mu Std                0.56902117
Policy mu Max                2.2893949
Policy mu Min                -1.946026
Policy log std Mean          -0.9851533
Policy log std Std           0.27211595
Policy log std Max           -0.14332122
Policy log std Min           -2.296825
Z mean eval                  0.9663043
Z variance eval              0.023973797
total_rewards                [2067.96754229 2763.02919031 1265.1095861    95.29481099 2754.51933991
  577.25960303  169.14326372 2962.73205621 2154.97005989  239.45896939]
total_rewards_mean           1504.9484421844404
total_rewards_std            1109.0508542352488
total_rewards_max            2962.7320562055716
total_rewards_min            95.2948109931715
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               29.425149991177022
(Previous) Eval Time (s)     22.80436234967783
Sample Time (s)              17.870709882117808
Epoch Time (s)               70.10022222297266
Total Train Time (s)         20887.91647733096
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:40.011522 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #301 | Epoch Duration: 61.87222599983215
2020-01-11 09:03:40.011734 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #301 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9668237
Z variance train             0.024052186
KL Divergence                20.100212
KL Loss                      2.0100212
QF Loss                      911.77014
VF Loss                      93.012665
Policy Loss                  -1084.4312
Q Predictions Mean           1085.2336
Q Predictions Std            195.27063
Q Predictions Max            1307.8561
Q Predictions Min            150.87776
V Predictions Mean           1081.7743
V Predictions Std            192.38812
V Predictions Max            1290.2275
V Predictions Min            145.37112
Log Pis Mean                 -0.6295414
Log Pis Std                  2.7149692
Log Pis Max                  7.3654737
Log Pis Min                  -8.132061
Policy mu Mean               0.033812556
Policy mu Std                0.6035768
Policy mu Max                2.1058316
Policy mu Min                -2.715131
Policy log std Mean          -0.9195733
Policy log std Std           0.2389767
Policy log std Max           -0.17569554
Policy log std Min           -1.9084489
Z mean eval                  0.97807866
Z variance eval              0.023461908
total_rewards                [ 273.85611612  485.3184871  2580.80407028    7.21649025  683.67451132
  448.19827746 3150.05712265 1785.83711689 2873.08909021 2039.95626073]
total_rewards_mean           1432.8007543011875
total_rewards_std            1124.2055862362092
total_rewards_max            3150.0571226503585
total_rewards_min            7.21649025136494
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               26.48399672936648
(Previous) Eval Time (s)     14.576075269840658
Sample Time (s)              18.115101367700845
Epoch Time (s)               59.175173366907984
Total Train Time (s)         20947.871640178375
Epoch                        302
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:04:39.971994 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #302 | Epoch Duration: 59.95994424819946
2020-01-11 09:04:39.972248 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9773372
Z variance train             0.023382917
KL Divergence                19.3237
KL Loss                      1.9323701
QF Loss                      1150.8115
VF Loss                      302.50897
Policy Loss                  -1032.224
Q Predictions Mean           1030.9424
Q Predictions Std            245.8133
Q Predictions Max            1226.1471
Q Predictions Min            37.185295
V Predictions Mean           1046.2551
V Predictions Std            246.69434
V Predictions Max            1250.4598
V Predictions Min            38.397957
Log Pis Mean                 -0.7324753
Log Pis Std                  2.5872047
Log Pis Max                  9.286767
Log Pis Min                  -7.519699
Policy mu Mean               0.016574968
Policy mu Std                0.5395583
Policy mu Max                2.217634
Policy mu Min                -2.4487972
Policy log std Mean          -0.9573746
Policy log std Std           0.27179262
Policy log std Max           -0.19288945
Policy log std Min           -2.5444453
Z mean eval                  0.9738925
Z variance eval              0.026530767
total_rewards                [2496.81504488 2833.67125659 2049.54822297 1551.68855328 2668.10659036
 2736.73910795 2659.84603171 2662.87573502 2622.02643641 2639.25757845]
total_rewards_mean           2492.057455762021
total_rewards_std            371.9657012344663
total_rewards_max            2833.6712565869975
total_rewards_min            1551.6885532775516
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               28.283010341227055
(Previous) Eval Time (s)     15.360579940024763
Sample Time (s)              17.332224453333765
Epoch Time (s)               60.97581473458558
Total Train Time (s)         21020.24897094723
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:05:52.354235 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #303 | Epoch Duration: 72.38176846504211
2020-01-11 09:05:52.354545 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #303 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9748564
Z variance train             0.026517471
KL Divergence                19.451626
KL Loss                      1.9451627
QF Loss                      890.87646
VF Loss                      199.21815
Policy Loss                  -1040.8842
Q Predictions Mean           1036.7302
Q Predictions Std            228.52597
Q Predictions Max            1249.9775
Q Predictions Min            -7.068587
V Predictions Mean           1049.4438
V Predictions Std            226.6762
V Predictions Max            1255.1283
V Predictions Min            -17.287848
Log Pis Mean                 -0.42143223
Log Pis Std                  2.5535932
Log Pis Max                  6.882023
Log Pis Min                  -8.06723
Policy mu Mean               0.10246697
Policy mu Std                0.5665942
Policy mu Max                2.159653
Policy mu Min                -2.1354103
Policy log std Mean          -0.96956456
Policy log std Std           0.2745529
Policy log std Max           -0.21829695
Policy log std Min           -2.2841036
Z mean eval                  0.99834573
Z variance eval              0.026705569
total_rewards                [2971.83478853 1021.27003757 3027.99202226  714.20113987 2813.19260475
 1287.36476476  164.15476974  807.66304678  -73.64639371  926.07614781]
total_rewards_mean           1366.010292836647
total_rewards_std            1095.78465635753
total_rewards_max            3027.9920222627043
total_rewards_min            -73.64639371392383
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               29.291408041957766
(Previous) Eval Time (s)     26.766230867709965
Sample Time (s)              18.656755515839905
Epoch Time (s)               74.71439442550763
Total Train Time (s)         21085.895788887516
Epoch                        304
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:06:58.004226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #304 | Epoch Duration: 65.6494402885437
2020-01-11 09:06:58.004445 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0001984
Z variance train             0.026716804
KL Divergence                19.539986
KL Loss                      1.9539986
QF Loss                      917.94727
VF Loss                      434.02164
Policy Loss                  -1008.2492
Q Predictions Mean           1008.3783
Q Predictions Std            267.87622
Q Predictions Max            1254.4891
Q Predictions Min            75.094124
V Predictions Mean           1005.18146
V Predictions Std            266.46893
V Predictions Max            1250.1052
V Predictions Min            53.59222
Log Pis Mean                 -0.9320471
Log Pis Std                  2.9036002
Log Pis Max                  9.770605
Log Pis Min                  -10.581258
Policy mu Mean               0.01932251
Policy mu Std                0.561569
Policy mu Max                2.1387355
Policy mu Min                -2.1742446
Policy log std Mean          -0.9176662
Policy log std Std           0.2960008
Policy log std Max           -0.14139885
Policy log std Min           -2.5208669
Z mean eval                  1.0081497
Z variance eval              0.017283274
total_rewards                [ 905.6870811   204.44272999 2903.05751898  286.17725739 1480.46565143
 2659.90401279  504.34631348  306.46171885 2727.98586275  410.91454017]
total_rewards_mean           1238.9442686947696
total_rewards_std            1060.5558358062733
total_rewards_max            2903.057518978202
total_rewards_min            204.4427299897942
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               30.797388850711286
(Previous) Eval Time (s)     17.700955886859447
Sample Time (s)              17.230112145189196
Epoch Time (s)               65.72845688275993
Total Train Time (s)         21148.273979478516
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:00.385921 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #305 | Epoch Duration: 62.38131403923035
2020-01-11 09:08:00.386120 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #305 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0068719
Z variance train             0.017299287
KL Divergence                20.407143
KL Loss                      2.0407143
QF Loss                      1375.2338
VF Loss                      195.81284
Policy Loss                  -1057.4172
Q Predictions Mean           1054.9971
Q Predictions Std            228.2878
Q Predictions Max            1260.2094
Q Predictions Min            -28.397121
V Predictions Mean           1063.0122
V Predictions Std            226.18924
V Predictions Max            1255.0864
V Predictions Min            16.330431
Log Pis Mean                 -0.33964083
Log Pis Std                  2.5071208
Log Pis Max                  7.1939316
Log Pis Min                  -6.9316354
Policy mu Mean               0.044372175
Policy mu Std                0.5349126
Policy mu Max                2.0193293
Policy mu Min                -1.8697464
Policy log std Mean          -0.99112225
Policy log std Std           0.27059308
Policy log std Max           -0.23299927
Policy log std Min           -2.2806473
Z mean eval                  1.0195557
Z variance eval              0.02092285
total_rewards                [ 357.14100575 2604.93782599  612.80841893 2744.725734   2819.8178194
   83.04225197  496.83013617  957.09886351 2297.78433928 2904.0830428 ]
total_rewards_mean           1587.8269437791964
total_rewards_std            1115.5724276261722
total_rewards_max            2904.0830428016925
total_rewards_min            83.04225196505193
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               30.022724030073732
(Previous) Eval Time (s)     14.35351020982489
Sample Time (s)              17.63049224158749
Epoch Time (s)               62.00672648148611
Total Train Time (s)         21215.486346770544
Epoch                        306
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:09:07.603767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #306 | Epoch Duration: 67.21745729446411
2020-01-11 09:09:07.604092 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0217844
Z variance train             0.020969925
KL Divergence                20.145203
KL Loss                      2.0145204
QF Loss                      923.868
VF Loss                      431.26752
Policy Loss                  -1053.7152
Q Predictions Mean           1054.4565
Q Predictions Std            218.00517
Q Predictions Max            1255.0039
Q Predictions Min            59.956005
V Predictions Mean           1061.3998
V Predictions Std            217.06105
V Predictions Max            1267.7164
V Predictions Min            172.23132
Log Pis Mean                 -0.5588993
Log Pis Std                  2.7477708
Log Pis Max                  10.633938
Log Pis Min                  -7.860686
Policy mu Mean               0.021653915
Policy mu Std                0.57688785
Policy mu Max                2.3648608
Policy mu Min                -1.7907964
Policy log std Mean          -0.9512547
Policy log std Std           0.2965987
Policy log std Max           -0.21922368
Policy log std Min           -2.938651
Z mean eval                  0.97390306
Z variance eval              0.03262391
total_rewards                [1622.86560642 3050.67340109 2044.54994303  378.40473728 2930.88701872
 3149.1042869   518.64531108 2478.46880763 1241.74614027 2882.25631506]
total_rewards_mean           2029.76015674847
total_rewards_std            991.5898703640505
total_rewards_max            3149.10428689897
total_rewards_min            378.4047372784942
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               30.678619049023837
(Previous) Eval Time (s)     19.56393198762089
Sample Time (s)              17.92216497566551
Epoch Time (s)               68.16471601231024
Total Train Time (s)         21282.61849936424
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:10:14.740514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #307 | Epoch Duration: 67.13618874549866
2020-01-11 09:10:14.740745 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9744889
Z variance train             0.032605015
KL Divergence                19.692396
KL Loss                      1.9692396
QF Loss                      2277.3997
VF Loss                      248.07684
Policy Loss                  -1035.1415
Q Predictions Mean           1034.3914
Q Predictions Std            264.2236
Q Predictions Max            1316.9464
Q Predictions Min            163.7661
V Predictions Mean           1030.8706
V Predictions Std            261.74542
V Predictions Max            1317.1694
V Predictions Min            162.8198
Log Pis Mean                 -0.022179686
Log Pis Std                  2.9477115
Log Pis Max                  18.182037
Log Pis Min                  -7.305978
Policy mu Mean               0.035587147
Policy mu Std                0.59914905
Policy mu Max                2.2279582
Policy mu Min                -2.7574012
Policy log std Mean          -0.9607788
Policy log std Std           0.26507685
Policy log std Max           -0.25102645
Policy log std Min           -2.2056317
Z mean eval                  1.0123551
Z variance eval              0.03401237
total_rewards                [2632.96351506 2091.61993651  318.4116312  2708.03420312 2688.24788185
  936.13642488 2793.66799518 1217.33618456  609.58635514 2717.33159822]
total_rewards_mean           1871.333572571625
total_rewards_std            941.7173417254581
total_rewards_max            2793.6679951784154
total_rewards_min            318.41163120262814
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               28.473962591961026
(Previous) Eval Time (s)     18.53511200286448
Sample Time (s)              18.390847377479076
Epoch Time (s)               65.39992197230458
Total Train Time (s)         21349.180088550318
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:11:21.309024 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #308 | Epoch Duration: 66.56806707382202
2020-01-11 09:11:21.309304 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #308 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0128176
Z variance train             0.034120187
KL Divergence                19.474382
KL Loss                      1.9474382
QF Loss                      526.2445
VF Loss                      68.427826
Policy Loss                  -1055.6942
Q Predictions Mean           1056.9686
Q Predictions Std            244.31229
Q Predictions Max            1256.946
Q Predictions Min            176.80331
V Predictions Mean           1055.5361
V Predictions Std            243.7173
V Predictions Max            1251.9637
V Predictions Min            156.54538
Log Pis Mean                 -0.6904525
Log Pis Std                  2.4308412
Log Pis Max                  6.5655975
Log Pis Min                  -8.058447
Policy mu Mean               0.05097173
Policy mu Std                0.56259215
Policy mu Max                2.2043304
Policy mu Min                -2.1036327
Policy log std Mean          -0.94507945
Policy log std Std           0.25678396
Policy log std Max           -0.16305715
Policy log std Min           -1.950237
Z mean eval                  0.98297226
Z variance eval              0.036143783
total_rewards                [2670.80484494 2935.71669101 2972.33166543  235.99731055  197.49070248
 2057.74673683 1192.81849069 3112.84178125 2999.54596498 2873.89337288]
total_rewards_mean           2124.918756104404
total_rewards_std            1101.4421138287184
total_rewards_max            3112.8417812532275
total_rewards_min            197.49070248301607
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               28.8198460964486
(Previous) Eval Time (s)     19.702971911989152
Sample Time (s)              18.379524159710854
Epoch Time (s)               66.9023421681486
Total Train Time (s)         21415.855576032307
Epoch                        309
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:12:27.984732 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #309 | Epoch Duration: 66.67521238327026
2020-01-11 09:12:27.984918 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #309 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98296916
Z variance train             0.03606073
KL Divergence                19.34702
KL Loss                      1.9347019
QF Loss                      495.4521
VF Loss                      134.56197
Policy Loss                  -1050.15
Q Predictions Mean           1049.1448
Q Predictions Std            260.22656
Q Predictions Max            1283.812
Q Predictions Min            140.66919
V Predictions Mean           1056.9084
V Predictions Std            260.60306
V Predictions Max            1286.3862
V Predictions Min            154.43176
Log Pis Mean                 -0.53169197
Log Pis Std                  2.624324
Log Pis Max                  10.853621
Log Pis Min                  -7.913077
Policy mu Mean               0.015351791
Policy mu Std                0.5920282
Policy mu Max                2.2115064
Policy mu Min                -2.8509035
Policy log std Mean          -0.9317231
Policy log std Std           0.2573614
Policy log std Max           -0.16682088
Policy log std Min           -1.9824841
Z mean eval                  1.0099905
Z variance eval              0.029047698
total_rewards                [1381.33737994  513.94150129  339.69932673  761.82258274 2976.67117209
  381.01398533  204.58949766 2712.79656799  569.14877987 2545.4747663 ]
total_rewards_mean           1238.649555993919
total_rewards_std            1036.132617168523
total_rewards_max            2976.6711720893873
total_rewards_min            204.58949766220752
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               28.00510703213513
(Previous) Eval Time (s)     19.475480790715665
Sample Time (s)              17.451713774818927
Epoch Time (s)               64.93230159766972
Total Train Time (s)         21478.569676911924
Epoch                        310
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:13:30.703624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #310 | Epoch Duration: 62.71852159500122
2020-01-11 09:13:30.703892 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0083933
Z variance train             0.0289159
KL Divergence                19.987972
KL Loss                      1.9987973
QF Loss                      1603.1385
VF Loss                      508.02585
Policy Loss                  -1075.1838
Q Predictions Mean           1076.196
Q Predictions Std            223.29945
Q Predictions Max            1270.4182
Q Predictions Min            139.27246
V Predictions Mean           1081.5203
V Predictions Std            221.7275
V Predictions Max            1280.5603
V Predictions Min            166.53925
Log Pis Mean                 -0.2417176
Log Pis Std                  2.5691257
Log Pis Max                  8.968539
Log Pis Min                  -6.7913094
Policy mu Mean               -0.029698249
Policy mu Std                0.59569937
Policy mu Max                2.2214077
Policy mu Min                -2.554051
Policy log std Mean          -0.9246405
Policy log std Std           0.24383873
Policy log std Max           -0.18587571
Policy log std Min           -2.0281847
Z mean eval                  0.9964177
Z variance eval              0.025899982
total_rewards                [-108.23995826  165.98676928 2860.07745859  821.21604958  588.44105136
  203.78499639 2846.89883879  245.17695769 2890.85053045  837.30458994]
total_rewards_mean           1135.149728381008
total_rewards_std            1166.999957465907
total_rewards_max            2890.850530452948
total_rewards_min            -108.23995826332323
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               28.266807966399938
(Previous) Eval Time (s)     17.26143078599125
Sample Time (s)              18.038191513624042
Epoch Time (s)               63.56643026601523
Total Train Time (s)         21540.99831008725
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:14:33.139495 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #311 | Epoch Duration: 62.43537735939026
2020-01-11 09:14:33.139827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9954174
Z variance train             0.02593919
KL Divergence                19.754168
KL Loss                      1.9754168
QF Loss                      933.122
VF Loss                      390.14407
Policy Loss                  -1064.9244
Q Predictions Mean           1062.904
Q Predictions Std            250.78664
Q Predictions Max            1275.238
Q Predictions Min            70.75218
V Predictions Mean           1065.5565
V Predictions Std            248.00319
V Predictions Max            1268.3618
V Predictions Min            57.329464
Log Pis Mean                 -0.43172938
Log Pis Std                  2.704872
Log Pis Max                  11.265795
Log Pis Min                  -6.886937
Policy mu Mean               0.018788476
Policy mu Std                0.5860016
Policy mu Max                1.9649295
Policy mu Min                -2.1390142
Policy log std Mean          -0.94780827
Policy log std Std           0.26564586
Policy log std Max           -0.073820174
Policy log std Min           -2.5965614
Z mean eval                  0.9902836
Z variance eval              0.022057746
total_rewards                [2569.61526483  541.63850524 3151.27142669 2814.12609263  378.13750944
 3101.21395149 3134.11092981 2476.51913335 2949.6673949    36.46230214]
total_rewards_mean           2115.2762510509465
total_rewards_std            1200.8479293405762
total_rewards_max            3151.2714266901635
total_rewards_min            36.46230213687012
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               29.892063884064555
(Previous) Eval Time (s)     16.13005932699889
Sample Time (s)              17.67887875251472
Epoch Time (s)               63.701001963578165
Total Train Time (s)         21615.771813700907
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:15:47.916986 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #312 | Epoch Duration: 74.77689599990845
2020-01-11 09:15:47.917286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.987426
Z variance train             0.022024896
KL Divergence                19.836
KL Loss                      1.9836
QF Loss                      725.2283
VF Loss                      233.98712
Policy Loss                  -1064.6079
Q Predictions Mean           1062.55
Q Predictions Std            234.20879
Q Predictions Max            1258.637
Q Predictions Min            146.78354
V Predictions Mean           1061.1318
V Predictions Std            230.5557
V Predictions Max            1254.967
V Predictions Min            149.86627
Log Pis Mean                 -0.09228193
Log Pis Std                  2.7093494
Log Pis Max                  14.304205
Log Pis Min                  -8.265812
Policy mu Mean               0.048306413
Policy mu Std                0.5700121
Policy mu Max                2.2198477
Policy mu Min                -2.8673377
Policy log std Mean          -1.005068
Policy log std Std           0.28490657
Policy log std Max           -0.18511516
Policy log std Min           -2.6872807
Z mean eval                  0.97519237
Z variance eval              0.018285884
total_rewards                [ -25.95277186 2737.92611431 2683.38360004 2916.51965103  133.17530259
 2553.41240835 1693.88681608 2833.75973475 2564.11317201 2872.24452159]
total_rewards_mean           2096.246854889579
total_rewards_std            1073.4337858612428
total_rewards_max            2916.519651034905
total_rewards_min            -25.952771862634933
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               30.863842546008527
(Previous) Eval Time (s)     27.205626524984837
Sample Time (s)              18.733370623085648
Epoch Time (s)               76.80283969407901
Total Train Time (s)         21687.44222687278
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:16:59.591531 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #313 | Epoch Duration: 71.67401385307312
2020-01-11 09:16:59.591757 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #313 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9748524
Z variance train             0.01829255
KL Divergence                20.83434
KL Loss                      2.0834339
QF Loss                      872.8684
VF Loss                      276.0911
Policy Loss                  -1032.8549
Q Predictions Mean           1031.3083
Q Predictions Std            278.76392
Q Predictions Max            1299.0631
Q Predictions Min            133.26567
V Predictions Mean           1028.2958
V Predictions Std            276.49695
V Predictions Max            1259.9866
V Predictions Min            144.749
Log Pis Mean                 -0.2763607
Log Pis Std                  2.5242074
Log Pis Max                  9.596468
Log Pis Min                  -8.150757
Policy mu Mean               -0.005370942
Policy mu Std                0.5865445
Policy mu Max                2.2683582
Policy mu Min                -2.4513416
Policy log std Mean          -0.97095644
Policy log std Std           0.2893315
Policy log std Max           -0.12743753
Policy log std Min           -2.3888345
Z mean eval                  0.9670744
Z variance eval              0.012972856
total_rewards                [2735.30121939  681.83026764 2783.03441286 2753.27944318  246.13932427
 2981.62517469 2560.2971364   953.94562795 2978.14434312 2418.32148742]
total_rewards_mean           2109.1918436916103
total_rewards_std            995.947822784549
total_rewards_max            2981.625174689766
total_rewards_min            246.13932427123177
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               31.091162621974945
(Previous) Eval Time (s)     22.07644093595445
Sample Time (s)              18.66854906314984
Epoch Time (s)               71.83615262107924
Total Train Time (s)         21757.28445451986
Epoch                        314
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:18:09.438604 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #314 | Epoch Duration: 69.84662532806396
2020-01-11 09:18:09.438885 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.966821
Z variance train             0.01289892
KL Divergence                21.634922
KL Loss                      2.1634922
QF Loss                      1170.2654
VF Loss                      123.68385
Policy Loss                  -1043.095
Q Predictions Mean           1042.5042
Q Predictions Std            243.55159
Q Predictions Max            1284.4198
Q Predictions Min            116.063705
V Predictions Mean           1046.9941
V Predictions Std            241.63222
V Predictions Max            1274.0424
V Predictions Min            132.37039
Log Pis Mean                 -0.14640181
Log Pis Std                  2.5346987
Log Pis Max                  8.548422
Log Pis Min                  -6.758331
Policy mu Mean               0.032971404
Policy mu Std                0.5911001
Policy mu Max                2.3634233
Policy mu Min                -2.6865149
Policy log std Mean          -0.9558002
Policy log std Std           0.2734966
Policy log std Max           -0.0448038
Policy log std Min           -2.5305243
Z mean eval                  0.9984436
Z variance eval              0.01559138
total_rewards                [2989.45513957  887.21851681 1568.09903886  800.30221745  971.36831882
 1157.05646335 -192.79359138 2776.8980831  3045.38416948 2475.07304766]
total_rewards_mean           1647.8061403725144
total_rewards_std            1053.6501285762552
total_rewards_max            3045.3841694797775
total_rewards_min            -192.7935913808174
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               26.902330433949828
(Previous) Eval Time (s)     20.08660934586078
Sample Time (s)              18.154490866232663
Epoch Time (s)               65.14343064604327
Total Train Time (s)         21821.576526679564
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:19:13.735020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #315 | Epoch Duration: 64.29591298103333
2020-01-11 09:19:13.735254 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99882126
Z variance train             0.015602732
KL Divergence                22.130861
KL Loss                      2.2130861
QF Loss                      643.3672
VF Loss                      442.56396
Policy Loss                  -1056.049
Q Predictions Mean           1055.723
Q Predictions Std            252.07036
Q Predictions Max            1275.042
Q Predictions Min            129.08159
V Predictions Mean           1061.749
V Predictions Std            254.4967
V Predictions Max            1286.2076
V Predictions Min            135.86641
Log Pis Mean                 -0.66313183
Log Pis Std                  2.717858
Log Pis Max                  13.30518
Log Pis Min                  -7.418049
Policy mu Mean               -0.014722718
Policy mu Std                0.5621886
Policy mu Max                2.8403554
Policy mu Min                -2.3219209
Policy log std Mean          -0.9450085
Policy log std Std           0.298629
Policy log std Max           -0.14436966
Policy log std Min           -3.3191886
Z mean eval                  0.97591764
Z variance eval              0.013024275
total_rewards                [ 924.62814142 3196.35511449 3231.99597701  542.00876189   63.71621038
 3219.53871469 2980.76948339  654.7160254  1706.20510758 3209.1364589 ]
total_rewards_mean           1972.9069995154382
total_rewards_std            1256.2004689825567
total_rewards_max            3231.9959770115374
total_rewards_min            63.716210380880995
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               29.09198392322287
(Previous) Eval Time (s)     19.238745351787657
Sample Time (s)              17.525610058568418
Epoch Time (s)               65.85633933357894
Total Train Time (s)         21885.33779255068
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:20:17.502606 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #316 | Epoch Duration: 63.767141819000244
2020-01-11 09:20:17.502877 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #316 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.97466326
Z variance train             0.01305854
KL Divergence                22.018286
KL Loss                      2.2018287
QF Loss                      826.7205
VF Loss                      264.31268
Policy Loss                  -1079.7457
Q Predictions Mean           1076.1172
Q Predictions Std            214.29944
Q Predictions Max            1272.006
Q Predictions Min            114.241806
V Predictions Mean           1077.0756
V Predictions Std            204.61739
V Predictions Max            1267.2852
V Predictions Min            130.63199
Log Pis Mean                 -0.044703424
Log Pis Std                  2.6479826
Log Pis Max                  9.772928
Log Pis Min                  -9.396
Policy mu Mean               -0.000706502
Policy mu Std                0.58705574
Policy mu Max                2.017875
Policy mu Min                -2.4167557
Policy log std Mean          -0.97443116
Policy log std Std           0.26359004
Policy log std Max           -0.23424101
Policy log std Min           -2.4275227
Z mean eval                  0.98596716
Z variance eval              0.012809718
total_rewards                [2926.54149955 2556.26849224 2416.41687521 1169.86822588   50.7607313
 2623.10933283 1384.99654809 2436.44709398  647.26076417 2905.27735798]
total_rewards_mean           1911.6946921228905
total_rewards_std            967.3883450949139
total_rewards_max            2926.5414995544324
total_rewards_min            50.76073130133009
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               30.159846077207476
(Previous) Eval Time (s)     17.149245463777333
Sample Time (s)              17.701962357386947
Epoch Time (s)               65.01105389837176
Total Train Time (s)         21955.902055298444
Epoch                        317
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:21:28.070565 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #317 | Epoch Duration: 70.56747484207153
2020-01-11 09:21:28.070811 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9849966
Z variance train             0.012770134
KL Divergence                22.291204
KL Loss                      2.2291205
QF Loss                      792.337
VF Loss                      478.48566
Policy Loss                  -1054.5106
Q Predictions Mean           1051.8027
Q Predictions Std            261.92236
Q Predictions Max            1279.8124
Q Predictions Min            74.89922
V Predictions Mean           1062.5817
V Predictions Std            252.77342
V Predictions Max            1280.7369
V Predictions Min            167.79266
Log Pis Mean                 -0.15189835
Log Pis Std                  2.8485022
Log Pis Max                  16.146328
Log Pis Min                  -6.6520367
Policy mu Mean               0.06077254
Policy mu Std                0.5570097
Policy mu Max                2.3565886
Policy mu Min                -3.685113
Policy log std Mean          -0.9580292
Policy log std Std           0.27290022
Policy log std Max           -0.1781525
Policy log std Min           -2.1881433
Z mean eval                  1.001871
Z variance eval              0.034555323
total_rewards                [ 265.51322932 2224.60067231 2923.63894203 1384.02908429 2188.86312779
 3218.22459679 2775.84471127  175.22896344 3001.56487585 2166.04658348]
total_rewards_mean           2032.35547865642
total_rewards_std            1037.4545090490315
total_rewards_max            3218.2245967925187
total_rewards_min            175.2289634402405
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               27.461160372011364
(Previous) Eval Time (s)     22.705373084172606
Sample Time (s)              17.542715571355075
Epoch Time (s)               67.70924902753904
Total Train Time (s)         22023.630448984448
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:22:35.804977 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #318 | Epoch Duration: 67.73394751548767
2020-01-11 09:22:35.805272 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0058444
Z variance train             0.034425598
KL Divergence                20.595821
KL Loss                      2.0595822
QF Loss                      856.1541
VF Loss                      382.12778
Policy Loss                  -1065.182
Q Predictions Mean           1064.6072
Q Predictions Std            243.97984
Q Predictions Max            1255.6918
Q Predictions Min            -12.725475
V Predictions Mean           1079.0403
V Predictions Std            243.824
V Predictions Max            1270.5356
V Predictions Min            5.196602
Log Pis Mean                 -0.25671428
Log Pis Std                  2.7569087
Log Pis Max                  11.661677
Log Pis Min                  -8.698469
Policy mu Mean               0.06887941
Policy mu Std                0.5905398
Policy mu Max                2.26439
Policy mu Min                -2.0738547
Policy log std Mean          -0.9562479
Policy log std Std           0.27300483
Policy log std Max           -0.21260399
Policy log std Min           -2.7473927
Z mean eval                  0.9746453
Z variance eval              0.03365044
total_rewards                [2814.29358389 3009.79706345 3126.47330629 2188.13845068 1374.26751184
 1917.67176476 2521.86607152 1763.4718661  3096.58397117  879.51708403]
total_rewards_mean           2269.2080673716137
total_rewards_std            738.0352099814648
total_rewards_max            3126.473306286732
total_rewards_min            879.5170840285793
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               27.65380699187517
(Previous) Eval Time (s)     22.72979160770774
Sample Time (s)              18.16176707483828
Epoch Time (s)               68.54536567442119
Total Train Time (s)         22089.771465452388
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:23:41.948711 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #319 | Epoch Duration: 66.14322447776794
2020-01-11 09:23:41.948929 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.974738
Z variance train             0.03359967
KL Divergence                20.004345
KL Loss                      2.0004346
QF Loss                      726.9928
VF Loss                      198.33728
Policy Loss                  -1084.5934
Q Predictions Mean           1085.2432
Q Predictions Std            191.83139
Q Predictions Max            1270.3906
Q Predictions Min            104.1647
V Predictions Mean           1089.9955
V Predictions Std            189.44006
V Predictions Max            1258.1178
V Predictions Min            109.797005
Log Pis Mean                 -0.24178466
Log Pis Std                  2.4811432
Log Pis Max                  9.701738
Log Pis Min                  -7.4779835
Policy mu Mean               0.07483011
Policy mu Std                0.5726705
Policy mu Max                1.9429824
Policy mu Min                -2.1070774
Policy log std Mean          -0.97870016
Policy log std Std           0.25777346
Policy log std Max           -0.22234148
Policy log std Min           -2.7074509
Z mean eval                  0.99879247
Z variance eval              0.030614322
total_rewards                [2937.40335418 3098.30839311 2978.76162305 2781.09670616 1064.84095488
 3197.64931359  803.69297144 3148.34959318 3171.18597324 3116.80958199]
total_rewards_mean           2629.809846481594
total_rewards_std            858.1475494207601
total_rewards_max            3197.6493135863843
total_rewards_min            803.6929714393368
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               30.690022793132812
(Previous) Eval Time (s)     20.32734536798671
Sample Time (s)              17.684594008605927
Epoch Time (s)               68.70196216972545
Total Train Time (s)         22160.67503310833
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:52.857534 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #320 | Epoch Duration: 70.90841245651245
2020-01-11 09:24:52.857805 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99821454
Z variance train             0.030591387
KL Divergence                19.944836
KL Loss                      1.9944836
QF Loss                      1449.4352
VF Loss                      202.6426
Policy Loss                  -1093.2168
Q Predictions Mean           1094.5577
Q Predictions Std            222.96254
Q Predictions Max            1329.3243
Q Predictions Min            52.297325
V Predictions Mean           1095.341
V Predictions Std            223.4137
V Predictions Max            1327.4106
V Predictions Min            9.876013
Log Pis Mean                 -0.16722977
Log Pis Std                  2.709308
Log Pis Max                  13.64159
Log Pis Min                  -6.619955
Policy mu Mean               0.022690516
Policy mu Std                0.5563431
Policy mu Max                2.6666744
Policy mu Min                -2.6739113
Policy log std Mean          -1.0088687
Policy log std Std           0.28489065
Policy log std Max           -0.15619773
Policy log std Min           -3.037221
Z mean eval                  0.97624207
Z variance eval              0.034670375
total_rewards                [ 958.84376379  850.26465579  277.46785358  252.02916651  968.0612621
 2816.78417151 2950.99415269  118.08769987 2919.93923806 3023.68151439]
total_rewards_mean           1513.6153478274373
total_rewards_std            1188.9047973445731
total_rewards_max            3023.681514388823
total_rewards_min            118.08769986674234
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               29.901661458890885
(Previous) Eval Time (s)     22.53346274001524
Sample Time (s)              17.944726647343487
Epoch Time (s)               70.37985084624961
Total Train Time (s)         22222.951304684393
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:25:55.140020 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #321 | Epoch Duration: 62.28188180923462
2020-01-11 09:25:55.140379 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9767278
Z variance train             0.03467516
KL Divergence                20.041985
KL Loss                      2.0041986
QF Loss                      1475.1702
VF Loss                      462.14923
Policy Loss                  -1074.9425
Q Predictions Mean           1076.4208
Q Predictions Std            224.1386
Q Predictions Max            1269.2736
Q Predictions Min            132.19637
V Predictions Mean           1086.9026
V Predictions Std            225.57411
V Predictions Max            1275.9735
V Predictions Min            99.01111
Log Pis Mean                 -0.62034583
Log Pis Std                  2.6546636
Log Pis Max                  6.9960203
Log Pis Min                  -7.172279
Policy mu Mean               -0.00975695
Policy mu Std                0.58887297
Policy mu Max                2.2391338
Policy mu Min                -2.849246
Policy log std Mean          -0.94262177
Policy log std Std           0.2581516
Policy log std Max           -0.041246712
Policy log std Min           -2.0124457
Z mean eval                  0.9803184
Z variance eval              0.02375439
total_rewards                [2645.90709915 2844.47820487 2998.71318097  889.63359098  529.03512208
 2983.97354399  123.31046013 3053.64588049  130.58142626 3035.86137969]
total_rewards_mean           1923.5139888626206
total_rewards_std            1250.3595234984627
total_rewards_max            3053.6458804930353
total_rewards_min            123.31046012733187
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               30.26470291102305
(Previous) Eval Time (s)     14.43516037799418
Sample Time (s)              18.380587627645582
Epoch Time (s)               63.08045091666281
Total Train Time (s)         22293.397516037337
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:27:05.591368 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #322 | Epoch Duration: 70.45074462890625
2020-01-11 09:27:05.591657 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9806329
Z variance train             0.023701012
KL Divergence                20.216911
KL Loss                      2.021691
QF Loss                      1112.6448
VF Loss                      157.41843
Policy Loss                  -1090.6416
Q Predictions Mean           1089.1376
Q Predictions Std            207.30418
Q Predictions Max            1320.1935
Q Predictions Min            56.752083
V Predictions Mean           1088.7197
V Predictions Std            208.79684
V Predictions Max            1308.9404
V Predictions Min            52.176926
Log Pis Mean                 -0.1669769
Log Pis Std                  2.6918292
Log Pis Max                  9.953959
Log Pis Min                  -7.2973347
Policy mu Mean               0.013734487
Policy mu Std                0.53599834
Policy mu Max                2.0844297
Policy mu Min                -2.668159
Policy log std Mean          -1.0189979
Policy log std Std           0.28351295
Policy log std Max           -0.26024675
Policy log std Min           -2.5155816
Z mean eval                  0.9890879
Z variance eval              0.022424335
total_rewards                [1488.25438799 1174.06410716 3029.67343244 2776.38761203  390.48479127
 1753.08095597 2745.36016618 2726.14239595 1571.58553199 3088.4920766 ]
total_rewards_mean           2074.35254575778
total_rewards_std            874.8989939782011
total_rewards_max            3088.4920765963243
total_rewards_min            390.48479127282735
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               31.52818787889555
(Previous) Eval Time (s)     21.80515002971515
Sample Time (s)              18.025173804722726
Epoch Time (s)               71.35851171333343
Total Train Time (s)         22364.762533692643
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:28:16.959117 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #323 | Epoch Duration: 71.36722421646118
2020-01-11 09:28:16.959329 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #323 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9921525
Z variance train             0.022460109
KL Divergence                20.142967
KL Loss                      2.0142968
QF Loss                      1016.7467
VF Loss                      202.12787
Policy Loss                  -1101.4417
Q Predictions Mean           1103.9224
Q Predictions Std            226.05779
Q Predictions Max            1299.9816
Q Predictions Min            35.63227
V Predictions Mean           1092.1149
V Predictions Std            222.552
V Predictions Max            1283.343
V Predictions Min            -6.5670557
Log Pis Mean                 -0.114468634
Log Pis Std                  2.4941616
Log Pis Max                  7.839177
Log Pis Min                  -6.8054266
Policy mu Mean               0.04943592
Policy mu Std                0.57480246
Policy mu Max                2.2311726
Policy mu Min                -2.410113
Policy log std Mean          -0.97220874
Policy log std Std           0.23967835
Policy log std Max           -0.26414067
Policy log std Min           -2.017599
Z mean eval                  0.9936797
Z variance eval              0.016033791
total_rewards                [1660.49223179  120.69982837 1820.89596072 2565.74823491 2972.95948338
 2803.01078415 2773.27247923 2962.03045339 2722.17904503 2328.34433788]
total_rewards_mean           2272.963283884845
total_rewards_std            836.5629929601043
total_rewards_max            2972.959483377803
total_rewards_min            120.69982836765386
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               29.308257713913918
(Previous) Eval Time (s)     21.813563061878085
Sample Time (s)              18.154324313160032
Epoch Time (s)               69.27614508895203
Total Train Time (s)         22434.50226959586
Epoch                        324
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:29:26.703664 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #324 | Epoch Duration: 69.74416184425354
2020-01-11 09:29:26.703924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99147666
Z variance train             0.016040092
KL Divergence                20.913792
KL Loss                      2.0913792
QF Loss                      1603.6948
VF Loss                      288.3218
Policy Loss                  -1083.8842
Q Predictions Mean           1089.606
Q Predictions Std            249.32156
Q Predictions Max            1294.2864
Q Predictions Min            118.5723
V Predictions Mean           1094.5493
V Predictions Std            247.6931
V Predictions Max            1300.3693
V Predictions Min            118.10072
Log Pis Mean                 -0.65554214
Log Pis Std                  2.6224554
Log Pis Max                  7.481987
Log Pis Min                  -12.786793
Policy mu Mean               -0.048769962
Policy mu Std                0.574395
Policy mu Max                2.646734
Policy mu Min                -2.3316944
Policy log std Mean          -0.94945574
Policy log std Std           0.26214415
Policy log std Max           -0.20389777
Policy log std Min           -2.2997065
Z mean eval                  1.0238006
Z variance eval              0.014227906
total_rewards                [1189.67011023  916.66954123 3145.7230457  3041.58347196 1485.80367793
 2634.54805274  139.54676563  903.36101535 2414.1645964   964.93338668]
total_rewards_mean           1683.6003663841832
total_rewards_std            989.9786439026681
total_rewards_max            3145.7230456951547
total_rewards_min            139.54676563469624
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               27.147306659258902
(Previous) Eval Time (s)     22.281231049913913
Sample Time (s)              18.541803745087236
Epoch Time (s)               67.97034145426005
Total Train Time (s)         22501.08815042721
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:33.295777 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #325 | Epoch Duration: 66.59164214134216
2020-01-11 09:30:33.296115 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.023588
Z variance train             0.014199247
KL Divergence                21.738
KL Loss                      2.1738002
QF Loss                      616.00073
VF Loss                      294.96143
Policy Loss                  -1083.8007
Q Predictions Mean           1084.0403
Q Predictions Std            218.75444
Q Predictions Max            1269.7762
Q Predictions Min            126.78726
V Predictions Mean           1094.5511
V Predictions Std            221.24179
V Predictions Max            1277.4681
V Predictions Min            135.1063
Log Pis Mean                 -0.6593369
Log Pis Std                  2.644576
Log Pis Max                  16.54529
Log Pis Min                  -9.30226
Policy mu Mean               0.014793524
Policy mu Std                0.5424812
Policy mu Max                2.5422237
Policy mu Min                -2.2762716
Policy log std Mean          -0.978638
Policy log std Std           0.28326595
Policy log std Max           -0.27180976
Policy log std Min           -3.3776119
Z mean eval                  1.013221
Z variance eval              0.016625134
total_rewards                [2012.25806774 2962.67257713 1446.09640963  270.76107372 1464.41178371
 3151.91837862 1992.99844774 2919.39568346 1228.16081108 3092.10580326]
total_rewards_mean           2054.077903608296
total_rewards_std            918.8177163050285
total_rewards_max            3151.9183786169588
total_rewards_min            270.7610737220083
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               29.999400584958494
(Previous) Eval Time (s)     20.90222475398332
Sample Time (s)              18.109129247721285
Epoch Time (s)               69.0107545866631
Total Train Time (s)         22568.640735561494
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:31:40.851427 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #326 | Epoch Duration: 67.55508255958557
2020-01-11 09:31:40.851618 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0108467
Z variance train             0.016693287
KL Divergence                21.542694
KL Loss                      2.1542695
QF Loss                      2300.1143
VF Loss                      298.67313
Policy Loss                  -1095.2426
Q Predictions Mean           1093.7769
Q Predictions Std            244.64972
Q Predictions Max            1309.5902
Q Predictions Min            66.785355
V Predictions Mean           1086.2628
V Predictions Std            237.25066
V Predictions Max            1294.487
V Predictions Min            99.09465
Log Pis Mean                 -0.41249755
Log Pis Std                  2.7143507
Log Pis Max                  12.777639
Log Pis Min                  -8.445118
Policy mu Mean               -0.017540082
Policy mu Std                0.5753869
Policy mu Max                2.1969516
Policy mu Min                -2.268235
Policy log std Mean          -0.9741813
Policy log std Std           0.28423056
Policy log std Max           -0.11344057
Policy log std Min           -2.4397233
Z mean eval                  0.98627186
Z variance eval              0.015672084
total_rewards                [1909.78817934 2718.13052556 2924.42198946 2769.27123235 2808.36871235
 2870.59418883  162.17477904  203.19612928 3057.47963266  571.38650523]
total_rewards_mean           1999.4811874087268
total_rewards_std            1146.5984814435212
total_rewards_max            3057.479632655103
total_rewards_min            162.17477903649603
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               30.92589187808335
(Previous) Eval Time (s)     19.446241817437112
Sample Time (s)              19.155502691864967
Epoch Time (s)               69.52763638738543
Total Train Time (s)         22641.76695746137
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:32:53.981176 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #327 | Epoch Duration: 73.12939524650574
2020-01-11 09:32:53.981399 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98505765
Z variance train             0.015669426
KL Divergence                21.895735
KL Loss                      2.1895735
QF Loss                      1258.0299
VF Loss                      730.30914
Policy Loss                  -1112.8584
Q Predictions Mean           1109.6134
Q Predictions Std            209.02751
Q Predictions Max            1286.0167
Q Predictions Min            147.48439
V Predictions Mean           1105.794
V Predictions Std            203.87537
V Predictions Max            1274.434
V Predictions Min            147.98721
Log Pis Mean                 -0.12019431
Log Pis Std                  2.5969553
Log Pis Max                  9.855599
Log Pis Min                  -7.523113
Policy mu Mean               0.051058814
Policy mu Std                0.6254677
Policy mu Max                2.3373315
Policy mu Min                -2.5957355
Policy log std Mean          -0.9497503
Policy log std Std           0.26105043
Policy log std Max           -0.09415853
Policy log std Min           -2.5332599
Z mean eval                  1.01311
Z variance eval              0.0130971
total_rewards                [ 909.01872284   10.17386052 3238.23525829 1223.94052071 3101.76356484
 2968.09407752 1931.73705137 1909.7262078  2084.49554622  221.42968541]
total_rewards_mean           1759.8614495542013
total_rewards_std            1097.3981954313551
total_rewards_max            3238.2352582942112
total_rewards_min            10.173860520195158
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               27.71290743490681
(Previous) Eval Time (s)     23.047663446050137
Sample Time (s)              20.623641851358116
Epoch Time (s)               71.38421273231506
Total Train Time (s)         22708.451891373377
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:34:00.670786 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #328 | Epoch Duration: 66.68915033340454
2020-01-11 09:34:00.671065 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #328 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0133297
Z variance train             0.013067925
KL Divergence                21.980524
KL Loss                      2.1980524
QF Loss                      933.6843
VF Loss                      229.54549
Policy Loss                  -1068.1036
Q Predictions Mean           1067.8319
Q Predictions Std            270.42514
Q Predictions Max            1292.7567
Q Predictions Min            40.31384
V Predictions Mean           1072.6982
V Predictions Std            274.43942
V Predictions Max            1297.6467
V Predictions Min            46.721237
Log Pis Mean                 -0.43380854
Log Pis Std                  2.8808007
Log Pis Max                  11.471288
Log Pis Min                  -10.779967
Policy mu Mean               0.0480293
Policy mu Std                0.58608437
Policy mu Max                2.252428
Policy mu Min                -2.1639228
Policy log std Mean          -0.97255325
Policy log std Std           0.3025141
Policy log std Max           -0.18034935
Policy log std Min           -2.9356532
Z mean eval                  1.0141777
Z variance eval              0.016378138
total_rewards                [-109.67131953  947.51590451 3037.04057285  179.38526949 2666.9312125
 2767.75352015 2955.95716157 3127.82881186 2935.8113375  2881.0018504 ]
total_rewards_mean           2138.9554321305964
total_rewards_std            1209.4396482068814
total_rewards_max            3127.82881186464
total_rewards_min            -109.67131952717804
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               27.531206801068038
(Previous) Eval Time (s)     18.352235348895192
Sample Time (s)              18.813197372481227
Epoch Time (s)               64.69663952244446
Total Train Time (s)         22777.244588541333
Epoch                        329
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:35:09.468374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #329 | Epoch Duration: 68.79711771011353
2020-01-11 09:35:09.468662 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0145495
Z variance train             0.01636235
KL Divergence                21.83104
KL Loss                      2.183104
QF Loss                      736.398
VF Loss                      379.4298
Policy Loss                  -1080.7457
Q Predictions Mean           1080.5568
Q Predictions Std            262.12393
Q Predictions Max            1301.4941
Q Predictions Min            42.67697
V Predictions Mean           1082.592
V Predictions Std            263.42746
V Predictions Max            1301.015
V Predictions Min            28.612276
Log Pis Mean                 -0.5427434
Log Pis Std                  2.8709419
Log Pis Max                  13.663339
Log Pis Min                  -7.5593815
Policy mu Mean               0.054412667
Policy mu Std                0.5819468
Policy mu Max                2.5031855
Policy mu Min                -2.4969573
Policy log std Mean          -0.96899456
Policy log std Std           0.2745832
Policy log std Max           -0.1563955
Policy log std Min           -2.125781
Z mean eval                  1.0093956
Z variance eval              0.015691474
total_rewards                [ 344.06724436 3111.2437811   284.30800747  610.16978257  877.07448412
 3049.67510441  687.74851337  649.95202675  772.16182603  215.6980281 ]
total_rewards_mean           1060.2098798265365
total_rewards_std            1030.4795738249024
total_rewards_max            3111.24378110261
total_rewards_min            215.69802809536387
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               26.59391111601144
(Previous) Eval Time (s)     22.452404668089002
Sample Time (s)              17.590869171079248
Epoch Time (s)               66.63718495517969
Total Train Time (s)         22830.98341786256
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:36:03.209723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #330 | Epoch Duration: 53.740864753723145
2020-01-11 09:36:03.209904 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0134088
Z variance train             0.015688574
KL Divergence                21.902447
KL Loss                      2.1902447
QF Loss                      874.6952
VF Loss                      434.8271
Policy Loss                  -1097.7456
Q Predictions Mean           1100.6458
Q Predictions Std            239.73419
Q Predictions Max            1327.8904
Q Predictions Min            157.22928
V Predictions Mean           1108.8557
V Predictions Std            239.09964
V Predictions Max            1327.3464
V Predictions Min            155.84111
Log Pis Mean                 -0.30314165
Log Pis Std                  2.9428074
Log Pis Max                  19.106916
Log Pis Min                  -8.381808
Policy mu Mean               0.03747081
Policy mu Std                0.6118906
Policy mu Max                4.7597833
Policy mu Min                -4.3533955
Policy log std Mean          -0.9632702
Policy log std Std           0.28059873
Policy log std Max           -0.061739028
Policy log std Min           -2.754671
Z mean eval                  0.97996014
Z variance eval              0.015619941
total_rewards                [-186.47013621  561.80895595 2965.71578644  455.23839156 3234.79346133
 1373.33174974 2922.02583636 3129.48276837  150.50215097 3353.20800506]
total_rewards_mean           1795.963696958536
total_rewards_std            1380.0991836370301
total_rewards_max            3353.2080050648988
total_rewards_min            -186.4701362064267
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               27.307886332273483
(Previous) Eval Time (s)     9.555800077971071
Sample Time (s)              17.513841789681464
Epoch Time (s)               54.37752819992602
Total Train Time (s)         22900.23929539742
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:37:12.468285 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #331 | Epoch Duration: 69.2582528591156
2020-01-11 09:37:12.468473 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #331 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9801356
Z variance train             0.015643282
KL Divergence                22.443674
KL Loss                      2.2443674
QF Loss                      1542.4608
VF Loss                      287.54306
Policy Loss                  -1103.0114
Q Predictions Mean           1101.9076
Q Predictions Std            232.7878
Q Predictions Max            1312.2278
Q Predictions Min            162.67868
V Predictions Mean           1100.1897
V Predictions Std            230.95238
V Predictions Max            1307.3473
V Predictions Min            165.50882
Log Pis Mean                 -0.40033856
Log Pis Std                  2.6982915
Log Pis Max                  9.422277
Log Pis Min                  -8.950502
Policy mu Mean               -0.01276851
Policy mu Std                0.5712364
Policy mu Max                2.0056565
Policy mu Min                -1.837507
Policy log std Mean          -0.9786337
Policy log std Std           0.29005307
Policy log std Max           -0.20102847
Policy log std Min           -2.8527937
Z mean eval                  1.0061114
Z variance eval              0.012132977
total_rewards                [3264.73560543 3111.55222609 3091.95093977 3164.83424697 3119.39033538
 3047.42383527 3073.22557472 3325.20231088 3112.18897573 3074.85845154]
total_rewards_mean           3138.5362501784475
total_rewards_std            84.87813161375037
total_rewards_max            3325.202310878456
total_rewards_min            3047.4238352736725
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               31.253624157980084
(Previous) Eval Time (s)     24.436217478942126
Sample Time (s)              18.26610183203593
Epoch Time (s)               73.95594346895814
Total Train Time (s)         22977.252759761177
Epoch                        332
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:38:29.483976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #332 | Epoch Duration: 77.01535940170288
2020-01-11 09:38:29.484135 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0057746
Z variance train             0.012118997
KL Divergence                22.706846
KL Loss                      2.2706847
QF Loss                      958.2926
VF Loss                      146.52968
Policy Loss                  -1113.2942
Q Predictions Mean           1112.181
Q Predictions Std            220.28905
Q Predictions Max            1301.858
Q Predictions Min            42.649998
V Predictions Mean           1114.5435
V Predictions Std            218.79814
V Predictions Max            1303.9652
V Predictions Min            27.517145
Log Pis Mean                 -0.2512936
Log Pis Std                  2.841677
Log Pis Max                  12.135904
Log Pis Min                  -6.8263865
Policy mu Mean               0.014362231
Policy mu Std                0.5613972
Policy mu Max                1.8486516
Policy mu Min                -1.9904436
Policy log std Mean          -1.0077544
Policy log std Std           0.303988
Policy log std Max           -0.21158332
Policy log std Min           -3.3083353
Z mean eval                  0.98039734
Z variance eval              0.01395447
total_rewards                [3212.89759065 1795.2768866  3126.27605596 3114.3169011  3386.30782871
 1335.6649466  1546.06011425 3073.88009889 3100.86251999 3272.51397862]
total_rewards_mean           2696.4056921362762
total_rewards_std            756.7749736851883
total_rewards_max            3386.307828711522
total_rewards_min            1335.664946598414
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               26.145671343896538
(Previous) Eval Time (s)     27.495289932005107
Sample Time (s)              18.90292161051184
Epoch Time (s)               72.54388288641348
Total Train Time (s)         23046.899279094767
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:39:39.133781 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #333 | Epoch Duration: 69.64952111244202
2020-01-11 09:39:39.133971 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.98250306
Z variance train             0.014020848
KL Divergence                22.594975
KL Loss                      2.2594974
QF Loss                      11426.663
VF Loss                      1501.8892
Policy Loss                  -1114.4635
Q Predictions Mean           1110.7932
Q Predictions Std            209.51442
Q Predictions Max            1314.1178
Q Predictions Min            -49.061455
V Predictions Mean           1103.9962
V Predictions Std            199.2326
V Predictions Max            1299.5178
V Predictions Min            153.7362
Log Pis Mean                 -0.27356648
Log Pis Std                  2.6017087
Log Pis Max                  11.206686
Log Pis Min                  -9.097956
Policy mu Mean               0.030752879
Policy mu Std                0.5932675
Policy mu Max                2.0018454
Policy mu Min                -2.0251951
Policy log std Mean          -0.9664303
Policy log std Std           0.275216
Policy log std Max           -0.0020769835
Policy log std Min           -3.1481304
Z mean eval                  0.9855746
Z variance eval              0.015951067
total_rewards                [2947.42313435 2988.16841616 2955.38856696 3078.11256179 1638.58010997
 2559.81288295 3261.89318863 3192.92637344 3290.95618573 1169.28722408]
total_rewards_mean           2708.2548644052613
total_rewards_std            689.1332263619211
total_rewards_max            3290.9561857306335
total_rewards_min            1169.287224079873
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               30.098564783111215
(Previous) Eval Time (s)     24.600595560856164
Sample Time (s)              18.092898750677705
Epoch Time (s)               72.79205909464508
Total Train Time (s)         23118.764009451494
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:51.003016 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #334 | Epoch Duration: 71.86890459060669
2020-01-11 09:40:51.003249 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9857038
Z variance train             0.015856652
KL Divergence                22.903809
KL Loss                      2.290381
QF Loss                      729.42444
VF Loss                      283.00958
Policy Loss                  -1101.5433
Q Predictions Mean           1100.4724
Q Predictions Std            222.38223
Q Predictions Max            1301.8585
Q Predictions Min            4.0107846
V Predictions Mean           1095.3679
V Predictions Std            219.32332
V Predictions Max            1288.9491
V Predictions Min            34.744167
Log Pis Mean                 -0.24278314
Log Pis Std                  2.4804995
Log Pis Max                  11.56436
Log Pis Min                  -8.404519
Policy mu Mean               0.0795421
Policy mu Std                0.5795621
Policy mu Max                2.8574622
Policy mu Min                -2.2091978
Policy log std Mean          -0.94147545
Policy log std Std           0.25114918
Policy log std Max           -0.15013409
Policy log std Min           -1.9367919
Z mean eval                  1.0075462
Z variance eval              0.015700078
total_rewards                [1449.27270503 3088.36637412 1130.40408853  252.93768704 3013.92192989
 2788.0577749  1225.36512473 2998.28822529 1663.76780118 3037.55992194]
total_rewards_mean           2064.794163265771
total_rewards_std            984.3564825209534
total_rewards_max            3088.3663741205232
total_rewards_min            252.93768703909274
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               30.345483750104904
(Previous) Eval Time (s)     23.67708579869941
Sample Time (s)              19.075644710101187
Epoch Time (s)               73.0982142589055
Total Train Time (s)         23191.790534154512
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:42:04.032557 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #335 | Epoch Duration: 73.02912497520447
2020-01-11 09:42:04.032724 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0084544
Z variance train             0.015699312
KL Divergence                22.964191
KL Loss                      2.2964191
QF Loss                      644.23535
VF Loss                      124.45215
Policy Loss                  -1073.1874
Q Predictions Mean           1074.2439
Q Predictions Std            277.87787
Q Predictions Max            1273.442
Q Predictions Min            111.43658
V Predictions Mean           1079.0271
V Predictions Std            278.01294
V Predictions Max            1285.9485
V Predictions Min            111.15867
Log Pis Mean                 -0.23913115
Log Pis Std                  2.8329732
Log Pis Max                  10.394018
Log Pis Min                  -7.0644073
Policy mu Mean               0.0101633975
Policy mu Std                0.59020734
Policy mu Max                2.6376216
Policy mu Min                -2.447815
Policy log std Mean          -0.9490113
Policy log std Std           0.29378635
Policy log std Max           -0.18623269
Policy log std Min           -2.3823
Z mean eval                  1.0585359
Z variance eval              0.0143991355
total_rewards                [2748.91939787 2854.23782415 2968.91687925  -58.6388457  1856.43361716
  339.36813916 1032.36394852  255.09230477  396.61484879 1440.18977742]
total_rewards_mean           1383.3497891402917
total_rewards_std            1109.4316031224064
total_rewards_max            2968.9168792525234
total_rewards_min            -58.63884570443368
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               27.790129837114364
(Previous) Eval Time (s)     23.607661546673626
Sample Time (s)              18.21917873248458
Epoch Time (s)               69.61697011627257
Total Train Time (s)         23258.84704296058
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:11.092594 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #336 | Epoch Duration: 67.05972409248352
2020-01-11 09:43:11.092836 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0597084
Z variance train             0.0142875705
KL Divergence                24.064793
KL Loss                      2.4064794
QF Loss                      955.69324
VF Loss                      353.61298
Policy Loss                  -1129.9073
Q Predictions Mean           1128.947
Q Predictions Std            235.53001
Q Predictions Max            1342.2135
Q Predictions Min            61.66643
V Predictions Mean           1116.9443
V Predictions Std            232.19313
V Predictions Max            1327.3599
V Predictions Min            62.647293
Log Pis Mean                 -0.12697978
Log Pis Std                  2.6838152
Log Pis Max                  9.938757
Log Pis Min                  -8.741535
Policy mu Mean               0.044260193
Policy mu Std                0.5883558
Policy mu Max                2.1718018
Policy mu Min                -2.116065
Policy log std Mean          -0.9881339
Policy log std Std           0.27029583
Policy log std Max           -0.2166661
Policy log std Min           -2.425599
Z mean eval                  0.9894913
Z variance eval              0.013674943
total_rewards                [ 348.27133472 1639.76277605  620.35734945  368.16740248 3061.52435774
 -109.53870167 2474.60649786 3113.18277295  584.88327987  685.53840808]
total_rewards_mean           1278.675547751233
total_rewards_std            1139.8666402106435
total_rewards_max            3113.18277294976
total_rewards_min            -109.53870166870782
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               29.828878290951252
(Previous) Eval Time (s)     21.05007706908509
Sample Time (s)              19.27167836483568
Epoch Time (s)               70.15063372487202
Total Train Time (s)         23326.74126715213
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:44:18.989938 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #337 | Epoch Duration: 67.89692234992981
2020-01-11 09:44:18.990125 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #337 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9895727
Z variance train             0.0136191845
KL Divergence                23.6035
KL Loss                      2.3603501
QF Loss                      483.7822
VF Loss                      180.73303
Policy Loss                  -1129.1919
Q Predictions Mean           1132.02
Q Predictions Std            210.75204
Q Predictions Max            1350.0256
Q Predictions Min            126.762215
V Predictions Mean           1137.1193
V Predictions Std            213.21234
V Predictions Max            1343.9484
V Predictions Min            118.6183
Log Pis Mean                 -0.5265158
Log Pis Std                  2.395001
Log Pis Max                  8.30299
Log Pis Min                  -6.5455317
Policy mu Mean               0.002255537
Policy mu Std                0.5534995
Policy mu Max                1.818382
Policy mu Min                -1.9700211
Policy log std Mean          -0.9719348
Policy log std Std           0.26262876
Policy log std Max           -0.1879493
Policy log std Min           -2.406204
Z mean eval                  1.0064907
Z variance eval              0.012592685
total_rewards                [ 961.82237782 3099.40220154 3287.62616448  646.55201357 3070.24123785
 3231.35342943 2321.92580719   81.34760261 3239.8635076   920.03034903]
total_rewards_mean           2086.016469111829
total_rewards_std            1218.7050104506732
total_rewards_max            3287.6261644754486
total_rewards_min            81.34760261138914
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               26.95043887803331
(Previous) Eval Time (s)     18.79604686331004
Sample Time (s)              18.1165960887447
Epoch Time (s)               63.86308183008805
Total Train Time (s)         23396.78976703575
Epoch                        338
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:45:29.041841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #338 | Epoch Duration: 70.05155873298645
2020-01-11 09:45:29.042068 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0051088
Z variance train             0.012593739
KL Divergence                23.759153
KL Loss                      2.3759153
QF Loss                      915.0687
VF Loss                      203.14198
Policy Loss                  -1117.911
Q Predictions Mean           1117.1389
Q Predictions Std            235.59557
Q Predictions Max            1359.5723
Q Predictions Min            99.75943
V Predictions Mean           1111.5612
V Predictions Std            232.50467
V Predictions Max            1355.5189
V Predictions Min            102.075226
Log Pis Mean                 0.0012730733
Log Pis Std                  2.815766
Log Pis Max                  16.12265
Log Pis Min                  -9.113911
Policy mu Mean               0.034475062
Policy mu Std                0.6325057
Policy mu Max                2.6324263
Policy mu Min                -3.27812
Policy log std Mean          -0.9366188
Policy log std Std           0.27007928
Policy log std Max           -0.18944788
Policy log std Min           -2.595179
Z mean eval                  1.0653112
Z variance eval              0.020901611
total_rewards                [1227.42425877  684.80109851  600.89691616 2680.81287372 2015.06274758
  156.87961183 2808.1075737  2801.30826338  390.46006706 1104.12048544]
total_rewards_mean           1446.98738961487
total_rewards_std            988.6889752494366
total_rewards_max            2808.1075736978405
total_rewards_min            156.87961183312802
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               28.763451101258397
(Previous) Eval Time (s)     24.984167526010424
Sample Time (s)              17.628152278717607
Epoch Time (s)               71.37577090598643
Total Train Time (s)         23461.292512598913
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:33.551514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #339 | Epoch Duration: 64.50913333892822
2020-01-11 09:46:33.551960 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #339 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0634041
Z variance train             0.020959137
KL Divergence                23.092806
KL Loss                      2.3092806
QF Loss                      2181.1392
VF Loss                      222.3195
Policy Loss                  -1157.6672
Q Predictions Mean           1157.204
Q Predictions Std            177.55844
Q Predictions Max            1357.7142
Q Predictions Min            136.96725
V Predictions Mean           1162.2233
V Predictions Std            174.142
V Predictions Max            1351.7695
V Predictions Min            150.87085
Log Pis Mean                 -0.11877778
Log Pis Std                  3.0626338
Log Pis Max                  10.375174
Log Pis Min                  -7.6926894
Policy mu Mean               -0.04435087
Policy mu Std                0.6157241
Policy mu Max                2.553758
Policy mu Min                -2.4193523
Policy log std Mean          -0.9862424
Policy log std Std           0.27491507
Policy log std Max           -0.17310524
Policy log std Min           -2.2921767
Z mean eval                  0.99839145
Z variance eval              0.015132224
total_rewards                [ 806.82691867 3160.61200699 3140.52678248  663.75250207 2937.69049124
 3082.08724353 3094.07340833 3118.39462603 1317.31327084 1062.3079433 ]
total_rewards_mean           2238.3585193472777
total_rewards_std            1055.0924176698907
total_rewards_max            3160.6120069898852
total_rewards_min            663.7525020700627
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               30.28406098810956
(Previous) Eval Time (s)     18.117219371255487
Sample Time (s)              18.056381749920547
Epoch Time (s)               66.4576621092856
Total Train Time (s)         23534.112977497745
Epoch                        340
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:47:46.373264 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #340 | Epoch Duration: 72.82108426094055
2020-01-11 09:47:46.373471 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99843633
Z variance train             0.015100582
KL Divergence                23.128551
KL Loss                      2.3128552
QF Loss                      1051.849
VF Loss                      60.90102
Policy Loss                  -1132.3905
Q Predictions Mean           1134.3567
Q Predictions Std            229.92581
Q Predictions Max            1339.6111
Q Predictions Min            111.18436
V Predictions Mean           1132.7079
V Predictions Std            231.83633
V Predictions Max            1333.8518
V Predictions Min            122.32173
Log Pis Mean                 -0.5684651
Log Pis Std                  2.4536588
Log Pis Max                  10.543291
Log Pis Min                  -7.4283695
Policy mu Mean               0.056919143
Policy mu Std                0.56682813
Policy mu Max                3.2122946
Policy mu Min                -2.2092412
Policy log std Mean          -0.9384762
Policy log std Std           0.2520016
Policy log std Max           -0.08661628
Policy log std Min           -2.503862
Z mean eval                  1.0120938
Z variance eval              0.015579127
total_rewards                [1222.15263142 3021.21079038 2945.66332501  523.02942623 2882.9082599
 3051.20291988 1020.17636398 1577.32508019 3040.58899098 2804.81237997]
total_rewards_mean           2208.907016795431
total_rewards_std            950.8432691757293
total_rewards_max            3051.202919879922
total_rewards_min            523.0294262348935
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               29.17287139268592
(Previous) Eval Time (s)     24.480346056167036
Sample Time (s)              17.6835624887608
Epoch Time (s)               71.33677993761376
Total Train Time (s)         23602.103146431968
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:48:54.369796 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #341 | Epoch Duration: 67.996084690094
2020-01-11 09:48:54.370134 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.012646
Z variance train             0.015566254
KL Divergence                23.408136
KL Loss                      2.3408136
QF Loss                      8504.771
VF Loss                      634.44867
Policy Loss                  -1129.1666
Q Predictions Mean           1131.9376
Q Predictions Std            211.33183
Q Predictions Max            1334.1078
Q Predictions Min            151.39996
V Predictions Mean           1145.8435
V Predictions Std            212.23349
V Predictions Max            1335.6917
V Predictions Min            166.52692
Log Pis Mean                 -0.19506562
Log Pis Std                  2.8894563
Log Pis Max                  10.981052
Log Pis Min                  -9.987757
Policy mu Mean               0.038590923
Policy mu Std                0.5931163
Policy mu Max                2.2683482
Policy mu Min                -3.013198
Policy log std Mean          -0.9701901
Policy log std Std           0.28739268
Policy log std Max           -0.0998981
Policy log std Min           -2.977436
Z mean eval                  1.0061404
Z variance eval              0.013730337
total_rewards                [-160.76807282 2910.08904214 3083.42826781 2918.51261039 2013.29093666
 2953.9213003  2884.19678994 1216.63600485 3095.04606946 2742.49581631]
total_rewards_mean           2365.684876504854
total_rewards_std            1011.6046760907965
total_rewards_max            3095.0460694631665
total_rewards_min            -160.7680728162801
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               29.991128124762326
(Previous) Eval Time (s)     21.139308491256088
Sample Time (s)              18.474988873116672
Epoch Time (s)               69.60542548913509
Total Train Time (s)         23676.23834009003
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:50:08.509244 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #342 | Epoch Duration: 74.13889646530151
2020-01-11 09:50:08.509514 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0021851
Z variance train             0.013741235
KL Divergence                23.527172
KL Loss                      2.3527172
QF Loss                      529.3707
VF Loss                      175.79672
Policy Loss                  -1113.5261
Q Predictions Mean           1113.3152
Q Predictions Std            267.33856
Q Predictions Max            1362.2213
Q Predictions Min            59.64902
V Predictions Mean           1104.59
V Predictions Std            264.79172
V Predictions Max            1354.8634
V Predictions Min            39.760944
Log Pis Mean                 -0.44912222
Log Pis Std                  2.7602115
Log Pis Max                  9.698363
Log Pis Min                  -8.120164
Policy mu Mean               0.010129589
Policy mu Std                0.56122214
Policy mu Max                2.300055
Policy mu Min                -2.4373324
Policy log std Mean          -0.9729006
Policy log std Std           0.2749512
Policy log std Max           -0.18550432
Policy log std Min           -2.588779
Z mean eval                  0.99899626
Z variance eval              0.011868527
total_rewards                [2347.15621746 3085.92956803  969.09641351 3078.13858161 1604.60706619
 3243.95043207 3175.68054427 2988.35680414 2975.55875133 3211.26751191]
total_rewards_mean           2667.97418905201
total_rewards_std            744.6285198790628
total_rewards_max            3243.950432065898
total_rewards_min            969.0964135102514
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               31.200308417901397
(Previous) Eval Time (s)     25.67247076611966
Sample Time (s)              19.216132619418204
Epoch Time (s)               76.08891180343926
Total Train Time (s)         23751.552873493172
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:51:23.826483 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #343 | Epoch Duration: 75.31677746772766
2020-01-11 09:51:23.826670 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.9991425
Z variance train             0.011851093
KL Divergence                23.61214
KL Loss                      2.3612142
QF Loss                      681.8482
VF Loss                      123.613716
Policy Loss                  -1119.0637
Q Predictions Mean           1117.032
Q Predictions Std            243.25952
Q Predictions Max            1355.1346
Q Predictions Min            84.89583
V Predictions Mean           1115.5583
V Predictions Std            243.80424
V Predictions Max            1357.8877
V Predictions Min            90.407394
Log Pis Mean                 -0.3214483
Log Pis Std                  2.9116178
Log Pis Max                  10.344496
Log Pis Min                  -9.428064
Policy mu Mean               0.040066212
Policy mu Std                0.58150506
Policy mu Max                2.366848
Policy mu Min                -1.8184624
Policy log std Mean          -0.98428345
Policy log std Std           0.28501055
Policy log std Max           -0.17060858
Policy log std Min           -2.4851542
Z mean eval                  1.0478674
Z variance eval              0.011888896
total_rewards                [3071.41800698 1399.46182292 3090.93220896 2262.64977786  336.78875019
 2911.90869744 3081.14287068 3326.39815689 3059.77353246 2833.48932151]
total_rewards_mean           2537.3963145882194
total_rewards_std            906.8422216343856
total_rewards_max            3326.3981568875483
total_rewards_min            336.7887501897336
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               28.445981533266604
(Previous) Eval Time (s)     24.900008044671267
Sample Time (s)              17.63771555479616
Epoch Time (s)               70.98370513273403
Total Train Time (s)         23824.778746361844
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:52:37.055437 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #344 | Epoch Duration: 73.22863245010376
2020-01-11 09:52:37.055627 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #344 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0503956
Z variance train             0.0118877385
KL Divergence                23.524467
KL Loss                      2.3524468
QF Loss                      953.94775
VF Loss                      643.85913
Policy Loss                  -1131.5868
Q Predictions Mean           1131.8326
Q Predictions Std            236.75076
Q Predictions Max            1333.1141
Q Predictions Min            75.219406
V Predictions Mean           1138.1904
V Predictions Std            232.07797
V Predictions Max            1337.3877
V Predictions Min            28.03419
Log Pis Mean                 -0.22509284
Log Pis Std                  2.6278906
Log Pis Max                  10.221614
Log Pis Min                  -8.52687
Policy mu Mean               0.014011652
Policy mu Std                0.5798057
Policy mu Max                2.6053495
Policy mu Min                -2.093813
Policy log std Mean          -0.99760866
Policy log std Std           0.26708522
Policy log std Max           -0.20095092
Policy log std Min           -2.7023783
Z mean eval                  1.0210333
Z variance eval              0.013089339
total_rewards                [3187.92755587 2913.1492654  3147.66261991 2985.14398022 1779.4372261
  551.33094675 2477.039782   1313.62867489 3099.00355701 3175.90566792]
total_rewards_mean           2463.0229276055093
total_rewards_std            884.6058311857405
total_rewards_max            3187.927555871457
total_rewards_min            551.3309467478733
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               30.55469521973282
(Previous) Eval Time (s)     27.144625267013907
Sample Time (s)              17.700904830824584
Epoch Time (s)               75.40022531757131
Total Train Time (s)         23895.77500326652
Epoch                        345
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:53:48.058329 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #345 | Epoch Duration: 71.00252437591553
2020-01-11 09:53:48.058641 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0233264
Z variance train             0.013159819
KL Divergence                23.42455
KL Loss                      2.342455
QF Loss                      1950.8151
VF Loss                      583.3455
Policy Loss                  -1138.8539
Q Predictions Mean           1136.176
Q Predictions Std            231.14006
Q Predictions Max            1351.795
Q Predictions Min            10.133749
V Predictions Mean           1133.0787
V Predictions Std            227.39757
V Predictions Max            1357.2972
V Predictions Min            78.32524
Log Pis Mean                 -0.12351492
Log Pis Std                  2.6494067
Log Pis Max                  9.951696
Log Pis Min                  -6.0199137
Policy mu Mean               0.059942633
Policy mu Std                0.59608084
Policy mu Max                2.6035168
Policy mu Min                -2.0299034
Policy log std Mean          -0.9619647
Policy log std Std           0.2943348
Policy log std Max           -0.20197773
Policy log std Min           -3.5277417
Z mean eval                  1.0152324
Z variance eval              0.014301151
total_rewards                [1919.73093423  694.99003256 3292.21477951 3495.42936504 3314.4928653
 3221.90753859  366.1989113  3134.7998546  3284.1291801  3391.27558428]
total_rewards_mean           2611.5169045508474
total_rewards_std            1124.222160008246
total_rewards_max            3495.4293650365753
total_rewards_min            366.19891130105276
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               29.277839341200888
(Previous) Eval Time (s)     22.74661434534937
Sample Time (s)              18.04166539432481
Epoch Time (s)               70.06611908087507
Total Train Time (s)         23968.444123731926
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:55:00.730312 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #346 | Epoch Duration: 72.6714415550232
2020-01-11 09:55:00.730497 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.016099
Z variance train             0.014342857
KL Divergence                22.985184
KL Loss                      2.2985184
QF Loss                      868.6992
VF Loss                      876.0865
Policy Loss                  -1122.3066
Q Predictions Mean           1122.8259
Q Predictions Std            241.61356
Q Predictions Max            1318.1366
Q Predictions Min            137.66273
V Predictions Mean           1111.2498
V Predictions Std            241.68336
V Predictions Max            1309.7128
V Predictions Min            133.37546
Log Pis Mean                 -0.13698567
Log Pis Std                  2.6683178
Log Pis Max                  11.361408
Log Pis Min                  -6.7082357
Policy mu Mean               0.009386364
Policy mu Std                0.59610707
Policy mu Max                2.2855594
Policy mu Min                -2.6740198
Policy log std Mean          -0.98364043
Policy log std Std           0.295514
Policy log std Max           -0.21451795
Policy log std Min           -3.0903282
Z mean eval                  1.0061524
Z variance eval              0.013825262
total_rewards                [3036.3049446  3123.81338005 2499.42823278 3225.442933   3006.34862075
 3383.11481456 3018.13214963 2710.69153237 3084.54751374 3263.21465026]
total_rewards_mean           3035.1038771728513
total_rewards_std            247.58781370378227
total_rewards_max            3383.114814562514
total_rewards_min            2499.4282327754527
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               25.97595457592979
(Previous) Eval Time (s)     25.351656186860055
Sample Time (s)              18.42848982801661
Epoch Time (s)               69.75610059080645
Total Train Time (s)         24038.397015915718
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:56:10.686615 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #347 | Epoch Duration: 69.95595240592957
2020-01-11 09:56:10.686827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0047374
Z variance train             0.013784816
KL Divergence                22.978567
KL Loss                      2.2978568
QF Loss                      947.1095
VF Loss                      320.28424
Policy Loss                  -1133.5465
Q Predictions Mean           1133.7617
Q Predictions Std            224.21912
Q Predictions Max            1343.9856
Q Predictions Min            47.69711
V Predictions Mean           1120.0757
V Predictions Std            219.77686
V Predictions Max            1332.5707
V Predictions Min            53.727222
Log Pis Mean                 -0.17436305
Log Pis Std                  2.7216983
Log Pis Max                  15.206807
Log Pis Min                  -8.443073
Policy mu Mean               0.03972049
Policy mu Std                0.57565856
Policy mu Max                2.61658
Policy mu Min                -2.2030704
Policy log std Mean          -0.9781349
Policy log std Std           0.2669909
Policy log std Max           -0.20717508
Policy log std Min           -2.986608
Z mean eval                  1.027374
Z variance eval              0.007649748
total_rewards                [ 858.09034437  596.00474523  515.80730139 2728.08616755 3031.39256064
   84.47355462 1381.22751859 2287.04974511 2899.54823876 3241.31866956]
total_rewards_mean           1762.2998845834277
total_rewards_std            1139.7996539998096
total_rewards_max            3241.318669561993
total_rewards_min            84.47355462493428
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               28.461923066992313
(Previous) Eval Time (s)     25.551175964064896
Sample Time (s)              17.916298083029687
Epoch Time (s)               71.9293971140869
Total Train Time (s)         24101.813871048857
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:57:14.107835 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #348 | Epoch Duration: 63.42081928253174
2020-01-11 09:57:14.108064 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0279965
Z variance train             0.0076353317
KL Divergence                24.696949
KL Loss                      2.4696949
QF Loss                      1769.1106
VF Loss                      194.13562
Policy Loss                  -1141.7802
Q Predictions Mean           1145.0074
Q Predictions Std            241.42737
Q Predictions Max            1353.715
Q Predictions Min            4.625004
V Predictions Mean           1150.8037
V Predictions Std            240.73193
V Predictions Max            1344.6644
V Predictions Min            14.192532
Log Pis Mean                 -0.09663627
Log Pis Std                  2.9284766
Log Pis Max                  13.985065
Log Pis Min                  -8.067235
Policy mu Mean               -0.010002548
Policy mu Std                0.6607612
Policy mu Max                3.1375005
Policy mu Min                -2.9943266
Policy log std Mean          -0.94692546
Policy log std Std           0.25859433
Policy log std Max           -0.24249518
Policy log std Min           -2.0995965
Z mean eval                  1.043331
Z variance eval              0.010283906
total_rewards                [2830.89102761 2918.74732766 3169.85552961 3032.20905355 2031.55525604
 2983.84654327 3048.83228467 3105.94978928 3130.5458637  3241.06225186]
total_rewards_mean           2949.3494927248757
total_rewards_std            326.5490414088069
total_rewards_max            3241.062251857391
total_rewards_min            2031.5552560386027
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               30.89896528236568
(Previous) Eval Time (s)     17.042256526183337
Sample Time (s)              18.205460749100894
Epoch Time (s)               66.14668255764991
Total Train Time (s)         24176.888787053525
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:58:29.184840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #349 | Epoch Duration: 75.07661128044128
2020-01-11 09:58:29.184993 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0421137
Z variance train             0.010282113
KL Divergence                24.46883
KL Loss                      2.446883
QF Loss                      711.8219
VF Loss                      115.42007
Policy Loss                  -1162.5277
Q Predictions Mean           1162.9414
Q Predictions Std            201.64297
Q Predictions Max            1357.8354
Q Predictions Min            10.596499
V Predictions Mean           1160.4403
V Predictions Std            200.65007
V Predictions Max            1333.9377
V Predictions Min            1.8635069
Log Pis Mean                 -0.15805644
Log Pis Std                  2.5731454
Log Pis Max                  8.966317
Log Pis Min                  -8.428847
Policy mu Mean               -0.045564108
Policy mu Std                0.5831258
Policy mu Max                1.9893576
Policy mu Min                -2.201113
Policy log std Mean          -0.9968686
Policy log std Std           0.2666649
Policy log std Max           0.17035675
Policy log std Min           -2.1928613
Z mean eval                  1.0179751
Z variance eval              0.01309344
total_rewards                [ 725.0227942  3571.54941839 2063.20269461  583.50660071 1030.02928877
  925.00155516  958.52606606 1375.74696853 3421.11467048 3419.06222223]
total_rewards_mean           1807.2762279136616
total_rewards_std            1154.9236855293016
total_rewards_max            3571.5494183896053
total_rewards_min            583.5066007088792
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               30.73679610528052
(Previous) Eval Time (s)     25.971876721829176
Sample Time (s)              18.23699684534222
Epoch Time (s)               74.94566967245191
Total Train Time (s)         24242.03011422651
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:59:34.333029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #350 | Epoch Duration: 65.14787435531616
2020-01-11 09:59:34.333337 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0201255
Z variance train             0.0130569395
KL Divergence                23.714508
KL Loss                      2.371451
QF Loss                      1085.0593
VF Loss                      196.24672
Policy Loss                  -1149.7734
Q Predictions Mean           1147.9031
Q Predictions Std            210.47319
Q Predictions Max            1375.7311
Q Predictions Min            57.119873
V Predictions Mean           1140.1796
V Predictions Std            211.88382
V Predictions Max            1363.57
V Predictions Min            39.945023
Log Pis Mean                 -0.2042175
Log Pis Std                  2.5747724
Log Pis Max                  8.523798
Log Pis Min                  -7.495237
Policy mu Mean               0.016942088
Policy mu Std                0.60405105
Policy mu Max                2.2705548
Policy mu Min                -2.0706096
Policy log std Mean          -0.9848777
Policy log std Std           0.23309116
Policy log std Max           -0.2047475
Policy log std Min           -2.1437297
Z mean eval                  1.0382478
Z variance eval              0.015079315
total_rewards                [3317.74266806 3108.19440897 3046.34903227  254.68992717  935.11963782
 3224.09826855 2960.57616969 3065.28555697 3500.05580061 3388.41306612]
total_rewards_mean           2680.0524536223406
total_rewards_std            1065.2964675508138
total_rewards_max            3500.0558006147576
total_rewards_min            254.68992717393064
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               26.677798813208938
(Previous) Eval Time (s)     16.173750557936728
Sample Time (s)              19.6432752199471
Epoch Time (s)               62.494824591092765
Total Train Time (s)         24312.767424063757
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:00:45.075698 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #351 | Epoch Duration: 70.74211764335632
2020-01-11 10:00:45.076002 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0395072
Z variance train             0.015084542
KL Divergence                22.677511
KL Loss                      2.2677512
QF Loss                      768.61
VF Loss                      319.9837
Policy Loss                  -1135.1593
Q Predictions Mean           1133.7302
Q Predictions Std            237.34637
Q Predictions Max            1350.322
Q Predictions Min            52.11398
V Predictions Mean           1134.6414
V Predictions Std            233.54732
V Predictions Max            1351.8501
V Predictions Min            58.588627
Log Pis Mean                 -0.041531906
Log Pis Std                  2.7290103
Log Pis Max                  12.009189
Log Pis Min                  -7.414036
Policy mu Mean               -0.055245966
Policy mu Std                0.6157071
Policy mu Max                2.353957
Policy mu Min                -2.3876235
Policy log std Mean          -0.9782201
Policy log std Std           0.27312654
Policy log std Max           -0.19204748
Policy log std Min           -2.56414
Z mean eval                  1.0066975
Z variance eval              0.012123516
total_rewards                [ 398.9245151    62.65138576 1710.44362826 3172.87039303 3321.21251161
 1498.31709131  857.12777707 3272.07565356 1906.94809532 3264.46529654]
total_rewards_mean           1946.5036347564333
total_rewards_std            1194.8541489612896
total_rewards_max            3321.212511607302
total_rewards_min            62.651385762017725
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               28.313547597732395
(Previous) Eval Time (s)     24.420731232035905
Sample Time (s)              18.143305318430066
Epoch Time (s)               70.87758414819837
Total Train Time (s)         24375.54909896385
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:01:47.860021 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #352 | Epoch Duration: 62.783809423446655
2020-01-11 10:01:47.860207 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0075824
Z variance train             0.012092894
KL Divergence                23.946135
KL Loss                      2.3946135
QF Loss                      1170.1936
VF Loss                      569.232
Policy Loss                  -1162.9058
Q Predictions Mean           1160.9248
Q Predictions Std            221.4864
Q Predictions Max            1356.2285
Q Predictions Min            109.30809
V Predictions Mean           1162.3456
V Predictions Std            219.98776
V Predictions Max            1357.3015
V Predictions Min            142.18544
Log Pis Mean                 -0.46135747
Log Pis Std                  2.7501864
Log Pis Max                  14.613127
Log Pis Min                  -9.430922
Policy mu Mean               0.031094845
Policy mu Std                0.5877112
Policy mu Max                2.3381498
Policy mu Min                -2.3357341
Policy log std Mean          -0.96597505
Policy log std Std           0.27442017
Policy log std Max           -0.18238133
Policy log std Min           -3.1193838
Z mean eval                  1.0462314
Z variance eval              0.009773475
total_rewards                [3182.01150558 3016.54039299 1664.95998553 1292.46835558 3324.48042914
 3185.00457663 3140.20407638 1759.75137823 3359.23660438 1633.56726304]
total_rewards_mean           2555.822456746556
total_rewards_std            803.2458192904763
total_rewards_max            3359.2366043768193
total_rewards_min            1292.4683555803435
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               29.52053381688893
(Previous) Eval Time (s)     16.32666878402233
Sample Time (s)              17.421928016934544
Epoch Time (s)               63.2691306178458
Total Train Time (s)         24445.61304865824
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:02:57.931881 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #353 | Epoch Duration: 70.07148671150208
2020-01-11 10:02:57.932121 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0465553
Z variance train             0.00977569
KL Divergence                24.31175
KL Loss                      2.431175
QF Loss                      6096.42
VF Loss                      181.58435
Policy Loss                  -1157.1759
Q Predictions Mean           1157.9965
Q Predictions Std            210.44006
Q Predictions Max            1330.3423
Q Predictions Min            19.885221
V Predictions Mean           1161.9243
V Predictions Std            210.66046
V Predictions Max            1335.6797
V Predictions Min            2.1584418
Log Pis Mean                 -0.041750822
Log Pis Std                  2.6157863
Log Pis Max                  15.470556
Log Pis Min                  -6.0335917
Policy mu Mean               -0.022597253
Policy mu Std                0.5985908
Policy mu Max                2.173489
Policy mu Min                -2.2734122
Policy log std Mean          -0.969661
Policy log std Std           0.2788658
Policy log std Max           0.5422113
Policy log std Min           -3.2825923
Z mean eval                  1.0432452
Z variance eval              0.008254779
total_rewards                [ -98.2889366  3052.89986224 1802.1979627  3389.61250017 1719.33866363
 1982.1213579   772.01090628 1464.58881104 3167.68089243 2636.099869  ]
total_rewards_mean           1988.8261888776583
total_rewards_std            1054.6150522535943
total_rewards_max            3389.6125001657642
total_rewards_min            -98.28893659695717
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               26.253711177036166
(Previous) Eval Time (s)     23.12875723093748
Sample Time (s)              18.943053773604333
Epoch Time (s)               68.32552218157798
Total Train Time (s)         24513.365216060076
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:04:05.689133 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #354 | Epoch Duration: 67.7568154335022
2020-01-11 10:04:05.689417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0447825
Z variance train             0.00830835
KL Divergence                24.733458
KL Loss                      2.4733458
QF Loss                      654.9707
VF Loss                      106.065735
Policy Loss                  -1151.6271
Q Predictions Mean           1151.6099
Q Predictions Std            249.7721
Q Predictions Max            1369.3843
Q Predictions Min            31.631598
V Predictions Mean           1149.1311
V Predictions Std            246.43918
V Predictions Max            1366.3828
V Predictions Min            46.095436
Log Pis Mean                 -0.28579655
Log Pis Std                  2.5759733
Log Pis Max                  9.048721
Log Pis Min                  -8.179902
Policy mu Mean               0.018237159
Policy mu Std                0.58994246
Policy mu Max                2.2614188
Policy mu Min                -3.007348
Policy log std Mean          -0.9699839
Policy log std Std           0.25816268
Policy log std Max           0.010779619
Policy log std Min           -1.9892654
Z mean eval                  1.0380774
Z variance eval              0.009039312
total_rewards                [3198.79473063  324.0424702  3362.08563488 1833.43562356 3207.26444149
 3275.92652993 3311.86152638 3164.72914986 2926.71064185 3040.07881045]
total_rewards_mean           2764.492955922661
total_rewards_std            915.8643875396552
total_rewards_max            3362.085634880485
total_rewards_min            324.0424701985459
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               29.014781466685236
(Previous) Eval Time (s)     22.559735811781138
Sample Time (s)              18.836914707440883
Epoch Time (s)               70.41143198590726
Total Train Time (s)         24584.276095107663
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:05:16.606460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #355 | Epoch Duration: 70.91678857803345
2020-01-11 10:05:16.606742 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0373826
Z variance train             0.009022741
KL Divergence                24.393145
KL Loss                      2.4393146
QF Loss                      1064.1086
VF Loss                      400.58017
Policy Loss                  -1145.0913
Q Predictions Mean           1142.2723
Q Predictions Std            246.50769
Q Predictions Max            1361.4999
Q Predictions Min            18.507275
V Predictions Mean           1143.6528
V Predictions Std            241.58209
V Predictions Max            1362.4935
V Predictions Min            43.218563
Log Pis Mean                 -0.0054832287
Log Pis Std                  2.667461
Log Pis Max                  11.247547
Log Pis Min                  -6.803172
Policy mu Mean               0.050650094
Policy mu Std                0.58867234
Policy mu Max                2.7147877
Policy mu Min                -2.140011
Policy log std Mean          -0.9908124
Policy log std Std           0.27263546
Policy log std Max           -0.007361412
Policy log std Min           -2.6998906
Z mean eval                  1.0252656
Z variance eval              0.009264717
total_rewards                [ 479.61154777 1382.4446049   445.99135663 3145.22703541 2083.93104995
 3133.50412601  874.79031439 3048.45574543  -98.92868088  245.43717875]
total_rewards_mean           1474.0464278348836
total_rewards_std            1216.3221838765137
total_rewards_max            3145.2270354051134
total_rewards_min            -98.92868087606033
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               29.966282036155462
(Previous) Eval Time (s)     23.06476165819913
Sample Time (s)              18.88575069885701
Epoch Time (s)               71.9167943932116
Total Train Time (s)         24650.616974751465
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:22.951409 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #356 | Epoch Duration: 66.34435224533081
2020-01-11 10:06:22.951747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0256771
Z variance train             0.009265149
KL Divergence                24.37878
KL Loss                      2.4378781
QF Loss                      1532.7361
VF Loss                      581.71735
Policy Loss                  -1152.8535
Q Predictions Mean           1149.6577
Q Predictions Std            237.84938
Q Predictions Max            1405.1414
Q Predictions Min            30.422865
V Predictions Mean           1140.9219
V Predictions Std            233.00122
V Predictions Max            1369.7915
V Predictions Min            18.320124
Log Pis Mean                 0.03599602
Log Pis Std                  2.7919323
Log Pis Max                  16.125668
Log Pis Min                  -6.5550556
Policy mu Mean               0.05765555
Policy mu Std                0.61162806
Policy mu Max                2.5846517
Policy mu Min                -1.9966733
Policy log std Mean          -1.001014
Policy log std Std           0.3169511
Policy log std Max           -0.10182595
Policy log std Min           -3.500032
Z mean eval                  1.0127617
Z variance eval              0.012167757
total_rewards                [ -17.02782152 3187.39863065 3401.6996909  2889.46232155 3340.80557509
 3282.54035065 1028.2233201   237.84103974 1930.5541996  2741.51726894]
total_rewards_mean           2202.301457569224
total_rewards_std            1259.8355934708295
total_rewards_max            3401.699690895034
total_rewards_min            -17.02782151555922
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               31.04513581423089
(Previous) Eval Time (s)     17.491982927080244
Sample Time (s)              18.196650312282145
Epoch Time (s)               66.73376905359328
Total Train Time (s)         24721.351392933168
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:07:33.690008 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #357 | Epoch Duration: 70.73802995681763
2020-01-11 10:07:33.690250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0122802
Z variance train             0.0121364035
KL Divergence                23.68524
KL Loss                      2.368524
QF Loss                      739.5372
VF Loss                      364.73215
Policy Loss                  -1164.8077
Q Predictions Mean           1162.6089
Q Predictions Std            211.00215
Q Predictions Max            1353.9429
Q Predictions Min            47.32496
V Predictions Mean           1152.9216
V Predictions Std            206.82526
V Predictions Max            1333.6292
V Predictions Min            45.22043
Log Pis Mean                 -0.19207689
Log Pis Std                  2.6932464
Log Pis Max                  12.17292
Log Pis Min                  -6.8126955
Policy mu Mean               -0.015851378
Policy mu Std                0.605812
Policy mu Max                2.5369692
Policy mu Min                -2.1886215
Policy log std Mean          -0.9674889
Policy log std Std           0.27999315
Policy log std Max           -0.107601404
Policy log std Min           -3.1618648
Z mean eval                  1.075789
Z variance eval              0.0069881068
total_rewards                [3303.3488628  3427.49132471  832.61515693  740.81305263  804.97516635
 2515.16692121 3173.02846484 1668.94325346 3022.56283724 3169.6400597 ]
total_rewards_mean           2265.8585099869088
total_rewards_std            1075.6741928239255
total_rewards_max            3427.491324714769
total_rewards_min            740.8130526319536
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               29.885734441690147
(Previous) Eval Time (s)     21.495961582753807
Sample Time (s)              19.290673398878425
Epoch Time (s)               70.67236942332238
Total Train Time (s)         24789.487816771027
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:08:41.830508 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #358 | Epoch Duration: 68.14007925987244
2020-01-11 10:08:41.830701 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0760843
Z variance train             0.006981538
KL Divergence                24.70729
KL Loss                      2.470729
QF Loss                      774.6759
VF Loss                      166.45413
Policy Loss                  -1143.9615
Q Predictions Mean           1145.081
Q Predictions Std            235.39838
Q Predictions Max            1392.8934
Q Predictions Min            71.93862
V Predictions Mean           1147.5027
V Predictions Std            236.07841
V Predictions Max            1386.843
V Predictions Min            43.013283
Log Pis Mean                 -0.37903827
Log Pis Std                  2.3906214
Log Pis Max                  8.815872
Log Pis Min                  -5.574041
Policy mu Mean               0.021543559
Policy mu Std                0.58726007
Policy mu Max                2.336184
Policy mu Min                -1.9915444
Policy log std Mean          -0.95940447
Policy log std Std           0.26626435
Policy log std Max           -0.08507943
Policy log std Min           -2.554189
Z mean eval                  1.0680902
Z variance eval              0.0065347487
total_rewards                [1391.64339074  211.90056861 2864.87919458 3386.20514931   44.58614624
 3161.88673757  898.88527569 3219.14961124 3015.22546686   28.06911687]
total_rewards_mean           1822.2430657718917
total_rewards_std            1367.940075390081
total_rewards_max            3386.205149313493
total_rewards_min            28.06911686763499
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               26.953898450825363
(Previous) Eval Time (s)     18.963293965905905
Sample Time (s)              17.924877545796335
Epoch Time (s)               63.8420699625276
Total Train Time (s)         24849.9554443229
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:42.303945 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #359 | Epoch Duration: 60.473053216934204
2020-01-11 10:09:42.304232 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0637071
Z variance train             0.006522103
KL Divergence                24.901663
KL Loss                      2.4901664
QF Loss                      3551.6826
VF Loss                      2799.9177
Policy Loss                  -1175.2859
Q Predictions Mean           1173.7268
Q Predictions Std            225.82033
Q Predictions Max            1378.0248
Q Predictions Min            69.4518
V Predictions Mean           1167.8003
V Predictions Std            206.5182
V Predictions Max            1356.5171
V Predictions Min            50.905552
Log Pis Mean                 -0.19054055
Log Pis Std                  2.760766
Log Pis Max                  12.2237835
Log Pis Min                  -9.081968
Policy mu Mean               0.0057059317
Policy mu Std                0.59721303
Policy mu Max                2.4101193
Policy mu Min                -2.3082714
Policy log std Mean          -0.9792311
Policy log std Std           0.26841965
Policy log std Max           -0.24240011
Policy log std Min           -3.1648507
Z mean eval                  1.0457815
Z variance eval              0.010492642
total_rewards                [3354.65903397 2370.6495908  3325.55535112 3457.76617954 3635.61123302
 3264.29982807 3258.03629123 3468.13815244 3343.41471201 3230.75982078]
total_rewards_mean           3270.889019296238
total_rewards_std            321.6159786574033
total_rewards_max            3635.611233017636
total_rewards_min            2370.6495907987046
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               28.18517016293481
(Previous) Eval Time (s)     15.593964114785194
Sample Time (s)              18.43208595085889
Epoch Time (s)               62.211220228578895
Total Train Time (s)         24922.10704424884
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:10:54.460849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #360 | Epoch Duration: 72.15629720687866
2020-01-11 10:10:54.461188 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0449626
Z variance train             0.010493597
KL Divergence                23.585905
KL Loss                      2.3585906
QF Loss                      620.4259
VF Loss                      157.39912
Policy Loss                  -1152.9886
Q Predictions Mean           1155.4225
Q Predictions Std            241.76884
Q Predictions Max            1378.4563
Q Predictions Min            -83.25872
V Predictions Mean           1160.157
V Predictions Std            239.08698
V Predictions Max            1383.8972
V Predictions Min            -41.581394
Log Pis Mean                 -0.08151417
Log Pis Std                  2.7882752
Log Pis Max                  20.858198
Log Pis Min                  -7.485083
Policy mu Mean               -0.022362687
Policy mu Std                0.59208244
Policy mu Max                2.4046035
Policy mu Min                -2.9802341
Policy log std Mean          -0.9718932
Policy log std Std           0.26663798
Policy log std Max           0.11088157
Policy log std Min           -2.051501
Z mean eval                  1.0590037
Z variance eval              0.009858945
total_rewards                [ 483.76547782   28.54050708 3014.94314556 1057.00604383 2856.43865174
 1122.20482853  503.40159478 2907.21902356 2980.05751154 3222.45774198]
total_rewards_mean           1817.6034526397223
total_rewards_std            1216.3084383086027
total_rewards_max            3222.4577419813095
total_rewards_min            28.540507080453956
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               27.918184106238186
(Previous) Eval Time (s)     25.538680035620928
Sample Time (s)              18.270645547658205
Epoch Time (s)               71.72750968951732
Total Train Time (s)         24988.777156427503
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:01.136911 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #361 | Epoch Duration: 66.67551326751709
2020-01-11 10:12:01.137120 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0618149
Z variance train             0.009839431
KL Divergence                24.063753
KL Loss                      2.4063754
QF Loss                      639.477
VF Loss                      149.66188
Policy Loss                  -1155.4257
Q Predictions Mean           1160.385
Q Predictions Std            263.57193
Q Predictions Max            1364.4692
Q Predictions Min            38.441105
V Predictions Mean           1149.8937
V Predictions Std            262.18936
V Predictions Max            1354.974
V Predictions Min            11.132352
Log Pis Mean                 -0.08006829
Log Pis Std                  2.686722
Log Pis Max                  11.4818125
Log Pis Min                  -7.4674115
Policy mu Mean               0.102088846
Policy mu Std                0.5870343
Policy mu Max                3.4542403
Policy mu Min                -2.702118
Policy log std Mean          -0.9871503
Policy log std Std           0.29382813
Policy log std Max           0.13086021
Policy log std Min           -2.6009436
Z mean eval                  1.0032803
Z variance eval              0.013326155
total_rewards                [2970.8099039  3378.52287665 3448.3199317  3123.83352664 1985.13309318
 1342.19647751 1525.14600336 2277.24851573 3042.84861413 2764.23576575]
total_rewards_mean           2585.8294708539784
total_rewards_std            719.6066297804192
total_rewards_max            3448.319931699777
total_rewards_min            1342.1964775069657
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               25.342100691981614
(Previous) Eval Time (s)     20.48636183794588
Sample Time (s)              17.559597632382065
Epoch Time (s)               63.38806016230956
Total Train Time (s)         25053.743741394486
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:13:06.106613 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #362 | Epoch Duration: 64.9692394733429
2020-01-11 10:13:06.106916 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0036101
Z variance train             0.013353085
KL Divergence                22.925726
KL Loss                      2.2925727
QF Loss                      5121.66
VF Loss                      1059.9408
Policy Loss                  -1151.9246
Q Predictions Mean           1155.6599
Q Predictions Std            239.86865
Q Predictions Max            1375.0029
Q Predictions Min            33.98103
V Predictions Mean           1160.2214
V Predictions Std            242.89249
V Predictions Max            1371.4227
V Predictions Min            43.728447
Log Pis Mean                 -0.123962015
Log Pis Std                  2.872815
Log Pis Max                  15.845196
Log Pis Min                  -7.2494535
Policy mu Mean               0.005212531
Policy mu Std                0.5765674
Policy mu Max                2.123018
Policy mu Min                -2.4022439
Policy log std Mean          -1.0142832
Policy log std Std           0.29468098
Policy log std Max           -0.09346056
Policy log std Min           -3.610756
Z mean eval                  1.0231822
Z variance eval              0.012037283
total_rewards                [2067.24068104  482.50072245  645.72571112 2145.83635452   28.04430841
 3214.94047119 2371.35642679 1212.53371031  484.35507097  802.09687635]
total_rewards_mean           1345.463033316562
total_rewards_std            986.5756862296187
total_rewards_max            3214.9404711929365
total_rewards_min            28.044308414193175
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               30.0210149330087
(Previous) Eval Time (s)     22.06723247701302
Sample Time (s)              18.52584096090868
Epoch Time (s)               70.6140883709304
Total Train Time (s)         25120.67944658175
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:14:13.047302 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #363 | Epoch Duration: 66.94019556045532
2020-01-11 10:14:13.047546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0236328
Z variance train             0.012035395
KL Divergence                23.701986
KL Loss                      2.3701987
QF Loss                      1181.0798
VF Loss                      144.47455
Policy Loss                  -1177.718
Q Predictions Mean           1175.4615
Q Predictions Std            216.33766
Q Predictions Max            1383.1791
Q Predictions Min            16.341318
V Predictions Mean           1176.737
V Predictions Std            214.51854
V Predictions Max            1378.2094
V Predictions Min            21.476507
Log Pis Mean                 0.3048653
Log Pis Std                  2.761308
Log Pis Max                  14.556942
Log Pis Min                  -7.858931
Policy mu Mean               0.0016439937
Policy mu Std                0.6615638
Policy mu Max                3.1797209
Policy mu Min                -3.0917335
Policy log std Mean          -0.9975946
Policy log std Std           0.25155777
Policy log std Max           -0.16727364
Policy log std Min           -2.0693984
Z mean eval                  1.0216628
Z variance eval              0.0111947525
total_rewards                [3165.49580875  750.96377708 3155.18534683 1344.83712387 3390.79493963
  833.71412266 3060.80915541 1349.52967517 3183.83649653 3220.72095866]
total_rewards_mean           2345.588740456924
total_rewards_std            1059.3600568145098
total_rewards_max            3390.794939625774
total_rewards_min            750.9637770760891
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               28.04392139893025
(Previous) Eval Time (s)     18.393006114289165
Sample Time (s)              17.55563693959266
Epoch Time (s)               63.992564452812076
Total Train Time (s)         25190.69720222894
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:23.069475 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #364 | Epoch Duration: 70.02173948287964
2020-01-11 10:15:23.069706 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0197966
Z variance train             0.011194621
KL Divergence                23.663296
KL Loss                      2.3663297
QF Loss                      673.8032
VF Loss                      1345.2748
Policy Loss                  -1159.1014
Q Predictions Mean           1161.0303
Q Predictions Std            244.6821
Q Predictions Max            1380.5332
Q Predictions Min            64.51013
V Predictions Mean           1158.3918
V Predictions Std            247.74518
V Predictions Max            1374.3674
V Predictions Min            64.30359
Log Pis Mean                 -0.046598844
Log Pis Std                  2.8418815
Log Pis Max                  12.352081
Log Pis Min                  -8.671959
Policy mu Mean               0.0029845897
Policy mu Std                0.57989305
Policy mu Max                1.978957
Policy mu Min                -2.6850097
Policy log std Mean          -1.0189064
Policy log std Std           0.29130706
Policy log std Max           -0.1544118
Policy log std Min           -2.6675167
Z mean eval                  1.062602
Z variance eval              0.013833182
total_rewards                [3062.99939656 1281.87404207 3181.74127921 3194.64051149 2512.06472946
 3164.0179612  3051.24111372 3351.54093118 3287.83376148 2426.43513141]
total_rewards_mean           2851.43888577807
total_rewards_std            600.7620857337072
total_rewards_max            3351.540931182404
total_rewards_min            1281.8740420726156
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               29.28731579799205
(Previous) Eval Time (s)     24.421881386078894
Sample Time (s)              18.962535026017576
Epoch Time (s)               72.67173221008852
Total Train Time (s)         25264.659541579895
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:16:37.034841 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #365 | Epoch Duration: 73.96495985984802
2020-01-11 10:16:37.035052 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0625287
Z variance train             0.013813421
KL Divergence                23.597359
KL Loss                      2.359736
QF Loss                      2263.7808
VF Loss                      1612.9154
Policy Loss                  -1197.0409
Q Predictions Mean           1198.7228
Q Predictions Std            182.68376
Q Predictions Max            1385.6255
Q Predictions Min            129.94493
V Predictions Mean           1189.3203
V Predictions Std            187.70807
V Predictions Max            1374.4464
V Predictions Min            116.73331
Log Pis Mean                 0.0168011
Log Pis Std                  2.6196222
Log Pis Max                  14.825928
Log Pis Min                  -7.8164864
Policy mu Mean               0.035983544
Policy mu Std                0.5812685
Policy mu Max                2.4412792
Policy mu Min                -1.9614339
Policy log std Mean          -0.9898204
Policy log std Std           0.2587075
Policy log std Max           -0.216174
Policy log std Min           -2.9412947
Z mean eval                  0.9985846
Z variance eval              0.012759608
total_rewards                [3187.41409141  692.52472889 1973.86511667 3464.95967685  231.56227415
 2753.88139024 2192.05613218 1690.26413938   22.01711206 3153.6395359 ]
total_rewards_mean           1936.2184197736303
total_rewards_std            1195.7167006444456
total_rewards_max            3464.9596768467263
total_rewards_min            22.01711206394866
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               28.117284012958407
(Previous) Eval Time (s)     25.71473567839712
Sample Time (s)              18.450358969625086
Epoch Time (s)               72.28237866098061
Total Train Time (s)         25328.819939220324
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:41.200546 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #366 | Epoch Duration: 64.16532588005066
2020-01-11 10:17:41.200767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #366 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.99789107
Z variance train             0.012859581
KL Divergence                23.492151
KL Loss                      2.3492153
QF Loss                      1289.2523
VF Loss                      191.56331
Policy Loss                  -1149.4481
Q Predictions Mean           1150.8457
Q Predictions Std            271.5522
Q Predictions Max            1398.8682
Q Predictions Min            -14.353775
V Predictions Mean           1146.5598
V Predictions Std            269.4657
V Predictions Max            1392.8811
V Predictions Min            -54.99979
Log Pis Mean                 -0.47027016
Log Pis Std                  2.8284056
Log Pis Max                  7.9969454
Log Pis Min                  -10.431415
Policy mu Mean               0.01105339
Policy mu Std                0.58571464
Policy mu Max                2.5301073
Policy mu Min                -2.1010184
Policy log std Mean          -0.99023193
Policy log std Std           0.27137902
Policy log std Max           -0.13735545
Policy log std Min           -2.4623098
Z mean eval                  1.0078168
Z variance eval              0.015146121
total_rewards                [3296.2969192    19.29102013 3227.4495938   652.21816703 3360.732837
 3546.54674942 2508.73299382 3267.93360824 1525.66228998 3428.92854361]
total_rewards_mean           2483.37927222308
total_rewards_std            1223.39223365784
total_rewards_max            3546.5467494191153
total_rewards_min            19.29102013498741
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               27.667590137105435
(Previous) Eval Time (s)     17.597398161888123
Sample Time (s)              18.1715099317953
Epoch Time (s)               63.43649823078886
Total Train Time (s)         25394.132659547962
Epoch                        367
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:18:46.520431 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #367 | Epoch Duration: 65.31945562362671
2020-01-11 10:18:46.520746 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #367 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0077013
Z variance train             0.015090826
KL Divergence                23.755703
KL Loss                      2.3755703
QF Loss                      732.1476
VF Loss                      277.006
Policy Loss                  -1154.2109
Q Predictions Mean           1152.5327
Q Predictions Std            269.187
Q Predictions Max            1388.4186
Q Predictions Min            31.744371
V Predictions Mean           1155.7515
V Predictions Std            265.15744
V Predictions Max            1407.7207
V Predictions Min            34.148216
Log Pis Mean                 0.08371865
Log Pis Std                  2.690371
Log Pis Max                  11.144128
Log Pis Min                  -5.3005867
Policy mu Mean               -0.018881764
Policy mu Std                0.61857593
Policy mu Max                2.4571939
Policy mu Min                -2.0929189
Policy log std Mean          -1.0032415
Policy log std Std           0.28839284
Policy log std Max           -0.1362716
Policy log std Min           -2.5621696
Z mean eval                  1.0208021
Z variance eval              0.014149666
total_rewards                [2692.08768162 1619.7138192  1168.58306974 3552.30755099 3556.4251081
 3552.24930352  361.08190489 3247.56918005 3203.05489008  762.77214327]
total_rewards_mean           2371.5844651464104
total_rewards_std            1199.8440678978766
total_rewards_max            3556.425108102014
total_rewards_min            361.0819048878168
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               31.143161787185818
(Previous) Eval Time (s)     19.480037606321275
Sample Time (s)              17.856969045940787
Epoch Time (s)               68.48016843944788
Total Train Time (s)         25466.222683897242
Epoch                        368
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:19:58.616393 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #368 | Epoch Duration: 72.09537291526794
2020-01-11 10:19:58.616747 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0196617
Z variance train             0.014085782
KL Divergence                24.278812
KL Loss                      2.4278812
QF Loss                      976.25867
VF Loss                      127.73022
Policy Loss                  -1178.5627
Q Predictions Mean           1178.856
Q Predictions Std            236.86852
Q Predictions Max            1414.6337
Q Predictions Min            43.213158
V Predictions Mean           1180.533
V Predictions Std            237.63005
V Predictions Max            1416.5416
V Predictions Min            40.998608
Log Pis Mean                 -0.013660543
Log Pis Std                  2.8212543
Log Pis Max                  12.377348
Log Pis Min                  -7.3643312
Policy mu Mean               0.02259176
Policy mu Std                0.5926204
Policy mu Max                2.0171452
Policy mu Min                -2.332323
Policy log std Mean          -0.99907005
Policy log std Std           0.25760266
Policy log std Max           -0.07908833
Policy log std Min           -2.1455817
Z mean eval                  1.0217491
Z variance eval              0.0122233415
total_rewards                [3137.42104847  618.9005031  3487.36180326 1075.978664   3071.05353825
 2759.85693356 3362.96486727 2490.37300688 1986.61223935 2424.98424431]
total_rewards_mean           2441.5506848444847
total_rewards_std            912.1963028194808
total_rewards_max            3487.3618032583163
total_rewards_min            618.9005030981023
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               27.393707429990172
(Previous) Eval Time (s)     23.09492112090811
Sample Time (s)              17.798045669682324
Epoch Time (s)               68.28667422058061
Total Train Time (s)         25531.495930894744
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:03.894873 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #369 | Epoch Duration: 65.27786755561829
2020-01-11 10:21:03.895116 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0224347
Z variance train             0.012248352
KL Divergence                23.624554
KL Loss                      2.3624554
QF Loss                      1856.1693
VF Loss                      277.39386
Policy Loss                  -1156.9843
Q Predictions Mean           1155.8037
Q Predictions Std            279.1057
Q Predictions Max            1414.6279
Q Predictions Min            11.815375
V Predictions Mean           1157.7917
V Predictions Std            274.46658
V Predictions Max            1411.4762
V Predictions Min            69.72299
Log Pis Mean                 -0.38878012
Log Pis Std                  2.7502365
Log Pis Max                  14.469484
Log Pis Min                  -7.44635
Policy mu Mean               0.007865584
Policy mu Std                0.5942808
Policy mu Max                2.7786279
Policy mu Min                -2.2512217
Policy log std Mean          -0.9753272
Policy log std Std           0.27462184
Policy log std Max           -0.17324638
Policy log std Min           -2.0314221
Z mean eval                  1.002944
Z variance eval              0.015217835
total_rewards                [1784.75672215   70.23625263 3432.92326207  805.47152419 3619.33815055
 3193.19563086 1189.47063135 3383.30624241 1172.79595054  392.3830829 ]
total_rewards_mean           1904.387744964819
total_rewards_std            1305.5356249192414
total_rewards_max            3619.3381505516645
total_rewards_min            70.23625262810815
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               27.379461736883968
(Previous) Eval Time (s)     20.085813351906836
Sample Time (s)              17.55261391075328
Epoch Time (s)               65.01788899954408
Total Train Time (s)         25591.94446252659
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:22:04.351079 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #370 | Epoch Duration: 60.45574426651001
2020-01-11 10:22:04.351375 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0016794
Z variance train             0.01523073
KL Divergence                23.049194
KL Loss                      2.3049195
QF Loss                      669.91516
VF Loss                      114.663315
Policy Loss                  -1161.0602
Q Predictions Mean           1162.0059
Q Predictions Std            265.20084
Q Predictions Max            1429.4048
Q Predictions Min            -7.951243
V Predictions Mean           1165.1333
V Predictions Std            267.90622
V Predictions Max            1431.6854
V Predictions Min            -23.064991
Log Pis Mean                 -0.35160238
Log Pis Std                  2.4914253
Log Pis Max                  7.678337
Log Pis Min                  -9.571658
Policy mu Mean               0.02492949
Policy mu Std                0.58350694
Policy mu Max                2.093635
Policy mu Min                -2.0693378
Policy log std Mean          -0.97636735
Policy log std Std           0.25859582
Policy log std Max           -0.10462266
Policy log std Min           -2.1855147
Z mean eval                  1.011009
Z variance eval              0.01308158
total_rewards                [ 778.62996084 3237.66360814 3127.27922914 3418.80619877 3415.90575717
 3295.86336886 1297.46167359 3435.09189073 3509.16289845 3328.5688521 ]
total_rewards_mean           2884.443343779742
total_rewards_std            936.1993833437823
total_rewards_max            3509.162898452535
total_rewards_min            778.6299608364366
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               26.800557070877403
(Previous) Eval Time (s)     15.523325381800532
Sample Time (s)              19.05318430857733
Epoch Time (s)               61.377066761255264
Total Train Time (s)         25660.426981495228
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:23:12.835724 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #371 | Epoch Duration: 68.484126329422
2020-01-11 10:23:12.835981 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #371 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0108707
Z variance train             0.013088484
KL Divergence                23.51001
KL Loss                      2.351001
QF Loss                      1405.0403
VF Loss                      146.55876
Policy Loss                  -1168.8564
Q Predictions Mean           1168.39
Q Predictions Std            270.31683
Q Predictions Max            1370.2363
Q Predictions Min            22.094458
V Predictions Mean           1166.0286
V Predictions Std            270.60843
V Predictions Max            1375.757
V Predictions Min            25.760954
Log Pis Mean                 -0.061355792
Log Pis Std                  3.1471374
Log Pis Max                  14.51868
Log Pis Min                  -7.690611
Policy mu Mean               0.027299624
Policy mu Std                0.60326743
Policy mu Max                2.8626223
Policy mu Min                -4.110896
Policy log std Mean          -1.0000567
Policy log std Std           0.2891319
Policy log std Max           -0.007569909
Policy log std Min           -2.343452
Z mean eval                  1.04422
Z variance eval              0.01766969
total_rewards                [3229.09104339 2243.3856982  3427.8286269   636.1804456  1991.2885348
 3351.2148975    30.95799865 3202.08692486 3563.95576472 2621.66626124]
total_rewards_mean           2429.7656195852933
total_rewards_std            1166.2777721968298
total_rewards_max            3563.955764716834
total_rewards_min            30.95799865436243
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               29.28902501333505
(Previous) Eval Time (s)     22.630080560222268
Sample Time (s)              18.252115786541253
Epoch Time (s)               70.17122136009857
Total Train Time (s)         25730.712596795987
Epoch                        372
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:23.124997 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #372 | Epoch Duration: 70.28877449035645
2020-01-11 10:24:23.125251 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.045638
Z variance train             0.017741209
KL Divergence                23.646852
KL Loss                      2.3646853
QF Loss                      802.5237
VF Loss                      116.602646
Policy Loss                  -1195.5557
Q Predictions Mean           1195.4558
Q Predictions Std            261.41025
Q Predictions Max            1465.7681
Q Predictions Min            8.498764
V Predictions Mean           1201.5568
V Predictions Std            262.32278
V Predictions Max            1472.5807
V Predictions Min            12.799059
Log Pis Mean                 -0.20470989
Log Pis Std                  2.7787702
Log Pis Max                  7.8815823
Log Pis Min                  -9.263371
Policy mu Mean               0.018775161
Policy mu Std                0.62571096
Policy mu Max                2.6958952
Policy mu Min                -2.5717256
Policy log std Mean          -0.9620676
Policy log std Std           0.2637561
Policy log std Max           -0.074310064
Policy log std Min           -2.005996
Z mean eval                  1.0203168
Z variance eval              0.016080774
total_rewards                [2804.33441223 1466.60989697 1925.449097   3157.55742734 3155.28621261
 3211.78533307 3012.37807475 3096.61510784 3151.33122157 2238.95050224]
total_rewards_mean           2722.029728562668
total_rewards_std            589.6551115598594
total_rewards_max            3211.785333070973
total_rewards_min            1466.6098969738973
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               29.482706129085273
(Previous) Eval Time (s)     22.747342112008482
Sample Time (s)              17.590391299221665
Epoch Time (s)               69.82043954031542
Total Train Time (s)         25802.332088989206
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:25:34.749909 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #373 | Epoch Duration: 71.6244912147522
2020-01-11 10:25:34.750182 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0225546
Z variance train             0.016065344
KL Divergence                23.632172
KL Loss                      2.363217
QF Loss                      968.2206
VF Loss                      198.81842
Policy Loss                  -1147.9031
Q Predictions Mean           1144.5768
Q Predictions Std            302.63495
Q Predictions Max            1396.3557
Q Predictions Min            -60.480442
V Predictions Mean           1141.54
V Predictions Std            297.48282
V Predictions Max            1397.1034
V Predictions Min            2.7326775
Log Pis Mean                 -0.60770744
Log Pis Std                  2.7190197
Log Pis Max                  8.807031
Log Pis Min                  -8.721594
Policy mu Mean               0.00819079
Policy mu Std                0.5416429
Policy mu Max                2.348038
Policy mu Min                -2.0560477
Policy log std Mean          -0.9921553
Policy log std Std           0.30887777
Policy log std Max           -0.2241832
Policy log std Min           -3.0978794
Z mean eval                  1.0160518
Z variance eval              0.020595126
total_rewards                [2949.6609004   559.53385346  775.44981026 1601.08560548 2544.98811743
  506.22934748  101.95819461 3307.14710766 2554.42854284  142.47578029]
total_rewards_mean           1504.2957259899244
total_rewards_std            1173.6938883804592
total_rewards_max            3307.1471076625003
total_rewards_min            101.95819460599688
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               30.94963203696534
(Previous) Eval Time (s)     24.551102834753692
Sample Time (s)              17.770217281766236
Epoch Time (s)               73.27095215348527
Total Train Time (s)         25863.7463203785
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:26:36.170460 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #374 | Epoch Duration: 61.42004656791687
2020-01-11 10:26:36.170750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0165979
Z variance train             0.020605592
KL Divergence                22.657368
KL Loss                      2.2657368
QF Loss                      1013.3858
VF Loss                      134.36499
Policy Loss                  -1188.3947
Q Predictions Mean           1185.9052
Q Predictions Std            236.74762
Q Predictions Max            1365.7303
Q Predictions Min            20.313332
V Predictions Mean           1183.5774
V Predictions Std            232.7039
V Predictions Max            1362.0132
V Predictions Min            1.0790703
Log Pis Mean                 0.090322316
Log Pis Std                  2.7926939
Log Pis Max                  9.689169
Log Pis Min                  -8.924161
Policy mu Mean               -0.0034580105
Policy mu Std                0.61340827
Policy mu Max                2.5084398
Policy mu Min                -2.5517778
Policy log std Mean          -0.98142016
Policy log std Std           0.25919577
Policy log std Max           -0.20571029
Policy log std Min           -2.2731497
Z mean eval                  1.0221052
Z variance eval              0.015920747
total_rewards                [3334.30875572 2499.39824159 3478.61631746 3486.55756024  837.90831697
 3309.11412606 1354.52450805 2589.73035842 3301.1917083   637.75918007]
total_rewards_mean           2482.910907287792
total_rewards_std            1071.044625778834
total_rewards_max            3486.5575602367953
total_rewards_min            637.7591800657244
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               28.544296248350292
(Previous) Eval Time (s)     12.699880904052407
Sample Time (s)              17.79243152309209
Epoch Time (s)               59.03660867549479
Total Train Time (s)         25930.994730154052
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:43.424093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #375 | Epoch Duration: 67.25309944152832
2020-01-11 10:27:43.424340 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0230918
Z variance train             0.015908897
KL Divergence                22.349503
KL Loss                      2.2349503
QF Loss                      768.90894
VF Loss                      283.6929
Policy Loss                  -1197.8757
Q Predictions Mean           1197.8643
Q Predictions Std            245.26874
Q Predictions Max            1419.1854
Q Predictions Min            24.647226
V Predictions Mean           1193.3506
V Predictions Std            244.28537
V Predictions Max            1407.6006
V Predictions Min            10.357453
Log Pis Mean                 -0.20856783
Log Pis Std                  2.8414772
Log Pis Max                  11.155365
Log Pis Min                  -8.903247
Policy mu Mean               -0.07298273
Policy mu Std                0.5649299
Policy mu Max                2.992684
Policy mu Min                -3.8154356
Policy log std Mean          -1.0361423
Policy log std Std           0.2745973
Policy log std Max           -0.010664821
Policy log std Min           -2.2525203
Z mean eval                  1.0573933
Z variance eval              0.020054761
total_rewards                [2189.69119019 3303.39228182 2154.22282923 3228.18956486 2121.16730235
 3221.30681306 3143.38482232 3251.67854628 3185.29913024    3.88553379]
total_rewards_mean           2580.221801414772
total_rewards_std            983.3708334162748
total_rewards_max            3303.392281816563
total_rewards_min            3.885533794404168
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               29.002927834633738
(Previous) Eval Time (s)     20.916093311738223
Sample Time (s)              17.569444163236767
Epoch Time (s)               67.48846530960873
Total Train Time (s)         26003.24495009845
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:55.675837 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #376 | Epoch Duration: 72.25131058692932
2020-01-11 10:28:55.676033 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.05808
Z variance train             0.020042863
KL Divergence                22.016598
KL Loss                      2.20166
QF Loss                      1137.9629
VF Loss                      628.5109
Policy Loss                  -1184.3527
Q Predictions Mean           1184.2063
Q Predictions Std            255.86426
Q Predictions Max            1403.1555
Q Predictions Min            24.234632
V Predictions Mean           1193.5178
V Predictions Std            252.27242
V Predictions Max            1404.463
V Predictions Min            29.419266
Log Pis Mean                 -0.2426928
Log Pis Std                  3.0077958
Log Pis Max                  13.384534
Log Pis Min                  -9.066222
Policy mu Mean               -0.027830966
Policy mu Std                0.59705657
Policy mu Max                2.316385
Policy mu Min                -2.6999116
Policy log std Mean          -1.01073
Policy log std Std           0.28353742
Policy log std Max           -0.2595017
Policy log std Min           -3.1027837
Z mean eval                  1.0305147
Z variance eval              0.014270465
total_rewards                [3178.6100353  1331.64513561 3473.53114932 3562.72436889 1895.60418989
 3181.70437501 3516.98598363  944.78279167  167.27716728 3370.30163752]
total_rewards_mean           2462.316683412414
total_rewards_std            1198.7705072008278
total_rewards_max            3562.72436889388
total_rewards_min            167.27716727596848
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               31.60717121185735
(Previous) Eval Time (s)     25.678648785687983
Sample Time (s)              17.302924726624042
Epoch Time (s)               74.58874472416937
Total Train Time (s)         26073.90886657918
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:30:06.342381 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #377 | Epoch Duration: 70.66620659828186
2020-01-11 10:30:06.342575 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0303425
Z variance train             0.014245967
KL Divergence                21.792673
KL Loss                      2.1792674
QF Loss                      1440.5986
VF Loss                      221.65627
Policy Loss                  -1199.2542
Q Predictions Mean           1197.7542
Q Predictions Std            232.76978
Q Predictions Max            1430.9026
Q Predictions Min            -7.855971
V Predictions Mean           1201.8525
V Predictions Std            235.31784
V Predictions Max            1429.6461
V Predictions Min            -7.0425615
Log Pis Mean                 0.057953052
Log Pis Std                  2.5905108
Log Pis Max                  11.54875
Log Pis Min                  -7.010535
Policy mu Mean               0.047207944
Policy mu Std                0.5725133
Policy mu Max                2.313557
Policy mu Min                -2.1201758
Policy log std Mean          -1.0217855
Policy log std Std           0.2839266
Policy log std Max           0.45994788
Policy log std Min           -3.1033654
Z mean eval                  1.0144086
Z variance eval              0.010158809
total_rewards                [2879.13589264 1959.83436898 3353.17947351 3207.85491942 3266.93956304
  147.5548402  3049.48975421 3471.39215907 3062.58445237 3163.06735427]
total_rewards_mean           2756.1032777701757
total_rewards_std            955.6413379712618
total_rewards_max            3471.3921590702453
total_rewards_min            147.55484019910227
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               27.415950094815344
(Previous) Eval Time (s)     21.75582858035341
Sample Time (s)              17.861740121617913
Epoch Time (s)               67.03351879678667
Total Train Time (s)         26143.318876290694
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:15.755088 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #378 | Epoch Duration: 69.41239213943481
2020-01-11 10:31:15.755286 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0132198
Z variance train             0.010155834
KL Divergence                22.83934
KL Loss                      2.283934
QF Loss                      912.1067
VF Loss                      362.69043
Policy Loss                  -1170.2474
Q Predictions Mean           1170.2788
Q Predictions Std            296.39066
Q Predictions Max            1421.2925
Q Predictions Min            -6.2564907
V Predictions Mean           1172.3525
V Predictions Std            293.26505
V Predictions Max            1429.1099
V Predictions Min            -5.866732
Log Pis Mean                 0.3004769
Log Pis Std                  2.904497
Log Pis Max                  12.634815
Log Pis Min                  -6.560395
Policy mu Mean               -0.03104674
Policy mu Std                0.6514288
Policy mu Max                2.615424
Policy mu Min                -4.013384
Policy log std Mean          -0.97558624
Policy log std Std           0.2949194
Policy log std Max           0.10460627
Policy log std Min           -2.8465598
Z mean eval                  0.9998208
Z variance eval              0.010428933
total_rewards                [3104.00438585 2031.25216361 1731.53828865 3344.17494127 2655.25865196
 3314.59680391 2751.12661888 3206.7965753  3287.46573286 3458.22948804]
total_rewards_mean           2888.444365032552
total_rewards_std            562.7988566054809
total_rewards_max            3458.2294880418476
total_rewards_min            1731.5382886473978
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               29.18954784795642
(Previous) Eval Time (s)     24.134368921164423
Sample Time (s)              17.31459088390693
Epoch Time (s)               70.63850765302777
Total Train Time (s)         26214.81342214765
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:32:27.253430 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #379 | Epoch Duration: 71.49798130989075
2020-01-11 10:32:27.253633 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0028666
Z variance train             0.010535859
KL Divergence                22.602468
KL Loss                      2.260247
QF Loss                      566.4612
VF Loss                      111.43121
Policy Loss                  -1237.9932
Q Predictions Mean           1241.6711
Q Predictions Std            168.34511
Q Predictions Max            1426.0077
Q Predictions Min            40.367786
V Predictions Mean           1240.1074
V Predictions Std            170.01643
V Predictions Max            1420.2969
V Predictions Min            13.80443
Log Pis Mean                 -0.08363356
Log Pis Std                  2.225029
Log Pis Max                  6.5432167
Log Pis Min                  -5.9612455
Policy mu Mean               0.05707327
Policy mu Std                0.5617658
Policy mu Max                2.2694564
Policy mu Min                -2.0145202
Policy log std Mean          -1.018088
Policy log std Std           0.23529434
Policy log std Max           -0.10002327
Policy log std Min           -1.9047709
Z mean eval                  1.0229577
Z variance eval              0.009778999
total_rewards                [ 236.33878105 1158.64666706 1533.94368574 3199.60457514 3409.08364202
  194.05723159  425.68457027  956.95784336   86.24431202 1904.62011316]
total_rewards_mean           1310.5181421407428
total_rewards_std            1149.1602929769126
total_rewards_max            3409.0836420165824
total_rewards_min            86.24431202395735
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               28.04586952412501
(Previous) Eval Time (s)     24.99357152171433
Sample Time (s)              17.539942231494933
Epoch Time (s)               70.57938327733427
Total Train Time (s)         26273.903616505675
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:33:26.349018 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #380 | Epoch Duration: 59.09521532058716
2020-01-11 10:33:26.349243 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0231442
Z variance train             0.009771677
KL Divergence                23.06784
KL Loss                      2.3067842
QF Loss                      600.39185
VF Loss                      120.9145
Policy Loss                  -1213.2959
Q Predictions Mean           1214.2478
Q Predictions Std            241.83835
Q Predictions Max            1418.596
Q Predictions Min            -3.8010879
V Predictions Mean           1215.7573
V Predictions Std            241.88281
V Predictions Max            1417.674
V Predictions Min            -21.19251
Log Pis Mean                 0.28313833
Log Pis Std                  2.5670078
Log Pis Max                  6.580591
Log Pis Min                  -8.327183
Policy mu Mean               -0.013348484
Policy mu Std                0.6261296
Policy mu Max                2.1722329
Policy mu Min                -1.9547642
Policy log std Mean          -0.9935914
Policy log std Std           0.25789675
Policy log std Max           -0.24468344
Policy log std Min           -2.341473
Z mean eval                  1.0367639
Z variance eval              0.011086758
total_rewards                [1091.79741687  167.75981945 3580.06058729 1457.06716284 2023.14787453
 3175.87709756 3508.46106165 2636.65600589 3015.13632957   61.26744543]
total_rewards_mean           2071.723080109278
total_rewards_std            1255.987883578021
total_rewards_max            3580.060587293167
total_rewards_min            61.26744543447601
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               29.520756314042956
(Previous) Eval Time (s)     13.509073142893612
Sample Time (s)              17.61034297477454
Epoch Time (s)               60.64017243171111
Total Train Time (s)         26338.12843935564
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:30.578703 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #381 | Epoch Duration: 64.22925782203674
2020-01-11 10:34:30.579018 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0348824
Z variance train             0.011087444
KL Divergence                21.9109
KL Loss                      2.19109
QF Loss                      1438.5999
VF Loss                      210.70047
Policy Loss                  -1191.7826
Q Predictions Mean           1192.9404
Q Predictions Std            270.54672
Q Predictions Max            1446.428
Q Predictions Min            -15.725668
V Predictions Mean           1194.9235
V Predictions Std            271.4147
V Predictions Max            1445.1146
V Predictions Min            -14.959059
Log Pis Mean                 0.052661434
Log Pis Std                  2.6993556
Log Pis Max                  13.3622875
Log Pis Min                  -9.777869
Policy mu Mean               -0.02467445
Policy mu Std                0.5990467
Policy mu Max                2.378943
Policy mu Min                -3.106833
Policy log std Mean          -1.0090189
Policy log std Std           0.2778159
Policy log std Max           -0.22376102
Policy log std Min           -2.297546
Z mean eval                  1.0524162
Z variance eval              0.011304838
total_rewards                [ 260.38921751 3380.85329995 2650.08792702 1157.56245366 3463.85272857
 3417.45183414 2357.6787455  3738.12823581 1009.93107371 3495.07098533]
total_rewards_mean           2493.1006501195006
total_rewards_std            1189.5531271666985
total_rewards_max            3738.1282358053377
total_rewards_min            260.38921751378496
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               29.991975399199873
(Previous) Eval Time (s)     17.09781954996288
Sample Time (s)              17.82621411094442
Epoch Time (s)               64.91600906010717
Total Train Time (s)         26406.6405782355
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:35:39.092298 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #382 | Epoch Duration: 68.51305890083313
2020-01-11 10:35:39.092454 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0509878
Z variance train             0.011316538
KL Divergence                21.266985
KL Loss                      2.1266985
QF Loss                      753.2881
VF Loss                      138.66962
Policy Loss                  -1214.0651
Q Predictions Mean           1212.0759
Q Predictions Std            257.0746
Q Predictions Max            1432.83
Q Predictions Min            -36.192482
V Predictions Mean           1214.5167
V Predictions Std            246.044
V Predictions Max            1446.1039
V Predictions Min            1.1523967
Log Pis Mean                 0.23141599
Log Pis Std                  2.9715106
Log Pis Max                  15.462575
Log Pis Min                  -8.314453
Policy mu Mean               0.011508183
Policy mu Std                0.60473907
Policy mu Max                2.4328065
Policy mu Min                -2.6101592
Policy log std Mean          -1.0342249
Policy log std Std           0.3079703
Policy log std Max           0.42876488
Policy log std Min           -3.3521552
Z mean eval                  1.0567974
Z variance eval              0.010010403
total_rewards                [2946.45736742 3183.3308927  3276.35835882 2736.30768654 3358.80019866
 3316.8667579  3286.77210357 3424.62304809 3464.19455694 2139.2256438 ]
total_rewards_mean           3113.293661444376
total_rewards_std            387.572476746389
total_rewards_max            3464.194556935303
total_rewards_min            2139.2256438015206
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               30.521932407747954
(Previous) Eval Time (s)     20.69458209304139
Sample Time (s)              17.888990581966937
Epoch Time (s)               69.10550508275628
Total Train Time (s)         26479.99452613108
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:52.448982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #383 | Epoch Duration: 73.35637497901917
2020-01-11 10:36:52.449164 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0569109
Z variance train             0.009992817
KL Divergence                21.661882
KL Loss                      2.1661882
QF Loss                      1966.2461
VF Loss                      514.6378
Policy Loss                  -1223.3708
Q Predictions Mean           1218.8303
Q Predictions Std            241.44887
Q Predictions Max            1452.9934
Q Predictions Min            12.00476
V Predictions Mean           1214.0162
V Predictions Std            239.46152
V Predictions Max            1438.7603
V Predictions Min            -6.8282022
Log Pis Mean                 -0.034023672
Log Pis Std                  2.9607043
Log Pis Max                  14.550201
Log Pis Min                  -7.4333973
Policy mu Mean               -0.011306488
Policy mu Std                0.6296047
Policy mu Max                2.3015938
Policy mu Min                -2.1532648
Policy log std Mean          -0.9782955
Policy log std Std           0.27447984
Policy log std Max           0.023048043
Policy log std Min           -2.4225578
Z mean eval                  1.0512835
Z variance eval              0.018827341
total_rewards                [3518.84406396  220.0649005  3322.13399421 3112.71656217 3449.82083429
   58.71786244 2948.6520979  3311.66209005  919.06673461 3579.47785791]
total_rewards_mean           2444.1156998042643
total_rewards_std            1365.392515199504
total_rewards_max            3579.4778579097074
total_rewards_min            58.71786243939472
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               29.70361338974908
(Previous) Eval Time (s)     24.945083762984723
Sample Time (s)              17.848449467215687
Epoch Time (s)               72.49714661994949
Total Train Time (s)         26550.307875978295
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:38:02.765722 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #384 | Epoch Duration: 70.31641411781311
2020-01-11 10:38:02.765913 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0517212
Z variance train             0.018854612
KL Divergence                21.418507
KL Loss                      2.1418507
QF Loss                      1074.149
VF Loss                      315.19733
Policy Loss                  -1228.5913
Q Predictions Mean           1226.3215
Q Predictions Std            261.81613
Q Predictions Max            1436.6536
Q Predictions Min            46.394882
V Predictions Mean           1236.0687
V Predictions Std            258.84515
V Predictions Max            1443.835
V Predictions Min            42.31669
Log Pis Mean                 0.12344618
Log Pis Std                  2.8143826
Log Pis Max                  18.812769
Log Pis Min                  -7.696678
Policy mu Mean               -0.019603342
Policy mu Std                0.60414404
Policy mu Max                2.094396
Policy mu Min                -2.606269
Policy log std Mean          -1.0049255
Policy log std Std           0.2818865
Policy log std Max           -0.17132843
Policy log std Min           -2.9003563
Z mean eval                  1.0616057
Z variance eval              0.020881694
total_rewards                [3424.21245377 3399.74146157 1172.48012301 3650.53699688 1556.51294956
 3556.49455241 3154.65186967 3520.24138492 3306.75700742 3419.73460113]
total_rewards_mean           3016.1363400344117
total_rewards_std            840.1404204339071
total_rewards_max            3650.5369968844434
total_rewards_min            1172.4801230081437
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               28.638402921147645
(Previous) Eval Time (s)     22.76405272586271
Sample Time (s)              18.323875037953258
Epoch Time (s)               69.72633068496361
Total Train Time (s)         26624.416993611958
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:16.877201 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #385 | Epoch Duration: 74.11114835739136
2020-01-11 10:39:16.877396 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0578473
Z variance train             0.02084304
KL Divergence                21.61423
KL Loss                      2.161423
QF Loss                      1028.904
VF Loss                      180.3489
Policy Loss                  -1210.0295
Q Predictions Mean           1206.0979
Q Predictions Std            282.33624
Q Predictions Max            1435.4734
Q Predictions Min            22.700026
V Predictions Mean           1217.8136
V Predictions Std            273.1966
V Predictions Max            1457.7477
V Predictions Min            22.594017
Log Pis Mean                 0.05765997
Log Pis Std                  2.8762722
Log Pis Max                  8.560275
Log Pis Min                  -7.4809484
Policy mu Mean               0.030859668
Policy mu Std                0.60284865
Policy mu Max                2.7023942
Policy mu Min                -2.2272158
Policy log std Mean          -1.0311527
Policy log std Std           0.30866402
Policy log std Max           -0.18387681
Policy log std Min           -2.7871323
Z mean eval                  1.0818704
Z variance eval              0.01147574
total_rewards                [3483.36284906 3057.88660798 3194.30550672 3711.16358407 3397.98414798
 3336.18525097 3425.56099782 3229.60135951 3251.25194792 1539.11272357]
total_rewards_mean           3162.6414975594885
total_rewards_std            567.3205652128071
total_rewards_max            3711.16358407138
total_rewards_min            1539.1127235700565
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               29.388784326147288
(Previous) Eval Time (s)     27.148575555998832
Sample Time (s)              18.3025098759681
Epoch Time (s)               74.83986975811422
Total Train Time (s)         26698.053674626164
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:40:30.520017 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #386 | Epoch Duration: 73.6424446105957
2020-01-11 10:40:30.520288 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.082698
Z variance train             0.011462295
KL Divergence                22.193398
KL Loss                      2.2193398
QF Loss                      1385.1622
VF Loss                      2772.8406
Policy Loss                  -1224.3577
Q Predictions Mean           1223.7224
Q Predictions Std            257.01236
Q Predictions Max            1450.689
Q Predictions Min            5.320549
V Predictions Mean           1217.7296
V Predictions Std            254.54047
V Predictions Max            1439.9255
V Predictions Min            10.407814
Log Pis Mean                 0.5125929
Log Pis Std                  3.1171217
Log Pis Max                  19.719353
Log Pis Min                  -7.657277
Policy mu Mean               -0.007163902
Policy mu Std                0.6332844
Policy mu Max                3.8168461
Policy mu Min                -3.497353
Policy log std Mean          -1.0488383
Policy log std Std           0.319269
Policy log std Max           -0.18782163
Policy log std Min           -3.0696726
Z mean eval                  1.0227177
Z variance eval              0.012962492
total_rewards                [3407.40496558 2431.0353613  3394.34965495 3736.74222949 3509.85241622
 3619.25426201 3755.19204875 3479.15251816 2149.36988599 3185.95322406]
total_rewards_mean           3266.8306566522338
total_rewards_std            517.4448783935865
total_rewards_max            3755.1920487538337
total_rewards_min            2149.36988599373
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               28.58073744829744
(Previous) Eval Time (s)     25.950757063925266
Sample Time (s)              18.805471973028034
Epoch Time (s)               73.33696648525074
Total Train Time (s)         26772.31982140802
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:41:44.788469 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #387 | Epoch Duration: 74.2679934501648
2020-01-11 10:41:44.788719 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #387 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0225388
Z variance train             0.012972387
KL Divergence                22.287981
KL Loss                      2.2287982
QF Loss                      722.59216
VF Loss                      272.89444
Policy Loss                  -1233.9706
Q Predictions Mean           1235.0463
Q Predictions Std            226.40154
Q Predictions Max            1474.131
Q Predictions Min            -64.916145
V Predictions Mean           1227.579
V Predictions Std            222.46902
V Predictions Max            1463.6058
V Predictions Min            -5.128584
Log Pis Mean                 0.014269888
Log Pis Std                  2.2931988
Log Pis Max                  5.9445763
Log Pis Min                  -6.7508698
Policy mu Mean               0.0253812
Policy mu Std                0.5776474
Policy mu Max                2.0321772
Policy mu Min                -2.236875
Policy log std Mean          -1.0055891
Policy log std Std           0.25701782
Policy log std Max           -0.21242118
Policy log std Min           -2.3132377
Z mean eval                  1.0454532
Z variance eval              0.016665548
total_rewards                [3336.357514   3484.85784295 3322.31700647 1915.77870466  866.5200153
  891.77014873  116.05764449 3426.56161572 3369.56971846 3188.07927328]
total_rewards_mean           2391.7869484054418
total_rewards_std            1248.8322656136754
total_rewards_max            3484.8578429450154
total_rewards_min            116.05764448719813
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               26.98362998198718
(Previous) Eval Time (s)     26.881407937034965
Sample Time (s)              18.34110075002536
Epoch Time (s)               72.2061386690475
Total Train Time (s)         26837.040263689123
Epoch                        388
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:49.514278 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #388 | Epoch Duration: 64.72541427612305
2020-01-11 10:42:49.514456 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.046294
Z variance train             0.016630324
KL Divergence                22.014383
KL Loss                      2.2014384
QF Loss                      1395.7681
VF Loss                      305.12762
Policy Loss                  -1212.2916
Q Predictions Mean           1211.5579
Q Predictions Std            285.95224
Q Predictions Max            1451.0148
Q Predictions Min            -8.033325
V Predictions Mean           1211.0203
V Predictions Std            276.7515
V Predictions Max            1457.2222
V Predictions Min            2.678422
Log Pis Mean                 0.022926563
Log Pis Std                  2.5630553
Log Pis Max                  13.267937
Log Pis Min                  -6.99057
Policy mu Mean               0.05047497
Policy mu Std                0.5605451
Policy mu Max                2.217451
Policy mu Min                -2.5269866
Policy log std Mean          -1.0297856
Policy log std Std           0.27659088
Policy log std Max           -0.15613568
Policy log std Min           -2.3807368
Z mean eval                  1.015579
Z variance eval              0.013128025
total_rewards                [ 771.97181017 1424.88815795 1539.97230983 3568.13873873 1354.71061304
 3264.75907336 2831.36822995 2425.50264958 3487.89977831 3398.13845298]
total_rewards_mean           2406.734981389244
total_rewards_std            995.5920059837189
total_rewards_max            3568.1387387342206
total_rewards_min            771.9718101655657
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               28.949527125805616
(Previous) Eval Time (s)     19.400366230867803
Sample Time (s)              17.356937545351684
Epoch Time (s)               65.7068309020251
Total Train Time (s)         26902.349132534117
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:43:54.825673 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #389 | Epoch Duration: 65.31108331680298
2020-01-11 10:43:54.825827 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.015118
Z variance train             0.013141696
KL Divergence                22.247347
KL Loss                      2.2247348
QF Loss                      1006.3773
VF Loss                      232.89566
Policy Loss                  -1210.1515
Q Predictions Mean           1208.8124
Q Predictions Std            264.41248
Q Predictions Max            1468.0334
Q Predictions Min            -73.24062
V Predictions Mean           1212.3013
V Predictions Std            247.9929
V Predictions Max            1450.5251
V Predictions Min            22.51017
Log Pis Mean                 0.31812555
Log Pis Std                  3.018902
Log Pis Max                  16.64677
Log Pis Min                  -9.508872
Policy mu Mean               0.07506052
Policy mu Std                0.5968284
Policy mu Max                2.5928578
Policy mu Min                -2.4898293
Policy log std Mean          -1.0541928
Policy log std Std           0.30133823
Policy log std Max           -0.0017048717
Policy log std Min           -3.497045
Z mean eval                  1.0393207
Z variance eval              0.015171552
total_rewards                [3240.79504298 3335.27306549  915.91097499 1937.06103962 1497.95176308
 3216.37310687  555.14770434   45.78625726 3453.57233102 1597.33847088]
total_rewards_mean           1979.5209756540382
total_rewards_std            1200.4464679874764
total_rewards_max            3453.5723310171597
total_rewards_min            45.78625725504332
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               29.883494519628584
(Previous) Eval Time (s)     19.004317802842706
Sample Time (s)              17.992655725218356
Epoch Time (s)               66.88046804768965
Total Train Time (s)         26968.63005190855
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:45:01.110533 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #390 | Epoch Duration: 66.2845687866211
2020-01-11 10:45:01.110713 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0385231
Z variance train             0.015219035
KL Divergence                22.067163
KL Loss                      2.2067163
QF Loss                      817.26135
VF Loss                      110.36641
Policy Loss                  -1235.6171
Q Predictions Mean           1238.783
Q Predictions Std            231.53546
Q Predictions Max            1425.3033
Q Predictions Min            90.68267
V Predictions Mean           1237.3049
V Predictions Std            233.30084
V Predictions Max            1417.8411
V Predictions Min            70.6947
Log Pis Mean                 0.4431402
Log Pis Std                  2.531648
Log Pis Max                  7.9098406
Log Pis Min                  -7.470559
Policy mu Mean               0.016398298
Policy mu Std                0.60735047
Policy mu Max                2.1860125
Policy mu Min                -2.7409878
Policy log std Mean          -1.048714
Policy log std Std           0.26665688
Policy log std Max           -0.023424268
Policy log std Min           -2.0673633
Z mean eval                  1.0238584
Z variance eval              0.012122169
total_rewards                [3519.02356585 3551.88893274 3344.77337024  370.7064836  1103.03575233
 3383.88942286 3189.06400454 3673.48935643 1439.04885169  285.52797554]
total_rewards_mean           2386.044771582295
total_rewards_std            1337.0382985958768
total_rewards_max            3673.4893564299864
total_rewards_min            285.5279755397886
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               28.921060161665082
(Previous) Eval Time (s)     18.408096320927143
Sample Time (s)              18.43119227932766
Epoch Time (s)               65.76034876191989
Total Train Time (s)         27035.08206286514
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:46:07.564371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #391 | Epoch Duration: 66.45353245735168
2020-01-11 10:46:07.564567 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0234256
Z variance train             0.012095703
KL Divergence                22.183123
KL Loss                      2.2183123
QF Loss                      3807.2202
VF Loss                      564.5994
Policy Loss                  -1198.5582
Q Predictions Mean           1199.8213
Q Predictions Std            278.46988
Q Predictions Max            1445.9375
Q Predictions Min            39.90635
V Predictions Mean           1210.2139
V Predictions Std            268.5165
V Predictions Max            1445.4298
V Predictions Min            46.796455
Log Pis Mean                 -0.0054866336
Log Pis Std                  2.7546623
Log Pis Max                  10.02842
Log Pis Min                  -6.656881
Policy mu Mean               -0.02493708
Policy mu Std                0.59379774
Policy mu Max                2.2744706
Policy mu Min                -2.3082361
Policy log std Mean          -1.0027106
Policy log std Std           0.28578058
Policy log std Max           0.21152163
Policy log std Min           -2.3413825
Z mean eval                  1.0528127
Z variance eval              0.011742557
total_rewards                [3422.11887155 2428.40494552 3299.24202352 3505.16927297 3566.25155607
 3581.26188801 2518.52191443   82.67917155 2655.74199366  488.79847873]
total_rewards_mean           2554.819011601568
total_rewards_std            1212.1683353496246
total_rewards_max            3581.261888006244
total_rewards_min            82.6791715513009
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               29.65652137529105
(Previous) Eval Time (s)     19.10098840110004
Sample Time (s)              17.753801554441452
Epoch Time (s)               66.51131133083254
Total Train Time (s)         27102.86704754457
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:47:15.357352 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #392 | Epoch Duration: 67.79259037971497
2020-01-11 10:47:15.357705 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0509272
Z variance train             0.011750316
KL Divergence                23.38034
KL Loss                      2.3380342
QF Loss                      1664.0724
VF Loss                      879.1885
Policy Loss                  -1225.4886
Q Predictions Mean           1226.0969
Q Predictions Std            255.5227
Q Predictions Max            1494.959
Q Predictions Min            -54.804348
V Predictions Mean           1237.0382
V Predictions Std            247.13701
V Predictions Max            1497.5869
V Predictions Min            6.763589
Log Pis Mean                 0.21956635
Log Pis Std                  2.782402
Log Pis Max                  19.50631
Log Pis Min                  -5.9312973
Policy mu Mean               0.028762117
Policy mu Std                0.59592897
Policy mu Max                2.337904
Policy mu Min                -3.4713247
Policy log std Mean          -1.0579816
Policy log std Std           0.26358476
Policy log std Max           -0.31518537
Policy log std Min           -2.609423
Z mean eval                  1.0654922
Z variance eval              0.008919427
total_rewards                [3418.50538577 2909.73729758   80.90076673 3427.79069246 3250.92875312
 1219.47850448 3435.47832494 3360.31216966 3629.05322804 3420.03155423]
total_rewards_mean           2815.2216676998737
total_rewards_std            1125.6478907377145
total_rewards_max            3629.0532280372463
total_rewards_min            80.90076673090532
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               28.77635719301179
(Previous) Eval Time (s)     20.381918503902853
Sample Time (s)              18.178436217829585
Epoch Time (s)               67.33671191474423
Total Train Time (s)         27175.026320975274
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:48:27.523261 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #393 | Epoch Duration: 72.16523051261902
2020-01-11 10:48:27.523568 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0663022
Z variance train             0.008933568
KL Divergence                24.21429
KL Loss                      2.4214292
QF Loss                      1353.2733
VF Loss                      267.19855
Policy Loss                  -1236.3802
Q Predictions Mean           1237.9307
Q Predictions Std            231.02068
Q Predictions Max            1436.8904
Q Predictions Min            46.096275
V Predictions Mean           1233.5593
V Predictions Std            230.37222
V Predictions Max            1432.0747
V Predictions Min            35.222244
Log Pis Mean                 0.21612601
Log Pis Std                  3.2130096
Log Pis Max                  18.277414
Log Pis Min                  -8.622486
Policy mu Mean               -0.09217122
Policy mu Std                0.6152752
Policy mu Max                3.0737114
Policy mu Min                -3.7096035
Policy log std Mean          -1.0300287
Policy log std Std           0.2786347
Policy log std Max           -0.19305766
Policy log std Min           -2.5406487
Z mean eval                  1.0247693
Z variance eval              0.010469964
total_rewards                [3344.2626181  3529.87881964 3384.10925769 3562.18315086 3070.68171955
 3208.01923476 3684.82669305 3221.74919304 3446.74056648 3276.96413604]
total_rewards_mean           3372.9415389196
total_rewards_std            177.40876364432881
total_rewards_max            3684.8266930498025
total_rewards_min            3070.6817195459716
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               28.65399013599381
(Previous) Eval Time (s)     25.210089810192585
Sample Time (s)              18.148823202122003
Epoch Time (s)               72.0129031483084
Total Train Time (s)         27248.675501455087
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:49:41.172287 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #394 | Epoch Duration: 73.6485505104065
2020-01-11 10:49:41.172494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.024792
Z variance train             0.010447821
KL Divergence                24.178127
KL Loss                      2.4178128
QF Loss                      907.26733
VF Loss                      726.6972
Policy Loss                  -1235.6896
Q Predictions Mean           1236.9268
Q Predictions Std            238.1016
Q Predictions Max            1441.9896
Q Predictions Min            -72.00098
V Predictions Mean           1243.6311
V Predictions Std            229.20807
V Predictions Max            1444.9115
V Predictions Min            -49.147823
Log Pis Mean                 0.055819996
Log Pis Std                  3.0725229
Log Pis Max                  16.45005
Log Pis Min                  -8.03491
Policy mu Mean               0.0013206373
Policy mu Std                0.56844586
Policy mu Max                1.9779466
Policy mu Min                -2.4291985
Policy log std Mean          -1.0617554
Policy log std Std           0.30286857
Policy log std Max           -0.11479008
Policy log std Min           -3.1350117
Z mean eval                  1.0291598
Z variance eval              0.011800496
total_rewards                [ 953.04026752 3444.41137503 3499.80366513 2825.4675083  3276.44730943
 3542.27280771 3370.93025001  208.0006365  3356.25758209  115.37901387]
total_rewards_mean           2459.201041559417
total_rewards_std            1359.943604857778
total_rewards_max            3542.2728077060624
total_rewards_min            115.37901387036837
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               31.011681609321386
(Previous) Eval Time (s)     26.845414764247835
Sample Time (s)              18.156284825410694
Epoch Time (s)               76.01338119897991
Total Train Time (s)         27316.98590753833
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:49.488195 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #395 | Epoch Duration: 68.31554913520813
2020-01-11 10:50:49.488438 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0277545
Z variance train             0.011823526
KL Divergence                23.720608
KL Loss                      2.3720608
QF Loss                      1169.8658
VF Loss                      232.01788
Policy Loss                  -1243.625
Q Predictions Mean           1242.6257
Q Predictions Std            231.56128
Q Predictions Max            1466.9832
Q Predictions Min            -28.033007
V Predictions Mean           1246.0483
V Predictions Std            227.60295
V Predictions Max            1456.517
V Predictions Min            -30.484308
Log Pis Mean                 -0.1299129
Log Pis Std                  2.7845945
Log Pis Max                  8.494994
Log Pis Min                  -12.564507
Policy mu Mean               0.06132878
Policy mu Std                0.6189654
Policy mu Max                2.5571077
Policy mu Min                -2.745516
Policy log std Mean          -1.0108404
Policy log std Std           0.2537963
Policy log std Max           -0.20694822
Policy log std Min           -2.478437
Z mean eval                  1.0345285
Z variance eval              0.008241205
total_rewards                [1408.34963404 3390.64486731 3256.08387292 1949.16384243 3502.88630046
  554.0299666  2769.57837725 3583.02229039 3497.82406592 2742.61196353]
total_rewards_mean           2665.419518083493
total_rewards_std            983.8241430159544
total_rewards_max            3583.02229039075
total_rewards_min            554.0299665980289
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               29.559227658901364
(Previous) Eval Time (s)     19.1472585410811
Sample Time (s)              18.609555622097105
Epoch Time (s)               67.31604182207957
Total Train Time (s)         27386.20635916572
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:51:58.712692 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #396 | Epoch Duration: 69.2240629196167
2020-01-11 10:51:58.712906 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0362618
Z variance train             0.008212467
KL Divergence                24.526754
KL Loss                      2.4526756
QF Loss                      1054.8037
VF Loss                      208.22154
Policy Loss                  -1265.8489
Q Predictions Mean           1265.6692
Q Predictions Std            194.42413
Q Predictions Max            1449.6799
Q Predictions Min            27.110807
V Predictions Mean           1258.7396
V Predictions Std            191.66484
V Predictions Max            1453.2587
V Predictions Min            41.69674
Log Pis Mean                 0.4371667
Log Pis Std                  2.7617729
Log Pis Max                  12.03377
Log Pis Min                  -6.4059143
Policy mu Mean               -0.008728874
Policy mu Std                0.6126996
Policy mu Max                1.94693
Policy mu Min                -2.692942
Policy log std Mean          -1.0422175
Policy log std Std           0.2829179
Policy log std Max           -0.15577328
Policy log std Min           -2.9762692
Z mean eval                  1.046572
Z variance eval              0.016482329
total_rewards                [3396.89169967 3466.91399619 1821.70709735 1637.94332362 3773.58547955
 2023.14401835 3655.5014436  3565.97853126 3324.11236042 1998.1736328 ]
total_rewards_mean           2866.3951582806467
total_rewards_std            827.7682377066825
total_rewards_max            3773.585479549008
total_rewards_min            1637.9433236158347
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               28.273642234969884
(Previous) Eval Time (s)     21.05492576956749
Sample Time (s)              17.738529645372182
Epoch Time (s)               67.06709764990956
Total Train Time (s)         27457.07885859534
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:09.590463 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #397 | Epoch Duration: 70.87731218338013
2020-01-11 10:53:09.590760 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0466254
Z variance train             0.016487952
KL Divergence                24.040466
KL Loss                      2.4040468
QF Loss                      1215.1504
VF Loss                      309.08215
Policy Loss                  -1249.1364
Q Predictions Mean           1249.3165
Q Predictions Std            223.10568
Q Predictions Max            1453.3112
Q Predictions Min            -52.36399
V Predictions Mean           1247.6559
V Predictions Std            223.19844
V Predictions Max            1466.9657
V Predictions Min            -43.55745
Log Pis Mean                 0.31805015
Log Pis Std                  2.6940093
Log Pis Max                  10.766855
Log Pis Min                  -7.4615774
Policy mu Mean               0.0064634006
Policy mu Std                0.6258503
Policy mu Max                2.9079504
Policy mu Min                -2.4418294
Policy log std Mean          -1.0130165
Policy log std Std           0.2804107
Policy log std Max           -0.16843992
Policy log std Min           -2.484094
Z mean eval                  1.0816616
Z variance eval              0.014829735
total_rewards                [3502.26865326 3468.55263342 1973.10654229 2576.32607907 3657.45226296
 2106.62142138 3038.63864241 3426.31723709 3394.39040723 3596.26308291]
total_rewards_mean           3073.9936962009815
total_rewards_std            597.9762550303795
total_rewards_max            3657.4522629585263
total_rewards_min            1973.1065422924921
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               29.082295547705144
(Previous) Eval Time (s)     24.86483641061932
Sample Time (s)              18.4708295292221
Epoch Time (s)               72.41796148754656
Total Train Time (s)         27528.853926868178
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:54:21.370982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #398 | Epoch Duration: 71.78001856803894
2020-01-11 10:54:21.371167 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.081453
Z variance train             0.014833188
KL Divergence                24.768337
KL Loss                      2.4768338
QF Loss                      1156.1611
VF Loss                      156.65033
Policy Loss                  -1254.4802
Q Predictions Mean           1254.8806
Q Predictions Std            233.79121
Q Predictions Max            1482.4004
Q Predictions Min            -43.938915
V Predictions Mean           1253.8372
V Predictions Std            230.35756
V Predictions Max            1480.602
V Predictions Min            -40.847908
Log Pis Mean                 0.24772312
Log Pis Std                  2.9983628
Log Pis Max                  16.945532
Log Pis Min                  -6.2650175
Policy mu Mean               0.0042068316
Policy mu Std                0.6225109
Policy mu Max                2.4886425
Policy mu Min                -3.1032972
Policy log std Mean          -1.0270791
Policy log std Std           0.26259565
Policy log std Max           -0.1908356
Policy log std Min           -2.522553
Z mean eval                  1.0547526
Z variance eval              0.01669091
total_rewards                [3517.71199249 3605.32867222 3478.00197043 3521.17740753 3864.13207643
 3901.03616056 3723.25007586 3726.25925595 3646.44127239 3764.90081085]
total_rewards_mean           3674.8239694702147
total_rewards_std            138.84507230488344
total_rewards_max            3901.036160555114
total_rewards_min            3478.0019704252627
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               29.10091269388795
(Previous) Eval Time (s)     24.226507554296404
Sample Time (s)              18.05635688500479
Epoch Time (s)               71.38377713318914
Total Train Time (s)         27603.49722452322
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:36.017615 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #399 | Epoch Duration: 74.64631199836731
2020-01-11 10:55:36.017763 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.054989
Z variance train             0.016713772
KL Divergence                24.102146
KL Loss                      2.4102147
QF Loss                      1635.2173
VF Loss                      249.47406
Policy Loss                  -1243.3888
Q Predictions Mean           1242.4647
Q Predictions Std            260.53687
Q Predictions Max            1490.0443
Q Predictions Min            -28.54375
V Predictions Mean           1235.5449
V Predictions Std            262.1988
V Predictions Max            1486.3638
V Predictions Min            -37.67232
Log Pis Mean                 0.29584068
Log Pis Std                  2.8834383
Log Pis Max                  19.557907
Log Pis Min                  -7.259055
Policy mu Mean               0.018670723
Policy mu Std                0.57728064
Policy mu Max                2.4115553
Policy mu Min                -2.6615815
Policy log std Mean          -1.042136
Policy log std Std           0.2781719
Policy log std Max           -0.2232539
Policy log std Min           -2.4585657
Z mean eval                  1.0297515
Z variance eval              0.01799798
total_rewards                [3464.70142623 3660.63257372 2662.89480216 3631.60203299 3510.93191656
 3679.92590081  466.98870218 3621.62058712  988.742397   3638.03323212]
total_rewards_mean           2932.6073570890017
total_rewards_std            1144.4509061714386
total_rewards_max            3679.925900810565
total_rewards_min            466.9887021809758
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               29.051479432731867
(Previous) Eval Time (s)     27.488725210074335
Sample Time (s)              18.93669390399009
Epoch Time (s)               75.47689854679629
Total Train Time (s)         27676.585334953386
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:56:49.109581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #400 | Epoch Duration: 73.0916919708252
2020-01-11 10:56:49.109756 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.028415
Z variance train             0.018081412
KL Divergence                24.175777
KL Loss                      2.4175777
QF Loss                      1098.3085
VF Loss                      207.02734
Policy Loss                  -1254.4192
Q Predictions Mean           1255.6882
Q Predictions Std            208.5065
Q Predictions Max            1481.3231
Q Predictions Min            -44.84877
V Predictions Mean           1254.1958
V Predictions Std            203.53302
V Predictions Max            1468.9604
V Predictions Min            -19.496727
Log Pis Mean                 0.1330543
Log Pis Std                  2.7038026
Log Pis Max                  10.211344
Log Pis Min                  -7.3203325
Policy mu Mean               0.025125833
Policy mu Std                0.61979383
Policy mu Max                2.5480874
Policy mu Min                -2.4233334
Policy log std Mean          -1.0218045
Policy log std Std           0.25866055
Policy log std Max           -0.19174826
Policy log std Min           -2.1018896
Z mean eval                  1.0528758
Z variance eval              0.013488037
total_rewards                [3630.99507196 3475.82306013 3496.39982369 3459.14381983 3523.34672775
  660.87117657 3595.56213921  357.06397192 3437.76845788 2412.79426157]
total_rewards_mean           2804.9768510493063
total_rewards_std            1196.7923910833183
total_rewards_max            3630.9950719597723
total_rewards_min            357.06397191757344
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               27.58769515203312
(Previous) Eval Time (s)     25.103173847775906
Sample Time (s)              18.91261049453169
Epoch Time (s)               71.60347949434072
Total Train Time (s)         27743.539875992574
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:57:56.070614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #401 | Epoch Duration: 66.96067786216736
2020-01-11 10:57:56.070904 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0533209
Z variance train             0.013436018
KL Divergence                24.386425
KL Loss                      2.4386425
QF Loss                      749.6886
VF Loss                      225.15797
Policy Loss                  -1256.2903
Q Predictions Mean           1254.446
Q Predictions Std            225.30197
Q Predictions Max            1460.9377
Q Predictions Min            18.534927
V Predictions Mean           1248.4197
V Predictions Std            221.47786
V Predictions Max            1454.2733
V Predictions Min            38.847286
Log Pis Mean                 0.045999587
Log Pis Std                  2.8739114
Log Pis Max                  9.0148325
Log Pis Min                  -11.771747
Policy mu Mean               0.013946354
Policy mu Std                0.564439
Policy mu Max                2.3920803
Policy mu Min                -3.0188615
Policy log std Mean          -1.0599768
Policy log std Std           0.25818634
Policy log std Max           -0.19843364
Policy log std Min           -2.1267958
Z mean eval                  1.0593894
Z variance eval              0.008440833
total_rewards                [1545.11898448  453.1495477  3185.82445514 3463.70896418  881.93657694
  690.81133053 3508.58835993 3276.86549028 2818.61992089   10.98187536]
total_rewards_mean           1983.5605505410542
total_rewards_std            1328.2387157650571
total_rewards_max            3508.588359926419
total_rewards_min            10.981875356219687
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               29.492519821971655
(Previous) Eval Time (s)     20.460044874809682
Sample Time (s)              18.456272875890136
Epoch Time (s)               68.40883757267147
Total Train Time (s)         27806.728930150624
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:59.264025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #402 | Epoch Duration: 63.192925453186035
2020-01-11 10:58:59.264210 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0585124
Z variance train             0.008398524
KL Divergence                25.299067
KL Loss                      2.5299067
QF Loss                      1158.7092
VF Loss                      134.0683
Policy Loss                  -1228.0912
Q Predictions Mean           1225.9724
Q Predictions Std            275.5941
Q Predictions Max            1448.646
Q Predictions Min            -99.18271
V Predictions Mean           1223.4918
V Predictions Std            275.40256
V Predictions Max            1443.6198
V Predictions Min            -88.68722
Log Pis Mean                 0.16058648
Log Pis Std                  2.7141426
Log Pis Max                  9.131649
Log Pis Min                  -7.8885016
Policy mu Mean               0.01835439
Policy mu Std                0.6132275
Policy mu Max                2.145347
Policy mu Min                -2.306374
Policy log std Mean          -1.0367663
Policy log std Std           0.2622695
Policy log std Max           -0.2781378
Policy log std Min           -2.537051
Z mean eval                  1.0456655
Z variance eval              0.014814412
total_rewards                [2962.46917034 3479.43435904 3417.58355074 3304.8835964  3435.20975578
 3385.01603138  439.34011085 3505.58599924 3480.41663186 3522.24180064]
total_rewards_mean           3093.2181006271435
total_rewards_std            898.0800375878118
total_rewards_max            3522.2418006362277
total_rewards_min            439.34011084961935
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               27.152486614882946
(Previous) Eval Time (s)     15.243855691049248
Sample Time (s)              18.567901492118835
Epoch Time (s)               60.96424379805103
Total Train Time (s)         27876.63447500253
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:00:09.174212 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #403 | Epoch Duration: 69.90983057022095
2020-01-11 11:00:09.174470 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0462264
Z variance train             0.0148589555
KL Divergence                24.128464
KL Loss                      2.4128463
QF Loss                      1277.4769
VF Loss                      210.29837
Policy Loss                  -1248.2622
Q Predictions Mean           1249.7869
Q Predictions Std            269.0279
Q Predictions Max            1502.8978
Q Predictions Min            -49.32745
V Predictions Mean           1246.3411
V Predictions Std            269.0706
V Predictions Max            1504.4071
V Predictions Min            -36.96441
Log Pis Mean                 0.5595161
Log Pis Std                  2.639003
Log Pis Max                  13.0980215
Log Pis Min                  -7.447267
Policy mu Mean               0.06770039
Policy mu Std                0.6451735
Policy mu Max                2.1237013
Policy mu Min                -2.1491888
Policy log std Mean          -1.023655
Policy log std Std           0.28063613
Policy log std Max           0.13259739
Policy log std Min           -2.3076553
Z mean eval                  1.0557529
Z variance eval              0.02068292
total_rewards                [2474.32730485 3492.3501323  3642.76950582 3668.0961374  3405.35062537
 3605.39534922 3357.49972222 3463.1723326  3547.88003288  813.02756269]
total_rewards_mean           3146.9868705346175
total_rewards_std            843.7038824107187
total_rewards_max            3668.0961373965633
total_rewards_min            813.0275626863724
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               30.265500674955547
(Previous) Eval Time (s)     24.189097337890416
Sample Time (s)              17.59563397197053
Epoch Time (s)               72.05023198481649
Total Train Time (s)         27949.4270477416
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:21.975111 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #404 | Epoch Duration: 72.80041790008545
2020-01-11 11:01:21.975424 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #404 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0562332
Z variance train             0.020692833
KL Divergence                22.103596
KL Loss                      2.2103596
QF Loss                      972.4932
VF Loss                      295.9957
Policy Loss                  -1244.756
Q Predictions Mean           1244.9856
Q Predictions Std            203.93077
Q Predictions Max            1429.4154
Q Predictions Min            -61.15948
V Predictions Mean           1240.0784
V Predictions Std            205.38344
V Predictions Max            1428.2971
V Predictions Min            -19.853243
Log Pis Mean                 0.6721425
Log Pis Std                  2.6276984
Log Pis Max                  9.019787
Log Pis Min                  -7.1295066
Policy mu Mean               0.023425078
Policy mu Std                0.6368032
Policy mu Max                2.1663845
Policy mu Min                -2.4168286
Policy log std Mean          -1.0522134
Policy log std Std           0.28248766
Policy log std Max           -0.13139284
Policy log std Min           -2.659694
Z mean eval                  1.0247356
Z variance eval              0.020058716
total_rewards                [3379.20710029 3558.12409422 3650.26661318 3455.40731163 1377.7015725
 3541.69339433 3110.6959807  3532.5445362  1353.53809968 3736.92247932]
total_rewards_mean           3069.6101182046914
total_rewards_std            866.724873639584
total_rewards_max            3736.9224793219696
total_rewards_min            1353.5380996767071
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               29.309824408032
(Previous) Eval Time (s)     24.93895454937592
Sample Time (s)              17.853008361998945
Epoch Time (s)               72.10178731940687
Total Train Time (s)         28020.21086443495
Epoch                        405
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:02:32.764649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #405 | Epoch Duration: 70.78897404670715
2020-01-11 11:02:32.764936 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0218151
Z variance train             0.020120662
KL Divergence                21.723694
KL Loss                      2.1723695
QF Loss                      845.57056
VF Loss                      418.32828
Policy Loss                  -1288.5062
Q Predictions Mean           1286.6401
Q Predictions Std            197.27808
Q Predictions Max            1481.0618
Q Predictions Min            123.41127
V Predictions Mean           1272.7156
V Predictions Std            194.34767
V Predictions Max            1465.9474
V Predictions Min            121.0065
Log Pis Mean                 0.45955816
Log Pis Std                  2.811684
Log Pis Max                  14.451015
Log Pis Min                  -7.373371
Policy mu Mean               -0.029751718
Policy mu Std                0.61934453
Policy mu Max                2.50002
Policy mu Min                -2.6400309
Policy log std Mean          -1.0725443
Policy log std Std           0.263068
Policy log std Max           -0.14996964
Policy log std Min           -2.3771358
Z mean eval                  1.0289682
Z variance eval              0.02575163
total_rewards                [3732.54490513  963.03662177 3587.70533967 3687.20071873 3393.35203044
 3416.00349985 3661.19020531 3607.69510167 3692.02397816 3620.04675338]
total_rewards_mean           3336.0799154107917
total_rewards_std            798.2225792116099
total_rewards_max            3732.544905125728
total_rewards_min            963.0366217656297
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               27.84059527795762
(Previous) Eval Time (s)     23.62583946203813
Sample Time (s)              18.398297767620534
Epoch Time (s)               69.86473250761628
Total Train Time (s)         28090.97124556359
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:03:43.528810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #406 | Epoch Duration: 70.76366639137268
2020-01-11 11:03:43.528999 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0304788
Z variance train             0.02586495
KL Divergence                22.767109
KL Loss                      2.276711
QF Loss                      977.2705
VF Loss                      106.615875
Policy Loss                  -1250.3114
Q Predictions Mean           1250.4675
Q Predictions Std            255.83995
Q Predictions Max            1502.9548
Q Predictions Min            -33.15708
V Predictions Mean           1250.1603
V Predictions Std            255.17178
V Predictions Max            1492.6967
V Predictions Min            -20.338797
Log Pis Mean                 0.44683257
Log Pis Std                  2.7462738
Log Pis Max                  12.354706
Log Pis Min                  -6.2083693
Policy mu Mean               0.032008335
Policy mu Std                0.6248356
Policy mu Max                2.99713
Policy mu Min                -2.566301
Policy log std Mean          -1.0093486
Policy log std Std           0.29806706
Policy log std Max           -0.17766571
Policy log std Min           -2.9795423
Z mean eval                  1.0375646
Z variance eval              0.020107862
total_rewards                [3757.12032016 3444.35685899 2276.63623262  308.21232235 3280.02159706
 3167.37926979 3814.63114415 4078.10609393 1142.61213209 3782.98331827]
total_rewards_mean           2905.2059289399444
total_rewards_std            1201.8784553287949
total_rewards_max            4078.106093927807
total_rewards_min            308.21232235292854
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               28.9607048118487
(Previous) Eval Time (s)     24.524467123206705
Sample Time (s)              18.346290751360357
Epoch Time (s)               71.83146268641576
Total Train Time (s)         28159.40707808826
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:51.967624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #407 | Epoch Duration: 68.43848156929016
2020-01-11 11:04:51.967856 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0346751
Z variance train             0.020184232
KL Divergence                23.404087
KL Loss                      2.3404088
QF Loss                      1116.686
VF Loss                      169.87257
Policy Loss                  -1258.776
Q Predictions Mean           1261.6115
Q Predictions Std            261.559
Q Predictions Max            1460.4043
Q Predictions Min            -11.979231
V Predictions Mean           1263.4939
V Predictions Std            259.57773
V Predictions Max            1463.4037
V Predictions Min            -8.638794
Log Pis Mean                 0.5068393
Log Pis Std                  2.763177
Log Pis Max                  11.157181
Log Pis Min                  -7.9018197
Policy mu Mean               0.027877647
Policy mu Std                0.61609423
Policy mu Max                2.724535
Policy mu Min                -2.738413
Policy log std Mean          -1.0455512
Policy log std Std           0.2831245
Policy log std Max           -0.14798385
Policy log std Min           -2.5138345
Z mean eval                  1.0315354
Z variance eval              0.027310371
total_rewards                [3596.12876692 3321.07530839 3618.66293618 2690.26151362 3501.35190859
 3519.91746259 3433.35118753 3517.61565265 3982.25092527 3471.30089769]
total_rewards_mean           3465.191655942639
total_rewards_std            306.1758297918866
total_rewards_max            3982.250925274782
total_rewards_min            2690.261513615177
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               30.452992506325245
(Previous) Eval Time (s)     21.131157004274428
Sample Time (s)              17.739109160844237
Epoch Time (s)               69.32325867144391
Total Train Time (s)         28234.27797506936
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:06:06.843755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #408 | Epoch Duration: 74.87572121620178
2020-01-11 11:06:06.843974 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.031718
Z variance train             0.027416784
KL Divergence                22.222908
KL Loss                      2.2222908
QF Loss                      975.5089
VF Loss                      404.97092
Policy Loss                  -1267.3384
Q Predictions Mean           1267.8674
Q Predictions Std            242.33194
Q Predictions Max            1469.9993
Q Predictions Min            -42.93161
V Predictions Mean           1267.4402
V Predictions Std            240.19978
V Predictions Max            1465.3098
V Predictions Min            -30.020716
Log Pis Mean                 0.5220923
Log Pis Std                  2.712396
Log Pis Max                  9.549077
Log Pis Min                  -8.31182
Policy mu Mean               0.014251463
Policy mu Std                0.60748947
Policy mu Max                2.4356914
Policy mu Min                -2.396843
Policy log std Mean          -1.0575044
Policy log std Std           0.26476336
Policy log std Max           -0.18948495
Policy log std Min           -2.5759826
Z mean eval                  1.1069338
Z variance eval              0.022020495
total_rewards                [3371.91968848 3725.03302158 2088.99294085 3221.69768464 3446.85396707
 3294.58325736 3387.42083342 3572.20061783 3503.76180133 3372.83563513]
total_rewards_mean           3298.5299447695725
total_rewards_std            425.279691370872
total_rewards_max            3725.033021579816
total_rewards_min            2088.9929408543176
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               29.013433302287012
(Previous) Eval Time (s)     26.683333337306976
Sample Time (s)              17.59465883485973
Epoch Time (s)               73.29142547445372
Total Train Time (s)         28306.839406716637
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:07:19.407040 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #409 | Epoch Duration: 72.56289768218994
2020-01-11 11:07:19.407237 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1062992
Z variance train             0.021937931
KL Divergence                22.587427
KL Loss                      2.2587428
QF Loss                      772.4008
VF Loss                      118.10523
Policy Loss                  -1234.9392
Q Predictions Mean           1234.5833
Q Predictions Std            265.32233
Q Predictions Max            1492.1692
Q Predictions Min            41.749058
V Predictions Mean           1231.3901
V Predictions Std            267.29138
V Predictions Max            1479.7029
V Predictions Min            23.197771
Log Pis Mean                 0.16630892
Log Pis Std                  2.679351
Log Pis Max                  8.111682
Log Pis Min                  -7.473866
Policy mu Mean               -0.0029980545
Policy mu Std                0.6235056
Policy mu Max                2.5985548
Policy mu Min                -2.451088
Policy log std Mean          -1.000438
Policy log std Std           0.26572588
Policy log std Max           -0.028321147
Policy log std Min           -2.2212305
Z mean eval                  1.0573986
Z variance eval              0.01700563
total_rewards                [3361.15108025 3527.87718682 3023.2076831  3331.89716625 3455.35412109
  393.97555935 3348.00587362  614.83025642   65.5338724  1580.34408581]
total_rewards_mean           2270.21768851043
total_rewards_std            1364.8928329509174
total_rewards_max            3527.877186819695
total_rewards_min            65.53387239637644
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               26.203156913165003
(Previous) Eval Time (s)     25.954531471710652
Sample Time (s)              18.079477542545646
Epoch Time (s)               70.2371659274213
Total Train Time (s)         28368.925090515055
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:08:21.496887 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #410 | Epoch Duration: 62.08951187133789
2020-01-11 11:08:21.497083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0557501
Z variance train             0.017014643
KL Divergence                22.941362
KL Loss                      2.2941363
QF Loss                      11156.942
VF Loss                      727.07074
Policy Loss                  -1243.3372
Q Predictions Mean           1248.0471
Q Predictions Std            266.0849
Q Predictions Max            1473.1975
Q Predictions Min            -23.31509
V Predictions Mean           1250.9221
V Predictions Std            265.27646
V Predictions Max            1491.4198
V Predictions Min            15.084437
Log Pis Mean                 0.26325747
Log Pis Std                  2.962155
Log Pis Max                  21.38328
Log Pis Min                  -6.960455
Policy mu Mean               0.077849016
Policy mu Std                0.6252382
Policy mu Max                5.6533947
Policy mu Min                -3.466384
Policy log std Mean          -1.0280011
Policy log std Std           0.28393084
Policy log std Max           0.4067024
Policy log std Min           -2.880978
Z mean eval                  1.0505645
Z variance eval              0.03102937
total_rewards                [-326.44977865 3926.26642034  375.92426315 3588.98652443  315.92093944
 3653.47848743 3539.18027429 3516.64306924  373.61039465 3925.55604514]
total_rewards_mean           2288.9116639453055
total_rewards_std            1733.2909828163565
total_rewards_max            3926.2664203399177
total_rewards_min            -326.44977864998225
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               26.076556679792702
(Previous) Eval Time (s)     17.80658055935055
Sample Time (s)              17.614294703118503
Epoch Time (s)               61.497431942261755
Total Train Time (s)         28432.5011514551
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:09:25.076156 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #411 | Epoch Duration: 63.57893919944763
2020-01-11 11:09:25.076350 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0484036
Z variance train             0.031093622
KL Divergence                22.149801
KL Loss                      2.2149801
QF Loss                      1125.9036
VF Loss                      142.98544
Policy Loss                  -1255.8557
Q Predictions Mean           1257.3408
Q Predictions Std            255.85849
Q Predictions Max            1497.1029
Q Predictions Min            -6.184212
V Predictions Mean           1260.5823
V Predictions Std            256.40793
V Predictions Max            1498.0302
V Predictions Min            -10.591026
Log Pis Mean                 0.09626585
Log Pis Std                  2.5877435
Log Pis Max                  7.000787
Log Pis Min                  -7.1602077
Policy mu Mean               -0.030464254
Policy mu Std                0.62011176
Policy mu Max                2.7904365
Policy mu Min                -2.1669614
Policy log std Mean          -1.0324359
Policy log std Std           0.26993677
Policy log std Max           -0.12366009
Policy log std Min           -2.0647697
Z mean eval                  1.0390964
Z variance eval              0.023878101
total_rewards                [3292.78629966 3358.69263785 1790.49216224   26.63843261 2400.34561241
  222.68882485 1142.80523616 1155.5995912  3774.39162808  226.72467536]
total_rewards_mean           1739.1165100429407
total_rewards_std            1335.464979704403
total_rewards_max            3774.3916280819644
total_rewards_min            26.63843260981199
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               28.791951623745263
(Previous) Eval Time (s)     19.887802805751562
Sample Time (s)              17.371915604919195
Epoch Time (s)               66.05167003441602
Total Train Time (s)         28496.22135794675
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:10:28.831778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #412 | Epoch Duration: 63.7552330493927
2020-01-11 11:10:28.832124 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0381944
Z variance train             0.023932464
KL Divergence                22.31923
KL Loss                      2.2319229
QF Loss                      909.6017
VF Loss                      1082.1539
Policy Loss                  -1303.5891
Q Predictions Mean           1304.0143
Q Predictions Std            233.70923
Q Predictions Max            1504.4498
Q Predictions Min            -48.32577
V Predictions Mean           1300.3123
V Predictions Std            219.61913
V Predictions Max            1502.1007
V Predictions Min            -36.272736
Log Pis Mean                 0.6429194
Log Pis Std                  2.809693
Log Pis Max                  15.038869
Log Pis Min                  -9.554406
Policy mu Mean               -0.045701794
Policy mu Std                0.63579047
Policy mu Max                2.1622112
Policy mu Min                -2.4745052
Policy log std Mean          -1.0553443
Policy log std Std           0.33312064
Policy log std Max           -0.25650233
Policy log std Min           -3.2399564
Z mean eval                  1.0584862
Z variance eval              0.017032374
total_rewards                [3421.92156601 3267.98377109 3405.78816308 3361.23306449 3541.53441434
 3497.44266255 3470.49894649 3535.17049085 1110.3007101  1171.53677473]
total_rewards_mean           2978.341056372929
total_rewards_std            922.1183210948433
total_rewards_max            3541.534414343292
total_rewards_min            1110.300710103818
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               31.96719653485343
(Previous) Eval Time (s)     17.591049937997013
Sample Time (s)              18.36682831728831
Epoch Time (s)               67.92507479013875
Total Train Time (s)         28573.472863965668
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:11:46.057566 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #413 | Epoch Duration: 77.2252037525177
2020-01-11 11:11:46.057758 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0624945
Z variance train             0.017030649
KL Divergence                23.023418
KL Loss                      2.302342
QF Loss                      1881.2415
VF Loss                      208.19608
Policy Loss                  -1275.7854
Q Predictions Mean           1270.5605
Q Predictions Std            251.75633
Q Predictions Max            1518.5524
Q Predictions Min            -48.758076
V Predictions Mean           1277.7657
V Predictions Std            245.44572
V Predictions Max            1516.591
V Predictions Min            15.782855
Log Pis Mean                 0.80115473
Log Pis Std                  3.0042992
Log Pis Max                  18.594864
Log Pis Min                  -7.0677156
Policy mu Mean               -0.016725501
Policy mu Std                0.6444763
Policy mu Max                3.2607813
Policy mu Min                -3.44138
Policy log std Mean          -1.0707378
Policy log std Std           0.300926
Policy log std Max           -0.19389307
Policy log std Min           -2.7119255
Z mean eval                  1.0528983
Z variance eval              0.016634751
total_rewards                [1080.05386833 3466.75282729 3432.93518456 1770.74456894 2937.62421226
 3903.91138092 2394.06470198 3290.57292818 3840.32657049 3502.77075896]
total_rewards_mean           2961.9757001923854
total_rewards_std            884.2826800262086
total_rewards_max            3903.911380924118
total_rewards_min            1080.0538683304433
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               27.712494731880724
(Previous) Eval Time (s)     26.890903221908957
Sample Time (s)              18.658813728485256
Epoch Time (s)               73.26221168227494
Total Train Time (s)         28642.126417996362
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:54.716304 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #414 | Epoch Duration: 68.65838527679443
2020-01-11 11:12:54.716524 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0512275
Z variance train             0.016605895
KL Divergence                23.246693
KL Loss                      2.3246694
QF Loss                      1094.2517
VF Loss                      267.24054
Policy Loss                  -1276.1503
Q Predictions Mean           1273.1102
Q Predictions Std            231.78494
Q Predictions Max            1478.9692
Q Predictions Min            58.804382
V Predictions Mean           1265.2759
V Predictions Std            231.84538
V Predictions Max            1497.7284
V Predictions Min            56.113743
Log Pis Mean                 0.54269904
Log Pis Std                  2.54152
Log Pis Max                  8.884384
Log Pis Min                  -5.536247
Policy mu Mean               -0.013485349
Policy mu Std                0.673295
Policy mu Max                2.8704038
Policy mu Min                -2.7540998
Policy log std Mean          -1.007618
Policy log std Std           0.25372413
Policy log std Max           0.06383002
Policy log std Min           -2.3427694
Z mean eval                  1.0447603
Z variance eval              0.014768308
total_rewards                [3375.12548595 3670.97897526 3349.11772617 3007.46486208 3363.46124075
 3399.51043115 3496.65740286 2617.06313941 3722.74251805 3370.94689398]
total_rewards_mean           3337.3068675661516
total_rewards_std            303.330152797277
total_rewards_max            3722.742518050768
total_rewards_min            2617.0631394077777
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               28.507669985760003
(Previous) Eval Time (s)     22.286747300066054
Sample Time (s)              18.20703994948417
Epoch Time (s)               69.00145723531023
Total Train Time (s)         28714.976770827547
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:14:07.579778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #415 | Epoch Duration: 72.86307668685913
2020-01-11 11:14:07.579982 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.044411
Z variance train             0.0147730755
KL Divergence                22.9468
KL Loss                      2.29468
QF Loss                      537.59155
VF Loss                      66.127144
Policy Loss                  -1268.1317
Q Predictions Mean           1270.8556
Q Predictions Std            226.89786
Q Predictions Max            1455.9547
Q Predictions Min            20.804956
V Predictions Mean           1269.4767
V Predictions Std            224.50865
V Predictions Max            1446.7374
V Predictions Min            17.352774
Log Pis Mean                 0.30264542
Log Pis Std                  2.9672241
Log Pis Max                  23.314163
Log Pis Min                  -7.9298005
Policy mu Mean               0.021548009
Policy mu Std                0.60868984
Policy mu Max                4.8966103
Policy mu Min                -4.79128
Policy log std Mean          -1.0518298
Policy log std Std           0.24745356
Policy log std Max           0.29217088
Policy log std Min           -2.0422401
Z mean eval                  1.0404581
Z variance eval              0.013763194
total_rewards                [3608.16254043 1864.47392851 3756.38265251 2868.60806051  258.09769744
 3717.00081263 3511.37298102 2932.10386565 3657.91194705 2396.3962489 ]
total_rewards_mean           2857.0510734650293
total_rewards_std            1055.4492867358906
total_rewards_max            3756.382652507839
total_rewards_min            258.09769743766526
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               28.425003950018436
(Previous) Eval Time (s)     26.14800935704261
Sample Time (s)              18.129377319011837
Epoch Time (s)               72.70239062607288
Total Train Time (s)         28786.060752250254
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:18.657847 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #416 | Epoch Duration: 71.0777153968811
2020-01-11 11:15:18.658026 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0373724
Z variance train             0.013753462
KL Divergence                23.247782
KL Loss                      2.3247783
QF Loss                      796.5761
VF Loss                      199.7285
Policy Loss                  -1271.0345
Q Predictions Mean           1269.6835
Q Predictions Std            252.73743
Q Predictions Max            1457.2744
Q Predictions Min            -31.972158
V Predictions Mean           1267.8823
V Predictions Std            251.53452
V Predictions Max            1466.1068
V Predictions Min            -54.744713
Log Pis Mean                 0.5137918
Log Pis Std                  2.734793
Log Pis Max                  11.184172
Log Pis Min                  -7.6642494
Policy mu Mean               0.052814364
Policy mu Std                0.58829135
Policy mu Max                2.4662101
Policy mu Min                -2.2540638
Policy log std Mean          -1.0647244
Policy log std Std           0.2633021
Policy log std Max           -0.052528143
Policy log std Min           -2.1938052
Z mean eval                  1.0559231
Z variance eval              0.008804823
total_rewards                [1074.33409412 1275.14760762  112.15983472  929.89536759 2429.17657006
 3320.76841168 3916.64319679 1816.92017601 3902.90231601 4043.523477  ]
total_rewards_mean           2282.1471051604303
total_rewards_std            1368.5009828697919
total_rewards_max            4043.5234770018888
total_rewards_min            112.15983472132758
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               29.19131122995168
(Previous) Eval Time (s)     24.522983917035162
Sample Time (s)              17.940703351981938
Epoch Time (s)               71.65499849896878
Total Train Time (s)         28852.607675765175
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:16:25.212366 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #417 | Epoch Duration: 66.55419063568115
2020-01-11 11:16:25.212583 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0568593
Z variance train             0.008795155
KL Divergence                23.86961
KL Loss                      2.386961
QF Loss                      1203.623
VF Loss                      320.14624
Policy Loss                  -1266.4169
Q Predictions Mean           1269.989
Q Predictions Std            281.73563
Q Predictions Max            1512.5817
Q Predictions Min            -11.678167
V Predictions Mean           1272.3435
V Predictions Std            277.37946
V Predictions Max            1502.4398
V Predictions Min            -13.374748
Log Pis Mean                 0.3801093
Log Pis Std                  3.1318054
Log Pis Max                  14.627616
Log Pis Min                  -6.936606
Policy mu Mean               0.0133601455
Policy mu Std                0.6211473
Policy mu Max                4.1455827
Policy mu Min                -2.5561512
Policy log std Mean          -1.0707664
Policy log std Std           0.30377227
Policy log std Max           0.031576037
Policy log std Min           -2.5044832
Z mean eval                  1.0422834
Z variance eval              0.010057168
total_rewards                [1242.6559875  3530.10664349 3819.41700807 3752.43484271 3451.55849716
 3705.32179858 3850.91333683  406.27679574 3668.46986035 3228.74371392]
total_rewards_mean           3065.589848435372
total_rewards_std            1149.6028139790571
total_rewards_max            3850.913336828613
total_rewards_min            406.27679574132753
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               28.101313071791083
(Previous) Eval Time (s)     19.421887035947293
Sample Time (s)              17.886772455181926
Epoch Time (s)               65.4099725629203
Total Train Time (s)         28922.53182137618
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:17:35.138445 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #418 | Epoch Duration: 69.92568755149841
2020-01-11 11:17:35.138614 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0441236
Z variance train             0.010025866
KL Divergence                23.586369
KL Loss                      2.3586369
QF Loss                      1360.8495
VF Loss                      285.28827
Policy Loss                  -1297.6124
Q Predictions Mean           1296.5853
Q Predictions Std            212.48305
Q Predictions Max            1513.3207
Q Predictions Min            -28.833803
V Predictions Mean           1292.3503
V Predictions Std            202.41078
V Predictions Max            1496.5961
V Predictions Min            -16.308146
Log Pis Mean                 0.40778
Log Pis Std                  2.8247619
Log Pis Max                  16.328205
Log Pis Min                  -8.960055
Policy mu Mean               0.0151219
Policy mu Std                0.6384834
Policy mu Max                2.161544
Policy mu Min                -2.1640015
Policy log std Mean          -1.0363479
Policy log std Std           0.275484
Policy log std Max           -0.14900929
Policy log std Min           -3.4597132
Z mean eval                  1.0790076
Z variance eval              0.006274765
total_rewards                [3610.63695045 3762.54520359 3801.15856476 3053.49147079 3962.32325179
 2278.84838173 3174.4406598   437.5328175  3962.74942231 3727.15887377]
total_rewards_mean           3177.0885596489393
total_rewards_std            1038.4558371467033
total_rewards_max            3962.7494223100134
total_rewards_min            437.53281749683254
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               28.86885364493355
(Previous) Eval Time (s)     23.937303092330694
Sample Time (s)              18.02577371848747
Epoch Time (s)               70.83193045575172
Total Train Time (s)         28991.2155023627
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:43.831359 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #419 | Epoch Duration: 68.6926109790802
2020-01-11 11:18:43.831528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0787302
Z variance train             0.006281691
KL Divergence                24.576704
KL Loss                      2.4576705
QF Loss                      803.85583
VF Loss                      230.96187
Policy Loss                  -1296.8712
Q Predictions Mean           1297.3716
Q Predictions Std            218.20111
Q Predictions Max            1518.2867
Q Predictions Min            13.915966
V Predictions Mean           1305.8068
V Predictions Std            215.67607
V Predictions Max            1516.5997
V Predictions Min            23.764755
Log Pis Mean                 0.5678083
Log Pis Std                  2.742947
Log Pis Max                  10.94832
Log Pis Min                  -7.657794
Policy mu Mean               -0.0137686115
Policy mu Std                0.6798118
Policy mu Max                2.782322
Policy mu Min                -2.4016712
Policy log std Mean          -1.0137372
Policy log std Std           0.25865555
Policy log std Max           -0.17038935
Policy log std Min           -2.0059404
Z mean eval                  1.0467976
Z variance eval              0.010301196
total_rewards                [3834.94508993 3843.53752011 3608.38167913  916.02757307   13.26327558
 3873.81428705 3357.87077256   25.43573243 3565.03547286  831.18447719]
total_rewards_mean           2386.9495879903598
total_rewards_std            1613.899864201506
total_rewards_max            3873.814287054397
total_rewards_min            13.26327557646918
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               30.639387178234756
(Previous) Eval Time (s)     21.797592056915164
Sample Time (s)              18.56189763965085
Epoch Time (s)               70.99887687480077
Total Train Time (s)         29058.00180266658
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:19:50.620408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #420 | Epoch Duration: 66.78869795799255
2020-01-11 11:19:50.620756 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0487154
Z variance train             0.0102943685
KL Divergence                24.193995
KL Loss                      2.4193995
QF Loss                      599.2288
VF Loss                      135.95668
Policy Loss                  -1279.1598
Q Predictions Mean           1282.9412
Q Predictions Std            262.77295
Q Predictions Max            1511.4211
Q Predictions Min            15.517498
V Predictions Mean           1286.7295
V Predictions Std            262.86368
V Predictions Max            1519.387
V Predictions Min            26.72686
Log Pis Mean                 0.36191684
Log Pis Std                  2.8221946
Log Pis Max                  10.4140415
Log Pis Min                  -8.05389
Policy mu Mean               0.013288796
Policy mu Std                0.6057645
Policy mu Max                2.5039732
Policy mu Min                -2.666607
Policy log std Mean          -1.0680436
Policy log std Std           0.28250247
Policy log std Max           -0.087436914
Policy log std Min           -2.3910613
Z mean eval                  1.0614427
Z variance eval              0.008412227
total_rewards                [  30.08270665 3867.70264779 3763.43952886 3761.0576575  3866.09505183
 3804.97814782 3213.18400371 3633.69489785 3799.98239657 3889.00512013]
total_rewards_mean           3362.922215871606
total_rewards_std            1126.6618382436786
total_rewards_max            3889.005120126879
total_rewards_min            30.08270665428774
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               30.08667631307617
(Previous) Eval Time (s)     17.58707834687084
Sample Time (s)              18.432790552265942
Epoch Time (s)               66.10654521221295
Total Train Time (s)         29133.595023395028
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:06.214391 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #421 | Epoch Duration: 75.59338784217834
2020-01-11 11:21:06.214618 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0600941
Z variance train             0.008422314
KL Divergence                24.501621
KL Loss                      2.4501622
QF Loss                      2833.1545
VF Loss                      804.3265
Policy Loss                  -1293.7634
Q Predictions Mean           1289.6296
Q Predictions Std            256.08194
Q Predictions Max            1537.0006
Q Predictions Min            -41.786915
V Predictions Mean           1296.937
V Predictions Std            239.77109
V Predictions Max            1534.87
V Predictions Min            -31.770018
Log Pis Mean                 0.811823
Log Pis Std                  3.2507987
Log Pis Max                  18.31849
Log Pis Min                  -10.9166565
Policy mu Mean               0.014005346
Policy mu Std                0.6271881
Policy mu Max                2.7125065
Policy mu Min                -3.3566895
Policy log std Mean          -1.088593
Policy log std Std           0.29104963
Policy log std Max           -0.051550746
Policy log std Min           -2.884182
Z mean eval                  1.0700431
Z variance eval              0.007232681
total_rewards                [3571.03487746 1338.16559983 3051.24501477 3927.8051982  2571.91326609
  146.98439407 3555.13946047 2754.26815264  463.0245477     6.36246428]
total_rewards_mean           2138.5942975503376
total_rewards_std            1435.9893976536025
total_rewards_max            3927.805198201396
total_rewards_min            6.362464276989963
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               29.162534767296165
(Previous) Eval Time (s)     27.073609681334347
Sample Time (s)              17.821830628439784
Epoch Time (s)               74.0579750770703
Total Train Time (s)         29196.560908357147
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:22:09.186334 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #422 | Epoch Duration: 62.971529722213745
2020-01-11 11:22:09.186563 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0701482
Z variance train             0.007219774
KL Divergence                24.26477
KL Loss                      2.4264772
QF Loss                      4516.853
VF Loss                      1357.132
Policy Loss                  -1299.6868
Q Predictions Mean           1298.2854
Q Predictions Std            272.42944
Q Predictions Max            1542.5481
Q Predictions Min            -7.584041
V Predictions Mean           1298.2698
V Predictions Std            267.226
V Predictions Max            1536.0548
V Predictions Min            11.145004
Log Pis Mean                 0.44894636
Log Pis Std                  2.8519344
Log Pis Max                  11.840395
Log Pis Min                  -6.8406
Policy mu Mean               -0.044539772
Policy mu Std                0.6190645
Policy mu Max                2.1214764
Policy mu Min                -2.673555
Policy log std Mean          -1.0557787
Policy log std Std           0.30397925
Policy log std Max           -0.031184316
Policy log std Min           -3.2343946
Z mean eval                  1.0936134
Z variance eval              0.010656958
total_rewards                [3357.64657051 3477.62652667 3510.89530768 3551.83360301 3368.50812858
 3562.46225477 3525.46852664   69.33533147 3658.76858077 3727.95973316]
total_rewards_mean           3181.0504563267073
total_rewards_std            1042.8209745048487
total_rewards_max            3727.9597331623368
total_rewards_min            69.33533147184056
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               30.381432875059545
(Previous) Eval Time (s)     15.986870479304343
Sample Time (s)              17.42694468703121
Epoch Time (s)               63.7952480413951
Total Train Time (s)         29268.38717988832
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:23:21.019076 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #423 | Epoch Duration: 71.83230543136597
2020-01-11 11:23:21.019371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0933454
Z variance train             0.010650964
KL Divergence                24.005964
KL Loss                      2.4005964
QF Loss                      881.5773
VF Loss                      115.029045
Policy Loss                  -1323.984
Q Predictions Mean           1323.7458
Q Predictions Std            221.27855
Q Predictions Max            1535.2625
Q Predictions Min            -32.665886
V Predictions Mean           1321.1864
V Predictions Std            222.14168
V Predictions Max            1533.1941
V Predictions Min            -31.890968
Log Pis Mean                 0.7299856
Log Pis Std                  2.9224772
Log Pis Max                  11.497317
Log Pis Min                  -7.4142885
Policy mu Mean               -0.0014221959
Policy mu Std                0.6205678
Policy mu Max                2.6850812
Policy mu Min                -2.4318588
Policy log std Mean          -1.0861251
Policy log std Std           0.295327
Policy log std Max           -0.19644511
Policy log std Min           -2.8840315
Z mean eval                  1.030404
Z variance eval              0.0083595235
total_rewards                [3623.78405168 3558.25245328 3504.97085265 3309.29292883 2106.32619856
 3363.38562783  623.86353806 1464.38711123 1123.20527962 3593.24145432]
total_rewards_mean           2627.070949607271
total_rewards_std            1116.6815351594416
total_rewards_max            3623.7840516822826
total_rewards_min            623.8635380631254
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               29.278022427111864
(Previous) Eval Time (s)     24.023643969092518
Sample Time (s)              17.70877118036151
Epoch Time (s)               71.01043757656589
Total Train Time (s)         29336.68654482579
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:24:29.324649 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #424 | Epoch Duration: 68.30504179000854
2020-01-11 11:24:29.324896 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.030564
Z variance train             0.008348809
KL Divergence                24.37411
KL Loss                      2.437411
QF Loss                      948.4378
VF Loss                      1358.3618
Policy Loss                  -1299.868
Q Predictions Mean           1295.2559
Q Predictions Std            256.54825
Q Predictions Max            1502.7789
Q Predictions Min            -64.444244
V Predictions Mean           1298.7388
V Predictions Std            254.36911
V Predictions Max            1512.0537
V Predictions Min            -59.19246
Log Pis Mean                 0.529914
Log Pis Std                  2.7848387
Log Pis Max                  8.98697
Log Pis Min                  -6.1457334
Policy mu Mean               0.020760205
Policy mu Std                0.62546444
Policy mu Max                2.2023919
Policy mu Min                -2.1214745
Policy log std Mean          -1.0576774
Policy log std Std           0.26224276
Policy log std Max           -0.29039556
Policy log std Min           -2.8171067
Z mean eval                  1.0316029
Z variance eval              0.012443478
total_rewards                [3555.31603101 3785.3514776  3835.67009291 3483.02795461 1578.09111907
 3617.9380968  3684.03150358 3620.03708035 3501.24832983 3362.04646968]
total_rewards_mean           3402.275815543714
total_rewards_std            622.6475728273845
total_rewards_max            3835.670092909439
total_rewards_min            1578.091119069835
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               29.61568156303838
(Previous) Eval Time (s)     21.317927749827504
Sample Time (s)              17.928072622045875
Epoch Time (s)               68.86168193491176
Total Train Time (s)         29409.62780708447
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:25:42.268035 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #425 | Epoch Duration: 72.94296479225159
2020-01-11 11:25:42.268233 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #425 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0333822
Z variance train             0.012473051
KL Divergence                23.874897
KL Loss                      2.3874898
QF Loss                      668.4201
VF Loss                      161.95842
Policy Loss                  -1295.8524
Q Predictions Mean           1296.6072
Q Predictions Std            239.31898
Q Predictions Max            1561.5859
Q Predictions Min            -4.207455
V Predictions Mean           1293.3171
V Predictions Std            240.62675
V Predictions Max            1536.6061
V Predictions Min            -27.225903
Log Pis Mean                 0.31638682
Log Pis Std                  2.8238504
Log Pis Max                  12.689434
Log Pis Min                  -6.9007034
Policy mu Mean               0.030393291
Policy mu Std                0.61609626
Policy mu Max                2.2526112
Policy mu Min                -2.528969
Policy log std Mean          -1.0588437
Policy log std Std           0.2584722
Policy log std Max           -0.15452462
Policy log std Min           -2.1969867
Z mean eval                  1.087022
Z variance eval              0.00976536
total_rewards                [3699.8865941  3488.65516037  553.22319055  420.00302893 3613.42593361
 3636.9002827  3507.11315597 3813.70614334 3744.56655953 3481.67283331]
total_rewards_mean           2995.915288241728
total_rewards_std            1259.33165823615
total_rewards_max            3813.706143335109
total_rewards_min            420.0030289339293
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               30.713317258283496
(Previous) Eval Time (s)     25.39892021473497
Sample Time (s)              17.63853061525151
Epoch Time (s)               73.75076808826998
Total Train Time (s)         29481.664352966473
Epoch                        426
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:54.308589 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #426 | Epoch Duration: 72.04021334648132
2020-01-11 11:26:54.308789 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.086029
Z variance train             0.009766084
KL Divergence                24.277376
KL Loss                      2.4277377
QF Loss                      1089.5758
VF Loss                      154.65202
Policy Loss                  -1312.4042
Q Predictions Mean           1313.7422
Q Predictions Std            236.96298
Q Predictions Max            1524.4938
Q Predictions Min            -48.447662
V Predictions Mean           1316.4397
V Predictions Std            237.14862
V Predictions Max            1525.4728
V Predictions Min            -26.594673
Log Pis Mean                 0.57200825
Log Pis Std                  2.7316806
Log Pis Max                  8.702864
Log Pis Min                  -7.468652
Policy mu Mean               -0.009125156
Policy mu Std                0.62709695
Policy mu Max                2.5770774
Policy mu Min                -2.3581893
Policy log std Mean          -1.0441107
Policy log std Std           0.28707102
Policy log std Max           0.4381103
Policy log std Min           -2.4495683
Z mean eval                  1.06702
Z variance eval              0.01210654
total_rewards                [3554.34331044 1319.35800406 1608.7678071  3417.0999175  3512.83687802
 3881.75356567 4009.93310385 3674.50108969 3863.65585744 2598.42589445]
total_rewards_mean           3144.067542820957
total_rewards_std            919.5852120257148
total_rewards_max            4009.9331038472155
total_rewards_min            1319.3580040558563
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               29.990325233899057
(Previous) Eval Time (s)     23.68805923918262
Sample Time (s)              18.1999242301099
Epoch Time (s)               71.87830870319158
Total Train Time (s)         29552.585163829848
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:28:05.233128 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #427 | Epoch Duration: 70.92417001724243
2020-01-11 11:28:05.233310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #427 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0702375
Z variance train             0.012071235
KL Divergence                24.357872
KL Loss                      2.4357872
QF Loss                      956.2626
VF Loss                      257.12744
Policy Loss                  -1310.7561
Q Predictions Mean           1312.7086
Q Predictions Std            244.71252
Q Predictions Max            1550.7836
Q Predictions Min            -20.632843
V Predictions Mean           1319.523
V Predictions Std            251.65514
V Predictions Max            1546.5586
V Predictions Min            -49.83162
Log Pis Mean                 0.46296167
Log Pis Std                  2.5202725
Log Pis Max                  9.5314
Log Pis Min                  -5.9350615
Policy mu Mean               -0.0053336266
Policy mu Std                0.6247478
Policy mu Max                2.2730105
Policy mu Min                -2.220027
Policy log std Mean          -1.040374
Policy log std Std           0.26929978
Policy log std Max           -0.16134405
Policy log std Min           -2.0250425
Z mean eval                  1.0577545
Z variance eval              0.009383815
total_rewards                [3589.18899695 3811.88665243  171.43107477 3702.32414475   28.42877915
 1588.84246348 1723.2853905  3626.41520963 3977.92933934 3833.16363825]
total_rewards_mean           2605.289568924842
total_rewards_std            1497.8954068589821
total_rewards_max            3977.9293393446633
total_rewards_min            28.428779149490257
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               31.11813125014305
(Previous) Eval Time (s)     22.733583624009043
Sample Time (s)              17.622312035411596
Epoch Time (s)               71.47402690956369
Total Train Time (s)         29621.442919312976
Epoch                        428
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:14.099688 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #428 | Epoch Duration: 68.86620593070984
2020-01-11 11:29:14.099986 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #428 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0581205
Z variance train             0.0094721755
KL Divergence                25.369335
KL Loss                      2.5369337
QF Loss                      1523.785
VF Loss                      621.7776
Policy Loss                  -1325.9587
Q Predictions Mean           1328.6942
Q Predictions Std            212.58548
Q Predictions Max            1571.7921
Q Predictions Min            67.067894
V Predictions Mean           1335.8997
V Predictions Std            206.72012
V Predictions Max            1581.6462
V Predictions Min            65.43292
Log Pis Mean                 0.2412125
Log Pis Std                  2.8074589
Log Pis Max                  12.823129
Log Pis Min                  -10.479114
Policy mu Mean               -0.014928247
Policy mu Std                0.57944053
Policy mu Max                2.0247862
Policy mu Min                -3.0129015
Policy log std Mean          -1.0539556
Policy log std Std           0.27160156
Policy log std Max           -0.13073903
Policy log std Min           -2.948822
Z mean eval                  1.0694709
Z variance eval              0.011644522
total_rewards                [3691.46586116  520.31616706 3587.91810629  855.32487817 3621.1936898
  326.33264253 3339.78480908 3399.27995769 3630.62233869 3351.16207278]
total_rewards_mean           2632.3400523245314
total_rewards_std            1362.0115245586194
total_rewards_max            3691.4658611615123
total_rewards_min            326.33264253258534
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               31.30647953879088
(Previous) Eval Time (s)     20.125471976120025
Sample Time (s)              17.84033152181655
Epoch Time (s)               69.27228303672746
Total Train Time (s)         29693.484568559565
Epoch                        429
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:30:26.143226 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #429 | Epoch Duration: 72.04306244850159
2020-01-11 11:30:26.143435 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0691421
Z variance train             0.01163623
KL Divergence                24.97993
KL Loss                      2.4979932
QF Loss                      1184.7954
VF Loss                      326.23325
Policy Loss                  -1287.7218
Q Predictions Mean           1287.5117
Q Predictions Std            275.87088
Q Predictions Max            1529.0557
Q Predictions Min            -26.56804
V Predictions Mean           1274.6581
V Predictions Std            271.85678
V Predictions Max            1511.422
V Predictions Min            -42.194317
Log Pis Mean                 0.6155426
Log Pis Std                  2.7563586
Log Pis Max                  8.639948
Log Pis Min                  -6.1575174
Policy mu Mean               -0.008756502
Policy mu Std                0.6089073
Policy mu Max                2.2555747
Policy mu Min                -2.3450468
Policy log std Mean          -1.068762
Policy log std Std           0.2963861
Policy log std Max           -0.08631301
Policy log std Min           -2.8726134
Z mean eval                  1.0736632
Z variance eval              0.010116921
total_rewards                [2638.20996617 2917.56181015  301.77848173  177.58133854  508.01061848
 1479.3320351  2479.88054509   20.07697835 3597.71816664  190.35209318]
total_rewards_mean           1431.0502033441594
total_rewards_std            1291.9905521360656
total_rewards_max            3597.718166643505
total_rewards_min            20.076978348491597
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               27.77892647124827
(Previous) Eval Time (s)     22.895962121896446
Sample Time (s)              18.378744402434677
Epoch Time (s)               69.05363299557939
Total Train Time (s)         29752.41693174839
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:31:25.078842 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #430 | Epoch Duration: 58.93524956703186
2020-01-11 11:31:25.079025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0746133
Z variance train             0.010070978
KL Divergence                25.677841
KL Loss                      2.567784
QF Loss                      581.3268
VF Loss                      395.69183
Policy Loss                  -1314.7102
Q Predictions Mean           1314.6416
Q Predictions Std            250.708
Q Predictions Max            1554.9888
Q Predictions Min            -44.073742
V Predictions Mean           1331.2332
V Predictions Std            252.6921
V Predictions Max            1566.3883
V Predictions Min            -42.77895
Log Pis Mean                 0.46532172
Log Pis Std                  2.8109295
Log Pis Max                  9.052944
Log Pis Min                  -12.011862
Policy mu Mean               -0.0003613776
Policy mu Std                0.61906874
Policy mu Max                2.7740865
Policy mu Min                -2.556682
Policy log std Mean          -1.067328
Policy log std Std           0.28771985
Policy log std Max           -0.05349028
Policy log std Min           -2.2713957
Z mean eval                  1.0709836
Z variance eval              0.008510722
total_rewards                [3721.82778994 1788.34357681 4084.64326938 2522.94705181  948.67498229
 1588.25575552  297.26864962  570.58818545  212.13687615 1251.02322191]
total_rewards_mean           1698.570935887247
total_rewards_std            1292.0857680099507
total_rewards_max            4084.6432693763804
total_rewards_min            212.1368761451839
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               29.465267692692578
(Previous) Eval Time (s)     12.77725771209225
Sample Time (s)              17.78388315392658
Epoch Time (s)               60.02640855871141
Total Train Time (s)         29813.83090714831
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:26.497637 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #431 | Epoch Duration: 61.41847085952759
2020-01-11 11:32:26.497849 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0710193
Z variance train             0.008541191
KL Divergence                25.772614
KL Loss                      2.5772614
QF Loss                      3767.8843
VF Loss                      264.56506
Policy Loss                  -1312.0533
Q Predictions Mean           1308.771
Q Predictions Std            272.24307
Q Predictions Max            1537.0663
Q Predictions Min            -31.741724
V Predictions Mean           1314.3372
V Predictions Std            264.7517
V Predictions Max            1538.0094
V Predictions Min            -34.130417
Log Pis Mean                 0.6992408
Log Pis Std                  3.262123
Log Pis Max                  18.983334
Log Pis Min                  -8.420227
Policy mu Mean               -0.03261416
Policy mu Std                0.6583898
Policy mu Max                4.0998297
Policy mu Min                -4.3407254
Policy log std Mean          -1.0541805
Policy log std Std           0.29389986
Policy log std Max           0.28358865
Policy log std Min           -2.6189222
Z mean eval                  1.0503325
Z variance eval              0.0076401224
total_rewards                [2258.26216021 4138.23339125 3885.521874   3262.20711841 4010.05010413
 3856.98620817 3552.31784091 3748.02470301 3774.73237772 3897.3564784 ]
total_rewards_mean           3638.3692256192953
total_rewards_std            514.6047599835686
total_rewards_max            4138.233391250433
total_rewards_min            2258.262160208185
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               27.72600162308663
(Previous) Eval Time (s)     14.168975558597594
Sample Time (s)              17.179934763815254
Epoch Time (s)               59.07491194549948
Total Train Time (s)         29887.10801331699
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:39.777648 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #432 | Epoch Duration: 73.27961158752441
2020-01-11 11:33:39.777840 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #432 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495851
Z variance train             0.007630737
KL Divergence                26.783604
KL Loss                      2.6783605
QF Loss                      1483.7668
VF Loss                      235.68245
Policy Loss                  -1331.3495
Q Predictions Mean           1337.4932
Q Predictions Std            217.41895
Q Predictions Max            1566.8334
Q Predictions Min            -27.738495
V Predictions Mean           1328.8726
V Predictions Std            213.37119
V Predictions Max            1549.7449
V Predictions Min            -33.080914
Log Pis Mean                 0.35739917
Log Pis Std                  2.8208156
Log Pis Max                  9.975852
Log Pis Min                  -9.358074
Policy mu Mean               -0.032635927
Policy mu Std                0.6020931
Policy mu Max                2.9940395
Policy mu Min                -2.8400574
Policy log std Mean          -1.0863564
Policy log std Std           0.25536644
Policy log std Max           -0.032941163
Policy log std Min           -2.311278
Z mean eval                  1.0571568
Z variance eval              0.008998729
total_rewards                [3876.57010589  593.38236338 3669.64969315 3711.7884496  2055.4796935
 3624.74022999  111.23467763  723.56237203 2002.15154264 3904.88441135]
total_rewards_mean           2427.3443539168416
total_rewards_std            1444.2985109010554
total_rewards_max            3904.8844113494906
total_rewards_min            111.23467762959947
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               31.26923719001934
(Previous) Eval Time (s)     28.373378434218466
Sample Time (s)              18.973213008604944
Epoch Time (s)               78.61582863284275
Total Train Time (s)         29956.99852428306
Epoch                        433
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:34:49.672823 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #433 | Epoch Duration: 69.89482855796814
2020-01-11 11:34:49.673028 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0587628
Z variance train             0.009074429
KL Divergence                25.633358
KL Loss                      2.563336
QF Loss                      742.8892
VF Loss                      227.70045
Policy Loss                  -1327.761
Q Predictions Mean           1327.5447
Q Predictions Std            238.38712
Q Predictions Max            1543.9049
Q Predictions Min            -60.57432
V Predictions Mean           1323.261
V Predictions Std            237.72746
V Predictions Max            1546.6663
V Predictions Min            -49.830353
Log Pis Mean                 0.54368436
Log Pis Std                  3.0007687
Log Pis Max                  12.307491
Log Pis Min                  -11.23862
Policy mu Mean               0.017987909
Policy mu Std                0.63978016
Policy mu Max                2.1933758
Policy mu Min                -2.3852644
Policy log std Mean          -1.0374842
Policy log std Std           0.27688763
Policy log std Max           -0.099843204
Policy log std Min           -2.5292559
Z mean eval                  1.098253
Z variance eval              0.013045509
total_rewards                [3710.04139936 3740.47370561 3489.76143454 3167.93591847 3913.29047897
 3657.79702683 3579.93720894 3431.42226895  218.66773286 3610.7616336 ]
total_rewards_mean           3252.008880814118
total_rewards_std            1028.7629364501781
total_rewards_max            3913.2904789682
total_rewards_min            218.66773286320392
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               28.093750606290996
(Previous) Eval Time (s)     19.652031775098294
Sample Time (s)              18.227117963600904
Epoch Time (s)               65.9729003449902
Total Train Time (s)         30029.41681254795
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:02.096181 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #434 | Epoch Duration: 72.42298245429993
2020-01-11 11:36:02.096400 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1003354
Z variance train             0.013037709
KL Divergence                24.731398
KL Loss                      2.4731398
QF Loss                      7505.991
VF Loss                      122.94977
Policy Loss                  -1322.4244
Q Predictions Mean           1320.425
Q Predictions Std            255.46597
Q Predictions Max            1579.414
Q Predictions Min            -18.729607
V Predictions Mean           1328.1947
V Predictions Std            255.0157
V Predictions Max            1591.3323
V Predictions Min            -11.269333
Log Pis Mean                 0.5527642
Log Pis Std                  2.7136078
Log Pis Max                  10.0971365
Log Pis Min                  -6.5874367
Policy mu Mean               0.007349462
Policy mu Std                0.6231501
Policy mu Max                2.4218752
Policy mu Min                -2.8739705
Policy log std Mean          -1.0653812
Policy log std Std           0.2618531
Policy log std Max           -0.17184913
Policy log std Min           -2.3339376
Z mean eval                  1.0490278
Z variance eval              0.015008169
total_rewards                [3299.46378248 3289.34995665   68.45169826 3509.49488856 3412.79667149
 3820.58791013 3297.0858213  3264.26284054  465.00981444 3719.13662598]
total_rewards_mean           2814.5640009840617
total_rewards_std            1289.5072902494915
total_rewards_max            3820.5879101313844
total_rewards_min            68.4516982638421
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               29.439416707027704
(Previous) Eval Time (s)     26.101815572939813
Sample Time (s)              18.040454090572894
Epoch Time (s)               73.58168637054041
Total Train Time (s)         30101.528963815887
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:37:14.217626 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #435 | Epoch Duration: 72.12100458145142
2020-01-11 11:37:14.217912 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #435 | Started Training: True
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0495939
Z variance train             0.015034998
KL Divergence                24.063845
KL Loss                      2.4063845
QF Loss                      1599.9375
VF Loss                      152.42168
Policy Loss                  -1331.6836
Q Predictions Mean           1333.4998
Q Predictions Std            219.21367
Q Predictions Max            1549.1688
Q Predictions Min            -3.4233398
V Predictions Mean           1330.2997
V Predictions Std            220.82892
V Predictions Max            1541.9421
V Predictions Min            -19.116905
Log Pis Mean                 0.45273244
Log Pis Std                  2.894439
Log Pis Max                  14.48131
Log Pis Min                  -7.7920403
Policy mu Mean               -0.05802469
Policy mu Std                0.6225029
Policy mu Max                2.1979575
Policy mu Min                -2.6082675
Policy log std Mean          -1.0629292
Policy log std Std           0.27874964
Policy log std Max           -0.16762036
Policy log std Min           -2.7627938
Z mean eval                  1.0580713
Z variance eval              0.015056695
total_rewards                [-2.84958433e+02  1.47465241e+03  4.13554124e+03  2.42568530e+02
 -3.32100701e+02  4.07325159e+03  3.66957814e+03  5.00768985e+02
  4.43364311e+03  4.34343267e+00]
total_rewards_mean           1791.7288302238544
total_rewards_std            1933.6461067387568
total_rewards_max            4433.643111475591
total_rewards_min            -332.1007010034532
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               29.866602295078337
(Previous) Eval Time (s)     24.640759146306664
Sample Time (s)              18.09798266319558
Epoch Time (s)               72.60534410458058
Total Train Time (s)         30166.98032857012
Epoch                        436
---------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:38:19.670317 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #436 | Epoch Duration: 65.45219349861145
2020-01-11 11:38:19.670492 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0585878
Z variance train             0.015086522
KL Divergence                23.233131
KL Loss                      2.3233132
QF Loss                      1213.8032
VF Loss                      390.9227
Policy Loss                  -1321.2837
Q Predictions Mean           1320.9182
Q Predictions Std            228.09966
Q Predictions Max            1523.9208
Q Predictions Min            43.009647
V Predictions Mean           1318.6952
V Predictions Std            229.51971
V Predictions Max            1518.8794
V Predictions Min            55.276695
Log Pis Mean                 0.811272
Log Pis Std                  2.7251945
Log Pis Max                  11.970748
Log Pis Min                  -6.9708376
Policy mu Mean               0.013172978
Policy mu Std                0.6086841
Policy mu Max                2.411912
Policy mu Min                -3.8096836
Policy log std Mean          -1.091534
Policy log std Std           0.29090768
Policy log std Max           0.24671412
Policy log std Min           -3.0419564
Z mean eval                  1.0878621
Z variance eval              0.012560177
total_rewards                [3109.24670455 4062.73871289 3532.14389093 2482.42927541 3269.61770689
 3383.10990841 3705.7745283  3359.71479226  791.09627756 3419.16732739]
total_rewards_mean           3111.503912460121
total_rewards_std            864.2921956566514
total_rewards_max            4062.7387128940877
total_rewards_min            791.0962775610247
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               28.32713548792526
(Previous) Eval Time (s)     17.487311420030892
Sample Time (s)              17.834964760113508
Epoch Time (s)               63.64941166806966
Total Train Time (s)         30237.084345593117
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:39:29.779310 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #437 | Epoch Duration: 70.10866165161133
2020-01-11 11:39:29.779518 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #437 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0879385
Z variance train             0.012574126
KL Divergence                24.259804
KL Loss                      2.4259803
QF Loss                      6691.507
VF Loss                      376.23077
Policy Loss                  -1349.1205
Q Predictions Mean           1354.8354
Q Predictions Std            242.24693
Q Predictions Max            1567.843
Q Predictions Min            66.967735
V Predictions Mean           1349.1462
V Predictions Std            237.21933
V Predictions Max            1560.0944
V Predictions Min            78.515076
Log Pis Mean                 0.7081783
Log Pis Std                  2.8459682
Log Pis Max                  11.662335
Log Pis Min                  -5.553728
Policy mu Mean               0.023569247
Policy mu Std                0.6096608
Policy mu Max                2.4995594
Policy mu Min                -2.1792967
Policy log std Mean          -1.0741796
Policy log std Std           0.30671254
Policy log std Max           -0.081835866
Policy log std Min           -3.089797
Z mean eval                  1.1049716
Z variance eval              0.014416302
total_rewards                [2487.79214327 3734.33348737 2193.2381709  3947.33293195 3778.72929666
  559.7361604  2008.23015721  109.98440422  856.8308449  1324.38386887]
total_rewards_mean           2100.0591465750736
total_rewards_std            1324.7241007440775
total_rewards_max            3947.33293195117
total_rewards_min            109.98440422089556
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               30.07841057702899
(Previous) Eval Time (s)     23.94627104094252
Sample Time (s)              18.40123756788671
Epoch Time (s)               72.42591918585822
Total Train Time (s)         30305.982162879314
Epoch                        438
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:40:38.684494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #438 | Epoch Duration: 68.90478491783142
2020-01-11 11:40:38.684784 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1065642
Z variance train             0.014422134
KL Divergence                23.324467
KL Loss                      2.3324468
QF Loss                      845.35803
VF Loss                      199.05063
Policy Loss                  -1340.637
Q Predictions Mean           1337.6715
Q Predictions Std            229.35417
Q Predictions Max            1559.7865
Q Predictions Min            55.178425
V Predictions Mean           1331.4893
V Predictions Std            224.01299
V Predictions Max            1553.0758
V Predictions Min            51.87338
Log Pis Mean                 0.6696466
Log Pis Std                  2.7205245
Log Pis Max                  9.231951
Log Pis Min                  -7.246661
Policy mu Mean               0.022728488
Policy mu Std                0.6372393
Policy mu Max                2.4898102
Policy mu Min                -2.867058
Policy log std Mean          -1.0772028
Policy log std Std           0.27241406
Policy log std Max           -0.22930515
Policy log std Min           -3.0347648
Z mean eval                  1.0811508
Z variance eval              0.011911904
total_rewards                [3364.84798733 3603.79422617 3351.46886607 3180.40170138 3018.85190621
 2885.94193361 3420.0305249  3566.74620668 3147.15221102 3062.20106551]
total_rewards_mean           3260.1436628889023
total_rewards_std            226.6106116107278
total_rewards_max            3603.794226171798
total_rewards_min            2885.9419336144456
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               29.48206761199981
(Previous) Eval Time (s)     20.424841993954033
Sample Time (s)              17.480748950969428
Epoch Time (s)               67.38765855692327
Total Train Time (s)         30380.067578955088
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:41:52.776067 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #439 | Epoch Duration: 74.09103751182556
2020-01-11 11:41:52.776332 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0813714
Z variance train             0.011945286
KL Divergence                23.490211
KL Loss                      2.3490212
QF Loss                      1278.2991
VF Loss                      362.53363
Policy Loss                  -1366.8444
Q Predictions Mean           1368.7031
Q Predictions Std            214.98448
Q Predictions Max            1574.8436
Q Predictions Min            -13.78725
V Predictions Mean           1355.5813
V Predictions Std            215.83047
V Predictions Max            1576.5492
V Predictions Min            -38.3026
Log Pis Mean                 0.4367814
Log Pis Std                  2.6346278
Log Pis Max                  8.964181
Log Pis Min                  -7.408823
Policy mu Mean               0.07344269
Policy mu Std                0.59854454
Policy mu Max                2.1404397
Policy mu Min                -2.40949
Policy log std Mean          -1.0937961
Policy log std Std           0.25733906
Policy log std Max           -0.19713545
Policy log std Min           -2.2679303
Z mean eval                  1.0533487
Z variance eval              0.009072176
total_rewards                [4049.14367569 3651.94444551 4044.03190104 4105.7920959   227.14272394
 3913.40854637 4062.59483422 3900.32756179 4178.88500312 3880.30587813]
total_rewards_mean           3601.357666570876
total_rewards_std            1133.5634427068378
total_rewards_max            4178.885003119315
total_rewards_min            227.14272394362152
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               29.97774903802201
(Previous) Eval Time (s)     27.127947306726128
Sample Time (s)              17.851188539061695
Epoch Time (s)               74.95688488380983
Total Train Time (s)         30452.386190173216
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:43:05.101330 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #440 | Epoch Duration: 72.32478713989258
2020-01-11 11:43:05.101581 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0539954
Z variance train             0.009065164
KL Divergence                23.376099
KL Loss                      2.33761
QF Loss                      937.2561
VF Loss                      230.22185
Policy Loss                  -1354.6337
Q Predictions Mean           1353.7704
Q Predictions Std            228.67993
Q Predictions Max            1569.6654
Q Predictions Min            22.731276
V Predictions Mean           1343.4279
V Predictions Std            227.56812
V Predictions Max            1562.6841
V Predictions Min            14.156682
Log Pis Mean                 0.613675
Log Pis Std                  2.685998
Log Pis Max                  8.790777
Log Pis Min                  -8.97053
Policy mu Mean               -0.013053318
Policy mu Std                0.6454385
Policy mu Max                2.5259163
Policy mu Min                -2.6347163
Policy log std Mean          -1.0646542
Policy log std Std           0.26307985
Policy log std Max           -0.26413757
Policy log std Min           -2.0739317
Z mean eval                  1.092067
Z variance eval              0.009120641
total_rewards                [ 294.53484113 1716.3677149   848.15663309 1629.39954017 1452.23381837
 2266.05888307 1044.35478468 1154.25596379  461.25394804  350.8903702 ]
total_rewards_mean           1121.7506497440222
total_rewards_std            618.59560025962
total_rewards_max            2266.058883066388
total_rewards_min            294.5348411285508
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               27.361390699632466
(Previous) Eval Time (s)     24.495536717120558
Sample Time (s)              17.863890434149653
Epoch Time (s)               69.72081785090268
Total Train Time (s)         30512.002051467076
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:44:04.720660 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #441 | Epoch Duration: 59.61888384819031
2020-01-11 11:44:04.720852 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0931377
Z variance train             0.009115665
KL Divergence                24.18061
KL Loss                      2.418061
QF Loss                      1901.4628
VF Loss                      401.1145
Policy Loss                  -1373.926
Q Predictions Mean           1376.2375
Q Predictions Std            185.96928
Q Predictions Max            1597.5751
Q Predictions Min            -9.805397
V Predictions Mean           1383.6653
V Predictions Std            185.05104
V Predictions Max            1594.0809
V Predictions Min            -9.521034
Log Pis Mean                 0.9296463
Log Pis Std                  2.871258
Log Pis Max                  13.679313
Log Pis Min                  -5.1571903
Policy mu Mean               -0.028959025
Policy mu Std                0.6551293
Policy mu Max                3.1360855
Policy mu Min                -2.4333398
Policy log std Mean          -1.0765926
Policy log std Std           0.28407642
Policy log std Max           -0.21938413
Policy log std Min           -2.614553
Z mean eval                  1.048715
Z variance eval              0.012206019
total_rewards                [3877.61069236 3756.55153857 1665.37784267 3711.43669664 2657.90956793
 3800.39798501  258.50714577  187.63135805 1296.90713952 3885.3239946 ]
total_rewards_mean           2509.765396110872
total_rewards_std            1452.3710503353136
total_rewards_max            3885.3239945954524
total_rewards_min            187.6313580501273
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               30.547622358892113
(Previous) Eval Time (s)     14.39331097714603
Sample Time (s)              17.715539888478816
Epoch Time (s)               62.65647322451696
Total Train Time (s)         30579.67299662251
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:12.400118 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #442 | Epoch Duration: 67.6790714263916
2020-01-11 11:45:12.400440 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0493839
Z variance train             0.012230244
KL Divergence                22.509315
KL Loss                      2.2509315
QF Loss                      2775.6
VF Loss                      136.40167
Policy Loss                  -1370.4296
Q Predictions Mean           1370.356
Q Predictions Std            197.59856
Q Predictions Max            1601.2827
Q Predictions Min            -45.049232
V Predictions Mean           1367.0828
V Predictions Std            194.89973
V Predictions Max            1580.6647
V Predictions Min            -6.869009
Log Pis Mean                 0.7792388
Log Pis Std                  2.797814
Log Pis Max                  10.351512
Log Pis Min                  -5.9367876
Policy mu Mean               -0.015469344
Policy mu Std                0.63583463
Policy mu Max                2.7173162
Policy mu Min                -2.5866091
Policy log std Mean          -1.0693376
Policy log std Std           0.25174338
Policy log std Max           -0.24277246
Policy log std Min           -2.4439154
Z mean eval                  1.0650156
Z variance eval              0.010422664
total_rewards                [3571.52696249 3453.08138592 1466.43185544 3946.50693019 3613.71461345
 2752.52098017  866.53999135 3868.65807107   77.97413199 2307.00527224]
total_rewards_mean           2592.396019430216
total_rewards_std            1299.261682467285
total_rewards_max            3946.50693018594
total_rewards_min            77.974131986174
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               29.389230945147574
(Previous) Eval Time (s)     19.415568508207798
Sample Time (s)              18.378259778022766
Epoch Time (s)               67.18305923137814
Total Train Time (s)         30646.314450425096
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:46:19.044148 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #443 | Epoch Duration: 66.6434690952301
2020-01-11 11:46:19.044345 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0629449
Z variance train             0.010453919
KL Divergence                23.05419
KL Loss                      2.305419
QF Loss                      1143.2238
VF Loss                      568.18896
Policy Loss                  -1338.8114
Q Predictions Mean           1342.6318
Q Predictions Std            261.77756
Q Predictions Max            1588.0275
Q Predictions Min            -67.394005
V Predictions Mean           1357.7228
V Predictions Std            262.71426
V Predictions Max            1609.5344
V Predictions Min            -49.28499
Log Pis Mean                 0.5038228
Log Pis Std                  2.9030097
Log Pis Max                  12.562794
Log Pis Min                  -9.994015
Policy mu Mean               -0.017141804
Policy mu Std                0.6412618
Policy mu Max                2.8528788
Policy mu Min                -2.477166
Policy log std Mean          -1.0641346
Policy log std Std           0.2810739
Policy log std Max           -0.078052044
Policy log std Min           -2.19732
Z mean eval                  1.1064638
Z variance eval              0.012377968
total_rewards                [ 234.67052742  604.3613764  1117.04641565 2441.85455589 3487.21186907
 1123.97903821 1720.39413468 2177.41005006 1600.7548577  3748.96237431]
total_rewards_mean           1825.6645199385662
total_rewards_std            1097.371445967555
total_rewards_max            3748.9623743095804
total_rewards_min            234.670527415079
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               28.17510622087866
(Previous) Eval Time (s)     18.87564251385629
Sample Time (s)              17.12777049932629
Epoch Time (s)               64.17851923406124
Total Train Time (s)         30706.686098861042
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:19.423675 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #444 | Epoch Duration: 60.37914562225342
2020-01-11 11:47:19.423984 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1048262
Z variance train             0.012376884
KL Divergence                22.687572
KL Loss                      2.2687573
QF Loss                      4264.949
VF Loss                      301.09885
Policy Loss                  -1352.7983
Q Predictions Mean           1351.8398
Q Predictions Std            260.81363
Q Predictions Max            1591.2631
Q Predictions Min            -100.130325
V Predictions Mean           1360.1804
V Predictions Std            252.41245
V Predictions Max            1598.5525
V Predictions Min            -71.32655
Log Pis Mean                 0.9347005
Log Pis Std                  2.9044766
Log Pis Max                  11.960793
Log Pis Min                  -8.353277
Policy mu Mean               0.023803798
Policy mu Std                0.6434313
Policy mu Max                2.9970977
Policy mu Min                -2.2640574
Policy log std Mean          -1.09329
Policy log std Std           0.3301016
Policy log std Max           -0.021545112
Policy log std Min           -2.9603636
Z mean eval                  1.06616
Z variance eval              0.009974401
total_rewards                [2906.95002519 3701.55021101 3647.95305446 3647.32558641 3867.97634401
 1336.52711885  146.40823373 3001.43364115  832.06057945  949.44101635]
total_rewards_mean           2403.762581061649
total_rewards_std            1354.731723814615
total_rewards_max            3867.976344005345
total_rewards_min            146.40823372541087
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               24.893646298907697
(Previous) Eval Time (s)     15.07595290709287
Sample Time (s)              17.988527222536504
Epoch Time (s)               57.95812642853707
Total Train Time (s)         30766.929475953802
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:19.670755 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #445 | Epoch Duration: 60.24654269218445
2020-01-11 11:48:19.670961 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0654503
Z variance train             0.009993525
KL Divergence                22.697474
KL Loss                      2.2697475
QF Loss                      1079.8958
VF Loss                      248.12384
Policy Loss                  -1384.9521
Q Predictions Mean           1384.8206
Q Predictions Std            211.20175
Q Predictions Max            1597.2446
Q Predictions Min            -67.401306
V Predictions Mean           1376.906
V Predictions Std            206.12016
V Predictions Max            1588.2932
V Predictions Min            -27.710283
Log Pis Mean                 0.93784374
Log Pis Std                  2.9475374
Log Pis Max                  13.090261
Log Pis Min                  -6.9606433
Policy mu Mean               0.014507851
Policy mu Std                0.6775348
Policy mu Max                2.4540687
Policy mu Min                -2.4001942
Policy log std Mean          -1.0706426
Policy log std Std           0.27686572
Policy log std Max           0.07519233
Policy log std Min           -2.3962746
Z mean eval                  1.0906957
Z variance eval              0.00900548
total_rewards                [1154.51100238 1985.04068866 4070.62440877 3694.24549413 3249.66481087
  177.23108429  721.955014   3853.6172137  4119.18831357 3762.27936253]
total_rewards_mean           2678.8357392911394
total_rewards_std            1442.7363284418636
total_rewards_max            4119.188313570192
total_rewards_min            177.23108428897262
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               29.832450463902205
(Previous) Eval Time (s)     17.364068838767707
Sample Time (s)              17.84863160131499
Epoch Time (s)               65.0451509039849
Total Train Time (s)         30833.587288181297
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:49:26.334541 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #446 | Epoch Duration: 66.66340780258179
2020-01-11 11:49:26.334778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #446 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0861691
Z variance train             0.009023195
KL Divergence                23.30608
KL Loss                      2.3306081
QF Loss                      1874.386
VF Loss                      111.85326
Policy Loss                  -1339.7482
Q Predictions Mean           1342.5641
Q Predictions Std            290.40762
Q Predictions Max            1575.0511
Q Predictions Min            -67.25959
V Predictions Mean           1340.3401
V Predictions Std            288.09488
V Predictions Max            1573.2388
V Predictions Min            -71.69675
Log Pis Mean                 0.66746026
Log Pis Std                  2.5749645
Log Pis Max                  11.027925
Log Pis Min                  -6.0651
Policy mu Mean               -0.004319664
Policy mu Std                0.66235065
Policy mu Max                2.5618076
Policy mu Min                -2.6038625
Policy log std Mean          -1.0286477
Policy log std Std           0.27298778
Policy log std Max           -0.07566732
Policy log std Min           -2.4157887
Z mean eval                  1.0606854
Z variance eval              0.008303578
total_rewards                [3876.84690876  835.79071982 3763.46488608 1455.12036945 3796.47566585
   61.98646687 3676.61570955 3862.66397567 3612.9322602   292.72571246]
total_rewards_mean           2523.4622674708044
total_rewards_std            1559.6354347662154
total_rewards_max            3876.846908758647
total_rewards_min            61.986466865591936
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               26.161186492070556
(Previous) Eval Time (s)     18.98200487298891
Sample Time (s)              17.742613119073212
Epoch Time (s)               62.88580448413268
Total Train Time (s)         30895.069155672565
Epoch                        447
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:50:27.819179 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #447 | Epoch Duration: 61.484227895736694
2020-01-11 11:50:27.819370 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.060099
Z variance train             0.008295623
KL Divergence                23.607841
KL Loss                      2.3607843
QF Loss                      712.9872
VF Loss                      384.67007
Policy Loss                  -1336.942
Q Predictions Mean           1340.7643
Q Predictions Std            290.9149
Q Predictions Max            1627.8501
Q Predictions Min            -94.95982
V Predictions Mean           1353.4296
V Predictions Std            288.93198
V Predictions Max            1646.3708
V Predictions Min            -61.19758
Log Pis Mean                 0.52016187
Log Pis Std                  3.0607374
Log Pis Max                  10.394989
Log Pis Min                  -9.941018
Policy mu Mean               0.02634035
Policy mu Std                0.63114923
Policy mu Max                2.6869922
Policy mu Min                -2.8359015
Policy log std Mean          -1.0713158
Policy log std Std           0.28904948
Policy log std Max           0.26245558
Policy log std Min           -2.151949
Z mean eval                  1.0990368
Z variance eval              0.009570032
total_rewards                [3962.44569554 2904.37489858 2412.83894634 3200.42328893 4025.00163926
 3739.53453555 3586.31173414 3763.22626855 3837.80816224 4098.89901364]
total_rewards_mean           3553.086418276033
total_rewards_std            519.0996675969077
total_rewards_max            4098.899013639854
total_rewards_min            2412.838946339737
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               27.26124212378636
(Previous) Eval Time (s)     17.580112335272133
Sample Time (s)              18.030823660083115
Epoch Time (s)               62.87217811914161
Total Train Time (s)         30964.594491664786
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:37.349492 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #448 | Epoch Duration: 69.52998471260071
2020-01-11 11:51:37.349682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1005704
Z variance train             0.009597065
KL Divergence                23.0448
KL Loss                      2.30448
QF Loss                      3275.7773
VF Loss                      326.63333
Policy Loss                  -1382.8318
Q Predictions Mean           1384.002
Q Predictions Std            203.8752
Q Predictions Max            1624.6921
Q Predictions Min            62.02896
V Predictions Mean           1371.2634
V Predictions Std            206.04805
V Predictions Max            1613.4359
V Predictions Min            -7.991645
Log Pis Mean                 0.9461623
Log Pis Std                  2.6312468
Log Pis Max                  8.802568
Log Pis Min                  -6.463123
Policy mu Mean               0.038853478
Policy mu Std                0.6256248
Policy mu Max                2.4761639
Policy mu Min                -2.0638483
Policy log std Mean          -1.1066281
Policy log std Std           0.2842509
Policy log std Max           -0.22890627
Policy log std Min           -2.7477465
Z mean eval                  1.0749555
Z variance eval              0.012003965
total_rewards                [3734.59310888 4024.15768521 4024.46812873 3932.27009402 4007.38726468
 4100.02397158  205.05317388 4033.97736601  970.26204564 3782.17325941]
total_rewards_mean           3281.436609803445
total_rewards_std            1362.0746229861923
total_rewards_max            4100.023971577484
total_rewards_min            205.05317387800483
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               25.577107690740377
(Previous) Eval Time (s)     24.23759741988033
Sample Time (s)              17.45194842526689
Epoch Time (s)               67.2666535358876
Total Train Time (s)         31029.938822967466
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:52:42.699221 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #449 | Epoch Duration: 65.34938025474548
2020-01-11 11:52:42.699486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0747726
Z variance train             0.011983251
KL Divergence                22.469574
KL Loss                      2.2469575
QF Loss                      1692.0917
VF Loss                      1298.7114
Policy Loss                  -1371.221
Q Predictions Mean           1368.3883
Q Predictions Std            237.32521
Q Predictions Max            1588.5764
Q Predictions Min            -39.124123
V Predictions Mean           1361.4606
V Predictions Std            223.67355
V Predictions Max            1565.8468
V Predictions Min            -45.68942
Log Pis Mean                 0.8807971
Log Pis Std                  3.1942754
Log Pis Max                  14.450936
Log Pis Min                  -6.5866942
Policy mu Mean               -0.007411213
Policy mu Std                0.62666184
Policy mu Max                2.7673156
Policy mu Min                -2.453128
Policy log std Mean          -1.1053765
Policy log std Std           0.33469558
Policy log std Max           -0.15366161
Policy log std Min           -3.2868633
Z mean eval                  1.0771885
Z variance eval              0.008028266
total_rewards                [ 302.17653792 1130.8989689  4071.84704891 4119.62965241 2204.36415739
 4027.52046896 4142.99385884 3702.54745649 3855.46296855 4013.28316812]
total_rewards_mean           3157.0724286490863
total_rewards_std            1348.1432246215904
total_rewards_max            4142.993858835105
total_rewards_min            302.17653791547707
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               29.316928475163877
(Previous) Eval Time (s)     22.32000614888966
Sample Time (s)              18.527893145103008
Epoch Time (s)               70.16482776915655
Total Train Time (s)         31099.0415158025
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:53:51.806213 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #450 | Epoch Duration: 69.10653758049011
2020-01-11 11:53:51.806387 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0767843
Z variance train             0.0080503905
KL Divergence                23.189617
KL Loss                      2.3189619
QF Loss                      5275.7617
VF Loss                      1549.9572
Policy Loss                  -1315.7367
Q Predictions Mean           1317.1938
Q Predictions Std            340.63113
Q Predictions Max            1618.0481
Q Predictions Min            -67.15119
V Predictions Mean           1323.5151
V Predictions Std            334.8702
V Predictions Max            1628.1713
V Predictions Min            -88.39059
Log Pis Mean                 0.673018
Log Pis Std                  3.0663764
Log Pis Max                  11.457758
Log Pis Min                  -6.9303007
Policy mu Mean               0.03013332
Policy mu Std                0.66458386
Policy mu Max                2.4576905
Policy mu Min                -2.8948529
Policy log std Mean          -1.0553819
Policy log std Std           0.3251353
Policy log std Max           -0.17610562
Policy log std Min           -3.104601
Z mean eval                  1.0436525
Z variance eval              0.013474246
total_rewards                [3651.1426192  3672.5518905  3136.44979189 3664.74697934  396.18060862
 3667.14820993 3850.89892608 3213.80393703 3802.23691499 3874.09228738]
total_rewards_mean           3292.9252164951495
total_rewards_std            994.0368545020297
total_rewards_max            3874.0922873826444
total_rewards_min            396.18060861732255
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               29.73053283104673
(Previous) Eval Time (s)     21.261458958964795
Sample Time (s)              17.769365868531168
Epoch Time (s)               68.76135765854269
Total Train Time (s)         31169.890871409327
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:55:02.661767 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #451 | Epoch Duration: 70.85519886016846
2020-01-11 11:55:02.662078 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0452547
Z variance train             0.013527093
KL Divergence                22.68624
KL Loss                      2.268624
QF Loss                      1575.1299
VF Loss                      625.1023
Policy Loss                  -1363.3517
Q Predictions Mean           1363.4531
Q Predictions Std            209.9646
Q Predictions Max            1566.7765
Q Predictions Min            52.88953
V Predictions Mean           1370.5875
V Predictions Std            206.4659
V Predictions Max            1578.6254
V Predictions Min            44.64984
Log Pis Mean                 1.0171752
Log Pis Std                  2.8353202
Log Pis Max                  12.143886
Log Pis Min                  -6.1610937
Policy mu Mean               0.020013947
Policy mu Std                0.6217519
Policy mu Max                2.5116773
Policy mu Min                -2.571972
Policy log std Mean          -1.1253705
Policy log std Std           0.2872307
Policy log std Max           -0.17449474
Policy log std Min           -2.7323523
Z mean eval                  1.0630624
Z variance eval              0.011897012
total_rewards                [3497.24796212 3417.33671725  570.08317637 3766.77501009 3973.16574318
 4482.84323934 3998.76700959  353.9582656  4156.44471593  409.74356004]
total_rewards_mean           2862.636539951358
total_rewards_std            1609.873249582994
total_rewards_max            4482.843239341043
total_rewards_min            353.95826559587033
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               27.231262462213635
(Previous) Eval Time (s)     23.35498704202473
Sample Time (s)              18.077934691682458
Epoch Time (s)               68.66418419592083
Total Train Time (s)         31238.137548081577
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:56:10.915238 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #452 | Epoch Duration: 68.25290822982788
2020-01-11 11:56:10.915529 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0623678
Z variance train             0.0118678035
KL Divergence                23.238394
KL Loss                      2.3238394
QF Loss                      631.0583
VF Loss                      73.78441
Policy Loss                  -1368.5203
Q Predictions Mean           1369.0469
Q Predictions Std            283.19684
Q Predictions Max            1602.6414
Q Predictions Min            -70.00415
V Predictions Mean           1368.2815
V Predictions Std            282.72653
V Predictions Max            1607.9911
V Predictions Min            -69.587585
Log Pis Mean                 0.5274494
Log Pis Std                  2.7923617
Log Pis Max                  10.221006
Log Pis Min                  -7.245244
Policy mu Mean               -0.0034056234
Policy mu Std                0.64666784
Policy mu Max                2.3964443
Policy mu Min                -2.6193585
Policy log std Mean          -1.0503533
Policy log std Std           0.2866833
Policy log std Max           -0.11648202
Policy log std Min           -2.1974359
Z mean eval                  1.083688
Z variance eval              0.01562194
total_rewards                [3763.4380713   913.6983864  3979.27106218   90.70619713 3618.27563674
 2915.36686485 3973.93039871 3926.19921462 3977.31768502 3842.6187257 ]
total_rewards_mean           3100.0822242648997
total_rewards_std            1346.0779677160558
total_rewards_max            3979.2710621753818
total_rewards_min            90.70619713172397
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               28.742477805819362
(Previous) Eval Time (s)     22.943402274977416
Sample Time (s)              18.237005597446114
Epoch Time (s)               69.92288567824289
Total Train Time (s)         31309.43041100353
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:22.210417 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #453 | Epoch Duration: 71.29469180107117
2020-01-11 11:57:22.210622 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #453 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0833267
Z variance train             0.015646549
KL Divergence                22.492128
KL Loss                      2.249213
QF Loss                      4797.5195
VF Loss                      526.933
Policy Loss                  -1380.3143
Q Predictions Mean           1380.8835
Q Predictions Std            254.09642
Q Predictions Max            1652.4194
Q Predictions Min            -135.35385
V Predictions Mean           1376.9137
V Predictions Std            255.20988
V Predictions Max            1648.9441
V Predictions Min            -112.96536
Log Pis Mean                 0.6104242
Log Pis Std                  2.7511082
Log Pis Max                  9.563387
Log Pis Min                  -6.105235
Policy mu Mean               -0.00067453086
Policy mu Std                0.6105196
Policy mu Max                3.0149302
Policy mu Min                -2.558341
Policy log std Mean          -1.0810394
Policy log std Std           0.25047624
Policy log std Max           -0.115773976
Policy log std Min           -2.1239915
Z mean eval                  1.0665356
Z variance eval              0.01413161
total_rewards                [3558.44934107 1380.11053036 3876.58372003 4037.40453974 3074.8450793
 3633.09086916 3900.60905493 4087.74108988 3691.72239639 4207.81599854]
total_rewards_mean           3544.8372619406773
total_rewards_std            784.2206883671483
total_rewards_max            4207.815998540045
total_rewards_min            1380.1105303647844
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               28.378696685191244
(Previous) Eval Time (s)     24.314897644799203
Sample Time (s)              18.111733279190958
Epoch Time (s)               70.8053276091814
Total Train Time (s)         31380.803056891542
Epoch                        454
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:58:33.588540 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #454 | Epoch Duration: 71.37776708602905
2020-01-11 11:58:33.588751 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0654197
Z variance train             0.014119235
KL Divergence                22.499939
KL Loss                      2.249994
QF Loss                      2985.776
VF Loss                      549.35077
Policy Loss                  -1393.7114
Q Predictions Mean           1393.0194
Q Predictions Std            198.51515
Q Predictions Max            1601.9106
Q Predictions Min            -25.69689
V Predictions Mean           1387.9355
V Predictions Std            200.93723
V Predictions Max            1600.4526
V Predictions Min            -32.199158
Log Pis Mean                 1.149518
Log Pis Std                  2.8517427
Log Pis Max                  11.490227
Log Pis Min                  -9.08453
Policy mu Mean               0.011587471
Policy mu Std                0.60766435
Policy mu Max                2.7438776
Policy mu Min                -2.4987514
Policy log std Mean          -1.1360781
Policy log std Std           0.27636704
Policy log std Max           -0.1200462
Policy log std Min           -2.7182858
Z mean eval                  1.1419154
Z variance eval              0.013263707
total_rewards                [3664.95264803 3914.37771593 4089.01857387 3947.51962676 1134.15766884
  957.75088302 3482.00992894 2950.83479354 3808.24339879 4188.00493585]
total_rewards_mean           3213.687017358172
total_rewards_std            1133.8824932034336
total_rewards_max            4188.004935853402
total_rewards_min            957.7508830206156
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               30.043722114991397
(Previous) Eval Time (s)     24.887025642208755
Sample Time (s)              17.39198022009805
Epoch Time (s)               72.3227279772982
Total Train Time (s)         31451.896682607476
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:44.687297 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #455 | Epoch Duration: 71.09835815429688
2020-01-11 11:59:44.687544 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1416199
Z variance train             0.013321263
KL Divergence                22.873013
KL Loss                      2.2873013
QF Loss                      895.69275
VF Loss                      308.80707
Policy Loss                  -1376.2068
Q Predictions Mean           1380.0125
Q Predictions Std            252.0122
Q Predictions Max            1593.6501
Q Predictions Min            -33.893597
V Predictions Mean           1386.4943
V Predictions Std            252.65372
V Predictions Max            1610.3207
V Predictions Min            -34.021038
Log Pis Mean                 1.0898994
Log Pis Std                  2.916763
Log Pis Max                  10.279496
Log Pis Min                  -7.0635824
Policy mu Mean               -0.02688041
Policy mu Std                0.65793604
Policy mu Max                2.3449767
Policy mu Min                -2.5367272
Policy log std Mean          -1.091752
Policy log std Std           0.29701546
Policy log std Max           -0.12840009
Policy log std Min           -2.8332064
Z mean eval                  1.0678152
Z variance eval              0.012985771
total_rewards                [3888.95983216 3828.40995121 3915.68221528 3808.00334419 1098.93414519
  854.51546897 3666.73178227 3570.11611522 1665.16447086 3944.78996386]
total_rewards_mean           3024.1307289205324
total_rewards_std            1209.2628295991149
total_rewards_max            3944.7899638609383
total_rewards_min            854.5154689672526
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               28.691308772191405
(Previous) Eval Time (s)     23.662357504013926
Sample Time (s)              17.649808942805976
Epoch Time (s)               70.0034752190113
Total Train Time (s)         31520.030158194248
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:00:52.825684 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #456 | Epoch Duration: 68.13794660568237
2020-01-11 12:00:52.825882 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #456 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0675659
Z variance train             0.012956113
KL Divergence                23.021765
KL Loss                      2.3021765
QF Loss                      4926.8203
VF Loss                      698.73914
Policy Loss                  -1347.2972
Q Predictions Mean           1349.9431
Q Predictions Std            310.9519
Q Predictions Max            1595.2625
Q Predictions Min            -99.39636
V Predictions Mean           1349.2256
V Predictions Std            303.70255
V Predictions Max            1602.6617
V Predictions Min            -89.978546
Log Pis Mean                 0.9267147
Log Pis Std                  3.0736072
Log Pis Max                  12.528967
Log Pis Min                  -6.1377654
Policy mu Mean               0.016209124
Policy mu Std                0.6895156
Policy mu Max                2.2184985
Policy mu Min                -2.4862418
Policy log std Mean          -1.036162
Policy log std Std           0.30873084
Policy log std Max           -0.093298316
Policy log std Min           -2.4349887
Z mean eval                  1.0641477
Z variance eval              0.011827157
total_rewards                [4122.16883888   88.38934363 3391.62589597 4302.95703788 3517.4253755
 2903.94084892 3581.14024716 3882.66794335 4042.70306173 3716.75380567]
total_rewards_mean           3354.9772398671303
total_rewards_std            1154.2299489981042
total_rewards_max            4302.9570378753115
total_rewards_min            88.38934362651014
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               28.0563609697856
(Previous) Eval Time (s)     21.796536766923964
Sample Time (s)              18.015422673430294
Epoch Time (s)               67.86832041013986
Total Train Time (s)         31589.022189214826
Epoch                        457
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:01.819700 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #457 | Epoch Duration: 68.99365234375
2020-01-11 12:02:01.819897 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0647185
Z variance train             0.011831108
KL Divergence                23.480795
KL Loss                      2.3480794
QF Loss                      1060.9629
VF Loss                      122.09188
Policy Loss                  -1355.8093
Q Predictions Mean           1354.1575
Q Predictions Std            293.13385
Q Predictions Max            1628.3406
Q Predictions Min            -71.398605
V Predictions Mean           1356.7872
V Predictions Std            289.78366
V Predictions Max            1623.5825
V Predictions Min            -77.25946
Log Pis Mean                 0.73450005
Log Pis Std                  2.793908
Log Pis Max                  16.230328
Log Pis Min                  -7.489187
Policy mu Mean               -0.0058305156
Policy mu Std                0.6721033
Policy mu Max                2.6955333
Policy mu Min                -2.6336195
Policy log std Mean          -1.0293555
Policy log std Std           0.27141148
Policy log std Max           -0.22400397
Policy log std Min           -2.5474417
Z mean eval                  1.086438
Z variance eval              0.0153942155
total_rewards                [3602.03150933 2350.15992381 3613.02817514 3583.84680727 3881.97314704
  348.72344076 3735.2602031  3801.85811126 3235.50878511 3424.48546473]
total_rewards_mean           3157.687556755437
total_rewards_std            1023.6767734663059
total_rewards_max            3881.9731470417837
total_rewards_min            348.72344075904243
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               29.563075298909098
(Previous) Eval Time (s)     22.921571015845984
Sample Time (s)              17.571580092422664
Epoch Time (s)               70.05622640717775
Total Train Time (s)         31662.9773844718
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:03:15.781457 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #458 | Epoch Duration: 73.96140170097351
2020-01-11 12:03:15.781714 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0865064
Z variance train             0.015387021
KL Divergence                23.221756
KL Loss                      2.3221757
QF Loss                      1018.1295
VF Loss                      197.69557
Policy Loss                  -1379.5796
Q Predictions Mean           1378.9758
Q Predictions Std            237.72296
Q Predictions Max            1623.8405
Q Predictions Min            -44.171944
V Predictions Mean           1371.0674
V Predictions Std            238.56664
V Predictions Max            1591.3582
V Predictions Min            -51.523376
Log Pis Mean                 0.48005286
Log Pis Std                  2.6951275
Log Pis Max                  13.184718
Log Pis Min                  -4.7181463
Policy mu Mean               0.075120896
Policy mu Std                0.6049716
Policy mu Max                2.2277417
Policy mu Min                -2.4792655
Policy log std Mean          -1.1102161
Policy log std Std           0.29058632
Policy log std Max           -0.18963903
Policy log std Min           -3.2883348
Z mean eval                  1.0824351
Z variance eval              0.012338904
total_rewards                [2986.925425   3811.97501069 3748.92489702  498.44647899 3740.79538154
 3941.85288997  373.32099579 4178.15924536 4086.80002667 3873.96880304]
total_rewards_mean           3124.116915406961
total_rewards_std            1378.1293489495029
total_rewards_max            4178.159245359569
total_rewards_min            373.32099578509207
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               29.317169232293963
(Previous) Eval Time (s)     26.826454396825284
Sample Time (s)              18.536416373681277
Epoch Time (s)               74.68004000280052
Total Train Time (s)         31734.450252521317
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:04:27.261255 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #459 | Epoch Duration: 71.47931981086731
2020-01-11 12:04:27.261542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.082517
Z variance train             0.012336068
KL Divergence                24.049376
KL Loss                      2.4049375
QF Loss                      1696.9991
VF Loss                      332.4685
Policy Loss                  -1367.889
Q Predictions Mean           1368.7671
Q Predictions Std            311.1323
Q Predictions Max            1623.8966
Q Predictions Min            -78.79816
V Predictions Mean           1376.6235
V Predictions Std            306.81668
V Predictions Max            1635.6736
V Predictions Min            -65.24351
Log Pis Mean                 0.76885355
Log Pis Std                  2.8970888
Log Pis Max                  11.961159
Log Pis Min                  -6.409392
Policy mu Mean               0.021683853
Policy mu Std                0.6605351
Policy mu Max                2.8217618
Policy mu Min                -2.4836574
Policy log std Mean          -1.0348175
Policy log std Std           0.30183598
Policy log std Max           -0.14972526
Policy log std Min           -2.7188206
Z mean eval                  1.0775121
Z variance eval              0.013546589
total_rewards                [4141.76412025 3914.87298362  309.58037326 4001.41735361 3496.92478023
 3584.69363335 3829.64140304 3657.84520384 1791.52280208 3941.09776265]
total_rewards_mean           3266.936041592501
total_rewards_std            1171.5465015178527
total_rewards_max            4141.764120247316
total_rewards_min            309.5803732589222
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               29.694924669340253
(Previous) Eval Time (s)     23.625451458152384
Sample Time (s)              17.774020954035223
Epoch Time (s)               71.09439708152786
Total Train Time (s)         31804.629081483465
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:37.444263 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #460 | Epoch Duration: 70.18251466751099
2020-01-11 12:05:37.444423 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0784876
Z variance train             0.013513456
KL Divergence                23.069553
KL Loss                      2.3069553
QF Loss                      760.3934
VF Loss                      311.15518
Policy Loss                  -1400.2574
Q Predictions Mean           1401.6517
Q Predictions Std            238.27109
Q Predictions Max            1616.3932
Q Predictions Min            -97.85625
V Predictions Mean           1409.3105
V Predictions Std            236.05962
V Predictions Max            1627.008
V Predictions Min            -101.65543
Log Pis Mean                 0.7352971
Log Pis Std                  2.9597526
Log Pis Max                  18.834904
Log Pis Min                  -13.240385
Policy mu Mean               0.027320638
Policy mu Std                0.65708774
Policy mu Max                3.4232087
Policy mu Min                -2.7739878
Policy log std Mean          -1.0586843
Policy log std Std           0.28496552
Policy log std Max           0.22555196
Policy log std Min           -2.4452622
Z mean eval                  1.0677361
Z variance eval              0.008135353
total_rewards                [ 883.90971135 1067.96454385 3832.18570677 4046.59933965 3907.45180923
 1222.45614533 3851.07849809 3433.31962133  246.39250082 3983.11906872]
total_rewards_mean           2647.447694516006
total_rewards_std            1489.955699646891
total_rewards_max            4046.5993396495546
total_rewards_min            246.39250082433676
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               30.447391911409795
(Previous) Eval Time (s)     22.71328029828146
Sample Time (s)              18.154194094240665
Epoch Time (s)               71.31486630393192
Total Train Time (s)         31871.69262360502
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:06:44.513479 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #461 | Epoch Duration: 67.06889581680298
2020-01-11 12:06:44.513750 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.06925
Z variance train             0.008135505
KL Divergence                24.088247
KL Loss                      2.4088247
QF Loss                      1480.0562
VF Loss                      287.00497
Policy Loss                  -1394.7943
Q Predictions Mean           1393.0929
Q Predictions Std            208.3188
Q Predictions Max            1623.9764
Q Predictions Min            5.480918
V Predictions Mean           1384.8934
V Predictions Std            204.98723
V Predictions Max            1612.4445
V Predictions Min            -21.120031
Log Pis Mean                 0.6351534
Log Pis Std                  2.787583
Log Pis Max                  18.231575
Log Pis Min                  -6.220312
Policy mu Mean               0.0647221
Policy mu Std                0.5927191
Policy mu Max                2.1765876
Policy mu Min                -2.146244
Policy log std Mean          -1.1055863
Policy log std Std           0.26951253
Policy log std Max           -0.2369067
Policy log std Min           -3.6854515
Z mean eval                  1.0762959
Z variance eval              0.011386721
total_rewards                [4128.17295499 3842.72368885 3804.94013416 3962.0974448  3739.18401744
  615.35166905 3801.4526125  4133.70837148 3999.24703226 4048.97504036]
total_rewards_mean           3607.585296588997
total_rewards_std            1006.1969748043971
total_rewards_max            4133.708371482591
total_rewards_min            615.3516690487229
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               29.574937601108104
(Previous) Eval Time (s)     18.46697222115472
Sample Time (s)              18.35427095880732
Epoch Time (s)               66.39618078107014
Total Train Time (s)         31944.26143216295
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:07:57.085619 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #462 | Epoch Duration: 72.5716757774353
2020-01-11 12:07:57.085795 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0764334
Z variance train             0.011329441
KL Divergence                23.731419
KL Loss                      2.373142
QF Loss                      751.27893
VF Loss                      154.1344
Policy Loss                  -1395.1572
Q Predictions Mean           1396.66
Q Predictions Std            235.80661
Q Predictions Max            1630.6016
Q Predictions Min            -47.68991
V Predictions Mean           1401.2744
V Predictions Std            235.40988
V Predictions Max            1637.3054
V Predictions Min            -35.47266
Log Pis Mean                 1.2981796
Log Pis Std                  2.6848264
Log Pis Max                  14.52965
Log Pis Min                  -4.688011
Policy mu Mean               -0.011046826
Policy mu Std                0.6464905
Policy mu Max                2.6490912
Policy mu Min                -2.8716433
Policy log std Mean          -1.1060617
Policy log std Std           0.30043498
Policy log std Max           -0.089722335
Policy log std Min           -3.0563054
Z mean eval                  1.1250994
Z variance eval              0.0058645224
total_rewards                [3953.4070025  3839.50481154 2679.25615569 1047.28569659 3770.49781346
  931.82419606 1801.07400815 4165.66382667 3376.5235938  1204.57683736]
total_rewards_mean           2676.9613941800835
total_rewards_std            1245.741212045302
total_rewards_max            4165.663826670275
total_rewards_min            931.824196055031
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               28.52777083031833
(Previous) Eval Time (s)     24.642132255248725
Sample Time (s)              18.55962284654379
Epoch Time (s)               71.72952593211085
Total Train Time (s)         32010.70213933289
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:09:03.533184 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #463 | Epoch Duration: 66.44722414016724
2020-01-11 12:09:03.533439 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.125769
Z variance train             0.005845685
KL Divergence                25.064388
KL Loss                      2.506439
QF Loss                      8112.8447
VF Loss                      991.28375
Policy Loss                  -1391.0691
Q Predictions Mean           1399.992
Q Predictions Std            267.70004
Q Predictions Max            1622.2458
Q Predictions Min            -80.29511
V Predictions Mean           1400.0295
V Predictions Std            270.24036
V Predictions Max            1625.942
V Predictions Min            -64.88725
Log Pis Mean                 1.3197262
Log Pis Std                  3.0637648
Log Pis Max                  13.891224
Log Pis Min                  -6.5852795
Policy mu Mean               -0.05958164
Policy mu Std                0.701224
Policy mu Max                2.6506934
Policy mu Min                -3.6044023
Policy log std Mean          -1.0680103
Policy log std Std           0.32341862
Policy log std Max           -0.17173475
Policy log std Min           -2.9692073
Z mean eval                  1.085866
Z variance eval              0.012203334
total_rewards                [3056.26040589  285.07331737  392.10400484 2602.38439448 4011.25740335
 2290.5579995    67.53231532   93.05266382 2996.23135479  575.11183496]
total_rewards_mean           1636.956569432254
total_rewards_std            1421.6220918740019
total_rewards_max            4011.25740334939
total_rewards_min            67.53231532074923
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               28.78531481605023
(Previous) Eval Time (s)     19.359498501755297
Sample Time (s)              18.02837149007246
Epoch Time (s)               66.17318480787799
Total Train Time (s)         32070.410295757465
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:10:03.245474 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #464 | Epoch Duration: 59.711849212646484
2020-01-11 12:10:03.245666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.084232
Z variance train             0.012161488
KL Divergence                23.372946
KL Loss                      2.3372946
QF Loss                      6786.8306
VF Loss                      210.26302
Policy Loss                  -1381.3042
Q Predictions Mean           1380.7122
Q Predictions Std            252.87242
Q Predictions Max            1635.9398
Q Predictions Min            -83.64698
V Predictions Mean           1382.2368
V Predictions Std            243.1667
V Predictions Max            1628.5126
V Predictions Min            -71.71966
Log Pis Mean                 1.0153638
Log Pis Std                  2.8810413
Log Pis Max                  11.321984
Log Pis Min                  -8.1404085
Policy mu Mean               0.0018932663
Policy mu Std                0.6388944
Policy mu Max                2.3607452
Policy mu Min                -2.7424679
Policy log std Mean          -1.1001812
Policy log std Std           0.3067739
Policy log std Max           -0.2293716
Policy log std Min           -3.1037223
Z mean eval                  1.080426
Z variance eval              0.013373582
total_rewards                [3981.32041345 4094.51109109 3875.37512745 4256.30602043 3798.09662685
  860.73692196 3867.69523862 4248.56143494 3542.15025362 4112.91902748]
total_rewards_mean           3663.7672155888627
total_rewards_std            956.9421421488615
total_rewards_max            4256.306020431541
total_rewards_min            860.7369219623597
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               31.601566702127457
(Previous) Eval Time (s)     12.89787045866251
Sample Time (s)              17.675252890214324
Epoch Time (s)               62.17469005100429
Total Train Time (s)         32146.246726593934
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:19.086485 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #465 | Epoch Duration: 75.84067487716675
2020-01-11 12:11:19.086712 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.080226
Z variance train             0.013507003
KL Divergence                23.391401
KL Loss                      2.3391402
QF Loss                      4334.227
VF Loss                      958.3298
Policy Loss                  -1389.4758
Q Predictions Mean           1388.063
Q Predictions Std            272.27502
Q Predictions Max            1624.3849
Q Predictions Min            -89.43961
V Predictions Mean           1375.1655
V Predictions Std            267.0549
V Predictions Max            1618.5015
V Predictions Min            -89.60887
Log Pis Mean                 1.014451
Log Pis Std                  2.974439
Log Pis Max                  13.773092
Log Pis Min                  -11.602759
Policy mu Mean               0.041334674
Policy mu Std                0.6578067
Policy mu Max                3.074046
Policy mu Min                -2.5224767
Policy log std Mean          -1.0662048
Policy log std Std           0.29237837
Policy log std Max           -0.03129089
Policy log std Min           -2.919458
Z mean eval                  1.1207589
Z variance eval              0.009911003
total_rewards                [2577.89260044 4153.43552597 4003.10020378 4050.11384695 3854.45912791
 3599.71527616 4003.45449334 4009.13406363 3817.79575669 2634.38942827]
total_rewards_mean           3670.3490323149003
total_rewards_std            551.4844794370381
total_rewards_max            4153.435525970397
total_rewards_min            2577.892600439238
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               29.32144682155922
(Previous) Eval Time (s)     26.56353534385562
Sample Time (s)              19.191311849281192
Epoch Time (s)               75.07629401469603
Total Train Time (s)         32219.69369828375
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:12:32.537023 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #466 | Epoch Duration: 73.45017623901367
2020-01-11 12:12:32.537309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #466 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1203436
Z variance train             0.009886744
KL Divergence                23.76534
KL Loss                      2.3765342
QF Loss                      1572.5503
VF Loss                      292.80615
Policy Loss                  -1374.0531
Q Predictions Mean           1373.9355
Q Predictions Std            301.61392
Q Predictions Max            1629.7102
Q Predictions Min            -128.55046
V Predictions Mean           1368.897
V Predictions Std            301.42618
V Predictions Max            1612.3336
V Predictions Min            -113.00409
Log Pis Mean                 0.7827728
Log Pis Std                  2.7818375
Log Pis Max                  13.523774
Log Pis Min                  -7.0334654
Policy mu Mean               0.02281069
Policy mu Std                0.61205655
Policy mu Max                3.0175169
Policy mu Min                -2.835216
Policy log std Mean          -1.0945718
Policy log std Std           0.29419273
Policy log std Max           -0.19449359
Policy log std Min           -2.8826241
Z mean eval                  1.1242311
Z variance eval              0.010002458
total_rewards                [4018.45281676  469.4324333  4115.52880076 4297.76314385   42.7624017
 4189.04552889 3022.59318965 4053.87769811 2889.345756   3184.03204181]
total_rewards_mean           3028.2833810830657
total_rewards_std            1472.34428132441
total_rewards_max            4297.763143845812
total_rewards_min            42.76240169817065
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               28.708277623169124
(Previous) Eval Time (s)     24.937064005061984
Sample Time (s)              17.97645400231704
Epoch Time (s)               71.62179563054815
Total Train Time (s)         32289.329437914304
Epoch                        467
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:13:42.181666 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #467 | Epoch Duration: 69.64418029785156
2020-01-11 12:13:42.181953 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #467 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1235874
Z variance train             0.009992278
KL Divergence                23.393536
KL Loss                      2.3393536
QF Loss                      708.0995
VF Loss                      406.4903
Policy Loss                  -1411.7493
Q Predictions Mean           1412.3362
Q Predictions Std            207.09517
Q Predictions Max            1619.2938
Q Predictions Min            -139.44151
V Predictions Mean           1412.7078
V Predictions Std            205.07004
V Predictions Max            1615.3324
V Predictions Min            -128.01648
Log Pis Mean                 1.0306237
Log Pis Std                  2.9097133
Log Pis Max                  9.464571
Log Pis Min                  -7.006626
Policy mu Mean               -0.012437216
Policy mu Std                0.67451036
Policy mu Max                2.6208422
Policy mu Min                -2.2107174
Policy log std Mean          -1.0906285
Policy log std Std           0.28555351
Policy log std Max           -0.07527381
Policy log std Min           -2.6042466
Z mean eval                  1.0946778
Z variance eval              0.007789175
total_rewards                [1766.30643595  321.68424336   91.86827273 4061.7569365  3286.73008163
 4123.72464903 4205.87844306 3783.43158733 4110.26307275  476.02585626]
total_rewards_mean           2622.7669578604814
total_rewards_std            1669.5177155018087
total_rewards_max            4205.878443060918
total_rewards_min            91.86827273481765
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               29.66373254545033
(Previous) Eval Time (s)     22.95911307260394
Sample Time (s)              18.25801516743377
Epoch Time (s)               70.88086078548804
Total Train Time (s)         32360.204245259054
Epoch                        468
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:14:53.060792 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #468 | Epoch Duration: 70.8785891532898
2020-01-11 12:14:53.061067 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #468 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0934821
Z variance train             0.0077958903
KL Divergence                24.248405
KL Loss                      2.4248407
QF Loss                      1086.8251
VF Loss                      275.37952
Policy Loss                  -1400.8911
Q Predictions Mean           1402.1924
Q Predictions Std            274.6348
Q Predictions Max            1660.0282
Q Predictions Min            -102.07592
V Predictions Mean           1389.418
V Predictions Std            274.38004
V Predictions Max            1650.6271
V Predictions Min            -111.94751
Log Pis Mean                 0.7022408
Log Pis Std                  3.093421
Log Pis Max                  13.1786785
Log Pis Min                  -8.47232
Policy mu Mean               0.034559786
Policy mu Std                0.6413632
Policy mu Max                3.309947
Policy mu Min                -2.8976665
Policy log std Mean          -1.0838084
Policy log std Std           0.2847894
Policy log std Max           -0.16068959
Policy log std Min           -2.410006
Z mean eval                  1.063735
Z variance eval              0.010783081
total_rewards                [3117.66192203 4276.05025301 2771.11965254 1203.33631383 4220.39283909
 3968.8350746  4085.93114239 4247.38134907 4195.54690923 2851.17164037]
total_rewards_mean           3493.7427096156925
total_rewards_std            953.9080464090736
total_rewards_max            4276.050253011063
total_rewards_min            1203.3363138342586
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               29.571667273063213
(Previous) Eval Time (s)     22.95652961404994
Sample Time (s)              17.956216755788773
Epoch Time (s)               70.48441364290193
Total Train Time (s)         32431.285268584732
Epoch                        469
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:16:04.144671 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #469 | Epoch Duration: 71.08340525627136
2020-01-11 12:16:04.144880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0622966
Z variance train             0.010798576
KL Divergence                24.000492
KL Loss                      2.4000492
QF Loss                      870.34424
VF Loss                      598.87744
Policy Loss                  -1428.9094
Q Predictions Mean           1434.3898
Q Predictions Std            212.13269
Q Predictions Max            1658.7349
Q Predictions Min            -76.28758
V Predictions Mean           1424.6606
V Predictions Std            204.83742
V Predictions Max            1646.7056
V Predictions Min            -80.713486
Log Pis Mean                 1.1026385
Log Pis Std                  2.756267
Log Pis Max                  12.588972
Log Pis Min                  -10.521227
Policy mu Mean               0.009742767
Policy mu Std                0.6600313
Policy mu Max                2.6070125
Policy mu Min                -2.410822
Policy log std Mean          -1.0985557
Policy log std Std           0.276495
Policy log std Max           -0.20539069
Policy log std Min           -2.8135936
Z mean eval                  1.0853002
Z variance eval              0.0115347635
total_rewards                [ 990.48294865 1418.45039211 4083.3591828  4335.1774251  3840.48028256
  301.76296296 4001.25418079 4022.63334261 4114.74255431 2185.88132689]
total_rewards_mean           2929.422459878297
total_rewards_std            1462.4168763824362
total_rewards_max            4335.177425097128
total_rewards_min            301.76296296442604
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               30.469227354042232
(Previous) Eval Time (s)     23.5552273937501
Sample Time (s)              18.032830588519573
Epoch Time (s)               72.0572853363119
Total Train Time (s)         32499.47510884842
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:17:12.338376 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #470 | Epoch Duration: 68.19335055351257
2020-01-11 12:17:12.338559 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0845665
Z variance train             0.011533765
KL Divergence                23.44046
KL Loss                      2.344046
QF Loss                      6976.446
VF Loss                      487.39276
Policy Loss                  -1401.5942
Q Predictions Mean           1405.3303
Q Predictions Std            263.2489
Q Predictions Max            1674.4402
Q Predictions Min            -91.67714
V Predictions Mean           1417.013
V Predictions Std            266.9129
V Predictions Max            1675.3395
V Predictions Min            -99.36669
Log Pis Mean                 1.1035302
Log Pis Std                  2.9970963
Log Pis Max                  16.609352
Log Pis Min                  -6.306489
Policy mu Mean               -0.038073175
Policy mu Std                0.64775866
Policy mu Max                3.0539281
Policy mu Min                -2.5376706
Policy log std Mean          -1.1153584
Policy log std Std           0.2851139
Policy log std Max           0.059633136
Policy log std Min           -2.238245
Z mean eval                  1.1219347
Z variance eval              0.010392066
total_rewards                [2172.84600577  346.70755587 4402.40955775   73.53992951 3799.08679793
 1389.46720616 2014.68471847 1983.07517417 4248.33564109 4197.24019003]
total_rewards_mean           2462.7392776746788
total_rewards_std            1536.152291931533
total_rewards_max            4402.409557746816
total_rewards_min            73.5399295055712
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               29.38429060904309
(Previous) Eval Time (s)     19.690999762155116
Sample Time (s)              18.728483581915498
Epoch Time (s)               67.8037739531137
Total Train Time (s)         32563.193874282762
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:18:16.060833 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #471 | Epoch Duration: 63.72212600708008
2020-01-11 12:18:16.061025 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1221114
Z variance train             0.010396204
KL Divergence                23.669386
KL Loss                      2.3669386
QF Loss                      795.57227
VF Loss                      198.34753
Policy Loss                  -1379.4523
Q Predictions Mean           1380.086
Q Predictions Std            310.6291
Q Predictions Max            1641.4038
Q Predictions Min            -102.1185
V Predictions Mean           1387.1571
V Predictions Std            313.37057
V Predictions Max            1640.4294
V Predictions Min            -116.98716
Log Pis Mean                 0.9407251
Log Pis Std                  3.3134804
Log Pis Max                  27.82128
Log Pis Min                  -8.000745
Policy mu Mean               0.004430885
Policy mu Std                0.67948794
Policy mu Max                7.119903
Policy mu Min                -3.716514
Policy log std Mean          -1.0999963
Policy log std Std           0.28186798
Policy log std Max           0.42045337
Policy log std Min           -2.7016919
Z mean eval                  1.0920125
Z variance eval              0.006665739
total_rewards                [3644.33775742 3993.82775541 -278.3320153  3762.03833595 4163.48613263
 3844.20550878 4008.98447928 1460.71264699 4118.94816663 1408.01409137]
total_rewards_mean           3012.622285915693
total_rewards_std            1482.2191824869192
total_rewards_max            4163.486132633575
total_rewards_min            -278.3320152954788
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               30.07652655802667
(Previous) Eval Time (s)     15.608975965995342
Sample Time (s)              18.661186858080328
Epoch Time (s)               64.34668938210234
Total Train Time (s)         32635.261206837837
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:28.133439 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #472 | Epoch Duration: 72.07226085662842
2020-01-11 12:19:28.133658 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #472 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0878656
Z variance train             0.0066564605
KL Divergence                24.571857
KL Loss                      2.4571857
QF Loss                      2463.219
VF Loss                      362.73315
Policy Loss                  -1422.3531
Q Predictions Mean           1422.1455
Q Predictions Std            228.39911
Q Predictions Max            1692.1721
Q Predictions Min            32.321552
V Predictions Mean           1426.3142
V Predictions Std            223.33736
V Predictions Max            1686.7747
V Predictions Min            31.321598
Log Pis Mean                 1.3029957
Log Pis Std                  2.9526808
Log Pis Max                  12.962264
Log Pis Min                  -5.466115
Policy mu Mean               0.007714193
Policy mu Std                0.65418756
Policy mu Max                2.3503761
Policy mu Min                -2.519532
Policy log std Mean          -1.1228838
Policy log std Std           0.29941088
Policy log std Max           -0.123006105
Policy log std Min           -3.2491474
Z mean eval                  1.0780809
Z variance eval              0.0062578097
total_rewards                [ -14.33415439 4001.45636353 4013.07295581  665.0612795    69.19659327
 1276.71731505 3879.60350199  257.29336676 2101.99644665 4352.06024796]
total_rewards_mean           2060.2123916141154
total_rewards_std            1738.5426227077298
total_rewards_max            4352.060247963646
total_rewards_min            -14.334154390531499
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               29.98587130662054
(Previous) Eval Time (s)     23.334194963797927
Sample Time (s)              18.029814942274243
Epoch Time (s)               71.34988121269271
Total Train Time (s)         32696.735208578873
Epoch                        473
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:20:29.614774 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #473 | Epoch Duration: 61.48091435432434
2020-01-11 12:20:29.615059 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.07922
Z variance train             0.0062663564
KL Divergence                24.574251
KL Loss                      2.457425
QF Loss                      834.84314
VF Loss                      196.17236
Policy Loss                  -1431.8372
Q Predictions Mean           1436.3203
Q Predictions Std            223.99417
Q Predictions Max            1666.2186
Q Predictions Min            44.85973
V Predictions Mean           1428.5935
V Predictions Std            224.23154
V Predictions Max            1662.5797
V Predictions Min            35.210777
Log Pis Mean                 1.12853
Log Pis Std                  2.94518
Log Pis Max                  14.468722
Log Pis Min                  -7.106678
Policy mu Mean               -0.022606475
Policy mu Std                0.6830027
Policy mu Max                2.6785862
Policy mu Min                -2.8962379
Policy log std Mean          -1.1076785
Policy log std Std           0.2751623
Policy log std Max           -0.048196793
Policy log std Min           -2.1653903
Z mean eval                  1.084914
Z variance eval              0.006871774
total_rewards                [4036.98362279 4378.6759957  1964.39033607 4341.64114181 4376.54018016
 4041.30437059 4187.37502703 4035.34311135 1394.2246522  4372.20241276]
total_rewards_mean           3712.8680850460623
total_rewards_std            1033.885303102672
total_rewards_max            4378.6759956964115
total_rewards_min            1394.2246522013138
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               27.82839407166466
(Previous) Eval Time (s)     13.464919872116297
Sample Time (s)              17.444556607864797
Epoch Time (s)               58.737870551645756
Total Train Time (s)         32765.40212785825
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:21:38.288003 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #474 | Epoch Duration: 68.6727294921875
2020-01-11 12:21:38.288224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0839814
Z variance train             0.0068804086
KL Divergence                24.537899
KL Loss                      2.45379
QF Loss                      1630.2544
VF Loss                      278.75952
Policy Loss                  -1383.0516
Q Predictions Mean           1383.9409
Q Predictions Std            319.8455
Q Predictions Max            1674.2039
Q Predictions Min            -125.07517
V Predictions Mean           1384.9675
V Predictions Std            321.86948
V Predictions Max            1628.9636
V Predictions Min            -135.31985
Log Pis Mean                 0.9380474
Log Pis Std                  2.723691
Log Pis Max                  9.721958
Log Pis Min                  -9.035697
Policy mu Mean               0.07468772
Policy mu Std                0.62889
Policy mu Max                2.3404891
Policy mu Min                -2.4559824
Policy log std Mean          -1.0963851
Policy log std Std           0.3094518
Policy log std Max           -0.07606411
Policy log std Min           -2.706281
Z mean eval                  1.0794997
Z variance eval              0.009628082
total_rewards                [3979.12946503  241.27111198 3870.87085372  749.99239273 3934.88161718
 1967.74010593  287.43015623   41.3794019  3818.75980827 2451.30661386]
total_rewards_mean           2134.2761526814634
total_rewards_std            1609.9043216573646
total_rewards_max            3979.129465031735
total_rewards_min            41.37940189538802
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               30.52596286404878
(Previous) Eval Time (s)     23.399510846938938
Sample Time (s)              17.429665431380272
Epoch Time (s)               71.35513914236799
Total Train Time (s)         32829.612401483115
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:42.503176 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #475 | Epoch Duration: 64.21478009223938
2020-01-11 12:22:42.503385 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0789487
Z variance train             0.009589122
KL Divergence                24.436247
KL Loss                      2.4436247
QF Loss                      1333.7153
VF Loss                      244.91658
Policy Loss                  -1421.0304
Q Predictions Mean           1418.3175
Q Predictions Std            253.29588
Q Predictions Max            1643.2885
Q Predictions Min            -20.775532
V Predictions Mean           1418.3901
V Predictions Std            246.78317
V Predictions Max            1660.6302
V Predictions Min            1.9139247
Log Pis Mean                 1.1480381
Log Pis Std                  3.1793215
Log Pis Max                  13.725923
Log Pis Min                  -9.1830845
Policy mu Mean               -0.015262523
Policy mu Std                0.6303736
Policy mu Max                2.2759383
Policy mu Min                -2.990157
Policy log std Mean          -1.1508043
Policy log std Std           0.3012473
Policy log std Max           -0.15286559
Policy log std Min           -2.7816942
Z mean eval                  1.1496024
Z variance eval              0.013229905
total_rewards                [4173.51897171 1363.83310375 4036.68061907 4211.87304642 3189.69448682
 4204.98406354 4056.26855729 4330.65684077 4439.79089765  889.76442481]
total_rewards_mean           3489.7065011829136
total_rewards_std            1228.8132811546543
total_rewards_max            4439.790897654392
total_rewards_min            889.7644248062667
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               27.56529990117997
(Previous) Eval Time (s)     16.258848522324115
Sample Time (s)              17.856268452014774
Epoch Time (s)               61.68041687551886
Total Train Time (s)         32897.31525086751
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:23:50.212056 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #476 | Epoch Duration: 67.70847487449646
2020-01-11 12:23:50.212357 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1508048
Z variance train             0.013265036
KL Divergence                24.324512
KL Loss                      2.4324512
QF Loss                      822.241
VF Loss                      117.71231
Policy Loss                  -1459.4988
Q Predictions Mean           1461.0004
Q Predictions Std            218.7905
Q Predictions Max            1659.7662
Q Predictions Min            -116.89032
V Predictions Mean           1462.1172
V Predictions Std            216.87228
V Predictions Max            1658.2021
V Predictions Min            -108.34395
Log Pis Mean                 1.2392881
Log Pis Std                  2.9132156
Log Pis Max                  10.219845
Log Pis Min                  -8.160822
Policy mu Mean               0.012347225
Policy mu Std                0.68416464
Policy mu Max                3.177831
Policy mu Min                -2.3346944
Policy log std Mean          -1.1066234
Policy log std Std           0.2773788
Policy log std Max           0.16197747
Policy log std Min           -2.3120217
Z mean eval                  1.1116714
Z variance eval              0.012577449
total_rewards                [4115.72771805 3828.95292309 4029.15001834 3209.04015285 3915.30353909
 4326.39561144 4206.40831825 3920.08044376 3908.71173747 4026.9987786 ]
total_rewards_mean           3948.6769240928697
total_rewards_std            285.4011607037828
total_rewards_max            4326.395611439242
total_rewards_min            3209.0401528456773
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               30.712526015006006
(Previous) Eval Time (s)     22.286585413850844
Sample Time (s)              18.688925730995834
Epoch Time (s)               71.68803715985268
Total Train Time (s)         32973.2213122542
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:25:06.120738 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #477 | Epoch Duration: 75.90818238258362
2020-01-11 12:25:06.120888 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #477 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1128725
Z variance train             0.012609003
KL Divergence                24.360151
KL Loss                      2.4360151
QF Loss                      1241.4214
VF Loss                      224.9638
Policy Loss                  -1409.1626
Q Predictions Mean           1409.7825
Q Predictions Std            288.14713
Q Predictions Max            1675.7064
Q Predictions Min            11.047518
V Predictions Mean           1418.1345
V Predictions Std            290.35852
V Predictions Max            1673.9481
V Predictions Min            -6.043947
Log Pis Mean                 1.1353197
Log Pis Std                  2.9338226
Log Pis Max                  11.4841175
Log Pis Min                  -6.145811
Policy mu Mean               -0.019807242
Policy mu Std                0.65142304
Policy mu Max                2.9864352
Policy mu Min                -2.6917112
Policy log std Mean          -1.1243145
Policy log std Std           0.29482538
Policy log std Max           -0.22631264
Policy log std Min           -2.497013
Z mean eval                  1.1062957
Z variance eval              0.009483828
total_rewards                [1400.82702722 3745.61032419 3998.65814841 4471.54653392 2821.8789778
 4127.70691648 1537.02979698 4141.6063651   824.50285383 4573.30902711]
total_rewards_mean           3164.267597105081
total_rewards_std            1340.1978898759148
total_rewards_max            4573.309027113695
total_rewards_min            824.5028538281312
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               29.742460242006928
(Previous) Eval Time (s)     26.50644123274833
Sample Time (s)              17.993042377755046
Epoch Time (s)               74.2419438525103
Total Train Time (s)         33044.69520605309
Epoch                        478
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:26:17.602855 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #478 | Epoch Duration: 71.48179078102112
2020-01-11 12:26:17.603202 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1050433
Z variance train             0.00948892
KL Divergence                24.854753
KL Loss                      2.4854753
QF Loss                      1076.3313
VF Loss                      115.37928
Policy Loss                  -1405.6699
Q Predictions Mean           1403.182
Q Predictions Std            267.15106
Q Predictions Max            1655.8904
Q Predictions Min            -208.06055
V Predictions Mean           1408.4819
V Predictions Std            264.27597
V Predictions Max            1641.5068
V Predictions Min            -182.66353
Log Pis Mean                 0.7367197
Log Pis Std                  2.8827596
Log Pis Max                  9.90599
Log Pis Min                  -5.8599024
Policy mu Mean               0.011914157
Policy mu Std                0.6571141
Policy mu Max                2.3907983
Policy mu Min                -2.6837082
Policy log std Mean          -1.073963
Policy log std Std           0.2680504
Policy log std Max           0.07780665
Policy log std Min           -2.1740165
Z mean eval                  1.0685403
Z variance eval              0.010629169
total_rewards                [3485.89571312 3274.165699   3906.42232335 1049.03923185 3830.41143521
 2669.19430084 4160.32495934 3855.14478277 3485.2204062  3773.39007721]
total_rewards_mean           3348.920892889081
total_rewards_std            862.082719575593
total_rewards_max            4160.32495933622
total_rewards_min            1049.0392318546833
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               28.079137197695673
(Previous) Eval Time (s)     23.745963140390813
Sample Time (s)              17.63641756726429
Epoch Time (s)               69.46151790535077
Total Train Time (s)         33114.95933220629
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:27.869406 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #479 | Epoch Duration: 70.26598525047302
2020-01-11 12:27:27.869593 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0677938
Z variance train             0.010576499
KL Divergence                24.388144
KL Loss                      2.4388144
QF Loss                      972.0615
VF Loss                      192.36526
Policy Loss                  -1418.447
Q Predictions Mean           1415.4055
Q Predictions Std            233.56622
Q Predictions Max            1667.1727
Q Predictions Min            -57.843693
V Predictions Mean           1419.1243
V Predictions Std            235.02034
V Predictions Max            1655.2161
V Predictions Min            -88.20698
Log Pis Mean                 1.1001773
Log Pis Std                  2.867877
Log Pis Max                  11.700023
Log Pis Min                  -6.376766
Policy mu Mean               0.034458376
Policy mu Std                0.66107357
Policy mu Max                2.5332642
Policy mu Min                -2.666053
Policy log std Mean          -1.1028746
Policy log std Std           0.2854381
Policy log std Max           -0.15154845
Policy log std Min           -2.719668
Z mean eval                  1.0887096
Z variance eval              0.009955493
total_rewards                [3952.98422281 4258.54074219 3838.44168192 3925.56584543 2987.29068634
 1363.59383103 4246.32701474 4355.13788852 3985.15617094 4198.87347632]
total_rewards_mean           3711.1911560233893
total_rewards_std            864.2556570400235
total_rewards_max            4355.137888516659
total_rewards_min            1363.5938310282218
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               26.49729222524911
(Previous) Eval Time (s)     24.55016425391659
Sample Time (s)              18.52179751638323
Epoch Time (s)               69.56925399554893
Total Train Time (s)         33183.7104790858
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:28:36.625962 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #480 | Epoch Duration: 68.75623035430908
2020-01-11 12:28:36.626174 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0906904
Z variance train             0.00994402
KL Divergence                24.82131
KL Loss                      2.482131
QF Loss                      918.0179
VF Loss                      325.08197
Policy Loss                  -1430.0591
Q Predictions Mean           1432.0486
Q Predictions Std            298.88702
Q Predictions Max            1723.7794
Q Predictions Min            -128.25543
V Predictions Mean           1427.1029
V Predictions Std            301.90524
V Predictions Max            1702.1125
V Predictions Min            -151.81305
Log Pis Mean                 0.98075277
Log Pis Std                  3.2369063
Log Pis Max                  14.876493
Log Pis Min                  -8.694649
Policy mu Mean               0.022764511
Policy mu Std                0.6454744
Policy mu Max                2.3080943
Policy mu Min                -2.5615053
Policy log std Mean          -1.111938
Policy log std Std           0.28748563
Policy log std Max           -0.038089514
Policy log std Min           -2.442233
Z mean eval                  1.1183782
Z variance eval              0.006435649
total_rewards                [3967.2717273   232.09711536 2218.65227782 1705.83174177 3989.11502776
 3940.61545463 4122.54304066 2541.95989803 3927.98251242  912.53106873]
total_rewards_mean           2755.8599864472726
total_rewards_std            1372.5130571989494
total_rewards_max            4122.543040659766
total_rewards_min            232.0971153552623
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               29.513250877149403
(Previous) Eval Time (s)     23.736814276780933
Sample Time (s)              17.767781927715987
Epoch Time (s)               71.01784708164632
Total Train Time (s)         33250.05613788869
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:29:42.975129 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #481 | Epoch Duration: 66.34878993034363
2020-01-11 12:29:42.975323 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1159714
Z variance train             0.0064221127
KL Divergence                25.84747
KL Loss                      2.584747
QF Loss                      1381.8167
VF Loss                      295.0161
Policy Loss                  -1420.1799
Q Predictions Mean           1414.6956
Q Predictions Std            292.15652
Q Predictions Max            1670.9757
Q Predictions Min            -169.88379
V Predictions Mean           1416.9097
V Predictions Std            289.5729
V Predictions Max            1674.6462
V Predictions Min            -158.04213
Log Pis Mean                 0.5237353
Log Pis Std                  2.8366573
Log Pis Max                  14.817944
Log Pis Min                  -6.688136
Policy mu Mean               0.025786873
Policy mu Std                0.6056755
Policy mu Max                3.0814676
Policy mu Min                -2.22463
Policy log std Mean          -1.1188736
Policy log std Std           0.2760667
Policy log std Max           -0.09822428
Policy log std Min           -2.4632158
Z mean eval                  1.079403
Z variance eval              0.006728478
total_rewards                [1253.16718016 3803.2279973  3891.22084116 4073.23819938 4081.26967711
 4069.19775118 4154.48035797 3984.55042903 4257.6930653  4066.49292588]
total_rewards_mean           3763.45384244655
total_rewards_std            845.4459556012571
total_rewards_max            4257.693065296894
total_rewards_min            1253.1671801613886
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               29.0140719152987
(Previous) Eval Time (s)     19.06747209886089
Sample Time (s)              17.578498310409486
Epoch Time (s)               65.66004232456908
Total Train Time (s)         33321.37796348194
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:54.301464 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #482 | Epoch Duration: 71.32595205307007
2020-01-11 12:30:54.301682 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #482 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0802968
Z variance train             0.00670216
KL Divergence                25.40517
KL Loss                      2.540517
QF Loss                      2813.5781
VF Loss                      1438.3256
Policy Loss                  -1417.6515
Q Predictions Mean           1415.8965
Q Predictions Std            290.9385
Q Predictions Max            1711.5287
Q Predictions Min            -153.81549
V Predictions Mean           1398.355
V Predictions Std            273.19012
V Predictions Max            1656.633
V Predictions Min            -166.49287
Log Pis Mean                 1.2458309
Log Pis Std                  3.2003546
Log Pis Max                  12.814249
Log Pis Min                  -8.354951
Policy mu Mean               -0.03333135
Policy mu Std                0.6609124
Policy mu Max                2.1554234
Policy mu Min                -2.4156206
Policy log std Mean          -1.146707
Policy log std Std           0.35953853
Policy log std Max           -0.17787367
Policy log std Min           -3.2823286
Z mean eval                  1.1096561
Z variance eval              0.0136800725
total_rewards                [4208.61218553 4431.06060054 1576.26921526 4293.05063091 4244.65917788
 4050.00092131 4302.26078803 2411.40286012 4204.93994077 4144.06774329]
total_rewards_mean           3786.632406363221
total_rewards_std            920.572709272891
total_rewards_max            4431.06060053904
total_rewards_min            1576.269215259518
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               29.944017190951854
(Previous) Eval Time (s)     24.733140972908586
Sample Time (s)              17.702135547529906
Epoch Time (s)               72.37929371139035
Total Train Time (s)         33393.15673569264
Epoch                        483
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:32:06.084521 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #483 | Epoch Duration: 71.78266310691833
2020-01-11 12:32:06.084728 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1114986
Z variance train             0.013714636
KL Divergence                24.220306
KL Loss                      2.4220307
QF Loss                      1070.4568
VF Loss                      136.07944
Policy Loss                  -1438.1505
Q Predictions Mean           1438.7786
Q Predictions Std            293.5671
Q Predictions Max            1700.5991
Q Predictions Min            -155.04012
V Predictions Mean           1436.6805
V Predictions Std            295.56613
V Predictions Max            1704.8585
V Predictions Min            -173.01903
Log Pis Mean                 1.3341424
Log Pis Std                  2.6952674
Log Pis Max                  14.69828
Log Pis Min                  -6.672661
Policy mu Mean               0.031853974
Policy mu Std                0.6276978
Policy mu Max                2.4473016
Policy mu Min                -2.7921412
Policy log std Mean          -1.1418519
Policy log std Std           0.29366478
Policy log std Max           0.14551288
Policy log std Min           -2.5600498
Z mean eval                  1.1130182
Z variance eval              0.013901807
total_rewards                [ 804.42659323 3698.37576024 3966.2313157  2676.15232867 4311.33977343
 3916.5493089  4010.72357908 4077.72515747 4050.78167442 3971.45598689]
total_rewards_mean           3548.3761478050956
total_rewards_std            1006.4881881596499
total_rewards_max            4311.339773433449
total_rewards_min            804.4265932263553
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               29.412539281416684
(Previous) Eval Time (s)     24.136210462078452
Sample Time (s)              18.298324376810342
Epoch Time (s)               71.84707412030548
Total Train Time (s)         33465.16277015349
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:18.093612 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #484 | Epoch Duration: 72.00874137878418
2020-01-11 12:33:18.093809 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1141336
Z variance train             0.013896952
KL Divergence                24.535488
KL Loss                      2.453549
QF Loss                      9894.779
VF Loss                      166.90085
Policy Loss                  -1451.0151
Q Predictions Mean           1453.1466
Q Predictions Std            250.41092
Q Predictions Max            1703.9873
Q Predictions Min            -180.56985
V Predictions Mean           1447.6934
V Predictions Std            250.88667
V Predictions Max            1692.9551
V Predictions Min            -175.05003
Log Pis Mean                 1.3931208
Log Pis Std                  2.9386153
Log Pis Max                  14.040864
Log Pis Min                  -6.602315
Policy mu Mean               0.0574959
Policy mu Std                0.6947905
Policy mu Max                2.3787134
Policy mu Min                -2.5253036
Policy log std Mean          -1.0898321
Policy log std Std           0.30377394
Policy log std Max           -0.16034645
Policy log std Min           -2.7859464
Z mean eval                  1.1217114
Z variance eval              0.019466426
total_rewards                [ 752.25997715 3052.03078411 3203.27234122 4068.50575324 4035.00323429
 4403.20824488 4065.2804806  4103.76352232 4177.46387756 4112.97915655]
total_rewards_mean           3597.376737190396
total_rewards_std            1033.8260112682842
total_rewards_max            4403.208244876254
total_rewards_min            752.2599771494521
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               28.116910104174167
(Previous) Eval Time (s)     24.297570921014994
Sample Time (s)              19.283392790239304
Epoch Time (s)               71.69787381542847
Total Train Time (s)         33537.77947558276
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:34:30.717950 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #485 | Epoch Duration: 72.6239881515503
2020-01-11 12:34:30.718212 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1232127
Z variance train             0.019407276
KL Divergence                24.202202
KL Loss                      2.4202201
QF Loss                      1057.0497
VF Loss                      1158.6919
Policy Loss                  -1442.7122
Q Predictions Mean           1444.6566
Q Predictions Std            271.02686
Q Predictions Max            1742.3962
Q Predictions Min            -21.08833
V Predictions Mean           1441.086
V Predictions Std            255.48106
V Predictions Max            1721.53
V Predictions Min            -19.55438
Log Pis Mean                 0.9875421
Log Pis Std                  2.7649982
Log Pis Max                  12.350023
Log Pis Min                  -7.6221585
Policy mu Mean               0.012127451
Policy mu Std                0.6590996
Policy mu Max                2.3858285
Policy mu Min                -3.2104974
Policy log std Mean          -1.1245768
Policy log std Std           0.2853122
Policy log std Max           -0.24342048
Policy log std Min           -2.7419662
Z mean eval                  1.0946577
Z variance eval              0.012501514
total_rewards                [ 468.41699052  551.30603803 2643.49362351  962.98602885  677.01526646
 1257.85670175 2210.447277   1489.61637202 3505.17072883 1771.22048668]
total_rewards_mean           1553.7529513651182
total_rewards_std            941.610440637622
total_rewards_max            3505.170728831945
total_rewards_min            468.4169905175479
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               27.835128653794527
(Previous) Eval Time (s)     25.22331763105467
Sample Time (s)              17.977629062253982
Epoch Time (s)               71.03607534710318
Total Train Time (s)         33596.844768245704
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:35:29.786950 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #486 | Epoch Duration: 59.0685510635376
2020-01-11 12:35:29.787146 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0957366
Z variance train             0.012535
KL Divergence                24.916382
KL Loss                      2.4916382
QF Loss                      1325.5261
VF Loss                      320.01367
Policy Loss                  -1475.995
Q Predictions Mean           1482.0227
Q Predictions Std            167.689
Q Predictions Max            1688.6356
Q Predictions Min            -169.15152
V Predictions Mean           1481.2493
V Predictions Std            175.56625
V Predictions Max            1685.2562
V Predictions Min            -166.69162
Log Pis Mean                 1.3240993
Log Pis Std                  2.8655946
Log Pis Max                  12.349484
Log Pis Min                  -6.5922737
Policy mu Mean               0.016073518
Policy mu Std                0.64880073
Policy mu Max                2.7262232
Policy mu Min                -2.6846528
Policy log std Mean          -1.1191411
Policy log std Std           0.28709942
Policy log std Max           0.27409816
Policy log std Min           -3.0673928
Z mean eval                  1.1053767
Z variance eval              0.015446566
total_rewards                [-436.81462456 4260.32247499 4323.3137648  4497.01216327 1908.13887629
 4014.89118184 4239.99227476 4337.05721173 4218.48223976 4263.61464065]
total_rewards_mean           3562.601020353777
total_rewards_std            1511.8201527505094
total_rewards_max            4497.012163272899
total_rewards_min            -436.8146245589408
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               28.442349520977587
(Previous) Eval Time (s)     13.255476486869156
Sample Time (s)              17.37741124536842
Epoch Time (s)               59.075237253215164
Total Train Time (s)         33669.69417888485
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:36:42.640609 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #487 | Epoch Duration: 72.85332560539246
2020-01-11 12:36:42.640814 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1057508
Z variance train             0.015409015
KL Divergence                25.02864
KL Loss                      2.5028641
QF Loss                      1248.1443
VF Loss                      198.30652
Policy Loss                  -1459.2079
Q Predictions Mean           1460.3378
Q Predictions Std            259.83926
Q Predictions Max            1700.3923
Q Predictions Min            -91.866936
V Predictions Mean           1453.0314
V Predictions Std            259.41376
V Predictions Max            1682.3307
V Predictions Min            -100.61279
Log Pis Mean                 1.2841518
Log Pis Std                  2.837566
Log Pis Max                  12.6067505
Log Pis Min                  -9.545532
Policy mu Mean               0.020438377
Policy mu Std                0.60606855
Policy mu Max                2.7399116
Policy mu Min                -2.488078
Policy log std Mean          -1.1790707
Policy log std Std           0.2722815
Policy log std Max           -0.18491024
Policy log std Min           -2.4086657
Z mean eval                  1.1055573
Z variance eval              0.017757269
total_rewards                [3312.25679373 3906.79504927 4124.09105875 3937.01149705 3919.46774582
 4178.0131431  4366.89242756  662.48185541 4420.95131881 4305.04732166]
total_rewards_mean           3713.3008211160327
total_rewards_std            1061.185434052765
total_rewards_max            4420.951318811538
total_rewards_min            662.4818554089431
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               28.901309906039387
(Previous) Eval Time (s)     27.033226512372494
Sample Time (s)              18.370590719394386
Epoch Time (s)               74.30512713780627
Total Train Time (s)         33741.66654687701
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:37:54.617027 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #488 | Epoch Duration: 71.97605276107788
2020-01-11 12:37:54.617224 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1040742
Z variance train             0.017813776
KL Divergence                24.577076
KL Loss                      2.4577076
QF Loss                      2269.0188
VF Loss                      4164.1904
Policy Loss                  -1431.8256
Q Predictions Mean           1438.1992
Q Predictions Std            254.82487
Q Predictions Max            1670.6847
Q Predictions Min            -81.22055
V Predictions Mean           1441.9033
V Predictions Std            248.83348
V Predictions Max            1679.3672
V Predictions Min            -97.64046
Log Pis Mean                 1.3888221
Log Pis Std                  2.7849426
Log Pis Max                  13.410122
Log Pis Min                  -5.0145836
Policy mu Mean               -0.017878374
Policy mu Std                0.62945235
Policy mu Max                2.4925718
Policy mu Min                -2.9662433
Policy log std Mean          -1.1650801
Policy log std Std           0.31618568
Policy log std Max           -0.24219388
Policy log std Min           -3.014251
Z mean eval                  1.1133326
Z variance eval              0.010957731
total_rewards                [3276.27806276 4415.43609024 4127.65900312 3984.71721426 4141.03714755
 4229.6033337  4171.19069618 4246.98679689 4183.32067589 4203.66186459]
total_rewards_mean           4097.9890885180785
total_rewards_std            292.38243498463066
total_rewards_max            4415.436090240758
total_rewards_min            3276.278062760594
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               27.05145596107468
(Previous) Eval Time (s)     24.703821287024766
Sample Time (s)              18.60927166696638
Epoch Time (s)               70.36454891506582
Total Train Time (s)         33813.634041879326
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:39:06.591093 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #489 | Epoch Duration: 71.97371006011963
2020-01-11 12:39:06.591374 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #489 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1150217
Z variance train             0.010946744
KL Divergence                25.305567
KL Loss                      2.5305567
QF Loss                      1280.8934
VF Loss                      311.98245
Policy Loss                  -1435.8699
Q Predictions Mean           1439.2888
Q Predictions Std            282.64246
Q Predictions Max            1689.3673
Q Predictions Min            -145.71794
V Predictions Mean           1443.7751
V Predictions Std            280.8516
V Predictions Max            1691.7933
V Predictions Min            -158.51271
Log Pis Mean                 1.3685973
Log Pis Std                  3.478603
Log Pis Max                  14.360147
Log Pis Min                  -6.961455
Policy mu Mean               0.0039899885
Policy mu Std                0.679891
Policy mu Max                3.7421637
Policy mu Min                -2.9594142
Policy log std Mean          -1.133788
Policy log std Std           0.32833862
Policy log std Max           -0.15967977
Policy log std Min           -3.6450353
Z mean eval                  1.0661113
Z variance eval              0.015726838
total_rewards                [  59.48381614  183.24519295  324.38468251 4174.23465273 1408.36302088
 1573.48193138 4400.15258745 4415.43008036 4352.29920341 2177.2537547 ]
total_rewards_mean           2306.832892251047
total_rewards_std            1770.633705721388
total_rewards_max            4415.430080355292
total_rewards_min            59.48381614172621
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               27.687461069319397
(Previous) Eval Time (s)     26.312673488166183
Sample Time (s)              17.78615897987038
Epoch Time (s)               71.78629353735596
Total Train Time (s)         33873.713576219976
Epoch                        490
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:40:06.675408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #490 | Epoch Duration: 60.08383131027222
2020-01-11 12:40:06.675624 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0609003
Z variance train             0.0156971
KL Divergence                24.842596
KL Loss                      2.4842596
QF Loss                      5029.1987
VF Loss                      327.20206
Policy Loss                  -1442.7211
Q Predictions Mean           1441.009
Q Predictions Std            291.07266
Q Predictions Max            1739.5938
Q Predictions Min            -178.76244
V Predictions Mean           1433.8422
V Predictions Std            278.7975
V Predictions Max            1723.3503
V Predictions Min            -181.58476
Log Pis Mean                 1.0694364
Log Pis Std                  3.1314178
Log Pis Max                  10.334375
Log Pis Min                  -9.830943
Policy mu Mean               0.008243624
Policy mu Std                0.68818647
Policy mu Max                2.3631663
Policy mu Min                -2.524964
Policy log std Mean          -1.0911014
Policy log std Std           0.30494276
Policy log std Max           -0.14406204
Policy log std Min           -2.9145875
Z mean eval                  1.0869224
Z variance eval              0.015996803
total_rewards                [-256.43604516 4089.31431488 4287.74213106 4240.48141303 1882.95631387
 4080.28949846 4319.16449125 4356.67586645 4122.61355438 3878.96195623]
total_rewards_mean           3500.1763494450083
total_rewards_std            1432.29547200609
total_rewards_max            4356.675866453765
total_rewards_min            -256.4360451555361
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               29.393980970606208
(Previous) Eval Time (s)     14.609940426889807
Sample Time (s)              18.542811776977032
Epoch Time (s)               62.54673317447305
Total Train Time (s)         33947.05913821235
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:20.027274 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #491 | Epoch Duration: 73.35148310661316
2020-01-11 12:41:20.027486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0855248
Z variance train             0.015994256
KL Divergence                24.639996
KL Loss                      2.4639995
QF Loss                      3696.1345
VF Loss                      602.2471
Policy Loss                  -1448.6556
Q Predictions Mean           1454.0519
Q Predictions Std            221.72644
Q Predictions Max            1714.1698
Q Predictions Min            -110.86534
V Predictions Mean           1457.3813
V Predictions Std            223.85513
V Predictions Max            1725.4843
V Predictions Min            -102.958984
Log Pis Mean                 1.3229294
Log Pis Std                  3.1352637
Log Pis Max                  16.007627
Log Pis Min                  -8.317493
Policy mu Mean               -0.011960284
Policy mu Std                0.6413033
Policy mu Max                2.6377783
Policy mu Min                -2.7738397
Policy log std Mean          -1.1644664
Policy log std Std           0.3044484
Policy log std Max           -0.20914733
Policy log std Min           -3.2473183
Z mean eval                  1.1286333
Z variance eval              0.014574741
total_rewards                [2920.06344242 2149.39719477  257.92974434  909.90350657 1765.96472982
 4176.26377767 4301.55240915 4112.05871818 4323.3074955  3509.83268175]
total_rewards_mean           2842.6273700170573
total_rewards_std            1421.8977128428157
total_rewards_max            4323.307495504567
total_rewards_min            257.92974433506186
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               30.095478967297822
(Previous) Eval Time (s)     25.41437919717282
Sample Time (s)              18.45961653534323
Epoch Time (s)               73.96947469981387
Total Train Time (s)         34014.689897655975
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:42:27.662353 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #492 | Epoch Duration: 67.63468885421753
2020-01-11 12:42:27.662573 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #492 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1323432
Z variance train             0.01460751
KL Divergence                24.074871
KL Loss                      2.4074872
QF Loss                      1165.4233
VF Loss                      812.247
Policy Loss                  -1430.3955
Q Predictions Mean           1440.1211
Q Predictions Std            277.05148
Q Predictions Max            1696.2183
Q Predictions Min            -102.284035
V Predictions Mean           1452.9312
V Predictions Std            278.64417
V Predictions Max            1716.7242
V Predictions Min            -120.56452
Log Pis Mean                 1.7050464
Log Pis Std                  3.3117464
Log Pis Max                  11.06378
Log Pis Min                  -7.005249
Policy mu Mean               0.03083559
Policy mu Std                0.6853119
Policy mu Max                2.9885352
Policy mu Min                -2.6564445
Policy log std Mean          -1.1327145
Policy log std Std           0.3026009
Policy log std Max           -0.07936418
Policy log std Min           -2.8049047
Z mean eval                  1.1144571
Z variance eval              0.015373772
total_rewards                [  66.96758692 1446.21327899 4248.66114199 3999.10949942 4062.94347384
 4023.49663504 4000.46035233 4002.71364806  388.93667657  113.55727902]
total_rewards_mean           2635.3059572172233
total_rewards_std            1776.9986586680286
total_rewards_max            4248.661141987236
total_rewards_min            66.96758691736474
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               27.271153992041945
(Previous) Eval Time (s)     19.079284687992185
Sample Time (s)              18.135179007425904
Epoch Time (s)               64.48561768746004
Total Train Time (s)         34079.70595659455
Epoch                        493
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:43:32.685250 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #493 | Epoch Duration: 65.02249455451965
2020-01-11 12:43:32.685515 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #493 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1146961
Z variance train             0.015422797
KL Divergence                24.466633
KL Loss                      2.4466634
QF Loss                      1573.8463
VF Loss                      181.706
Policy Loss                  -1474.2594
Q Predictions Mean           1474.5181
Q Predictions Std            233.91371
Q Predictions Max            1711.9348
Q Predictions Min            -180.26508
V Predictions Mean           1469.099
V Predictions Std            232.29979
V Predictions Max            1692.1642
V Predictions Min            -187.54819
Log Pis Mean                 1.2872167
Log Pis Std                  2.8596714
Log Pis Max                  11.122182
Log Pis Min                  -11.739807
Policy mu Mean               -0.029856797
Policy mu Std                0.6813471
Policy mu Max                2.6876042
Policy mu Min                -2.6091104
Policy log std Mean          -1.1216154
Policy log std Std           0.27951136
Policy log std Max           -0.26656306
Policy log std Min           -2.753796
Z mean eval                  1.096267
Z variance eval              0.016136786
total_rewards                [4125.72144555 1982.6727573  4118.10715584 3597.41102199 4393.4622796
 3933.73895036 4278.50291422 2647.78562585  857.56330223 3848.7106521 ]
total_rewards_mean           3378.367610505783
total_rewards_std            1111.7653322578353
total_rewards_max            4393.462279599347
total_rewards_min            857.5633022335265
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               29.08241142798215
(Previous) Eval Time (s)     19.615814849734306
Sample Time (s)              18.28069697925821
Epoch Time (s)               66.97892325697467
Total Train Time (s)         34150.35591925867
Epoch                        494
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:43.338808 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #494 | Epoch Duration: 70.65308833122253
2020-01-11 12:44:43.338989 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0953944
Z variance train             0.01613817
KL Divergence                23.657768
KL Loss                      2.3657768
QF Loss                      4141.289
VF Loss                      306.1309
Policy Loss                  -1449.1353
Q Predictions Mean           1449.2781
Q Predictions Std            279.42792
Q Predictions Max            1717.3751
Q Predictions Min            -148.0887
V Predictions Mean           1453.9048
V Predictions Std            271.47906
V Predictions Max            1714.1295
V Predictions Min            -160.08961
Log Pis Mean                 1.3426652
Log Pis Std                  3.104988
Log Pis Max                  15.601167
Log Pis Min                  -6.5120053
Policy mu Mean               0.031179521
Policy mu Std                0.6874385
Policy mu Max                2.526304
Policy mu Min                -2.5346053
Policy log std Mean          -1.1232705
Policy log std Std           0.32412195
Policy log std Max           -0.0070174932
Policy log std Min           -3.4105883
Z mean eval                  1.1064596
Z variance eval              0.013880497
total_rewards                [1639.86458838 3754.71821429  705.72784727 4357.77981184  377.58213034
 3998.62679941  452.91382553 1993.88618653 2822.78415352  756.1319642 ]
total_rewards_mean           2086.001552131019
total_rewards_std            1470.1523796485696
total_rewards_max            4357.77981183523
total_rewards_min            377.58213033579636
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               29.31776504823938
(Previous) Eval Time (s)     23.28965786099434
Sample Time (s)              17.360641956329346
Epoch Time (s)               69.96806486556306
Total Train Time (s)         34212.23774310341
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:45:45.223632 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #495 | Epoch Duration: 61.88451814651489
2020-01-11 12:45:45.223825 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1032937
Z variance train             0.013884759
KL Divergence                23.264475
KL Loss                      2.3264475
QF Loss                      681.54034
VF Loss                      298.12137
Policy Loss                  -1452.1669
Q Predictions Mean           1454.565
Q Predictions Std            306.93744
Q Predictions Max            1758.0676
Q Predictions Min            -156.40187
V Predictions Mean           1458.2385
V Predictions Std            310.82037
V Predictions Max            1757.5481
V Predictions Min            -177.04648
Log Pis Mean                 0.8984075
Log Pis Std                  3.0739744
Log Pis Max                  22.380634
Log Pis Min                  -9.804909
Policy mu Mean               0.01914366
Policy mu Std                0.62419915
Policy mu Max                3.7415545
Policy mu Min                -3.6855998
Policy log std Mean          -1.1202481
Policy log std Std           0.27146268
Policy log std Max           -0.015740514
Policy log std Min           -2.374764
Z mean eval                  1.0825357
Z variance eval              0.011485802
total_rewards                [4202.5817434  3982.82571725 4318.47184146 4232.70817713 2992.67371408
  496.62525447 4360.73221024 4278.57960162 3830.72028499 4278.47607175]
total_rewards_mean           3697.439461639099
total_rewards_std            1135.066634819487
total_rewards_max            4360.732210244198
total_rewards_min            496.6252544738023
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               28.453459286130965
(Previous) Eval Time (s)     15.205836148001254
Sample Time (s)              17.568538256455213
Epoch Time (s)               61.22783369058743
Total Train Time (s)         34282.396210735664
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:46:55.387880 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #496 | Epoch Duration: 70.16389036178589
2020-01-11 12:46:55.388096 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0818151
Z variance train             0.011491814
KL Divergence                23.42836
KL Loss                      2.3428361
QF Loss                      961.81274
VF Loss                      294.57678
Policy Loss                  -1448.4924
Q Predictions Mean           1449.841
Q Predictions Std            314.95374
Q Predictions Max            1700.3704
Q Predictions Min            -186.17683
V Predictions Mean           1437.8342
V Predictions Std            311.00812
V Predictions Max            1688.1814
V Predictions Min            -183.1864
Log Pis Mean                 1.1721553
Log Pis Std                  2.876304
Log Pis Max                  12.098468
Log Pis Min                  -6.491576
Policy mu Mean               -0.015779713
Policy mu Std                0.6615643
Policy mu Max                2.3823256
Policy mu Min                -2.928328
Policy log std Mean          -1.1262548
Policy log std Std           0.3084362
Policy log std Max           0.18565094
Policy log std Min           -2.9071143
Z mean eval                  1.0732399
Z variance eval              0.0135027915
total_rewards                [2021.50367744 3687.86773493 4442.33245658 3935.32984139 1546.24478928
 1203.02544088 4269.40423461 4061.50701354 4284.51274715 3962.10072086]
total_rewards_mean           3341.382865666129
total_rewards_std            1177.9930439507443
total_rewards_max            4442.332456580016
total_rewards_min            1203.0254408822818
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               30.265296548139304
(Previous) Eval Time (s)     24.141571772750467
Sample Time (s)              18.53913795016706
Epoch Time (s)               72.94600627105683
Total Train Time (s)         34353.31686219899
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:48:06.316140 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #497 | Epoch Duration: 70.9278495311737
2020-01-11 12:48:06.316447 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0737077
Z variance train             0.013550131
KL Divergence                23.210188
KL Loss                      2.321019
QF Loss                      3396.574
VF Loss                      344.02045
Policy Loss                  -1480.9948
Q Predictions Mean           1476.8563
Q Predictions Std            236.56741
Q Predictions Max            1717.7396
Q Predictions Min            -57.84755
V Predictions Mean           1488.6455
V Predictions Std            236.4618
V Predictions Max            1721.7397
V Predictions Min            -50.752785
Log Pis Mean                 1.1311063
Log Pis Std                  2.691512
Log Pis Max                  13.751603
Log Pis Min                  -6.0352316
Policy mu Mean               0.04538966
Policy mu Std                0.6391178
Policy mu Max                2.471516
Policy mu Min                -2.1431699
Policy log std Mean          -1.1173544
Policy log std Std           0.27723876
Policy log std Max           -0.07681805
Policy log std Min           -2.582728
Z mean eval                  1.1090715
Z variance eval              0.0136579005
total_rewards                [4120.36526797  338.2086358    51.565036   4442.38049794 4286.84924655
 4355.77260933 4023.5185045  2013.08553919 1443.520258   2897.08960279]
total_rewards_mean           2797.2355198082305
total_rewards_std            1632.5396737708086
total_rewards_max            4442.380497939565
total_rewards_min            51.565036004265295
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               28.477032056078315
(Previous) Eval Time (s)     22.123059257864952
Sample Time (s)              18.409235399216413
Epoch Time (s)               69.00932671315968
Total Train Time (s)         34417.90384353185
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:49:10.906408 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #498 | Epoch Duration: 64.58974361419678
2020-01-11 12:49:10.906605 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1098732
Z variance train             0.013690946
KL Divergence                23.417347
KL Loss                      2.3417346
QF Loss                      1243.1134
VF Loss                      443.50027
Policy Loss                  -1442.0519
Q Predictions Mean           1444.4299
Q Predictions Std            312.15576
Q Predictions Max            1702.4149
Q Predictions Min            -173.77846
V Predictions Mean           1444.3555
V Predictions Std            312.5458
V Predictions Max            1687.3232
V Predictions Min            -152.64632
Log Pis Mean                 1.1355234
Log Pis Std                  3.0862954
Log Pis Max                  19.582691
Log Pis Min                  -5.8629146
Policy mu Mean               0.030488227
Policy mu Std                0.677351
Policy mu Max                2.688716
Policy mu Min                -3.8824525
Policy log std Mean          -1.1297982
Policy log std Std           0.29843125
Policy log std Max           0.03255385
Policy log std Min           -2.3824143
Z mean eval                  1.0654815
Z variance eval              0.015748149
total_rewards                [4031.39987836 4172.4372509  4184.69555434 1718.77408503 4360.29541029
 4007.55896226 4263.67121723 4603.97948086  273.0495862  4243.55285882]
total_rewards_mean           3585.941428429932
total_rewards_std            1344.1741219233897
total_rewards_max            4603.9794808550105
total_rewards_min            273.0495862022335
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               30.99252194399014
(Previous) Eval Time (s)     17.70316989487037
Sample Time (s)              18.501530637033284
Epoch Time (s)               67.1972224758938
Total Train Time (s)         34492.88838833338
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:50:25.898525 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #499 | Epoch Duration: 74.99175214767456
2020-01-11 12:50:25.898810 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Iteration #499 | Started Training: True
2020-01-11 12:50:26.519091 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] Variant:
2020-01-11 12:50:26.519463 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] {
  "env_name": "Hopper-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20",
    "use_gpu": true,
    "gpu_id": 0,
    "debug": false,
    "docker": false,
    "num_iterations": 1000
  }
}
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0019376408
Z variance train             0.693145
KL Divergence                0.14916778
KL Loss                      0.014916778
QF Loss                      70.34567
VF Loss                      4.4341574
Policy Loss                  -2.079393
Q Predictions Mean           -0.0023045375
Q Predictions Std            0.0010986081
Q Predictions Max            0.0017850115
Q Predictions Min            -0.0054990025
V Predictions Mean           0.00880776
V Predictions Std            0.0014018345
V Predictions Max            0.013202997
V Predictions Min            0.0060151126
Log Pis Mean                 -2.0737145
Log Pis Std                  0.3831366
Log Pis Max                  -0.82241416
Log Pis Min                  -3.171927
Policy mu Mean               3.8408183e-05
Policy mu Std                0.0009007452
Policy mu Max                0.001969648
Policy mu Min                -0.00234535
Policy log std Mean          -0.0005568333
Policy log std Std           0.0011438006
Policy log std Max           0.001831908
Policy log std Min           -0.0030535706
Z mean eval                  0.005756306
Z variance eval              0.674224
total_rewards                [ 61.38693623 113.01327395 116.02390092  78.44867491  73.2734333
 150.57021339  74.81610569  67.92799259 137.92069701  73.75640018]
total_rewards_mean           94.71376281701069
total_rewards_std            30.270942841517652
total_rewards_max            150.5702133908658
total_rewards_min            61.38693623112616
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               23.39730157610029
(Previous) Eval Time (s)     0
Sample Time (s)              15.17737470054999
Epoch Time (s)               38.57467627665028
Total Train Time (s)         39.968701692763716
Epoch                        0
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:06.575276 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #0 | Epoch Duration: 39.97466492652893
2020-01-11 12:51:06.575542 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #0 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0069435285
Z variance train             0.67628586
KL Divergence                0.16881907
KL Loss                      0.016881907
QF Loss                      85.0119
VF Loss                      1.4627635
Policy Loss                  -10.905362
Q Predictions Mean           10.007549
Q Predictions Std            8.671779
Q Predictions Max            34.86257
Q Predictions Min            -6.73171
V Predictions Mean           11.5984535
V Predictions Std            8.22942
V Predictions Max            35.272766
V Predictions Min            -3.3859167
Log Pis Mean                 -1.920514
Log Pis Std                  0.50672823
Log Pis Max                  -0.3085872
Log Pis Min                  -3.628249
Policy mu Mean               0.117926694
Policy mu Std                0.2027278
Policy mu Max                0.4952334
Policy mu Min                -0.24866314
Policy log std Mean          -0.16378818
Policy log std Std           0.025983334
Policy log std Max           -0.101779826
Policy log std Min           -0.23183076
Z mean eval                  0.092427224
Z variance eval              0.22269996
total_rewards                [ 88.31661483 160.34940943 199.30750984  95.68465525 175.6756274
 112.24698586 136.9068843   55.84862928  52.47216383  77.45470909]
total_rewards_mean           115.42631891163653
total_rewards_std            48.202572036849375
total_rewards_max            199.30750984122517
total_rewards_min            52.47216383346039
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               25.518305903766304
(Previous) Eval Time (s)     1.3997573098167777
Sample Time (s)              11.710441849660128
Epoch Time (s)               38.62850506324321
Total Train Time (s)         78.6954736080952
Epoch                        1
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:45.304851 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #1 | Epoch Duration: 38.72908687591553
2020-01-11 12:51:45.305136 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0934286
Z variance train             0.22231428
KL Divergence                1.8811272
KL Loss                      0.18811272
QF Loss                      36.145943
VF Loss                      3.5269725
Policy Loss                  -17.406351
Q Predictions Mean           15.449587
Q Predictions Std            16.395124
Q Predictions Max            67.51149
Q Predictions Min            -5.86962
V Predictions Mean           18.184551
V Predictions Std            16.13917
V Predictions Max            68.73525
V Predictions Min            -1.3462957
Log Pis Mean                 -1.8057686
Log Pis Std                  0.76702154
Log Pis Max                  1.3376659
Log Pis Min                  -3.7438653
Policy mu Mean               0.12421521
Policy mu Std                0.31657064
Policy mu Max                1.3321635
Policy mu Min                -0.33710226
Policy log std Mean          -0.1883903
Policy log std Std           0.10197929
Policy log std Max           -0.09061712
Policy log std Min           -0.5328781
Z mean eval                  0.060991425
Z variance eval              0.08260755
total_rewards                [198.45948536 203.83292039 187.31556748 197.42140996 187.39513631
 197.72362659 189.36371706 189.8156448  210.07286065 192.93700859]
total_rewards_mean           195.43373771996409
total_rewards_std            7.129974377300457
total_rewards_max            210.0728606465592
total_rewards_min            187.31556748001643
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               25.6551773683168
(Previous) Eval Time (s)     1.500083340331912
Sample Time (s)              11.460345430765301
Epoch Time (s)               38.61560613941401
Total Train Time (s)         117.88746403809637
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:24.495236 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #2 | Epoch Duration: 39.18991160392761
2020-01-11 12:52:24.495435 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06522969
Z variance train             0.07827815
KL Divergence                4.0949674
KL Loss                      0.40949675
QF Loss                      41.060658
VF Loss                      30.66106
Policy Loss                  -24.804773
Q Predictions Mean           22.588032
Q Predictions Std            28.951641
Q Predictions Max            106.101166
Q Predictions Min            -2.1414497
V Predictions Mean           26.636106
V Predictions Std            32.089897
V Predictions Max            126.92295
V Predictions Min            -0.38471577
Log Pis Mean                 -1.7094694
Log Pis Std                  0.88051796
Log Pis Max                  2.426793
Log Pis Min                  -3.8710275
Policy mu Mean               0.021276304
Policy mu Std                0.36924258
Policy mu Max                1.6513544
Policy mu Min                -1.6084194
Policy log std Mean          -0.21116179
Policy log std Std           0.13883194
Policy log std Max           -0.0946959
Policy log std Min           -0.5879069
Z mean eval                  0.032008044
Z variance eval              0.03112787
total_rewards                [180.78277111 189.04334453 204.47166565 188.49249267 192.99342232
 188.41003375 200.60154835 190.37501448 197.51156167 195.99486851]
total_rewards_mean           192.86767230346985
total_rewards_std            6.570561461927455
total_rewards_max            204.4716656525169
total_rewards_min            180.78277110732273
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               27.21719363378361
(Previous) Eval Time (s)     2.0741261886432767
Sample Time (s)              12.083760148379952
Epoch Time (s)               41.37507997080684
Total Train Time (s)         159.18084556423128
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:53:05.788779 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #3 | Epoch Duration: 41.293190479278564
2020-01-11 12:53:05.788970 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030359143
Z variance train             0.030940836
KL Divergence                6.3432026
KL Loss                      0.63432026
QF Loss                      30.265991
VF Loss                      9.992334
Policy Loss                  -42.422386
Q Predictions Mean           40.724205
Q Predictions Std            53.15372
Q Predictions Max            156.76782
Q Predictions Min            -4.8803844
V Predictions Mean           42.86013
V Predictions Std            53.4645
V Predictions Max            155.05243
V Predictions Min            -3.3447578
Log Pis Mean                 -1.4440154
Log Pis Std                  1.2674633
Log Pis Max                  4.5372353
Log Pis Min                  -3.9453616
Policy mu Mean               0.102510355
Policy mu Std                0.45624965
Policy mu Max                1.8393766
Policy mu Min                -1.8420365
Policy log std Mean          -0.26759928
Policy log std Std           0.20277216
Policy log std Max           -0.09863521
Policy log std Min           -0.70077074
Z mean eval                  0.031311277
Z variance eval              0.022602836
total_rewards                [192.82131874 196.90224099 199.67523725 189.05397271 198.24569968
 198.60206488 200.44821929 198.44775624 203.69860915 198.32021479]
total_rewards_mean           197.6215333708532
total_rewards_std            3.855166224528826
total_rewards_max            203.69860914767688
total_rewards_min            189.0539727062519
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               28.47028563497588
(Previous) Eval Time (s)     1.991987959947437
Sample Time (s)              11.839425818994641
Epoch Time (s)               42.30169941391796
Total Train Time (s)         201.6900160573423
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:53:48.298723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #4 | Epoch Duration: 42.509634017944336
2020-01-11 12:53:48.298891 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #4 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032603692
Z variance train             0.023442317
KL Divergence                7.02439
KL Loss                      0.702439
QF Loss                      74.19501
VF Loss                      12.818774
Policy Loss                  -61.690372
Q Predictions Mean           57.907906
Q Predictions Std            76.58031
Q Predictions Max            212.05153
Q Predictions Min            -3.6894991
V Predictions Mean           62.38302
V Predictions Std            77.89921
V Predictions Max            217.8136
V Predictions Min            -0.5535821
Log Pis Mean                 -1.3470914
Log Pis Std                  1.4546258
Log Pis Max                  6.6066985
Log Pis Min                  -3.5449965
Policy mu Mean               0.16581637
Policy mu Std                0.5069017
Policy mu Max                1.9460552
Policy mu Min                -2.256291
Policy log std Mean          -0.25565633
Policy log std Std           0.18732595
Policy log std Max           -0.10720019
Policy log std Min           -0.7820875
Z mean eval                  0.02878862
Z variance eval              0.0120406505
total_rewards                [294.78041485 304.08688073 312.75780315 299.14772629 310.14076885
 291.44787437 272.73195521 310.42914091 299.13162923 320.99124901]
total_rewards_mean           301.5645442612796
total_rewards_std            12.85546764143108
total_rewards_max            320.9912490149272
total_rewards_min            272.7319552136012
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               27.70890953578055
(Previous) Eval Time (s)     2.1996500520035625
Sample Time (s)              13.135116294026375
Epoch Time (s)               43.043675881810486
Total Train Time (s)         246.08506594831124
Epoch                        5
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:32.695850 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #5 | Epoch Duration: 44.39677286148071
2020-01-11 12:54:32.696105 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028875506
Z variance train             0.012045466
KL Divergence                8.691999
KL Loss                      0.86919993
QF Loss                      61.950325
VF Loss                      22.923607
Policy Loss                  -85.095345
Q Predictions Mean           81.8862
Q Predictions Std            103.764244
Q Predictions Max            294.81274
Q Predictions Min            -5.376377
V Predictions Mean           86.883446
V Predictions Std            105.73498
V Predictions Max            298.95236
V Predictions Min            -1.424462
Log Pis Mean                 -1.4129854
Log Pis Std                  1.2774708
Log Pis Max                  5.8679495
Log Pis Min                  -4.5652566
Policy mu Mean               0.06769366
Policy mu Std                0.5012553
Policy mu Max                1.9583457
Policy mu Min                -2.1375446
Policy log std Mean          -0.2719567
Policy log std Std           0.20646518
Policy log std Max           -0.0152181685
Policy log std Min           -0.8507292
Z mean eval                  0.016350104
Z variance eval              0.007268662
total_rewards                [264.79057149 245.25071421 266.49339144 268.61445574 238.48052616
 263.84042937 261.13604042 254.1292542  255.26481632 260.27773127]
total_rewards_mean           257.8277930612465
total_rewards_std            9.196581714246058
total_rewards_max            268.61445573958133
total_rewards_min            238.48052615707937
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               27.022027054335922
(Previous) Eval Time (s)     3.5524652749300003
Sample Time (s)              13.672847895883024
Epoch Time (s)               44.247340225148946
Total Train Time (s)         289.5073096798733
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:16.120486 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #6 | Epoch Duration: 43.42418098449707
2020-01-11 12:55:16.120768 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017883731
Z variance train             0.007342607
KL Divergence                9.9297905
KL Loss                      0.99297905
QF Loss                      313.59778
VF Loss                      34.392918
Policy Loss                  -107.3454
Q Predictions Mean           105.57936
Q Predictions Std            125.3626
Q Predictions Max            351.0733
Q Predictions Min            -7.1255717
V Predictions Mean           108.820854
V Predictions Std            125.48909
V Predictions Max            357.94427
V Predictions Min            -3.7286282
Log Pis Mean                 -1.2299261
Log Pis Std                  1.6994617
Log Pis Max                  7.6023884
Log Pis Min                  -4.8734956
Policy mu Mean               0.15871647
Policy mu Std                0.6014847
Policy mu Max                2.3599117
Policy mu Min                -2.0919447
Policy log std Mean          -0.31076297
Policy log std Std           0.24562816
Policy log std Max           -0.08538943
Policy log std Min           -1.1078196
Z mean eval                  0.028499087
Z variance eval              0.0055544935
total_rewards                [324.68602163 174.67681749 312.25923955 145.70039464 138.62284355
 198.39934765 137.0604313  322.55080727 297.44093724 333.31404467]
total_rewards_mean           238.47108849965116
total_rewards_std            81.82626895759033
total_rewards_max            333.31404467155454
total_rewards_min            137.0604313028823
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               25.87000434473157
(Previous) Eval Time (s)     2.7290414650924504
Sample Time (s)              12.576032475568354
Epoch Time (s)               41.175078285392374
Total Train Time (s)         330.7518015606329
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:55:57.365924 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #7 | Epoch Duration: 41.244962215423584
2020-01-11 12:55:57.366102 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028020913
Z variance train             0.005487039
KL Divergence                10.596031
KL Loss                      1.0596031
QF Loss                      222.27383
VF Loss                      37.397354
Policy Loss                  -140.43898
Q Predictions Mean           141.57083
Q Predictions Std            149.77396
Q Predictions Max            431.63727
Q Predictions Min            -0.67681545
V Predictions Mean           138.8659
V Predictions Std            147.24893
V Predictions Max            423.73248
V Predictions Min            -0.69425374
Log Pis Mean                 -1.2059188
Log Pis Std                  1.7882757
Log Pis Max                  7.4660044
Log Pis Min                  -4.926438
Policy mu Mean               0.023681687
Policy mu Std                0.60924757
Policy mu Max                2.35797
Policy mu Min                -2.3924654
Policy log std Mean          -0.2933195
Policy log std Std           0.22172678
Policy log std Max           -0.065642536
Policy log std Min           -1.0818189
Z mean eval                  0.007943086
Z variance eval              0.0059326543
total_rewards                [340.25028009 344.83227967 316.41688581 321.73731293 322.85579613
 328.35697086 334.28665042 316.81886798 305.62254649 334.84827184]
total_rewards_mean           326.6025862213001
total_rewards_std            11.51536509804525
total_rewards_max            344.8322796705376
total_rewards_min            305.62254649047435
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               25.415896309074014
(Previous) Eval Time (s)     2.7986742318607867
Sample Time (s)              12.883698219899088
Epoch Time (s)               41.09826876083389
Total Train Time (s)         372.08485841425136
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:56:38.698595 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #8 | Epoch Duration: 41.33233428001404
2020-01-11 12:56:38.698778 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0075393147
Z variance train             0.0058042263
KL Divergence                10.471015
KL Loss                      1.0471015
QF Loss                      434.64252
VF Loss                      36.76709
Policy Loss                  -170.07004
Q Predictions Mean           167.89148
Q Predictions Std            176.01837
Q Predictions Max            503.6988
Q Predictions Min            -5.044222
V Predictions Mean           170.50015
V Predictions Std            175.33011
V Predictions Max            502.67456
V Predictions Min            -3.8211603
Log Pis Mean                 -0.8425698
Log Pis Std                  1.8661742
Log Pis Max                  8.7835045
Log Pis Min                  -5.0919714
Policy mu Mean               0.1724419
Policy mu Std                0.6770782
Policy mu Max                2.7686133
Policy mu Min                -2.4612434
Policy log std Mean          -0.34372023
Policy log std Std           0.27189848
Policy log std Max           0.0067336336
Policy log std Min           -1.2197025
Z mean eval                  0.024420632
Z variance eval              0.0041689575
total_rewards                [301.09530432 337.6539805  303.56933047 280.90464274 317.51690505
 309.24326464 315.02968424 297.71174285 287.77312745 322.92234761]
total_rewards_mean           307.3420329873287
total_rewards_std            15.986488387127428
total_rewards_max            337.65398050284915
total_rewards_min            280.904642737178
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               26.01996268099174
(Previous) Eval Time (s)     3.032453211955726
Sample Time (s)              12.985331521369517
Epoch Time (s)               42.03774741431698
Total Train Time (s)         414.1886532185599
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:20.804976 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #9 | Epoch Duration: 42.10604119300842
2020-01-11 12:57:20.805241 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02646622
Z variance train             0.00429978
KL Divergence                11.278105
KL Loss                      1.1278105
QF Loss                      73.95313
VF Loss                      14.119717
Policy Loss                  -165.16595
Q Predictions Mean           162.84343
Q Predictions Std            196.89377
Q Predictions Max            556.08344
Q Predictions Min            -4.5224214
V Predictions Mean           165.51758
V Predictions Std            197.91855
V Predictions Max            554.9185
V Predictions Min            -2.7175517
Log Pis Mean                 -1.0839729
Log Pis Std                  1.8196534
Log Pis Max                  9.703669
Log Pis Min                  -4.9922843
Policy mu Mean               0.028578533
Policy mu Std                0.59767014
Policy mu Max                2.679599
Policy mu Min                -2.5968673
Policy log std Mean          -0.3289263
Policy log std Std           0.2956758
Policy log std Max           -0.07970582
Policy log std Min           -1.370024
Z mean eval                  0.022232821
Z variance eval              0.0050627626
total_rewards                [301.56803375 308.3058364  291.86503133 275.14735524 284.64206346
 272.42313943 298.7009673  300.48605335 301.676092   305.27750757]
total_rewards_mean           294.0092079816226
total_rewards_std            11.938659822323112
total_rewards_max            308.30583640419593
total_rewards_min            272.4231394252992
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               27.519884943030775
(Previous) Eval Time (s)     3.100476913154125
Sample Time (s)              13.157905467785895
Epoch Time (s)               43.778267323970795
Total Train Time (s)         457.70025158673525
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:04.317506 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #10 | Epoch Duration: 43.51204514503479
2020-01-11 12:58:04.317783 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024770185
Z variance train             0.005125423
KL Divergence                10.936361
KL Loss                      1.0936362
QF Loss                      295.73624
VF Loss                      26.168478
Policy Loss                  -201.3032
Q Predictions Mean           198.75148
Q Predictions Std            221.5504
Q Predictions Max            603.8952
Q Predictions Min            -6.3986573
V Predictions Mean           202.28491
V Predictions Std            222.77635
V Predictions Max            606.84247
V Predictions Min            -1.870068
Log Pis Mean                 -0.9997534
Log Pis Std                  1.6487101
Log Pis Max                  7.6677823
Log Pis Min                  -4.604624
Policy mu Mean               0.07650706
Policy mu Std                0.6019019
Policy mu Max                2.4174798
Policy mu Min                -2.8293886
Policy log std Mean          -0.35265258
Policy log std Std           0.30026853
Policy log std Max           0.07793287
Policy log std Min           -1.4116803
Z mean eval                  0.015652541
Z variance eval              0.005267519
total_rewards                [263.23380598 290.85230591 300.81964797 305.66319087 311.25661696
 282.0179303  296.88414964 273.23049351 307.62041785 292.90927204]
total_rewards_mean           292.4487831032951
total_rewards_std            14.773958730472446
total_rewards_max            311.2566169584714
total_rewards_min            263.2338059810577
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               26.681740988977253
(Previous) Eval Time (s)     2.8339848471805453
Sample Time (s)              12.85430706338957
Epoch Time (s)               42.37003289954737
Total Train Time (s)         500.04698431445286
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:58:46.664871 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #11 | Epoch Duration: 42.34686255455017
2020-01-11 12:58:46.665104 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017202562
Z variance train             0.004865533
KL Divergence                11.002914
KL Loss                      1.1002915
QF Loss                      181.07234
VF Loss                      52.17975
Policy Loss                  -248.92714
Q Predictions Mean           245.00754
Q Predictions Std            245.6705
Q Predictions Max            662.5687
Q Predictions Min            -3.016951
V Predictions Mean           249.83835
V Predictions Std            246.93062
V Predictions Max            665.2566
V Predictions Min            -2.1041462
Log Pis Mean                 -0.774643
Log Pis Std                  1.8096651
Log Pis Max                  5.764523
Log Pis Min                  -4.814332
Policy mu Mean               0.185661
Policy mu Std                0.6644957
Policy mu Max                2.9382272
Policy mu Min                -2.1911383
Policy log std Mean          -0.36604786
Policy log std Std           0.28500217
Policy log std Max           0.08274603
Policy log std Min           -1.5257007
Z mean eval                  0.0148001285
Z variance eval              0.0052176416
total_rewards                [315.80193262 319.1162798  332.11650264 338.59017701 322.87048972
 316.22365896 334.25938578 331.94133847 335.77609556 338.08035707]
total_rewards_mean           328.4776217641104
total_rewards_std            8.580902948580936
total_rewards_max            338.59017701182074
total_rewards_min            315.80193261782637
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               26.98285420006141
(Previous) Eval Time (s)     2.810535743832588
Sample Time (s)              13.544519854243845
Epoch Time (s)               43.337909798137844
Total Train Time (s)         543.4323657322675
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:59:30.049865 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #12 | Epoch Duration: 43.38459086418152
2020-01-11 12:59:30.050062 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014926562
Z variance train             0.00524496
KL Divergence                10.699949
KL Loss                      1.0699949
QF Loss                      265.7166
VF Loss                      61.28228
Policy Loss                  -258.06573
Q Predictions Mean           254.49438
Q Predictions Std            256.76083
Q Predictions Max            715.4876
Q Predictions Min            -1.3253379
V Predictions Mean           258.3325
V Predictions Std            257.37897
V Predictions Max            716.49335
V Predictions Min            -1.0958868
Log Pis Mean                 -0.9442928
Log Pis Std                  1.9438498
Log Pis Max                  7.921427
Log Pis Min                  -6.0506687
Policy mu Mean               0.048888493
Policy mu Std                0.70031065
Policy mu Max                2.8512623
Policy mu Min                -2.8321984
Policy log std Mean          -0.3788602
Policy log std Std           0.30704036
Policy log std Max           0.10775741
Policy log std Min           -1.7137343
Z mean eval                  0.029839326
Z variance eval              0.0053322827
total_rewards                [305.84743871 303.52871035 289.46504642 286.88144831 298.10187167
 284.37588975 280.12378248 286.1204261  291.85685653 298.09972152]
total_rewards_mean           292.4401191847412
total_rewards_std            8.14587105667993
total_rewards_max            305.8474387126886
total_rewards_min            280.1237824837426
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               28.758478636853397
(Previous) Eval Time (s)     2.8569374782964587
Sample Time (s)              12.891096551902592
Epoch Time (s)               44.50651266705245
Total Train Time (s)         588.0653962534852
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:14.688431 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #13 | Epoch Duration: 44.638150215148926
2020-01-11 13:00:14.688773 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034245513
Z variance train             0.005297721
KL Divergence                10.659327
KL Loss                      1.0659326
QF Loss                      409.09558
VF Loss                      120.770355
Policy Loss                  -288.8505
Q Predictions Mean           283.13284
Q Predictions Std            279.66516
Q Predictions Max            755.8578
Q Predictions Min            -1.309652
V Predictions Mean           284.04657
V Predictions Std            277.7728
V Predictions Max            748.7658
V Predictions Min            -3.1427734
Log Pis Mean                 -0.6500893
Log Pis Std                  2.0287135
Log Pis Max                  8.4333315
Log Pis Min                  -6.6981454
Policy mu Mean               0.17819655
Policy mu Std                0.7385257
Policy mu Max                2.5760183
Policy mu Min                -2.7626138
Policy log std Mean          -0.38996825
Policy log std Std           0.29402006
Policy log std Max           0.07920103
Policy log std Min           -1.4692183
Z mean eval                  0.017868534
Z variance eval              0.004895323
total_rewards                [287.79326598 286.18283502 282.10209828 302.6775806  286.93192028
 278.67573386 287.71825528 281.85149321 278.10198471 279.57571844]
total_rewards_mean           285.16108856501006
total_rewards_std            6.840122357244287
total_rewards_max            302.6775805964505
total_rewards_min            278.1019847138413
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               27.353071324992925
(Previous) Eval Time (s)     2.988294509705156
Sample Time (s)              13.610101957805455
Epoch Time (s)               43.951467792503536
Total Train Time (s)         631.5487938793376
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:58.171722 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #14 | Epoch Duration: 43.48271441459656
2020-01-11 13:00:58.171991 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017735012
Z variance train             0.004842176
KL Divergence                10.861052
KL Loss                      1.0861052
QF Loss                      278.8469
VF Loss                      98.97631
Policy Loss                  -250.65028
Q Predictions Mean           243.76315
Q Predictions Std            294.3006
Q Predictions Max            787.65955
Q Predictions Min            -9.744161
V Predictions Mean           252.67236
V Predictions Std            297.1654
V Predictions Max            802.03076
V Predictions Min            -8.565884
Log Pis Mean                 -0.7203664
Log Pis Std                  2.3904102
Log Pis Max                  13.491255
Log Pis Min                  -6.149107
Policy mu Mean               -0.023322454
Policy mu Std                0.7269004
Policy mu Max                2.6874213
Policy mu Min                -3.5207741
Policy log std Mean          -0.34617892
Policy log std Std           0.29688898
Policy log std Max           0.10735212
Policy log std Min           -1.6867508
Z mean eval                  0.016543983
Z variance eval              0.0047692684
total_rewards                [259.16347044 278.61242767 264.5536226  308.80801179 285.06491553
 262.4264823  279.68886253 296.98827703 266.55106717 278.59480663]
total_rewards_mean           278.0451943678251
total_rewards_std            15.074463201988229
total_rewards_max            308.80801178844075
total_rewards_min            259.1634704351494
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               25.6920235469006
(Previous) Eval Time (s)     2.5192888299934566
Sample Time (s)              13.525228187907487
Epoch Time (s)               41.736540564801544
Total Train Time (s)         673.4962778198533
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:01:40.118654 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #15 | Epoch Duration: 41.946497201919556
2020-01-11 13:01:40.118806 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #15 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019408679
Z variance train             0.0047343187
KL Divergence                11.01398
KL Loss                      1.101398
QF Loss                      431.44366
VF Loss                      86.79666
Policy Loss                  -302.8077
Q Predictions Mean           296.873
Q Predictions Std            318.31573
Q Predictions Max            841.4767
Q Predictions Min            -6.799603
V Predictions Mean           300.3539
V Predictions Std            319.07706
V Predictions Max            850.0561
V Predictions Min            -4.9259877
Log Pis Mean                 -0.6664418
Log Pis Std                  1.9944844
Log Pis Max                  6.8548307
Log Pis Min                  -4.485857
Policy mu Mean               0.17554073
Policy mu Std                0.7427897
Policy mu Max                2.4492145
Policy mu Min                -2.7264948
Policy log std Mean          -0.39728817
Policy log std Std           0.31370053
Policy log std Max           0.036729224
Policy log std Min           -1.6720581
Z mean eval                  0.024265166
Z variance eval              0.0036865235
total_rewards                [286.71808674 290.9265508  298.56932278 268.78803955 342.19368946
 280.575141   300.15445992 300.70548829 290.26451723 341.70318684]
total_rewards_mean           300.0598482612112
total_rewards_std            22.862685234706607
total_rewards_max            342.1936894643089
total_rewards_min            268.78803954913303
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               28.9319730498828
(Previous) Eval Time (s)     2.7289704671129584
Sample Time (s)              13.003757130354643
Epoch Time (s)               44.6647006473504
Total Train Time (s)         718.4887787993066
Epoch                        16
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:02:25.112110 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #16 | Epoch Duration: 44.99315047264099
2020-01-11 13:02:25.112309 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012826358
Z variance train             0.004156931
KL Divergence                11.552478
KL Loss                      1.1552478
QF Loss                      169.92691
VF Loss                      53.98797
Policy Loss                  -304.37158
Q Predictions Mean           299.9809
Q Predictions Std            321.44632
Q Predictions Max            885.4269
Q Predictions Min            -10.295655
V Predictions Mean           304.60956
V Predictions Std            320.62115
V Predictions Max            882.0562
V Predictions Min            0.18302876
Log Pis Mean                 -0.69500095
Log Pis Std                  1.7983378
Log Pis Max                  4.878118
Log Pis Min                  -7.5382595
Policy mu Mean               0.1433
Policy mu Std                0.72084486
Policy mu Max                2.3842416
Policy mu Min                -1.8988975
Policy log std Mean          -0.38823292
Policy log std Std           0.3070469
Policy log std Max           -0.032324918
Policy log std Min           -1.7396206
Z mean eval                  0.027338928
Z variance eval              0.0030665018
total_rewards                [280.07160029 249.5137855  277.10317104 314.90387581 272.89276356
 231.36277369 391.60446434 265.42814757 291.8043917  310.94758697]
total_rewards_mean           288.5632560458772
total_rewards_std            41.95697530076263
total_rewards_max            391.6044643407084
total_rewards_min            231.3627736867868
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               26.16897400887683
(Previous) Eval Time (s)     3.057125468272716
Sample Time (s)              13.062044305726886
Epoch Time (s)               42.28814378287643
Total Train Time (s)         760.7763812541962
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:07.403874 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #17 | Epoch Duration: 42.29138255119324
2020-01-11 13:03:07.404158 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026848176
Z variance train             0.00306456
KL Divergence                12.276491
KL Loss                      1.2276491
QF Loss                      785.99976
VF Loss                      111.00566
Policy Loss                  -311.727
Q Predictions Mean           306.89636
Q Predictions Std            343.04355
Q Predictions Max            889.534
Q Predictions Min            -1.7269917
V Predictions Mean           308.83362
V Predictions Std            341.4034
V Predictions Max            888.31354
V Predictions Min            -2.698635
Log Pis Mean                 -0.6048809
Log Pis Std                  2.1523929
Log Pis Max                  8.921375
Log Pis Min                  -4.9406433
Policy mu Mean               0.010189795
Policy mu Std                0.8104257
Policy mu Max                2.6413598
Policy mu Min                -3.745624
Policy log std Mean          -0.3672398
Policy log std Std           0.27716634
Policy log std Max           0.074034095
Policy log std Min           -1.6216937
Z mean eval                  0.061852038
Z variance eval              0.002842093
total_rewards                [307.23247423 227.72623223 244.38140237 284.73971189 252.07115757
 231.81977491 242.13469929 253.64418222 266.75825984 239.95093254]
total_rewards_mean           255.04588270907752
total_rewards_std            23.552622068881476
total_rewards_max            307.23247423369526
total_rewards_min            227.72623222704664
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               27.984274834860116
(Previous) Eval Time (s)     3.0600656997412443
Sample Time (s)              13.484332480002195
Epoch Time (s)               44.528673014603555
Total Train Time (s)         804.9761488540098
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:51.604245 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #18 | Epoch Duration: 44.19985818862915
2020-01-11 13:03:51.604528 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04909357
Z variance train             0.0019705826
KL Divergence                13.377094
KL Loss                      1.3377094
QF Loss                      265.0214
VF Loss                      130.58322
Policy Loss                  -306.8528
Q Predictions Mean           305.212
Q Predictions Std            342.80182
Q Predictions Max            958.12506
Q Predictions Min            -5.9291034
V Predictions Mean           312.5827
V Predictions Std            347.34378
V Predictions Max            970.6338
V Predictions Min            -4.371536
Log Pis Mean                 -0.45198244
Log Pis Std                  2.361471
Log Pis Max                  14.201766
Log Pis Min                  -3.4282153
Policy mu Mean               0.06978422
Policy mu Std                0.84315765
Policy mu Max                2.848539
Policy mu Min                -3.6156855
Policy log std Mean          -0.37655532
Policy log std Std           0.29750246
Policy log std Max           0.12699051
Policy log std Min           -1.5003128
Z mean eval                  0.032551955
Z variance eval              0.0023884312
total_rewards                [229.59976767 252.11726177 314.66253153 310.1411363  296.67004475
 311.79687717 223.08720538 320.0566634  229.4070158  259.32839416]
total_rewards_mean           274.6866897915763
total_rewards_std            37.76876573073495
total_rewards_max            320.0566633995989
total_rewards_min            223.08720537972485
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               29.03593271691352
(Previous) Eval Time (s)     2.730958143249154
Sample Time (s)              13.010860747192055
Epoch Time (s)               44.77775160735473
Total Train Time (s)         850.054338642396
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:04:36.682599 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #19 | Epoch Duration: 45.07783389091492
2020-01-11 13:04:36.682927 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035602063
Z variance train             0.0024167045
KL Divergence                12.784178
KL Loss                      1.2784178
QF Loss                      692.8074
VF Loss                      57.885433
Policy Loss                  -320.45477
Q Predictions Mean           317.82422
Q Predictions Std            361.00085
Q Predictions Max            1017.2798
Q Predictions Min            -10.095617
V Predictions Mean           322.92346
V Predictions Std            362.23184
V Predictions Max            1021.9833
V Predictions Min            -6.0927887
Log Pis Mean                 -0.529155
Log Pis Std                  2.0769544
Log Pis Max                  7.918576
Log Pis Min                  -3.4868479
Policy mu Mean               0.16604418
Policy mu Std                0.77026176
Policy mu Max                2.4124887
Policy mu Min                -2.69885
Policy log std Mean          -0.41185126
Policy log std Std           0.332315
Policy log std Max           -0.034288123
Policy log std Min           -1.6310999
Z mean eval                  0.028429937
Z variance eval              0.0015821023
total_rewards                [359.90797637 397.50861844 350.53738241 307.23506261 422.24478604
 397.0734668  403.72526283 429.04803256 453.53165351 378.29415298]
total_rewards_mean           389.9106394560139
total_rewards_std            40.42938551379035
total_rewards_max            453.53165351180894
total_rewards_min            307.23506261023164
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               25.97846653405577
(Previous) Eval Time (s)     3.030778472777456
Sample Time (s)              13.107301436830312
Epoch Time (s)               42.11654644366354
Total Train Time (s)         892.9637104491703
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:05:19.594108 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #20 | Epoch Duration: 42.910919189453125
2020-01-11 13:05:19.594416 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0131801125
Z variance train             0.00145547
KL Divergence                14.103607
KL Loss                      1.4103607
QF Loss                      213.44232
VF Loss                      46.81124
Policy Loss                  -363.33057
Q Predictions Mean           360.2741
Q Predictions Std            376.52155
Q Predictions Max            1025.1687
Q Predictions Min            -4.4116025
V Predictions Mean           363.04623
V Predictions Std            377.66635
V Predictions Max            1013.9024
V Predictions Min            -2.172397
Log Pis Mean                 -0.642649
Log Pis Std                  2.0666792
Log Pis Max                  9.714956
Log Pis Min                  -5.2287564
Policy mu Mean               0.006653484
Policy mu Std                0.7835911
Policy mu Max                2.6177874
Policy mu Min                -2.7577028
Policy log std Mean          -0.41435716
Policy log std Std           0.339225
Policy log std Max           0.16936746
Policy log std Min           -1.4961437
Z mean eval                  0.016211245
Z variance eval              0.0019518979
total_rewards                [381.70742756 396.98047642 394.02079063 390.87203211 439.94660362
 405.07513825 406.65967094 389.76137714 389.82789419 407.50312566]
total_rewards_mean           400.2354536522396
total_rewards_std            15.468320860047761
total_rewards_max            439.9466036172197
total_rewards_min            381.7074275615538
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               25.24387700110674
(Previous) Eval Time (s)     3.8248661351390183
Sample Time (s)              13.727970531210303
Epoch Time (s)               42.79671366745606
Total Train Time (s)         935.660970161669
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:02.290041 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #21 | Epoch Duration: 42.69540810585022
2020-01-11 13:06:02.290205 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #21 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02966624
Z variance train             0.0021563394
KL Divergence                13.241825
KL Loss                      1.3241825
QF Loss                      180.02373
VF Loss                      54.55162
Policy Loss                  -375.80896
Q Predictions Mean           371.59125
Q Predictions Std            397.37744
Q Predictions Max            1032.819
Q Predictions Min            -8.794551
V Predictions Mean           377.06165
V Predictions Std            399.97034
V Predictions Max            1024.7158
V Predictions Min            -0.75126624
Log Pis Mean                 -0.5353912
Log Pis Std                  2.0798564
Log Pis Max                  7.6666894
Log Pis Min                  -5.1779675
Policy mu Mean               0.10783839
Policy mu Std                0.83395123
Policy mu Max                2.8468683
Policy mu Min                -2.6395855
Policy log std Mean          -0.38594317
Policy log std Std           0.29998636
Policy log std Max           0.014181465
Policy log std Min           -1.5055356
Z mean eval                  0.021659968
Z variance eval              0.00258008
total_rewards                [189.41315298 187.15664612 382.15430205 193.58525399 208.25155179
 195.67557439 446.17192004 449.63432253 242.35154597 398.35030619]
total_rewards_mean           289.27445760550074
total_rewards_std            108.60031278189629
total_rewards_max            449.63432253369666
total_rewards_min            187.15664612486543
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               26.9258065498434
(Previous) Eval Time (s)     3.7233209861442447
Sample Time (s)              14.221943406388164
Epoch Time (s)               44.87107094237581
Total Train Time (s)         979.6713189501315
Epoch                        22
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:06:46.304441 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #22 | Epoch Duration: 44.01405668258667
2020-01-11 13:06:46.304744 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #22 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023783162
Z variance train             0.0031657952
KL Divergence                12.3429985
KL Loss                      1.2342999
QF Loss                      322.06335
VF Loss                      99.9649
Policy Loss                  -384.3465
Q Predictions Mean           379.66156
Q Predictions Std            396.3462
Q Predictions Max            1095.1401
Q Predictions Min            -8.678114
V Predictions Mean           380.94943
V Predictions Std            393.4533
V Predictions Max            1099.2142
V Predictions Min            0.6983266
Log Pis Mean                 -0.14323518
Log Pis Std                  2.256481
Log Pis Max                  7.5280504
Log Pis Min                  -4.308327
Policy mu Mean               -0.0155652175
Policy mu Std                0.87308496
Policy mu Max                2.955018
Policy mu Min                -2.8195434
Policy log std Mean          -0.45718512
Policy log std Std           0.35639915
Policy log std Max           -0.03354229
Policy log std Min           -1.660883
Z mean eval                  0.01013872
Z variance eval              0.0037015039
total_rewards                [485.21488956 441.43792771 475.43153246 375.51760576 397.05457901
 437.34324544 264.67343081 278.68000786 451.7006364  485.9107145 ]
total_rewards_mean           409.2964569514247
total_rewards_std            76.74135966207751
total_rewards_max            485.91071450355787
total_rewards_min            264.67343081492174
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               25.761256170924753
(Previous) Eval Time (s)     2.8659618669189513
Sample Time (s)              13.49283909238875
Epoch Time (s)               42.12005713023245
Total Train Time (s)         1023.0091504384764
Epoch                        23
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:07:29.644504 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #23 | Epoch Duration: 43.33953237533569
2020-01-11 13:07:29.644772 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014051551
Z variance train             0.0031679422
KL Divergence                12.129549
KL Loss                      1.2129549
QF Loss                      325.2149
VF Loss                      102.777115
Policy Loss                  -418.06052
Q Predictions Mean           414.45218
Q Predictions Std            415.25665
Q Predictions Max            1135.9943
Q Predictions Min            -2.3129935
V Predictions Mean           416.83582
V Predictions Std            417.38696
V Predictions Max            1134.7812
V Predictions Min            -1.424007
Log Pis Mean                 0.011192933
Log Pis Std                  2.4713197
Log Pis Max                  8.606705
Log Pis Min                  -3.471467
Policy mu Mean               0.1428458
Policy mu Std                0.9314835
Policy mu Max                2.622358
Policy mu Min                -2.8447485
Policy log std Mean          -0.4497211
Policy log std Std           0.35308692
Policy log std Max           0.20044456
Policy log std Min           -1.8652624
Z mean eval                  0.035847142
Z variance eval              0.002973244
total_rewards                [412.42310335 292.73986884 415.02652339 424.58517589 488.33923322
 434.53569571 481.19536013 454.13288659 454.5544152  492.94652385]
total_rewards_mean           435.0478786181002
total_rewards_std            55.082292430456086
total_rewards_max            492.94652385425377
total_rewards_min            292.73986883512936
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               27.344634288921952
(Previous) Eval Time (s)     4.085182229988277
Sample Time (s)              14.44962946139276
Epoch Time (s)               45.87944598030299
Total Train Time (s)         1068.8794096778147
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:08:15.517103 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #24 | Epoch Duration: 45.87209701538086
2020-01-11 13:08:15.517399 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #24 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028866794
Z variance train             0.0026620238
KL Divergence                12.626535
KL Loss                      1.2626536
QF Loss                      302.90125
VF Loss                      104.17258
Policy Loss                  -418.07535
Q Predictions Mean           417.80072
Q Predictions Std            425.34628
Q Predictions Max            1142.8862
Q Predictions Min            -3.5029252
V Predictions Mean           420.8396
V Predictions Std            426.66052
V Predictions Max            1144.0044
V Predictions Min            -2.6834755
Log Pis Mean                 -0.12952906
Log Pis Std                  2.495735
Log Pis Max                  8.489162
Log Pis Min                  -6.271227
Policy mu Mean               0.123733126
Policy mu Std                0.935847
Policy mu Max                2.937101
Policy mu Min                -2.6373858
Policy log std Mean          -0.4151806
Policy log std Std           0.34521705
Policy log std Max           0.026608273
Policy log std Min           -1.8963623
Z mean eval                  0.026491841
Z variance eval              0.0029971413
total_rewards                [323.91488207 441.19055695 436.23891715 510.89046534 538.62799241
 367.85954807 378.54348041 388.52653895 490.19254286 292.59147114]
total_rewards_mean           416.8576395357192
total_rewards_std            76.6601590108277
total_rewards_max            538.627992410678
total_rewards_min            292.5914711433811
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               28.732640233822167
(Previous) Eval Time (s)     4.077575876843184
Sample Time (s)              14.60029983241111
Epoch Time (s)               47.41051594307646
Total Train Time (s)         1116.2920385063626
Epoch                        25
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:02.929282 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #25 | Epoch Duration: 47.41166424751282
2020-01-11 13:09:02.929482 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025184939
Z variance train             0.002761394
KL Divergence                12.510846
KL Loss                      1.2510847
QF Loss                      271.78195
VF Loss                      186.71962
Policy Loss                  -420.95444
Q Predictions Mean           416.15952
Q Predictions Std            425.74136
Q Predictions Max            1160.7803
Q Predictions Min            -2.8319514
V Predictions Mean           416.07452
V Predictions Std            427.49347
V Predictions Max            1169.7275
V Predictions Min            -2.1866875
Log Pis Mean                 0.43747795
Log Pis Std                  2.7410274
Log Pis Max                  9.955855
Log Pis Min                  -4.377689
Policy mu Mean               0.020199962
Policy mu Std                1.0356315
Policy mu Max                2.964546
Policy mu Min                -2.640071
Policy log std Mean          -0.4783528
Policy log std Std           0.3781115
Policy log std Max           -0.0032541752
Policy log std Min           -2.0046253
Z mean eval                  0.02694326
Z variance eval              0.0028904458
total_rewards                [288.87709281 310.68846854 447.64043081 283.08849752 298.682763
 317.53122367 519.01855478 307.73968218 301.34684038 540.27316151]
total_rewards_mean           361.4886715198163
total_rewards_std            95.17573532847778
total_rewards_max            540.2731615090534
total_rewards_min            283.0884975192184
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               25.84621139196679
(Previous) Eval Time (s)     4.078456501010805
Sample Time (s)              13.975061425939202
Epoch Time (s)               43.8997293189168
Total Train Time (s)         1159.6137187369168
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:09:46.251494 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #26 | Epoch Duration: 43.321837425231934
2020-01-11 13:09:46.251695 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036034774
Z variance train             0.003061121
KL Divergence                12.22676
KL Loss                      1.222676
QF Loss                      1505.104
VF Loss                      130.27061
Policy Loss                  -468.06525
Q Predictions Mean           460.70425
Q Predictions Std            458.08734
Q Predictions Max            1257.3331
Q Predictions Min            -0.58698964
V Predictions Mean           464.43546
V Predictions Std            459.70526
V Predictions Max            1256.7776
V Predictions Min            -8.557641
Log Pis Mean                 0.6284655
Log Pis Std                  3.087498
Log Pis Max                  10.939497
Log Pis Min                  -5.9614773
Policy mu Mean               -0.07390814
Policy mu Std                1.1144462
Policy mu Max                3.0222447
Policy mu Min                -3.4201126
Policy log std Mean          -0.46530595
Policy log std Std           0.35047063
Policy log std Max           -0.0912116
Policy log std Min           -1.8455901
Z mean eval                  0.055180263
Z variance eval              0.0020371783
total_rewards                [459.49868185 549.38909226 386.80683831 409.78220097 315.56632808
 387.40320291 401.43986782 487.27098208 383.53438488 410.83553108]
total_rewards_mean           419.15271102435224
total_rewards_std            61.44365598141152
total_rewards_max            549.3890922641725
total_rewards_min            315.56632807862445
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               26.344206786248833
(Previous) Eval Time (s)     3.500315035227686
Sample Time (s)              13.699444547761232
Epoch Time (s)               43.54396636923775
Total Train Time (s)         1203.3170140138827
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:10:29.956835 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #27 | Epoch Duration: 43.704957485198975
2020-01-11 13:10:29.957029 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012850856
Z variance train             0.002078609
KL Divergence                13.014717
KL Loss                      1.3014717
QF Loss                      503.40115
VF Loss                      193.3071
Policy Loss                  -497.66885
Q Predictions Mean           489.3649
Q Predictions Std            460.66983
Q Predictions Max            1308.1028
Q Predictions Min            -3.807507
V Predictions Mean           490.25998
V Predictions Std            460.5629
V Predictions Max            1305.8947
V Predictions Min            -1.0062952
Log Pis Mean                 0.29993632
Log Pis Std                  2.4716413
Log Pis Max                  11.40276
Log Pis Min                  -3.6597877
Policy mu Mean               -0.112412214
Policy mu Std                0.99785644
Policy mu Max                2.6913042
Policy mu Min                -2.8485994
Policy log std Mean          -0.44356546
Policy log std Std           0.3306295
Policy log std Max           -0.06285056
Policy log std Min           -1.6305707
Z mean eval                  0.0077746883
Z variance eval              0.0016220752
total_rewards                [465.86796645 437.78376461 387.79869889 459.7113705  451.195643
 532.31198741 447.67778323 409.33115117 451.09795333 382.61854136]
total_rewards_mean           442.5394859945818
total_rewards_std            40.96981316731252
total_rewards_max            532.3119874057277
total_rewards_min            382.61854136206125
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               28.31896388484165
(Previous) Eval Time (s)     3.6610762630589306
Sample Time (s)              14.07119760895148
Epoch Time (s)               46.05123775685206
Total Train Time (s)         1249.453625710681
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:11:16.092489 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #28 | Epoch Duration: 46.13531255722046
2020-01-11 13:11:16.092653 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008634341
Z variance train             0.0015317093
KL Divergence                13.837461
KL Loss                      1.3837461
QF Loss                      380.9655
VF Loss                      77.44176
Policy Loss                  -484.24942
Q Predictions Mean           479.00995
Q Predictions Std            475.6788
Q Predictions Max            1312.8416
Q Predictions Min            -6.9235334
V Predictions Mean           485.3715
V Predictions Std            480.01352
V Predictions Max            1351.8522
V Predictions Min            -3.4814966
Log Pis Mean                 0.0739788
Log Pis Std                  2.3493538
Log Pis Max                  11.169815
Log Pis Min                  -4.45555
Policy mu Mean               0.026036054
Policy mu Std                0.93832016
Policy mu Max                2.6313546
Policy mu Min                -2.8339243
Policy log std Mean          -0.48197982
Policy log std Std           0.3713602
Policy log std Max           -0.08946999
Policy log std Min           -1.8907413
Z mean eval                  0.038437948
Z variance eval              0.0021964344
total_rewards                [278.79714469 573.35359657 407.95782178 501.54948001 448.64784929
 456.4233972  369.67420605 531.33677024 517.44134523 452.33171416]
total_rewards_mean           453.7513325209958
total_rewards_std            81.53248419179998
total_rewards_max            573.3535965719005
total_rewards_min            278.79714468634745
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               27.116965042892843
(Previous) Eval Time (s)     3.74489339068532
Sample Time (s)              14.060370961669832
Epoch Time (s)               44.922229395247996
Total Train Time (s)         1294.362741889432
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:01.006678 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #29 | Epoch Duration: 44.91384482383728
2020-01-11 13:12:01.006969 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #29 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037064575
Z variance train             0.00218954
KL Divergence                12.978675
KL Loss                      1.2978675
QF Loss                      1055.0471
VF Loss                      190.95793
Policy Loss                  -465.48444
Q Predictions Mean           468.38455
Q Predictions Std            472.93936
Q Predictions Max            1352.0895
Q Predictions Min            -15.300528
V Predictions Mean           466.88016
V Predictions Std            469.198
V Predictions Max            1350.7434
V Predictions Min            -2.885346
Log Pis Mean                 0.11674349
Log Pis Std                  2.5184312
Log Pis Max                  8.135425
Log Pis Min                  -4.766385
Policy mu Mean               -0.10150671
Policy mu Std                0.9640639
Policy mu Max                2.4565396
Policy mu Min                -2.7191756
Policy log std Mean          -0.47512683
Policy log std Std           0.356667
Policy log std Max           0.039265558
Policy log std Min           -1.7330028
Z mean eval                  0.01662395
Z variance eval              0.008971082
total_rewards                [466.96679405 475.61489669 409.65942695 414.52617366 417.53978115
 410.95747292 464.82345057 459.98978074 450.63681688 453.12122541]
total_rewards_mean           442.383581903672
total_rewards_std            24.813934983934107
total_rewards_max            475.61489668863965
total_rewards_min            409.6594269540095
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               28.46138303494081
(Previous) Eval Time (s)     3.736237217672169
Sample Time (s)              14.738916301168501
Epoch Time (s)               46.93653655378148
Total Train Time (s)         1341.5989631265402
Epoch                        30
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:12:48.242717 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #30 | Epoch Duration: 47.23549461364746
2020-01-11 13:12:48.242998 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023321202
Z variance train             0.0048621846
KL Divergence                10.898432
KL Loss                      1.0898432
QF Loss                      572.102
VF Loss                      143.09
Policy Loss                  -490.04318
Q Predictions Mean           486.0548
Q Predictions Std            488.73032
Q Predictions Max            1434.5762
Q Predictions Min            -4.513134
V Predictions Mean           487.84747
V Predictions Std            488.73108
V Predictions Max            1427.4701
V Predictions Min            -0.16421926
Log Pis Mean                 -0.14118859
Log Pis Std                  2.3945127
Log Pis Max                  7.06086
Log Pis Min                  -4.249814
Policy mu Mean               0.019764572
Policy mu Std                0.9285854
Policy mu Max                3.1089263
Policy mu Min                -3.026549
Policy log std Mean          -0.44187632
Policy log std Std           0.3244678
Policy log std Max           0.16797046
Policy log std Min           -1.7018704
Z mean eval                  0.027504444
Z variance eval              0.003322777
total_rewards                [569.16081679 560.73674209 602.59949283 545.89986509 575.21703071
 574.68854984 604.99823862 588.71426023 636.19971378 587.51198965]
total_rewards_mean           584.5726699620267
total_rewards_std            24.330640250494483
total_rewards_max            636.1997137766397
total_rewards_min            545.8998650889084
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               27.851302972063422
(Previous) Eval Time (s)     4.034929053392261
Sample Time (s)              14.320357601158321
Epoch Time (s)               46.206589626614004
Total Train Time (s)         1388.3827348658815
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:13:35.028371 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #31 | Epoch Duration: 46.78511691093445
2020-01-11 13:13:35.028685 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028115904
Z variance train             0.0032979038
KL Divergence                11.925158
KL Loss                      1.1925157
QF Loss                      2438.6672
VF Loss                      90.40698
Policy Loss                  -529.61707
Q Predictions Mean           527.6529
Q Predictions Std            485.47855
Q Predictions Max            1420.0397
Q Predictions Min            0.75420386
V Predictions Mean           529.1121
V Predictions Std            486.2328
V Predictions Max            1435.6826
V Predictions Min            1.3568108
Log Pis Mean                 -0.13457507
Log Pis Std                  2.3257184
Log Pis Max                  7.2289
Log Pis Min                  -3.8216012
Policy mu Mean               -0.025249846
Policy mu Std                0.9114778
Policy mu Max                2.6297312
Policy mu Min                -3.351066
Policy log std Mean          -0.42880294
Policy log std Std           0.31418636
Policy log std Max           0.18684293
Policy log std Min           -1.438113
Z mean eval                  0.023242855
Z variance eval              0.0033805943
total_rewards                [579.06711945 565.46891865 570.77944339 530.53292068 505.44749427
 583.38668885 490.27273921 595.55321276 495.35721957 522.4677034 ]
total_rewards_mean           543.8333460220763
total_rewards_std            37.417321593738095
total_rewards_max            595.5532127562102
total_rewards_min            490.2727392093328
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               27.88914395403117
(Previous) Eval Time (s)     4.613156035076827
Sample Time (s)              15.290813599713147
Epoch Time (s)               47.79311358882114
Total Train Time (s)         1435.8336076107807
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:14:22.477881 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #32 | Epoch Duration: 47.44896697998047
2020-01-11 13:14:22.478083 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023370128
Z variance train             0.0033848598
KL Divergence                11.92062
KL Loss                      1.192062
QF Loss                      439.05768
VF Loss                      93.60521
Policy Loss                  -517.95795
Q Predictions Mean           517.5522
Q Predictions Std            479.75037
Q Predictions Max            1408.6149
Q Predictions Min            -1.4733632
V Predictions Mean           519.6797
V Predictions Std            478.14343
V Predictions Max            1401.0028
V Predictions Min            -1.353454
Log Pis Mean                 -0.13203532
Log Pis Std                  2.3721309
Log Pis Max                  8.436514
Log Pis Min                  -8.480138
Policy mu Mean               0.03234349
Policy mu Std                0.88291585
Policy mu Max                2.5594065
Policy mu Min                -3.0887172
Policy log std Mean          -0.4939328
Policy log std Std           0.36006775
Policy log std Max           0.07632786
Policy log std Min           -1.9891741
Z mean eval                  0.034168635
Z variance eval              0.0041574547
total_rewards                [494.21826042 585.20252424 495.35588832 488.5537814  591.63356025
 543.36563508 544.39785696 576.37419316 546.36943493 522.31427151]
total_rewards_mean           538.7785406292955
total_rewards_std            36.24535304438596
total_rewards_max            591.6335602486108
total_rewards_min            488.5537814029403
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               25.98423590697348
(Previous) Eval Time (s)     4.268728481605649
Sample Time (s)              14.798188443761319
Epoch Time (s)               45.05115283234045
Total Train Time (s)         1480.5828813565895
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:07.231276 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #33 | Epoch Duration: 44.753018617630005
2020-01-11 13:15:07.231521 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033557296
Z variance train             0.004155421
KL Divergence                11.371932
KL Loss                      1.1371932
QF Loss                      390.07874
VF Loss                      160.9448
Policy Loss                  -519.5617
Q Predictions Mean           520.59985
Q Predictions Std            495.22574
Q Predictions Max            1414.1788
Q Predictions Min            2.9517992
V Predictions Mean           522.6564
V Predictions Std            494.58508
V Predictions Max            1418.241
V Predictions Min            1.3037977
Log Pis Mean                 0.15239947
Log Pis Std                  2.63717
Log Pis Max                  8.756683
Log Pis Min                  -4.650184
Policy mu Mean               0.10008844
Policy mu Std                0.988865
Policy mu Max                3.348257
Policy mu Min                -3.135351
Policy log std Mean          -0.4622122
Policy log std Std           0.31372714
Policy log std Max           0.25171983
Policy log std Min           -1.5460846
Z mean eval                  0.01281474
Z variance eval              0.004071056
total_rewards                [585.0978726  604.6464912  559.8824098  628.11434418 533.44542528
 559.08934898 573.96785295 532.70578648 554.1279401  566.31769255]
total_rewards_mean           569.7395164128328
total_rewards_std            28.345462342006808
total_rewards_max            628.1143441771289
total_rewards_min            532.7057864843389
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               27.893071432132274
(Previous) Eval Time (s)     3.9703202680684626
Sample Time (s)              14.595870247110724
Epoch Time (s)               46.45926194731146
Total Train Time (s)         1527.1209403104149
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:53.768562 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #34 | Epoch Duration: 46.536837339401245
2020-01-11 13:15:53.768749 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014432535
Z variance train             0.0040643644
KL Divergence                11.311966
KL Loss                      1.1311966
QF Loss                      597.3484
VF Loss                      267.66644
Policy Loss                  -510.9062
Q Predictions Mean           507.46097
Q Predictions Std            483.04742
Q Predictions Max            1350.6487
Q Predictions Min            -17.294813
V Predictions Mean           510.07153
V Predictions Std            483.50195
V Predictions Max            1348.3734
V Predictions Min            -16.895695
Log Pis Mean                 -0.16625094
Log Pis Std                  2.3825514
Log Pis Max                  9.238575
Log Pis Min                  -4.698095
Policy mu Mean               0.09368058
Policy mu Std                0.85889953
Policy mu Max                3.6176672
Policy mu Min                -2.887853
Policy log std Mean          -0.47843495
Policy log std Std           0.3394715
Policy log std Max           0.23913395
Policy log std Min           -1.5488743
Z mean eval                  0.021307167
Z variance eval              0.0041198255
total_rewards                [494.76814946 484.69828352 585.58506676 579.61594988 517.80398238
 624.41407791 528.30098516 472.27787354 612.79172586 572.49275679]
total_rewards_mean           547.2748851265757
total_rewards_std            51.88289709887493
total_rewards_max            624.414077910271
total_rewards_min            472.27787354312505
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               26.131383549422026
(Previous) Eval Time (s)     4.0476192510686815
Sample Time (s)              15.197633587755263
Epoch Time (s)               45.37663638824597
Total Train Time (s)         1572.859065681696
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:16:39.507551 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #35 | Epoch Duration: 45.73866605758667
2020-01-11 13:16:39.507735 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021000773
Z variance train             0.0041219033
KL Divergence                11.251633
KL Loss                      1.1251633
QF Loss                      763.9186
VF Loss                      532.12683
Policy Loss                  -595.70856
Q Predictions Mean           589.8623
Q Predictions Std            478.44553
Q Predictions Max            1342.0907
Q Predictions Min            -1.8343524
V Predictions Mean           599.0412
V Predictions Std            481.62515
V Predictions Max            1340.7057
V Predictions Min            -1.1121916
Log Pis Mean                 0.21934888
Log Pis Std                  2.4039617
Log Pis Max                  10.365986
Log Pis Min                  -3.984906
Policy mu Mean               0.09980184
Policy mu Std                0.9643656
Policy mu Max                2.7131484
Policy mu Min                -3.4103935
Policy log std Mean          -0.5138587
Policy log std Std           0.32911798
Policy log std Max           -0.047321767
Policy log std Min           -1.5618036
Z mean eval                  0.090470135
Z variance eval              0.0035901815
total_rewards                [545.3278321  440.23148985 390.63740118 455.00862074 487.32827615
 384.90929181 320.7463865  459.17569614 620.25875068 388.14332311]
total_rewards_mean           449.1767068259993
total_rewards_std            82.43799295311018
total_rewards_max            620.2587506755044
total_rewards_min            320.746386496249
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               28.027905622962862
(Previous) Eval Time (s)     4.409385928884149
Sample Time (s)              14.480240107979625
Epoch Time (s)               46.917531659826636
Total Train Time (s)         1619.3480082508177
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:17:25.996723 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #36 | Epoch Duration: 46.48878860473633
2020-01-11 13:17:25.996899 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09236379
Z variance train             0.0035692782
KL Divergence                12.055751
KL Loss                      1.2055751
QF Loss                      555.5335
VF Loss                      81.344986
Policy Loss                  -560.7245
Q Predictions Mean           561.0303
Q Predictions Std            504.24197
Q Predictions Max            1412.8945
Q Predictions Min            0.27267772
V Predictions Mean           561.54736
V Predictions Std            504.58395
V Predictions Max            1407.0508
V Predictions Min            -3.7067316
Log Pis Mean                 -0.106391266
Log Pis Std                  2.1844819
Log Pis Max                  5.8438673
Log Pis Min                  -4.4212284
Policy mu Mean               0.012656282
Policy mu Std                0.88072115
Policy mu Max                2.6034734
Policy mu Min                -2.474374
Policy log std Mean          -0.4769772
Policy log std Std           0.3134988
Policy log std Max           0.10926212
Policy log std Min           -1.52477
Z mean eval                  0.03618317
Z variance eval              0.002759031
total_rewards                [606.22363691 635.89011096 622.24465032 609.31210375 629.42319876
 651.74039132 607.69891563 635.01935373 635.45405759 647.93697352]
total_rewards_mean           628.0943392488349
total_rewards_std            15.488122139140517
total_rewards_max            651.740391324938
total_rewards_min            606.2236369086104
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               29.56445282883942
(Previous) Eval Time (s)     3.9803637582808733
Sample Time (s)              14.502237536944449
Epoch Time (s)               48.04705412406474
Total Train Time (s)         1668.295399365481
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:18:14.948043 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #37 | Epoch Duration: 48.95096778869629
2020-01-11 13:18:14.948341 UTC | [2020_01_10_08_58_14] [2020_01_10_18_15_41] [2020_01_11_03_15_31] [2020_01_11_12_50_26] Iteration #37 | Started Training: True
