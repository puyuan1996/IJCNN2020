---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.002548047
Z variance train             0.6932094
KL Divergence                0.14910097
KL Loss                      0.014910097
QF Loss                      61.968273
VF Loss                      4.1619277
Policy Loss                  -1.9967742
Q Predictions Mean           -0.0011159198
Q Predictions Std            0.0010055336
Q Predictions Max            0.0007985224
Q Predictions Min            -0.0036676915
V Predictions Mean           -0.0064326786
V Predictions Std            0.0012013721
V Predictions Max            -0.0036854176
V Predictions Min            -0.009080635
Log Pis Mean                 -1.9825214
Log Pis Std                  0.38614535
Log Pis Max                  -0.9946431
Log Pis Min                  -2.7250185
Policy mu Mean               -0.0007236393
Policy mu Std                0.0012135297
Policy mu Max                0.0019941595
Policy mu Min                -0.0027270028
Policy log std Mean          -0.0008616333
Policy log std Std           0.0014184922
Policy log std Max           0.0025442091
Policy log std Min           -0.0030400897
Z mean eval                  0.022762287
Z variance eval              0.6356482
total_rewards                [ 52.72272451  58.7426038   69.41354343  77.93148053 107.76629929
  84.54759093  76.34710352  65.1918933   82.40579372  54.40140021]
total_rewards_mean           72.9470433250331
total_rewards_std            15.811971095951625
total_rewards_max            107.76629929365308
total_rewards_min            52.72272450866298
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               42.0583142740652
(Previous) Eval Time (s)     0
Sample Time (s)              20.886008612345904
Epoch Time (s)               62.9443228864111
Total Train Time (s)         64.45370300998911
Epoch                        0
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:49:23.879883 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #0 | Epoch Duration: 64.45666432380676
2020-01-11 00:49:23.880059 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #0 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022887094
Z variance train             0.635148
KL Divergence                0.22572637
KL Loss                      0.022572637
QF Loss                      506.06702
VF Loss                      2.8911517
Policy Loss                  -16.701
Q Predictions Mean           18.158396
Q Predictions Std            16.59718
Q Predictions Max            54.855183
Q Predictions Min            -6.234274
V Predictions Mean           18.086811
V Predictions Std            14.35644
V Predictions Max            49.240757
V Predictions Min            -4.834334
Log Pis Mean                 -1.5634636
Log Pis Std                  0.99866366
Log Pis Max                  1.3440974
Log Pis Min                  -4.8751106
Policy mu Mean               0.32240462
Policy mu Std                0.374735
Policy mu Max                1.0592791
Policy mu Min                -0.1693929
Policy log std Mean          -0.19679122
Policy log std Std           0.07595349
Policy log std Max           -0.08136284
Policy log std Min           -0.37462333
Z mean eval                  0.058517367
Z variance eval              0.35631126
total_rewards                [120.42337728 129.47873469 146.80159085  83.59653297  50.91755468
  62.76436669 145.93077371  73.08406429  69.6876797   95.90883297]
total_rewards_mean           97.8593507830777
total_rewards_std            33.5633815174503
total_rewards_max            146.80159084854049
total_rewards_min            50.917554682902484
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               42.57960775773972
(Previous) Eval Time (s)     1.5120530179701746
Sample Time (s)              14.555511630140245
Epoch Time (s)               58.64717240585014
Total Train Time (s)         123.30146887060255
Epoch                        1
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:50:22.731437 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #1 | Epoch Duration: 58.85111665725708
2020-01-11 00:50:22.731789 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #1 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05893644
Z variance train             0.36317673
KL Divergence                0.96696734
KL Loss                      0.096696734
QF Loss                      28.049644
VF Loss                      1.5121564
Policy Loss                  -13.847781
Q Predictions Mean           11.762515
Q Predictions Std            14.109618
Q Predictions Max            71.703316
Q Predictions Min            -4.8491035
V Predictions Mean           13.328485
V Predictions Std            13.727485
V Predictions Max            69.56121
V Predictions Min            -3.592905
Log Pis Mean                 -1.9290547
Log Pis Std                  0.6654309
Log Pis Max                  1.9169326
Log Pis Min                  -7.460696
Policy mu Mean               0.040064726
Policy mu Std                0.25760275
Policy mu Max                1.0961615
Policy mu Min                -0.38682395
Policy log std Mean          -0.16260014
Policy log std Std           0.08207769
Policy log std Max           -0.09087294
Policy log std Min           -0.47462445
Z mean eval                  0.10950021
Z variance eval              0.097213164
total_rewards                [100.48907649 132.16700251 128.97633935 170.38387411  75.08172984
 159.83186881  89.73994412  73.97779968  90.60013478  72.96219099]
total_rewards_mean           109.42099606657605
total_rewards_std            34.26881746795108
total_rewards_max            170.3838741060933
total_rewards_min            72.9621909863873
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               42.57091520773247
(Previous) Eval Time (s)     1.7157774749211967
Sample Time (s)              15.712058518081903
Epoch Time (s)               59.99875120073557
Total Train Time (s)         183.67286466807127
Epoch                        2
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:51:23.101935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #2 | Epoch Duration: 60.369953632354736
2020-01-11 00:51:23.102047 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #2 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.10486176
Z variance train             0.10086483
KL Divergence                3.5600724
KL Loss                      0.35600725
QF Loss                      19.315615
VF Loss                      3.0462332
Policy Loss                  -18.567387
Q Predictions Mean           16.16924
Q Predictions Std            23.572279
Q Predictions Max            115.91734
Q Predictions Min            -6.642402
V Predictions Mean           18.725002
V Predictions Std            23.874931
V Predictions Max            115.6776
V Predictions Min            -3.8995118
Log Pis Mean                 -1.7663541
Log Pis Std                  0.8331349
Log Pis Max                  2.31276
Log Pis Min                  -3.4284008
Policy mu Mean               0.09917376
Policy mu Std                0.32215914
Policy mu Max                1.5275053
Policy mu Min                -1.262656
Policy log std Mean          -0.1904914
Policy log std Std           0.13184522
Policy log std Max           -0.099466436
Policy log std Min           -0.74706405
Z mean eval                  0.07047607
Z variance eval              0.042333808
total_rewards                [145.76088671 103.53945042 119.30520091 113.66341656 126.47024152
  96.78259321 172.18550643  85.96397325 201.07376462 106.20464617]
total_rewards_mean           127.09496797858256
total_rewards_std            34.20201690632231
total_rewards_max            201.07376462056735
total_rewards_min            85.96397324562173
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               43.09359092870727
(Previous) Eval Time (s)     2.0868011177517474
Sample Time (s)              16.028693458531052
Epoch Time (s)               61.20908550499007
Total Train Time (s)         245.11072090035304
Epoch                        3
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:52:24.540558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #3 | Epoch Duration: 61.4384081363678
2020-01-11 00:52:24.540708 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #3 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07400391
Z variance train             0.04236172
KL Divergence                5.5488276
KL Loss                      0.55488276
QF Loss                      27.015799
VF Loss                      30.77782
Policy Loss                  -32.45594
Q Predictions Mean           30.366873
Q Predictions Std            43.218124
Q Predictions Max            169.95992
Q Predictions Min            -4.6500287
V Predictions Mean           29.19679
V Predictions Std            40.677273
V Predictions Max            152.52513
V Predictions Min            -4.9441204
Log Pis Mean                 -1.6220663
Log Pis Std                  1.0235163
Log Pis Max                  2.8672104
Log Pis Min                  -3.5631115
Policy mu Mean               0.14839786
Policy mu Std                0.3670606
Policy mu Max                1.8023995
Policy mu Min                -1.7391614
Policy log std Mean          -0.2184427
Policy log std Std           0.15950717
Policy log std Max           -0.1050425
Policy log std Min           -0.8991207
Z mean eval                  0.027715374
Z variance eval              0.0335674
total_rewards                [197.30390125 204.23775632 199.43683451 210.31126133 177.81393532
 181.23983339 198.45370367 236.25698205 215.96517317 205.07742819]
total_rewards_mean           202.6096809181551
total_rewards_std            15.828943667340585
total_rewards_max            236.2569820527553
total_rewards_min            177.813935321863
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               42.82674903282896
(Previous) Eval Time (s)     2.3158963546156883
Sample Time (s)              16.01842558570206
Epoch Time (s)               61.16107097314671
Total Train Time (s)         307.32772445725277
Epoch                        4
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:53:26.761048 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #4 | Epoch Duration: 62.22019696235657
2020-01-11 00:53:26.761247 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #4 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025860349
Z variance train             0.03331464
KL Divergence                6.098922
KL Loss                      0.6098922
QF Loss                      39.74733
VF Loss                      13.098613
Policy Loss                  -45.16471
Q Predictions Mean           42.980927
Q Predictions Std            56.897343
Q Predictions Max            194.1656
Q Predictions Min            -3.425336
V Predictions Mean           43.813454
V Predictions Std            55.985645
V Predictions Max            193.16939
V Predictions Min            -2.4341495
Log Pis Mean                 -1.4954481
Log Pis Std                  1.3205512
Log Pis Max                  4.1004558
Log Pis Min                  -3.8517752
Policy mu Mean               0.07069048
Policy mu Std                0.46020418
Policy mu Max                2.2708602
Policy mu Min                -1.8992499
Policy log std Mean          -0.236989
Policy log std Std           0.16578321
Policy log std Max           -0.080493174
Policy log std Min           -0.8133364
Z mean eval                  0.047725618
Z variance eval              0.01320378
total_rewards                [369.14890666 340.58758262 398.97603399 295.67474366 373.0700976
 393.16997787 364.30663646 336.76008693 340.43787218 413.41749581]
total_rewards_mean           362.55494337899484
total_rewards_std            33.34360235146826
total_rewards_max            413.4174958121909
total_rewards_min            295.67474365753475
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               43.13124636141583
(Previous) Eval Time (s)     3.3748117350041866
Sample Time (s)              17.46919958665967
Epoch Time (s)               63.97525768307969
Total Train Time (s)         373.7771719088778
Epoch                        5
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:54:33.209066 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #5 | Epoch Duration: 66.44765663146973
2020-01-11 00:54:33.209246 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #5 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044979863
Z variance train             0.013410742
KL Divergence                8.350897
KL Loss                      0.8350897
QF Loss                      64.22273
VF Loss                      17.21096
Policy Loss                  -64.273994
Q Predictions Mean           61.660507
Q Predictions Std            74.34466
Q Predictions Max            216.55466
Q Predictions Min            -7.7582755
V Predictions Mean           63.759846
V Predictions Std            76.5108
V Predictions Max            222.1864
V Predictions Min            -7.301541
Log Pis Mean                 -1.3142918
Log Pis Std                  1.2249726
Log Pis Max                  3.9138808
Log Pis Min                  -3.5331078
Policy mu Mean               0.043720786
Policy mu Std                0.55636704
Policy mu Max                2.090416
Policy mu Min                -2.2389867
Policy log std Mean          -0.26233074
Policy log std Std           0.17867605
Policy log std Max           -0.069169275
Policy log std Min           -0.86236906
Z mean eval                  0.03553063
Z variance eval              0.011980338
total_rewards                [314.38216741 299.54533748 275.58606178 262.32296204 280.72060263
 214.36916361 302.92482618 268.00119169 287.77296798 290.47275758]
total_rewards_mean           279.60980383767526
total_rewards_std            26.537020059028468
total_rewards_max            314.3821674064979
total_rewards_min            214.36916360934651
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               42.82732213800773
(Previous) Eval Time (s)     5.846996225882322
Sample Time (s)              20.514299772679806
Epoch Time (s)               69.18861813656986
Total Train Time (s)         440.5761480475776
Epoch                        6
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:55:40.009297 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #6 | Epoch Duration: 66.79992771148682
2020-01-11 00:55:40.009426 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #6 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034457
Z variance train             0.011964992
KL Divergence                8.623461
KL Loss                      0.8623461
QF Loss                      41.04029
VF Loss                      8.8553505
Policy Loss                  -85.46159
Q Predictions Mean           83.38358
Q Predictions Std            96.45495
Q Predictions Max            252.06769
Q Predictions Min            -6.7994175
V Predictions Mean           85.3501
V Predictions Std            95.628654
V Predictions Max            247.50108
V Predictions Min            -3.2008386
Log Pis Mean                 -1.3348966
Log Pis Std                  1.3514802
Log Pis Max                  5.823474
Log Pis Min                  -4.177545
Policy mu Mean               0.12917165
Policy mu Std                0.55484205
Policy mu Max                2.2114766
Policy mu Min                -2.5678778
Policy log std Mean          -0.29639474
Policy log std Std           0.22165652
Policy log std Max           -0.08380723
Policy log std Min           -0.9848344
Z mean eval                  0.048027795
Z variance eval              0.0073400117
total_rewards                [213.6500319  242.20642894 243.44250746 215.33874922 232.86073225
 250.1096136  221.08293784 226.84768403 242.41641554 213.46966321]
total_rewards_mean           230.14247640130506
total_rewards_std            13.195527655169764
total_rewards_max            250.10961360176805
total_rewards_min            213.46966321377565
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               42.002022413071245
(Previous) Eval Time (s)     3.4580928129144013
Sample Time (s)              16.126425464171916
Epoch Time (s)               61.58654069015756
Total Train Time (s)         502.14309348585084
Epoch                        7
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:56:41.576011 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #7 | Epoch Duration: 61.56647276878357
2020-01-11 00:56:41.576130 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #7 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047891673
Z variance train             0.0073281974
KL Divergence                9.853132
KL Loss                      0.98531324
QF Loss                      96.52278
VF Loss                      19.320087
Policy Loss                  -101.3295
Q Predictions Mean           98.43662
Q Predictions Std            113.65965
Q Predictions Max            300.37173
Q Predictions Min            -6.643599
V Predictions Mean           102.52481
V Predictions Std            114.880035
V Predictions Max            313.06137
V Predictions Min            -2.8439052
Log Pis Mean                 -1.1712298
Log Pis Std                  1.6844753
Log Pis Max                  8.803408
Log Pis Min                  -4.2343364
Policy mu Mean               0.06873101
Policy mu Std                0.6009538
Policy mu Max                2.3460734
Policy mu Min                -2.0776641
Policy log std Mean          -0.28417635
Policy log std Std           0.19597234
Policy log std Max           -0.062410463
Policy log std Min           -0.9228201
Z mean eval                  0.02462985
Z variance eval              0.007214494
total_rewards                [266.23353425 250.58230393 253.45358468 252.28284793 256.6301473
 258.04368277 235.87313628 267.58985103 252.14290206 245.23420492]
total_rewards_mean           253.80661951566776
total_rewards_std            8.837632533874022
total_rewards_max            267.58985103002607
total_rewards_min            235.8731362791663
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               42.92968117026612
(Previous) Eval Time (s)     3.437799734994769
Sample Time (s)              16.907732150517404
Epoch Time (s)               63.275213055778295
Total Train Time (s)         565.2045159833506
Epoch                        8
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:57:44.638930 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #8 | Epoch Duration: 63.06267309188843
2020-01-11 00:57:44.639088 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019653479
Z variance train             0.0072022206
KL Divergence                9.956795
KL Loss                      0.9956795
QF Loss                      70.29454
VF Loss                      36.330956
Policy Loss                  -133.07602
Q Predictions Mean           129.26112
Q Predictions Std            138.55115
Q Predictions Max            373.3022
Q Predictions Min            -6.774548
V Predictions Mean           135.57233
V Predictions Std            140.32352
V Predictions Max            381.50357
V Predictions Min            -4.1371217
Log Pis Mean                 -0.96115965
Log Pis Std                  1.889322
Log Pis Max                  7.7834625
Log Pis Min                  -4.3833323
Policy mu Mean               0.083553016
Policy mu Std                0.6447609
Policy mu Max                2.6123185
Policy mu Min                -2.416265
Policy log std Mean          -0.3257123
Policy log std Std           0.23912081
Policy log std Max           -0.06156874
Policy log std Min           -1.0364326
Z mean eval                  0.017193679
Z variance eval              0.004554008
total_rewards                [309.65117717 380.12376634 364.1604482  344.55704518 325.59720664
 332.81377106 356.69158199 362.39470187 359.75292855 363.62469933]
total_rewards_mean           349.93673263288866
total_rewards_std            20.336158843847148
total_rewards_max            380.1237663441661
total_rewards_min            309.651177168675
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               43.17888479027897
(Previous) Eval Time (s)     3.225041314959526
Sample Time (s)              17.06033064983785
Epoch Time (s)               63.46425675507635
Total Train Time (s)         630.0513907331042
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:58:49.486811 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #9 | Epoch Duration: 64.8476049900055
2020-01-11 00:58:49.486935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #9 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019715333
Z variance train             0.0046138754
KL Divergence                11.06102
KL Loss                      1.106102
QF Loss                      104.41266
VF Loss                      52.226578
Policy Loss                  -151.11108
Q Predictions Mean           148.79752
Q Predictions Std            164.16917
Q Predictions Max            423.4887
Q Predictions Min            -2.9751122
V Predictions Mean           148.30423
V Predictions Std            164.90695
V Predictions Max            427.45984
V Predictions Min            -6.171373
Log Pis Mean                 -1.1434801
Log Pis Std                  1.5307924
Log Pis Max                  5.0305557
Log Pis Min                  -4.02256
Policy mu Mean               -0.01853828
Policy mu Std                0.60299206
Policy mu Max                2.442542
Policy mu Min                -2.4818282
Policy log std Mean          -0.33414355
Policy log std Std           0.26003247
Policy log std Max           -0.011969872
Policy log std Min           -1.177952
Z mean eval                  0.0056226114
Z variance eval              0.004093374
total_rewards                [358.17657862 333.58275179 321.53208083 347.89666568 329.93307003
 319.4440957  318.47009587 316.89515403 317.88089698 321.2369409 ]
total_rewards_mean           328.5048330438315
total_rewards_std            13.476527310990608
total_rewards_max            358.17657862088817
total_rewards_min            316.8951540340466
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               42.40026440797374
(Previous) Eval Time (s)     4.608173854183406
Sample Time (s)              18.563131300732493
Epoch Time (s)               65.57156956288964
Total Train Time (s)         695.3658579783514
Epoch                        10
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 00:59:54.802662 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #10 | Epoch Duration: 65.31561994552612
2020-01-11 00:59:54.802819 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #10 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.004177173
Z variance train             0.004110822
KL Divergence                11.411509
KL Loss                      1.1411508
QF Loss                      115.82961
VF Loss                      38.48948
Policy Loss                  -171.92084
Q Predictions Mean           168.04999
Q Predictions Std            188.14833
Q Predictions Max            515.4407
Q Predictions Min            -7.0948353
V Predictions Mean           169.02014
V Predictions Std            187.20036
V Predictions Max            506.3312
V Predictions Min            -4.64075
Log Pis Mean                 -1.0610623
Log Pis Std                  1.6859462
Log Pis Max                  7.412961
Log Pis Min                  -3.702786
Policy mu Mean               0.002376706
Policy mu Std                0.62742716
Policy mu Max                1.9044183
Policy mu Min                -2.6398509
Policy log std Mean          -0.34498277
Policy log std Std           0.26603335
Policy log std Max           -0.00861828
Policy log std Min           -1.261339
Z mean eval                  0.008595196
Z variance eval              0.004700712
total_rewards                [318.69242677 330.004348   327.88857654 313.91721521 332.89818084
 323.77125236 303.61864069 318.5439021  322.79732807 323.96827604]
total_rewards_mean           321.6100146607547
total_rewards_std            8.060595458720112
total_rewards_max            332.8981808387702
total_rewards_min            303.61864068981663
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               42.61299475003034
(Previous) Eval Time (s)     4.351999145001173
Sample Time (s)              18.088790208566934
Epoch Time (s)               65.05378410359845
Total Train Time (s)         760.1459455895238
Epoch                        11
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:00:59.583084 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #11 | Epoch Duration: 64.7801263332367
2020-01-11 01:00:59.583241 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00796102
Z variance train             0.0047122394
KL Divergence                11.2337055
KL Loss                      1.1233705
QF Loss                      174.09824
VF Loss                      46.429558
Policy Loss                  -201.77606
Q Predictions Mean           196.2266
Q Predictions Std            214.21065
Q Predictions Max            590.7081
Q Predictions Min            -8.301851
V Predictions Mean           200.75497
V Predictions Std            214.0897
V Predictions Max            590.8506
V Predictions Min            -6.8189263
Log Pis Mean                 -0.8866652
Log Pis Std                  1.9872277
Log Pis Max                  8.598951
Log Pis Min                  -4.391849
Policy mu Mean               0.02672007
Policy mu Std                0.69856054
Policy mu Max                2.7052546
Policy mu Min                -2.3910172
Policy log std Mean          -0.33899578
Policy log std Std           0.26564547
Policy log std Max           -0.061904997
Policy log std Min           -1.2303361
Z mean eval                  0.023009155
Z variance eval              0.0048040156
total_rewards                [321.21186354 334.22752287 311.28499262 298.37978252 301.47259178
 301.06766156 316.90315589 323.57170273 302.87553428 312.40766271]
total_rewards_mean           312.3402470501509
total_rewards_std            11.115281080788002
total_rewards_max            334.22752287226825
total_rewards_min            298.37978251960106
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               42.70055721979588
(Previous) Eval Time (s)     4.078146122395992
Sample Time (s)              18.277465049177408
Epoch Time (s)               65.05616839136928
Total Train Time (s)         825.6071968702599
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:02:05.045340 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #12 | Epoch Duration: 65.46197390556335
2020-01-11 01:02:05.045465 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021157201
Z variance train             0.0047979853
KL Divergence                11.089777
KL Loss                      1.1089777
QF Loss                      65.02873
VF Loss                      38.960617
Policy Loss                  -216.7297
Q Predictions Mean           214.08871
Q Predictions Std            231.62047
Q Predictions Max            633.5849
Q Predictions Min            -8.622909
V Predictions Mean           214.12164
V Predictions Std            231.9639
V Predictions Max            635.4404
V Predictions Min            -6.704921
Log Pis Mean                 -1.0452847
Log Pis Std                  1.7070283
Log Pis Max                  6.8156896
Log Pis Min                  -9.342373
Policy mu Mean               0.042793225
Policy mu Std                0.65122443
Policy mu Max                2.5626895
Policy mu Min                -2.2723281
Policy log std Mean          -0.33192775
Policy log std Std           0.2589277
Policy log std Max           -0.050116338
Policy log std Min           -1.1725221
Z mean eval                  0.027454278
Z variance eval              0.0049862885
total_rewards                [316.33985367 305.83331918 306.6732994  297.32135663 316.56401804
 309.91005312 322.34220046 316.24306555 326.30590294 320.09041518]
total_rewards_mean           313.76234841742297
total_rewards_std            8.30612065872153
total_rewards_max            326.30590294313834
total_rewards_min            297.3213566347617
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               42.51369256898761
(Previous) Eval Time (s)     4.4837477072142065
Sample Time (s)              18.436657233163714
Epoch Time (s)               65.43409750936553
Total Train Time (s)         891.1220230902545
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:03:10.561292 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #13 | Epoch Duration: 65.51571035385132
2020-01-11 01:03:10.561499 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #13 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02150084
Z variance train             0.005182655
KL Divergence                10.943283
KL Loss                      1.0943283
QF Loss                      142.5987
VF Loss                      91.897835
Policy Loss                  -253.1161
Q Predictions Mean           252.81216
Q Predictions Std            254.76408
Q Predictions Max            690.32605
Q Predictions Min            -3.0066097
V Predictions Mean           257.50714
V Predictions Std            256.28534
V Predictions Max            701.4594
V Predictions Min            0.21328628
Log Pis Mean                 -0.9477788
Log Pis Std                  1.930403
Log Pis Max                  11.839958
Log Pis Min                  -4.743611
Policy mu Mean               -0.12722073
Policy mu Std                0.68976307
Policy mu Max                2.0796726
Policy mu Min                -3.43344
Policy log std Mean          -0.31380036
Policy log std Std           0.23078422
Policy log std Max           -0.011995867
Policy log std Min           -1.1607724
Z mean eval                  0.0076291626
Z variance eval              0.006484343
total_rewards                [292.4840175  285.93893934 273.97912548 289.21157302 297.50649766
 292.2228503  305.66049414 303.89237116 299.94559617 309.7673239 ]
total_rewards_mean           295.06087886806716
total_rewards_std            10.06492546398778
total_rewards_max            309.76732389995806
total_rewards_min            273.97912548208956
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               42.604704570025206
(Previous) Eval Time (s)     4.5651467042043805
Sample Time (s)              18.628663724288344
Epoch Time (s)               65.79851499851793
Total Train Time (s)         956.4039536528289
Epoch                        14
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:04:15.844881 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #14 | Epoch Duration: 65.2832396030426
2020-01-11 01:04:15.845009 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #14 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007263454
Z variance train             0.0065145297
KL Divergence                10.463398
KL Loss                      1.0463399
QF Loss                      185.39587
VF Loss                      49.462566
Policy Loss                  -252.17189
Q Predictions Mean           247.90823
Q Predictions Std            264.51993
Q Predictions Max            718.3282
Q Predictions Min            -7.529051
V Predictions Mean           253.59174
V Predictions Std            265.52448
V Predictions Max            731.35645
V Predictions Min            -6.3893414
Log Pis Mean                 -0.8732405
Log Pis Std                  1.8992456
Log Pis Max                  7.3934555
Log Pis Min                  -3.5883954
Policy mu Mean               0.14157583
Policy mu Std                0.68506134
Policy mu Max                2.5583024
Policy mu Min                -2.6738505
Policy log std Mean          -0.32821652
Policy log std Std           0.23839286
Policy log std Max           -0.022610083
Policy log std Min           -1.2722038
Z mean eval                  0.013158694
Z variance eval              0.005689989
total_rewards                [259.36064029 270.65510394 266.51830064 266.33091945 274.43102303
 256.66321084 269.65086943 259.4065337  268.81410562 267.92828539]
total_rewards_mean           265.97589923300944
total_rewards_std            5.411296761412618
total_rewards_max            274.4310230336515
total_rewards_min            256.66321084120676
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               42.64181221276522
(Previous) Eval Time (s)     4.04964980809018
Sample Time (s)              17.666434411425143
Epoch Time (s)               64.35789643228054
Total Train Time (s)         1020.3451589928009
Epoch                        15
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:05:19.785536 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #15 | Epoch Duration: 63.94043445587158
2020-01-11 01:05:19.785661 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #15 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012848017
Z variance train             0.005696933
KL Divergence                10.73341
KL Loss                      1.073341
QF Loss                      254.65082
VF Loss                      30.047932
Policy Loss                  -274.63397
Q Predictions Mean           272.0503
Q Predictions Std            287.7713
Q Predictions Max            802.03436
Q Predictions Min            -2.7564054
V Predictions Mean           274.78156
V Predictions Std            287.57654
V Predictions Max            792.00433
V Predictions Min            -6.0253887
Log Pis Mean                 -0.7092178
Log Pis Std                  2.2286608
Log Pis Max                  9.327732
Log Pis Min                  -5.5720096
Policy mu Mean               0.055247422
Policy mu Std                0.77890474
Policy mu Max                2.846027
Policy mu Min                -2.4330287
Policy log std Mean          -0.35381004
Policy log std Std           0.26240984
Policy log std Max           0.09881222
Policy log std Min           -1.3968091
Z mean eval                  0.02322068
Z variance eval              0.005872228
total_rewards                [268.05590162 294.33574187 296.48343454 278.75257811 298.1699824
 288.52671904 291.46725808 299.4888954  294.98455089 293.84178333]
total_rewards_mean           290.41068452879006
total_rewards_std            9.316174720432185
total_rewards_max            299.4888953962709
total_rewards_min            268.05590161997276
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               43.2498856568709
(Previous) Eval Time (s)     3.6319666621275246
Sample Time (s)              17.01214822381735
Epoch Time (s)               63.894000542815775
Total Train Time (s)         1084.7287002489902
Epoch                        16
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:06:24.169846 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #16 | Epoch Duration: 64.3840913772583
2020-01-11 01:06:24.169971 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #16 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023321515
Z variance train             0.005874302
KL Divergence                10.502974
KL Loss                      1.0502974
QF Loss                      296.36237
VF Loss                      43.57106
Policy Loss                  -298.16782
Q Predictions Mean           293.5833
Q Predictions Std            297.04477
Q Predictions Max            831.0693
Q Predictions Min            -21.100256
V Predictions Mean           300.22073
V Predictions Std            298.3506
V Predictions Max            853.5384
V Predictions Min            -2.0976257
Log Pis Mean                 -0.7373284
Log Pis Std                  1.9988502
Log Pis Max                  8.322564
Log Pis Min                  -6.875156
Policy mu Mean               0.15357979
Policy mu Std                0.7340337
Policy mu Max                2.351819
Policy mu Min                -2.5824244
Policy log std Mean          -0.38545296
Policy log std Std           0.2782265
Policy log std Max           0.06499432
Policy log std Min           -1.3863828
Z mean eval                  0.02347546
Z variance eval              0.0055736676
total_rewards                [282.8674179  270.5961457  271.47834192 280.05974533 283.23563905
 263.59605744 283.50254212 281.54873084 281.99282701 286.3024242 ]
total_rewards_mean           278.51798715075563
total_rewards_std            6.965846226247192
total_rewards_max            286.30242420185607
total_rewards_min            263.59605744042847
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               43.4298051581718
(Previous) Eval Time (s)     4.121852441225201
Sample Time (s)              18.071642375551164
Epoch Time (s)               65.62329997494817
Total Train Time (s)         1150.193984201178
Epoch                        17
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:07:29.635858 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #17 | Epoch Duration: 65.46579599380493
2020-01-11 01:07:29.635988 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #17 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024308793
Z variance train             0.0055724927
KL Divergence                10.541767
KL Loss                      1.0541767
QF Loss                      197.73795
VF Loss                      155.40555
Policy Loss                  -335.72876
Q Predictions Mean           329.61948
Q Predictions Std            315.82944
Q Predictions Max            873.31116
Q Predictions Min            -2.4249148
V Predictions Mean           328.1843
V Predictions Std            316.1622
V Predictions Max            871.2481
V Predictions Min            -4.150321
Log Pis Mean                 -0.36230895
Log Pis Std                  2.3730924
Log Pis Max                  9.696023
Log Pis Min                  -5.239225
Policy mu Mean               0.033301488
Policy mu Std                0.8133181
Policy mu Max                2.8396113
Policy mu Min                -2.8183136
Policy log std Mean          -0.39989066
Policy log std Std           0.28305313
Policy log std Max           -0.05030869
Policy log std Min           -1.5060626
Z mean eval                  0.019713137
Z variance eval              0.006305518
total_rewards                [284.30239035 293.36702125 292.97048538 280.69578132 286.15537921
 295.52909248 293.03984578 287.21428944 285.77833839 288.18125291]
total_rewards_mean           288.7233876520081
total_rewards_std            4.542879612101365
total_rewards_max            295.52909247616816
total_rewards_min            280.6957813194092
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               42.77646773215383
(Previous) Eval Time (s)     3.9641102328896523
Sample Time (s)              17.22710641566664
Epoch Time (s)               63.967684380710125
Total Train Time (s)         1214.1884068674408
Epoch                        18
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:08:33.630801 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #18 | Epoch Duration: 63.994717597961426
2020-01-11 01:08:33.630923 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #18 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02696592
Z variance train             0.0058173137
KL Divergence                10.475346
KL Loss                      1.0475346
QF Loss                      277.68
VF Loss                      141.12659
Policy Loss                  -345.66394
Q Predictions Mean           343.20505
Q Predictions Std            332.5283
Q Predictions Max            975.2222
Q Predictions Min            -0.8510184
V Predictions Mean           340.2035
V Predictions Std            329.0069
V Predictions Max            960.6439
V Predictions Min            -2.70333
Log Pis Mean                 -0.5662482
Log Pis Std                  2.048155
Log Pis Max                  8.217749
Log Pis Min                  -6.8515987
Policy mu Mean               0.096972786
Policy mu Std                0.7836365
Policy mu Max                2.2278197
Policy mu Min                -2.8982573
Policy log std Mean          -0.37657407
Policy log std Std           0.26403475
Policy log std Max           0.06464948
Policy log std Min           -1.5372537
Z mean eval                  0.020659292
Z variance eval              0.0048986166
total_rewards                [275.84427028 265.91733685 286.33239774 289.63687267 275.31956817
 277.59687741 304.69261642 296.78971945 278.29478043 194.57269029]
total_rewards_mean           274.4997129716213
total_rewards_std            28.75076161704442
total_rewards_max            304.6926164239698
total_rewards_min            194.5726902945691
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               43.12115132575855
(Previous) Eval Time (s)     3.990926319733262
Sample Time (s)              17.80968835297972
Epoch Time (s)               64.92176599847153
Total Train Time (s)         1279.2019095090218
Epoch                        19
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:09:38.645069 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #19 | Epoch Duration: 65.01405549049377
2020-01-11 01:09:38.645194 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #19 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024401035
Z variance train             0.004968148
KL Divergence                10.940388
KL Loss                      1.0940388
QF Loss                      185.27484
VF Loss                      206.8265
Policy Loss                  -331.7333
Q Predictions Mean           327.58667
Q Predictions Std            339.94287
Q Predictions Max            1011.4803
Q Predictions Min            -13.249999
V Predictions Mean           321.2171
V Predictions Std            336.9656
V Predictions Max            1000.1001
V Predictions Min            -9.95992
Log Pis Mean                 -0.8569813
Log Pis Std                  1.8362043
Log Pis Max                  6.259917
Log Pis Min                  -4.2804537
Policy mu Mean               0.117106594
Policy mu Std                0.7442459
Policy mu Max                2.6761153
Policy mu Min                -2.2155855
Policy log std Mean          -0.34907207
Policy log std Std           0.26395765
Policy log std Max           0.17088309
Policy log std Min           -1.3395658
Z mean eval                  0.017299939
Z variance eval              0.005542821
total_rewards                [264.40469911 265.92357821 290.7085007  281.80045262 278.47630878
 280.19813982 283.85104941 285.57620701 261.58545354 292.76903344]
total_rewards_mean           278.52934226459814
total_rewards_std            10.431076798622332
total_rewards_max            292.7690334405048
total_rewards_min            261.585453544754
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               43.942495323717594
(Previous) Eval Time (s)     4.083001311868429
Sample Time (s)              18.243206625804305
Epoch Time (s)               66.26870326139033
Total Train Time (s)         1345.1201590532437
Epoch                        20
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:10:44.566170 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #20 | Epoch Duration: 65.92086839675903
2020-01-11 01:10:44.566349 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #20 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016440235
Z variance train             0.0055593224
KL Divergence                10.74991
KL Loss                      1.0749911
QF Loss                      251.60602
VF Loss                      118.447525
Policy Loss                  -361.59665
Q Predictions Mean           358.2473
Q Predictions Std            348.64606
Q Predictions Max            947.05975
Q Predictions Min            -4.5889792
V Predictions Mean           363.9551
V Predictions Std            350.67294
V Predictions Max            959.82446
V Predictions Min            -5.0545263
Log Pis Mean                 -0.58805996
Log Pis Std                  2.1108441
Log Pis Max                  11.827343
Log Pis Min                  -3.7716074
Policy mu Mean               -0.033167556
Policy mu Std                0.7986542
Policy mu Max                2.5205803
Policy mu Min                -2.772466
Policy log std Mean          -0.37179327
Policy log std Std           0.2603102
Policy log std Max           -0.008419022
Policy log std Min           -1.340688
Z mean eval                  0.012611553
Z variance eval              0.0053414083
total_rewards                [293.57816643 351.42041455 247.98355612 338.2973362  333.13551701
 313.51914461 321.5323016  337.34803458 343.28293376 285.03714453]
total_rewards_mean           316.51345493810055
total_rewards_std            30.60604235903329
total_rewards_max            351.4204145466951
total_rewards_min            247.98355611838804
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               43.44930993625894
(Previous) Eval Time (s)     3.7349174530245364
Sample Time (s)              19.047372598666698
Epoch Time (s)               66.23159998795018
Total Train Time (s)         1411.500535596162
Epoch                        21
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:11:50.945980 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #21 | Epoch Duration: 66.3795018196106
2020-01-11 01:11:50.946102 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #21 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012303111
Z variance train             0.0053374423
KL Divergence                10.887085
KL Loss                      1.0887085
QF Loss                      268.01083
VF Loss                      157.39395
Policy Loss                  -325.09265
Q Predictions Mean           316.2039
Q Predictions Std            346.3969
Q Predictions Max            1025.7175
Q Predictions Min            -4.752026
V Predictions Mean           321.67673
V Predictions Std            347.6541
V Predictions Max            1026.1732
V Predictions Min            -2.422345
Log Pis Mean                 -0.52440673
Log Pis Std                  2.3787432
Log Pis Max                  15.150578
Log Pis Min                  -3.9567297
Policy mu Mean               0.13110405
Policy mu Std                0.83556134
Policy mu Max                3.6048112
Policy mu Min                -3.2749171
Policy log std Mean          -0.31904086
Policy log std Std           0.22796316
Policy log std Max           0.17061886
Policy log std Min           -1.2408988
Z mean eval                  0.022867128
Z variance eval              0.0050275186
total_rewards                [12.59661874 14.19190934 10.52755948 10.79421755 14.20928512 16.38787207
 16.28907679 14.11529834 15.71636841 12.24821547]
total_rewards_mean           13.707642131634397
total_rewards_std            2.0124619325157083
total_rewards_max            16.387872065399183
total_rewards_min            10.52755948468039
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               44.44064091797918
(Previous) Eval Time (s)     3.882602399215102
Sample Time (s)              17.335185119882226
Epoch Time (s)               65.65842843707651
Total Train Time (s)         1473.6564297494479
Epoch                        22
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:12:53.103601 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #22 | Epoch Duration: 62.15738773345947
2020-01-11 01:12:53.103754 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #22 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02196355
Z variance train             0.0050179223
KL Divergence                10.93099
KL Loss                      1.093099
QF Loss                      3520.109
VF Loss                      175.91411
Policy Loss                  -371.9574
Q Predictions Mean           375.31052
Q Predictions Std            370.2077
Q Predictions Max            1091.3102
Q Predictions Min            -7.326226
V Predictions Mean           377.57025
V Predictions Std            368.28867
V Predictions Max            1099.5425
V Predictions Min            -5.621961
Log Pis Mean                 -0.371269
Log Pis Std                  2.2742007
Log Pis Max                  15.205375
Log Pis Min                  -4.4854193
Policy mu Mean               0.1368047
Policy mu Std                0.8686733
Policy mu Max                3.5621274
Policy mu Min                -3.8501794
Policy log std Mean          -0.40519047
Policy log std Std           0.2834194
Policy log std Max           0.04951428
Policy log std Min           -1.3782841
Z mean eval                  0.010491111
Z variance eval              0.0043520257
total_rewards                [359.17797353 353.6522251  368.1506224  333.0841053  343.3257836
 347.45914261 365.66165972 381.76445812 371.73836212 352.9181783 ]
total_rewards_mean           357.6932510812538
total_rewards_std            13.81175973149391
total_rewards_max            381.76445811518425
total_rewards_min            333.08410530492836
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               42.82419019471854
(Previous) Eval Time (s)     0.3813630589284003
Sample Time (s)              17.35806670272723
Epoch Time (s)               60.56361995637417
Total Train Time (s)         1538.2163374209777
Epoch                        23
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:13:57.663674 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #23 | Epoch Duration: 64.55980396270752
2020-01-11 01:13:57.663797 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #23 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010388398
Z variance train             0.004349929
KL Divergence                11.344425
KL Loss                      1.1344426
QF Loss                      176.46466
VF Loss                      56.976315
Policy Loss                  -343.75217
Q Predictions Mean           338.94662
Q Predictions Std            373.7753
Q Predictions Max            1093.3987
Q Predictions Min            -3.6087635
V Predictions Mean           339.97263
V Predictions Std            373.03046
V Predictions Max            1117.3115
V Predictions Min            -3.670843
Log Pis Mean                 -0.39560813
Log Pis Std                  2.302365
Log Pis Max                  9.725986
Log Pis Min                  -4.67301
Policy mu Mean               0.17802875
Policy mu Std                0.83219993
Policy mu Max                3.7986562
Policy mu Min                -2.6492343
Policy log std Mean          -0.37319443
Policy log std Std           0.27556226
Policy log std Max           0.08420034
Policy log std Min           -1.4440372
Z mean eval                  0.0121588
Z variance eval              0.003605099
total_rewards                [363.33957062 345.55841822 375.44648292 364.20592721 365.52237546
 376.37051538 364.62688364 354.31723675 365.1994599  375.45798739]
total_rewards_mean           365.00448574966356
total_rewards_std            9.185439078926107
total_rewards_max            376.37051538057915
total_rewards_min            345.5584182163001
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               42.873220172245055
(Previous) Eval Time (s)     4.377347290981561
Sample Time (s)              18.23577706515789
Epoch Time (s)               65.4863445283845
Total Train Time (s)         1603.749330945313
Epoch                        24
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:15:03.197231 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #24 | Epoch Duration: 65.53334093093872
2020-01-11 01:15:03.197348 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #24 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013424188
Z variance train             0.003599159
KL Divergence                11.67783
KL Loss                      1.167783
QF Loss                      304.41336
VF Loss                      270.4656
Policy Loss                  -396.14096
Q Predictions Mean           392.21356
Q Predictions Std            383.07544
Q Predictions Max            1136.7172
Q Predictions Min            -5.842915
V Predictions Mean           401.61276
V Predictions Std            382.46136
V Predictions Max            1152.9336
V Predictions Min            -4.718262
Log Pis Mean                 -0.25098112
Log Pis Std                  2.329172
Log Pis Max                  10.955662
Log Pis Min                  -4.149771
Policy mu Mean               0.14137149
Policy mu Std                0.8689306
Policy mu Max                3.3224099
Policy mu Min                -2.5204942
Policy log std Mean          -0.39824876
Policy log std Std           0.26131046
Policy log std Max           0.13104972
Policy log std Min           -1.2700903
Z mean eval                  0.018360967
Z variance eval              0.0040744725
total_rewards                [376.36206984 369.7235597  369.84126989 369.22812931 379.0296252
 336.09817916 382.99232583 378.66922193 343.9242045  348.70520543]
total_rewards_mean           365.45737907918834
total_rewards_std            15.630285335490573
total_rewards_max            382.992325834966
total_rewards_min            336.09817916381917
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               42.87263482995331
(Previous) Eval Time (s)     4.424130995757878
Sample Time (s)              18.40776971913874
Epoch Time (s)               65.70453554484993
Total Train Time (s)         1669.3012054935098
Epoch                        25
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:16:08.752420 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #25 | Epoch Duration: 65.55494976043701
2020-01-11 01:16:08.752647 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #25 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018073967
Z variance train             0.0040753055
KL Divergence                11.472614
KL Loss                      1.1472615
QF Loss                      236.84164
VF Loss                      91.70015
Policy Loss                  -397.04797
Q Predictions Mean           395.0681
Q Predictions Std            388.44376
Q Predictions Max            1054.5941
Q Predictions Min            -5.3379726
V Predictions Mean           399.0752
V Predictions Std            389.52567
V Predictions Max            1056.6606
V Predictions Min            -1.7135657
Log Pis Mean                 -0.27207503
Log Pis Std                  2.3012707
Log Pis Max                  8.937049
Log Pis Min                  -4.0243096
Policy mu Mean               0.17048347
Policy mu Std                0.8546295
Policy mu Max                3.4877841
Policy mu Min                -2.8824172
Policy log std Mean          -0.4285991
Policy log std Std           0.2973985
Policy log std Max           -0.0013134629
Policy log std Min           -1.6941234
Z mean eval                  0.009314334
Z variance eval              0.0038446852
total_rewards                [269.43186593 302.18564393 314.78577019 289.30373261 377.61757431
 319.94796383 312.67575187 348.20966206 341.00000191 327.57133377]
total_rewards_mean           320.2729300412254
total_rewards_std            29.173162286724448
total_rewards_max            377.61757430906744
total_rewards_min            269.4318659318609
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               43.358547064010054
(Previous) Eval Time (s)     4.274287790991366
Sample Time (s)              18.704591517802328
Epoch Time (s)               66.33742637280375
Total Train Time (s)         1735.2768317386508
Epoch                        26
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:17:14.729049 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #26 | Epoch Duration: 65.97620844841003
2020-01-11 01:17:14.729287 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #26 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008446088
Z variance train             0.0038482337
KL Divergence                11.6225395
KL Loss                      1.162254
QF Loss                      200.3642
VF Loss                      179.02805
Policy Loss                  -415.38373
Q Predictions Mean           412.51263
Q Predictions Std            407.14325
Q Predictions Max            1190.2017
Q Predictions Min            -14.627888
V Predictions Mean           422.5403
V Predictions Std            409.58002
V Predictions Max            1213.27
V Predictions Min            -2.4485767
Log Pis Mean                 -0.1793864
Log Pis Std                  2.2366238
Log Pis Max                  8.88416
Log Pis Min                  -3.4637685
Policy mu Mean               0.2356954
Policy mu Std                0.81730783
Policy mu Max                2.2448015
Policy mu Min                -3.2494135
Policy log std Mean          -0.4066583
Policy log std Std           0.2979493
Policy log std Max           0.22834975
Policy log std Min           -1.5501064
Z mean eval                  0.024121188
Z variance eval              0.0046162913
total_rewards                [336.71183709 330.76707049 329.70834326 325.40832695 325.43638118
 326.10532788 314.32546853 284.48168484 313.05673426 340.21897498]
total_rewards_mean           322.6220149472398
total_rewards_std            15.058432147832464
total_rewards_max            340.2189749804981
total_rewards_min            284.48168484460143
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               43.266701120883226
(Previous) Eval Time (s)     3.9128549909219146
Sample Time (s)              17.881803908385336
Epoch Time (s)               65.06136002019048
Total Train Time (s)         1801.0194629658945
Epoch                        27
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:18:20.472398 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #27 | Epoch Duration: 65.74290537834167
2020-01-11 01:18:20.472597 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #27 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023040753
Z variance train             0.0046190647
KL Divergence                11.45462
KL Loss                      1.145462
QF Loss                      264.0789
VF Loss                      153.60533
Policy Loss                  -435.03235
Q Predictions Mean           432.5053
Q Predictions Std            401.47623
Q Predictions Max            1069.2188
Q Predictions Min            -6.7281337
V Predictions Mean           438.59656
V Predictions Std            403.3902
V Predictions Max            1065.1051
V Predictions Min            -13.89917
Log Pis Mean                 -0.21207327
Log Pis Std                  2.4121711
Log Pis Max                  11.243003
Log Pis Min                  -5.6833315
Policy mu Mean               0.13607219
Policy mu Std                0.8729267
Policy mu Max                3.2449374
Policy mu Min                -3.0896769
Policy log std Mean          -0.4171745
Policy log std Std           0.29602784
Policy log std Max           0.14364412
Policy log std Min           -1.4452734
Z mean eval                  0.020795235
Z variance eval              0.004773562
total_rewards                [245.83479647 349.12312487 344.82527294 344.31900169 316.77967834
 362.03768572 333.64007551 319.6798897  350.18912442 309.4805072 ]
total_rewards_mean           327.59091568630896
total_rewards_std            31.568744687049684
total_rewards_max            362.0376857197138
total_rewards_min            245.8347964740085
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               42.66632713517174
(Previous) Eval Time (s)     4.5941848694346845
Sample Time (s)              18.509559345897287
Epoch Time (s)               65.77007135050371
Total Train Time (s)         1866.3528139744885
Epoch                        28
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:19:25.806158 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #28 | Epoch Duration: 65.33341407775879
2020-01-11 01:19:25.806273 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #28 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021097342
Z variance train             0.0047762142
KL Divergence                11.170302
KL Loss                      1.1170303
QF Loss                      222.20616
VF Loss                      92.200424
Policy Loss                  -443.78955
Q Predictions Mean           436.5593
Q Predictions Std            402.34982
Q Predictions Max            965.11334
Q Predictions Min            -10.828359
V Predictions Mean           440.0823
V Predictions Std            402.49774
V Predictions Max            981.2879
V Predictions Min            -12.890979
Log Pis Mean                 -0.31421176
Log Pis Std                  2.1970487
Log Pis Max                  9.838295
Log Pis Min                  -5.8715076
Policy mu Mean               -0.0766683
Policy mu Std                0.8606547
Policy mu Max                2.9523265
Policy mu Min                -2.8532727
Policy log std Mean          -0.42006025
Policy log std Std           0.29923454
Policy log std Max           0.15023021
Policy log std Min           -1.6329576
Z mean eval                  0.033177815
Z variance eval              0.004575518
total_rewards                [339.65857826 368.62724773 349.16373903 318.88564371 356.10387049
 345.11475775 347.09623239 347.52448898 346.1522907  341.75074047]
total_rewards_mean           346.0077589501217
total_rewards_std            11.924260870388538
total_rewards_max            368.62724772911105
total_rewards_min            318.8856437089496
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               42.89284147089347
(Previous) Eval Time (s)     4.157326876185834
Sample Time (s)              18.11052758479491
Epoch Time (s)               65.16069593187422
Total Train Time (s)         1931.8717474979348
Epoch                        29
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:20:31.327135 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #29 | Epoch Duration: 65.52074837684631
2020-01-11 01:20:31.327333 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #29 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034066163
Z variance train             0.004576975
KL Divergence                11.269543
KL Loss                      1.1269543
QF Loss                      509.78662
VF Loss                      116.217636
Policy Loss                  -396.9029
Q Predictions Mean           391.86047
Q Predictions Std            407.1625
Q Predictions Max            1087.3529
Q Predictions Min            -8.4288435
V Predictions Mean           393.19647
V Predictions Std            407.7807
V Predictions Max            1108.8999
V Predictions Min            -3.1747231
Log Pis Mean                 -0.4819992
Log Pis Std                  2.072816
Log Pis Max                  5.6814356
Log Pis Min                  -5.6363173
Policy mu Mean               0.16657129
Policy mu Std                0.8034828
Policy mu Max                2.1948001
Policy mu Min                -2.8856404
Policy log std Mean          -0.3620688
Policy log std Std           0.26785338
Policy log std Max           0.1457937
Policy log std Min           -1.494106
Z mean eval                  0.037455782
Z variance eval              0.0044949586
total_rewards                [381.8219209  419.17014045 353.02803704 382.43100028 365.7486692
 309.17739773 362.16261106 352.80161634 329.55469453 347.26901122]
total_rewards_mean           360.3165098735978
total_rewards_std            28.791544630539445
total_rewards_max            419.1701404500007
total_rewards_min            309.17739772560435
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               43.79511395795271
(Previous) Eval Time (s)     4.517123182769865
Sample Time (s)              18.70404778327793
Epoch Time (s)               67.0162849240005
Total Train Time (s)         1999.1007020710967
Epoch                        30
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:21:38.557338 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #30 | Epoch Duration: 67.22984719276428
2020-01-11 01:21:38.557507 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #30 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036742084
Z variance train             0.0044973777
KL Divergence                11.416101
KL Loss                      1.1416101
QF Loss                      190.81473
VF Loss                      153.68265
Policy Loss                  -413.56647
Q Predictions Mean           411.51566
Q Predictions Std            399.10898
Q Predictions Max            963.9843
Q Predictions Min            -3.1574388
V Predictions Mean           421.76578
V Predictions Std            401.32364
V Predictions Max            983.91
V Predictions Min            -2.0765688
Log Pis Mean                 -0.3439216
Log Pis Std                  2.3272324
Log Pis Max                  9.560952
Log Pis Min                  -4.6316566
Policy mu Mean               -0.085614
Policy mu Std                0.8534161
Policy mu Max                3.1161559
Policy mu Min                -3.3640237
Policy log std Mean          -0.35103193
Policy log std Std           0.2800344
Policy log std Max           0.36515826
Policy log std Min           -1.6068685
Z mean eval                  0.022849564
Z variance eval              0.004277271
total_rewards                [308.07370945 390.97161855 383.13469129 395.6529762  356.02581384
 366.12860713 332.1611618  362.64242299 304.37781659 405.52070054]
total_rewards_mean           360.4689518362753
total_rewards_std            33.854141635065936
total_rewards_max            405.5207005372041
total_rewards_min            304.37781658545117
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               42.366404841654
(Previous) Eval Time (s)     4.730459088925272
Sample Time (s)              18.695763608906418
Epoch Time (s)               65.7926275394857
Total Train Time (s)         2064.970345825888
Epoch                        31
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:22:44.427120 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #31 | Epoch Duration: 65.8694703578949
2020-01-11 01:22:44.427277 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #31 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022014052
Z variance train             0.00427572
KL Divergence                11.554427
KL Loss                      1.1554427
QF Loss                      217.32831
VF Loss                      96.826515
Policy Loss                  -419.55124
Q Predictions Mean           418.00412
Q Predictions Std            400.5514
Q Predictions Max            1162.9525
Q Predictions Min            -6.8190875
V Predictions Mean           421.7068
V Predictions Std            401.6731
V Predictions Max            1160.9591
V Predictions Min            -5.119766
Log Pis Mean                 -0.28021842
Log Pis Std                  2.368799
Log Pis Max                  10.708384
Log Pis Min                  -3.788486
Policy mu Mean               -0.036941808
Policy mu Std                0.8792493
Policy mu Max                2.3263628
Policy mu Min                -3.1747613
Policy log std Mean          -0.3837631
Policy log std Std           0.2530506
Policy log std Max           0.078206986
Policy log std Min           -1.5628015
Z mean eval                  0.014279721
Z variance eval              0.0039156205
total_rewards                [382.47131262 379.92267367 382.02948728 409.61725756 399.17762698
 367.95104316 372.90148266 390.79882037 365.24134894 389.53579762]
total_rewards_mean           383.9646850864192
total_rewards_std            13.110828637360195
total_rewards_max            409.61725755955007
total_rewards_min            365.2413489401139
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               42.01888927957043
(Previous) Eval Time (s)     4.807049966882914
Sample Time (s)              19.83969791326672
Epoch Time (s)               66.66563715972006
Total Train Time (s)         2131.6110398168676
Epoch                        32
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:23:51.071677 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #32 | Epoch Duration: 66.64423489570618
2020-01-11 01:23:51.071942 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #32 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015490375
Z variance train             0.0039138533
KL Divergence                11.712764
KL Loss                      1.1712765
QF Loss                      592.36523
VF Loss                      203.35706
Policy Loss                  -407.74814
Q Predictions Mean           401.45715
Q Predictions Std            394.581
Q Predictions Max            1068.9088
Q Predictions Min            -1.3291191
V Predictions Mean           401.8091
V Predictions Std            393.34888
V Predictions Max            1072.5726
V Predictions Min            1.1503882
Log Pis Mean                 -0.042437226
Log Pis Std                  2.643687
Log Pis Max                  11.696726
Log Pis Min                  -5.9207387
Policy mu Mean               0.04816881
Policy mu Std                0.94542605
Policy mu Max                2.726316
Policy mu Min                -3.2563195
Policy log std Mean          -0.4034671
Policy log std Std           0.27834386
Policy log std Max           -0.0056670904
Policy log std Min           -1.6975585
Z mean eval                  0.015896505
Z variance eval              0.005093787
total_rewards                [375.42203788 384.53691413 397.52640981 397.51400533 396.78805623
 382.18458675 389.21103519 397.74248411 410.90944237 394.00515055]
total_rewards_mean           392.5840122342171
total_rewards_std            9.537668182886387
total_rewards_max            410.90944236541134
total_rewards_min            375.42203787651187
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               42.19131897203624
(Previous) Eval Time (s)     4.785404220689088
Sample Time (s)              16.980341699440032
Epoch Time (s)               63.95706489216536
Total Train Time (s)         2195.0565707888454
Epoch                        33
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:24:54.519951 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #33 | Epoch Duration: 63.44758200645447
2020-01-11 01:24:54.520287 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #33 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01696066
Z variance train             0.005122919
KL Divergence                10.771841
KL Loss                      1.0771841
QF Loss                      122.078964
VF Loss                      187.7569
Policy Loss                  -417.60117
Q Predictions Mean           413.66394
Q Predictions Std            408.04794
Q Predictions Max            1043.3536
Q Predictions Min            -3.7079365
V Predictions Mean           411.07614
V Predictions Std            403.47522
V Predictions Max            1041.7825
V Predictions Min            -5.923097
Log Pis Mean                 -0.4038285
Log Pis Std                  1.9622717
Log Pis Max                  5.9498997
Log Pis Min                  -5.0472593
Policy mu Mean               -0.047773954
Policy mu Std                0.8088772
Policy mu Max                2.0414221
Policy mu Min                -2.188765
Policy log std Mean          -0.38406196
Policy log std Std           0.27256468
Policy log std Max           0.20305385
Policy log std Min           -1.599534
Z mean eval                  0.029310826
Z variance eval              0.0050136317
total_rewards                [353.59885041 385.04522652 421.45623429 387.99667685 400.79637037
 386.62344502 420.4057478  392.2736201  385.41344623 391.4527575 ]
total_rewards_mean           392.5062375084879
total_rewards_std            18.333242351517917
total_rewards_max            421.4562342917257
total_rewards_min            353.5988504070696
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               43.14977333927527
(Previous) Eval Time (s)     4.275713269133121
Sample Time (s)              18.55834493553266
Epoch Time (s)               65.98383154394105
Total Train Time (s)         2261.5589841613546
Epoch                        34
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:26:01.021782 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #34 | Epoch Duration: 66.50132632255554
2020-01-11 01:26:01.021899 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #34 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030870136
Z variance train             0.0050229
KL Divergence                10.984842
KL Loss                      1.0984843
QF Loss                      219.38127
VF Loss                      249.41397
Policy Loss                  -412.34283
Q Predictions Mean           405.84915
Q Predictions Std            413.85403
Q Predictions Max            1141.8507
Q Predictions Min            -20.765102
V Predictions Mean           422.86386
V Predictions Std            423.10263
V Predictions Max            1154.264
V Predictions Min            -0.4258219
Log Pis Mean                 -0.37957567
Log Pis Std                  2.111978
Log Pis Max                  6.6733804
Log Pis Min                  -3.3484294
Policy mu Mean               0.099910915
Policy mu Std                0.84141403
Policy mu Max                2.929663
Policy mu Min                -2.4748793
Policy log std Mean          -0.38074222
Policy log std Std           0.26308832
Policy log std Max           0.16355252
Policy log std Min           -1.5459076
Z mean eval                  0.012198259
Z variance eval              0.0051793316
total_rewards                [392.3041232  384.07907431 386.47302361 393.0075695  364.24856959
 379.80887679 372.04988173 385.99068832 403.45116972 387.44144704]
total_rewards_mean           384.8854423807226
total_rewards_std            10.454764615176925
total_rewards_max            403.4511697197776
total_rewards_min            364.24856959379775
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               43.04754499020055
(Previous) Eval Time (s)     4.793000048957765
Sample Time (s)              18.740132255479693
Epoch Time (s)               66.58067729463801
Total Train Time (s)         2328.7197174169123
Epoch                        35
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:27:08.183310 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #35 | Epoch Duration: 67.16130948066711
2020-01-11 01:27:08.183474 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #35 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012346586
Z variance train             0.0051762904
KL Divergence                10.803241
KL Loss                      1.080324
QF Loss                      165.53952
VF Loss                      34.1538
Policy Loss                  -394.02686
Q Predictions Mean           390.74033
Q Predictions Std            401.54608
Q Predictions Max            1029.1688
Q Predictions Min            -3.532654
V Predictions Mean           394.60168
V Predictions Std            403.47507
V Predictions Max            1066.5175
V Predictions Min            -2.5381496
Log Pis Mean                 -0.60692286
Log Pis Std                  1.9281405
Log Pis Max                  7.8409615
Log Pis Min                  -3.2386186
Policy mu Mean               -0.03449333
Policy mu Std                0.798049
Policy mu Max                2.0453432
Policy mu Min                -3.5099893
Policy log std Mean          -0.38554403
Policy log std Std           0.28476626
Policy log std Max           0.16889864
Policy log std Min           -1.3963442
Z mean eval                  0.01639281
Z variance eval              0.004279819
total_rewards                [406.14147492 398.85871892 661.56857049 385.900505   401.21110767
 393.37145511 388.5839832  648.90923191 396.92157806 592.8935842 ]
total_rewards_mean           467.4360209488861
total_rewards_std            110.69268761724763
total_rewards_max            661.5685704909907
total_rewards_min            385.90050499701414
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               42.779598681721836
(Previous) Eval Time (s)     5.373376282863319
Sample Time (s)              19.034571080934256
Epoch Time (s)               67.18754604551941
Total Train Time (s)         2395.993558176793
Epoch                        36
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:28:15.457711 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #36 | Epoch Duration: 67.27412033081055
2020-01-11 01:28:15.457832 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #36 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015972635
Z variance train             0.004286496
KL Divergence                11.21114
KL Loss                      1.121114
QF Loss                      484.65024
VF Loss                      32.854687
Policy Loss                  -423.62552
Q Predictions Mean           422.80038
Q Predictions Std            415.11343
Q Predictions Max            1200.1962
Q Predictions Min            -10.667946
V Predictions Mean           423.81946
V Predictions Std            413.9793
V Predictions Max            1229.2208
V Predictions Min            -5.620592
Log Pis Mean                 -0.46886683
Log Pis Std                  2.1875412
Log Pis Max                  10.168211
Log Pis Min                  -4.4370394
Policy mu Mean               0.003082461
Policy mu Std                0.80021036
Policy mu Max                2.188225
Policy mu Min                -3.4546778
Policy log std Mean          -0.34733215
Policy log std Std           0.2587643
Policy log std Max           0.2337728
Policy log std Min           -1.2995305
Z mean eval                  0.017378366
Z variance eval              0.005115079
total_rewards                [390.39863455 497.01759194 440.84419258 276.42217682 406.55399808
 599.75583864 370.3375303  413.9810019  296.00054116 411.52834669]
total_rewards_mean           410.28398526554247
total_rewards_std            87.95236948795386
total_rewards_max            599.7558386367057
total_rewards_min            276.4221768162628
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               44.2015216499567
(Previous) Eval Time (s)     5.459710001945496
Sample Time (s)              19.394491232465953
Epoch Time (s)               69.05572288436815
Total Train Time (s)         2464.886104705278
Epoch                        37
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:29:24.351417 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #37 | Epoch Duration: 68.89349174499512
2020-01-11 01:29:24.351547 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #37 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016844984
Z variance train             0.0051322235
KL Divergence                10.953791
KL Loss                      1.0953791
QF Loss                      268.3354
VF Loss                      53.89119
Policy Loss                  -452.3595
Q Predictions Mean           452.99112
Q Predictions Std            405.2808
Q Predictions Max            1054.7072
Q Predictions Min            -2.5494182
V Predictions Mean           454.537
V Predictions Std            403.69998
V Predictions Max            1060.8036
V Predictions Min            -5.5673018
Log Pis Mean                 -0.35298654
Log Pis Std                  2.1252437
Log Pis Max                  11.451529
Log Pis Min                  -5.1811624
Policy mu Mean               -0.10830144
Policy mu Std                0.8521135
Policy mu Max                2.866182
Policy mu Min                -3.5533736
Policy log std Mean          -0.39444053
Policy log std Std           0.2662602
Policy log std Max           0.17204262
Policy log std Min           -1.3535266
Z mean eval                  0.033077955
Z variance eval              0.005003172
total_rewards                [367.84759865 338.53877988 370.27753895 365.78585932 377.88834083
 386.16449387 368.42018288 382.93723    382.19525987 377.40100642]
total_rewards_mean           371.74562906699083
total_rewards_std            12.956422302250587
total_rewards_max            386.1644938749317
total_rewards_min            338.53877988039
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               44.011110371910036
(Previous) Eval Time (s)     5.2972471178509295
Sample Time (s)              19.284314948599786
Epoch Time (s)               68.59267243836075
Total Train Time (s)         2532.784919743426
Epoch                        38
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:30:32.251018 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #38 | Epoch Duration: 67.8993752002716
2020-01-11 01:30:32.251141 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #38 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03805209
Z variance train             0.0052486556
KL Divergence                10.690157
KL Loss                      1.0690157
QF Loss                      1102.9684
VF Loss                      69.85658
Policy Loss                  -460.67874
Q Predictions Mean           461.10168
Q Predictions Std            409.4876
Q Predictions Max            1210.3645
Q Predictions Min            0.1854645
V Predictions Mean           460.03412
V Predictions Std            408.08444
V Predictions Max            1214.1073
V Predictions Min            -11.740226
Log Pis Mean                 -0.79237294
Log Pis Std                  2.019434
Log Pis Max                  8.735056
Log Pis Min                  -7.1170893
Policy mu Mean               0.0858776
Policy mu Std                0.7888661
Policy mu Max                2.4005833
Policy mu Min                -2.5068622
Policy log std Mean          -0.35733438
Policy log std Std           0.24615744
Policy log std Max           0.22435059
Policy log std Min           -1.39111
Z mean eval                  0.017812507
Z variance eval              0.007672581
total_rewards                [401.11238249 434.23882319 611.63935046 400.66960735 491.71280541
 421.53712219 428.15142347 444.17344445 484.00021004 406.76321331]
total_rewards_mean           452.3998382379897
total_rewards_std            61.01510096773023
total_rewards_max            611.6393504623142
total_rewards_min            400.6696073503055
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               42.33221886213869
(Previous) Eval Time (s)     4.603734041098505
Sample Time (s)              18.788677617441863
Epoch Time (s)               65.72463052067906
Total Train Time (s)         2599.225456314627
Epoch                        39
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:31:38.694951 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #39 | Epoch Duration: 66.44368386268616
2020-01-11 01:31:38.695189 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #39 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02367672
Z variance train             0.008318467
KL Divergence                9.506746
KL Loss                      0.95067465
QF Loss                      246.47699
VF Loss                      42.63679
Policy Loss                  -457.9126
Q Predictions Mean           459.77512
Q Predictions Std            418.22055
Q Predictions Max            1114.6475
Q Predictions Min            -4.3386374
V Predictions Mean           459.56775
V Predictions Std            417.99643
V Predictions Max            1153.6757
V Predictions Min            -6.454384
Log Pis Mean                 -0.6320921
Log Pis Std                  1.8204395
Log Pis Max                  5.6423984
Log Pis Min                  -4.1680336
Policy mu Mean               0.075292595
Policy mu Std                0.761617
Policy mu Max                2.417359
Policy mu Min                -2.1729543
Policy log std Mean          -0.3576784
Policy log std Std           0.24447173
Policy log std Max           0.4409817
Policy log std Min           -1.2264496
Z mean eval                  0.059397817
Z variance eval              0.0070499266
total_rewards                [398.19149179 484.87783941 411.04841987 428.54843167 405.19138922
 438.53376445 597.26722893 559.24041544 567.2654733  543.87729656]
total_rewards_mean           483.40417506480725
total_rewards_std            72.83139484053625
total_rewards_max            597.2672289337651
total_rewards_min            398.19149179234785
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               43.326066293753684
(Previous) Eval Time (s)     5.322561010718346
Sample Time (s)              19.16995286522433
Epoch Time (s)               67.81858016969636
Total Train Time (s)         2667.1646085772663
Epoch                        40
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:32:46.633748 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #40 | Epoch Duration: 67.93838930130005
2020-01-11 01:32:46.633867 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #40 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019012386
Z variance train             0.005090923
KL Divergence                10.797869
KL Loss                      1.0797869
QF Loss                      124.38066
VF Loss                      199.00783
Policy Loss                  -440.0881
Q Predictions Mean           436.43164
Q Predictions Std            410.2325
Q Predictions Max            1191.7325
Q Predictions Min            -9.54427
V Predictions Mean           440.72485
V Predictions Std            410.26755
V Predictions Max            1174.2062
V Predictions Min            -0.29267353
Log Pis Mean                 -0.55720466
Log Pis Std                  2.032797
Log Pis Max                  8.507336
Log Pis Min                  -5.696212
Policy mu Mean               -0.09580483
Policy mu Std                0.8058943
Policy mu Max                2.6492672
Policy mu Min                -2.9756205
Policy log std Mean          -0.3749222
Policy log std Std           0.25677532
Policy log std Max           0.15853213
Policy log std Min           -1.5146273
Z mean eval                  0.053976722
Z variance eval              0.0049466295
total_rewards                [608.76161852 803.4775401  617.77979518 629.33987435 661.0272475
 291.51895106 620.03347267 570.73308153 771.9936988  629.82568126]
total_rewards_mean           620.4490960981659
total_rewards_std            130.03436008958286
total_rewards_max            803.4775401010229
total_rewards_min            291.5189510639785
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               42.73999550007284
(Previous) Eval Time (s)     5.4421834028325975
Sample Time (s)              19.826370656490326
Epoch Time (s)               68.00854955939576
Total Train Time (s)         2737.021925165318
Epoch                        41
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:33:56.495473 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #41 | Epoch Duration: 69.86146211624146
2020-01-11 01:33:56.495759 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #41 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040383846
Z variance train             0.0044293916
KL Divergence                11.1426115
KL Loss                      1.1142612
QF Loss                      204.3457
VF Loss                      114.80572
Policy Loss                  -523.398
Q Predictions Mean           524.3642
Q Predictions Std            428.60092
Q Predictions Max            1614.7313
Q Predictions Min            -2.5425541
V Predictions Mean           522.7245
V Predictions Std            425.77777
V Predictions Max            1588.8257
V Predictions Min            -0.85931575
Log Pis Mean                 -0.52444
Log Pis Std                  1.9281267
Log Pis Max                  5.4422674
Log Pis Min                  -5.2661753
Policy mu Mean               -0.009042136
Policy mu Std                0.81807876
Policy mu Max                2.103408
Policy mu Min                -2.4905992
Policy log std Mean          -0.40534928
Policy log std Std           0.28435406
Policy log std Max           0.43396777
Policy log std Min           -1.352614
Z mean eval                  0.020607987
Z variance eval              0.0041773696
total_rewards                [568.6155951  469.34637677 538.04808062 564.6523212  511.4367804
 571.07486065 475.02212046 581.33446883 488.9499265  529.03708667]
total_rewards_mean           529.7517617192277
total_rewards_std            39.76246081849981
total_rewards_max            581.3344688257558
total_rewards_min            469.3463767695486
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               43.3131401212886
(Previous) Eval Time (s)     7.29486033692956
Sample Time (s)              21.45458520296961
Epoch Time (s)               72.06258566118777
Total Train Time (s)         2807.257337898016
Epoch                        42
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:35:06.729382 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #42 | Epoch Duration: 70.23341345787048
2020-01-11 01:35:06.729503 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #42 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021637678
Z variance train             0.0040289536
KL Divergence                11.432671
KL Loss                      1.143267
QF Loss                      328.2493
VF Loss                      273.24286
Policy Loss                  -431.09616
Q Predictions Mean           429.43695
Q Predictions Std            420.74756
Q Predictions Max            1489.57
Q Predictions Min            -9.146447
V Predictions Mean           432.17892
V Predictions Std            419.8068
V Predictions Max            1483.0651
V Predictions Min            -5.229785
Log Pis Mean                 -0.42828995
Log Pis Std                  2.0277061
Log Pis Max                  7.876428
Log Pis Min                  -4.0703783
Policy mu Mean               0.12484812
Policy mu Std                0.77064246
Policy mu Max                2.7600467
Policy mu Min                -2.982549
Policy log std Mean          -0.37161538
Policy log std Std           0.27021134
Policy log std Max           0.2715634
Policy log std Min           -2.2913845
Z mean eval                  0.02251265
Z variance eval              0.005477868
total_rewards                [533.12915453 495.64047404 369.95636595 562.08528139 573.91953908
 378.79716875 566.50648756 559.52498721 630.53748102 595.54897715]
total_rewards_mean           526.5645916693504
total_rewards_std            83.13597446350968
total_rewards_max            630.5374810247309
total_rewards_min            369.95636595267786
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               42.00827145203948
(Previous) Eval Time (s)     5.465478153899312
Sample Time (s)              19.003048945218325
Epoch Time (s)               66.47679855115712
Total Train Time (s)         2873.6259118942544
Epoch                        43
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:36:13.116440 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #43 | Epoch Duration: 66.38677477836609
2020-01-11 01:36:13.116738 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #43 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05459703
Z variance train             0.0056800293
KL Divergence                10.491962
KL Loss                      1.0491962
QF Loss                      3504.3213
VF Loss                      176.40524
Policy Loss                  -389.8357
Q Predictions Mean           387.48566
Q Predictions Std            402.84146
Q Predictions Max            1442.5134
Q Predictions Min            -3.588326
V Predictions Mean           381.74353
V Predictions Std            399.98965
V Predictions Max            1406.6453
V Predictions Min            -8.437162
Log Pis Mean                 -0.66773754
Log Pis Std                  2.102286
Log Pis Max                  5.6033125
Log Pis Min                  -8.6751375
Policy mu Mean               -0.03824615
Policy mu Std                0.7874558
Policy mu Max                2.2440352
Policy mu Min                -2.611044
Policy log std Mean          -0.3707004
Policy log std Std           0.27354658
Policy log std Max           0.17864418
Policy log std Min           -1.7667783
Z mean eval                  0.014595458
Z variance eval              0.005886437
total_rewards                [366.72288149 611.96081973 635.21328635 490.68794984 636.47661338
 586.76683387 579.39731204 516.43654684 585.99690034 380.70519117]
total_rewards_mean           539.0364335048553
total_rewards_std            93.69316523812634
total_rewards_max            636.4766133815468
total_rewards_min            366.7228814859793
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               42.55413610767573
(Previous) Eval Time (s)     5.375203034374863
Sample Time (s)              19.60548316128552
Epoch Time (s)               67.53482230333611
Total Train Time (s)         2942.243315353524
Epoch                        44
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:37:21.721055 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #44 | Epoch Duration: 68.60411667823792
2020-01-11 01:37:21.721183 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #44 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013239351
Z variance train             0.0065051382
KL Divergence                10.1370325
KL Loss                      1.0137032
QF Loss                      331.4939
VF Loss                      108.037735
Policy Loss                  -468.75095
Q Predictions Mean           466.187
Q Predictions Std            432.64404
Q Predictions Max            1461.9604
Q Predictions Min            -2.4475808
V Predictions Mean           463.76453
V Predictions Std            433.3817
V Predictions Max            1456.8442
V Predictions Min            -26.936867
Log Pis Mean                 -0.23800129
Log Pis Std                  2.2561014
Log Pis Max                  9.924492
Log Pis Min                  -4.807066
Policy mu Mean               -0.025695294
Policy mu Std                0.8848312
Policy mu Max                2.3580494
Policy mu Min                -3.317876
Policy log std Mean          -0.3955257
Policy log std Std           0.2776526
Policy log std Max           0.093100116
Policy log std Min           -1.4028516
Z mean eval                  0.018649487
Z variance eval              0.006101871
total_rewards                [708.54141138 619.52857563 676.10103832 562.35247207 698.62746021
 626.70335938 661.53463027 682.9034354  678.16021263 645.72315724]
total_rewards_mean           656.0175752528419
total_rewards_std            41.58266688272723
total_rewards_max            708.5414113754456
total_rewards_min            562.3524720674613
Number of train steps total  46000
Number of env steps total    232000
Number of rollouts total     0
Train Time (s)               42.95045252377167
(Previous) Eval Time (s)     6.444290086161345
Sample Time (s)              21.03182444907725
Epoch Time (s)               70.42656705901027
Total Train Time (s)         3013.43760076724
Epoch                        45
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:38:32.918202 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #45 | Epoch Duration: 71.19689130783081
2020-01-11 01:38:32.918446 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #45 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020787751
Z variance train             0.0053220503
KL Divergence                10.740941
KL Loss                      1.0740942
QF Loss                      378.8359
VF Loss                      297.0876
Policy Loss                  -536.62573
Q Predictions Mean           533.54736
Q Predictions Std            435.81332
Q Predictions Max            1521.9506
Q Predictions Min            2.69051
V Predictions Mean           523.9287
V Predictions Std            430.53156
V Predictions Max            1504.2935
V Predictions Min            -4.454168
Log Pis Mean                 0.009125821
Log Pis Std                  2.65291
Log Pis Max                  9.9466305
Log Pis Min                  -5.409736
Policy mu Mean               0.005611407
Policy mu Std                0.98612523
Policy mu Max                2.7232482
Policy mu Min                -2.6837544
Policy log std Mean          -0.43062377
Policy log std Std           0.29252923
Policy log std Max           0.19533038
Policy log std Min           -1.6047186
Z mean eval                  0.028137218
Z variance eval              0.005683775
total_rewards                [518.16304025 972.92076345 579.84192284 477.74719991 540.88226656
 598.41500555 741.51916291 715.94719922 721.11223562 590.43487971]
total_rewards_mean           645.6983676019427
total_rewards_std            138.55121118801742
total_rewards_max            972.9207634492054
total_rewards_min            477.74719990943026
Number of train steps total  47000
Number of env steps total    237000
Number of rollouts total     0
Train Time (s)               43.51805628091097
(Previous) Eval Time (s)     7.214353798888624
Sample Time (s)              22.573494638316333
Epoch Time (s)               73.30590471811593
Total Train Time (s)         3085.9369737086818
Epoch                        46
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:39:45.417534 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #46 | Epoch Duration: 72.4989001750946
2020-01-11 01:39:45.417700 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #46 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030195486
Z variance train             0.0055080564
KL Divergence                10.975441
KL Loss                      1.0975441
QF Loss                      472.27707
VF Loss                      210.05711
Policy Loss                  -540.47754
Q Predictions Mean           532.2388
Q Predictions Std            430.24734
Q Predictions Max            1448.601
Q Predictions Min            -4.5036592
V Predictions Mean           537.9259
V Predictions Std            429.56866
V Predictions Max            1460.5466
V Predictions Min            -2.9120421
Log Pis Mean                 0.39252463
Log Pis Std                  2.6196055
Log Pis Max                  14.374642
Log Pis Min                  -5.5558577
Policy mu Mean               0.03934604
Policy mu Std                1.0338678
Policy mu Max                4.038772
Policy mu Min                -2.648893
Policy log std Mean          -0.43260837
Policy log std Std           0.29303268
Policy log std Max           0.07454345
Policy log std Min           -1.7602789
Z mean eval                  0.048730016
Z variance eval              0.01499032
total_rewards                [ 589.92023831 1329.11064975  637.32271838  282.28677966 1045.84427637
  724.34257967  167.40315922  783.22941219  835.9626868   396.73918496]
total_rewards_mean           679.2161685310219
total_rewards_std            332.14924233250485
total_rewards_max            1329.1106497534317
total_rewards_min            167.40315922492894
Number of train steps total  48000
Number of env steps total    242000
Number of rollouts total     0
Train Time (s)               43.31187231000513
(Previous) Eval Time (s)     6.407125893980265
Sample Time (s)              21.19112720992416
Epoch Time (s)               70.91012541390955
Total Train Time (s)         3159.8761789705604
Epoch                        47
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:40:59.358696 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #47 | Epoch Duration: 73.9407958984375
2020-01-11 01:40:59.358957 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #47 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046503954
Z variance train             0.0054527014
KL Divergence                11.10298
KL Loss                      1.110298
QF Loss                      1667.2473
VF Loss                      224.04742
Policy Loss                  -579.88257
Q Predictions Mean           576.7118
Q Predictions Std            453.02692
Q Predictions Max            1639.463
Q Predictions Min            -0.7412671
V Predictions Mean           586.45215
V Predictions Std            457.7468
V Predictions Max            1691.2654
V Predictions Min            -2.2979598
Log Pis Mean                 0.45012757
Log Pis Std                  2.6824975
Log Pis Max                  9.775463
Log Pis Min                  -5.20426
Policy mu Mean               0.0061424277
Policy mu Std                1.0938169
Policy mu Max                2.4855971
Policy mu Min                -3.0720415
Policy log std Mean          -0.44263014
Policy log std Std           0.29530647
Policy log std Max           0.18232168
Policy log std Min           -1.628538
Z mean eval                  0.05358718
Z variance eval              0.0056436933
total_rewards                [372.29314038 757.87938603 253.05631106 285.83472218 541.18715279
 238.5163676  322.13007419 436.15683945 195.79030537 236.80854972]
total_rewards_mean           363.9652848782504
total_rewards_std            164.985254890334
total_rewards_max            757.8793860330584
total_rewards_min            195.79030536767675
Number of train steps total  49000
Number of env steps total    247000
Number of rollouts total     0
Train Time (s)               41.95917961327359
(Previous) Eval Time (s)     9.437538597267121
Sample Time (s)              19.534729093313217
Epoch Time (s)               70.93144730385393
Total Train Time (s)         3227.7565030422993
Epoch                        48
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:42:07.241442 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #48 | Epoch Duration: 67.88230061531067
2020-01-11 01:42:07.241700 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #48 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04643996
Z variance train             0.0045950953
KL Divergence                11.756426
KL Loss                      1.1756426
QF Loss                      323.37314
VF Loss                      152.6953
Policy Loss                  -514.5539
Q Predictions Mean           508.51642
Q Predictions Std            461.54272
Q Predictions Max            1536.82
Q Predictions Min            -41.98949
V Predictions Mean           511.23514
V Predictions Std            461.46884
V Predictions Max            1531.987
V Predictions Min            -36.304214
Log Pis Mean                 0.43927965
Log Pis Std                  2.806144
Log Pis Max                  8.5822
Log Pis Min                  -6.733954
Policy mu Mean               -0.061805326
Policy mu Std                1.1022882
Policy mu Max                3.4245965
Policy mu Min                -2.9959457
Policy log std Mean          -0.45129105
Policy log std Std           0.29126638
Policy log std Max           0.22243416
Policy log std Min           -1.6279147
Z mean eval                  0.07849844
Z variance eval              0.012394288
total_rewards                [ 388.77034821  807.16519005  357.01592322 1264.09507853  911.02171843
  846.02693238  441.52071763  247.00320852  258.79017295  853.04693832]
total_rewards_mean           637.4456228245785
total_rewards_std            325.7330575126279
total_rewards_max            1264.0950785270875
total_rewards_min            247.00320852116124
Number of train steps total  50000
Number of env steps total    252000
Number of rollouts total     0
Train Time (s)               43.11058506788686
(Previous) Eval Time (s)     6.388174913357943
Sample Time (s)              20.36360718915239
Epoch Time (s)               69.86236717039719
Total Train Time (s)         3299.1005552900024
Epoch                        49
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:43:18.587308 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #49 | Epoch Duration: 71.3453357219696
2020-01-11 01:43:18.587582 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #49 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05075838
Z variance train             0.004244192
KL Divergence                11.826372
KL Loss                      1.1826372
QF Loss                      931.6418
VF Loss                      115.38013
Policy Loss                  -601.5735
Q Predictions Mean           596.0143
Q Predictions Std            520.1269
Q Predictions Max            1953.2009
Q Predictions Min            -21.117683
V Predictions Mean           601.6287
V Predictions Std            518.7779
V Predictions Max            1925.9829
V Predictions Min            -13.323604
Log Pis Mean                 0.74751306
Log Pis Std                  2.7845862
Log Pis Max                  8.5265465
Log Pis Min                  -4.2549
Policy mu Mean               -0.021048838
Policy mu Std                1.1002678
Policy mu Max                2.6041718
Policy mu Min                -3.1657014
Policy log std Mean          -0.4971802
Policy log std Std           0.32396236
Policy log std Max           0.013789758
Policy log std Min           -1.8346229
Z mean eval                  0.038054597
Z variance eval              0.0035410668
total_rewards                [682.2528477  709.65191543 355.06755311 548.62688516 235.0179776
 946.20177488 407.42963756 306.52928073 912.33650159 719.25856084]
total_rewards_mean           582.2372934622085
total_rewards_std            237.97430203057095
total_rewards_max            946.2017748847053
total_rewards_min            235.0179776044893
Number of train steps total  51000
Number of env steps total    257000
Number of rollouts total     0
Train Time (s)               42.898838472086936
(Previous) Eval Time (s)     7.870916659943759
Sample Time (s)              21.45716361934319
Epoch Time (s)               72.22691875137389
Total Train Time (s)         3370.8608419341035
Epoch                        50
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:44:30.348649 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #50 | Epoch Duration: 71.76088762283325
2020-01-11 01:44:30.348837 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #50 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04339506
Z variance train             0.0037733174
KL Divergence                11.945941
KL Loss                      1.1945941
QF Loss                      534.8775
VF Loss                      222.94495
Policy Loss                  -620.7114
Q Predictions Mean           611.4603
Q Predictions Std            523.6146
Q Predictions Max            1671.6443
Q Predictions Min            -12.399296
V Predictions Mean           610.2778
V Predictions Std            524.8631
V Predictions Max            1682.7603
V Predictions Min            -15.784318
Log Pis Mean                 0.8059451
Log Pis Std                  2.853865
Log Pis Max                  11.889324
Log Pis Min                  -3.6667476
Policy mu Mean               -0.07212469
Policy mu Std                1.1590445
Policy mu Max                2.7029848
Policy mu Min                -2.6691303
Policy log std Mean          -0.5151953
Policy log std Std           0.33063897
Policy log std Max           -0.018599406
Policy log std Min           -1.7486441
Z mean eval                  0.02505424
Z variance eval              0.0034503029
total_rewards                [780.90415639 766.82501725 921.74049458 650.56295117 904.50437027
 467.94276008 478.54522616 300.12325268 859.28693171 849.5831971 ]
total_rewards_mean           698.001835738366
total_rewards_std            203.70265020786007
total_rewards_max            921.7404945848211
total_rewards_min            300.12325267691295
Number of train steps total  52000
Number of env steps total    262000
Number of rollouts total     0
Train Time (s)               43.12113262200728
(Previous) Eval Time (s)     7.40466867480427
Sample Time (s)              21.0571047347039
Epoch Time (s)               71.58290603151545
Total Train Time (s)         3443.1542624835856
Epoch                        51
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:45:42.645993 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #51 | Epoch Duration: 72.2969651222229
2020-01-11 01:45:42.646290 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #51 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022944447
Z variance train             0.003494827
KL Divergence                12.025032
KL Loss                      1.2025032
QF Loss                      473.5199
VF Loss                      478.4623
Policy Loss                  -626.71515
Q Predictions Mean           631.8894
Q Predictions Std            547.8857
Q Predictions Max            1825.758
Q Predictions Min            -16.165924
V Predictions Mean           639.38086
V Predictions Std            552.4632
V Predictions Max            1829.7633
V Predictions Min            -25.423862
Log Pis Mean                 0.9600304
Log Pis Std                  2.9762418
Log Pis Max                  10.52582
Log Pis Min                  -8.189785
Policy mu Mean               -0.10347295
Policy mu Std                1.1810224
Policy mu Max                3.0531595
Policy mu Min                -2.7982228
Policy log std Mean          -0.500253
Policy log std Std           0.3258806
Policy log std Max           -0.041953117
Policy log std Min           -1.6559443
Z mean eval                  0.059672814
Z variance eval              0.0042878594
total_rewards                [ 556.161196    989.43221671 1119.53253419  771.69600447  899.58733288
  282.45963384  895.87563593 1399.63780084 2627.72974783 2259.24911534]
total_rewards_mean           1180.1361218029135
total_rewards_std            697.8349863389492
total_rewards_max            2627.729747833768
total_rewards_min            282.4596338446548
Number of train steps total  53000
Number of env steps total    267000
Number of rollouts total     0
Train Time (s)               42.30966822290793
(Previous) Eval Time (s)     8.118465370964259
Sample Time (s)              21.469003702048212
Epoch Time (s)               71.8971372959204
Total Train Time (s)         3520.2823855788447
Epoch                        52
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:46:59.774505 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #52 | Epoch Duration: 77.12799382209778
2020-01-11 01:46:59.774762 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #52 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038049225
Z variance train             0.0034956906
KL Divergence                12.120663
KL Loss                      1.2120663
QF Loss                      1084.8611
VF Loss                      357.55792
Policy Loss                  -696.5724
Q Predictions Mean           689.6021
Q Predictions Std            563.4221
Q Predictions Max            1582.1136
Q Predictions Min            -35.32627
V Predictions Mean           707.10004
V Predictions Std            573.2688
V Predictions Max            1641.4774
V Predictions Min            -10.863659
Log Pis Mean                 0.8037851
Log Pis Std                  2.761189
Log Pis Max                  8.246693
Log Pis Min                  -3.1602516
Policy mu Mean               0.039917063
Policy mu Std                1.1551099
Policy mu Max                3.4008954
Policy mu Min                -2.9557538
Policy log std Mean          -0.5090613
Policy log std Std           0.34083295
Policy log std Max           0.10208993
Policy log std Min           -1.759429
Z mean eval                  0.05022521
Z variance eval              0.0038348634
total_rewards                [ 983.54051538  966.90815305  752.36884114  945.99800389  617.51881446
  922.6778016   335.33209455  878.35561025 1010.56688715  362.20877064]
total_rewards_mean           777.5475492107738
total_rewards_std            242.1762035938049
total_rewards_max            1010.5668871503292
total_rewards_min            335.3320945508373
Number of train steps total  54000
Number of env steps total    272000
Number of rollouts total     0
Train Time (s)               44.13091041194275
(Previous) Eval Time (s)     13.3491000700742
Sample Time (s)              21.113823090214282
Epoch Time (s)               78.59383357223123
Total Train Time (s)         3594.566183161922
Epoch                        53
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:48:14.058384 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #53 | Epoch Duration: 74.28343796730042
2020-01-11 01:48:14.058509 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #53 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.1073727
Z variance train             0.0054473435
KL Divergence                10.97546
KL Loss                      1.097546
QF Loss                      942.9342
VF Loss                      249.63406
Policy Loss                  -737.9926
Q Predictions Mean           734.454
Q Predictions Std            577.8454
Q Predictions Max            1958.7648
Q Predictions Min            -15.848877
V Predictions Mean           740.06006
V Predictions Std            579.8093
V Predictions Max            1972.5173
V Predictions Min            -17.828592
Log Pis Mean                 0.9474518
Log Pis Std                  2.8247793
Log Pis Max                  11.078968
Log Pis Min                  -6.2516217
Policy mu Mean               -0.053556547
Policy mu Std                1.1781738
Policy mu Max                3.6150558
Policy mu Min                -2.8686163
Policy log std Mean          -0.531647
Policy log std Std           0.3314536
Policy log std Max           -0.06863128
Policy log std Min           -1.8571247
Z mean eval                  0.05138576
Z variance eval              0.0072341235
total_rewards                [457.98039003 465.27515089 545.37848781 586.88497589 497.19658313
 610.02448693 505.48351852 619.30778171 489.34939717 502.90373051]
total_rewards_mean           527.9784502594762
total_rewards_std            55.90282800119733
total_rewards_max            619.3077817118576
total_rewards_min            457.98039002774937
Number of train steps total  55000
Number of env steps total    277000
Number of rollouts total     0
Train Time (s)               43.65024741087109
(Previous) Eval Time (s)     9.038479373324662
Sample Time (s)              20.908439091406763
Epoch Time (s)               73.59716587560251
Total Train Time (s)         3664.9521233644336
Epoch                        54
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:49:24.446072 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #54 | Epoch Duration: 70.38745450973511
2020-01-11 01:49:24.446233 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #54 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029771924
Z variance train             0.0074648
KL Divergence                10.169283
KL Loss                      1.0169283
QF Loss                      533.63245
VF Loss                      133.06374
Policy Loss                  -705.84875
Q Predictions Mean           701.9542
Q Predictions Std            565.2017
Q Predictions Max            1699.6841
Q Predictions Min            -1.9952725
V Predictions Mean           706.74994
V Predictions Std            567.62354
V Predictions Max            1688.1678
V Predictions Min            -4.873666
Log Pis Mean                 0.7914748
Log Pis Std                  2.7301624
Log Pis Max                  9.637563
Log Pis Min                  -5.3327513
Policy mu Mean               0.12125688
Policy mu Std                1.1234244
Policy mu Max                3.0007617
Policy mu Min                -2.6847358
Policy log std Mean          -0.5255756
Policy log std Std           0.33121845
Policy log std Max           -0.082324445
Policy log std Min           -1.7125871
Z mean eval                  0.05908386
Z variance eval              0.0062494054
total_rewards                [526.85604473 492.72271741 619.88730195 482.83535122 497.5506718
 551.29486414 417.46373209 579.07101984 487.60135151 452.1125774 ]
total_rewards_mean           510.73956320873157
total_rewards_std            56.95346333540861
total_rewards_max            619.887301947679
total_rewards_min            417.4637320930365
Number of train steps total  56000
Number of env steps total    282000
Number of rollouts total     0
Train Time (s)               43.617921927943826
(Previous) Eval Time (s)     5.828533367719501
Sample Time (s)              20.905896010808647
Epoch Time (s)               70.35235130647197
Total Train Time (s)         3736.374050577637
Epoch                        55
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:50:35.869273 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #55 | Epoch Duration: 71.42291641235352
2020-01-11 01:50:35.869402 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #55 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.061803184
Z variance train             0.006157377
KL Divergence                10.801136
KL Loss                      1.0801136
QF Loss                      2695.5876
VF Loss                      335.3566
Policy Loss                  -761.19226
Q Predictions Mean           758.1697
Q Predictions Std            556.57574
Q Predictions Max            1555.98
Q Predictions Min            -0.6567638
V Predictions Mean           751.6614
V Predictions Std            552.64667
V Predictions Max            1519.6807
V Predictions Min            -3.662662
Log Pis Mean                 0.9656853
Log Pis Std                  2.6472342
Log Pis Max                  6.8063574
Log Pis Min                  -4.183958
Policy mu Mean               -0.08189752
Policy mu Std                1.1548547
Policy mu Max                2.9173834
Policy mu Min                -2.8963404
Policy log std Mean          -0.52357584
Policy log std Std           0.32245702
Policy log std Max           0.09270689
Policy log std Min           -1.9530373
Z mean eval                  0.036508787
Z variance eval              0.0050755097
total_rewards                [371.75773149 535.33024064 495.81409166 460.95973404 526.40469879
 373.24335762 508.92431839 436.0845036  554.17628058 406.77532132]
total_rewards_mean           466.9470278113305
total_rewards_std            63.92665998167695
total_rewards_max            554.1762805750345
total_rewards_min            371.75773148519494
Number of train steps total  57000
Number of env steps total    287000
Number of rollouts total     0
Train Time (s)               43.303503966890275
(Previous) Eval Time (s)     6.898853582795709
Sample Time (s)              20.8593937382102
Epoch Time (s)               71.06175128789619
Total Train Time (s)         3806.135979996063
Epoch                        56
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:51:45.635673 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #56 | Epoch Duration: 69.76613235473633
2020-01-11 01:51:45.635935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #56 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037537005
Z variance train             0.005195045
KL Divergence                10.812719
KL Loss                      1.081272
QF Loss                      490.36517
VF Loss                      125.66441
Policy Loss                  -734.4881
Q Predictions Mean           729.8544
Q Predictions Std            548.6752
Q Predictions Max            1689.4752
Q Predictions Min            -8.379373
V Predictions Mean           734.3789
V Predictions Std            550.9119
V Predictions Max            1683.0858
V Predictions Min            -10.203993
Log Pis Mean                 0.9334167
Log Pis Std                  2.6584873
Log Pis Max                  9.361162
Log Pis Min                  -4.390871
Policy mu Mean               -0.060662974
Policy mu Std                1.1389314
Policy mu Max                3.0721538
Policy mu Min                -2.7340758
Policy log std Mean          -0.51464015
Policy log std Std           0.29890147
Policy log std Max           -0.030813873
Policy log std Min           -1.9402196
Z mean eval                  0.024642643
Z variance eval              0.004667358
total_rewards                [576.99554585 781.37434668 585.80955817 591.79158461 584.68547729
 766.72648116 369.93263952 580.85388411 432.63169147 484.53540158]
total_rewards_mean           575.5336610436764
total_rewards_std            122.63059580364097
total_rewards_max            781.3743466764749
total_rewards_min            369.9326395225681
Number of train steps total  58000
Number of env steps total    292000
Number of rollouts total     0
Train Time (s)               42.29282710608095
(Previous) Eval Time (s)     5.602990481071174
Sample Time (s)              18.356212710030377
Epoch Time (s)               66.2520302971825
Total Train Time (s)         3873.5256508444436
Epoch                        57
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:52:53.028476 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #57 | Epoch Duration: 67.39211988449097
2020-01-11 01:52:53.028658 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #57 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019519864
Z variance train             0.0050361766
KL Divergence                10.964352
KL Loss                      1.0964352
QF Loss                      2080.8867
VF Loss                      912.63086
Policy Loss                  -762.41833
Q Predictions Mean           764.2477
Q Predictions Std            575.3337
Q Predictions Max            1769.5582
Q Predictions Min            -3.4228516
V Predictions Mean           778.4732
V Predictions Std            581.5739
V Predictions Max            1794.786
V Predictions Min            -7.3335505
Log Pis Mean                 0.80075943
Log Pis Std                  2.8469162
Log Pis Max                  10.240716
Log Pis Min                  -4.3184204
Policy mu Mean               -0.13473307
Policy mu Std                1.1439345
Policy mu Max                3.2505593
Policy mu Min                -3.236443
Policy log std Mean          -0.5341778
Policy log std Std           0.33108053
Policy log std Max           -0.04474473
Policy log std Min           -1.8300227
Z mean eval                  0.021763619
Z variance eval              0.0042464943
total_rewards                [865.04726667 662.87718295 569.47031152 633.62949767 573.18266294
 694.15123053 784.38935277 593.97818494 681.17044631 561.6944697 ]
total_rewards_mean           661.9590605999352
total_rewards_std            94.63224674964502
total_rewards_max            865.0472666703323
total_rewards_min            561.694469700325
Number of train steps total  59000
Number of env steps total    297000
Number of rollouts total     0
Train Time (s)               42.66314099216834
(Previous) Eval Time (s)     6.742873886600137
Sample Time (s)              20.796192986425012
Epoch Time (s)               70.20220786519349
Total Train Time (s)         3944.7698512510397
Epoch                        58
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:54:04.272002 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #58 | Epoch Duration: 71.24321722984314
2020-01-11 01:54:04.272198 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #58 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02073061
Z variance train             0.0043066964
KL Divergence                11.477194
KL Loss                      1.1477194
QF Loss                      582.51697
VF Loss                      183.43976
Policy Loss                  -764.91064
Q Predictions Mean           761.1826
Q Predictions Std            553.6855
Q Predictions Max            1613.0693
Q Predictions Min            -20.679028
V Predictions Mean           769.1901
V Predictions Std            557.38446
V Predictions Max            1618.6171
V Predictions Min            -5.8325653
Log Pis Mean                 0.64494765
Log Pis Std                  2.5826313
Log Pis Max                  7.965987
Log Pis Min                  -4.377883
Policy mu Mean               -0.12725483
Policy mu Std                1.111802
Policy mu Max                2.608624
Policy mu Min                -2.9016714
Policy log std Mean          -0.50031453
Policy log std Std           0.28821245
Policy log std Max           -0.0004005283
Policy log std Min           -1.6954347
Z mean eval                  0.018484894
Z variance eval              0.0038876012
total_rewards                [600.49825122 763.87363423 745.95259945 890.44555268 879.91758634
 795.01825654 632.04089238 546.541682   598.70100573 817.26490898]
total_rewards_mean           727.0254369562884
total_rewards_std            117.74425438632102
total_rewards_max            890.4455526825275
total_rewards_min            546.541681999362
Number of train steps total  60000
Number of env steps total    302000
Number of rollouts total     0
Train Time (s)               42.94574713893235
(Previous) Eval Time (s)     7.783647990319878
Sample Time (s)              22.141610883641988
Epoch Time (s)               72.87100601289421
Total Train Time (s)         4017.696454625111
Epoch                        59
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:55:17.200261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #59 | Epoch Duration: 72.92793536186218
2020-01-11 01:55:17.200393 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #59 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01905189
Z variance train             0.00428977
KL Divergence                11.54219
KL Loss                      1.154219
QF Loss                      415.66235
VF Loss                      210.73003
Policy Loss                  -748.53265
Q Predictions Mean           746.69183
Q Predictions Std            600.1531
Q Predictions Max            2138.4282
Q Predictions Min            -6.836288
V Predictions Mean           743.28296
V Predictions Std            598.92834
V Predictions Max            2157.8215
V Predictions Min            -6.7476416
Log Pis Mean                 0.3764761
Log Pis Std                  2.5450003
Log Pis Max                  10.338648
Log Pis Min                  -3.6059315
Policy mu Mean               -0.057417348
Policy mu Std                1.0792558
Policy mu Max                3.0969195
Policy mu Min                -2.8350642
Policy log std Mean          -0.49003625
Policy log std Std           0.32130125
Policy log std Max           -0.017315716
Policy log std Min           -1.7119262
Z mean eval                  0.016247878
Z variance eval              0.0039484105
total_rewards                [ 908.75090327  694.14077577  548.47281692  345.25158228 1345.48907158
  582.32184837  830.2896604   625.80137924  994.58622565  787.47569893]
total_rewards_mean           766.2579962401745
total_rewards_std            263.80582606027684
total_rewards_max            1345.4890715785039
total_rewards_min            345.251582275417
Number of train steps total  61000
Number of env steps total    307000
Number of rollouts total     0
Train Time (s)               42.505504202097654
(Previous) Eval Time (s)     7.840345115866512
Sample Time (s)              19.659861938096583
Epoch Time (s)               70.00571125606075
Total Train Time (s)         4087.741579366382
Epoch                        60
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:56:27.246506 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #60 | Epoch Duration: 70.04600095748901
2020-01-11 01:56:27.246669 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #60 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018100612
Z variance train             0.0038172256
KL Divergence                11.904249
KL Loss                      1.1904249
QF Loss                      1703.9691
VF Loss                      93.85579
Policy Loss                  -727.2735
Q Predictions Mean           719.4342
Q Predictions Std            584.40155
Q Predictions Max            1774.0101
Q Predictions Min            -25.844542
V Predictions Mean           731.10345
V Predictions Std            588.7181
V Predictions Max            1768.4963
V Predictions Min            -0.8643719
Log Pis Mean                 0.4475351
Log Pis Std                  2.5442214
Log Pis Max                  11.379923
Log Pis Min                  -4.164323
Policy mu Mean               0.057694048
Policy mu Std                1.0549483
Policy mu Max                2.9407835
Policy mu Min                -3.1402512
Policy log std Mean          -0.48117092
Policy log std Std           0.3093967
Policy log std Max           0.1247198
Policy log std Min           -1.9431708
Z mean eval                  0.034434892
Z variance eval              0.003437588
total_rewards                [514.49759574 515.56426718 514.48190938 874.61031573 604.92406532
 529.89674046 527.88293298 650.61643009 694.27699994 913.0462093 ]
total_rewards_mean           633.9797466130643
total_rewards_std            143.2500196444556
total_rewards_max            913.0462092970208
total_rewards_min            514.4819093804055
Number of train steps total  62000
Number of env steps total    312000
Number of rollouts total     0
Train Time (s)               42.20550139807165
(Previous) Eval Time (s)     7.8803599760867655
Sample Time (s)              21.31825708039105
Epoch Time (s)               71.40411845454946
Total Train Time (s)         4158.967036402319
Epoch                        61
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:57:38.473212 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #61 | Epoch Duration: 71.22641634941101
2020-01-11 01:57:38.473347 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #61 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.038147114
Z variance train             0.0038850456
KL Divergence                11.838427
KL Loss                      1.1838427
QF Loss                      659.1121
VF Loss                      149.58804
Policy Loss                  -809.0775
Q Predictions Mean           804.06104
Q Predictions Std            585.60645
Q Predictions Max            1780.0476
Q Predictions Min            -23.775124
V Predictions Mean           809.5604
V Predictions Std            588.0434
V Predictions Max            1753.6278
V Predictions Min            -16.208525
Log Pis Mean                 0.5172066
Log Pis Std                  2.4797826
Log Pis Max                  10.852245
Log Pis Min                  -4.0111017
Policy mu Mean               0.06955278
Policy mu Std                1.052825
Policy mu Max                2.850183
Policy mu Min                -4.250047
Policy log std Mean          -0.5388257
Policy log std Std           0.35281205
Policy log std Max           0.004806429
Policy log std Min           -2.7482336
Z mean eval                  0.017905148
Z variance eval              0.0034236356
total_rewards                [ 985.41305184  774.60732743  660.06315623  537.83034907  561.45300241
  496.60418395  550.58655914  835.58862639 1003.14001314 1002.03071595]
total_rewards_mean           740.7316985548944
total_rewards_std            195.63238467919658
total_rewards_max            1003.1400131358956
total_rewards_min            496.6041839549858
Number of train steps total  63000
Number of env steps total    317000
Number of rollouts total     0
Train Time (s)               43.67540021287277
(Previous) Eval Time (s)     7.702390817925334
Sample Time (s)              20.977102645672858
Epoch Time (s)               72.35489367647097
Total Train Time (s)         4232.8088939087465
Epoch                        62
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 01:58:52.319772 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #62 | Epoch Duration: 73.84627938270569
2020-01-11 01:58:52.320077 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #62 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018180069
Z variance train             0.0033525382
KL Divergence                12.0316925
KL Loss                      1.2031692
QF Loss                      655.12854
VF Loss                      147.04735
Policy Loss                  -739.1507
Q Predictions Mean           732.64935
Q Predictions Std            592.1326
Q Predictions Max            1846.9679
Q Predictions Min            -5.186481
V Predictions Mean           737.29846
V Predictions Std            591.10535
V Predictions Max            1846.1283
V Predictions Min            -3.1319695
Log Pis Mean                 0.27862713
Log Pis Std                  2.42697
Log Pis Max                  7.674616
Log Pis Min                  -5.0054846
Policy mu Mean               0.049420107
Policy mu Std                1.035983
Policy mu Max                2.9454668
Policy mu Min                -2.7427998
Policy log std Mean          -0.49374613
Policy log std Std           0.2980447
Policy log std Max           -0.035235137
Policy log std Min           -1.5971076
Z mean eval                  0.045041632
Z variance eval              0.0034426902
total_rewards                [591.91671121 755.33255059 665.61560729 634.32991379 566.73723407
 498.9862456  690.49576146 528.17314177 468.46047125 752.02920508]
total_rewards_mean           615.2076842091535
total_rewards_std            96.14523001229357
total_rewards_max            755.3325505888738
total_rewards_min            468.46047124548227
Number of train steps total  64000
Number of env steps total    322000
Number of rollouts total     0
Train Time (s)               42.47525670612231
(Previous) Eval Time (s)     9.193502883892506
Sample Time (s)              19.435272791888565
Epoch Time (s)               71.10403238190338
Total Train Time (s)         4302.677230370697
Epoch                        63
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:00:02.186820 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #63 | Epoch Duration: 69.86653900146484
2020-01-11 02:00:02.186943 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #63 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046181064
Z variance train             0.0036178292
KL Divergence                11.801842
KL Loss                      1.1801842
QF Loss                      1487.7129
VF Loss                      410.88535
Policy Loss                  -772.5404
Q Predictions Mean           770.49664
Q Predictions Std            572.97675
Q Predictions Max            1717.9406
Q Predictions Min            -13.655596
V Predictions Mean           758.52344
V Predictions Std            567.1267
V Predictions Max            1700.3746
V Predictions Min            -24.412294
Log Pis Mean                 0.28344947
Log Pis Std                  2.548174
Log Pis Max                  8.212121
Log Pis Min                  -6.013429
Policy mu Mean               -0.05397172
Policy mu Std                1.0525283
Policy mu Max                2.3427815
Policy mu Min                -2.9864182
Policy log std Mean          -0.5058424
Policy log std Std           0.2919222
Policy log std Max           -0.007041365
Policy log std Min           -1.6737607
Z mean eval                  0.03726891
Z variance eval              0.0040880004
total_rewards                [ 755.00651642  496.61533762  997.64539177 1010.89472259  413.33537851
  928.56292086  847.31295042  698.13162236 1007.83924499  811.85552212]
total_rewards_mean           796.7199607657512
total_rewards_std            199.872635995267
total_rewards_max            1010.894722586859
total_rewards_min            413.33537850723263
Number of train steps total  65000
Number of env steps total    327000
Number of rollouts total     0
Train Time (s)               42.47814815118909
(Previous) Eval Time (s)     7.955793725792319
Sample Time (s)              21.071499709039927
Epoch Time (s)               71.50544158602133
Total Train Time (s)         4375.28485624399
Epoch                        64
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:01:14.799223 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #64 | Epoch Duration: 72.61214113235474
2020-01-11 02:01:14.799500 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #64 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036074124
Z variance train             0.0039513605
KL Divergence                11.63406
KL Loss                      1.163406
QF Loss                      620.7426
VF Loss                      236.50793
Policy Loss                  -763.9023
Q Predictions Mean           762.35516
Q Predictions Std            585.68634
Q Predictions Max            1721.8865
Q Predictions Min            -7.2872276
V Predictions Mean           771.9797
V Predictions Std            584.771
V Predictions Max            1720.2831
V Predictions Min            -1.2464895
Log Pis Mean                 0.39974356
Log Pis Std                  2.4775002
Log Pis Max                  12.588956
Log Pis Min                  -4.735931
Policy mu Mean               0.050606146
Policy mu Std                1.0414358
Policy mu Max                2.5770261
Policy mu Min                -3.566945
Policy log std Mean          -0.5060152
Policy log std Std           0.29376736
Policy log std Max           0.03605956
Policy log std Min           -1.5727826
Z mean eval                  0.03433479
Z variance eval              0.003585225
total_rewards                [1035.78633416  616.6879893  1087.25839067  994.94112443 1020.45425214
 1143.80426927 1060.38272402  761.91011945  777.33023319 1024.24640252]
total_rewards_mean           952.2801839138967
total_rewards_std            162.68902597081166
total_rewards_max            1143.8042692724514
total_rewards_min            616.6879892955299
Number of train steps total  66000
Number of env steps total    332000
Number of rollouts total     0
Train Time (s)               43.17647615727037
(Previous) Eval Time (s)     9.062253612093627
Sample Time (s)              21.845599697437137
Epoch Time (s)               74.08432946680114
Total Train Time (s)         4450.072856804356
Epoch                        65
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:02:29.588159 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #65 | Epoch Duration: 74.78843808174133
2020-01-11 02:02:29.588375 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #65 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035556424
Z variance train             0.0034236107
KL Divergence                12.082439
KL Loss                      1.208244
QF Loss                      219.3298
VF Loss                      128.70634
Policy Loss                  -809.70483
Q Predictions Mean           807.8047
Q Predictions Std            581.57196
Q Predictions Max            1669.6296
Q Predictions Min            -4.2929068
V Predictions Mean           813.72327
V Predictions Std            585.7888
V Predictions Max            1685.5886
V Predictions Min            -8.533533
Log Pis Mean                 0.30562302
Log Pis Std                  2.45898
Log Pis Max                  7.7169204
Log Pis Min                  -5.297927
Policy mu Mean               -0.1552628
Policy mu Std                1.0210284
Policy mu Max                2.2221868
Policy mu Min                -2.916324
Policy log std Mean          -0.49456486
Policy log std Std           0.27850142
Policy log std Max           -0.014842331
Policy log std Min           -1.4856155
Z mean eval                  0.02613478
Z variance eval              0.0075381906
total_rewards                [ 508.49603697  849.24158739 1021.32664061  553.50628329  775.19109665
  717.00025117  648.02908136  722.59949571  737.32425314  800.52130692]
total_rewards_mean           733.3236033210085
total_rewards_std            138.99837014997303
total_rewards_max            1021.32664061463
total_rewards_min            508.49603697431246
Number of train steps total  67000
Number of env steps total    337000
Number of rollouts total     0
Train Time (s)               42.97422110289335
(Previous) Eval Time (s)     9.766155754216015
Sample Time (s)              21.82918842881918
Epoch Time (s)               74.56956528592855
Total Train Time (s)         4523.397885495331
Epoch                        66
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:03:42.916580 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #66 | Epoch Duration: 73.32800459861755
2020-01-11 02:03:42.916861 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #66 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035490423
Z variance train             0.005678212
KL Divergence                10.478741
KL Loss                      1.0478741
QF Loss                      457.57233
VF Loss                      151.03816
Policy Loss                  -730.70905
Q Predictions Mean           725.25806
Q Predictions Std            589.05896
Q Predictions Max            1664.8813
Q Predictions Min            -16.125698
V Predictions Mean           733.8395
V Predictions Std            593.5264
V Predictions Max            1651.889
V Predictions Min            0.6845788
Log Pis Mean                 0.2686395
Log Pis Std                  2.6151223
Log Pis Max                  11.376534
Log Pis Min                  -5.2526155
Policy mu Mean               0.10337857
Policy mu Std                1.02584
Policy mu Max                2.7468796
Policy mu Min                -3.1516361
Policy log std Mean          -0.4622363
Policy log std Std           0.26827583
Policy log std Max           0.094389856
Policy log std Min           -1.4751239
Z mean eval                  0.033058092
Z variance eval              0.0061074803
total_rewards                [ 643.02307381  169.59658385 1414.05801192  547.64252115 1015.41804612
  758.36868112  722.70138938  167.54541661  729.99304179  753.04921565]
total_rewards_mean           692.1395981389343
total_rewards_std            347.5169672972401
total_rewards_max            1414.0580119174135
total_rewards_min            167.54541661013306
Number of train steps total  68000
Number of env steps total    342000
Number of rollouts total     0
Train Time (s)               43.69151949696243
(Previous) Eval Time (s)     8.524343637749553
Sample Time (s)              21.48573051393032
Epoch Time (s)               73.7015936486423
Total Train Time (s)         4596.66237338027
Epoch                        67
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:04:56.183890 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #67 | Epoch Duration: 73.26678729057312
2020-01-11 02:04:56.184206 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #67 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04481524
Z variance train             0.0058871936
KL Divergence                10.503744
KL Loss                      1.0503744
QF Loss                      935.88916
VF Loss                      476.38654
Policy Loss                  -846.9638
Q Predictions Mean           843.7932
Q Predictions Std            593.2821
Q Predictions Max            2049.935
Q Predictions Min            -25.904577
V Predictions Mean           839.02783
V Predictions Std            588.27747
V Predictions Max            2026.2493
V Predictions Min            -21.999542
Log Pis Mean                 0.74249506
Log Pis Std                  2.5940306
Log Pis Max                  8.19388
Log Pis Min                  -5.9330688
Policy mu Mean               0.03959838
Policy mu Std                1.0702157
Policy mu Max                3.131682
Policy mu Min                -3.0454662
Policy log std Mean          -0.5328639
Policy log std Std           0.2852893
Policy log std Max           -0.033441126
Policy log std Min           -1.8585107
Z mean eval                  0.05022358
Z variance eval              0.0046612425
total_rewards                [251.69131973 779.78984143 752.96735846 223.2811189  229.93793384
 760.2468855  229.13816728 203.13660705 722.2897525  214.55503966]
total_rewards_mean           436.7034024350044
total_rewards_std            259.5165339595345
total_rewards_max            779.7898414344683
total_rewards_min            203.1366070480402
Number of train steps total  69000
Number of env steps total    347000
Number of rollouts total     0
Train Time (s)               43.290643360000104
(Previous) Eval Time (s)     8.089297455269843
Sample Time (s)              21.810953448992223
Epoch Time (s)               73.19089426426217
Total Train Time (s)         4667.766016601119
Epoch                        68
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:06:07.286766 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #68 | Epoch Duration: 71.10238814353943
2020-01-11 02:06:07.286896 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #68 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050307103
Z variance train             0.0048055695
KL Divergence                11.178555
KL Loss                      1.1178554
QF Loss                      764.58875
VF Loss                      227.41061
Policy Loss                  -822.5513
Q Predictions Mean           814.9915
Q Predictions Std            572.6932
Q Predictions Max            1726.5073
Q Predictions Min            -4.155816
V Predictions Mean           823.18176
V Predictions Std            576.4492
V Predictions Max            1773.2762
V Predictions Min            -6.7716265
Log Pis Mean                 0.3025487
Log Pis Std                  2.367978
Log Pis Max                  6.802513
Log Pis Min                  -4.770672
Policy mu Mean               -0.11317757
Policy mu Std                1.0694596
Policy mu Max                2.4688642
Policy mu Min                -2.9194975
Policy log std Mean          -0.47904372
Policy log std Std           0.28807652
Policy log std Max           0.042658374
Policy log std Min           -1.9758279
Z mean eval                  0.045835614
Z variance eval              0.005137013
total_rewards                [ 225.23461982  752.95521547  514.97822773  177.75691874  532.54224439
  438.40654362  796.16994976  247.79814025 1373.59442883  374.37553396]
total_rewards_mean           543.3811822580284
total_rewards_std            340.56599029485017
total_rewards_max            1373.5944288315245
total_rewards_min            177.75691874180893
Number of train steps total  70000
Number of env steps total    352000
Number of rollouts total     0
Train Time (s)               42.25027904799208
(Previous) Eval Time (s)     6.00054964190349
Sample Time (s)              21.227897940203547
Epoch Time (s)               69.47872663009912
Total Train Time (s)         4738.555455287453
Epoch                        69
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:07:18.077183 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #69 | Epoch Duration: 70.79019045829773
2020-01-11 02:07:18.077303 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #69 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.054393373
Z variance train             0.0070172
KL Divergence                10.370867
KL Loss                      1.0370867
QF Loss                      2008.2406
VF Loss                      239.14557
Policy Loss                  -730.76587
Q Predictions Mean           727.8247
Q Predictions Std            589.8292
Q Predictions Max            1760.9282
Q Predictions Min            -23.202818
V Predictions Mean           734.3255
V Predictions Std            592.59174
V Predictions Max            1753.3275
V Predictions Min            -33.45547
Log Pis Mean                 0.51062787
Log Pis Std                  2.556484
Log Pis Max                  8.124647
Log Pis Min                  -4.730655
Policy mu Mean               -0.12805028
Policy mu Std                1.0808301
Policy mu Max                2.3532481
Policy mu Min                -3.1293693
Policy log std Mean          -0.444569
Policy log std Std           0.25678128
Policy log std Max           0.0077074617
Policy log std Min           -1.4185251
Z mean eval                  0.05096811
Z variance eval              0.0048668734
total_rewards                [356.9789236  215.41895583 240.28252814 218.5375553  282.65319914
 179.43600286 234.06859802 482.35681987 233.72423046 567.30966537]
total_rewards_mean           301.0766478588143
total_rewards_std            122.01465021019729
total_rewards_max            567.3096653662737
total_rewards_min            179.43600285608898
Number of train steps total  71000
Number of env steps total    357000
Number of rollouts total     0
Train Time (s)               43.368404247332364
(Previous) Eval Time (s)     7.31178283225745
Sample Time (s)              20.37146154232323
Epoch Time (s)               71.05164862191305
Total Train Time (s)         4806.529799913056
Epoch                        70
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:08:26.053314 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #70 | Epoch Duration: 67.97590255737305
2020-01-11 02:08:26.053497 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #70 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04525111
Z variance train             0.0045042755
KL Divergence                11.567408
KL Loss                      1.1567408
QF Loss                      650.1709
VF Loss                      194.84491
Policy Loss                  -896.3251
Q Predictions Mean           888.73
Q Predictions Std            551.27814
Q Predictions Max            1730.612
Q Predictions Min            -2.9423664
V Predictions Mean           893.5041
V Predictions Std            549.51025
V Predictions Max            1723.4385
V Predictions Min            -5.045106
Log Pis Mean                 0.6362314
Log Pis Std                  2.5853736
Log Pis Max                  9.035135
Log Pis Min                  -6.6629558
Policy mu Mean               -0.049078446
Policy mu Std                1.115629
Policy mu Max                2.946931
Policy mu Min                -3.2651148
Policy log std Mean          -0.4977181
Policy log std Std           0.27532613
Policy log std Max           0.02058208
Policy log std Min           -1.5328159
Z mean eval                  0.08634983
Z variance eval              0.005605404
total_rewards                [ 278.63329464  761.24230125  444.64749547  755.02059909  543.02717946
  746.70253307 1591.39616134  278.02884711  768.21260763  775.78906131]
total_rewards_mean           694.2700080362758
total_rewards_std            354.8337166370593
total_rewards_max            1591.396161341943
total_rewards_min            278.0288471085103
Number of train steps total  72000
Number of env steps total    362000
Number of rollouts total     0
Train Time (s)               42.83847885718569
(Previous) Eval Time (s)     4.235780251212418
Sample Time (s)              16.7384937396273
Epoch Time (s)               63.81275284802541
Total Train Time (s)         4874.321118475404
Epoch                        71
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:09:33.845158 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #71 | Epoch Duration: 67.79153633117676
2020-01-11 02:09:33.845288 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #71 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.08407372
Z variance train             0.005872303
KL Divergence                10.721861
KL Loss                      1.0721861
QF Loss                      1047.4606
VF Loss                      225.66519
Policy Loss                  -809.41125
Q Predictions Mean           804.11523
Q Predictions Std            560.2508
Q Predictions Max            1611.2172
Q Predictions Min            1.0774643
V Predictions Mean           807.63293
V Predictions Std            559.86383
V Predictions Max            1628.7921
V Predictions Min            -4.336372
Log Pis Mean                 0.63338923
Log Pis Std                  2.655156
Log Pis Max                  9.691126
Log Pis Min                  -7.3928742
Policy mu Mean               -0.010969336
Policy mu Std                1.114284
Policy mu Max                3.3377783
Policy mu Min                -3.526079
Policy log std Mean          -0.48676848
Policy log std Std           0.2676654
Policy log std Max           -0.036610633
Policy log std Min           -2.2257454
Z mean eval                  0.055488013
Z variance eval              0.0044114213
total_rewards                [ 455.61066469  460.4107968  1255.56135227  390.16236874  991.72079135
  357.45950617  406.83123869  922.22704829  424.77794536  402.00872822]
total_rewards_mean           606.6770440579452
total_rewards_std            306.1043837251223
total_rewards_max            1255.5613522724411
total_rewards_min            357.45950617120184
Number of train steps total  73000
Number of env steps total    367000
Number of rollouts total     0
Train Time (s)               42.355293311178684
(Previous) Eval Time (s)     8.21435323683545
Sample Time (s)              21.253754848614335
Epoch Time (s)               71.82340139662847
Total Train Time (s)         4944.315466796979
Epoch                        72
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:10:43.844366 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #72 | Epoch Duration: 69.99893927574158
2020-01-11 02:10:43.844621 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #72 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07407467
Z variance train             0.0045292787
KL Divergence                11.573577
KL Loss                      1.1573577
QF Loss                      490.62503
VF Loss                      293.47632
Policy Loss                  -842.647
Q Predictions Mean           847.746
Q Predictions Std            576.8312
Q Predictions Max            1706.8049
Q Predictions Min            -11.279031
V Predictions Mean           851.4584
V Predictions Std            578.21576
V Predictions Max            1725.5819
V Predictions Min            -14.598247
Log Pis Mean                 0.59157073
Log Pis Std                  2.3001916
Log Pis Max                  6.659176
Log Pis Min                  -4.4044514
Policy mu Mean               -0.009008765
Policy mu Std                1.0719572
Policy mu Max                2.6019704
Policy mu Min                -2.7483616
Policy log std Mean          -0.48523
Policy log std Std           0.29276305
Policy log std Max           -0.0023904443
Policy log std Min           -1.8556132
Z mean eval                  0.08263227
Z variance eval              0.0072402433
total_rewards                [480.52237081 740.60675915 749.12546845 417.64674862 841.98492807
 726.38957097 459.4028502  378.08398381 335.12006501 436.82116645]
total_rewards_mean           556.5703911552737
total_rewards_std            176.3544687530306
total_rewards_max            841.9849280674939
total_rewards_min            335.12006501044556
Number of train steps total  74000
Number of env steps total    372000
Number of rollouts total     0
Train Time (s)               43.650371155235916
(Previous) Eval Time (s)     6.3896147180348635
Sample Time (s)              20.3044643397443
Epoch Time (s)               70.34445021301508
Total Train Time (s)         5015.194648811128
Epoch                        73
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:11:54.722460 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #73 | Epoch Duration: 70.87764883041382
2020-01-11 02:11:54.722583 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #73 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0846254
Z variance train             0.007106725
KL Divergence                10.709078
KL Loss                      1.0709078
QF Loss                      609.5677
VF Loss                      172.66681
Policy Loss                  -756.12225
Q Predictions Mean           752.6127
Q Predictions Std            578.1698
Q Predictions Max            1601.0547
Q Predictions Min            -8.22958
V Predictions Mean           759.5173
V Predictions Std            579.88416
V Predictions Max            1605.4803
V Predictions Min            -9.477368
Log Pis Mean                 0.5084928
Log Pis Std                  2.4816523
Log Pis Max                  11.405657
Log Pis Min                  -6.17506
Policy mu Mean               0.035986234
Policy mu Std                1.0408431
Policy mu Max                2.7448995
Policy mu Min                -2.8970592
Policy log std Mean          -0.4938394
Policy log std Std           0.29589278
Policy log std Max           0.25380838
Policy log std Min           -1.6427921
Z mean eval                  0.08438338
Z variance eval              0.005395061
total_rewards                [487.24089091 942.41897823 375.56124404 626.41581148 421.4511676
 442.68757821 380.16516821 483.3621268  449.68244806 970.46669888]
total_rewards_mean           557.9452112429635
total_rewards_std            210.17836300798135
total_rewards_max            970.4666988792179
total_rewards_min            375.56124404303625
Number of train steps total  75000
Number of env steps total    377000
Number of rollouts total     0
Train Time (s)               43.53583812061697
(Previous) Eval Time (s)     6.922599188052118
Sample Time (s)              20.08475254382938
Epoch Time (s)               70.54318985249847
Total Train Time (s)         5084.825706852134
Epoch                        74
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:13:04.358334 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #74 | Epoch Duration: 69.63561248779297
2020-01-11 02:13:04.358616 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #74 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06278984
Z variance train             0.0045866603
KL Divergence                11.965604
KL Loss                      1.1965604
QF Loss                      1098.9187
VF Loss                      194.87152
Policy Loss                  -775.99005
Q Predictions Mean           775.9873
Q Predictions Std            554.7147
Q Predictions Max            1603.035
Q Predictions Min            -18.761887
V Predictions Mean           779.61395
V Predictions Std            554.9578
V Predictions Max            1608.181
V Predictions Min            0.6285457
Log Pis Mean                 0.5434497
Log Pis Std                  2.4106581
Log Pis Max                  7.777646
Log Pis Min                  -4.9410195
Policy mu Mean               0.04875509
Policy mu Std                1.0570471
Policy mu Max                2.6378095
Policy mu Min                -2.8264177
Policy log std Mean          -0.5325782
Policy log std Std           0.294168
Policy log std Max           0.022592768
Policy log std Min           -1.6574612
Z mean eval                  0.08489192
Z variance eval              0.0060559628
total_rewards                [729.74951296 651.69576489 652.06902958 692.60945081 644.92261403
 683.83264767 707.50335929 542.73656272 684.84704149 698.59105144]
total_rewards_mean           668.8557034881671
total_rewards_std            49.178498210151226
total_rewards_max            729.7495129604099
total_rewards_min            542.7365627186465
Number of train steps total  76000
Number of env steps total    382000
Number of rollouts total     0
Train Time (s)               43.0243885810487
(Previous) Eval Time (s)     6.014767195098102
Sample Time (s)              19.79067398654297
Epoch Time (s)               68.82982976268977
Total Train Time (s)         5154.6542423856445
Epoch                        75
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:14:14.186064 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #75 | Epoch Duration: 69.82725071907043
2020-01-11 02:14:14.186181 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #75 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.053846754
Z variance train             0.005646436
KL Divergence                11.462474
KL Loss                      1.1462474
QF Loss                      997.852
VF Loss                      229.1254
Policy Loss                  -844.9715
Q Predictions Mean           843.285
Q Predictions Std            562.9115
Q Predictions Max            1630.0598
Q Predictions Min            -39.900234
V Predictions Mean           844.11896
V Predictions Std            563.36096
V Predictions Max            1649.29
V Predictions Min            -11.898061
Log Pis Mean                 0.5650058
Log Pis Std                  2.3191476
Log Pis Max                  5.888899
Log Pis Min                  -4.920047
Policy mu Mean               -0.11363808
Policy mu Std                1.0681258
Policy mu Max                2.8688672
Policy mu Min                -2.8976493
Policy log std Mean          -0.50784874
Policy log std Std           0.2857099
Policy log std Max           -0.02621381
Policy log std Min           -1.6046429
Z mean eval                  0.07692835
Z variance eval              0.009540955
total_rewards                [484.43842427 556.10492526 680.3158748  869.73273998 549.64730079
 682.67496259 605.89787811 646.96422075 655.86981806 596.10195709]
total_rewards_mean           632.7748101697073
total_rewards_std            99.24382216618855
total_rewards_max            869.7327399824322
total_rewards_min            484.43842426891854
Number of train steps total  77000
Number of env steps total    387000
Number of rollouts total     0
Train Time (s)               42.50318763311952
(Previous) Eval Time (s)     7.011967457830906
Sample Time (s)              20.629213200882077
Epoch Time (s)               70.1443682918325
Total Train Time (s)         5224.851287466474
Epoch                        76
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:15:24.385319 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #76 | Epoch Duration: 70.19902753829956
2020-01-11 02:15:24.385486 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #76 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07563272
Z variance train             0.009794169
KL Divergence                9.910524
KL Loss                      0.99105245
QF Loss                      2616.5806
VF Loss                      349.56714
Policy Loss                  -829.1537
Q Predictions Mean           830.4741
Q Predictions Std            595.9046
Q Predictions Max            1651.6664
Q Predictions Min            -16.463902
V Predictions Mean           831.13965
V Predictions Std            592.5522
V Predictions Max            1674.5314
V Predictions Min            -4.4846745
Log Pis Mean                 0.72522986
Log Pis Std                  2.6716993
Log Pis Max                  10.763218
Log Pis Min                  -3.3447537
Policy mu Mean               -0.05322659
Policy mu Std                1.0881693
Policy mu Max                2.590788
Policy mu Min                -4.5089846
Policy log std Mean          -0.52679825
Policy log std Std           0.3107898
Policy log std Max           -0.056252643
Policy log std Min           -2.0388227
Z mean eval                  0.073381245
Z variance eval              0.007808771
total_rewards                [428.92827378 476.52034635 494.85973197 623.38157752 433.76076558
 511.54464611 514.87196689 487.83928972 446.2154572  450.82981244]
total_rewards_mean           486.8751867574523
total_rewards_std            54.15696713810765
total_rewards_max            623.3815775196132
total_rewards_min            428.92827377575765
Number of train steps total  78000
Number of env steps total    392000
Number of rollouts total     0
Train Time (s)               43.033230334986
(Previous) Eval Time (s)     7.0663834903389215
Sample Time (s)              20.793897383846343
Epoch Time (s)               70.89351120917127
Total Train Time (s)         5294.601009004284
Epoch                        77
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:16:34.135478 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #77 | Epoch Duration: 69.74986219406128
2020-01-11 02:16:34.135613 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #77 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07606255
Z variance train             0.0075072413
KL Divergence                10.545633
KL Loss                      1.0545634
QF Loss                      664.80334
VF Loss                      371.45224
Policy Loss                  -815.7317
Q Predictions Mean           813.54126
Q Predictions Std            554.3286
Q Predictions Max            1632.6688
Q Predictions Min            -19.284866
V Predictions Mean           809.02136
V Predictions Std            550.2796
V Predictions Max            1643.6127
V Predictions Min            -4.2435017
Log Pis Mean                 0.6567848
Log Pis Std                  2.6621253
Log Pis Max                  7.770439
Log Pis Min                  -4.8294806
Policy mu Mean               -0.086052746
Policy mu Std                1.12746
Policy mu Max                2.654088
Policy mu Min                -3.0579388
Policy log std Mean          -0.5083656
Policy log std Std           0.29496685
Policy log std Max           0.04588303
Policy log std Min           -1.6126269
Z mean eval                  0.0760277
Z variance eval              0.006925969
total_rewards                [ 606.53449102  581.34473181  678.06063432  675.69319045  523.86415212
  684.66051204  617.15164094  713.59118689  595.78764464 1515.30463435]
total_rewards_mean           719.199281858316
total_rewards_std            270.9410408415735
total_rewards_max            1515.3046343538856
total_rewards_min            523.8641521225902
Number of train steps total  79000
Number of env steps total    397000
Number of rollouts total     0
Train Time (s)               42.844530885107815
(Previous) Eval Time (s)     5.922511498909444
Sample Time (s)              20.29340013489127
Epoch Time (s)               69.06044251890853
Total Train Time (s)         5365.7289548390545
Epoch                        78
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:17:45.265160 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #78 | Epoch Duration: 71.12945079803467
2020-01-11 02:17:45.265282 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #78 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07147203
Z variance train             0.0076006046
KL Divergence                10.382203
KL Loss                      1.0382203
QF Loss                      547.9626
VF Loss                      383.49725
Policy Loss                  -814.4439
Q Predictions Mean           813.51294
Q Predictions Std            574.0333
Q Predictions Max            1607.2373
Q Predictions Min            -8.410392
V Predictions Mean           816.49286
V Predictions Std            572.90686
V Predictions Max            1621.3291
V Predictions Min            -2.7496397
Log Pis Mean                 0.44358653
Log Pis Std                  2.6254888
Log Pis Max                  12.407385
Log Pis Min                  -5.910893
Policy mu Mean               0.066359185
Policy mu Std                1.0761173
Policy mu Max                3.1076517
Policy mu Min                -3.2084856
Policy log std Mean          -0.49854276
Policy log std Std           0.293751
Policy log std Max           0.07317169
Policy log std Min           -1.9476023
Z mean eval                  0.074356906
Z variance eval              0.007159345
total_rewards                [1356.73531134  430.56222885  485.1384349   933.56136805  886.37397789
  537.38802397 1022.93066087 1286.35829217  520.96320885 1021.54519345]
total_rewards_mean           848.1556700330481
total_rewards_std            320.91073802161793
total_rewards_max            1356.7353113394229
total_rewards_min            430.562228850969
Number of train steps total  80000
Number of env steps total    402000
Number of rollouts total     0
Train Time (s)               43.97589063504711
(Previous) Eval Time (s)     7.991287922952324
Sample Time (s)              22.155781255103648
Epoch Time (s)               74.12295981310308
Total Train Time (s)         5441.496637022123
Epoch                        79
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:19:01.034041 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #79 | Epoch Duration: 75.76866841316223
2020-01-11 02:19:01.034162 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #79 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07817339
Z variance train             0.0067781084
KL Divergence                10.749602
KL Loss                      1.0749602
QF Loss                      626.3981
VF Loss                      146.08911
Policy Loss                  -840.4053
Q Predictions Mean           837.1284
Q Predictions Std            565.4569
Q Predictions Max            1555.8015
Q Predictions Min            -1.9230813
V Predictions Mean           843.0023
V Predictions Std            566.82104
V Predictions Max            1565.6683
V Predictions Min            -2.3693972
Log Pis Mean                 0.53622675
Log Pis Std                  2.4491873
Log Pis Max                  7.424506
Log Pis Min                  -5.0975895
Policy mu Mean               0.030490397
Policy mu Std                1.0612136
Policy mu Max                2.745991
Policy mu Min                -2.9570546
Policy log std Mean          -0.49461564
Policy log std Std           0.30939105
Policy log std Max           0.08473052
Policy log std Min           -1.576283
Z mean eval                  0.0837432
Z variance eval              0.0058615864
total_rewards                [ 250.97274858 1257.83136892  233.43757688 1054.32975107  266.47038604
 1239.08382465  269.48338114  691.91886778  780.94081192  280.12269528]
total_rewards_mean           632.4591412269914
total_rewards_std            407.09104950101124
total_rewards_max            1257.831368920893
total_rewards_min            233.43757688340796
Number of train steps total  81000
Number of env steps total    407000
Number of rollouts total     0
Train Time (s)               42.90504058776423
(Previous) Eval Time (s)     9.636733668856323
Sample Time (s)              21.172030246816576
Epoch Time (s)               73.71380450343713
Total Train Time (s)         5513.665483477991
Epoch                        80
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:20:13.204139 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #80 | Epoch Duration: 72.1698842048645
2020-01-11 02:20:13.204261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #80 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07985669
Z variance train             0.0062019536
KL Divergence                10.836882
KL Loss                      1.0836881
QF Loss                      11365.802
VF Loss                      864.3569
Policy Loss                  -858.0305
Q Predictions Mean           855.75494
Q Predictions Std            526.0996
Q Predictions Max            1549.4441
Q Predictions Min            1.3213404
V Predictions Mean           843.9171
V Predictions Std            522.16156
V Predictions Max            1517.7734
V Predictions Min            -5.258662
Log Pis Mean                 0.77443355
Log Pis Std                  2.6788845
Log Pis Max                  11.10007
Log Pis Min                  -3.9730306
Policy mu Mean               -0.224533
Policy mu Std                1.1369845
Policy mu Max                3.0890298
Policy mu Min                -2.8234081
Policy log std Mean          -0.5217313
Policy log std Std           0.2973334
Policy log std Max           0.072316006
Policy log std Min           -1.5670407
Z mean eval                  0.08378989
Z variance eval              0.00796061
total_rewards                [ 283.60985467 2805.25076766  924.26422192 1020.69451407 2422.26583141
 2120.45969436 1169.51637463  250.25583715 1962.76006306  994.73843979]
total_rewards_mean           1395.3815598718063
total_rewards_std            837.3231349055093
total_rewards_max            2805.250767655251
total_rewards_min            250.2558371500403
Number of train steps total  82000
Number of env steps total    412000
Number of rollouts total     0
Train Time (s)               43.31800524238497
(Previous) Eval Time (s)     8.092570988927037
Sample Time (s)              21.210607977584004
Epoch Time (s)               72.62118420889601
Total Train Time (s)         5594.078764966689
Epoch                        81
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:21:33.618765 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #81 | Epoch Duration: 80.4144115447998
2020-01-11 02:21:33.618889 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #81 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07525996
Z variance train             0.008183789
KL Divergence                10.224905
KL Loss                      1.0224905
QF Loss                      350.12103
VF Loss                      345.94666
Policy Loss                  -808.92114
Q Predictions Mean           809.2915
Q Predictions Std            579.1672
Q Predictions Max            1557.9044
Q Predictions Min            -14.521993
V Predictions Mean           815.25464
V Predictions Std            581.87067
V Predictions Max            1576.8175
V Predictions Min            -6.208104
Log Pis Mean                 0.51774013
Log Pis Std                  2.5808108
Log Pis Max                  8.721955
Log Pis Min                  -7.19164
Policy mu Mean               -0.08404083
Policy mu Std                1.0872178
Policy mu Max                2.8075824
Policy mu Min                -2.8427968
Policy log std Mean          -0.476149
Policy log std Std           0.2780497
Policy log std Max           0.111491695
Policy log std Min           -1.6889052
Z mean eval                  0.08372369
Z variance eval              0.008075475
total_rewards                [ 477.0073698  1305.48445356  468.6298253   518.46931239 1040.09707016
  481.16558555  549.68211123  515.99823194  530.83076935 1002.96431732]
total_rewards_mean           689.0329046593436
total_rewards_std            290.1779033094436
total_rewards_max            1305.4844535562265
total_rewards_min            468.6298253047087
Number of train steps total  83000
Number of env steps total    417000
Number of rollouts total     0
Train Time (s)               42.33343238616362
(Previous) Eval Time (s)     15.885562606155872
Sample Time (s)              22.65370687795803
Epoch Time (s)               80.87270187027752
Total Train Time (s)         5666.818074112292
Epoch                        82
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:22:46.358761 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #82 | Epoch Duration: 72.73977994918823
2020-01-11 02:22:46.358882 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #82 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07318398
Z variance train             0.008220604
KL Divergence                10.279331
KL Loss                      1.0279331
QF Loss                      654.3877
VF Loss                      200.36026
Policy Loss                  -782.6583
Q Predictions Mean           781.10547
Q Predictions Std            528.5906
Q Predictions Max            1476.8866
Q Predictions Min            -28.89534
V Predictions Mean           791.8435
V Predictions Std            533.7263
V Predictions Max            1485.9613
V Predictions Min            -0.5982418
Log Pis Mean                 0.7717764
Log Pis Std                  2.689688
Log Pis Max                  8.651131
Log Pis Min                  -3.5977492
Policy mu Mean               -0.2746691
Policy mu Std                1.1242269
Policy mu Max                2.3969278
Policy mu Min                -2.8954165
Policy log std Mean          -0.4927903
Policy log std Std           0.2695047
Policy log std Max           0.008413434
Policy log std Min           -1.5587656
Z mean eval                  0.07659356
Z variance eval              0.005724256
total_rewards                [ 142.05065773  950.38783461  151.22256688 1259.73046374 1317.41182178
  822.3269179  1784.19956208  352.64117145 1024.78847545 1261.56455017]
total_rewards_mean           906.6324021783819
total_rewards_std            517.168954945054
total_rewards_max            1784.1995620759828
total_rewards_min            142.0506577348771
Number of train steps total  84000
Number of env steps total    422000
Number of rollouts total     0
Train Time (s)               43.663142974022776
(Previous) Eval Time (s)     7.752394264098257
Sample Time (s)              21.747527410276234
Epoch Time (s)               73.16306464839727
Total Train Time (s)         5743.1964015243575
Epoch                        83
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:24:02.739661 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #83 | Epoch Duration: 76.38067436218262
2020-01-11 02:24:02.739825 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #83 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07809679
Z variance train             0.005719972
KL Divergence                11.01514
KL Loss                      1.101514
QF Loss                      518.52527
VF Loss                      347.4206
Policy Loss                  -840.63855
Q Predictions Mean           840.2038
Q Predictions Std            541.5423
Q Predictions Max            1456.065
Q Predictions Min            -1.9527448
V Predictions Mean           841.29297
V Predictions Std            539.0012
V Predictions Max            1448.1644
V Predictions Min            -9.20247
Log Pis Mean                 0.7234391
Log Pis Std                  2.605067
Log Pis Max                  9.488352
Log Pis Min                  -4.1263876
Policy mu Mean               -0.055207044
Policy mu Std                1.1384603
Policy mu Max                3.319524
Policy mu Min                -2.9492555
Policy log std Mean          -0.5159394
Policy log std Std           0.28425446
Policy log std Max           0.032348856
Policy log std Min           -1.6016064
Z mean eval                  0.092274286
Z variance eval              0.005653356
total_rewards                [1969.96885756 2867.68290182  503.65350953  510.97256796 2878.53540588
  555.34601639 1973.03543276 1058.61447505  476.77402101 1830.51639893]
total_rewards_mean           1462.5099586896747
total_rewards_std            917.376750074721
total_rewards_max            2878.5354058836574
total_rewards_min            476.77402101143406
Number of train steps total  85000
Number of env steps total    427000
Number of rollouts total     0
Train Time (s)               42.81512011727318
(Previous) Eval Time (s)     10.969756862148643
Sample Time (s)              19.661148062441498
Epoch Time (s)               73.44602504186332
Total Train Time (s)         5822.600552891381
Epoch                        84
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:25:22.143773 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #84 | Epoch Duration: 79.40383243560791
2020-01-11 02:25:22.143894 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #84 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.062197227
Z variance train             0.0038262282
KL Divergence                12.140266
KL Loss                      1.2140267
QF Loss                      441.34598
VF Loss                      148.35675
Policy Loss                  -841.2907
Q Predictions Mean           844.2277
Q Predictions Std            553.6646
Q Predictions Max            1522.0138
Q Predictions Min            -8.790832
V Predictions Mean           841.8467
V Predictions Std            553.3219
V Predictions Max            1527.8741
V Predictions Min            -11.324792
Log Pis Mean                 0.20025146
Log Pis Std                  2.251185
Log Pis Max                  8.492228
Log Pis Min                  -4.82797
Policy mu Mean               0.09620875
Policy mu Std                1.0123913
Policy mu Max                2.7854638
Policy mu Min                -2.7796574
Policy log std Mean          -0.48373178
Policy log std Std           0.28701243
Policy log std Max           0.034992084
Policy log std Min           -1.7570443
Z mean eval                  0.07785778
Z variance eval              0.010274838
total_rewards                [2685.46722044 1198.93461809  266.50564496  239.75029164 2450.81112007
  123.87149424 2378.4848385  1876.36865313  265.9550492  1891.98752957]
total_rewards_mean           1337.813645984526
total_rewards_std            986.4252633054261
total_rewards_max            2685.4672204405483
total_rewards_min            123.87149424232291
Number of train steps total  86000
Number of env steps total    432000
Number of rollouts total     0
Train Time (s)               44.58469966799021
(Previous) Eval Time (s)     16.927363275084645
Sample Time (s)              21.984452822245657
Epoch Time (s)               83.49651576532051
Total Train Time (s)         5904.997156983707
Epoch                        85
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:26:44.541466 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #85 | Epoch Duration: 82.39747953414917
2020-01-11 02:26:44.541584 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #85 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07438922
Z variance train             0.0055534495
KL Divergence                10.959752
KL Loss                      1.0959753
QF Loss                      1054.689
VF Loss                      271.85507
Policy Loss                  -882.25916
Q Predictions Mean           877.9635
Q Predictions Std            541.0446
Q Predictions Max            1525.5708
Q Predictions Min            -1.7255328
V Predictions Mean           874.8954
V Predictions Std            537.68445
V Predictions Max            1525.3914
V Predictions Min            -4.3169284
Log Pis Mean                 0.81999445
Log Pis Std                  2.825709
Log Pis Max                  9.438143
Log Pis Min                  -6.1329393
Policy mu Mean               -0.039255995
Policy mu Std                1.1637353
Policy mu Max                3.4775949
Policy mu Min                -3.2353568
Policy log std Mean          -0.5157484
Policy log std Std           0.2978254
Policy log std Max           0.054232538
Policy log std Min           -1.9794741
Z mean eval                  0.08407952
Z variance eval              0.00816845
total_rewards                [1486.03765988  787.48295044  980.44665661 1536.32200819  887.40119833
  721.2982808   805.85117175  791.91652101  746.8898113  1162.97296596]
total_rewards_mean           990.6619224255685
total_rewards_std            288.1871495010528
total_rewards_max            1536.3220081902634
total_rewards_min            721.2982807979229
Number of train steps total  87000
Number of env steps total    437000
Number of rollouts total     0
Train Time (s)               43.2687008199282
(Previous) Eval Time (s)     15.82807026989758
Sample Time (s)              20.4674113499932
Epoch Time (s)               79.56418243981898
Total Train Time (s)         5980.139142142609
Epoch                        86
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:27:59.684535 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #86 | Epoch Duration: 75.1428611278534
2020-01-11 02:27:59.684652 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #86 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.087859355
Z variance train             0.0041573234
KL Divergence                11.718875
KL Loss                      1.1718875
QF Loss                      364.71655
VF Loss                      160.38332
Policy Loss                  -776.6301
Q Predictions Mean           773.1538
Q Predictions Std            569.36005
Q Predictions Max            1511.3969
Q Predictions Min            -11.555071
V Predictions Mean           772.30884
V Predictions Std            568.2462
V Predictions Max            1504.1613
V Predictions Min            -18.076939
Log Pis Mean                 0.34040943
Log Pis Std                  2.265842
Log Pis Max                  6.37956
Log Pis Min                  -4.150757
Policy mu Mean               0.010215071
Policy mu Std                1.0412629
Policy mu Max                2.4458742
Policy mu Min                -2.7960944
Policy log std Mean          -0.4758711
Policy log std Std           0.295266
Policy log std Max           0.06670034
Policy log std Min           -2.0929608
Z mean eval                  0.06869157
Z variance eval              0.00843562
total_rewards                [1001.75315808 1015.48893086 1270.43544916  995.48901708 1349.44707114
 1283.6369411   983.42194293 1302.69111859  958.36614148 1023.58609334]
total_rewards_mean           1118.4315863764364
total_rewards_std            151.62053036057551
total_rewards_max            1349.4470711447204
total_rewards_min            958.3661414778012
Number of train steps total  88000
Number of env steps total    442000
Number of rollouts total     0
Train Time (s)               43.087815278209746
(Previous) Eval Time (s)     11.406497469171882
Sample Time (s)              21.728008545469493
Epoch Time (s)               76.22232129285112
Total Train Time (s)         6056.959188366309
Epoch                        87
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:29:16.506213 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #87 | Epoch Duration: 76.82146954536438
2020-01-11 02:29:16.506337 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #87 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06590458
Z variance train             0.008070664
KL Divergence                9.851803
KL Loss                      0.9851803
QF Loss                      646.51154
VF Loss                      585.35785
Policy Loss                  -852.40955
Q Predictions Mean           853.573
Q Predictions Std            519.30597
Q Predictions Max            1533.2286
Q Predictions Min            -26.457695
V Predictions Mean           855.6698
V Predictions Std            514.42694
V Predictions Max            1517.4089
V Predictions Min            -14.264961
Log Pis Mean                 0.69176245
Log Pis Std                  2.3372116
Log Pis Max                  10.374495
Log Pis Min                  -3.5182314
Policy mu Mean               -0.023204148
Policy mu Std                1.111132
Policy mu Max                2.9199338
Policy mu Min                -2.7486396
Policy log std Mean          -0.53687674
Policy log std Std           0.2727788
Policy log std Max           0.10541612
Policy log std Min           -1.5749769
Z mean eval                  0.072379924
Z variance eval              0.009294963
total_rewards                [1079.28531163 1144.87708544 2827.76644585 2169.34255002  755.01137812
 2094.97692177 1468.95570049 1208.51746369 1938.36759771 2417.98712029]
total_rewards_mean           1710.5087575022585
total_rewards_std            640.3713651488204
total_rewards_max            2827.766445852415
total_rewards_min            755.0113781227569
Number of train steps total  89000
Number of env steps total    447000
Number of rollouts total     0
Train Time (s)               42.95138508500531
(Previous) Eval Time (s)     12.005396197084337
Sample Time (s)              21.856923357583582
Epoch Time (s)               76.81370463967323
Total Train Time (s)         6140.474621474743
Epoch                        88
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:30:40.022529 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #88 | Epoch Duration: 83.51609992980957
2020-01-11 02:30:40.022652 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #88 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06373656
Z variance train             0.004338079
KL Divergence                11.524941
KL Loss                      1.1524942
QF Loss                      366.68817
VF Loss                      213.39696
Policy Loss                  -829.25885
Q Predictions Mean           825.905
Q Predictions Std            522.45776
Q Predictions Max            1446.3395
Q Predictions Min            -3.9249318
V Predictions Mean           820.7489
V Predictions Std            520.9961
V Predictions Max            1416.5466
V Predictions Min            -9.30418
Log Pis Mean                 0.45479393
Log Pis Std                  2.3707964
Log Pis Max                  8.099173
Log Pis Min                  -4.866109
Policy mu Mean               0.046361517
Policy mu Std                1.0724872
Policy mu Max                2.2992647
Policy mu Min                -2.7174962
Policy log std Mean          -0.5181261
Policy log std Std           0.29222086
Policy log std Max           0.07296398
Policy log std Min           -1.7790072
Z mean eval                  0.075433895
Z variance eval              0.011685731
total_rewards                [ 981.00569161 2587.33503206  642.43212643  708.14738734  754.78071664
 1397.25431469 1615.33067915 1572.66485297 1045.32975628 1827.37710485]
total_rewards_mean           1313.1657662025452
total_rewards_std            579.950521572308
total_rewards_max            2587.335032063769
total_rewards_min            642.432126429521
Number of train steps total  90000
Number of env steps total    452000
Number of rollouts total     0
Train Time (s)               43.94762178417295
(Previous) Eval Time (s)     18.70754547417164
Sample Time (s)              21.99292061617598
Epoch Time (s)               84.64808787452057
Total Train Time (s)         6222.968714368064
Epoch                        89
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:32:02.517611 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #89 | Epoch Duration: 82.49486422538757
2020-01-11 02:32:02.517729 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #89 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06645646
Z variance train             0.006121476
KL Divergence                10.83195
KL Loss                      1.0831951
QF Loss                      396.2378
VF Loss                      221.57167
Policy Loss                  -815.05115
Q Predictions Mean           813.0161
Q Predictions Std            519.8985
Q Predictions Max            1456.5355
Q Predictions Min            -9.63224
V Predictions Mean           816.5067
V Predictions Std            521.4056
V Predictions Max            1458.0303
V Predictions Min            -3.168536
Log Pis Mean                 0.5287403
Log Pis Std                  2.6982005
Log Pis Max                  12.597477
Log Pis Min                  -3.294107
Policy mu Mean               0.066447794
Policy mu Std                1.0591587
Policy mu Max                3.1456783
Policy mu Min                -3.6079166
Policy log std Mean          -0.49375677
Policy log std Std           0.27887952
Policy log std Max           0.02151519
Policy log std Min           -1.5746279
Z mean eval                  0.0915977
Z variance eval              0.0066994405
total_rewards                [888.09078783 711.81475735 834.34240553 619.33156135 612.134479
 866.99545793 906.03351132 596.50277788 930.10175026 945.02938682]
total_rewards_mean           791.0376875277365
total_rewards_std            133.77217116177036
total_rewards_max            945.0293868166809
total_rewards_min            596.5027778779734
Number of train steps total  91000
Number of env steps total    457000
Number of rollouts total     0
Train Time (s)               44.50845571793616
(Previous) Eval Time (s)     16.55406475486234
Sample Time (s)              22.038515110965818
Epoch Time (s)               83.10103558376431
Total Train Time (s)         6299.060809421353
Epoch                        90
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:33:18.611785 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #90 | Epoch Duration: 76.0939531326294
2020-01-11 02:33:18.611942 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #90 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09064506
Z variance train             0.009178711
KL Divergence                9.602316
KL Loss                      0.9602316
QF Loss                      346.9369
VF Loss                      361.00006
Policy Loss                  -863.7692
Q Predictions Mean           865.7937
Q Predictions Std            534.6764
Q Predictions Max            1454.953
Q Predictions Min            -1.5336509
V Predictions Mean           878.17487
V Predictions Std            539.3446
V Predictions Max            1470.9073
V Predictions Min            -6.712747
Log Pis Mean                 0.5681665
Log Pis Std                  2.6248677
Log Pis Max                  13.6202965
Log Pis Min                  -4.3166056
Policy mu Mean               0.05537073
Policy mu Std                1.1002884
Policy mu Max                2.8222432
Policy mu Min                -3.2349908
Policy log std Mean          -0.5109363
Policy log std Std           0.26571178
Policy log std Max           0.016927093
Policy log std Min           -1.4987526
Z mean eval                  0.07209778
Z variance eval              0.010829173
total_rewards                [1038.82883548 3189.77738464 1968.88433061 1662.5613533   907.91818183
 1522.46151362  840.16846316  798.4020062  1407.8068513  1567.21059556]
total_rewards_mean           1490.401951569755
total_rewards_std            678.6076611796652
total_rewards_max            3189.7773846404684
total_rewards_min            798.4020061975865
Number of train steps total  92000
Number of env steps total    462000
Number of rollouts total     0
Train Time (s)               43.12411726266146
(Previous) Eval Time (s)     9.546734143979847
Sample Time (s)              22.634675746317953
Epoch Time (s)               75.30552715295926
Total Train Time (s)         6380.6231299676
Epoch                        91
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:34:40.174793 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #91 | Epoch Duration: 81.56270027160645
2020-01-11 02:34:40.174916 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #91 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0821314
Z variance train             0.004098869
KL Divergence                11.628265
KL Loss                      1.1628265
QF Loss                      828.20593
VF Loss                      172.44797
Policy Loss                  -845.01666
Q Predictions Mean           839.14197
Q Predictions Std            535.3177
Q Predictions Max            1446.7283
Q Predictions Min            -9.554655
V Predictions Mean           846.5028
V Predictions Std            533.47174
V Predictions Max            1446.4811
V Predictions Min            -0.43891552
Log Pis Mean                 0.7087142
Log Pis Std                  2.5344412
Log Pis Max                  7.9218936
Log Pis Min                  -4.703148
Policy mu Mean               0.14070393
Policy mu Std                1.1047267
Policy mu Max                3.3074503
Policy mu Min                -2.8516254
Policy log std Mean          -0.5403841
Policy log std Std           0.28793904
Policy log std Max           0.10090673
Policy log std Min           -1.6426657
Z mean eval                  0.04988625
Z variance eval              0.0043405313
total_rewards                [1034.26651572  879.81374269  866.29546668  684.73033664  834.79376842
  641.49525388 1019.29614888  848.58140617  710.12033512  673.7205659 ]
total_rewards_mean           819.3113540101161
total_rewards_std            132.67030511940732
total_rewards_max            1034.266515721887
total_rewards_min            641.4952538842349
Number of train steps total  93000
Number of env steps total    467000
Number of rollouts total     0
Train Time (s)               43.6364717669785
(Previous) Eval Time (s)     15.803656504955143
Sample Time (s)              21.84518962027505
Epoch Time (s)               81.2853178922087
Total Train Time (s)         6456.0913832844235
Epoch                        92
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:35:55.646006 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #92 | Epoch Duration: 75.47098541259766
2020-01-11 02:35:55.646173 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #92 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05071615
Z variance train             0.004338151
KL Divergence                11.596242
KL Loss                      1.1596242
QF Loss                      614.833
VF Loss                      490.81915
Policy Loss                  -819.0264
Q Predictions Mean           822.3065
Q Predictions Std            539.59015
Q Predictions Max            1431.7244
Q Predictions Min            3.9166915
V Predictions Mean           803.5759
V Predictions Std            531.1361
V Predictions Max            1380.9116
V Predictions Min            1.5669364
Log Pis Mean                 0.17275776
Log Pis Std                  2.2343261
Log Pis Max                  7.3360553
Log Pis Min                  -3.8854842
Policy mu Mean               -0.09688119
Policy mu Std                0.9887089
Policy mu Max                2.5604324
Policy mu Min                -2.9692419
Policy log std Mean          -0.5175246
Policy log std Std           0.30429175
Policy log std Max           0.11511931
Policy log std Min           -1.7044398
Z mean eval                  0.06041237
Z variance eval              0.012423517
total_rewards                [ 604.37608976  583.78516831  679.86419517 1146.70916168 1634.09775689
  629.27323458  621.2728998   755.30790443  636.66510483  630.92290884]
total_rewards_mean           792.2274424291691
total_rewards_std            321.4227905048426
total_rewards_max            1634.0977568946555
total_rewards_min            583.7851683068197
Number of train steps total  94000
Number of env steps total    472000
Number of rollouts total     0
Train Time (s)               43.23126532090828
(Previous) Eval Time (s)     9.989084629807621
Sample Time (s)              22.445044276770204
Epoch Time (s)               75.6653942274861
Total Train Time (s)         6531.154161540326
Epoch                        93
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:37:10.708119 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #93 | Epoch Duration: 75.06182527542114
2020-01-11 02:37:10.708247 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #93 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06169074
Z variance train             0.012362784
KL Divergence                8.881334
KL Loss                      0.88813347
QF Loss                      711.646
VF Loss                      374.43427
Policy Loss                  -897.5359
Q Predictions Mean           892.21423
Q Predictions Std            501.73038
Q Predictions Max            1468.1407
Q Predictions Min            -28.78921
V Predictions Mean           888.40857
V Predictions Std            499.4328
V Predictions Max            1419.2875
V Predictions Min            -8.407628
Log Pis Mean                 0.4969653
Log Pis Std                  2.2953002
Log Pis Max                  8.218721
Log Pis Min                  -5.343806
Policy mu Mean               0.11122734
Policy mu Std                1.0469779
Policy mu Max                3.5444474
Policy mu Min                -2.9164965
Policy log std Mean          -0.53441006
Policy log std Std           0.28215382
Policy log std Max           -0.0029002428
Policy log std Min           -1.6009643
Z mean eval                  0.048037432
Z variance eval              0.005419706
total_rewards                [ 624.45374501  743.3675771  1005.98092315  856.76054052 1139.08638944
  896.24674273  612.05131831  904.51283612 1152.06707272 1241.8152272 ]
total_rewards_mean           917.6342372292231
total_rewards_std            207.59047532919018
total_rewards_max            1241.815227202889
total_rewards_min            612.0513183063473
Number of train steps total  95000
Number of env steps total    477000
Number of rollouts total     0
Train Time (s)               42.545531754381955
(Previous) Eval Time (s)     9.385259896051139
Sample Time (s)              22.927413284778595
Epoch Time (s)               74.85820493521169
Total Train Time (s)         6606.758070863783
Epoch                        94
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:38:26.314443 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #94 | Epoch Duration: 75.6061019897461
2020-01-11 02:38:26.314567 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #94 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050048046
Z variance train             0.008561235
KL Divergence                9.827225
KL Loss                      0.98272246
QF Loss                      582.0092
VF Loss                      414.9017
Policy Loss                  -850.19366
Q Predictions Mean           857.60266
Q Predictions Std            490.29407
Q Predictions Max            1374.8387
Q Predictions Min            -21.310106
V Predictions Mean           855.872
V Predictions Std            488.82913
V Predictions Max            1360.2003
V Predictions Min            -3.2154818
Log Pis Mean                 0.30113044
Log Pis Std                  2.415918
Log Pis Max                  8.353859
Log Pis Min                  -5.8579264
Policy mu Mean               0.009373969
Policy mu Std                1.0164522
Policy mu Max                2.8620741
Policy mu Min                -2.7788794
Policy log std Mean          -0.51957387
Policy log std Std           0.26875383
Policy log std Max           0.001993984
Policy log std Min           -1.6327394
Z mean eval                  0.05651449
Z variance eval              0.008499295
total_rewards                [ 888.0505786   897.23711997  893.02483179 1058.44162824  783.14528936
  976.09529001  754.53485939  735.82536552  741.581092    880.91368921]
total_rewards_mean           860.884974408187
total_rewards_std            101.50012039877781
total_rewards_max            1058.441628243384
total_rewards_min            735.8253655177247
Number of train steps total  96000
Number of env steps total    482000
Number of rollouts total     0
Train Time (s)               42.64129717228934
(Previous) Eval Time (s)     10.132904177065939
Sample Time (s)              21.9816861897707
Epoch Time (s)               74.75588753912598
Total Train Time (s)         6680.786028176546
Epoch                        95
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:39:40.346966 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #95 | Epoch Duration: 74.03227710723877
2020-01-11 02:39:40.347188 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #95 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.056066662
Z variance train             0.008457044
KL Divergence                9.782387
KL Loss                      0.9782387
QF Loss                      799.6146
VF Loss                      410.42926
Policy Loss                  -892.45
Q Predictions Mean           889.1546
Q Predictions Std            504.9275
Q Predictions Max            1389.4805
Q Predictions Min            -15.357552
V Predictions Mean           889.74976
V Predictions Std            501.17636
V Predictions Max            1404.4084
V Predictions Min            -26.782486
Log Pis Mean                 0.14597663
Log Pis Std                  2.2476919
Log Pis Max                  8.719357
Log Pis Min                  -5.010097
Policy mu Mean               -0.022942342
Policy mu Std                0.97681296
Policy mu Max                2.9900358
Policy mu Min                -2.928329
Policy log std Mean          -0.5164148
Policy log std Std           0.27159703
Policy log std Max           0.019277781
Policy log std Min           -1.914066
Z mean eval                  0.03556313
Z variance eval              0.005136948
total_rewards                [ 645.3718796   868.73480942  679.30887042  601.88386427  672.88206705
  832.30403881 1037.25188439  659.73594152  648.15200404  708.36878612]
total_rewards_mean           735.3994145628128
total_rewards_std            128.58359189192126
total_rewards_max            1037.251884387625
total_rewards_min            601.8838642692402
Number of train steps total  97000
Number of env steps total    487000
Number of rollouts total     0
Train Time (s)               42.88711320981383
(Previous) Eval Time (s)     9.409027504269034
Sample Time (s)              22.073235136456788
Epoch Time (s)               74.36937585053965
Total Train Time (s)         6753.8927013748325
Epoch                        96
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:40:53.454896 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #96 | Epoch Duration: 73.10753536224365
2020-01-11 02:40:53.455063 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #96 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03870297
Z variance train             0.0052347495
KL Divergence                11.081781
KL Loss                      1.1081781
QF Loss                      338.82422
VF Loss                      131.60023
Policy Loss                  -824.87756
Q Predictions Mean           819.9968
Q Predictions Std            491.32535
Q Predictions Max            1382.4688
Q Predictions Min            -5.102368
V Predictions Mean           822.6363
V Predictions Std            490.1823
V Predictions Max            1367.639
V Predictions Min            -2.2483392
Log Pis Mean                 0.332506
Log Pis Std                  2.428286
Log Pis Max                  7.074829
Log Pis Min                  -5.284292
Policy mu Mean               -0.020718537
Policy mu Std                1.0453916
Policy mu Max                3.174648
Policy mu Min                -2.882749
Policy log std Mean          -0.5194572
Policy log std Std           0.28621995
Policy log std Max           0.119280756
Policy log std Min           -1.6213202
Z mean eval                  0.029978106
Z variance eval              0.0063004987
total_rewards                [ 863.4387382  1240.36839273  673.05732328  668.60792992  595.58696689
  653.10350296  974.41589959  710.64650563  737.46528215  476.75892805]
total_rewards_mean           759.344946940791
total_rewards_std            206.14615789650205
total_rewards_max            1240.36839273499
total_rewards_min            476.75892804940236
Number of train steps total  98000
Number of env steps total    492000
Number of rollouts total     0
Train Time (s)               43.06585217313841
(Previous) Eval Time (s)     8.146966977976263
Sample Time (s)              22.193504178896546
Epoch Time (s)               73.40632333001122
Total Train Time (s)         6826.929919871502
Epoch                        97
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:42:06.496024 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #97 | Epoch Duration: 73.0407862663269
2020-01-11 02:42:06.496251 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #97 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02953279
Z variance train             0.00626292
KL Divergence                10.6765375
KL Loss                      1.0676538
QF Loss                      542.2419
VF Loss                      164.29776
Policy Loss                  -890.2702
Q Predictions Mean           883.69116
Q Predictions Std            511.6983
Q Predictions Max            1433.2911
Q Predictions Min            -8.082176
V Predictions Mean           890.0357
V Predictions Std            514.8069
V Predictions Max            1433.7397
V Predictions Min            -9.178391
Log Pis Mean                 0.30004567
Log Pis Std                  2.5092254
Log Pis Max                  10.103424
Log Pis Min                  -6.3009543
Policy mu Mean               0.15824968
Policy mu Std                1.0386796
Policy mu Max                2.8448448
Policy mu Min                -3.179396
Policy log std Mean          -0.48885664
Policy log std Std           0.26388794
Policy log std Max           0.088588506
Policy log std Min           -1.718607
Z mean eval                  0.040725213
Z variance eval              0.006240148
total_rewards                [985.10125022 844.08589826 751.5037975  847.01042541 679.40672124
 682.45967296 847.16280869 843.58582036 818.08949385 754.1899345 ]
total_rewards_mean           805.2595822991896
total_rewards_std            86.83293296097808
total_rewards_max            985.1012502226438
total_rewards_min            679.4067212359288
Number of train steps total  99000
Number of env steps total    497000
Number of rollouts total     0
Train Time (s)               44.20221738703549
(Previous) Eval Time (s)     7.781187348999083
Sample Time (s)              22.036998245865107
Epoch Time (s)               74.02040298189968
Total Train Time (s)         6902.2492375862785
Epoch                        98
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:43:21.816343 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #98 | Epoch Duration: 75.31991600990295
2020-01-11 02:43:21.816492 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #98 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03907
Z variance train             0.006219356
KL Divergence                10.602531
KL Loss                      1.0602531
QF Loss                      638.88293
VF Loss                      298.62607
Policy Loss                  -847.19116
Q Predictions Mean           844.0597
Q Predictions Std            509.1882
Q Predictions Max            1420.9336
Q Predictions Min            -4.5733995
V Predictions Mean           852.9193
V Predictions Std            506.81644
V Predictions Max            1436.5107
V Predictions Min            -5.076937
Log Pis Mean                 0.5065868
Log Pis Std                  2.4831028
Log Pis Max                  12.871712
Log Pis Min                  -5.0606036
Policy mu Mean               0.03603145
Policy mu Std                1.0589199
Policy mu Max                3.304822
Policy mu Min                -3.2783663
Policy log std Mean          -0.5136638
Policy log std Std           0.2678577
Policy log std Max           -0.01951003
Policy log std Min           -1.4782009
Z mean eval                  0.036786802
Z variance eval              0.0071502565
total_rewards                [1004.70759388  624.12808307 1040.4295172   947.64673162  634.51269768
  987.24986286 1488.94875853  692.85848369  961.96965574 1021.30762264]
total_rewards_mean           940.3759006899451
total_rewards_std            240.66108810978753
total_rewards_max            1488.9487585329564
total_rewards_min            624.1280830686466
Number of train steps total  100000
Number of env steps total    502000
Number of rollouts total     0
Train Time (s)               43.69841403514147
(Previous) Eval Time (s)     9.080454694107175
Sample Time (s)              22.326821491122246
Epoch Time (s)               75.10569022037089
Total Train Time (s)         6978.770863451064
Epoch                        99
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:44:38.338738 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #99 | Epoch Duration: 76.52214908599854
2020-01-11 02:44:38.338864 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #99 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03186254
Z variance train             0.0066556805
KL Divergence                10.482795
KL Loss                      1.0482795
QF Loss                      321.58627
VF Loss                      78.848564
Policy Loss                  -837.373
Q Predictions Mean           834.5366
Q Predictions Std            512.2841
Q Predictions Max            1380.9802
Q Predictions Min            -21.21746
V Predictions Mean           837.359
V Predictions Std            510.83682
V Predictions Max            1371.6853
V Predictions Min            -7.4314914
Log Pis Mean                 0.14400889
Log Pis Std                  2.2385073
Log Pis Max                  10.067041
Log Pis Min                  -3.7932112
Policy mu Mean               0.050813515
Policy mu Std                0.9561721
Policy mu Max                3.0184195
Policy mu Min                -3.866268
Policy log std Mean          -0.5209928
Policy log std Std           0.2707132
Policy log std Max           -0.0053713024
Policy log std Min           -1.4661837
Z mean eval                  0.03835938
Z variance eval              0.008064957
total_rewards                [ 980.83573708  746.35998659  720.04683527  966.27167597  916.14575162
 1588.27784811  816.85351419  943.9032341   720.15175073 1096.63792591]
total_rewards_mean           949.5484259568071
total_rewards_std            244.17290220841153
total_rewards_max            1588.2778481097935
total_rewards_min            720.0468352732187
Number of train steps total  101000
Number of env steps total    507000
Number of rollouts total     0
Train Time (s)               43.385417392943054
(Previous) Eval Time (s)     10.496661074925214
Sample Time (s)              22.246849358081818
Epoch Time (s)               76.12892782595009
Total Train Time (s)         7054.83041618485
Epoch                        100
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:45:54.399355 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #100 | Epoch Duration: 76.06039905548096
2020-01-11 02:45:54.399472 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #100 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033955164
Z variance train             0.009012333
KL Divergence                9.459262
KL Loss                      0.9459262
QF Loss                      9527.208
VF Loss                      269.9297
Policy Loss                  -890.0903
Q Predictions Mean           891.5342
Q Predictions Std            476.48355
Q Predictions Max            1378.773
Q Predictions Min            -18.310232
V Predictions Mean           886.93036
V Predictions Std            473.3952
V Predictions Max            1363.6809
V Predictions Min            -6.8482256
Log Pis Mean                 0.37401426
Log Pis Std                  2.5417285
Log Pis Max                  9.417237
Log Pis Min                  -5.763912
Policy mu Mean               -0.10672316
Policy mu Std                1.057326
Policy mu Max                3.09513
Policy mu Min                -3.5064106
Policy log std Mean          -0.54143274
Policy log std Std           0.27486864
Policy log std Max           0.036209375
Policy log std Min           -1.6344925
Z mean eval                  0.03256644
Z variance eval              0.0076158186
total_rewards                [1527.58172905  822.56838539  645.15294501  849.25851095  745.53543529
 1142.86655863 1142.39619491 1458.21159365  892.50326509  787.69013741]
total_rewards_mean           1001.3764755383756
total_rewards_std            288.17938436331195
total_rewards_max            1527.5817290541543
total_rewards_min            645.1529450137984
Number of train steps total  102000
Number of env steps total    512000
Number of rollouts total     0
Train Time (s)               42.869309226982296
(Previous) Eval Time (s)     10.42788157472387
Sample Time (s)              21.301544461864978
Epoch Time (s)               74.59873526357114
Total Train Time (s)         7129.322784351651
Epoch                        101
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:47:08.895698 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #101 | Epoch Duration: 74.49612331390381
2020-01-11 02:47:08.895869 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #101 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03422216
Z variance train             0.0076147006
KL Divergence                9.910002
KL Loss                      0.9910002
QF Loss                      420.13763
VF Loss                      296.68005
Policy Loss                  -872.25995
Q Predictions Mean           867.62024
Q Predictions Std            493.32053
Q Predictions Max            1422.6672
Q Predictions Min            -9.789468
V Predictions Mean           861.47296
V Predictions Std            490.38724
V Predictions Max            1385.6737
V Predictions Min            -3.440221
Log Pis Mean                 0.36886847
Log Pis Std                  2.447817
Log Pis Max                  9.47843
Log Pis Min                  -5.5042744
Policy mu Mean               0.14907062
Policy mu Std                1.0473379
Policy mu Max                2.4261363
Policy mu Min                -3.0243206
Policy log std Mean          -0.52671707
Policy log std Std           0.28362995
Policy log std Max           0.07739884
Policy log std Min           -1.472439
Z mean eval                  0.029122597
Z variance eval              0.0075973496
total_rewards                [1064.74865537 1341.03304631  947.94754554  792.93203516  850.72893314
  935.56422746  825.2390951  1008.5341838  1465.23339321  833.43990784]
total_rewards_mean           1006.540102293284
total_rewards_std            216.07572713338578
total_rewards_max            1465.2333932127626
total_rewards_min            792.9320351624846
Number of train steps total  103000
Number of env steps total    517000
Number of rollouts total     0
Train Time (s)               43.17827918380499
(Previous) Eval Time (s)     10.324995416682214
Sample Time (s)              21.89581023203209
Epoch Time (s)               75.39908483251929
Total Train Time (s)         7204.893995701801
Epoch                        102
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:48:24.469929 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #102 | Epoch Duration: 75.57391262054443
2020-01-11 02:48:24.470129 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #102 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02953892
Z variance train             0.007595496
KL Divergence                10.046282
KL Loss                      1.0046282
QF Loss                      482.52264
VF Loss                      263.486
Policy Loss                  -838.1403
Q Predictions Mean           840.97205
Q Predictions Std            489.6428
Q Predictions Max            1340.3849
Q Predictions Min            0.954628
V Predictions Mean           829.268
V Predictions Std            482.89658
V Predictions Max            1303.9882
V Predictions Min            2.7134943
Log Pis Mean                 0.40502542
Log Pis Std                  2.4257312
Log Pis Max                  7.676505
Log Pis Min                  -4.7634735
Policy mu Mean               -0.122598924
Policy mu Std                1.00561
Policy mu Max                2.6904101
Policy mu Min                -2.8443208
Policy log std Mean          -0.5414652
Policy log std Std           0.28546003
Policy log std Max           -0.0420817
Policy log std Min           -1.6188394
Z mean eval                  0.03527776
Z variance eval              0.0077003227
total_rewards                [ 856.01018685  964.07801734 1039.04847391  968.2631601  1042.11717571
  778.41409827  960.72648634  693.44343057 1047.73905194 1009.24479774]
total_rewards_mean           935.9084878770279
total_rewards_std            114.9940159421116
total_rewards_max            1047.7390519387397
total_rewards_min            693.4434305698295
Number of train steps total  104000
Number of env steps total    522000
Number of rollouts total     0
Train Time (s)               43.59437622083351
(Previous) Eval Time (s)     10.499527094885707
Sample Time (s)              21.96394736599177
Epoch Time (s)               76.05785068171099
Total Train Time (s)         7281.908384915907
Epoch                        103
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:49:41.485014 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #103 | Epoch Duration: 77.01474332809448
2020-01-11 02:49:41.485139 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #103 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035422776
Z variance train             0.0076875724
KL Divergence                9.943687
KL Loss                      0.99436873
QF Loss                      458.1524
VF Loss                      168.41808
Policy Loss                  -937.72205
Q Predictions Mean           937.40894
Q Predictions Std            465.19797
Q Predictions Max            1398.9121
Q Predictions Min            -0.66613305
V Predictions Mean           935.5434
V Predictions Std            463.33786
V Predictions Max            1385.5276
V Predictions Min            -0.99111074
Log Pis Mean                 0.23691303
Log Pis Std                  2.1913097
Log Pis Max                  7.07755
Log Pis Min                  -6.8102694
Policy mu Mean               -0.043224707
Policy mu Std                0.98867106
Policy mu Max                2.5435195
Policy mu Min                -3.1709082
Policy log std Mean          -0.52882653
Policy log std Std           0.25974712
Policy log std Max           -0.024808764
Policy log std Min           -1.5587188
Z mean eval                  0.035154883
Z variance eval              0.0068266555
total_rewards                [ 986.35448664 1274.17096316 1675.43701167 2950.98502064 1306.90273664
 1012.60530884  591.35141579 2526.13519921 1591.32858373 1279.10585063]
total_rewards_mean           1519.437657695583
total_rewards_std            682.477756946797
total_rewards_max            2950.9850206448955
total_rewards_min            591.3514157904037
Number of train steps total  105000
Number of env steps total    527000
Number of rollouts total     0
Train Time (s)               43.81837005726993
(Previous) Eval Time (s)     11.456190486904234
Sample Time (s)              21.306195007171482
Epoch Time (s)               76.58075555134565
Total Train Time (s)         7362.6063693254255
Epoch                        104
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:51:02.184746 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #104 | Epoch Duration: 80.69951248168945
2020-01-11 02:51:02.184870 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #104 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03193574
Z variance train             0.006826273
KL Divergence                10.094388
KL Loss                      1.0094389
QF Loss                      408.5741
VF Loss                      307.40005
Policy Loss                  -866.07245
Q Predictions Mean           868.45654
Q Predictions Std            458.63303
Q Predictions Max            1336.602
Q Predictions Min            -14.577796
V Predictions Mean           865.66077
V Predictions Std            454.44077
V Predictions Max            1328.6691
V Predictions Min            -2.5471764
Log Pis Mean                 0.19896546
Log Pis Std                  2.2169979
Log Pis Max                  6.7752075
Log Pis Min                  -5.956378
Policy mu Mean               0.11326331
Policy mu Std                1.0159433
Policy mu Max                2.5427868
Policy mu Min                -2.681816
Policy log std Mean          -0.5280616
Policy log std Std           0.2773599
Policy log std Max           0.0082473755
Policy log std Min           -1.4414648
Z mean eval                  0.013395418
Z variance eval              0.007184534
total_rewards                [1256.41357951 1311.28583425 1295.54080702 1180.50243453 3262.29718007
 1036.59058102 2408.17946626  934.59700108  793.3192775   850.91177578]
total_rewards_mean           1432.963793701322
total_rewards_std            746.9614720968675
total_rewards_max            3262.2971800693813
total_rewards_min            793.3192775041913
Number of train steps total  106000
Number of env steps total    532000
Number of rollouts total     0
Train Time (s)               43.29482100578025
(Previous) Eval Time (s)     15.574693491216749
Sample Time (s)              22.224092188756913
Epoch Time (s)               81.09360668575391
Total Train Time (s)         7442.072389970534
Epoch                        105
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:52:21.652954 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #105 | Epoch Duration: 79.46796464920044
2020-01-11 02:52:21.653159 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #105 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012338148
Z variance train             0.0071994215
KL Divergence                10.038715
KL Loss                      1.0038716
QF Loss                      266.00558
VF Loss                      810.0035
Policy Loss                  -862.61487
Q Predictions Mean           864.17676
Q Predictions Std            484.07672
Q Predictions Max            1337.562
Q Predictions Min            -45.95876
V Predictions Mean           858.70465
V Predictions Std            479.24695
V Predictions Max            1318.1509
V Predictions Min            -15.614932
Log Pis Mean                 0.07668942
Log Pis Std                  2.3540707
Log Pis Max                  7.513511
Log Pis Min                  -5.6295385
Policy mu Mean               -0.03256416
Policy mu Std                0.9864061
Policy mu Max                2.4193282
Policy mu Min                -2.7719772
Policy log std Mean          -0.53139496
Policy log std Std           0.28686476
Policy log std Max           -0.04993403
Policy log std Min           -1.4390544
Z mean eval                  0.020916134
Z variance eval              0.0066600917
total_rewards                [1393.20823789 1031.19190034  661.76172812  922.24585739  860.59786839
 1151.53353215 1592.05270548  888.41328727  858.46936958  597.57473786]
total_rewards_mean           995.7049224467994
total_rewards_std            293.8030613317274
total_rewards_max            1592.0527054750137
total_rewards_min            597.5747378602423
Number of train steps total  107000
Number of env steps total    537000
Number of rollouts total     0
Train Time (s)               44.03464848967269
(Previous) Eval Time (s)     13.948791336733848
Sample Time (s)              21.962805446237326
Epoch Time (s)               79.94624527264386
Total Train Time (s)         7520.133307530079
Epoch                        106
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:53:39.714309 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #106 | Epoch Duration: 78.06100153923035
2020-01-11 02:53:39.714429 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #106 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020859292
Z variance train             0.0066570924
KL Divergence                10.272839
KL Loss                      1.0272839
QF Loss                      406.01602
VF Loss                      310.3038
Policy Loss                  -861.3779
Q Predictions Mean           863.30994
Q Predictions Std            470.50354
Q Predictions Max            1313.2578
Q Predictions Min            -10.028275
V Predictions Mean           873.61786
V Predictions Std            473.0251
V Predictions Max            1326.4734
V Predictions Min            -10.064764
Log Pis Mean                 0.29762572
Log Pis Std                  2.5694637
Log Pis Max                  10.406369
Log Pis Min                  -4.737024
Policy mu Mean               0.16069026
Policy mu Std                1.045759
Policy mu Max                3.138935
Policy mu Min                -4.3564963
Policy log std Mean          -0.5125202
Policy log std Std           0.2806665
Policy log std Max           -0.044056803
Policy log std Min           -1.5314945
Z mean eval                  0.021334395
Z variance eval              0.007875711
total_rewards                [2279.85939616 1878.53271219 2886.35276942  687.37146764 3019.04847869
 1268.84193997 1204.5769483  2616.62861048 2602.32067798  913.38132015]
total_rewards_mean           1935.6914320977944
total_rewards_std            817.9147571728013
total_rewards_max            3019.048478693208
total_rewards_min            687.3714676435926
Number of train steps total  108000
Number of env steps total    542000
Number of rollouts total     0
Train Time (s)               43.034202840644866
(Previous) Eval Time (s)     12.063308720942587
Sample Time (s)              21.4447289891541
Epoch Time (s)               76.54224055074155
Total Train Time (s)         7604.185845338274
Epoch                        107
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:55:03.772903 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #107 | Epoch Duration: 84.0583245754242
2020-01-11 02:55:03.773183 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #107 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02151261
Z variance train             0.007871085
KL Divergence                9.892562
KL Loss                      0.9892562
QF Loss                      230.7812
VF Loss                      165.49109
Policy Loss                  -917.5176
Q Predictions Mean           915.89417
Q Predictions Std            469.18484
Q Predictions Max            1345.3461
Q Predictions Min            -22.971622
V Predictions Mean           924.7075
V Predictions Std            470.11575
V Predictions Max            1370.2688
V Predictions Min            3.5600088
Log Pis Mean                 0.28952926
Log Pis Std                  2.318927
Log Pis Max                  9.7964325
Log Pis Min                  -3.9799309
Policy mu Mean               -0.026905192
Policy mu Std                1.0160519
Policy mu Max                3.630448
Policy mu Min                -2.8470669
Policy log std Mean          -0.5314774
Policy log std Std           0.2626449
Policy log std Max           -0.026597857
Policy log std Min           -1.4033513
Z mean eval                  0.026531745
Z variance eval              0.0072655813
total_rewards                [1206.84720816 1128.90202002 1006.31733126  910.90996805 1135.01679388
 1448.4286616  2312.73780527  857.00876107  889.03757998  954.64102124]
total_rewards_mean           1184.984715052872
total_rewards_std            412.6257296024006
total_rewards_max            2312.7378052673243
total_rewards_min            857.0087610740193
Number of train steps total  109000
Number of env steps total    547000
Number of rollouts total     0
Train Time (s)               43.47352684382349
(Previous) Eval Time (s)     19.57914665294811
Sample Time (s)              21.822479223832488
Epoch Time (s)               84.87515272060409
Total Train Time (s)         7682.300466590561
Epoch                        108
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:56:21.887314 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #108 | Epoch Duration: 78.11392545700073
2020-01-11 02:56:21.887478 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #108 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026088092
Z variance train             0.007269047
KL Divergence                10.200321
KL Loss                      1.0200322
QF Loss                      669.4991
VF Loss                      129.61552
Policy Loss                  -797.60315
Q Predictions Mean           796.119
Q Predictions Std            497.9863
Q Predictions Max            1315.3438
Q Predictions Min            -6.812651
V Predictions Mean           801.5554
V Predictions Std            495.45483
V Predictions Max            1309.4344
V Predictions Min            -4.032889
Log Pis Mean                 0.0022904463
Log Pis Std                  2.2379682
Log Pis Max                  9.291784
Log Pis Min                  -5.582658
Policy mu Mean               0.010161973
Policy mu Std                0.9514058
Policy mu Max                3.0831752
Policy mu Min                -2.7247825
Policy log std Mean          -0.49777594
Policy log std Std           0.2606739
Policy log std Max           -0.05916497
Policy log std Min           -1.5326514
Z mean eval                  0.015740618
Z variance eval              0.0069584474
total_rewards                [2971.90063771 2304.31247248 1694.12127593 1366.81223629 2807.20946676
 1066.84071842 2311.85622005 2054.18182335 1394.05087772 2838.46549917]
total_rewards_mean           2080.975122788515
total_rewards_std            644.8936218789262
total_rewards_max            2971.9006377105766
total_rewards_min            1066.840718420427
Number of train steps total  110000
Number of env steps total    552000
Number of rollouts total     0
Train Time (s)               43.92825767304748
(Previous) Eval Time (s)     12.817695409059525
Sample Time (s)              21.53483876027167
Epoch Time (s)               78.28079184237868
Total Train Time (s)         7770.190617640037
Epoch                        109
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:57:49.778740 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #109 | Epoch Duration: 87.89114117622375
2020-01-11 02:57:49.778862 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #109 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015965577
Z variance train             0.006961909
KL Divergence                10.287174
KL Loss                      1.0287174
QF Loss                      464.70898
VF Loss                      151.7521
Policy Loss                  -805.9113
Q Predictions Mean           804.66797
Q Predictions Std            483.2478
Q Predictions Max            1358.9646
Q Predictions Min            -1.0826839
V Predictions Mean           807.6678
V Predictions Std            482.96927
V Predictions Max            1339.7681
V Predictions Min            -0.86242366
Log Pis Mean                 0.17750105
Log Pis Std                  2.2328365
Log Pis Max                  7.624708
Log Pis Min                  -3.1776328
Policy mu Mean               -0.098821126
Policy mu Std                0.9782733
Policy mu Max                2.2891295
Policy mu Min                -2.8826394
Policy log std Mean          -0.49569854
Policy log std Std           0.26474348
Policy log std Max           0.016708821
Policy log std Min           -1.4265059
Z mean eval                  0.018434558
Z variance eval              0.0062716864
total_rewards                [1733.83320858 2219.57567158 1861.19173118 1612.47856993 1664.86293782
 1141.44794688 2755.16353168  986.527978    967.38721791  945.94533486]
total_rewards_mean           1588.8414128423397
total_rewards_std            567.6382091514529
total_rewards_max            2755.163531682489
total_rewards_min            945.9453348642047
Number of train steps total  111000
Number of env steps total    557000
Number of rollouts total     0
Train Time (s)               42.83557153912261
(Previous) Eval Time (s)     22.42779730912298
Sample Time (s)              21.336787714157254
Epoch Time (s)               86.60015656240284
Total Train Time (s)         7851.807617041748
Epoch                        110
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 02:59:11.396950 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #110 | Epoch Duration: 81.61799097061157
2020-01-11 02:59:11.397071 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #110 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01982671
Z variance train             0.0062737153
KL Divergence                10.577598
KL Loss                      1.0577598
QF Loss                      1495.4731
VF Loss                      438.09967
Policy Loss                  -864.2231
Q Predictions Mean           860.2267
Q Predictions Std            475.21906
Q Predictions Max            1311.9371
Q Predictions Min            -5.1929374
V Predictions Mean           865.4978
V Predictions Std            474.38547
V Predictions Max            1336.4707
V Predictions Min            1.5655917
Log Pis Mean                 0.39611652
Log Pis Std                  2.4671876
Log Pis Max                  12.536507
Log Pis Min                  -7.6453395
Policy mu Mean               0.11585939
Policy mu Std                1.0316767
Policy mu Max                3.667129
Policy mu Min                -3.1923954
Policy log std Mean          -0.5136853
Policy log std Std           0.2585013
Policy log std Max           -0.002077192
Policy log std Min           -1.3598187
Z mean eval                  0.009332173
Z variance eval              0.0060594645
total_rewards                [1102.25450225 2924.1118839  1197.5191254  2909.14033265 1081.22443696
 1239.93833931 1553.62588154 1725.31363114 1569.19202402 2740.44473699]
total_rewards_mean           1804.2764894162315
total_rewards_std            719.5667560523265
total_rewards_max            2924.111883902124
total_rewards_min            1081.2244369578918
Number of train steps total  112000
Number of env steps total    562000
Number of rollouts total     0
Train Time (s)               43.87184996297583
(Previous) Eval Time (s)     17.445390834938735
Sample Time (s)              22.003392362967134
Epoch Time (s)               83.3206331608817
Total Train Time (s)         7936.3708323123865
Epoch                        111
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:00:35.966150 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #111 | Epoch Duration: 84.5689344406128
2020-01-11 03:00:35.966458 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #111 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009159188
Z variance train             0.0060635796
KL Divergence                10.747456
KL Loss                      1.0747455
QF Loss                      232.27219
VF Loss                      127.278595
Policy Loss                  -894.21576
Q Predictions Mean           891.03467
Q Predictions Std            464.60455
Q Predictions Max            1352.1906
Q Predictions Min            -19.036106
V Predictions Mean           891.8705
V Predictions Std            462.33978
V Predictions Max            1342.7843
V Predictions Min            3.6661859
Log Pis Mean                 0.28940976
Log Pis Std                  2.166446
Log Pis Max                  7.9675045
Log Pis Min                  -4.035242
Policy mu Mean               0.102307595
Policy mu Std                1.0097897
Policy mu Max                2.7400386
Policy mu Min                -2.7754521
Policy log std Mean          -0.5182817
Policy log std Std           0.27675402
Policy log std Max           -0.011262029
Policy log std Min           -1.4660039
Z mean eval                  0.01776765
Z variance eval              0.0052755317
total_rewards                [1280.1610762  1157.25394381 2844.07367119 1177.98410762 2819.35536703
 1237.78333994 1352.19840567 1339.3252139  1791.68345625 1826.43272957]
total_rewards_mean           1682.6251311181907
total_rewards_std            615.7327602070757
total_rewards_max            2844.0736711948875
total_rewards_min            1157.2539438091135
Number of train steps total  113000
Number of env steps total    567000
Number of rollouts total     0
Train Time (s)               44.69864692306146
(Previous) Eval Time (s)     18.69340237369761
Sample Time (s)              21.9090990354307
Epoch Time (s)               85.30114833218977
Total Train Time (s)         8020.6365438476205
Epoch                        112
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:02:00.234741 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #112 | Epoch Duration: 84.26807069778442
2020-01-11 03:02:00.234859 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #112 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018407634
Z variance train             0.005275258
KL Divergence                11.244913
KL Loss                      1.1244913
QF Loss                      678.87256
VF Loss                      109.47534
Policy Loss                  -897.3869
Q Predictions Mean           895.8819
Q Predictions Std            482.9308
Q Predictions Max            1349.5724
Q Predictions Min            1.7948343
V Predictions Mean           894.23334
V Predictions Std            482.59982
V Predictions Max            1344.5062
V Predictions Min            -5.629826
Log Pis Mean                 0.11366777
Log Pis Std                  2.2096117
Log Pis Max                  7.6718845
Log Pis Min                  -4.888321
Policy mu Mean               0.05550457
Policy mu Std                0.9748733
Policy mu Max                2.347053
Policy mu Min                -2.888776
Policy log std Mean          -0.5218956
Policy log std Std           0.26099408
Policy log std Max           -0.014642596
Policy log std Min           -1.4388491
Z mean eval                  0.018358644
Z variance eval              0.005374624
total_rewards                [2374.49061653 2996.22111123 3017.59754267 3049.7662338  1399.259823
 2147.38607984 3099.87990681 3158.85779686 2999.31585774 2989.74475017]
total_rewards_mean           2723.2519718659887
total_rewards_std            543.3971801812723
total_rewards_max            3158.857796857369
total_rewards_min            1399.2598230041144
Number of train steps total  114000
Number of env steps total    572000
Number of rollouts total     0
Train Time (s)               43.1654618778266
(Previous) Eval Time (s)     17.660112452227622
Sample Time (s)              21.600636101793498
Epoch Time (s)               82.42621043184772
Total Train Time (s)         8115.121406442951
Epoch                        113
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:03:34.721818 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #113 | Epoch Duration: 94.48686647415161
2020-01-11 03:03:34.721941 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #113 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019586787
Z variance train             0.005379309
KL Divergence                11.258402
KL Loss                      1.1258402
QF Loss                      598.19824
VF Loss                      300.99936
Policy Loss                  -934.3781
Q Predictions Mean           929.05835
Q Predictions Std            447.22318
Q Predictions Max            1331.3839
Q Predictions Min            -2.111003
V Predictions Mean           927.8808
V Predictions Std            447.8732
V Predictions Max            1326.6948
V Predictions Min            -7.7356963
Log Pis Mean                 0.25050473
Log Pis Std                  2.16281
Log Pis Max                  8.991582
Log Pis Min                  -6.9477615
Policy mu Mean               0.125546
Policy mu Std                1.0074085
Policy mu Max                3.418972
Policy mu Min                -3.6023784
Policy log std Mean          -0.54778594
Policy log std Std           0.26329577
Policy log std Max           0.008232176
Policy log std Min           -1.5664153
Z mean eval                  0.010324964
Z variance eval              0.0052880556
total_rewards                [2923.21266404 2069.68291302 1496.30047643 1604.37449501 1762.86347729
  902.65948765 1219.07948757 3100.36299412 2732.88778163 1203.80104538]
total_rewards_mean           1901.522482215664
total_rewards_std            736.3772564644499
total_rewards_max            3100.362994122949
total_rewards_min            902.6594876509547
Number of train steps total  115000
Number of env steps total    577000
Number of rollouts total     0
Train Time (s)               42.387389490846545
(Previous) Eval Time (s)     29.720524067990482
Sample Time (s)              22.145639390684664
Epoch Time (s)               94.25355294952169
Total Train Time (s)         8200.113190432545
Epoch                        114
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:04:59.714616 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #114 | Epoch Duration: 84.9925811290741
2020-01-11 03:04:59.714738 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #114 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008900023
Z variance train             0.0052945963
KL Divergence                11.322144
KL Loss                      1.1322144
QF Loss                      361.11777
VF Loss                      229.15758
Policy Loss                  -849.3372
Q Predictions Mean           848.8751
Q Predictions Std            480.70526
Q Predictions Max            1324.5669
Q Predictions Min            -10.945531
V Predictions Mean           839.1538
V Predictions Std            476.78983
V Predictions Max            1305.2507
V Predictions Min            -20.974146
Log Pis Mean                 0.14372583
Log Pis Std                  2.2313416
Log Pis Max                  7.3490415
Log Pis Min                  -4.0192537
Policy mu Mean               -0.06367258
Policy mu Std                0.9964451
Policy mu Max                3.3837495
Policy mu Min                -2.786332
Policy log std Mean          -0.49691197
Policy log std Std           0.24429448
Policy log std Max           0.07467651
Policy log std Min           -1.486157
Z mean eval                  0.022306794
Z variance eval              0.0057867886
total_rewards                [2042.81919443  619.61767837 2366.57233557 2048.03830528 3126.93931812
 1189.32934518 2659.13875493 2790.34539916 2308.8527393   937.22455908]
total_rewards_mean           2008.8877629410938
total_rewards_std            790.8446375804502
total_rewards_max            3126.9393181208657
total_rewards_min            619.6176783691832
Number of train steps total  116000
Number of env steps total    582000
Number of rollouts total     0
Train Time (s)               42.587242586072534
(Previous) Eval Time (s)     20.4593019830063
Sample Time (s)              22.738863910082728
Epoch Time (s)               85.78540847916156
Total Train Time (s)         8286.893441380933
Epoch                        115
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:06:26.501185 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #115 | Epoch Duration: 86.786301612854
2020-01-11 03:06:26.501490 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #115 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021553664
Z variance train             0.0057897456
KL Divergence                10.8916645
KL Loss                      1.0891665
QF Loss                      746.21277
VF Loss                      167.32048
Policy Loss                  -899.99084
Q Predictions Mean           898.02783
Q Predictions Std            471.95676
Q Predictions Max            1350.2007
Q Predictions Min            -9.142052
V Predictions Mean           903.39575
V Predictions Std            474.50156
V Predictions Max            1355.6964
V Predictions Min            -8.112898
Log Pis Mean                 0.029798843
Log Pis Std                  2.2187557
Log Pis Max                  8.866581
Log Pis Min                  -4.7396555
Policy mu Mean               0.09441724
Policy mu Std                0.933562
Policy mu Max                2.6736596
Policy mu Min                -2.9371421
Policy log std Mean          -0.5357308
Policy log std Std           0.26951307
Policy log std Max           0.05663824
Policy log std Min           -1.8195038
Z mean eval                  0.014313941
Z variance eval              0.0054020165
total_rewards                [3105.44298861 1839.55992882  974.88348511 1664.07149642 1020.27799219
 2014.10022984  980.82572797 3058.29155352  998.32149765 1012.23725264]
total_rewards_mean           1666.8012152762028
total_rewards_std            799.9393133199706
total_rewards_max            3105.442988605809
total_rewards_min            974.8834851071923
Number of train steps total  117000
Number of env steps total    587000
Number of rollouts total     0
Train Time (s)               44.1232552989386
(Previous) Eval Time (s)     21.45991874486208
Sample Time (s)              20.11740549793467
Epoch Time (s)               85.70057954173535
Total Train Time (s)         8369.286719972733
Epoch                        116
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:07:48.893325 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #116 | Epoch Duration: 82.39163160324097
2020-01-11 03:07:48.893445 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #116 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01504639
Z variance train             0.0054067066
KL Divergence                10.897844
KL Loss                      1.0897845
QF Loss                      1783.1138
VF Loss                      347.75992
Policy Loss                  -871.87085
Q Predictions Mean           869.4898
Q Predictions Std            468.45728
Q Predictions Max            1316.4797
Q Predictions Min            -8.807477
V Predictions Mean           865.75507
V Predictions Std            462.54996
V Predictions Max            1312.1722
V Predictions Min            -5.0263014
Log Pis Mean                 0.19503099
Log Pis Std                  2.0636559
Log Pis Max                  8.397566
Log Pis Min                  -4.452381
Policy mu Mean               0.14548306
Policy mu Std                0.97257847
Policy mu Max                3.2034838
Policy mu Min                -3.1270313
Policy log std Mean          -0.53527135
Policy log std Std           0.2604745
Policy log std Max           -0.02161032
Policy log std Min           -2.130637
Z mean eval                  0.029278543
Z variance eval              0.005377519
total_rewards                [2919.46658595 1067.89954562 1526.85425853  852.5304195  2848.36377291
 2608.16284908 2522.22612095 2909.47815839 1017.12997728   42.70609051]
total_rewards_mean           1831.4817778708934
total_rewards_std            997.8620241576375
total_rewards_max            2919.4665859458887
total_rewards_min            42.70609050868243
Number of train steps total  118000
Number of env steps total    592000
Number of rollouts total     0
Train Time (s)               43.58344871504232
(Previous) Eval Time (s)     18.150772897992283
Sample Time (s)              22.064365869387984
Epoch Time (s)               83.79858748242259
Total Train Time (s)         8455.544492685702
Epoch                        117
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:09:15.153584 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #117 | Epoch Duration: 86.26004648208618
2020-01-11 03:09:15.153706 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #117 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02632407
Z variance train             0.005327908
KL Divergence                10.786564
KL Loss                      1.0786564
QF Loss                      386.1408
VF Loss                      127.22323
Policy Loss                  -903.1289
Q Predictions Mean           907.90076
Q Predictions Std            483.5856
Q Predictions Max            1376.6078
Q Predictions Min            -7.647709
V Predictions Mean           906.8845
V Predictions Std            479.75583
V Predictions Max            1392.0396
V Predictions Min            0.9985832
Log Pis Mean                 0.37900746
Log Pis Std                  2.3332849
Log Pis Max                  10.263224
Log Pis Min                  -5.200071
Policy mu Mean               0.20322919
Policy mu Std                1.0103428
Policy mu Max                3.0899026
Policy mu Min                -2.950264
Policy log std Mean          -0.50506383
Policy log std Std           0.22996521
Policy log std Max           -0.022415668
Policy log std Min           -1.2679719
Z mean eval                  0.04483391
Z variance eval              0.0052513727
total_rewards                [2213.22350175 2374.74833274 3090.62462109 1033.10240476 3141.60182841
 3138.54699114 3177.52234683 1702.71688547 1134.68900687 3182.36980608]
total_rewards_mean           2418.914572513206
total_rewards_std            823.2011293752546
total_rewards_max            3182.3698060789525
total_rewards_min            1033.102404757067
Number of train steps total  119000
Number of env steps total    597000
Number of rollouts total     0
Train Time (s)               43.47799160890281
(Previous) Eval Time (s)     20.612011545337737
Sample Time (s)              21.299385722260922
Epoch Time (s)               85.38938887650147
Total Train Time (s)         8545.434045989998
Epoch                        118
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:10:45.048748 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #118 | Epoch Duration: 89.89493680000305
2020-01-11 03:10:45.048914 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #118 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04477506
Z variance train             0.0052537993
KL Divergence                10.742186
KL Loss                      1.0742186
QF Loss                      320.22992
VF Loss                      119.60473
Policy Loss                  -863.7044
Q Predictions Mean           866.34094
Q Predictions Std            481.55487
Q Predictions Max            1354.7422
Q Predictions Min            -31.430464
V Predictions Mean           862.2942
V Predictions Std            480.19952
V Predictions Max            1357.0385
V Predictions Min            -9.567639
Log Pis Mean                 0.16874228
Log Pis Std                  2.1063633
Log Pis Max                  5.640408
Log Pis Min                  -5.064053
Policy mu Mean               0.091890514
Policy mu Std                0.9956823
Policy mu Max                4.028026
Policy mu Min                -2.7158983
Policy log std Mean          -0.49465963
Policy log std Std           0.2539308
Policy log std Max           0.074920386
Policy log std Min           -1.4892287
Z mean eval                  0.0155886365
Z variance eval              0.005381097
total_rewards                [1464.49995511 3016.70728143  977.90385156 3009.25828014 2499.31514904
 1816.02557381 2627.71717034 1804.27316668  977.93402924 3091.23594514]
total_rewards_mean           2128.4870402488013
total_rewards_std            785.4656195597639
total_rewards_max            3091.23594514214
total_rewards_min            977.9038515588154
Number of train steps total  120000
Number of env steps total    602000
Number of rollouts total     0
Train Time (s)               42.78680397802964
(Previous) Eval Time (s)     25.11730798985809
Sample Time (s)              21.926022121682763
Epoch Time (s)               89.83013408957049
Total Train Time (s)         8633.493061858695
Epoch                        119
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:12:13.107304 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #119 | Epoch Duration: 88.05826783180237
2020-01-11 03:12:13.107426 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #119 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016521823
Z variance train             0.0051336717
KL Divergence                10.781738
KL Loss                      1.0781739
QF Loss                      233.24771
VF Loss                      196.21307
Policy Loss                  -793.4278
Q Predictions Mean           796.82263
Q Predictions Std            487.46567
Q Predictions Max            1364.6805
Q Predictions Min            -18.39848
V Predictions Mean           800.9418
V Predictions Std            489.84152
V Predictions Max            1342.9438
V Predictions Min            -1.8329842
Log Pis Mean                 -0.22203742
Log Pis Std                  2.007858
Log Pis Max                  6.6388025
Log Pis Min                  -4.8817973
Policy mu Mean               -0.025044074
Policy mu Std                0.912315
Policy mu Max                2.2699332
Policy mu Min                -3.0063365
Policy log std Mean          -0.5033366
Policy log std Std           0.26616147
Policy log std Max           0.1291318
Policy log std Min           -1.3511401
Z mean eval                  0.013675001
Z variance eval              0.0060448227
total_rewards                [ 940.4390805  3169.44273342 1287.09005203  664.25151107 3177.11889063
  915.86578869  932.9875152  2907.17832185 1207.95146624 2065.92321027]
total_rewards_mean           1726.8248569910374
total_rewards_std            958.6769242843673
total_rewards_max            3177.1188906348584
total_rewards_min            664.2515110695662
Number of train steps total  121000
Number of env steps total    607000
Number of rollouts total     0
Train Time (s)               43.667392895091325
(Previous) Eval Time (s)     23.345207260921597
Sample Time (s)              22.158184226136655
Epoch Time (s)               89.17078438214958
Total Train Time (s)         8716.230444611982
Epoch                        120
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:13:35.847895 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #120 | Epoch Duration: 82.74034976959229
2020-01-11 03:13:35.848131 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #120 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013141347
Z variance train             0.0060396716
KL Divergence                10.442179
KL Loss                      1.044218
QF Loss                      364.3593
VF Loss                      94.24179
Policy Loss                  -888.95013
Q Predictions Mean           890.58154
Q Predictions Std            479.05103
Q Predictions Max            1414.6185
Q Predictions Min            -10.964549
V Predictions Mean           889.1615
V Predictions Std            476.32266
V Predictions Max            1386.1519
V Predictions Min            -11.944525
Log Pis Mean                 0.09597408
Log Pis Std                  2.2539825
Log Pis Max                  8.529091
Log Pis Min                  -4.945195
Policy mu Mean               -0.027820444
Policy mu Std                0.95693594
Policy mu Max                3.0375488
Policy mu Min                -3.0810556
Policy log std Mean          -0.53220296
Policy log std Std           0.23741719
Policy log std Max           0.017663658
Policy log std Min           -1.4011033
Z mean eval                  0.023127714
Z variance eval              0.005321932
total_rewards                [3182.98925892 3157.17819798 2277.93318983 3137.65127022 3241.3829354
 3139.77068274 3194.37525424 2056.89941525 1676.63584563 3201.08488163]
total_rewards_mean           2826.5900931854253
total_rewards_std            556.2875407444677
total_rewards_max            3241.3829354015497
total_rewards_min            1676.635845634552
Number of train steps total  122000
Number of env steps total    612000
Number of rollouts total     0
Train Time (s)               42.89668181911111
(Previous) Eval Time (s)     16.914523052982986
Sample Time (s)              21.253439854364842
Epoch Time (s)               81.06464472645894
Total Train Time (s)         8809.72697732132
Epoch                        121
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:15:09.345565 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #121 | Epoch Duration: 93.49728035926819
2020-01-11 03:15:09.345698 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #121 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023425568
Z variance train             0.0056573832
KL Divergence                10.644291
KL Loss                      1.0644292
QF Loss                      308.20425
VF Loss                      124.727036
Policy Loss                  -912.14636
Q Predictions Mean           907.5341
Q Predictions Std            443.83948
Q Predictions Max            1329.8262
Q Predictions Min            -7.479253
V Predictions Mean           915.0797
V Predictions Std            444.612
V Predictions Max            1332.4955
V Predictions Min            -0.17290705
Log Pis Mean                 0.065672435
Log Pis Std                  2.0503678
Log Pis Max                  8.123017
Log Pis Min                  -3.6047175
Policy mu Mean               0.023063598
Policy mu Std                0.944283
Policy mu Max                2.6393955
Policy mu Min                -2.8509092
Policy log std Mean          -0.48953536
Policy log std Std           0.23553881
Policy log std Max           -0.07240376
Policy log std Min           -1.5338427
Z mean eval                  0.019010346
Z variance eval              0.005077145
total_rewards                [1896.34078271 3096.9368479  3058.76090205 3120.15994245 3093.17414928
 3072.4669895  2438.38493887 1659.11345489 3057.17457034 3044.52588618]
total_rewards_mean           2753.7038464171565
total_rewards_std            526.4319803664799
total_rewards_max            3120.1599424478845
total_rewards_min            1659.1134548854598
Number of train steps total  123000
Number of env steps total    617000
Number of rollouts total     0
Train Time (s)               42.87032354110852
(Previous) Eval Time (s)     29.346929799299687
Sample Time (s)              21.95562448631972
Epoch Time (s)               94.17287782672793
Total Train Time (s)         8904.915589998476
Epoch                        122
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:16:44.535139 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #122 | Epoch Duration: 95.18934464454651
2020-01-11 03:16:44.535261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #122 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01875331
Z variance train             0.0050525293
KL Divergence                10.819994
KL Loss                      1.0819994
QF Loss                      229.88452
VF Loss                      271.81903
Policy Loss                  -885.7176
Q Predictions Mean           888.9238
Q Predictions Std            488.38284
Q Predictions Max            1352.8507
Q Predictions Min            -9.048462
V Predictions Mean           896.0752
V Predictions Std            489.5473
V Predictions Max            1360.2528
V Predictions Min            -10.681637
Log Pis Mean                 -0.09489505
Log Pis Std                  2.003856
Log Pis Max                  7.1348124
Log Pis Min                  -4.5093207
Policy mu Mean               0.10415077
Policy mu Std                0.92078555
Policy mu Max                2.5799417
Policy mu Min                -3.2133272
Policy log std Mean          -0.4723676
Policy log std Std           0.24462906
Policy log std Max           0.05161059
Policy log std Min           -1.358412
Z mean eval                  0.026332323
Z variance eval              0.005071006
total_rewards                [3139.0986262  2062.57108171 3046.69283872 3074.96780992 3009.79110478
 3117.59800832 3074.95012661 2859.76310106 2298.21691577 3064.53622426]
total_rewards_mean           2874.8185837350657
total_rewards_std            358.4817173495213
total_rewards_max            3139.0986262035417
total_rewards_min            2062.571081710294
Number of train steps total  124000
Number of env steps total    622000
Number of rollouts total     0
Train Time (s)               43.72837990615517
(Previous) Eval Time (s)     30.36315782321617
Sample Time (s)              22.678536923602223
Epoch Time (s)               96.77007465297356
Total Train Time (s)         9001.96009443188
Epoch                        123
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:18:21.581653 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #123 | Epoch Duration: 97.04628276824951
2020-01-11 03:18:21.581827 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #123 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026028523
Z variance train             0.0050653424
KL Divergence                10.81344
KL Loss                      1.081344
QF Loss                      872.85864
VF Loss                      207.76425
Policy Loss                  -874.44806
Q Predictions Mean           870.1821
Q Predictions Std            489.72006
Q Predictions Max            1344.8545
Q Predictions Min            -42.266747
V Predictions Mean           879.0161
V Predictions Std            491.821
V Predictions Max            1364.727
V Predictions Min            -5.4404655
Log Pis Mean                 0.084415875
Log Pis Std                  2.2725616
Log Pis Max                  10.266361
Log Pis Min                  -4.095822
Policy mu Mean               -0.054937664
Policy mu Std                0.9659764
Policy mu Max                2.9437428
Policy mu Min                -3.1355133
Policy log std Mean          -0.51683617
Policy log std Std           0.25806075
Policy log std Max           0.039902866
Policy log std Min           -1.405285
Z mean eval                  0.019047732
Z variance eval              0.004752905
total_rewards                [2059.85851195 3275.58007807 3164.71843513 1168.91201195 2482.31629396
 3120.86085594  972.93623391 3193.02433168 2044.61303161 3178.32730657]
total_rewards_mean           2466.11470907662
total_rewards_std            828.4265386402383
total_rewards_max            3275.5800780653467
total_rewards_min            972.9362339078629
Number of train steps total  125000
Number of env steps total    627000
Number of rollouts total     0
Train Time (s)               43.60309116076678
(Previous) Eval Time (s)     30.6391060850583
Sample Time (s)              22.174874181393534
Epoch Time (s)               96.41707142721862
Total Train Time (s)         9093.28955172794
Epoch                        124
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:19:52.913496 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #124 | Epoch Duration: 91.33154201507568
2020-01-11 03:19:52.913638 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #124 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018067807
Z variance train             0.0047417535
KL Divergence                11.090187
KL Loss                      1.1090187
QF Loss                      223.98943
VF Loss                      195.9376
Policy Loss                  -908.51166
Q Predictions Mean           906.2285
Q Predictions Std            477.73486
Q Predictions Max            1368.137
Q Predictions Min            -20.540705
V Predictions Mean           911.7285
V Predictions Std            478.39783
V Predictions Max            1361.1521
V Predictions Min            -7.0832014
Log Pis Mean                 0.021958256
Log Pis Std                  2.0721087
Log Pis Max                  6.210571
Log Pis Min                  -9.696642
Policy mu Mean               0.09235423
Policy mu Std                0.90348685
Policy mu Max                2.576947
Policy mu Min                -2.7626727
Policy log std Mean          -0.5267581
Policy log std Std           0.26784903
Policy log std Max           -0.084860966
Policy log std Min           -1.5678151
Z mean eval                  0.016531883
Z variance eval              0.0041854484
total_rewards                [1170.52338979 2544.96869303 3174.95157157 2814.24553772 3112.00515961
 1765.45523704 2098.95983358 2196.53610915 3130.35967851 1410.34602056]
total_rewards_mean           2341.8351230558037
total_rewards_std            694.651555162472
total_rewards_max            3174.95157156671
total_rewards_min            1170.523389792896
Number of train steps total  126000
Number of env steps total    632000
Number of rollouts total     0
Train Time (s)               43.316587889101356
(Previous) Eval Time (s)     25.55335488822311
Sample Time (s)              22.254893015138805
Epoch Time (s)               91.12483579246327
Total Train Time (s)         9180.091351644602
Epoch                        125
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:21:19.719207 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #125 | Epoch Duration: 86.80544352531433
2020-01-11 03:21:19.719428 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #125 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016538655
Z variance train             0.004180261
KL Divergence                11.385033
KL Loss                      1.1385033
QF Loss                      295.4803
VF Loss                      85.01192
Policy Loss                  -927.29553
Q Predictions Mean           928.7007
Q Predictions Std            482.29504
Q Predictions Max            1365.919
Q Predictions Min            -2.4885185
V Predictions Mean           927.9338
V Predictions Std            479.33868
V Predictions Max            1377.9886
V Predictions Min            -2.1084979
Log Pis Mean                 -0.050169773
Log Pis Std                  2.0655913
Log Pis Max                  9.454192
Log Pis Min                  -4.915715
Policy mu Mean               0.14069301
Policy mu Std                0.9051456
Policy mu Max                2.8447561
Policy mu Min                -2.6614497
Policy log std Mean          -0.5149277
Policy log std Std           0.2441572
Policy log std Max           0.05313784
Policy log std Min           -1.3542919
Z mean eval                  0.025821935
Z variance eval              0.0044102767
total_rewards                [1020.95903195 2840.84925076 3170.62537399 1734.31897912 1247.68953795
 1695.38809132 3004.33140193 3086.23530242 1463.50126551 3073.39580567]
total_rewards_mean           2233.7294040613383
total_rewards_std            827.4999757453704
total_rewards_max            3170.6253739926815
total_rewards_min            1020.9590319455764
Number of train steps total  127000
Number of env steps total    637000
Number of rollouts total     0
Train Time (s)               43.213033626787364
(Previous) Eval Time (s)     21.233695851173252
Sample Time (s)              21.533573892433196
Epoch Time (s)               85.98030337039381
Total Train Time (s)         9268.988794166595
Epoch                        126
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:22:48.618241 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #126 | Epoch Duration: 88.89864230155945
2020-01-11 03:22:48.618414 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #126 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02601635
Z variance train             0.004416878
KL Divergence                11.243332
KL Loss                      1.1243333
QF Loss                      481.03326
VF Loss                      213.8996
Policy Loss                  -936.2822
Q Predictions Mean           939.6149
Q Predictions Std            466.72714
Q Predictions Max            1388.522
Q Predictions Min            -12.934207
V Predictions Mean           937.80505
V Predictions Std            462.41235
V Predictions Max            1384.921
V Predictions Min            -6.4523
Log Pis Mean                 0.02181597
Log Pis Std                  2.1927242
Log Pis Max                  9.230028
Log Pis Min                  -4.3727283
Policy mu Mean               -0.011008185
Policy mu Std                0.9436836
Policy mu Max                3.630732
Policy mu Min                -2.8939428
Policy log std Mean          -0.5234112
Policy log std Std           0.2538065
Policy log std Max           0.005809784
Policy log std Min           -1.3941154
Z mean eval                  0.021885026
Z variance eval              0.003972023
total_rewards                [ 395.83677414 1115.50772893 1137.04956919 1376.33650586 1130.32933314
  684.38549506 3067.23877073 1314.39772277 3079.17696829 1104.03847998]
total_rewards_mean           1440.42973480762
total_rewards_std            861.4931607881505
total_rewards_max            3079.1769682931395
total_rewards_min            395.8367741372756
Number of train steps total  128000
Number of env steps total    642000
Number of rollouts total     0
Train Time (s)               44.4380087046884
(Previous) Eval Time (s)     24.151785848662257
Sample Time (s)              21.942820051684976
Epoch Time (s)               90.53261460503563
Total Train Time (s)         9351.306206384208
Epoch                        127
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:24:10.937324 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #127 | Epoch Duration: 82.31878232955933
2020-01-11 03:24:10.937459 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #127 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022385666
Z variance train             0.0039728456
KL Divergence                11.581932
KL Loss                      1.1581932
QF Loss                      337.61853
VF Loss                      138.80327
Policy Loss                  -928.5794
Q Predictions Mean           929.6049
Q Predictions Std            463.36557
Q Predictions Max            1380.3304
Q Predictions Min            -54.853703
V Predictions Mean           932.2003
V Predictions Std            462.564
V Predictions Max            1378.471
V Predictions Min            -1.4146216
Log Pis Mean                 0.038079917
Log Pis Std                  2.1939363
Log Pis Max                  10.619939
Log Pis Min                  -5.940695
Policy mu Mean               -0.032534223
Policy mu Std                0.9632284
Policy mu Max                2.5320327
Policy mu Min                -2.8970835
Policy log std Mean          -0.5173016
Policy log std Std           0.24662182
Policy log std Max           -0.014328688
Policy log std Min           -1.3462734
Z mean eval                  0.010035462
Z variance eval              0.0047996193
total_rewards                [1642.06243351 1998.01586765 1546.6549963  1472.00146718 1583.96957573
  944.26295853 2905.78692491 3171.12382749 2002.30167424  945.64352068]
total_rewards_mean           1821.1823246219797
total_rewards_std            698.8551811030178
total_rewards_max            3171.123827494433
total_rewards_min            944.2629585260503
Number of train steps total  129000
Number of env steps total    647000
Number of rollouts total     0
Train Time (s)               42.822586468886584
(Previous) Eval Time (s)     15.937729877885431
Sample Time (s)              23.217091912403703
Epoch Time (s)               81.97740825917572
Total Train Time (s)         9435.827414691914
Epoch                        128
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:25:35.460615 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #128 | Epoch Duration: 84.52305889129639
2020-01-11 03:25:35.460750 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #128 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010032657
Z variance train             0.004815782
KL Divergence                11.210521
KL Loss                      1.1210521
QF Loss                      268.32434
VF Loss                      119.14505
Policy Loss                  -909.99646
Q Predictions Mean           902.8046
Q Predictions Std            487.1875
Q Predictions Max            1371.7628
Q Predictions Min            -7.9326253
V Predictions Mean           908.5808
V Predictions Std            486.0816
V Predictions Max            1370.2372
V Predictions Min            -4.44941
Log Pis Mean                 -0.065018654
Log Pis Std                  2.0144792
Log Pis Max                  7.192321
Log Pis Min                  -4.644226
Policy mu Mean               0.055690665
Policy mu Std                0.8796369
Policy mu Max                2.3200233
Policy mu Min                -2.7617855
Policy log std Mean          -0.50131637
Policy log std Std           0.2523126
Policy log std Max           -0.017659903
Policy log std Min           -1.3631854
Z mean eval                  0.022333845
Z variance eval              0.005017449
total_rewards                [1905.20661305  858.19512285 2036.63840348 2071.27585697 1403.72474379
 2039.60894704 1494.82359542 2088.55751732 1917.72619071 1446.76816216]
total_rewards_mean           1726.2525152771782
total_rewards_std            387.6523003607804
total_rewards_max            2088.5575173216093
total_rewards_min            858.1951228490469
Number of train steps total  130000
Number of env steps total    652000
Number of rollouts total     0
Train Time (s)               43.44381337380037
(Previous) Eval Time (s)     18.483139974065125
Sample Time (s)              21.76499141473323
Epoch Time (s)               83.69194476259872
Total Train Time (s)         9519.084540211596
Epoch                        129
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:26:58.718771 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #129 | Epoch Duration: 83.25792121887207
2020-01-11 03:26:58.718899 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #129 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023064177
Z variance train             0.0050064055
KL Divergence                11.174709
KL Loss                      1.117471
QF Loss                      449.02966
VF Loss                      769.8541
Policy Loss                  -949.436
Q Predictions Mean           948.4895
Q Predictions Std            465.5671
Q Predictions Max            1364.3525
Q Predictions Min            -2.0951014
V Predictions Mean           947.0122
V Predictions Std            464.06778
V Predictions Max            1355.527
V Predictions Min            -3.3777423
Log Pis Mean                 -0.18862906
Log Pis Std                  2.1596797
Log Pis Max                  6.7634726
Log Pis Min                  -4.8181157
Policy mu Mean               0.11690769
Policy mu Std                0.9030401
Policy mu Max                2.6628978
Policy mu Min                -2.8032024
Policy log std Mean          -0.4924545
Policy log std Std           0.24410342
Policy log std Max           -0.02337867
Policy log std Min           -1.4862311
Z mean eval                  0.0060274284
Z variance eval              0.004959279
total_rewards                [1455.06953994 3137.60058899 1064.60305142  906.7802232   989.25213815
 1617.65787842 2460.18669291 2233.10935513 2731.59680184 1440.13995572]
total_rewards_mean           1803.5996225718827
total_rewards_std            745.5223542734124
total_rewards_max            3137.6005889887233
total_rewards_min            906.7802232023118
Number of train steps total  131000
Number of env steps total    657000
Number of rollouts total     0
Train Time (s)               43.24754459504038
(Previous) Eval Time (s)     18.048873665742576
Sample Time (s)              21.7079687602818
Epoch Time (s)               83.00438702106476
Total Train Time (s)         9602.94725055201
Epoch                        130
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:28:22.582909 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #130 | Epoch Duration: 83.86391162872314
2020-01-11 03:28:22.583048 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #130 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.006248002
Z variance train             0.004963183
KL Divergence                11.244337
KL Loss                      1.1244338
QF Loss                      437.4759
VF Loss                      208.02818
Policy Loss                  -956.1624
Q Predictions Mean           954.19257
Q Predictions Std            479.3369
Q Predictions Max            1386.2882
Q Predictions Min            -21.533194
V Predictions Mean           957.92224
V Predictions Std            478.10568
V Predictions Max            1373.479
V Predictions Min            -14.127425
Log Pis Mean                 0.14733304
Log Pis Std                  2.2603524
Log Pis Max                  7.193545
Log Pis Min                  -4.2711234
Policy mu Mean               -0.01362177
Policy mu Std                0.9890931
Policy mu Max                2.8479798
Policy mu Min                -3.793687
Policy log std Mean          -0.5034192
Policy log std Std           0.24896337
Policy log std Max           0.07351816
Policy log std Min           -1.6322687
Z mean eval                  0.011208505
Z variance eval              0.004066188
total_rewards                [1915.65843009  900.14480445  919.96653356 3120.34961532 2127.57003578
  934.18501492 1243.85697303 1967.8241931  2237.05338953 1744.62100275]
total_rewards_mean           1711.1229992526278
total_rewards_std            681.9374812350844
total_rewards_max            3120.349615323107
total_rewards_min            900.1448044460457
Number of train steps total  132000
Number of env steps total    662000
Number of rollouts total     0
Train Time (s)               43.03009939007461
(Previous) Eval Time (s)     18.90814090380445
Sample Time (s)              22.619101902935654
Epoch Time (s)               84.55734219681472
Total Train Time (s)         9685.896231159102
Epoch                        131
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:29:45.533133 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #131 | Epoch Duration: 82.94998145103455
2020-01-11 03:29:45.533262 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #131 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011248742
Z variance train             0.00406344
KL Divergence                11.705728
KL Loss                      1.1705728
QF Loss                      639.3622
VF Loss                      299.64337
Policy Loss                  -944.2838
Q Predictions Mean           943.12933
Q Predictions Std            484.96448
Q Predictions Max            1405.8414
Q Predictions Min            -1.8896202
V Predictions Mean           950.78687
V Predictions Std            488.6843
V Predictions Max            1431.4949
V Predictions Min            -5.475625
Log Pis Mean                 -0.006414272
Log Pis Std                  2.2672808
Log Pis Max                  9.962587
Log Pis Min                  -5.153961
Policy mu Mean               0.17147733
Policy mu Std                0.94662553
Policy mu Max                2.7794356
Policy mu Min                -3.8530514
Policy log std Mean          -0.4866493
Policy log std Std           0.25288194
Policy log std Max           0.09680456
Policy log std Min           -1.5454247
Z mean eval                  0.009164038
Z variance eval              0.003969412
total_rewards                [3092.37149444 1670.69507943 1149.02881108 1009.09640203 1614.30852723
 3037.24090071 1769.11147431 2718.84014984 3151.30026871 3177.52368692]
total_rewards_mean           2238.951679470097
total_rewards_std            833.2767654731894
total_rewards_max            3177.523686919404
total_rewards_min            1009.0964020316187
Number of train steps total  133000
Number of env steps total    667000
Number of rollouts total     0
Train Time (s)               43.11643958278
(Previous) Eval Time (s)     17.300540685188025
Sample Time (s)              21.703558780252934
Epoch Time (s)               82.12053904822096
Total Train Time (s)         9773.171482762322
Epoch                        132
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:31:12.814939 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #132 | Epoch Duration: 87.28152084350586
2020-01-11 03:31:12.815252 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #132 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009197845
Z variance train             0.003967883
KL Divergence                11.864384
KL Loss                      1.1864384
QF Loss                      201.95215
VF Loss                      186.49745
Policy Loss                  -951.36694
Q Predictions Mean           949.99786
Q Predictions Std            480.76547
Q Predictions Max            1379.3411
Q Predictions Min            -11.420288
V Predictions Mean           953.9396
V Predictions Std            474.66605
V Predictions Max            1374.8281
V Predictions Min            -1.7494539
Log Pis Mean                 -0.0051606596
Log Pis Std                  2.2704346
Log Pis Max                  13.996532
Log Pis Min                  -9.123375
Policy mu Mean               0.054818425
Policy mu Std                0.93028665
Policy mu Max                3.8442957
Policy mu Min                -2.8181057
Policy log std Mean          -0.5049351
Policy log std Std           0.2686131
Policy log std Max           0.083738565
Policy log std Min           -2.8372371
Z mean eval                  0.01186206
Z variance eval              0.003539427
total_rewards                [1665.31637435 1122.20383789 2228.44331286 1485.076564   2527.84795348
 1784.1860496  1185.68018356 1355.44734141 2215.05897622 2634.44726225]
total_rewards_mean           1820.370785562147
total_rewards_std            522.4694139347201
total_rewards_max            2634.4472622478816
total_rewards_min            1122.2038378859122
Number of train steps total  134000
Number of env steps total    672000
Number of rollouts total     0
Train Time (s)               43.14620371395722
(Previous) Eval Time (s)     22.46123566199094
Sample Time (s)              22.038645836059004
Epoch Time (s)               87.64608521200716
Total Train Time (s)         9855.91353331739
Epoch                        133
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:32:35.556542 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #133 | Epoch Duration: 82.74106454849243
2020-01-11 03:32:35.556696 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #133 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01187591
Z variance train             0.0035434905
KL Divergence                11.849912
KL Loss                      1.1849912
QF Loss                      249.48666
VF Loss                      137.58734
Policy Loss                  -1011.4937
Q Predictions Mean           1010.96106
Q Predictions Std            418.79895
Q Predictions Max            1373.2122
Q Predictions Min            0.08203131
V Predictions Mean           1016.1256
V Predictions Std            420.04013
V Predictions Max            1376.6168
V Predictions Min            -4.81613
Log Pis Mean                 0.135379
Log Pis Std                  2.109438
Log Pis Max                  8.191335
Log Pis Min                  -5.1337914
Policy mu Mean               0.019092318
Policy mu Std                0.94287574
Policy mu Max                2.5082982
Policy mu Min                -2.8719532
Policy log std Mean          -0.5216958
Policy log std Std           0.23795582
Policy log std Max           0.0112810135
Policy log std Min           -1.3816572
Z mean eval                  0.019093387
Z variance eval              0.0036671378
total_rewards                [2006.35949339 1597.87372175 1699.0603382  1003.2682224  2026.51170861
 1819.08659847 1011.56195155 1172.68748293 2999.13024299 2166.17974847]
total_rewards_mean           1750.1719508760489
total_rewards_std            578.135764279009
total_rewards_max            2999.1302429924303
total_rewards_min            1003.2682223954278
Number of train steps total  135000
Number of env steps total    677000
Number of rollouts total     0
Train Time (s)               43.61284227576107
(Previous) Eval Time (s)     17.555986414663494
Sample Time (s)              22.32670664647594
Epoch Time (s)               83.4955353369005
Total Train Time (s)         9939.437526387628
Epoch                        134
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:33:59.081645 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #134 | Epoch Duration: 83.52483463287354
2020-01-11 03:33:59.081767 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #134 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01812284
Z variance train             0.0036631904
KL Divergence                11.605574
KL Loss                      1.1605574
QF Loss                      211.24744
VF Loss                      184.25854
Policy Loss                  -1000.222
Q Predictions Mean           997.1844
Q Predictions Std            442.50793
Q Predictions Max            1402.2571
Q Predictions Min            2.098116
V Predictions Mean           996.15967
V Predictions Std            441.78574
V Predictions Max            1390.7026
V Predictions Min            3.6819944
Log Pis Mean                 -0.013490258
Log Pis Std                  2.0870156
Log Pis Max                  9.356714
Log Pis Min                  -5.888734
Policy mu Mean               0.08983049
Policy mu Std                0.95554155
Policy mu Max                2.280906
Policy mu Min                -3.077396
Policy log std Mean          -0.4965665
Policy log std Std           0.23547433
Policy log std Max           0.09628871
Policy log std Min           -1.3854412
Z mean eval                  0.009201434
Z variance eval              0.003784772
total_rewards                [3094.48357275 1952.98964281 1659.09286578 1942.57519003 2126.3515796
 1981.70497612 2938.43859805 2382.17652517 2590.2452251  1312.14591058]
total_rewards_mean           2198.0204085986143
total_rewards_std            528.3991604649806
total_rewards_max            3094.4835727515674
total_rewards_min            1312.145910582488
Number of train steps total  136000
Number of env steps total    682000
Number of rollouts total     0
Train Time (s)               42.99251943966374
(Previous) Eval Time (s)     17.585062869358808
Sample Time (s)              21.67760471254587
Epoch Time (s)               82.25518702156842
Total Train Time (s)         10027.776517492719
Epoch                        135
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:35:27.422410 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #135 | Epoch Duration: 88.34055256843567
2020-01-11 03:35:27.422530 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #135 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008988291
Z variance train             0.0037841934
KL Divergence                11.512938
KL Loss                      1.1512938
QF Loss                      233.79416
VF Loss                      89.182526
Policy Loss                  -1003.814
Q Predictions Mean           1001.46716
Q Predictions Std            444.7154
Q Predictions Max            1408.8646
Q Predictions Min            1.4363747
V Predictions Mean           1004.0492
V Predictions Std            443.5488
V Predictions Max            1402.7987
V Predictions Min            -1.5642576
Log Pis Mean                 0.15626186
Log Pis Std                  2.0593505
Log Pis Max                  9.907537
Log Pis Min                  -3.5251317
Policy mu Mean               0.056949716
Policy mu Std                0.9198221
Policy mu Max                2.4450881
Policy mu Min                -3.052739
Policy log std Mean          -0.5148507
Policy log std Std           0.23154049
Policy log std Max           0.053203225
Policy log std Min           -1.292322
Z mean eval                  0.024176147
Z variance eval              0.0035844252
total_rewards                [1739.61474119 1443.26320524 3076.38168218 3012.44059035 1427.30082167
 1160.08067658 1421.67215965 1464.99280764 1629.02337769 1735.57118503]
total_rewards_mean           1811.034124722238
total_rewards_std            637.6519155594702
total_rewards_max            3076.3816821759274
total_rewards_min            1160.08067657747
Number of train steps total  137000
Number of env steps total    687000
Number of rollouts total     0
Train Time (s)               43.22913419920951
(Previous) Eval Time (s)     23.670192253310233
Sample Time (s)              21.482233677059412
Epoch Time (s)               88.38156012957916
Total Train Time (s)         10109.329826458823
Epoch                        136
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:36:48.981585 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #136 | Epoch Duration: 81.55891799926758
2020-01-11 03:36:48.981863 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #136 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024083165
Z variance train             0.0035812226
KL Divergence                11.741391
KL Loss                      1.1741391
QF Loss                      279.53967
VF Loss                      100.67493
Policy Loss                  -984.49713
Q Predictions Mean           983.5575
Q Predictions Std            461.49933
Q Predictions Max            1407.9127
Q Predictions Min            -8.282548
V Predictions Mean           985.66406
V Predictions Std            461.56628
V Predictions Max            1395.9998
V Predictions Min            -1.438108
Log Pis Mean                 0.02634554
Log Pis Std                  1.9916326
Log Pis Max                  8.170589
Log Pis Min                  -4.0148144
Policy mu Mean               0.06801868
Policy mu Std                0.9171049
Policy mu Max                2.6264508
Policy mu Min                -3.7046602
Policy log std Mean          -0.4901143
Policy log std Std           0.23144409
Policy log std Max           0.044644237
Policy log std Min           -1.3738716
Z mean eval                  0.02412247
Z variance eval              0.0035379112
total_rewards                [1234.1328986  2980.5072878  3073.74618845 3052.74216278 3031.67023514
 2967.03869975 2990.64641101 2279.89683771 3039.79145906 2937.04881629]
total_rewards_mean           2758.7220996604105
total_rewards_std            554.1667877603652
total_rewards_max            3073.7461884544446
total_rewards_min            1234.1328986025146
Number of train steps total  138000
Number of env steps total    692000
Number of rollouts total     0
Train Time (s)               42.73790031997487
(Previous) Eval Time (s)     16.84728933684528
Sample Time (s)              21.27467077318579
Epoch Time (s)               80.85986043000594
Total Train Time (s)         10203.946948973928
Epoch                        137
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:38:23.598166 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #137 | Epoch Duration: 94.61611008644104
2020-01-11 03:38:23.598287 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #137 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025038412
Z variance train             0.0035397192
KL Divergence                11.7114725
KL Loss                      1.1711472
QF Loss                      241.15578
VF Loss                      190.00052
Policy Loss                  -1002.22925
Q Predictions Mean           1004.21765
Q Predictions Std            439.2868
Q Predictions Max            1401.1398
Q Predictions Min            -10.146236
V Predictions Mean           1012.11633
V Predictions Std            440.03836
V Predictions Max            1412.2391
V Predictions Min            -2.8748782
Log Pis Mean                 -0.17533688
Log Pis Std                  1.9984506
Log Pis Max                  6.0413094
Log Pis Min                  -5.827075
Policy mu Mean               0.14910857
Policy mu Std                0.870928
Policy mu Max                2.6315868
Policy mu Min                -2.8731365
Policy log std Mean          -0.48648217
Policy log std Std           0.21285743
Policy log std Max           0.111813515
Policy log std Min           -1.2415456
Z mean eval                  0.017635155
Z variance eval              0.0035988204
total_rewards                [3011.36854011 2969.64433873 3089.33721543 3033.67661418 3017.31550799
 3028.58301615 3110.6953878  3022.97096923 3038.1643355  3063.79605307]
total_rewards_mean           3038.5551978184367
total_rewards_std            38.37360071535721
total_rewards_max            3110.6953877985256
total_rewards_min            2969.644338727219
Number of train steps total  139000
Number of env steps total    697000
Number of rollouts total     0
Train Time (s)               42.570394774433225
(Previous) Eval Time (s)     30.603322422597557
Sample Time (s)              22.152839807327837
Epoch Time (s)               95.32655700435862
Total Train Time (s)         10301.42495769076
Epoch                        138
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:40:01.082153 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #138 | Epoch Duration: 97.48372721672058
2020-01-11 03:40:01.082435 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #138 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018618625
Z variance train             0.003604211
KL Divergence                11.617369
KL Loss                      1.1617368
QF Loss                      350.36478
VF Loss                      272.27948
Policy Loss                  -999.9701
Q Predictions Mean           1003.4337
Q Predictions Std            448.50494
Q Predictions Max            1439.7866
Q Predictions Min            -6.3893995
V Predictions Mean           1011.23334
V Predictions Std            451.25427
V Predictions Max            1444.6997
V Predictions Min            -0.4354547
Log Pis Mean                 0.09642397
Log Pis Std                  2.3174171
Log Pis Max                  12.385471
Log Pis Min                  -5.931048
Policy mu Mean               0.14871775
Policy mu Std                0.941053
Policy mu Max                4.069145
Policy mu Min                -2.9720173
Policy log std Mean          -0.51016015
Policy log std Std           0.23675773
Policy log std Max           0.03053224
Policy log std Min           -1.5295529
Z mean eval                  0.039774932
Z variance eval              0.0039992826
total_rewards                [2552.64926471 1132.08495143 1612.34569628 2351.07806795 3138.34429823
 1964.06063551  968.36878344 1623.16882815 1242.10582412 2500.92821625]
total_rewards_mean           1908.5134566055435
total_rewards_std            676.5536395625251
total_rewards_max            3138.3442982278602
total_rewards_min            968.3687834362302
Number of train steps total  140000
Number of env steps total    702000
Number of rollouts total     0
Train Time (s)               43.33122874982655
(Previous) Eval Time (s)     32.76023043971509
Sample Time (s)              22.995913608931005
Epoch Time (s)               99.08737279847264
Total Train Time (s)         10385.705089869909
Epoch                        139
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:41:25.362518 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #139 | Epoch Duration: 84.27987360954285
2020-01-11 03:41:25.362679 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #139 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03943505
Z variance train             0.003998709
KL Divergence                11.428109
KL Loss                      1.142811
QF Loss                      274.21994
VF Loss                      134.9208
Policy Loss                  -1038.11
Q Predictions Mean           1036.7681
Q Predictions Std            456.5535
Q Predictions Max            1437.6802
Q Predictions Min            -9.199526
V Predictions Mean           1043.0066
V Predictions Std            458.7649
V Predictions Max            1453.4801
V Predictions Min            -17.541191
Log Pis Mean                 -0.084487
Log Pis Std                  1.9430639
Log Pis Max                  7.272213
Log Pis Min                  -4.2254086
Policy mu Mean               0.0710152
Policy mu Std                0.9316406
Policy mu Max                2.3644338
Policy mu Min                -3.0859132
Policy log std Mean          -0.505387
Policy log std Std           0.23503534
Policy log std Max           0.15170369
Policy log std Min           -1.3265102
Z mean eval                  0.010809677
Z variance eval              0.004572298
total_rewards                [1579.22425109 2895.74888885 2846.44245039 1126.12720027 2155.64025786
 2083.76253235 1477.21697537 1929.1919753  1355.69872819 2710.42001895]
total_rewards_mean           2015.9473278621015
total_rewards_std            607.1548627078924
total_rewards_max            2895.748888852412
total_rewards_min            1126.1272002702005
Number of train steps total  141000
Number of env steps total    707000
Number of rollouts total     0
Train Time (s)               43.219623473938555
(Previous) Eval Time (s)     17.952504062559456
Sample Time (s)              21.81598324328661
Epoch Time (s)               82.98811077978462
Total Train Time (s)         10472.947934045456
Epoch                        140
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:42:52.609835 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #140 | Epoch Duration: 87.24702596664429
2020-01-11 03:42:52.609976 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #140 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011092135
Z variance train             0.0045840037
KL Divergence                11.060213
KL Loss                      1.1060213
QF Loss                      468.05447
VF Loss                      219.29744
Policy Loss                  -1018.47577
Q Predictions Mean           1015.46936
Q Predictions Std            473.74002
Q Predictions Max            1428.9827
Q Predictions Min            -14.686026
V Predictions Mean           1015.8453
V Predictions Std            472.17932
V Predictions Max            1426.2467
V Predictions Min            -4.2831793
Log Pis Mean                 -0.053660467
Log Pis Std                  2.1696327
Log Pis Max                  9.800129
Log Pis Min                  -4.7035213
Policy mu Mean               0.23106872
Policy mu Std                0.8870803
Policy mu Max                3.916741
Policy mu Min                -3.8956578
Policy log std Mean          -0.49608037
Policy log std Std           0.23575358
Policy log std Max           -0.020592332
Policy log std Min           -1.9642699
Z mean eval                  0.009489909
Z variance eval              0.0046280497
total_rewards                [3006.10245711 3059.68222122 2998.7692553  2984.73133232 3030.94508264
 2950.71079006 2994.76892421 3017.65218637 2946.28399909 3055.9331833 ]
total_rewards_mean           3004.557943161184
total_rewards_std            36.55957322004591
total_rewards_max            3059.6822212186644
total_rewards_min            2946.2839990851558
Number of train steps total  142000
Number of env steps total    712000
Number of rollouts total     0
Train Time (s)               42.625644562765956
(Previous) Eval Time (s)     22.211178162135184
Sample Time (s)              21.65521146217361
Epoch Time (s)               86.49203418707475
Total Train Time (s)         10569.315351812635
Epoch                        141
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:44:28.977546 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #141 | Epoch Duration: 96.36745285987854
2020-01-11 03:44:28.977668 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #141 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009425148
Z variance train             0.004623499
KL Divergence                11.108592
KL Loss                      1.1108593
QF Loss                      302.45276
VF Loss                      132.71133
Policy Loss                  -1044.1539
Q Predictions Mean           1046.0889
Q Predictions Std            443.8815
Q Predictions Max            1423.5848
Q Predictions Min            -0.3938726
V Predictions Mean           1042.8406
V Predictions Std            441.22675
V Predictions Max            1416.7711
V Predictions Min            -11.863066
Log Pis Mean                 -0.1864971
Log Pis Std                  2.3471913
Log Pis Max                  10.334478
Log Pis Min                  -7.8283815
Policy mu Mean               0.06410179
Policy mu Std                0.915819
Policy mu Max                2.6894782
Policy mu Min                -3.1810324
Policy log std Mean          -0.4761246
Policy log std Std           0.22659586
Policy log std Max           0.11286795
Policy log std Min           -1.4526131
Z mean eval                  0.017026816
Z variance eval              0.004231675
total_rewards                [ 955.67143645 3134.51927484 3075.4618355  3144.95400159 3110.44473706
 3125.76656196 3126.42131809 3071.16111368 3119.61996924 3136.50416381]
total_rewards_mean           2900.0524412219174
total_rewards_std            648.551429169628
total_rewards_max            3144.954001590973
total_rewards_min            955.6714364512459
Number of train steps total  143000
Number of env steps total    717000
Number of rollouts total     0
Train Time (s)               43.467789269052446
(Previous) Eval Time (s)     32.08636728301644
Sample Time (s)              19.762675628531724
Epoch Time (s)               95.31683218060061
Total Train Time (s)         10663.482422633562
Epoch                        142
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:46:03.146936 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #142 | Epoch Duration: 94.16917705535889
2020-01-11 03:46:03.147058 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #142 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017199852
Z variance train             0.004232922
KL Divergence                11.351509
KL Loss                      1.1351509
QF Loss                      651.13525
VF Loss                      145.23093
Policy Loss                  -1018.0499
Q Predictions Mean           1017.86005
Q Predictions Std            461.6949
Q Predictions Max            1440.0378
Q Predictions Min            -24.590204
V Predictions Mean           1018.5145
V Predictions Std            461.84967
V Predictions Max            1440.5153
V Predictions Min            -14.497813
Log Pis Mean                 0.16618216
Log Pis Std                  2.300492
Log Pis Max                  10.490443
Log Pis Min                  -6.2290516
Policy mu Mean               0.07743355
Policy mu Std                0.9466548
Policy mu Max                3.2974148
Policy mu Min                -3.5551202
Policy log std Mean          -0.49408603
Policy log std Std           0.24184747
Policy log std Max           0.07081428
Policy log std Min           -1.4849392
Z mean eval                  0.012797579
Z variance eval              0.0050264727
total_rewards                [3116.05639485 1572.6368955  3171.47438488 1514.14257655 1168.84148362
 3194.38093759 3250.79557833 1559.81871262 2110.28667425 3221.90425279]
total_rewards_mean           2388.033789097563
total_rewards_std            831.3700233079182
total_rewards_max            3250.795578325863
total_rewards_min            1168.8414836226684
Number of train steps total  144000
Number of env steps total    722000
Number of rollouts total     0
Train Time (s)               43.75540546793491
(Previous) Eval Time (s)     30.938512248918414
Sample Time (s)              21.953234632965177
Epoch Time (s)               96.6471523498185
Total Train Time (s)         10753.422592076939
Epoch                        143
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:47:33.087961 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #143 | Epoch Duration: 89.94080567359924
2020-01-11 03:47:33.088090 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #143 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012923854
Z variance train             0.0050347643
KL Divergence                10.931251
KL Loss                      1.0931251
QF Loss                      304.3889
VF Loss                      143.5704
Policy Loss                  -1018.97876
Q Predictions Mean           1020.963
Q Predictions Std            487.3524
Q Predictions Max            1441.5349
Q Predictions Min            4.2181587
V Predictions Mean           1014.3578
V Predictions Std            486.101
V Predictions Max            1420.748
V Predictions Min            -29.15026
Log Pis Mean                 -0.2697108
Log Pis Std                  1.9544184
Log Pis Max                  7.111436
Log Pis Min                  -5.7372065
Policy mu Mean               0.04913051
Policy mu Std                0.8499473
Policy mu Max                2.758507
Policy mu Min                -2.6468067
Policy log std Mean          -0.46800503
Policy log std Std           0.2383921
Policy log std Max           0.09678948
Policy log std Min           -1.6180203
Z mean eval                  0.019181453
Z variance eval              0.0046919924
total_rewards                [1044.72540869 1541.99013808 3255.18849562 2153.82125718  992.02852698
 1047.37078678 3307.00760762 1626.3748886  1021.08541694 1056.57173669]
total_rewards_mean           1704.616426320236
total_rewards_std            864.2147492720562
total_rewards_max            3307.0076076233477
total_rewards_min            992.0285269839258
Number of train steps total  145000
Number of env steps total    727000
Number of rollouts total     0
Train Time (s)               43.730216237250715
(Previous) Eval Time (s)     24.231921446043998
Sample Time (s)              22.219699557404965
Epoch Time (s)               90.18183724069968
Total Train Time (s)         10836.253681040369
Epoch                        144
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:48:55.921081 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #144 | Epoch Duration: 82.83289241790771
2020-01-11 03:48:55.921213 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #144 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019357491
Z variance train             0.004693393
KL Divergence                10.999148
KL Loss                      1.0999149
QF Loss                      311.81778
VF Loss                      105.20174
Policy Loss                  -1033.37
Q Predictions Mean           1031.6301
Q Predictions Std            461.61154
Q Predictions Max            1436.3871
Q Predictions Min            -2.825993
V Predictions Mean           1032.6289
V Predictions Std            462.1685
V Predictions Max            1440.5288
V Predictions Min            -3.215837
Log Pis Mean                 -0.06380817
Log Pis Std                  2.0243733
Log Pis Max                  7.191654
Log Pis Min                  -5.5643015
Policy mu Mean               0.15497132
Policy mu Std                0.8784283
Policy mu Max                3.0299425
Policy mu Min                -2.8644018
Policy log std Mean          -0.4897131
Policy log std Std           0.24318014
Policy log std Max           0.04280874
Policy log std Min           -1.2738167
Z mean eval                  0.016498663
Z variance eval              0.0046151825
total_rewards                [3038.44930219 3051.21382873 3089.04491643 3101.14584545 1028.73386428
 3075.48701565 3095.7282244  3086.8745831  3075.73413877 2188.7759866 ]
total_rewards_mean           2783.11877055876
total_rewards_std            642.184211939928
total_rewards_max            3101.145845447034
total_rewards_min            1028.7338642788925
Number of train steps total  146000
Number of env steps total    732000
Number of rollouts total     0
Train Time (s)               43.61115532135591
(Previous) Eval Time (s)     16.88273927103728
Sample Time (s)              21.703510316088796
Epoch Time (s)               82.19740490848199
Total Train Time (s)         10931.48963495344
Epoch                        145
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:50:31.158576 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #145 | Epoch Duration: 95.23724102973938
2020-01-11 03:50:31.158699 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #145 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016893562
Z variance train             0.0046116924
KL Divergence                11.0582485
KL Loss                      1.1058248
QF Loss                      274.9043
VF Loss                      508.45874
Policy Loss                  -958.3195
Q Predictions Mean           956.865
Q Predictions Std            520.8846
Q Predictions Max            1426.7545
Q Predictions Min            -3.4344602
V Predictions Mean           963.57837
V Predictions Std            520.76105
V Predictions Max            1440.9733
V Predictions Min            2.1867368
Log Pis Mean                 -0.3756576
Log Pis Std                  1.9979217
Log Pis Max                  9.458275
Log Pis Min                  -5.2987027
Policy mu Mean               0.106803395
Policy mu Std                0.88312745
Policy mu Max                3.3235233
Policy mu Min                -4.0102177
Policy log std Mean          -0.4605423
Policy log std Std           0.24426305
Policy log std Max           0.0052651465
Policy log std Min           -1.2271328
Z mean eval                  0.021663446
Z variance eval              0.004004711
total_rewards                [3278.50806599 3208.73613267 2839.50276832 3331.14161514 2587.80936201
 1532.06517319 3249.13902779 3247.20309782 2640.32018267 1976.16312907]
total_rewards_mean           2789.0588554666456
total_rewards_std            586.2691272605854
total_rewards_max            3331.141615139526
total_rewards_min            1532.0651731917528
Number of train steps total  147000
Number of env steps total    737000
Number of rollouts total     0
Train Time (s)               43.521247384138405
(Previous) Eval Time (s)     29.922350264154375
Sample Time (s)              21.94538125442341
Epoch Time (s)               95.38897890271619
Total Train Time (s)         11022.474953748751
Epoch                        146
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:52:02.148194 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #146 | Epoch Duration: 90.9893729686737
2020-01-11 03:52:02.148366 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #146 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021739135
Z variance train             0.0040192953
KL Divergence                11.481365
KL Loss                      1.1481365
QF Loss                      487.14606
VF Loss                      460.39386
Policy Loss                  -981.49243
Q Predictions Mean           982.4749
Q Predictions Std            473.5554
Q Predictions Max            1419.8212
Q Predictions Min            -7.3026814
V Predictions Mean           995.9305
V Predictions Std            475.8364
V Predictions Max            1424.2875
V Predictions Min            1.6469598
Log Pis Mean                 -0.19007081
Log Pis Std                  2.1011899
Log Pis Max                  9.239737
Log Pis Min                  -4.826701
Policy mu Mean               0.07341582
Policy mu Std                0.8743572
Policy mu Max                3.063546
Policy mu Min                -3.1917741
Policy log std Mean          -0.50315124
Policy log std Std           0.24101172
Policy log std Max           0.029679358
Policy log std Min           -1.5826771
Z mean eval                  0.011471862
Z variance eval              0.0042897747
total_rewards                [ 973.73997584 3095.16145388 3051.52675433 2821.96169172 2138.63462155
 3059.79213959 2204.96438409 2152.36816061 2905.3002009  2077.56363783]
total_rewards_mean           2448.1013020323776
total_rewards_std            637.1153726235752
total_rewards_max            3095.16145388049
total_rewards_min            973.739975838626
Number of train steps total  148000
Number of env steps total    742000
Number of rollouts total     0
Train Time (s)               42.92507841065526
(Previous) Eval Time (s)     25.522509552072734
Sample Time (s)              21.35905611142516
Epoch Time (s)               89.80664407415316
Total Train Time (s)         11112.10519289365
Epoch                        147
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:53:31.779144 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #147 | Epoch Duration: 89.63064932823181
2020-01-11 03:53:31.779269 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #147 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011186798
Z variance train             0.004294435
KL Divergence                11.370128
KL Loss                      1.1370128
QF Loss                      218.39868
VF Loss                      335.6153
Policy Loss                  -1046.2756
Q Predictions Mean           1047.0327
Q Predictions Std            489.4076
Q Predictions Max            1455.0201
Q Predictions Min            -12.136228
V Predictions Mean           1053.9901
V Predictions Std            488.7198
V Predictions Max            1459.9546
V Predictions Min            -15.11884
Log Pis Mean                 -0.16714706
Log Pis Std                  1.9730071
Log Pis Max                  10.252391
Log Pis Min                  -4.2645683
Policy mu Mean               0.21837695
Policy mu Std                0.8606473
Policy mu Max                3.4541883
Policy mu Min                -2.6272912
Policy log std Mean          -0.4810427
Policy log std Std           0.2318417
Policy log std Max           0.028778762
Policy log std Min           -1.3609593
Z mean eval                  0.016970556
Z variance eval              0.0055398955
total_rewards                [3139.67621189 2301.43458158 3159.44352998 3124.50745645 3202.85062129
 2483.97046427 1576.17310091 2345.88006644 2334.03729644 2640.16350332]
total_rewards_mean           2630.813683256504
total_rewards_std            502.09774730259704
total_rewards_max            3202.850621289261
total_rewards_min            1576.1731009110288
Number of train steps total  149000
Number of env steps total    747000
Number of rollouts total     0
Train Time (s)               42.916621996089816
(Previous) Eval Time (s)     25.346278976183385
Sample Time (s)              21.905965763609856
Epoch Time (s)               90.16886673588306
Total Train Time (s)         11203.868943768553
Epoch                        148
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:55:03.562932 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #148 | Epoch Duration: 91.78353762626648
2020-01-11 03:55:03.563160 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #148 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016207715
Z variance train             0.0055369954
KL Divergence                10.905507
KL Loss                      1.0905508
QF Loss                      401.8249
VF Loss                      149.61676
Policy Loss                  -1017.7733
Q Predictions Mean           1019.6193
Q Predictions Std            478.7576
Q Predictions Max            1433.7177
Q Predictions Min            -28.817745
V Predictions Mean           1022.3281
V Predictions Std            478.1501
V Predictions Max            1431.4706
V Predictions Min            -6.5549498
Log Pis Mean                 -0.05195474
Log Pis Std                  2.3872976
Log Pis Max                  10.210348
Log Pis Min                  -7.4981213
Policy mu Mean               0.14566208
Policy mu Std                0.93666846
Policy mu Max                3.0239406
Policy mu Min                -3.712756
Policy log std Mean          -0.494573
Policy log std Std           0.2488787
Policy log std Max           0.057428718
Policy log std Min           -1.8362434
Z mean eval                  0.024171198
Z variance eval              0.005798947
total_rewards                [2334.84369058 3064.28379724 3085.92488315  865.02699413 3099.0616209
 3141.09774574 3083.09182542 3106.12254914 1803.77981084 3076.85770464]
total_rewards_mean           2666.0090621798226
total_rewards_std            733.5732104977753
total_rewards_max            3141.0977457388053
total_rewards_min            865.0269941323171
Number of train steps total  150000
Number of env steps total    752000
Number of rollouts total     0
Train Time (s)               44.22759982198477
(Previous) Eval Time (s)     26.960697237867862
Sample Time (s)              21.845995467156172
Epoch Time (s)               93.0342925270088
Total Train Time (s)         11296.979360247962
Epoch                        149
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:56:36.660377 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #149 | Epoch Duration: 93.0970025062561
2020-01-11 03:56:36.660656 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #149 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024085809
Z variance train             0.0057932944
KL Divergence                10.747036
KL Loss                      1.0747036
QF Loss                      370.83163
VF Loss                      158.52295
Policy Loss                  -1025.9325
Q Predictions Mean           1023.67615
Q Predictions Std            484.17786
Q Predictions Max            1449.0764
Q Predictions Min            -10.88434
V Predictions Mean           1033.1316
V Predictions Std            484.98077
V Predictions Max            1460.6937
V Predictions Min            -16.588575
Log Pis Mean                 0.03974379
Log Pis Std                  2.458301
Log Pis Max                  11.751588
Log Pis Min                  -5.6015525
Policy mu Mean               0.14096041
Policy mu Std                0.97008103
Policy mu Max                2.9357083
Policy mu Min                -3.7566767
Policy log std Mean          -0.49419865
Policy log std Std           0.21965116
Policy log std Max           0.08317119
Policy log std Min           -1.3215543
Z mean eval                  0.013199878
Z variance eval              0.005675558
total_rewards                [3100.39576509 3086.94840283 3168.84958942 1733.23367804 2907.97263135
 3094.39658211 3148.52391059 3148.95709475 3152.17885613 3064.82757154]
total_rewards_mean           2960.628408184738
total_rewards_std            415.25095399781065
total_rewards_max            3168.8495894168445
total_rewards_min            1733.2336780377848
Number of train steps total  151000
Number of env steps total    757000
Number of rollouts total     0
Train Time (s)               43.234133118763566
(Previous) Eval Time (s)     27.023168892599642
Sample Time (s)              21.843285995535553
Epoch Time (s)               92.10058800689876
Total Train Time (s)         11393.71095726965
Epoch                        150
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:58:13.392619 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #150 | Epoch Duration: 96.73175072669983
2020-01-11 03:58:13.392779 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #150 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012357777
Z variance train             0.005675592
KL Divergence                10.592073
KL Loss                      1.0592073
QF Loss                      328.75024
VF Loss                      349.6964
Policy Loss                  -1058.135
Q Predictions Mean           1058.3613
Q Predictions Std            476.09326
Q Predictions Max            1477.2678
Q Predictions Min            3.6738741
V Predictions Mean           1045.4287
V Predictions Std            473.91788
V Predictions Max            1453.7633
V Predictions Min            -3.6215515
Log Pis Mean                 -0.071385816
Log Pis Std                  2.2283716
Log Pis Max                  7.695719
Log Pis Min                  -6.0965366
Policy mu Mean               -0.00950734
Policy mu Std                0.9375479
Policy mu Max                2.1436505
Policy mu Min                -3.1342359
Policy log std Mean          -0.4973613
Policy log std Std           0.24903008
Policy log std Max           0.0623464
Policy log std Min           -1.8945117
Z mean eval                  0.015844494
Z variance eval              0.0056343316
total_rewards                [ 705.13392875 3186.14227492 1463.47452411 2794.96530633 1550.10741194
 2760.13507032 3136.74388768 3193.89768721 1076.79784758 2578.80226923]
total_rewards_mean           2244.6200208067385
total_rewards_std            899.4527679828378
total_rewards_max            3193.897687212441
total_rewards_min            705.1339287456259
Number of train steps total  152000
Number of env steps total    762000
Number of rollouts total     0
Train Time (s)               43.87629496585578
(Previous) Eval Time (s)     31.65410443721339
Sample Time (s)              21.82111259782687
Epoch Time (s)               97.35151200089604
Total Train Time (s)         11484.423232917674
Epoch                        151
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 03:59:44.106165 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #151 | Epoch Duration: 90.71325635910034
2020-01-11 03:59:44.106323 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #151 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015974944
Z variance train             0.005630638
KL Divergence                10.644482
KL Loss                      1.0644482
QF Loss                      671.3484
VF Loss                      104.73347
Policy Loss                  -1088.7905
Q Predictions Mean           1087.3308
Q Predictions Std            446.312
Q Predictions Max            1465.5889
Q Predictions Min            -2.683215
V Predictions Mean           1093.5513
V Predictions Std            446.6328
V Predictions Max            1471.3145
V Predictions Min            -1.5800744
Log Pis Mean                 -0.31820285
Log Pis Std                  2.083301
Log Pis Max                  9.211004
Log Pis Min                  -5.441981
Policy mu Mean               0.034656174
Policy mu Std                0.87411165
Policy mu Max                2.6064756
Policy mu Min                -2.8889167
Policy log std Mean          -0.50080603
Policy log std Std           0.22303742
Policy log std Max           0.013228685
Policy log std Min           -1.3053303
Z mean eval                  0.03355565
Z variance eval              0.0052618063
total_rewards                [3002.44050542 3128.40084767 1211.88656194 2688.3152375  1045.91948192
 3200.63997397 1512.14976185 1603.24180715  665.20267168 2869.76101118]
total_rewards_mean           2092.7957860288043
total_rewards_std            925.8701066086854
total_rewards_max            3200.6399739724425
total_rewards_min            665.2026716806859
Number of train steps total  153000
Number of env steps total    767000
Number of rollouts total     0
Train Time (s)               43.40791953308508
(Previous) Eval Time (s)     25.01561511401087
Sample Time (s)              21.642991419881582
Epoch Time (s)               90.06652606697753
Total Train Time (s)         11571.14752927376
Epoch                        152
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:01:10.833508 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #152 | Epoch Duration: 86.72704768180847
2020-01-11 04:01:10.833695 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #152 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032687336
Z variance train             0.0052659153
KL Divergence                10.820652
KL Loss                      1.0820652
QF Loss                      472.48767
VF Loss                      103.07863
Policy Loss                  -1065.3892
Q Predictions Mean           1062.7429
Q Predictions Std            455.62738
Q Predictions Max            1463.1659
Q Predictions Min            -3.1623511
V Predictions Mean           1061.6548
V Predictions Std            454.5627
V Predictions Max            1460.2869
V Predictions Min            -3.7623694
Log Pis Mean                 -0.30539697
Log Pis Std                  2.132381
Log Pis Max                  10.716253
Log Pis Min                  -5.0906477
Policy mu Mean               -0.019812271
Policy mu Std                0.84522206
Policy mu Max                2.3501456
Policy mu Min                -3.0696635
Policy log std Mean          -0.4786038
Policy log std Std           0.20787357
Policy log std Max           0.14575335
Policy log std Min           -1.2273732
Z mean eval                  0.017138738
Z variance eval              0.0058237608
total_rewards                [1382.30585941 2297.89613012 3004.46616423 3352.29313759 3338.74474898
 1638.34014968 3297.15372471 3283.75456337 1631.69950714 3320.8524483 ]
total_rewards_mean           2654.750643351442
total_rewards_std            784.5328845244774
total_rewards_max            3352.2931375944277
total_rewards_min            1382.3058594087563
Number of train steps total  154000
Number of env steps total    772000
Number of rollouts total     0
Train Time (s)               43.04836732940748
(Previous) Eval Time (s)     21.675895079039037
Sample Time (s)              21.831825411878526
Epoch Time (s)               86.55608782032505
Total Train Time (s)         11662.4206773052
Epoch                        153
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:02:42.106800 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #153 | Epoch Duration: 91.27297139167786
2020-01-11 04:02:42.106921 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #153 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016795903
Z variance train             0.005827546
KL Divergence                10.541288
KL Loss                      1.0541289
QF Loss                      583.0129
VF Loss                      230.80258
Policy Loss                  -1007.5306
Q Predictions Mean           1006.24304
Q Predictions Std            481.919
Q Predictions Max            1457.2936
Q Predictions Min            -14.79287
V Predictions Mean           1010.3519
V Predictions Std            479.12674
V Predictions Max            1448.6647
V Predictions Min            -8.83845
Log Pis Mean                 -0.1127246
Log Pis Std                  2.4687746
Log Pis Max                  12.435488
Log Pis Min                  -5.79377
Policy mu Mean               0.07653909
Policy mu Std                0.9471691
Policy mu Max                2.6960375
Policy mu Min                -3.1258628
Policy log std Mean          -0.48832583
Policy log std Std           0.22688253
Policy log std Max           0.13000888
Policy log std Min           -1.3400016
Z mean eval                  0.016967608
Z variance eval              0.0065123714
total_rewards                [2137.64736314 3220.39781815 1182.95926282 2644.22957755 1887.9731958
 2700.02440201 3296.80579901 1568.20130172 2934.55653442 2166.52576247]
total_rewards_mean           2373.9321017096286
total_rewards_std            668.1705687223215
total_rewards_max            3296.805799010094
total_rewards_min            1182.9592628222395
Number of train steps total  155000
Number of env steps total    777000
Number of rollouts total     0
Train Time (s)               42.61492381710559
(Previous) Eval Time (s)     26.3925624191761
Sample Time (s)              22.16391668142751
Epoch Time (s)               91.1714029177092
Total Train Time (s)         11748.400055873208
Epoch                        154
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:04:08.088965 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #154 | Epoch Duration: 85.98193836212158
2020-01-11 04:04:08.089141 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #154 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015897315
Z variance train             0.006513638
KL Divergence                10.286171
KL Loss                      1.0286171
QF Loss                      1078.9443
VF Loss                      205.81447
Policy Loss                  -1040.9875
Q Predictions Mean           1040.4622
Q Predictions Std            465.40076
Q Predictions Max            1460.8315
Q Predictions Min            2.7615476
V Predictions Mean           1046.5714
V Predictions Std            468.47076
V Predictions Max            1471.7487
V Predictions Min            -3.2347066
Log Pis Mean                 -0.12111145
Log Pis Std                  2.0069795
Log Pis Max                  8.841282
Log Pis Min                  -5.2266045
Policy mu Mean               0.12025091
Policy mu Std                0.89460295
Policy mu Max                2.6430237
Policy mu Min                -2.8439417
Policy log std Mean          -0.47964287
Policy log std Std           0.23175588
Policy log std Max           0.071844965
Policy log std Min           -1.3795208
Z mean eval                  0.015494138
Z variance eval              0.0059406934
total_rewards                [3098.33610168 3040.51539474 2600.01104262 3118.09311597 1713.12356497
 3158.92617471 3059.87276372 1132.59380399 2086.78072731 3102.61926105]
total_rewards_mean           2611.087195076327
total_rewards_std            684.7858225270467
total_rewards_max            3158.926174712933
total_rewards_min            1132.5938039921589
Number of train steps total  156000
Number of env steps total    782000
Number of rollouts total     0
Train Time (s)               43.8181929923594
(Previous) Eval Time (s)     21.202825834043324
Sample Time (s)              21.89292686060071
Epoch Time (s)               86.91394568700343
Total Train Time (s)         11840.052782736719
Epoch                        155
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:05:39.746691 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #155 | Epoch Duration: 91.65734362602234
2020-01-11 04:05:39.746951 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #155 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015097859
Z variance train             0.005932113
KL Divergence                10.523132
KL Loss                      1.0523132
QF Loss                      257.12573
VF Loss                      337.77713
Policy Loss                  -1071.9141
Q Predictions Mean           1075.9263
Q Predictions Std            443.98083
Q Predictions Max            1472.5264
Q Predictions Min            -3.088762
V Predictions Mean           1083.8821
V Predictions Std            444.9534
V Predictions Max            1450.7294
V Predictions Min            -6.4878864
Log Pis Mean                 -0.028141048
Log Pis Std                  2.0922775
Log Pis Max                  7.2542305
Log Pis Min                  -6.0486665
Policy mu Mean               0.08457748
Policy mu Std                0.9117559
Policy mu Max                2.6331356
Policy mu Min                -2.9007628
Policy log std Mean          -0.49466768
Policy log std Std           0.24333693
Policy log std Max           0.14955974
Policy log std Min           -1.3493938
Z mean eval                  0.021153847
Z variance eval              0.0060089305
total_rewards                [3117.7770697  3156.96044003 3168.43094525 3203.96303646 3113.44304907
 3202.06613304 3245.15947118 3243.01970217 1425.01895509 3215.18845896]
total_rewards_mean           3009.102726094123
total_rewards_std            529.8473817388049
total_rewards_max            3245.1594711752787
total_rewards_min            1425.0189550928753
Number of train steps total  157000
Number of env steps total    787000
Number of rollouts total     0
Train Time (s)               43.56915915478021
(Previous) Eval Time (s)     25.945968315936625
Sample Time (s)              22.05579899577424
Epoch Time (s)               91.57092646649107
Total Train Time (s)         11936.721743260976
Epoch                        156
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:07:16.416882 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #156 | Epoch Duration: 96.66976690292358
2020-01-11 04:07:16.417018 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #156 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021518847
Z variance train             0.0060084895
KL Divergence                10.690662
KL Loss                      1.0690663
QF Loss                      189.67787
VF Loss                      133.26363
Policy Loss                  -1001.45624
Q Predictions Mean           994.74335
Q Predictions Std            515.2289
Q Predictions Max            1468.0166
Q Predictions Min            -9.98913
V Predictions Mean           999.4161
V Predictions Std            516.3308
V Predictions Max            1473.31
V Predictions Min            -2.7012508
Log Pis Mean                 -0.1227056
Log Pis Std                  2.161719
Log Pis Max                  10.92329
Log Pis Min                  -7.2509317
Policy mu Mean               0.06391918
Policy mu Std                0.8834997
Policy mu Max                2.716509
Policy mu Min                -3.0412862
Policy log std Mean          -0.47266617
Policy log std Std           0.2230724
Policy log std Max           0.10039437
Policy log std Min           -1.28089
Z mean eval                  0.018834185
Z variance eval              0.0062062526
total_rewards                [3131.83988417 2656.25550484 3081.42335468  682.16301262 2686.12525084
  986.48158077 3080.30299014  880.23339699 3144.13584144 3057.89509553]
total_rewards_mean           2338.685591202424
total_rewards_std            990.8548031883792
total_rewards_max            3144.1358414393985
total_rewards_min            682.1630126178899
Number of train steps total  158000
Number of env steps total    792000
Number of rollouts total     0
Train Time (s)               43.20583751285449
(Previous) Eval Time (s)     31.04459054907784
Sample Time (s)              21.506274092476815
Epoch Time (s)               95.75670215440914
Total Train Time (s)         12025.563773923088
Epoch                        157
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:08:45.266387 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #157 | Epoch Duration: 88.84910774230957
2020-01-11 04:08:45.266817 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #157 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019097168
Z variance train             0.0062200865
KL Divergence                10.642656
KL Loss                      1.0642656
QF Loss                      164.78632
VF Loss                      77.53815
Policy Loss                  -1042.8765
Q Predictions Mean           1040.7902
Q Predictions Std            493.62372
Q Predictions Max            1462.3549
Q Predictions Min            -0.92427504
V Predictions Mean           1045.4368
V Predictions Std            494.49338
V Predictions Max            1460.0416
V Predictions Min            -19.58403
Log Pis Mean                 -0.37404084
Log Pis Std                  1.9711357
Log Pis Max                  9.873651
Log Pis Min                  -5.898494
Policy mu Mean               0.021298869
Policy mu Std                0.8291714
Policy mu Max                2.4148974
Policy mu Min                -2.9523296
Policy log std Mean          -0.48379502
Policy log std Std           0.24605915
Policy log std Max           0.030391783
Policy log std Min           -1.2992945
Z mean eval                  0.021574084
Z variance eval              0.006462019
total_rewards                [1473.34053001  911.75859124 1091.30899028 2229.52591845 3110.81252282
 3118.3412587  2014.68114904 1349.09637443 3010.658434   3112.50104561]
total_rewards_mean           2142.2024814568276
total_rewards_std            854.7161719837037
total_rewards_max            3118.341258700139
total_rewards_min            911.7585912443892
Number of train steps total  159000
Number of env steps total    797000
Number of rollouts total     0
Train Time (s)               43.17101076012477
(Previous) Eval Time (s)     24.13671690924093
Sample Time (s)              19.88717635674402
Epoch Time (s)               87.19490402610973
Total Train Time (s)         12111.473239690065
Epoch                        158
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:10:11.174583 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #158 | Epoch Duration: 85.90751504898071
2020-01-11 04:10:11.174703 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #158 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020743392
Z variance train             0.0064610257
KL Divergence                10.699322
KL Loss                      1.0699322
QF Loss                      335.403
VF Loss                      213.2521
Policy Loss                  -1043.2524
Q Predictions Mean           1040.1188
Q Predictions Std            490.23206
Q Predictions Max            1480.7778
Q Predictions Min            -29.853933
V Predictions Mean           1044.6887
V Predictions Std            488.03738
V Predictions Max            1472.1849
V Predictions Min            -13.180361
Log Pis Mean                 0.0181435
Log Pis Std                  2.0305464
Log Pis Max                  7.131838
Log Pis Min                  -4.9049034
Policy mu Mean               0.07379934
Policy mu Std                0.93941873
Policy mu Max                2.6640487
Policy mu Min                -3.5879052
Policy log std Mean          -0.5016453
Policy log std Std           0.22240987
Policy log std Max           -0.053556353
Policy log std Min           -1.2821648
Z mean eval                  0.016162748
Z variance eval              0.005755045
total_rewards                [3152.53485117 3135.06652168 2051.15108084 3198.96722731 3217.00086588
 3096.34954603 1586.77957845 1006.63475609 2653.87218886 1545.41906928]
total_rewards_mean           2464.377568560147
total_rewards_std            798.4471113592342
total_rewards_max            3217.000865876136
total_rewards_min            1006.6347560933598
Number of train steps total  160000
Number of env steps total    802000
Number of rollouts total     0
Train Time (s)               43.87007615994662
(Previous) Eval Time (s)     22.84912257269025
Sample Time (s)              21.812981138937175
Epoch Time (s)               88.53217987157404
Total Train Time (s)         12201.925400424283
Epoch                        159
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:11:41.630463 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #159 | Epoch Duration: 90.45564675331116
2020-01-11 04:11:41.630654 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #159 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01586554
Z variance train             0.0057587475
KL Divergence                11.080591
KL Loss                      1.1080592
QF Loss                      14906.9
VF Loss                      174.35065
Policy Loss                  -1103.5364
Q Predictions Mean           1107.5977
Q Predictions Std            447.14154
Q Predictions Max            1495.187
Q Predictions Min            -9.096598
V Predictions Mean           1110.25
V Predictions Std            447.6911
V Predictions Max            1486.4626
V Predictions Min            -15.277824
Log Pis Mean                 -0.19726229
Log Pis Std                  2.0584707
Log Pis Max                  9.26198
Log Pis Min                  -4.1092463
Policy mu Mean               0.185017
Policy mu Std                0.87933
Policy mu Max                2.232158
Policy mu Min                -2.6713936
Policy log std Mean          -0.47270015
Policy log std Std           0.21625622
Policy log std Max           -0.0040870607
Policy log std Min           -1.14999
Z mean eval                  0.01918241
Z variance eval              0.0060319677
total_rewards                [3150.84665162 3158.12324574 1137.73930849 1084.04544205 2833.14045451
 2859.42322576 1126.1420512  1044.06409245 1024.65903283 1032.74540907]
total_rewards_mean           1845.092891372283
total_rewards_std            948.959720696187
total_rewards_max            3158.1232457425162
total_rewards_min            1024.659032827634
Number of train steps total  161000
Number of env steps total    807000
Number of rollouts total     0
Train Time (s)               43.500773537904024
(Previous) Eval Time (s)     24.772339711897075
Sample Time (s)              21.71149823674932
Epoch Time (s)               89.98461148655042
Total Train Time (s)         12284.579748063814
Epoch                        160
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:13:04.287392 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #160 | Epoch Duration: 82.65658831596375
2020-01-11 04:13:04.287558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #160 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019153742
Z variance train             0.0060346117
KL Divergence                10.9480095
KL Loss                      1.094801
QF Loss                      243.27258
VF Loss                      84.799614
Policy Loss                  -1087.8916
Q Predictions Mean           1089.0762
Q Predictions Std            468.81674
Q Predictions Max            1489.8092
Q Predictions Min            0.20886499
V Predictions Mean           1083.9348
V Predictions Std            466.3597
V Predictions Max            1484.9088
V Predictions Min            -22.838804
Log Pis Mean                 -0.4249091
Log Pis Std                  1.9559184
Log Pis Max                  9.023376
Log Pis Min                  -5.8103576
Policy mu Mean               -0.072073095
Policy mu Std                0.86671436
Policy mu Max                3.4506793
Policy mu Min                -3.274142
Policy log std Mean          -0.4634687
Policy log std Std           0.21503507
Policy log std Max           0.006907314
Policy log std Min           -1.3607416
Z mean eval                  0.047184806
Z variance eval              0.005528112
total_rewards                [1276.25218135 1558.19245887 3158.09210058 2999.71648794 3186.54377194
 3199.9542615  3168.41383926 3155.77634813 3186.29221139 3095.09562361]
total_rewards_mean           2798.4329284574587
total_rewards_std            695.6991893337366
total_rewards_max            3199.9542615007745
total_rewards_min            1276.2521813478234
Number of train steps total  162000
Number of env steps total    812000
Number of rollouts total     0
Train Time (s)               43.173836786765605
(Previous) Eval Time (s)     17.44408835982904
Sample Time (s)              21.836771811824292
Epoch Time (s)               82.45469695841894
Total Train Time (s)         12378.170279690996
Epoch                        161
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:14:37.879769 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #161 | Epoch Duration: 93.59208559989929
2020-01-11 04:14:37.879890 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #161 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04722897
Z variance train             0.0055311783
KL Divergence                11.165332
KL Loss                      1.1165332
QF Loss                      328.46832
VF Loss                      223.22527
Policy Loss                  -1036.4052
Q Predictions Mean           1037.0627
Q Predictions Std            476.3324
Q Predictions Max            1463.0781
Q Predictions Min            -8.754802
V Predictions Mean           1030.442
V Predictions Std            472.94598
V Predictions Max            1461.278
V Predictions Min            2.1038263
Log Pis Mean                 -0.277763
Log Pis Std                  2.105821
Log Pis Max                  9.552567
Log Pis Min                  -6.41707
Policy mu Mean               -0.03277532
Policy mu Std                0.8932832
Policy mu Max                3.35522
Policy mu Min                -2.916192
Policy log std Mean          -0.48249567
Policy log std Std           0.23159349
Policy log std Max           0.19825706
Policy log std Min           -1.243653
Z mean eval                  0.01692199
Z variance eval              0.0053655272
total_rewards                [2219.53348118 1031.09597869 3182.87103617 3119.81454695 1026.50479262
 2326.1656412  1521.63582298 1051.86542396 1017.98468214 3064.43432544]
total_rewards_mean           1956.1905731331753
total_rewards_std            888.8300581609188
total_rewards_max            3182.871036167715
total_rewards_min            1017.9846821438296
Number of train steps total  163000
Number of env steps total    817000
Number of rollouts total     0
Train Time (s)               43.53184923669323
(Previous) Eval Time (s)     28.581238687969744
Sample Time (s)              21.294233612250537
Epoch Time (s)               93.40732153691351
Total Train Time (s)         12463.449300271459
Epoch                        162
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:16:03.160890 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #162 | Epoch Duration: 85.28088688850403
2020-01-11 04:16:03.161068 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #162 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017474858
Z variance train             0.0053609507
KL Divergence                11.048634
KL Loss                      1.1048634
QF Loss                      191.20561
VF Loss                      269.2465
Policy Loss                  -1073.5509
Q Predictions Mean           1073.1914
Q Predictions Std            448.93652
Q Predictions Max            1479.9916
Q Predictions Min            0.862085
V Predictions Mean           1071.4958
V Predictions Std            448.67938
V Predictions Max            1481.2994
V Predictions Min            -20.549297
Log Pis Mean                 -0.28922877
Log Pis Std                  2.0017607
Log Pis Max                  12.840002
Log Pis Min                  -5.638624
Policy mu Mean               0.14029227
Policy mu Std                0.86535776
Policy mu Max                2.6990716
Policy mu Min                -3.0901074
Policy log std Mean          -0.49535766
Policy log std Std           0.22885531
Policy log std Max           0.12663227
Policy log std Min           -1.3446778
Z mean eval                  0.017269174
Z variance eval              0.0058174427
total_rewards                [3174.14015933 1036.72355709 1117.15870247  982.36962598 1072.25709562
  876.93429922 1230.09188169 1048.83017206 3160.31676572 1705.20656186]
total_rewards_mean           1540.4028821043235
total_rewards_std            840.3508809590132
total_rewards_max            3174.1401593334654
total_rewards_min            876.934299218648
Number of train steps total  164000
Number of env steps total    822000
Number of rollouts total     0
Train Time (s)               43.422947886865586
(Previous) Eval Time (s)     20.454560759011656
Sample Time (s)              19.967677618842572
Epoch Time (s)               83.84518626471981
Total Train Time (s)         12542.088360369671
Epoch                        163
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:17:21.807054 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #163 | Epoch Duration: 78.64580082893372
2020-01-11 04:17:21.807371 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #163 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017695896
Z variance train             0.0058214767
KL Divergence                10.760764
KL Loss                      1.0760764
QF Loss                      357.26175
VF Loss                      125.805405
Policy Loss                  -1090.3892
Q Predictions Mean           1086.871
Q Predictions Std            478.33044
Q Predictions Max            1494.6412
Q Predictions Min            -11.250775
V Predictions Mean           1094.4514
V Predictions Std            480.344
V Predictions Max            1490.4608
V Predictions Min            -18.820118
Log Pis Mean                 -0.18691036
Log Pis Std                  1.9909441
Log Pis Max                  9.176651
Log Pis Min                  -4.761036
Policy mu Mean               0.17776239
Policy mu Std                0.8602442
Policy mu Max                3.028941
Policy mu Min                -2.8657956
Policy log std Mean          -0.4902725
Policy log std Std           0.24465126
Policy log std Max           0.03957981
Policy log std Min           -1.4443138
Z mean eval                  0.014438483
Z variance eval              0.0052551143
total_rewards                [2996.14974602 3032.57118852 1054.85836264 3048.57408722 2436.85045391
 2975.1600423  3070.44545955 3053.07392973 2182.64516627  996.32899824]
total_rewards_mean           2484.665743438689
total_rewards_std            783.5571086609364
total_rewards_max            3070.445459545646
total_rewards_min            996.3289982366928
Number of train steps total  165000
Number of env steps total    827000
Number of rollouts total     0
Train Time (s)               43.20369193702936
(Previous) Eval Time (s)     15.254904400091618
Sample Time (s)              20.090643444098532
Epoch Time (s)               78.54923978121951
Total Train Time (s)         12630.293569225352
Epoch                        164
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:18:50.012172 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #164 | Epoch Duration: 88.20457196235657
2020-01-11 04:18:50.012349 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #164 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014948778
Z variance train             0.0052717277
KL Divergence                10.875185
KL Loss                      1.0875186
QF Loss                      486.28568
VF Loss                      258.4567
Policy Loss                  -1080.7242
Q Predictions Mean           1073.5503
Q Predictions Std            462.66855
Q Predictions Max            1496.4242
Q Predictions Min            -9.740534
V Predictions Mean           1085.0826
V Predictions Std            462.73383
V Predictions Max            1490.2908
V Predictions Min            -9.661453
Log Pis Mean                 -0.21603058
Log Pis Std                  2.0762022
Log Pis Max                  8.917605
Log Pis Min                  -4.2159805
Policy mu Mean               0.049666945
Policy mu Std                0.88159317
Policy mu Max                3.1411655
Policy mu Min                -3.1198497
Policy log std Mean          -0.46656632
Policy log std Std           0.21682197
Policy log std Max           -0.007815152
Policy log std Min           -1.1245646
Z mean eval                  0.027283933
Z variance eval              0.0047386647
total_rewards                [3228.00614582  940.06122154 3253.72991877 2151.76348397 1253.92775905
 2688.2751031  1039.94058401 2529.79322364 3207.82495608 1015.82219267]
total_rewards_mean           2130.914458863306
total_rewards_std            933.5492834551106
total_rewards_max            3253.7299187669378
total_rewards_min            940.0612215367495
Number of train steps total  166000
Number of env steps total    832000
Number of rollouts total     0
Train Time (s)               44.81669946806505
(Previous) Eval Time (s)     24.9100103196688
Sample Time (s)              19.931480710860342
Epoch Time (s)               89.6581904985942
Total Train Time (s)         12716.578501935583
Epoch                        165
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:20:16.299597 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #165 | Epoch Duration: 86.28704524040222
2020-01-11 04:20:16.299852 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #165 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026359845
Z variance train             0.0047399085
KL Divergence                11.022781
KL Loss                      1.1022781
QF Loss                      522.68054
VF Loss                      207.54413
Policy Loss                  -1089.2797
Q Predictions Mean           1087.0911
Q Predictions Std            463.18015
Q Predictions Max            1503.7355
Q Predictions Min            -7.063956
V Predictions Mean           1085.9907
V Predictions Std            461.5964
V Predictions Max            1495.5496
V Predictions Min            -7.184633
Log Pis Mean                 -0.18497582
Log Pis Std                  2.184946
Log Pis Max                  9.368417
Log Pis Min                  -4.9701166
Policy mu Mean               0.040013682
Policy mu Std                0.90304536
Policy mu Max                3.215867
Policy mu Min                -2.8837793
Policy log std Mean          -0.4650028
Policy log std Std           0.22198531
Policy log std Max           0.0144735575
Policy log std Min           -1.2423892
Z mean eval                  0.03986969
Z variance eval              0.0047687152
total_rewards                [1505.53507481 3139.05762612 3118.09852668 3176.85793434 2142.17933098
 2172.23552779 3184.84529647 3111.84563553 1094.1449713  3176.13172824]
total_rewards_mean           2582.093165225288
total_rewards_std            753.8276015805877
total_rewards_max            3184.845296465343
total_rewards_min            1094.144971295793
Number of train steps total  167000
Number of env steps total    837000
Number of rollouts total     0
Train Time (s)               43.35423630196601
(Previous) Eval Time (s)     21.53860902506858
Sample Time (s)              21.479719023685902
Epoch Time (s)               86.3725643507205
Total Train Time (s)         12808.35942418268
Epoch                        166
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:21:48.082545 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #166 | Epoch Duration: 91.78252172470093
2020-01-11 04:21:48.082684 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #166 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039427735
Z variance train             0.0047722915
KL Divergence                10.960751
KL Loss                      1.096075
QF Loss                      483.27063
VF Loss                      231.4375
Policy Loss                  -1065.8757
Q Predictions Mean           1064.5154
Q Predictions Std            476.7044
Q Predictions Max            1476.4164
Q Predictions Min            -6.934747
V Predictions Mean           1057.0214
V Predictions Std            471.86368
V Predictions Max            1474.0331
V Predictions Min            0.5231734
Log Pis Mean                 -0.08293019
Log Pis Std                  2.110118
Log Pis Max                  11.565276
Log Pis Min                  -4.4039564
Policy mu Mean               0.010708665
Policy mu Std                0.9373979
Policy mu Max                3.8898084
Policy mu Min                -2.8123198
Policy log std Mean          -0.47344732
Policy log std Std           0.23718373
Policy log std Max           0.120042086
Policy log std Min           -1.243271
Z mean eval                  0.027015945
Z variance eval              0.0050636693
total_rewards                [2681.56874436  961.92700347 1780.11262763 2887.85092756 1502.42089898
 3184.57346305 2743.29932876 1583.76754749 1255.60957129 1788.41131507]
total_rewards_mean           2036.9541427654026
total_rewards_std            730.7896153182928
total_rewards_max            3184.5734630464026
total_rewards_min            961.9270034700306
Number of train steps total  168000
Number of env steps total    842000
Number of rollouts total     0
Train Time (s)               43.57351274881512
(Previous) Eval Time (s)     26.94834469584748
Sample Time (s)              22.69218669226393
Epoch Time (s)               93.21404413692653
Total Train Time (s)         12895.042409723625
Epoch                        167
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:23:14.768152 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #167 | Epoch Duration: 86.68530797958374
2020-01-11 04:23:14.768344 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #167 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026287366
Z variance train             0.0050605694
KL Divergence                10.937166
KL Loss                      1.0937166
QF Loss                      210.23337
VF Loss                      109.6709
Policy Loss                  -1051.5458
Q Predictions Mean           1051.319
Q Predictions Std            483.77786
Q Predictions Max            1497.9708
Q Predictions Min            -4.431429
V Predictions Mean           1053.8909
V Predictions Std            482.61984
V Predictions Max            1494.2341
V Predictions Min            0.8421779
Log Pis Mean                 -0.20271954
Log Pis Std                  2.1479726
Log Pis Max                  6.6177588
Log Pis Min                  -5.314507
Policy mu Mean               0.04869743
Policy mu Std                0.89098203
Policy mu Max                3.0599139
Policy mu Min                -2.7607672
Policy log std Mean          -0.46329507
Policy log std Std           0.22158253
Policy log std Max           0.052319944
Policy log std Min           -1.2312481
Z mean eval                  0.024118185
Z variance eval              0.004484955
total_rewards                [1184.78878329 3147.54185246 3190.76063366 1046.93327167 3174.39133195
 2312.07100902 3169.65056791  926.64143979 3203.39223917 2102.04348223]
total_rewards_mean           2345.8214611151607
total_rewards_std            925.5848959016145
total_rewards_max            3203.3922391699366
total_rewards_min            926.641439791063
Number of train steps total  169000
Number of env steps total    847000
Number of rollouts total     0
Train Time (s)               43.85123800393194
(Previous) Eval Time (s)     20.419355480000377
Sample Time (s)              21.3290260322392
Epoch Time (s)               85.59961951617151
Total Train Time (s)         12984.009724192787
Epoch                        168
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:24:43.736451 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #168 | Epoch Duration: 88.96799206733704
2020-01-11 04:24:43.736575 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #168 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023891816
Z variance train             0.004482082
KL Divergence                11.343405
KL Loss                      1.1343405
QF Loss                      896.87787
VF Loss                      102.042175
Policy Loss                  -1147.9158
Q Predictions Mean           1146.8878
Q Predictions Std            460.58362
Q Predictions Max            1523.4333
Q Predictions Min            -20.039011
V Predictions Mean           1147.1221
V Predictions Std            455.96115
V Predictions Max            1520.4669
V Predictions Min            -3.3744519
Log Pis Mean                 0.043202356
Log Pis Std                  2.227319
Log Pis Max                  10.433612
Log Pis Min                  -5.3390045
Policy mu Mean               0.075269066
Policy mu Std                0.98108804
Policy mu Max                3.2165244
Policy mu Min                -5.021955
Policy log std Mean          -0.48680827
Policy log std Std           0.24485102
Policy log std Max           0.14499933
Policy log std Min           -1.9475715
Z mean eval                  0.015636094
Z variance eval              0.0043116095
total_rewards                [3125.78480276 3058.13600804 1444.27795577 3016.6843264  3062.71923128
 3045.85254819 3028.86517411 3049.03978452 3020.34615051 3016.17186452]
total_rewards_mean           2886.7877846095407
total_rewards_std            481.82265954222186
total_rewards_max            3125.7848027640844
total_rewards_min            1444.2779557701117
Number of train steps total  170000
Number of env steps total    852000
Number of rollouts total     0
Train Time (s)               43.25531930522993
(Previous) Eval Time (s)     23.787465809844434
Sample Time (s)              21.729445522185415
Epoch Time (s)               88.77223063725978
Total Train Time (s)         13077.807430909947
Epoch                        169
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:26:17.547211 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #169 | Epoch Duration: 93.8104887008667
2020-01-11 04:26:17.547527 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #169 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014543961
Z variance train             0.0043038363
KL Divergence                11.450992
KL Loss                      1.1450992
QF Loss                      1244.1465
VF Loss                      238.31941
Policy Loss                  -1062.0813
Q Predictions Mean           1058.844
Q Predictions Std            506.64377
Q Predictions Max            1529.0067
Q Predictions Min            -7.4399805
V Predictions Mean           1071.1392
V Predictions Std            507.44855
V Predictions Max            1532.5834
V Predictions Min            -4.053999
Log Pis Mean                 0.005295597
Log Pis Std                  2.5259855
Log Pis Max                  13.126132
Log Pis Min                  -4.7994094
Policy mu Mean               0.0838235
Policy mu Std                0.9249484
Policy mu Max                3.5691488
Policy mu Min                -4.3954043
Policy log std Mean          -0.4941491
Policy log std Std           0.23915727
Policy log std Max           0.0506559
Policy log std Min           -1.738517
Z mean eval                  0.030645246
Z variance eval              0.0041733524
total_rewards                [2760.0882662  1441.55048735 3127.11022986 1163.40551226 1181.04318831
 2225.45626578  989.46332408 3148.74481835  749.08001179  977.82849568]
total_rewards_mean           1776.3770599658078
total_rewards_std            896.2003606362505
total_rewards_max            3148.7448183489523
total_rewards_min            749.0800117929714
Number of train steps total  171000
Number of env steps total    857000
Number of rollouts total     0
Train Time (s)               43.78364073485136
(Previous) Eval Time (s)     28.825447940733284
Sample Time (s)              21.560944576747715
Epoch Time (s)               94.17003325233236
Total Train Time (s)         13160.499977978878
Epoch                        170
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:27:40.237551 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #170 | Epoch Duration: 82.68975806236267
2020-01-11 04:27:40.237845 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #170 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030595506
Z variance train             0.0041582524
KL Divergence                11.492258
KL Loss                      1.1492258
QF Loss                      274.18216
VF Loss                      432.95462
Policy Loss                  -1133.1453
Q Predictions Mean           1138.5652
Q Predictions Std            445.3353
Q Predictions Max            1522.5809
Q Predictions Min            -0.75332433
V Predictions Mean           1143.6575
V Predictions Std            443.22708
V Predictions Max            1510.7693
V Predictions Min            2.2252846
Log Pis Mean                 0.27690327
Log Pis Std                  2.4308395
Log Pis Max                  11.555213
Log Pis Min                  -4.334718
Policy mu Mean               0.3081828
Policy mu Std                0.9743596
Policy mu Max                3.1612315
Policy mu Min                -3.1523962
Policy log std Mean          -0.5141817
Policy log std Std           0.22710939
Policy log std Max           0.02845788
Policy log std Min           -1.341676
Z mean eval                  0.013058448
Z variance eval              0.0035367205
total_rewards                [3147.47385682 3113.70930588 3199.06290336 3197.37945982 2146.75945946
 1032.22805703 3188.54215006 1846.83821076 1158.64750964 3175.57067589]
total_rewards_mean           2520.621158872514
total_rewards_std            848.6520165634158
total_rewards_max            3199.062903358105
total_rewards_min            1032.2280570293108
Number of train steps total  172000
Number of env steps total    862000
Number of rollouts total     0
Train Time (s)               43.390482229646295
(Previous) Eval Time (s)     17.34493371611461
Sample Time (s)              21.8650741269812
Epoch Time (s)               82.6004900727421
Total Train Time (s)         13251.218306967523
Epoch                        171
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:29:10.956725 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #171 | Epoch Duration: 90.71867728233337
2020-01-11 04:29:10.956866 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #171 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012409752
Z variance train             0.003535432
KL Divergence                12.015085
KL Loss                      1.2015085
QF Loss                      364.26056
VF Loss                      253.54362
Policy Loss                  -1084.0695
Q Predictions Mean           1081.48
Q Predictions Std            469.13684
Q Predictions Max            1503.3727
Q Predictions Min            -0.9523088
V Predictions Mean           1082.9105
V Predictions Std            466.93823
V Predictions Max            1495.9941
V Predictions Min            -0.09697199
Log Pis Mean                 -0.24915628
Log Pis Std                  2.2055554
Log Pis Max                  9.51352
Log Pis Min                  -5.5147243
Policy mu Mean               -0.013303153
Policy mu Std                0.87835824
Policy mu Max                2.9282556
Policy mu Min                -3.0398147
Policy log std Mean          -0.48611423
Policy log std Std           0.23459123
Policy log std Max           0.07568604
Policy log std Min           -1.2984104
Z mean eval                  0.017208667
Z variance eval              0.0034768
total_rewards                [2918.50019574 1164.23112875 1887.00712338 1061.99954084 3183.72295991
 1159.58062219 1054.69864401 3241.57621706 3219.88835604 3183.70630396]
total_rewards_mean           2207.4911091879544
total_rewards_std            971.3978593447333
total_rewards_max            3241.5762170597973
total_rewards_min            1054.698644014625
Number of train steps total  173000
Number of env steps total    867000
Number of rollouts total     0
Train Time (s)               43.01983445091173
(Previous) Eval Time (s)     25.462914237286896
Sample Time (s)              22.02461222652346
Epoch Time (s)               90.50736091472208
Total Train Time (s)         13338.699963479768
Epoch                        172
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:30:38.443317 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #172 | Epoch Duration: 87.48631310462952
2020-01-11 04:30:38.443582 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #172 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018216096
Z variance train             0.0034677298
KL Divergence                12.096325
KL Loss                      1.2096325
QF Loss                      327.59335
VF Loss                      576.98755
Policy Loss                  -1038.8632
Q Predictions Mean           1043.7788
Q Predictions Std            531.93713
Q Predictions Max            1505.8226
Q Predictions Min            -14.374373
V Predictions Mean           1057.9429
V Predictions Std            535.62177
V Predictions Max            1521.8615
V Predictions Min            -9.392996
Log Pis Mean                 -0.20911779
Log Pis Std                  2.2479146
Log Pis Max                  8.765524
Log Pis Min                  -4.098525
Policy mu Mean               0.008849405
Policy mu Std                0.86565596
Policy mu Max                2.7208817
Policy mu Min                -3.0189126
Policy log std Mean          -0.4834056
Policy log std Std           0.24315912
Policy log std Max           0.01140514
Policy log std Min           -1.2710018
Z mean eval                  0.020714875
Z variance eval              0.003638753
total_rewards                [3211.70181024 1705.26823133 2476.91751658 2198.7684742  3179.41058638
 2685.60158297 3250.22209027 3148.55903907 3212.40646897 3161.88342927]
total_rewards_mean           2823.0739229281626
total_rewards_std            510.9545031211403
total_rewards_max            3250.2220902738245
total_rewards_min            1705.26823132987
Number of train steps total  174000
Number of env steps total    872000
Number of rollouts total     0
Train Time (s)               43.60725907096639
(Previous) Eval Time (s)     22.44162109075114
Sample Time (s)              21.817240722477436
Epoch Time (s)               87.86612088419497
Total Train Time (s)         13432.698020420037
Epoch                        173
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:32:12.446705 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #173 | Epoch Duration: 94.00288963317871
2020-01-11 04:32:12.447002 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #173 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021336246
Z variance train             0.0036425483
KL Divergence                11.828598
KL Loss                      1.1828598
QF Loss                      206.82336
VF Loss                      73.84161
Policy Loss                  -1094.8876
Q Predictions Mean           1089.9973
Q Predictions Std            490.88452
Q Predictions Max            1537.169
Q Predictions Min            -2.156173
V Predictions Mean           1095.4993
V Predictions Std            490.04346
V Predictions Max            1535.0188
V Predictions Min            5.7632036
Log Pis Mean                 -0.29387105
Log Pis Std                  2.0265224
Log Pis Max                  8.2459955
Log Pis Min                  -4.502656
Policy mu Mean               0.053000554
Policy mu Std                0.90801907
Policy mu Max                2.965024
Policy mu Min                -2.975013
Policy log std Mean          -0.46925423
Policy log std Std           0.24170576
Policy log std Max           0.076946884
Policy log std Min           -1.248456
Z mean eval                  0.007852482
Z variance eval              0.0039916374
total_rewards                [1044.72034017 1383.07693665 2606.60359075 1047.92153869  994.92585872
 2549.49209363 3224.67159922  998.11435105 2098.43315538 2956.16614415]
total_rewards_mean           1890.4125608407103
total_rewards_std            847.7696792410626
total_rewards_max            3224.6715992225595
total_rewards_min            994.9258587216386
Number of train steps total  175000
Number of env steps total    877000
Number of rollouts total     0
Train Time (s)               43.7068099710159
(Previous) Eval Time (s)     28.578150670975447
Sample Time (s)              20.129422947764397
Epoch Time (s)               92.41438358975574
Total Train Time (s)         13516.742764104623
Epoch                        174
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:33:36.491882 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #174 | Epoch Duration: 84.04465627670288
2020-01-11 04:33:36.492101 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #174 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007866008
Z variance train             0.003990405
KL Divergence                11.500436
KL Loss                      1.1500436
QF Loss                      142.03903
VF Loss                      164.68661
Policy Loss                  -1102.7045
Q Predictions Mean           1099.3424
Q Predictions Std            479.01013
Q Predictions Max            1517.7239
Q Predictions Min            -10.295535
V Predictions Mean           1094.7654
V Predictions Std            477.32727
V Predictions Max            1508.7552
V Predictions Min            -18.192732
Log Pis Mean                 -0.3714335
Log Pis Std                  2.0703137
Log Pis Max                  8.945351
Log Pis Min                  -6.482244
Policy mu Mean               0.03080436
Policy mu Std                0.8671009
Policy mu Max                2.063836
Policy mu Min                -3.2586467
Policy log std Mean          -0.46548748
Policy log std Std           0.22229257
Policy log std Max           0.09284818
Policy log std Min           -1.218815
Z mean eval                  0.023612123
Z variance eval              0.0054831
total_rewards                [1577.58169652 1008.78717437 3253.5974917  2229.31567766 1115.78454077
 2168.22149789 1086.21068209 2507.22700384 1031.2345398  1026.34957542]
total_rewards_mean           1700.4309880067872
total_rewards_std            753.428415865902
total_rewards_max            3253.5974916988507
total_rewards_min            1008.7871743686751
Number of train steps total  176000
Number of env steps total    882000
Number of rollouts total     0
Train Time (s)               43.82617819402367
(Previous) Eval Time (s)     20.208196403924376
Sample Time (s)              21.59503490384668
Epoch Time (s)               85.62940950179473
Total Train Time (s)         13599.347300205845
Epoch                        175
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:34:59.101810 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #175 | Epoch Duration: 82.60955548286438
2020-01-11 04:34:59.102017 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #175 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023129825
Z variance train             0.0054880534
KL Divergence                10.7192745
KL Loss                      1.0719274
QF Loss                      231.17484
VF Loss                      165.10077
Policy Loss                  -1072.91
Q Predictions Mean           1072.2332
Q Predictions Std            536.7359
Q Predictions Max            1534.0034
Q Predictions Min            1.9795264
V Predictions Mean           1068.3064
V Predictions Std            537.11774
V Predictions Max            1545.0883
V Predictions Min            -10.627943
Log Pis Mean                 -0.16179407
Log Pis Std                  2.179909
Log Pis Max                  9.260807
Log Pis Min                  -4.2287726
Policy mu Mean               0.026999759
Policy mu Std                0.88678306
Policy mu Max                3.9645977
Policy mu Min                -3.3151896
Policy log std Mean          -0.48884383
Policy log std Std           0.2261824
Policy log std Max           0.0946933
Policy log std Min           -1.2309823
Z mean eval                  0.0156162055
Z variance eval              0.0042719515
total_rewards                [ 971.75480581 1356.14336931  925.4000174  2693.4622268  2454.12309809
  934.33558655 1732.14241977 2796.44269481 1734.91638364 1619.872923  ]
total_rewards_mean           1721.8593525191168
total_rewards_std            677.980480773207
total_rewards_max            2796.4426948128594
total_rewards_min            925.4000174028434
Number of train steps total  177000
Number of env steps total    887000
Number of rollouts total     0
Train Time (s)               43.330885482952
(Previous) Eval Time (s)     17.188085650093853
Sample Time (s)              20.40018577547744
Epoch Time (s)               80.91915690852329
Total Train Time (s)         13681.247109923977
Epoch                        176
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:36:21.006807 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #176 | Epoch Duration: 81.90460515022278
2020-01-11 04:36:21.007088 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #176 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01610306
Z variance train             0.0042729587
KL Divergence                11.284621
KL Loss                      1.1284622
QF Loss                      293.89377
VF Loss                      186.26671
Policy Loss                  -1125.1768
Q Predictions Mean           1120.7163
Q Predictions Std            452.11914
Q Predictions Max            1520.8728
Q Predictions Min            1.2297016
V Predictions Mean           1117.9076
V Predictions Std            452.53458
V Predictions Max            1521.9567
V Predictions Min            -22.748331
Log Pis Mean                 -0.12447047
Log Pis Std                  2.2142167
Log Pis Max                  10.982488
Log Pis Min                  -3.7226944
Policy mu Mean               0.058991324
Policy mu Std                0.89047605
Policy mu Max                2.7437801
Policy mu Min                -3.2125125
Policy log std Mean          -0.4845197
Policy log std Std           0.23294346
Policy log std Max           0.118828475
Policy log std Min           -1.3921282
Z mean eval                  0.008061169
Z variance eval              0.004962139
total_rewards                [1222.68431296 2971.92891349 3017.1004842  2994.4353217  3044.13485248
 1136.83206444 2955.83694959 1760.6555648   996.9036901  2943.29520963]
total_rewards_mean           2304.3807363401734
total_rewards_std            857.2035193076131
total_rewards_max            3044.134852481675
total_rewards_min            996.903690098098
Number of train steps total  178000
Number of env steps total    892000
Number of rollouts total     0
Train Time (s)               42.930238298140466
(Previous) Eval Time (s)     18.173276083078235
Sample Time (s)              21.944722237996757
Epoch Time (s)               83.04823661921546
Total Train Time (s)         13770.60696981661
Epoch                        177
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:37:50.368116 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #177 | Epoch Duration: 89.36081528663635
2020-01-11 04:37:50.368295 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #177 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.008578257
Z variance train             0.004975738
KL Divergence                11.064215
KL Loss                      1.1064215
QF Loss                      146.25293
VF Loss                      200.29224
Policy Loss                  -1062.342
Q Predictions Mean           1064.7589
Q Predictions Std            519.4655
Q Predictions Max            1543.0243
Q Predictions Min            -18.403236
V Predictions Mean           1071.8573
V Predictions Std            519.17236
V Predictions Max            1543.7783
V Predictions Min            -2.5204515
Log Pis Mean                 -0.24810629
Log Pis Std                  2.213848
Log Pis Max                  10.103688
Log Pis Min                  -5.280247
Policy mu Mean               0.085883476
Policy mu Std                0.8883425
Policy mu Max                2.8922594
Policy mu Min                -3.2993615
Policy log std Mean          -0.47545943
Policy log std Std           0.23181254
Policy log std Max           0.16240802
Policy log std Min           -1.3227761
Z mean eval                  0.012163478
Z variance eval              0.004259481
total_rewards                [3130.07723091 3122.24027254 1067.84421348 1020.9239847  1025.37838272
 1391.56357795 3144.19846225 1658.61728522 2502.35888798 2506.8075543 ]
total_rewards_mean           2057.0009852058993
total_rewards_std            871.0076757991526
total_rewards_max            3144.1984622508207
total_rewards_min            1020.9239847032986
Number of train steps total  179000
Number of env steps total    897000
Number of rollouts total     0
Train Time (s)               43.487708563916385
(Previous) Eval Time (s)     24.4856426990591
Sample Time (s)              22.026134246960282
Epoch Time (s)               89.99948550993577
Total Train Time (s)         13856.164809009526
Epoch                        178
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:39:15.928850 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #178 | Epoch Duration: 85.5604145526886
2020-01-11 04:39:15.929020 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #178 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01284094
Z variance train             0.0042548673
KL Divergence                11.348459
KL Loss                      1.134846
QF Loss                      380.40094
VF Loss                      301.6054
Policy Loss                  -1099.4648
Q Predictions Mean           1096.0176
Q Predictions Std            489.17828
Q Predictions Max            1520.08
Q Predictions Min            -27.285255
V Predictions Mean           1105.7095
V Predictions Std            490.09476
V Predictions Max            1534.8398
V Predictions Min            -0.2583469
Log Pis Mean                 -0.49332714
Log Pis Std                  1.9054433
Log Pis Max                  6.5354166
Log Pis Min                  -4.848339
Policy mu Mean               0.09331287
Policy mu Std                0.82252616
Policy mu Max                2.6220076
Policy mu Min                -2.7139792
Policy log std Mean          -0.5206929
Policy log std Std           0.24127641
Policy log std Max           0.10641742
Policy log std Min           -1.4891624
Z mean eval                  0.01844802
Z variance eval              0.0038338914
total_rewards                [3282.10574655 1135.73111024 1955.08335952 1043.98679005 3214.07935795
  965.94372299  891.06236569 2385.84629845 1113.60857162 1092.9087823 ]
total_rewards_mean           1708.0356105378742
total_rewards_std            893.570810286251
total_rewards_max            3282.1057465524864
total_rewards_min            891.0623656884121
Number of train steps total  180000
Number of env steps total    902000
Number of rollouts total     0
Train Time (s)               43.7229773318395
(Previous) Eval Time (s)     20.046329407021403
Sample Time (s)              22.0456804134883
Epoch Time (s)               85.8149871523492
Total Train Time (s)         13938.645479021594
Epoch                        179
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:40:38.412320 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #179 | Epoch Duration: 82.4831805229187
2020-01-11 04:40:38.412446 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #179 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018081207
Z variance train             0.0038323023
KL Divergence                11.567029
KL Loss                      1.1567029
QF Loss                      287.73474
VF Loss                      377.75394
Policy Loss                  -1161.5773
Q Predictions Mean           1156.7075
Q Predictions Std            463.01758
Q Predictions Max            1564.6418
Q Predictions Min            -4.8180165
V Predictions Mean           1160.2646
V Predictions Std            462.8382
V Predictions Max            1553.8677
V Predictions Min            -5.5320635
Log Pis Mean                 -0.0892014
Log Pis Std                  2.5720031
Log Pis Max                  15.41733
Log Pis Min                  -6.3668528
Policy mu Mean               0.055445954
Policy mu Std                0.8990188
Policy mu Max                4.2386985
Policy mu Min                -3.4472651
Policy log std Mean          -0.48154044
Policy log std Std           0.23496893
Policy log std Max           0.11988944
Policy log std Min           -1.5242023
Z mean eval                  0.015217182
Z variance eval              0.0038263933
total_rewards                [1095.73706989 1675.73917354  993.01576864 2570.58996392 1193.66198768
 2218.50205921 1757.49694324 1771.17928942 2973.57139006 1322.01819275]
total_rewards_mean           1757.151183835663
total_rewards_std            623.6395254450773
total_rewards_max            2973.571390059141
total_rewards_min            993.0157686365063
Number of train steps total  181000
Number of env steps total    907000
Number of rollouts total     0
Train Time (s)               44.5986869209446
(Previous) Eval Time (s)     16.7142835278064
Sample Time (s)              21.85690538212657
Epoch Time (s)               83.16987583087757
Total Train Time (s)         14023.978694025893
Epoch                        180
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:42:03.747244 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #180 | Epoch Duration: 85.33470487594604
2020-01-11 04:42:03.747369 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #180 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013710159
Z variance train             0.0038258457
KL Divergence                11.584442
KL Loss                      1.1584443
QF Loss                      183.6096
VF Loss                      137.22066
Policy Loss                  -1121.3563
Q Predictions Mean           1120.07
Q Predictions Std            505.84454
Q Predictions Max            1545.6417
Q Predictions Min            -10.713402
V Predictions Mean           1115.0332
V Predictions Std            504.03598
V Predictions Max            1529.99
V Predictions Min            -20.189768
Log Pis Mean                 -0.2506926
Log Pis Std                  2.1635647
Log Pis Max                  7.6053705
Log Pis Min                  -7.5949736
Policy mu Mean               0.08864232
Policy mu Std                0.87353927
Policy mu Max                2.5727518
Policy mu Min                -2.8332033
Policy log std Mean          -0.4822086
Policy log std Std           0.22961049
Policy log std Max           0.11129475
Policy log std Min           -1.1586103
Z mean eval                  0.018315133
Z variance eval              0.003053553
total_rewards                [1058.16242881  910.2546114  2088.2718819  1085.07562321  935.94699334
 1734.77129715 2388.35205601 1597.07332087  969.81407618 1021.02269478]
total_rewards_mean           1378.8744983637946
total_rewards_std            509.59931031775795
total_rewards_max            2388.35205600637
total_rewards_min            910.2546113998287
Number of train steps total  182000
Number of env steps total    912000
Number of rollouts total     0
Train Time (s)               41.70687668211758
(Previous) Eval Time (s)     18.878882273100317
Sample Time (s)              21.9269639714621
Epoch Time (s)               82.51272292668
Total Train Time (s)         14100.69206480356
Epoch                        181
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:43:20.466648 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #181 | Epoch Duration: 76.71914005279541
2020-01-11 04:43:20.466934 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #181 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0179437
Z variance train             0.0030525927
KL Divergence                12.063272
KL Loss                      1.2063273
QF Loss                      204.14589
VF Loss                      178.51295
Policy Loss                  -1178.1229
Q Predictions Mean           1182.6672
Q Predictions Std            449.97635
Q Predictions Max            1565.0376
Q Predictions Min            3.5983942
V Predictions Mean           1174.6311
V Predictions Std            449.25137
V Predictions Max            1564.6451
V Predictions Min            -2.594541
Log Pis Mean                 -0.28508085
Log Pis Std                  1.9126573
Log Pis Max                  8.253434
Log Pis Min                  -5.194576
Policy mu Mean               -0.042875484
Policy mu Std                0.8750198
Policy mu Max                2.634834
Policy mu Min                -3.5194235
Policy log std Mean          -0.4791832
Policy log std Std           0.23538543
Policy log std Max           0.16652054
Policy log std Min           -1.2328839
Z mean eval                  0.021576975
Z variance eval              0.0026662447
total_rewards                [1164.05854673 1144.56135666 1074.39030983 1033.64155712 3234.54708097
 1036.03539615 1229.23570495 1023.88465469 1204.91526216 1066.65859187]
total_rewards_mean           1321.1928461109796
total_rewards_std            641.6293903613356
total_rewards_max            3234.5470809689455
total_rewards_min            1023.8846546858971
Number of train steps total  183000
Number of env steps total    917000
Number of rollouts total     0
Train Time (s)               44.60288444068283
(Previous) Eval Time (s)     13.085050599649549
Sample Time (s)              22.345412254333496
Epoch Time (s)               80.03334729466587
Total Train Time (s)         14180.685672479682
Epoch                        182
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:44:40.461924 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #182 | Epoch Duration: 79.99477648735046
2020-01-11 04:44:40.462099 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #182 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021763753
Z variance train             0.002666529
KL Divergence                12.354012
KL Loss                      1.2354012
QF Loss                      218.41199
VF Loss                      102.912186
Policy Loss                  -1082.4524
Q Predictions Mean           1080.0957
Q Predictions Std            511.06354
Q Predictions Max            1555.6293
Q Predictions Min            -9.754769
V Predictions Mean           1084.7258
V Predictions Std            509.3415
V Predictions Max            1554.2402
V Predictions Min            1.2363029
Log Pis Mean                 -0.38709256
Log Pis Std                  1.9988143
Log Pis Max                  7.817296
Log Pis Min                  -5.870285
Policy mu Mean               0.061376408
Policy mu Std                0.824286
Policy mu Max                2.0639904
Policy mu Min                -3.2623286
Policy log std Mean          -0.467122
Policy log std Std           0.2309971
Policy log std Max           0.09779668
Policy log std Min           -1.2350397
Z mean eval                  0.02388385
Z variance eval              0.0029803265
total_rewards                [2943.20639055 1033.25907688  983.3953163  1175.3838799   941.80150237
 2075.18330002  889.28503044 1465.53987913 3134.83446819 1008.151584  ]
total_rewards_mean           1565.0040427768665
total_rewards_std            810.0538754917463
total_rewards_max            3134.8344681931526
total_rewards_min            889.2850304380007
Number of train steps total  184000
Number of env steps total    922000
Number of rollouts total     0
Train Time (s)               44.16107143368572
(Previous) Eval Time (s)     13.046249131672084
Sample Time (s)              21.695287214126438
Epoch Time (s)               78.90260777948424
Total Train Time (s)         14261.876244002953
Epoch                        183
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:46:01.657510 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #183 | Epoch Duration: 81.19526219367981
2020-01-11 04:46:01.657714 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #183 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023284368
Z variance train             0.0029778106
KL Divergence                12.191868
KL Loss                      1.2191868
QF Loss                      209.82837
VF Loss                      251.14795
Policy Loss                  -1185.7664
Q Predictions Mean           1179.299
Q Predictions Std            416.56506
Q Predictions Max            1510.3729
Q Predictions Min            -1.5522921
V Predictions Mean           1177.7196
V Predictions Std            408.5584
V Predictions Max            1510.5948
V Predictions Min            0.57140833
Log Pis Mean                 -0.23376283
Log Pis Std                  2.1275492
Log Pis Max                  8.563822
Log Pis Min                  -6.036002
Policy mu Mean               0.014221775
Policy mu Std                0.93928665
Policy mu Max                2.3994505
Policy mu Min                -4.065844
Policy log std Mean          -0.49950647
Policy log std Std           0.23068333
Policy log std Max           0.1673387
Policy log std Min           -1.7543554
Z mean eval                  0.018822346
Z variance eval              0.0028909459
total_rewards                [3201.74093112 3164.78594765 3147.68710295 3204.79263515 3204.34204614
 3162.9614454  1193.33188367 3199.98101377 3199.33700149 3188.08187624]
total_rewards_mean           2986.704188357563
total_rewards_std            598.1054885890104
total_rewards_max            3204.792635145841
total_rewards_min            1193.331883674306
Number of train steps total  185000
Number of env steps total    927000
Number of rollouts total     0
Train Time (s)               44.22911007422954
(Previous) Eval Time (s)     15.338651848956943
Sample Time (s)              22.036988372448832
Epoch Time (s)               81.60475029563531
Total Train Time (s)         14360.080268810969
Epoch                        184
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:47:39.867264 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #184 | Epoch Duration: 98.20936417579651
2020-01-11 04:47:39.867547 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #184 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019824352
Z variance train             0.0028969024
KL Divergence                12.379459
KL Loss                      1.2379459
QF Loss                      1425.1226
VF Loss                      224.60078
Policy Loss                  -1174.5667
Q Predictions Mean           1172.304
Q Predictions Std            470.29803
Q Predictions Max            1544.208
Q Predictions Min            1.124646
V Predictions Mean           1169.3042
V Predictions Std            470.09576
V Predictions Max            1558.3655
V Predictions Min            -7.369547
Log Pis Mean                 -0.34580493
Log Pis Std                  2.154456
Log Pis Max                  7.454268
Log Pis Min                  -4.9795647
Policy mu Mean               -0.058515567
Policy mu Std                0.86249113
Policy mu Max                2.7206547
Policy mu Min                -3.2532654
Policy log std Mean          -0.49587512
Policy log std Std           0.23324896
Policy log std Max           0.14051604
Policy log std Min           -1.2554978
Z mean eval                  0.014856255
Z variance eval              0.0027972218
total_rewards                [1604.48102985 2078.04545566 1059.08276217 1102.20138769 1196.33668759
 1587.51036725 1009.85244863 1037.43899794 2758.96744963 1861.38226102]
total_rewards_mean           1529.5298847431561
total_rewards_std            543.9354182532
total_rewards_max            2758.967449633564
total_rewards_min            1009.8524486297723
Number of train steps total  186000
Number of env steps total    932000
Number of rollouts total     0
Train Time (s)               44.28684279229492
(Previous) Eval Time (s)     31.942998162005097
Sample Time (s)              22.27276735054329
Epoch Time (s)               98.5026083048433
Total Train Time (s)         14440.533394036349
Epoch                        185
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:49:00.321066 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #185 | Epoch Duration: 80.45331263542175
2020-01-11 04:49:00.321218 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #185 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014976008
Z variance train             0.0027954425
KL Divergence                12.482615
KL Loss                      1.2482616
QF Loss                      241.52145
VF Loss                      133.63995
Policy Loss                  -1119.1564
Q Predictions Mean           1117.6073
Q Predictions Std            489.3103
Q Predictions Max            1539.7072
Q Predictions Min            -23.991625
V Predictions Mean           1119.1819
V Predictions Std            486.5596
V Predictions Max            1537.9445
V Predictions Min            -24.175064
Log Pis Mean                 -0.05996167
Log Pis Std                  2.1691263
Log Pis Max                  9.936602
Log Pis Min                  -4.6767015
Policy mu Mean               0.12531225
Policy mu Std                0.90681964
Policy mu Max                4.153851
Policy mu Min                -3.1144218
Policy log std Mean          -0.47706082
Policy log std Std           0.24123324
Policy log std Max           0.1577161
Policy log std Min           -1.4028671
Z mean eval                  0.013264294
Z variance eval              0.003415869
total_rewards                [ 956.68938747 1075.88063671 3245.79065602 2895.00844096 1644.0900361
 1224.05250342 1517.52041554 1600.36030691 2954.57442537 2280.7471989 ]
total_rewards_mean           1939.471400739109
total_rewards_std            798.1345227072584
total_rewards_max            3245.7906560195943
total_rewards_min            956.6893874673672
Number of train steps total  187000
Number of env steps total    937000
Number of rollouts total     0
Train Time (s)               44.78130257735029
(Previous) Eval Time (s)     13.89348960109055
Sample Time (s)              21.777604229282588
Epoch Time (s)               80.45239640772343
Total Train Time (s)         14526.664993757382
Epoch                        186
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:50:26.454965 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #186 | Epoch Duration: 86.13361501693726
2020-01-11 04:50:26.455140 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #186 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01300182
Z variance train             0.0034137801
KL Divergence                12.095702
KL Loss                      1.2095703
QF Loss                      259.96173
VF Loss                      126.72494
Policy Loss                  -1089.4034
Q Predictions Mean           1089.995
Q Predictions Std            494.9882
Q Predictions Max            1544.1311
Q Predictions Min            -28.255194
V Predictions Mean           1088.8125
V Predictions Std            494.65598
V Predictions Max            1529.3588
V Predictions Min            -10.446766
Log Pis Mean                 -0.086189196
Log Pis Std                  2.4946735
Log Pis Max                  10.306862
Log Pis Min                  -6.4503655
Policy mu Mean               0.09457541
Policy mu Std                0.93092656
Policy mu Max                2.8907032
Policy mu Min                -2.8351297
Policy log std Mean          -0.4709599
Policy log std Std           0.22873373
Policy log std Max           0.12300217
Policy log std Min           -1.844729
Z mean eval                  0.018170072
Z variance eval              0.0034401126
total_rewards                [ 724.10221798 2053.90887828 2545.09004639 2317.75041409  892.14694226
 1051.35500813 1552.6351962   986.4829806  1212.17820422 1360.95662911]
total_rewards_mean           1469.6606517276575
total_rewards_std            599.9974087098893
total_rewards_max            2545.0900463875746
total_rewards_min            724.10221798427
Number of train steps total  188000
Number of env steps total    942000
Number of rollouts total     0
Train Time (s)               44.66001005098224
(Previous) Eval Time (s)     19.57447471981868
Sample Time (s)              21.76623470708728
Epoch Time (s)               86.0007194778882
Total Train Time (s)         14608.446604315192
Epoch                        187
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:51:48.238213 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #187 | Epoch Duration: 81.78294801712036
2020-01-11 04:51:48.238344 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #187 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01794054
Z variance train             0.0034479103
KL Divergence                12.116485
KL Loss                      1.2116485
QF Loss                      503.6012
VF Loss                      331.7635
Policy Loss                  -1140.3617
Q Predictions Mean           1141.526
Q Predictions Std            493.33124
Q Predictions Max            1561.189
Q Predictions Min            -2.9676867
V Predictions Mean           1143.7874
V Predictions Std            494.14148
V Predictions Max            1564.3298
V Predictions Min            4.8664274
Log Pis Mean                 -0.3192205
Log Pis Std                  1.7811723
Log Pis Max                  5.535537
Log Pis Min                  -4.951517
Policy mu Mean               0.106736906
Policy mu Std                0.82758784
Policy mu Max                2.4357798
Policy mu Min                -2.9895103
Policy log std Mean          -0.4749298
Policy log std Std           0.23320298
Policy log std Max           0.10712379
Policy log std Min           -1.38518
Z mean eval                  0.0123237055
Z variance eval              0.0035206913
total_rewards                [1014.52222151 1599.85720263 1157.02144662 1612.75713093 2151.02873441
 3180.27966498 1580.99243157 1052.77144908 1053.38205866 1704.06399539]
total_rewards_mean           1610.6676335784512
total_rewards_std            628.3626626250451
total_rewards_max            3180.279664981538
total_rewards_min            1014.5222215136326
Number of train steps total  189000
Number of env steps total    947000
Number of rollouts total     0
Train Time (s)               43.34727043332532
(Previous) Eval Time (s)     15.356479268986732
Sample Time (s)              21.975702182389796
Epoch Time (s)               80.67945188470185
Total Train Time (s)         14690.017347175162
Epoch                        188
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:53:09.811957 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #188 | Epoch Duration: 81.57350659370422
2020-01-11 04:53:09.812126 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #188 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012244986
Z variance train             0.0035206291
KL Divergence                11.947423
KL Loss                      1.1947423
QF Loss                      846.3314
VF Loss                      113.198616
Policy Loss                  -1138.8221
Q Predictions Mean           1135.5826
Q Predictions Std            498.95584
Q Predictions Max            1572.6163
Q Predictions Min            -7.687351
V Predictions Mean           1142.5176
V Predictions Std            498.74225
V Predictions Max            1578.9606
V Predictions Min            -5.8928385
Log Pis Mean                 -0.036196634
Log Pis Std                  2.303803
Log Pis Max                  9.02129
Log Pis Min                  -5.090041
Policy mu Mean               0.068963915
Policy mu Std                0.9510611
Policy mu Max                3.7669408
Policy mu Min                -3.1495874
Policy log std Mean          -0.50202256
Policy log std Std           0.23017001
Policy log std Max           0.15092197
Policy log std Min           -1.2717228
Z mean eval                  0.014792332
Z variance eval              0.0039329873
total_rewards                [3131.53053346  952.07569272 1061.90974798 2806.39508822  993.59807331
 1235.92562042 1498.22218677 1093.96262348 1002.2871679  2006.56965309]
total_rewards_mean           1578.2476387341617
total_rewards_std            761.2395005262347
total_rewards_max            3131.5305334611294
total_rewards_min            952.0756927163127
Number of train steps total  190000
Number of env steps total    952000
Number of rollouts total     0
Train Time (s)               44.75147570669651
(Previous) Eval Time (s)     16.250286477152258
Sample Time (s)              22.09293058188632
Epoch Time (s)               83.09469276573509
Total Train Time (s)         14773.16927336296
Epoch                        189
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:54:32.965500 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #189 | Epoch Duration: 83.15325975418091
2020-01-11 04:54:32.965626 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #189 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0145598175
Z variance train             0.0039320285
KL Divergence                11.863512
KL Loss                      1.1863512
QF Loss                      406.28186
VF Loss                      153.41101
Policy Loss                  -1120.3728
Q Predictions Mean           1115.8406
Q Predictions Std            508.53967
Q Predictions Max            1538.678
Q Predictions Min            -8.319982
V Predictions Mean           1113.6245
V Predictions Std            506.01938
V Predictions Max            1522.3909
V Predictions Min            -3.2242422
Log Pis Mean                 -0.2777219
Log Pis Std                  1.9796468
Log Pis Max                  8.295145
Log Pis Min                  -4.1157637
Policy mu Mean               0.1428327
Policy mu Std                0.8699403
Policy mu Max                3.2704368
Policy mu Min                -2.864975
Policy log std Mean          -0.4834118
Policy log std Std           0.23122028
Policy log std Max           -0.02258405
Policy log std Min           -1.3316936
Z mean eval                  0.01945493
Z variance eval              0.004057315
total_rewards                [1523.8649238  1510.94419471 1590.70699056 1579.45115157 1719.53800325
 1292.36500475 1502.67053544 2467.0889286   996.71462547 1194.28358864]
total_rewards_mean           1537.7627946806115
total_rewards_std            370.71624095654437
total_rewards_max            2467.088928604978
total_rewards_min            996.7146254729024
Number of train steps total  191000
Number of env steps total    957000
Number of rollouts total     0
Train Time (s)               43.21584547823295
(Previous) Eval Time (s)     16.308607785962522
Sample Time (s)              21.795715249609202
Epoch Time (s)               81.32016851380467
Total Train Time (s)         14855.072379310615
Epoch                        190
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:55:54.869619 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #190 | Epoch Duration: 81.90389895439148
2020-01-11 04:55:54.869736 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #190 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019652748
Z variance train             0.0040552355
KL Divergence                11.559088
KL Loss                      1.1559088
QF Loss                      183.75993
VF Loss                      88.105415
Policy Loss                  -1150.985
Q Predictions Mean           1150.1697
Q Predictions Std            481.97183
Q Predictions Max            1543.3997
Q Predictions Min            -0.66412634
V Predictions Mean           1153.8438
V Predictions Std            481.58493
V Predictions Max            1546.1389
V Predictions Min            -2.9243274
Log Pis Mean                 -0.332484
Log Pis Std                  2.0494928
Log Pis Max                  9.960827
Log Pis Min                  -3.9416966
Policy mu Mean               0.03881358
Policy mu Std                0.84852135
Policy mu Max                2.6081614
Policy mu Min                -3.488217
Policy log std Mean          -0.4872789
Policy log std Std           0.21771762
Policy log std Max           0.048890233
Policy log std Min           -1.3443143
Z mean eval                  0.023752669
Z variance eval              0.0042185234
total_rewards                [1150.277622   2560.82616395 1003.36341348 1711.25317017 1028.87855448
 2687.56959166 1303.40102624 1043.63233258 1841.88115111 3285.61661355]
total_rewards_mean           1761.6699639239243
total_rewards_std            777.0927203657716
total_rewards_max            3285.6166135543594
total_rewards_min            1003.3634134838072
Number of train steps total  192000
Number of env steps total    962000
Number of rollouts total     0
Train Time (s)               42.8692779308185
(Previous) Eval Time (s)     16.892097516916692
Sample Time (s)              21.755071406252682
Epoch Time (s)               81.51644685398787
Total Train Time (s)         14937.674719954375
Epoch                        191
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:57:17.473990 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #191 | Epoch Duration: 82.6041648387909
2020-01-11 04:57:17.474112 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #191 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024168978
Z variance train             0.004213297
KL Divergence                11.451375
KL Loss                      1.1451375
QF Loss                      174.57013
VF Loss                      111.90666
Policy Loss                  -1180.775
Q Predictions Mean           1178.435
Q Predictions Std            469.0828
Q Predictions Max            1572.9298
Q Predictions Min            -2.801859
V Predictions Mean           1188.6722
V Predictions Std            471.5542
V Predictions Max            1584.8398
V Predictions Min            4.2536607
Log Pis Mean                 -0.41272938
Log Pis Std                  1.9040238
Log Pis Max                  7.0212135
Log Pis Min                  -4.7679358
Policy mu Mean               0.036122803
Policy mu Std                0.81874794
Policy mu Max                2.739126
Policy mu Min                -2.9731245
Policy log std Mean          -0.5242738
Policy log std Std           0.21842456
Policy log std Max           -0.023830295
Policy log std Min           -1.399243
Z mean eval                  0.017603707
Z variance eval              0.004857211
total_rewards                [3070.48950085 2437.95397953 2244.42935821  996.50781406 3085.0317298
 1636.49957542 3044.0421019  3103.27150161 1555.32250674 3113.82582125]
total_rewards_mean           2428.737388935024
total_rewards_std            749.7560012781107
total_rewards_max            3113.8258212489104
total_rewards_min            996.5078140591431
Number of train steps total  193000
Number of env steps total    967000
Number of rollouts total     0
Train Time (s)               43.68292181007564
(Previous) Eval Time (s)     17.979583289008588
Sample Time (s)              21.750415809452534
Epoch Time (s)               83.41292090853676
Total Train Time (s)         15026.840525049716
Epoch                        192
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 04:58:46.643999 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #192 | Epoch Duration: 89.1697449684143
2020-01-11 04:58:46.644217 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #192 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017088164
Z variance train             0.0048592766
KL Divergence                11.020395
KL Loss                      1.1020396
QF Loss                      339.77258
VF Loss                      102.657104
Policy Loss                  -1127.846
Q Predictions Mean           1126.2327
Q Predictions Std            489.11993
Q Predictions Max            1544.7977
Q Predictions Min            0.007358074
V Predictions Mean           1130.7838
V Predictions Std            491.4053
V Predictions Max            1554.1394
V Predictions Min            3.5224512
Log Pis Mean                 -0.4935164
Log Pis Std                  1.8496336
Log Pis Max                  6.388857
Log Pis Min                  -5.263729
Policy mu Mean               -0.048658594
Policy mu Std                0.82730305
Policy mu Max                2.3163548
Policy mu Min                -2.9031472
Policy log std Mean          -0.48999175
Policy log std Std           0.21342637
Policy log std Max           0.042591333
Policy log std Min           -1.2588029
Z mean eval                  0.030934233
Z variance eval              0.004388688
total_rewards                [1014.51416566 3132.98684585 1024.51743421 3194.53754548 1013.77843607
 1802.71949666 1620.66555353 3237.81168252 1007.94320149  681.05820312]
total_rewards_mean           1773.0532564595499
total_rewards_std            976.2012380188479
total_rewards_max            3237.811682517938
total_rewards_min            681.0582031182636
Number of train steps total  194000
Number of env steps total    972000
Number of rollouts total     0
Train Time (s)               43.72480677906424
(Previous) Eval Time (s)     23.736151784658432
Sample Time (s)              19.89468353614211
Epoch Time (s)               87.35564209986478
Total Train Time (s)         15106.811188797466
Epoch                        193
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:00:06.617536 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #193 | Epoch Duration: 79.9731605052948
2020-01-11 05:00:06.617738 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #193 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03077724
Z variance train             0.004388277
KL Divergence                11.21661
KL Loss                      1.1216611
QF Loss                      226.13716
VF Loss                      147.39603
Policy Loss                  -1164.9373
Q Predictions Mean           1159.2208
Q Predictions Std            449.64404
Q Predictions Max            1528.6093
Q Predictions Min            -30.08054
V Predictions Mean           1158.9036
V Predictions Std            447.59277
V Predictions Max            1529.1702
V Predictions Min            -5.73038
Log Pis Mean                 -0.19999383
Log Pis Std                  2.38144
Log Pis Max                  10.279375
Log Pis Min                  -4.5973263
Policy mu Mean               -0.059345108
Policy mu Std                0.9100361
Policy mu Max                2.2799993
Policy mu Min                -3.6335988
Policy log std Mean          -0.51016915
Policy log std Std           0.21693766
Policy log std Max           0.046572387
Policy log std Min           -1.2088747
Z mean eval                  0.030039797
Z variance eval              0.0043648616
total_rewards                [1028.80651856 2622.65025197 1009.16834978 1110.29494826 1020.86381438
 1271.50474484 2602.3145714  1033.55037403 2909.04823849 1027.00384053]
total_rewards_mean           1563.5205652228838
total_rewards_std            758.8412573461159
total_rewards_max            2909.0482384901493
total_rewards_min            1009.1683497816089
Number of train steps total  195000
Number of env steps total    977000
Number of rollouts total     0
Train Time (s)               43.22048602858558
(Previous) Eval Time (s)     16.35344455484301
Sample Time (s)              21.466133874375373
Epoch Time (s)               81.04006445780396
Total Train Time (s)         15186.128562559374
Epoch                        194
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:01:25.938113 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #194 | Epoch Duration: 79.32021880149841
2020-01-11 05:01:25.938277 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #194 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030827206
Z variance train             0.0043564783
KL Divergence                11.19804
KL Loss                      1.119804
QF Loss                      511.02786
VF Loss                      257.58478
Policy Loss                  -1207.7919
Q Predictions Mean           1209.2124
Q Predictions Std            409.76434
Q Predictions Max            1548.1124
Q Predictions Min            -2.2403982
V Predictions Mean           1214.606
V Predictions Std            408.86664
V Predictions Max            1545.1633
V Predictions Min            -0.5067636
Log Pis Mean                 -0.24150309
Log Pis Std                  2.005313
Log Pis Max                  7.4469476
Log Pis Min                  -5.3604274
Policy mu Mean               0.03634503
Policy mu Std                0.8529565
Policy mu Max                3.0121446
Policy mu Min                -3.2231958
Policy log std Mean          -0.52735674
Policy log std Std           0.21264991
Policy log std Max           0.13919857
Policy log std Min           -1.333417
Z mean eval                  0.018892512
Z variance eval              0.003317495
total_rewards                [1892.03346179 3162.40296962 1153.58484302 1998.70266326 3187.4329717
 1858.53337584 3045.28065079 3201.22467779 3150.19941314 3179.76369744]
total_rewards_mean           2582.915872437862
total_rewards_std            732.2371132401922
total_rewards_max            3201.2246777873584
total_rewards_min            1153.5848430174544
Number of train steps total  196000
Number of env steps total    982000
Number of rollouts total     0
Train Time (s)               44.47256170492619
(Previous) Eval Time (s)     14.633364179171622
Sample Time (s)              19.91438814206049
Epoch Time (s)               79.0203140261583
Total Train Time (s)         15277.606904549524
Epoch                        195
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:02:57.419083 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #195 | Epoch Duration: 91.48067927360535
2020-01-11 05:02:57.419215 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #195 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01880539
Z variance train             0.0033175282
KL Divergence                11.841234
KL Loss                      1.1841234
QF Loss                      116.21336
VF Loss                      64.979546
Policy Loss                  -1207.2327
Q Predictions Mean           1206.9762
Q Predictions Std            433.21234
Q Predictions Max            1546.6102
Q Predictions Min            -2.9335935
V Predictions Mean           1208.364
V Predictions Std            431.42078
V Predictions Max            1544.0197
V Predictions Min            2.4136372
Log Pis Mean                 -0.32060227
Log Pis Std                  2.0599244
Log Pis Max                  10.917427
Log Pis Min                  -5.373156
Policy mu Mean               0.063571684
Policy mu Std                0.8373196
Policy mu Max                2.3331144
Policy mu Min                -2.9403534
Policy log std Mean          -0.4769946
Policy log std Std           0.20384109
Policy log std Max           0.097341925
Policy log std Min           -1.1007557
Z mean eval                  0.015268816
Z variance eval              0.0031830494
total_rewards                [3158.99907803 3086.83205382 3095.01165532 3106.08400032 1947.91448727
 3090.88116541 3123.81228007 2256.52091427 3187.03714257 2709.03506764]
total_rewards_mean           2876.212784472092
total_rewards_std            412.64345667578385
total_rewards_max            3187.037142570857
total_rewards_min            1947.9144872712134
Number of train steps total  197000
Number of env steps total    987000
Number of rollouts total     0
Train Time (s)               44.32374408701435
(Previous) Eval Time (s)     27.093496945220977
Sample Time (s)              22.318190350197256
Epoch Time (s)               93.73543138243258
Total Train Time (s)         15373.713131201454
Epoch                        196
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:04:33.526247 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #196 | Epoch Duration: 96.10693073272705
2020-01-11 05:04:33.526366 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #196 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015274443
Z variance train             0.0031846142
KL Divergence                11.987745
KL Loss                      1.1987746
QF Loss                      160.3
VF Loss                      105.534195
Policy Loss                  -1177.3151
Q Predictions Mean           1174.1355
Q Predictions Std            479.29935
Q Predictions Max            1547.5903
Q Predictions Min            -5.524525
V Predictions Mean           1180.5984
V Predictions Std            479.18362
V Predictions Max            1553.1918
V Predictions Min            4.304989
Log Pis Mean                 -0.31184652
Log Pis Std                  2.1220825
Log Pis Max                  8.662821
Log Pis Min                  -5.078973
Policy mu Mean               -0.0021701083
Policy mu Std                0.89131415
Policy mu Max                2.6295798
Policy mu Min                -2.9684515
Policy log std Mean          -0.4804374
Policy log std Std           0.21590127
Policy log std Max           0.090103924
Policy log std Min           -1.3737757
Z mean eval                  0.037805535
Z variance eval              0.0032305538
total_rewards                [3153.93733319 3130.94917666 3122.27412745 1621.19204782 2406.06881729
 1170.65600769 3151.1349692  2905.27414081 3083.98610243 2435.74231434]
total_rewards_mean           2618.121503687874
total_rewards_std            674.9150851571559
total_rewards_max            3153.9373331861457
total_rewards_min            1170.6560076899111
Number of train steps total  198000
Number of env steps total    992000
Number of rollouts total     0
Train Time (s)               43.67423610622063
(Previous) Eval Time (s)     29.464749246370047
Sample Time (s)              22.036765900906175
Epoch Time (s)               95.17575125349686
Total Train Time (s)         15467.20967237465
Epoch                        197
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:06:07.028895 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #197 | Epoch Duration: 93.50243830680847
2020-01-11 05:06:07.029020 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #197 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03691311
Z variance train             0.0032326956
KL Divergence                11.966248
KL Loss                      1.1966248
QF Loss                      159.69989
VF Loss                      150.87875
Policy Loss                  -1142.667
Q Predictions Mean           1145.2605
Q Predictions Std            468.63693
Q Predictions Max            1552.6437
Q Predictions Min            -7.055111
V Predictions Mean           1145.8833
V Predictions Std            468.238
V Predictions Max            1546.6464
V Predictions Min            -12.393055
Log Pis Mean                 -0.07745637
Log Pis Std                  2.2151976
Log Pis Max                  7.110168
Log Pis Min                  -5.2693157
Policy mu Mean               -0.048183363
Policy mu Std                0.92293465
Policy mu Max                2.4614213
Policy mu Min                -3.009604
Policy log std Mean          -0.5061874
Policy log std Std           0.21675076
Policy log std Max           0.043223143
Policy log std Min           -1.4402633
Z mean eval                  0.018889781
Z variance eval              0.0035749222
total_rewards                [1288.09600515 1035.07673633 1608.02440838 1063.70006217 1034.40986044
 1016.71821803 1040.87560634 3270.79320895 2400.98456704 3322.61017616]
total_rewards_mean           1708.1288848997458
total_rewards_std            892.2122968368233
total_rewards_max            3322.610176163913
total_rewards_min            1016.7182180271977
Number of train steps total  199000
Number of env steps total    997000
Number of rollouts total     0
Train Time (s)               44.275767508894205
(Previous) Eval Time (s)     27.79119976889342
Sample Time (s)              22.41465205932036
Epoch Time (s)               94.48161933710799
Total Train Time (s)         15551.385866529308
Epoch                        198
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:07:31.204484 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #198 | Epoch Duration: 84.17535471916199
2020-01-11 05:07:31.204658 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #198 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01858059
Z variance train             0.0035775006
KL Divergence                11.776364
KL Loss                      1.1776365
QF Loss                      4715.275
VF Loss                      104.21139
Policy Loss                  -1178.1321
Q Predictions Mean           1181.7913
Q Predictions Std            458.94037
Q Predictions Max            1553.0901
Q Predictions Min            3.2410142
V Predictions Mean           1173.3811
V Predictions Std            457.5343
V Predictions Max            1554.1816
V Predictions Min            -3.0221329
Log Pis Mean                 -0.3109426
Log Pis Std                  2.0714126
Log Pis Max                  9.377509
Log Pis Min                  -5.6987057
Policy mu Mean               0.05807909
Policy mu Std                0.8693893
Policy mu Max                3.4828112
Policy mu Min                -3.3001754
Policy log std Mean          -0.46214628
Policy log std Std           0.21543227
Policy log std Max           0.1103428
Policy log std Min           -1.6595414
Z mean eval                  0.031943996
Z variance eval              0.003342526
total_rewards                [1744.03436812 1541.42969003 3214.88497051 3187.93937359 2418.45656737
 3230.50923855 2557.80332709 1876.46789893 1999.75523599 1314.001163  ]
total_rewards_mean           2308.5281833177123
total_rewards_std            685.3694086177038
total_rewards_max            3230.509238549829
total_rewards_min            1314.0011630008569
Number of train steps total  200000
Number of env steps total    1002000
Number of rollouts total     0
Train Time (s)               43.026417300105095
(Previous) Eval Time (s)     17.484661316964775
Sample Time (s)              20.92107463441789
Epoch Time (s)               81.43215325148776
Total Train Time (s)         15639.192854267545
Epoch                        199
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:08:59.013032 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #199 | Epoch Duration: 87.80824160575867
2020-01-11 05:08:59.013172 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #199 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031612895
Z variance train             0.0033456583
KL Divergence                11.985376
KL Loss                      1.1985377
QF Loss                      490.61633
VF Loss                      609.83075
Policy Loss                  -1176.8396
Q Predictions Mean           1168.1704
Q Predictions Std            469.75723
Q Predictions Max            1565.7117
Q Predictions Min            4.5447016
V Predictions Mean           1163.5347
V Predictions Std            470.28757
V Predictions Max            1558.0125
V Predictions Min            -8.2154875
Log Pis Mean                 0.07433174
Log Pis Std                  2.4951713
Log Pis Max                  15.345135
Log Pis Min                  -5.0008087
Policy mu Mean               0.15613176
Policy mu Std                0.94914556
Policy mu Max                3.125331
Policy mu Min                -4.7276073
Policy log std Mean          -0.48707262
Policy log std Std           0.22827569
Policy log std Max           0.03204027
Policy log std Min           -1.5318503
Z mean eval                  0.028957814
Z variance eval              0.0045722546
total_rewards                [2289.58442023 1219.97060041 1051.47645927 1966.58057771 1037.80620792
 3223.94429554 1857.04351884 1572.71389711 1548.43042244 1343.7006299 ]
total_rewards_mean           1711.1251029360071
total_rewards_std            634.0459093895104
total_rewards_max            3223.9442955371524
total_rewards_min            1037.806207919064
Number of train steps total  201000
Number of env steps total    1007000
Number of rollouts total     0
Train Time (s)               43.72235556598753
(Previous) Eval Time (s)     23.860535346902907
Sample Time (s)              22.1971800676547
Epoch Time (s)               89.78007098054513
Total Train Time (s)         15721.378439617809
Epoch                        200
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:10:21.200883 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #200 | Epoch Duration: 82.18759822845459
2020-01-11 05:10:21.201056 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #200 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026658272
Z variance train             0.0045854645
KL Divergence                11.132504
KL Loss                      1.1132505
QF Loss                      287.7243
VF Loss                      128.31944
Policy Loss                  -1203.6218
Q Predictions Mean           1208.1453
Q Predictions Std            443.2779
Q Predictions Max            1578.1218
Q Predictions Min            1.1391437
V Predictions Mean           1207.7312
V Predictions Std            441.79202
V Predictions Max            1577.5599
V Predictions Min            2.2531903
Log Pis Mean                 -0.23777655
Log Pis Std                  1.9852902
Log Pis Max                  9.9319935
Log Pis Min                  -6.2281713
Policy mu Mean               0.048800796
Policy mu Std                0.903878
Policy mu Max                3.0797632
Policy mu Min                -3.1373215
Policy log std Mean          -0.50063664
Policy log std Std           0.20643412
Policy log std Max           0.04947847
Policy log std Min           -1.3090392
Z mean eval                  0.04147912
Z variance eval              0.0046531567
total_rewards                [1352.32083118 1031.56260369 1532.59103164 1459.67675692 1064.23624715
 1026.08609416 1027.36086223 1163.8106993  1669.90072765  885.10797441]
total_rewards_mean           1221.265382832643
total_rewards_std            249.97097864937447
total_rewards_max            1669.9007276545228
total_rewards_min            885.1079744067829
Number of train steps total  202000
Number of env steps total    1012000
Number of rollouts total     0
Train Time (s)               43.841583122033626
(Previous) Eval Time (s)     16.267810771241784
Sample Time (s)              22.15436092764139
Epoch Time (s)               82.2637548209168
Total Train Time (s)         15799.451940609142
Epoch                        201
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:11:39.276907 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #201 | Epoch Duration: 78.0757200717926
2020-01-11 05:11:39.277039 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #201 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04057731
Z variance train             0.0046540075
KL Divergence                10.980609
KL Loss                      1.098061
QF Loss                      209.03696
VF Loss                      181.91298
Policy Loss                  -1195.9683
Q Predictions Mean           1194.5522
Q Predictions Std            469.5361
Q Predictions Max            1566.3656
Q Predictions Min            -0.68142396
V Predictions Mean           1196.106
V Predictions Std            466.6617
V Predictions Max            1568.0188
V Predictions Min            -10.39262
Log Pis Mean                 -0.16485138
Log Pis Std                  1.8498018
Log Pis Max                  9.082382
Log Pis Min                  -5.5508556
Policy mu Mean               0.055429116
Policy mu Std                0.8909905
Policy mu Max                2.9042976
Policy mu Min                -2.8309193
Policy log std Mean          -0.47978488
Policy log std Std           0.21849164
Policy log std Max           0.07043147
Policy log std Min           -1.2991652
Z mean eval                  0.02347915
Z variance eval              0.0042143213
total_rewards                [1557.76022788 1535.33485655 1854.54415476 2149.93634257 1100.72245691
 1002.10837706  970.35135917 1077.44370503 1019.30968683 1028.68416453]
total_rewards_mean           1329.6195331267513
total_rewards_std            397.7449549470346
total_rewards_max            2149.936342565506
total_rewards_min            970.3513591664812
Number of train steps total  203000
Number of env steps total    1017000
Number of rollouts total     0
Train Time (s)               44.00782562699169
(Previous) Eval Time (s)     12.07953845988959
Sample Time (s)              21.512146807275712
Epoch Time (s)               77.59951089415699
Total Train Time (s)         15878.441208427772
Epoch                        202
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:12:58.267742 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #202 | Epoch Duration: 78.99047827720642
2020-01-11 05:12:58.267863 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #202 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024330173
Z variance train             0.004209565
KL Divergence                11.339241
KL Loss                      1.1339241
QF Loss                      207.93909
VF Loss                      581.8319
Policy Loss                  -1226.3855
Q Predictions Mean           1226.4498
Q Predictions Std            436.96265
Q Predictions Max            1581.9491
Q Predictions Min            -3.8557236
V Predictions Mean           1232.8586
V Predictions Std            433.1854
V Predictions Max            1590.5388
V Predictions Min            -9.252555
Log Pis Mean                 -0.12906411
Log Pis Std                  2.2935445
Log Pis Max                  11.519691
Log Pis Min                  -5.325606
Policy mu Mean               0.119625725
Policy mu Std                0.923766
Policy mu Max                3.6026149
Policy mu Min                -3.1539154
Policy log std Mean          -0.4796261
Policy log std Std           0.21721484
Policy log std Max           0.0047985315
Policy log std Min           -1.3977109
Z mean eval                  0.018380482
Z variance eval              0.0046613924
total_rewards                [1070.92148438 1278.40172444 1247.29806059 1129.63072684 1048.65206807
 1061.27523186 1051.38510228 1068.13453857 2880.37213288 1004.12054449]
total_rewards_mean           1284.019161438895
total_rewards_std            538.7995686163625
total_rewards_max            2880.37213287502
total_rewards_min            1004.120544494251
Number of train steps total  204000
Number of env steps total    1022000
Number of rollouts total     0
Train Time (s)               43.21215734817088
(Previous) Eval Time (s)     13.470395782031119
Sample Time (s)              21.61673050466925
Epoch Time (s)               78.29928363487124
Total Train Time (s)         15956.051635635551
Epoch                        203
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:14:15.880861 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #203 | Epoch Duration: 77.61288714408875
2020-01-11 05:14:15.881038 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #203 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018458635
Z variance train             0.0046680197
KL Divergence                11.013174
KL Loss                      1.1013174
QF Loss                      181.38187
VF Loss                      129.94176
Policy Loss                  -1212.4121
Q Predictions Mean           1207.332
Q Predictions Std            418.16565
Q Predictions Max            1559.5063
Q Predictions Min            -9.338366
V Predictions Mean           1205.0774
V Predictions Std            416.774
V Predictions Max            1555.1323
V Predictions Min            -4.7526636
Log Pis Mean                 -0.17436723
Log Pis Std                  2.0257962
Log Pis Max                  9.416391
Log Pis Min                  -4.5181484
Policy mu Mean               0.031987626
Policy mu Std                0.8959437
Policy mu Max                3.5785985
Policy mu Min                -2.9355702
Policy log std Mean          -0.5045988
Policy log std Std           0.20060357
Policy log std Max           0.0615353
Policy log std Min           -1.2974241
Z mean eval                  0.020120282
Z variance eval              0.0039657764
total_rewards                [1038.96917979 3138.71521092 3178.33774375 1393.88278181 3140.92589808
 3184.6649236  3205.42825093 1449.77644309 1062.15029838 1374.89040856]
total_rewards_mean           2216.7741138893066
total_rewards_std            961.1176049749415
total_rewards_max            3205.428250925404
total_rewards_min            1038.9691797862265
Number of train steps total  205000
Number of env steps total    1027000
Number of rollouts total     0
Train Time (s)               44.123685251921415
(Previous) Eval Time (s)     12.783756975084543
Sample Time (s)              21.571922816336155
Epoch Time (s)               78.47936504334211
Total Train Time (s)         16043.893831887748
Epoch                        204
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:15:43.726833 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #204 | Epoch Duration: 87.84564423561096
2020-01-11 05:15:43.727044 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #204 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019332632
Z variance train             0.0039645163
KL Divergence                11.424913
KL Loss                      1.1424913
QF Loss                      595.2398
VF Loss                      77.12708
Policy Loss                  -1242.2723
Q Predictions Mean           1238.7748
Q Predictions Std            400.23523
Q Predictions Max            1570.4504
Q Predictions Min            0.04084149
V Predictions Mean           1239.0015
V Predictions Std            392.9341
V Predictions Max            1565.1633
V Predictions Min            -0.18332112
Log Pis Mean                 -0.32106483
Log Pis Std                  1.932136
Log Pis Max                  7.9944525
Log Pis Min                  -5.671812
Policy mu Mean               0.11506987
Policy mu Std                0.89588195
Policy mu Max                3.3580978
Policy mu Min                -2.9386742
Policy log std Mean          -0.51568574
Policy log std Std           0.21202154
Policy log std Max           0.020687878
Policy log std Min           -1.933675
Z mean eval                  0.013162589
Z variance eval              0.0042747473
total_rewards                [1305.69244421 3220.71990675 1656.04425051 1060.73335263 1691.80423769
 1035.97937891  994.02238654 1203.45673089 1752.60085389  987.87059829]
total_rewards_mean           1490.8924140324227
total_rewards_std            643.214343106019
total_rewards_max            3220.719906752568
total_rewards_min            987.8705982883532
Number of train steps total  206000
Number of env steps total    1032000
Number of rollouts total     0
Train Time (s)               43.91707030730322
(Previous) Eval Time (s)     22.149782299995422
Sample Time (s)              21.65162673732266
Epoch Time (s)               87.7184793446213
Total Train Time (s)         16123.45713596791
Epoch                        205
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:17:03.292066 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #205 | Epoch Duration: 79.56486392021179
2020-01-11 05:17:03.292231 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #205 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013437783
Z variance train             0.0042627365
KL Divergence                11.244234
KL Loss                      1.1244234
QF Loss                      4597.5576
VF Loss                      554.21967
Policy Loss                  -1232.3114
Q Predictions Mean           1224.6781
Q Predictions Std            448.26996
Q Predictions Max            1609.0258
Q Predictions Min            -21.094643
V Predictions Mean           1223.3618
V Predictions Std            440.68237
V Predictions Max            1597.477
V Predictions Min            4.035065
Log Pis Mean                 -0.065366894
Log Pis Std                  2.096345
Log Pis Max                  9.062389
Log Pis Min                  -3.8664384
Policy mu Mean               0.047420915
Policy mu Std                0.91932386
Policy mu Max                3.4951289
Policy mu Min                -3.0914586
Policy log std Mean          -0.47667602
Policy log std Std           0.22031602
Policy log std Max           0.1358741
Policy log std Min           -1.7201365
Z mean eval                  0.011017143
Z variance eval              0.0046155276
total_rewards                [3225.3089987  3207.85139927 3173.40198225 1200.31449353 1328.70510471
 3278.4084962  3262.32099137 3242.73653698 1005.86434189 3201.39717375]
total_rewards_mean           2612.630951866441
total_rewards_std            942.2294739299584
total_rewards_max            3278.408496202156
total_rewards_min            1005.8643418900135
Number of train steps total  207000
Number of env steps total    1037000
Number of rollouts total     0
Train Time (s)               43.29207930481061
(Previous) Eval Time (s)     13.995899065863341
Sample Time (s)              22.055954307783395
Epoch Time (s)               79.34393267845735
Total Train Time (s)         16214.05802274542
Epoch                        206
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:18:33.895858 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #206 | Epoch Duration: 90.60349225997925
2020-01-11 05:18:33.896047 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #206 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010653345
Z variance train             0.0046108374
KL Divergence                10.994381
KL Loss                      1.0994381
QF Loss                      613.5414
VF Loss                      523.9135
Policy Loss                  -1183.0046
Q Predictions Mean           1180.727
Q Predictions Std            437.3267
Q Predictions Max            1566.9421
Q Predictions Min            -4.4582777
V Predictions Mean           1199.456
V Predictions Std            440.20377
V Predictions Max            1588.6908
V Predictions Min            -9.802548
Log Pis Mean                 -0.32740325
Log Pis Std                  2.2523813
Log Pis Max                  10.259196
Log Pis Min                  -5.814165
Policy mu Mean               -0.034147188
Policy mu Std                0.86815596
Policy mu Max                3.265385
Policy mu Min                -3.1049173
Policy log std Mean          -0.49357215
Policy log std Std           0.2172976
Policy log std Max           0.00394392
Policy log std Min           -1.3151133
Z mean eval                  0.0207407
Z variance eval              0.0045259795
total_rewards                [2992.24768926 1519.71466903 1622.69119858 1445.8255648  3214.39721682
  993.78856174 3200.90046974 1157.46316111 3205.37137139 3224.90955793]
total_rewards_mean           2257.730946039794
total_rewards_std            926.9856631384127
total_rewards_max            3224.9095579347468
total_rewards_min            993.7885617426978
Number of train steps total  208000
Number of env steps total    1042000
Number of rollouts total     0
Train Time (s)               43.476711708121
(Previous) Eval Time (s)     25.25520218303427
Sample Time (s)              22.419580991845578
Epoch Time (s)               91.15149488300085
Total Train Time (s)         16302.588849086314
Epoch                        207
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:20:02.430848 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #207 | Epoch Duration: 88.5346040725708
2020-01-11 05:20:02.431102 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #207 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021272648
Z variance train             0.0045259055
KL Divergence                11.054062
KL Loss                      1.1054062
QF Loss                      252.14691
VF Loss                      119.7411
Policy Loss                  -1244.3379
Q Predictions Mean           1242.429
Q Predictions Std            427.32126
Q Predictions Max            1585.5199
Q Predictions Min            -13.043429
V Predictions Mean           1245.302
V Predictions Std            427.34567
V Predictions Max            1591.8114
V Predictions Min            -1.3537312
Log Pis Mean                 0.0013493933
Log Pis Std                  2.203819
Log Pis Max                  8.874849
Log Pis Min                  -3.9881532
Policy mu Mean               0.14359191
Policy mu Std                0.9057685
Policy mu Max                2.793816
Policy mu Min                -2.8370028
Policy log std Mean          -0.5127837
Policy log std Std           0.21746047
Policy log std Max           0.01102373
Policy log std Min           -1.8552974
Z mean eval                  0.026287239
Z variance eval              0.004796763
total_rewards                [2230.49108912  933.96854301 1130.9277201  2452.94459343 1607.77094727
 3267.97407808 1060.05128407  900.00774175 1252.61010463 3248.65299282]
total_rewards_mean           1808.5399094286197
total_rewards_std            880.6951447857138
total_rewards_max            3267.974078082491
total_rewards_min            900.007741750749
Number of train steps total  209000
Number of env steps total    1047000
Number of rollouts total     0
Train Time (s)               43.95492256293073
(Previous) Eval Time (s)     22.63806111505255
Sample Time (s)              21.97846307279542
Epoch Time (s)               88.5714467507787
Total Train Time (s)         16387.231902874075
Epoch                        208
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:21:27.073909 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #208 | Epoch Duration: 84.64265298843384
2020-01-11 05:21:27.074042 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #208 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026514659
Z variance train             0.004787128
KL Divergence                10.9328165
KL Loss                      1.0932816
QF Loss                      143.832
VF Loss                      125.515076
Policy Loss                  -1222.9792
Q Predictions Mean           1221.0631
Q Predictions Std            450.54102
Q Predictions Max            1582.0052
Q Predictions Min            -3.6244812
V Predictions Mean           1215.3768
V Predictions Std            447.15533
V Predictions Max            1573.4495
V Predictions Min            2.9636307
Log Pis Mean                 -0.3984178
Log Pis Std                  1.6746689
Log Pis Max                  6.940127
Log Pis Min                  -6.2209096
Policy mu Mean               0.065750234
Policy mu Std                0.81234974
Policy mu Max                2.7850757
Policy mu Min                -2.8216305
Policy log std Mean          -0.48334607
Policy log std Std           0.21591058
Policy log std Max           0.15468282
Policy log std Min           -1.223254
Z mean eval                  0.013780375
Z variance eval              0.0047280197
total_rewards                [1112.09778916 1898.23535011 3234.42325147 3164.23687377 3231.95087868
 1030.07750331 3155.83927662 2930.21678352 2496.55448909 3181.63946525]
total_rewards_mean           2543.5271660983653
total_rewards_std            838.2311936673422
total_rewards_max            3234.423251465355
total_rewards_min            1030.0775033127752
Number of train steps total  210000
Number of env steps total    1052000
Number of rollouts total     0
Train Time (s)               44.199336491990834
(Previous) Eval Time (s)     18.709034299943596
Sample Time (s)              22.219856807030737
Epoch Time (s)               85.12822759896517
Total Train Time (s)         16478.53773483541
Epoch                        209
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:22:58.383373 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #209 | Epoch Duration: 91.30921387672424
2020-01-11 05:22:58.383552 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #209 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014496347
Z variance train             0.0047162306
KL Divergence                10.987686
KL Loss                      1.0987686
QF Loss                      197.58606
VF Loss                      259.37756
Policy Loss                  -1227.335
Q Predictions Mean           1226.1031
Q Predictions Std            447.35062
Q Predictions Max            1608.8416
Q Predictions Min            0.81295633
V Predictions Mean           1215.0481
V Predictions Std            443.20193
V Predictions Max            1595.7218
V Predictions Min            0.6433186
Log Pis Mean                 -0.3986276
Log Pis Std                  1.7736162
Log Pis Max                  6.683016
Log Pis Min                  -3.2863667
Policy mu Mean               0.06543896
Policy mu Std                0.83387196
Policy mu Max                2.5711076
Policy mu Min                -2.9776824
Policy log std Mean          -0.46502078
Policy log std Std           0.22470072
Policy log std Max           0.094572246
Policy log std Min           -1.3438892
Z mean eval                  0.01862069
Z variance eval              0.005458097
total_rewards                [2139.31067028 1025.54276584 3203.5286814  1382.18169851 1224.3408481
 1265.62643594 3118.60806031 1724.42342043 1553.72836446 1514.74436254]
total_rewards_mean           1815.2035307799656
total_rewards_std            732.1521191675139
total_rewards_max            3203.528681402849
total_rewards_min            1025.5427658367332
Number of train steps total  211000
Number of env steps total    1057000
Number of rollouts total     0
Train Time (s)               42.88761508092284
(Previous) Eval Time (s)     24.889772252179682
Sample Time (s)              20.891570174135268
Epoch Time (s)               88.66895750723779
Total Train Time (s)         16559.709030996542
Epoch                        210
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:24:19.557904 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #210 | Epoch Duration: 81.17419743537903
2020-01-11 05:24:19.558125 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #210 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020090763
Z variance train             0.005459784
KL Divergence                10.582567
KL Loss                      1.0582567
QF Loss                      278.22974
VF Loss                      92.76041
Policy Loss                  -1255.0143
Q Predictions Mean           1256.0471
Q Predictions Std            394.86432
Q Predictions Max            1579.2244
Q Predictions Min            -0.7591829
V Predictions Mean           1250.4343
V Predictions Std            393.4803
V Predictions Max            1574.848
V Predictions Min            2.1999784
Log Pis Mean                 -0.15971972
Log Pis Std                  2.1295793
Log Pis Max                  9.816036
Log Pis Min                  -10.242204
Policy mu Mean               0.0055589504
Policy mu Std                0.91996163
Policy mu Max                2.6990588
Policy mu Min                -3.0017998
Policy log std Mean          -0.48929417
Policy log std Std           0.21571329
Policy log std Max           0.079152584
Policy log std Min           -1.6536367
Z mean eval                  0.013240695
Z variance eval              0.0059935763
total_rewards                [2681.16094501 1051.47184651 2340.23787531 1040.26959016 1025.6108358
  900.36544118 1053.8853053  1245.38488488 2745.3629493  1212.21960727]
total_rewards_mean           1529.5969280727227
total_rewards_std            706.1947981023212
total_rewards_max            2745.362949302705
total_rewards_min            900.365441180988
Number of train steps total  212000
Number of env steps total    1062000
Number of rollouts total     0
Train Time (s)               44.074296122882515
(Previous) Eval Time (s)     17.394773373845965
Sample Time (s)              21.625037863384932
Epoch Time (s)               83.09410736011341
Total Train Time (s)         16641.004640232306
Epoch                        211
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:25:40.854926 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #211 | Epoch Duration: 81.2965841293335
2020-01-11 05:25:40.855110 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #211 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013394972
Z variance train             0.0059928414
KL Divergence                10.408925
KL Loss                      1.0408925
QF Loss                      307.7921
VF Loss                      129.95319
Policy Loss                  -1242.0403
Q Predictions Mean           1244.1262
Q Predictions Std            460.59988
Q Predictions Max            1589.2463
Q Predictions Min            -11.859721
V Predictions Mean           1246.4268
V Predictions Std            457.38644
V Predictions Max            1586.4567
V Predictions Min            3.8095038
Log Pis Mean                 -0.2789173
Log Pis Std                  2.2655787
Log Pis Max                  9.382054
Log Pis Min                  -5.0268903
Policy mu Mean               0.000526129
Policy mu Std                0.89063704
Policy mu Max                3.1980343
Policy mu Min                -3.6932864
Policy log std Mean          -0.49529552
Policy log std Std           0.23672125
Policy log std Max           0.15016925
Policy log std Min           -1.8460829
Z mean eval                  0.009532723
Z variance eval              0.006816038
total_rewards                [ 997.56875451  976.62037589 2500.36482693  962.41302953 1036.79442691
 1051.47682878 1957.87876941 1054.12279361 1038.36959098 1603.58239867]
total_rewards_mean           1317.919179522099
total_rewards_std            503.2477034088993
total_rewards_max            2500.364826930595
total_rewards_min            962.4130295321983
Number of train steps total  213000
Number of env steps total    1067000
Number of rollouts total     0
Train Time (s)               44.528609931934625
(Previous) Eval Time (s)     15.597021826077253
Sample Time (s)              21.929850053973496
Epoch Time (s)               82.05548181198537
Total Train Time (s)         16720.034200145397
Epoch                        212
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:26:59.890998 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #212 | Epoch Duration: 79.03571915626526
2020-01-11 05:26:59.891304 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #212 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00977906
Z variance train             0.0068232557
KL Divergence                10.046473
KL Loss                      1.0046473
QF Loss                      102.34595
VF Loss                      131.47852
Policy Loss                  -1242.3745
Q Predictions Mean           1240.0375
Q Predictions Std            450.95114
Q Predictions Max            1613.1658
Q Predictions Min            -2.1711
V Predictions Mean           1235.2251
V Predictions Std            447.76926
V Predictions Max            1605.9148
V Predictions Min            -3.5055964
Log Pis Mean                 -0.45618686
Log Pis Std                  1.7575493
Log Pis Max                  4.7952633
Log Pis Min                  -5.2717032
Policy mu Mean               0.11332355
Policy mu Std                0.8090279
Policy mu Max                2.3190985
Policy mu Min                -3.1718838
Policy log std Mean          -0.4667257
Policy log std Std           0.19556215
Policy log std Max           0.059729576
Policy log std Min           -1.2480444
Z mean eval                  0.021234611
Z variance eval              0.007109215
total_rewards                [2093.97767411 2189.86885962 2039.95028569 1027.32618932 2139.83866335
 1272.21102261  997.5217878  1880.56657215 1776.85622534 1777.0502365 ]
total_rewards_mean           1719.5167516477504
total_rewards_std            432.8766714150192
total_rewards_max            2189.8688596179445
total_rewards_min            997.521787796541
Number of train steps total  214000
Number of env steps total    1072000
Number of rollouts total     0
Train Time (s)               43.889228329993784
(Previous) Eval Time (s)     12.577024376951158
Sample Time (s)              22.038533338345587
Epoch Time (s)               78.50478604529053
Total Train Time (s)         16801.723585878965
Epoch                        213
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:28:21.582525 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #213 | Epoch Duration: 81.690993309021
2020-01-11 05:28:21.582705 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #213 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021415848
Z variance train             0.007114268
KL Divergence                10.00509
KL Loss                      1.000509
QF Loss                      146.65913
VF Loss                      110.557076
Policy Loss                  -1274.8776
Q Predictions Mean           1273.7551
Q Predictions Std            389.20612
Q Predictions Max            1593.735
Q Predictions Min            -3.2181568
V Predictions Mean           1275.7594
V Predictions Std            390.9784
V Predictions Max            1595.9935
V Predictions Min            -9.558791
Log Pis Mean                 -0.25808248
Log Pis Std                  2.1057534
Log Pis Max                  11.298462
Log Pis Min                  -4.1839585
Policy mu Mean               0.1178919
Policy mu Std                0.88083225
Policy mu Max                2.8796358
Policy mu Min                -3.561486
Policy log std Mean          -0.47139478
Policy log std Std           0.20807
Policy log std Max           0.17634511
Policy log std Min           -1.2019062
Z mean eval                  0.022089245
Z variance eval              0.007369312
total_rewards                [2811.0518717  1860.0943774  3220.71826699 1553.57708568 2417.99268752
 3231.51026881 3208.91565354 2623.30857386 3184.97022854 1856.24317847]
total_rewards_mean           2596.838219251855
total_rewards_std            614.0694715524661
total_rewards_max            3231.51026881158
total_rewards_min            1553.5770856789197
Number of train steps total  215000
Number of env steps total    1077000
Number of rollouts total     0
Train Time (s)               44.38263331307098
(Previous) Eval Time (s)     15.762999833095819
Sample Time (s)              21.76617023907602
Epoch Time (s)               81.91180338524282
Total Train Time (s)         16894.635582163
Epoch                        214
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:29:54.495319 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #214 | Epoch Duration: 92.91248393058777
2020-01-11 05:29:54.495449 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #214 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021877665
Z variance train             0.007367936
KL Divergence                9.859629
KL Loss                      0.98596287
QF Loss                      649.3598
VF Loss                      671.5485
Policy Loss                  -1272.5056
Q Predictions Mean           1268.0837
Q Predictions Std            396.77267
Q Predictions Max            1551.9386
Q Predictions Min            -1.250475
V Predictions Mean           1268.7539
V Predictions Std            398.6426
V Predictions Max            1568.2245
V Predictions Min            3.6617079
Log Pis Mean                 -0.15051998
Log Pis Std                  2.164268
Log Pis Max                  9.589341
Log Pis Min                  -5.8871756
Policy mu Mean               0.13474463
Policy mu Std                0.877167
Policy mu Max                3.214901
Policy mu Min                -3.0451007
Policy log std Mean          -0.48103747
Policy log std Std           0.19829123
Policy log std Max           0.054726005
Policy log std Min           -1.2211442
Z mean eval                  0.012163282
Z variance eval              0.006206167
total_rewards                [3087.81054776 1300.54854994 1969.13474875 3054.8874828  3020.17592283
 3086.09763867 3105.11270662 3117.68035677 3094.5038722  3090.90667855]
total_rewards_mean           2792.6858504892316
total_rewards_std            598.4699143915855
total_rewards_max            3117.6803567715037
total_rewards_min            1300.548549940386
Number of train steps total  216000
Number of env steps total    1082000
Number of rollouts total     0
Train Time (s)               43.90410126093775
(Previous) Eval Time (s)     26.763447171077132
Sample Time (s)              22.317826095037162
Epoch Time (s)               92.98537452705204
Total Train Time (s)         16987.043764387257
Epoch                        215
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:31:26.907529 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #215 | Epoch Duration: 92.41194987297058
2020-01-11 05:31:26.907705 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #215 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011526787
Z variance train             0.006204327
KL Divergence                10.349722
KL Loss                      1.0349722
QF Loss                      348.2234
VF Loss                      180.51717
Policy Loss                  -1271.8884
Q Predictions Mean           1268.344
Q Predictions Std            399.00085
Q Predictions Max            1586.0773
Q Predictions Min            -15.037806
V Predictions Mean           1276.7634
V Predictions Std            398.83582
V Predictions Max            1591.7239
V Predictions Min            -2.7601924
Log Pis Mean                 -0.19655557
Log Pis Std                  1.9178457
Log Pis Max                  6.4735804
Log Pis Min                  -4.853282
Policy mu Mean               0.0038265258
Policy mu Std                0.8571221
Policy mu Max                2.508391
Policy mu Min                -3.0154803
Policy log std Mean          -0.4896985
Policy log std Std           0.2209061
Policy log std Max           0.056477666
Policy log std Min           -1.5648224
Z mean eval                  0.019531284
Z variance eval              0.005296621
total_rewards                [2900.72608427 1356.7323478  2520.62244362 3303.44949707 1607.92833424
  921.95337246 1084.11337688 3160.00767939 3255.24278978 3189.53767672]
total_rewards_mean           2330.031360224663
total_rewards_std            927.1961645017947
total_rewards_max            3303.449497071412
total_rewards_min            921.9533724636034
Number of train steps total  217000
Number of env steps total    1087000
Number of rollouts total     0
Train Time (s)               43.437553501687944
(Previous) Eval Time (s)     26.18978854222223
Sample Time (s)              21.55063707381487
Epoch Time (s)               91.17797911772504
Total Train Time (s)         17073.471140217967
Epoch                        216
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:32:53.337173 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #216 | Epoch Duration: 86.42927241325378
2020-01-11 05:32:53.337420 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #216 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019656561
Z variance train             0.00529845
KL Divergence                10.789646
KL Loss                      1.0789646
QF Loss                      162.23123
VF Loss                      58.88941
Policy Loss                  -1312.6558
Q Predictions Mean           1312.6068
Q Predictions Std            349.39572
Q Predictions Max            1578.2332
Q Predictions Min            6.6205363
V Predictions Mean           1310.5684
V Predictions Std            349.37408
V Predictions Max            1573.903
V Predictions Min            6.127217
Log Pis Mean                 -0.54294235
Log Pis Std                  1.8348954
Log Pis Max                  4.407429
Log Pis Min                  -5.5893126
Policy mu Mean               0.13410878
Policy mu Std                0.82072955
Policy mu Max                2.6527953
Policy mu Min                -2.6350222
Policy log std Mean          -0.48259804
Policy log std Std           0.207613
Policy log std Max           0.12539768
Policy log std Min           -1.2889435
Z mean eval                  0.021110287
Z variance eval              0.00554707
total_rewards                [1848.81128246  896.37410459  943.93138559 3234.81342049  955.29772329
 2137.46898223 2130.53540984 3235.39246664 2096.96911986 1264.78986051]
total_rewards_mean           1874.4383755496413
total_rewards_std            832.2684422126342
total_rewards_max            3235.392466641639
total_rewards_min            896.3741045936428
Number of train steps total  218000
Number of env steps total    1092000
Number of rollouts total     0
Train Time (s)               44.49467439297587
(Previous) Eval Time (s)     21.440832985565066
Sample Time (s)              20.144771555438638
Epoch Time (s)               86.08027893397957
Total Train Time (s)         17157.26748526795
Epoch                        217
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:34:17.134552 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #217 | Epoch Duration: 83.79697895050049
2020-01-11 05:34:17.134686 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #217 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021384563
Z variance train             0.0055433987
KL Divergence                10.656534
KL Loss                      1.0656534
QF Loss                      147.17596
VF Loss                      111.38238
Policy Loss                  -1320.4849
Q Predictions Mean           1318.3086
Q Predictions Std            341.24112
Q Predictions Max            1569.1436
Q Predictions Min            -6.9300523
V Predictions Mean           1327.3794
V Predictions Std            339.90543
V Predictions Max            1577.0063
V Predictions Min            0.12262231
Log Pis Mean                 -0.36932266
Log Pis Std                  2.0145352
Log Pis Max                  7.5948057
Log Pis Min                  -5.5426
Policy mu Mean               0.09763884
Policy mu Std                0.84844923
Policy mu Max                2.3906438
Policy mu Min                -2.9909008
Policy log std Mean          -0.48067427
Policy log std Std           0.21858975
Policy log std Max           0.024614483
Policy log std Min           -2.1868753
Z mean eval                  0.03242325
Z variance eval              0.0056788283
total_rewards                [3127.81422618  906.38101051 3151.2974069  3071.33462494 3065.07904463
 3106.0432817  3112.55783573 3130.10040409  868.28218274 1785.32401731]
total_rewards_mean           2532.421403474207
total_rewards_std            911.3722335507974
total_rewards_max            3151.2974069028214
total_rewards_min            868.2821827373454
Number of train steps total  219000
Number of env steps total    1097000
Number of rollouts total     0
Train Time (s)               44.31358917383477
(Previous) Eval Time (s)     19.157306300010532
Sample Time (s)              22.145087636075914
Epoch Time (s)               85.61598310992122
Total Train Time (s)         17250.623378630262
Epoch                        218
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:35:50.492935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #218 | Epoch Duration: 93.35807251930237
2020-01-11 05:35:50.493175 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #218 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033062432
Z variance train             0.0056865504
KL Divergence                10.586223
KL Loss                      1.0586222
QF Loss                      331.98755
VF Loss                      85.63021
Policy Loss                  -1299.6832
Q Predictions Mean           1299.767
Q Predictions Std            358.4575
Q Predictions Max            1583.7002
Q Predictions Min            -15.277287
V Predictions Mean           1303.907
V Predictions Std            359.087
V Predictions Max            1588.9722
V Predictions Min            -11.130858
Log Pis Mean                 -0.3756051
Log Pis Std                  2.0412054
Log Pis Max                  8.069503
Log Pis Min                  -4.560147
Policy mu Mean               -0.026119733
Policy mu Std                0.8439781
Policy mu Max                3.0035605
Policy mu Min                -2.9688582
Policy log std Mean          -0.47739553
Policy log std Std           0.198025
Policy log std Max           -0.00730294
Policy log std Min           -1.2485476
Z mean eval                  0.03374462
Z variance eval              0.0053601987
total_rewards                [1007.93927583 3126.6355886   937.6422129  1035.59868544 1067.61477777
 3179.21142612 1621.71625276 1661.40916043 1882.94215312 3084.96160329]
total_rewards_mean           1860.56711362518
total_rewards_std            884.6592143629556
total_rewards_max            3179.2114261215943
total_rewards_min            937.6422128989199
Number of train steps total  220000
Number of env steps total    1102000
Number of rollouts total     0
Train Time (s)               44.797453481238335
(Previous) Eval Time (s)     26.899146114941686
Sample Time (s)              21.928814097307622
Epoch Time (s)               93.62541369348764
Total Train Time (s)         17336.49580253288
Epoch                        219
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:37:16.369318 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #219 | Epoch Duration: 85.8759982585907
2020-01-11 05:37:16.369441 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #219 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033503436
Z variance train             0.0053621265
KL Divergence                10.715426
KL Loss                      1.0715426
QF Loss                      376.8714
VF Loss                      104.94538
Policy Loss                  -1282.542
Q Predictions Mean           1278.3269
Q Predictions Std            405.37912
Q Predictions Max            1581.8856
Q Predictions Min            -0.16908139
V Predictions Mean           1278.0515
V Predictions Std            402.96402
V Predictions Max            1580.1212
V Predictions Min            6.5685725
Log Pis Mean                 -0.21364087
Log Pis Std                  2.101252
Log Pis Max                  12.682167
Log Pis Min                  -4.70086
Policy mu Mean               0.17181014
Policy mu Std                0.85781527
Policy mu Max                2.6841824
Policy mu Min                -3.264059
Policy log std Mean          -0.4770135
Policy log std Std           0.19630562
Policy log std Max           -0.04151553
Policy log std Min           -1.2974396
Z mean eval                  0.016264081
Z variance eval              0.0054261177
total_rewards                [1032.54906171  963.60658177 2105.63248551 2015.32425455 1034.72418979
 1033.83947666  986.45390096 2088.68957071 2154.15734546 1894.22219258]
total_rewards_mean           1530.9199059702707
total_rewards_std            525.0164623287361
total_rewards_max            2154.1573454648665
total_rewards_min            963.6065817667128
Number of train steps total  221000
Number of env steps total    1107000
Number of rollouts total     0
Train Time (s)               44.260840891394764
(Previous) Eval Time (s)     19.149510221090168
Sample Time (s)              21.847940299194306
Epoch Time (s)               85.25829141167924
Total Train Time (s)         17418.23941496713
Epoch                        220
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:38:38.115763 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #220 | Epoch Duration: 81.74622535705566
2020-01-11 05:38:38.115883 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #220 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017554734
Z variance train             0.0054284795
KL Divergence                10.754981
KL Loss                      1.0754981
QF Loss                      231.58537
VF Loss                      198.71014
Policy Loss                  -1332.0243
Q Predictions Mean           1327.3811
Q Predictions Std            336.90286
Q Predictions Max            1579.7212
Q Predictions Min            3.1465182
V Predictions Mean           1342.6304
V Predictions Std            335.55954
V Predictions Max            1598.3019
V Predictions Min            5.730605
Log Pis Mean                 -0.2361369
Log Pis Std                  1.9864123
Log Pis Max                  6.2224655
Log Pis Min                  -6.4766407
Policy mu Mean               0.17904909
Policy mu Std                0.8667477
Policy mu Max                2.7214582
Policy mu Min                -2.675555
Policy log std Mean          -0.5044622
Policy log std Std           0.20942964
Policy log std Max           0.117144644
Policy log std Min           -1.2117001
Z mean eval                  0.009163752
Z variance eval              0.0058133537
total_rewards                [2426.10401287 3282.89922881 2379.8770811  1537.96840843 1313.27077083
 1071.91696985 1040.09120229 1598.86347306 1858.76476258 3219.57643793]
total_rewards_mean           1972.933234774875
total_rewards_std            781.052712053619
total_rewards_max            3282.8992288098957
total_rewards_min            1040.091202294143
Number of train steps total  222000
Number of env steps total    1112000
Number of rollouts total     0
Train Time (s)               43.15941597195342
(Previous) Eval Time (s)     15.63720607291907
Sample Time (s)              21.45681931404397
Epoch Time (s)               80.25344135891646
Total Train Time (s)         17502.23029192537
Epoch                        221
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:40:02.108480 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #221 | Epoch Duration: 83.99250364303589
2020-01-11 05:40:02.108605 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #221 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.007580866
Z variance train             0.00580474
KL Divergence                10.60421
KL Loss                      1.060421
QF Loss                      491.4135
VF Loss                      269.30093
Policy Loss                  -1271.4113
Q Predictions Mean           1271.6936
Q Predictions Std            434.54477
Q Predictions Max            1587.6145
Q Predictions Min            -9.916288
V Predictions Mean           1274.9596
V Predictions Std            433.86502
V Predictions Max            1607.1786
V Predictions Min            -14.317717
Log Pis Mean                 -0.35215032
Log Pis Std                  1.9547782
Log Pis Max                  6.725547
Log Pis Min                  -4.7877
Policy mu Mean               0.11131436
Policy mu Std                0.8430646
Policy mu Max                2.3308353
Policy mu Min                -2.7631803
Policy log std Mean          -0.4704536
Policy log std Std           0.18942626
Policy log std Max           0.028735042
Policy log std Min           -1.0305068
Z mean eval                  0.03203143
Z variance eval              0.00799522
total_rewards                [1861.65976108  442.82767643 3162.40205247 2202.87323597 1516.35741343
 1033.23167228 3158.08383883 1875.2494862  1585.17644581 1957.95913518]
total_rewards_mean           1879.5820717677393
total_rewards_std            799.3980866208475
total_rewards_max            3162.40205246603
total_rewards_min            442.82767643115585
Number of train steps total  223000
Number of env steps total    1117000
Number of rollouts total     0
Train Time (s)               43.33873885311186
(Previous) Eval Time (s)     19.37601903406903
Sample Time (s)              22.053814372979105
Epoch Time (s)               84.76857226016
Total Train Time (s)         17585.573939690832
Epoch                        222
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:41:25.457422 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #222 | Epoch Duration: 83.34869313240051
2020-01-11 05:41:25.457653 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #222 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031906597
Z variance train             0.007992068
KL Divergence                10.023497
KL Loss                      1.0023497
QF Loss                      170.75124
VF Loss                      50.118073
Policy Loss                  -1320.3433
Q Predictions Mean           1320.4957
Q Predictions Std            379.8078
Q Predictions Max            1600.0336
Q Predictions Min            5.3548203
V Predictions Mean           1322.8379
V Predictions Std            381.90714
V Predictions Max            1597.1735
V Predictions Min            -5.190363
Log Pis Mean                 -0.20807925
Log Pis Std                  2.097477
Log Pis Max                  8.590152
Log Pis Min                  -4.883217
Policy mu Mean               0.058364242
Policy mu Std                0.9095357
Policy mu Max                2.4664552
Policy mu Min                -3.0873094
Policy log std Mean          -0.48820236
Policy log std Std           0.20431592
Policy log std Max           0.08133209
Policy log std Min           -1.3755097
Z mean eval                  0.016666386
Z variance eval              0.007376791
total_rewards                [1260.43224639 1011.87400442 1570.35145479 3177.95044934 3192.69459718
 1680.91551425 3112.23095664 1847.48447207 1842.20457176 1804.28506808]
total_rewards_mean           2050.0423334913094
total_rewards_std            769.3070880686225
total_rewards_max            3192.694597182326
total_rewards_min            1011.8740044177392
Number of train steps total  224000
Number of env steps total    1122000
Number of rollouts total     0
Train Time (s)               43.66156023973599
(Previous) Eval Time (s)     17.955870111938566
Sample Time (s)              19.96632000338286
Epoch Time (s)               81.58375035505742
Total Train Time (s)         17669.881965569686
Epoch                        223
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:42:49.766608 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #223 | Epoch Duration: 84.30879235267639
2020-01-11 05:42:49.766729 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #223 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0162565
Z variance train             0.007375314
KL Divergence                10.012645
KL Loss                      1.0012645
QF Loss                      141.08585
VF Loss                      123.330444
Policy Loss                  -1318.6193
Q Predictions Mean           1317.69
Q Predictions Std            404.1924
Q Predictions Max            1620.9846
Q Predictions Min            0.5234432
V Predictions Mean           1324.6678
V Predictions Std            404.39938
V Predictions Max            1629.7426
V Predictions Min            1.2206069
Log Pis Mean                 -0.3457514
Log Pis Std                  1.9833307
Log Pis Max                  7.391488
Log Pis Min                  -5.8721685
Policy mu Mean               0.14513485
Policy mu Std                0.8378807
Policy mu Max                2.1714046
Policy mu Min                -3.1852875
Policy log std Mean          -0.46045157
Policy log std Std           0.2102986
Policy log std Max           0.017139494
Policy log std Min           -1.1327369
Z mean eval                  0.016301583
Z variance eval              0.0066624694
total_rewards                [2175.84847235 3095.48769065 1507.06977164 1432.89422396 2783.2371294
 1405.49855243 1055.03952648 3317.23751319 1272.97811733 1037.8992578 ]
total_rewards_mean           1908.3190255228315
total_rewards_std            822.2351924320238
total_rewards_max            3317.2375131877525
total_rewards_min            1037.8992578034035
Number of train steps total  225000
Number of env steps total    1127000
Number of rollouts total     0
Train Time (s)               44.935841239988804
(Previous) Eval Time (s)     20.680706535931677
Sample Time (s)              21.638016413897276
Epoch Time (s)               87.25456418981776
Total Train Time (s)         17754.902485202067
Epoch                        224
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:44:14.788918 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #224 | Epoch Duration: 85.02209734916687
2020-01-11 05:44:14.789043 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #224 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016295187
Z variance train             0.00666136
KL Divergence                10.287653
KL Loss                      1.0287653
QF Loss                      311.24115
VF Loss                      120.06815
Policy Loss                  -1323.0463
Q Predictions Mean           1318.7894
Q Predictions Std            342.36563
Q Predictions Max            1629.8014
Q Predictions Min            11.460426
V Predictions Mean           1321.5095
V Predictions Std            343.06342
V Predictions Max            1643.3003
V Predictions Min            12.143109
Log Pis Mean                 -0.121838294
Log Pis Std                  2.0670884
Log Pis Max                  8.062561
Log Pis Min                  -4.578662
Policy mu Mean               0.11806498
Policy mu Std                0.8989129
Policy mu Max                2.6779191
Policy mu Min                -3.2109401
Policy log std Mean          -0.44735262
Policy log std Std           0.20560299
Policy log std Max           0.07714543
Policy log std Min           -1.20797
Z mean eval                  0.01123448
Z variance eval              0.0067920485
total_rewards                [3279.30828244  715.09932816 1300.27636671 3144.32727819  993.23216301
 3202.56817465 3188.76435005 3192.49350071 3238.92406869 2445.00681329]
total_rewards_mean           2470.0000325898573
total_rewards_std            995.2695226708951
total_rewards_max            3279.30828243953
total_rewards_min            715.0993281594217
Number of train steps total  226000
Number of env steps total    1132000
Number of rollouts total     0
Train Time (s)               44.22435575257987
(Previous) Eval Time (s)     18.447972868103534
Sample Time (s)              21.761760266963392
Epoch Time (s)               84.4340888876468
Total Train Time (s)         17844.561439279
Epoch                        225
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:45:44.451174 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #225 | Epoch Duration: 89.66202712059021
2020-01-11 05:45:44.451335 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #225 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010971708
Z variance train             0.0068011633
KL Divergence                10.289612
KL Loss                      1.0289612
QF Loss                      177.7467
VF Loss                      111.449715
Policy Loss                  -1302.82
Q Predictions Mean           1302.0531
Q Predictions Std            369.4671
Q Predictions Max            1599.9446
Q Predictions Min            3.9714959
V Predictions Mean           1296.3276
V Predictions Std            369.31458
V Predictions Max            1597.3827
V Predictions Min            -7.670264
Log Pis Mean                 -0.35943422
Log Pis Std                  2.1666276
Log Pis Max                  9.666627
Log Pis Min                  -6.6771374
Policy mu Mean               -0.045454383
Policy mu Std                0.8772899
Policy mu Max                2.4331627
Policy mu Min                -2.966364
Policy log std Mean          -0.4685278
Policy log std Std           0.21294583
Policy log std Max           0.08728081
Policy log std Min           -1.3575699
Z mean eval                  0.026983932
Z variance eval              0.0066373
total_rewards                [3234.1553045  2326.20950477 2932.2003322  1526.5207745  3155.65752698
 2894.29892364 3187.88200617 1334.73455405 3216.52391105 3286.95208938]
total_rewards_mean           2709.513492723102
total_rewards_std            693.813432743041
total_rewards_max            3286.952089376604
total_rewards_min            1334.7345540508782
Number of train steps total  227000
Number of env steps total    1137000
Number of rollouts total     0
Train Time (s)               43.36422969494015
(Previous) Eval Time (s)     23.675666354130954
Sample Time (s)              22.272337272763252
Epoch Time (s)               89.31223332183436
Total Train Time (s)         17937.628533023875
Epoch                        226
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:47:17.521125 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #226 | Epoch Duration: 93.0696542263031
2020-01-11 05:47:17.521331 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #226 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02695559
Z variance train             0.0066357134
KL Divergence                10.442001
KL Loss                      1.0442002
QF Loss                      175.6376
VF Loss                      60.11779
Policy Loss                  -1357.6149
Q Predictions Mean           1357.7988
Q Predictions Std            312.06284
Q Predictions Max            1610.9224
Q Predictions Min            10.516497
V Predictions Mean           1357.1323
V Predictions Std            312.94357
V Predictions Max            1609.0034
V Predictions Min            -30.562943
Log Pis Mean                 -0.48202202
Log Pis Std                  1.7737726
Log Pis Max                  9.54785
Log Pis Min                  -5.6487594
Policy mu Mean               0.13863538
Policy mu Std                0.79159945
Policy mu Max                2.0181837
Policy mu Min                -2.7713313
Policy log std Mean          -0.42904234
Policy log std Std           0.19517937
Policy log std Max           0.1887826
Policy log std Min           -1.3364106
Z mean eval                  0.011716746
Z variance eval              0.005187169
total_rewards                [ 252.50148969 1361.78823069 1810.74662691 1724.55349486 3305.65646937
 3262.41857386 1857.08381336 3083.30421633 2449.93986354 1624.06902557]
total_rewards_mean           2073.206180418373
total_rewards_std            914.0757072265657
total_rewards_max            3305.6564693740734
total_rewards_min            252.50148969335243
Number of train steps total  228000
Number of env steps total    1142000
Number of rollouts total     0
Train Time (s)               44.030011664144695
(Previous) Eval Time (s)     27.43284429470077
Sample Time (s)              19.799244246445596
Epoch Time (s)               91.26210020529106
Total Train Time (s)         18021.996566372924
Epoch                        227
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:48:41.892015 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #227 | Epoch Duration: 84.37045693397522
2020-01-11 05:48:41.892260 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #227 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0116091
Z variance train             0.005190021
KL Divergence                10.966108
KL Loss                      1.0966109
QF Loss                      771.2014
VF Loss                      472.77432
Policy Loss                  -1352.4418
Q Predictions Mean           1349.6603
Q Predictions Std            333.65125
Q Predictions Max            1618.3392
Q Predictions Min            -27.170555
V Predictions Mean           1356.2349
V Predictions Std            326.47385
V Predictions Max            1624.5281
V Predictions Min            -1.4941283
Log Pis Mean                 -0.04398138
Log Pis Std                  2.3533678
Log Pis Max                  14.334594
Log Pis Min                  -6.323253
Policy mu Mean               0.16961153
Policy mu Std                0.9283791
Policy mu Max                3.3322637
Policy mu Min                -4.4944644
Policy log std Mean          -0.4667835
Policy log std Std           0.21391219
Policy log std Max           0.030741602
Policy log std Min           -1.185555
Z mean eval                  0.027825797
Z variance eval              0.0057492163
total_rewards                [1015.70659033 1535.85546679 1407.64872039 1272.50285777 1824.96191547
 1569.13762878 1029.71332469  946.67216108 1625.65621807 1878.72944957]
total_rewards_mean           1410.6584332934794
total_rewards_std            318.31388093060195
total_rewards_max            1878.7294495675312
total_rewards_min            946.6721610761713
Number of train steps total  229000
Number of env steps total    1147000
Number of rollouts total     0
Train Time (s)               44.436056251171976
(Previous) Eval Time (s)     20.540953459218144
Sample Time (s)              21.777282861061394
Epoch Time (s)               86.75429257145151
Total Train Time (s)         18102.556990400422
Epoch                        228
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:50:02.456856 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #228 | Epoch Duration: 80.5644052028656
2020-01-11 05:50:02.457133 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #228 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028112924
Z variance train             0.0057528876
KL Divergence                10.601818
KL Loss                      1.0601819
QF Loss                      145.0816
VF Loss                      227.8258
Policy Loss                  -1355.1394
Q Predictions Mean           1355.787
Q Predictions Std            332.20312
Q Predictions Max            1610.9237
Q Predictions Min            4.492912
V Predictions Mean           1349.0242
V Predictions Std            330.25348
V Predictions Max            1602.9155
V Predictions Min            0.8934058
Log Pis Mean                 -0.24501061
Log Pis Std                  1.9285992
Log Pis Max                  8.359289
Log Pis Min                  -7.715605
Policy mu Mean               0.1374891
Policy mu Std                0.8582982
Policy mu Max                3.0549388
Policy mu Min                -2.4317515
Policy log std Mean          -0.474131
Policy log std Std           0.2000527
Policy log std Max           0.0024485588
Policy log std Min           -1.4279988
Z mean eval                  0.024107685
Z variance eval              0.0062800073
total_rewards                [1047.80787837 1848.15725995 1284.02703705 1589.6427644  1598.05792135
 1059.75717437 1206.25106418 1312.25567204 1030.52678371  983.15477737]
total_rewards_mean           1295.9638332790144
total_rewards_std            278.66885752785794
total_rewards_max            1848.1572599509004
total_rewards_min            983.1547773746229
Number of train steps total  230000
Number of env steps total    1152000
Number of rollouts total     0
Train Time (s)               43.52779212221503
(Previous) Eval Time (s)     14.350826160982251
Sample Time (s)              22.378673794213682
Epoch Time (s)               80.25729207741097
Total Train Time (s)         18179.823753353674
Epoch                        229
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:51:19.725170 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #229 | Epoch Duration: 77.26783013343811
2020-01-11 05:51:19.725355 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #229 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02407613
Z variance train             0.006282223
KL Divergence                10.539684
KL Loss                      1.0539684
QF Loss                      195.9566
VF Loss                      94.94075
Policy Loss                  -1381.3176
Q Predictions Mean           1385.2528
Q Predictions Std            251.3897
Q Predictions Max            1603.5878
Q Predictions Min            -11.867028
V Predictions Mean           1382.5537
V Predictions Std            249.33057
V Predictions Max            1594.9633
V Predictions Min            -7.976519
Log Pis Mean                 -0.36864668
Log Pis Std                  1.927021
Log Pis Max                  6.570953
Log Pis Min                  -6.5630627
Policy mu Mean               -0.032020435
Policy mu Std                0.8474609
Policy mu Max                2.420866
Policy mu Min                -2.6083887
Policy log std Mean          -0.45662966
Policy log std Std           0.19895667
Policy log std Max           0.060131043
Policy log std Min           -1.5446198
Z mean eval                  0.007216929
Z variance eval              0.0068115457
total_rewards                [1328.24029889 1518.45508847 1350.30294724 1544.71009994 1795.25295263
 1342.07565308 2665.04622345 1587.57480155 1352.94079589 1411.39857789]
total_rewards_mean           1589.599743902982
total_rewards_std            384.78073240901495
total_rewards_max            2665.0462234541887
total_rewards_min            1328.2402988912713
Number of train steps total  231000
Number of env steps total    1157000
Number of rollouts total     0
Train Time (s)               43.90234341612086
(Previous) Eval Time (s)     11.361135391984135
Sample Time (s)              21.754192379303277
Epoch Time (s)               77.01767118740827
Total Train Time (s)         18261.21231607767
Epoch                        230
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:52:41.122927 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #230 | Epoch Duration: 81.39740800857544
2020-01-11 05:52:41.123187 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #230 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00747423
Z variance train             0.0068225833
KL Divergence                10.346174
KL Loss                      1.0346174
QF Loss                      211.78944
VF Loss                      147.91083
Policy Loss                  -1298.2479
Q Predictions Mean           1299.2803
Q Predictions Std            414.1425
Q Predictions Max            1613.6448
Q Predictions Min            -20.867493
V Predictions Mean           1295.8171
V Predictions Std            411.89005
V Predictions Max            1606.5718
V Predictions Min            3.6656663
Log Pis Mean                 -0.4268025
Log Pis Std                  1.9253876
Log Pis Max                  9.412919
Log Pis Min                  -4.191404
Policy mu Mean               0.06641238
Policy mu Std                0.8232723
Policy mu Max                2.6313384
Policy mu Min                -2.958893
Policy log std Mean          -0.4550782
Policy log std Std           0.19861622
Policy log std Max           0.046834826
Policy log std Min           -1.2736193
Z mean eval                  0.027549526
Z variance eval              0.006816688
total_rewards                [2498.72576267 1109.04326432 3369.61396968 1096.76420836 2374.3995511
 1096.05102963 1093.9007533  1087.83618166 1353.19982785 1081.62343047]
total_rewards_mean           1616.1157979041225
total_rewards_std            783.1130974306243
total_rewards_max            3369.613969679735
total_rewards_min            1081.6234304718464
Number of train steps total  232000
Number of env steps total    1162000
Number of rollouts total     0
Train Time (s)               43.99621141701937
(Previous) Eval Time (s)     15.740616519935429
Sample Time (s)              21.71601053373888
Epoch Time (s)               81.45283847069368
Total Train Time (s)         18342.37540854374
Epoch                        231
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:54:02.287867 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #231 | Epoch Duration: 81.16448211669922
2020-01-11 05:54:02.288070 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #231 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027061924
Z variance train             0.006812462
KL Divergence                10.215618
KL Loss                      1.0215619
QF Loss                      286.59998
VF Loss                      329.4139
Policy Loss                  -1383.2838
Q Predictions Mean           1381.8894
Q Predictions Std            300.49844
Q Predictions Max            1620.8019
Q Predictions Min            6.016404
V Predictions Mean           1373.6091
V Predictions Std            297.1222
V Predictions Max            1608.8881
V Predictions Min            -3.7428422
Log Pis Mean                 -0.13067903
Log Pis Std                  2.202669
Log Pis Max                  11.377605
Log Pis Min                  -5.5241976
Policy mu Mean               0.006116897
Policy mu Std                0.89433104
Policy mu Max                3.8030229
Policy mu Min                -3.1825945
Policy log std Mean          -0.49556658
Policy log std Std           0.22099711
Policy log std Max           0.0695191
Policy log std Min           -1.7584419
Z mean eval                  0.014684985
Z variance eval              0.008152269
total_rewards                [3112.4785202  1431.66366041 3089.3028941  1445.99435286 3141.68335973
 3180.04946505 1323.08279494 3136.33495597 1813.10860943 3164.21392182]
total_rewards_mean           2483.7912534505685
total_rewards_std            809.2794357901219
total_rewards_max            3180.049465052206
total_rewards_min            1323.0827949411314
Number of train steps total  233000
Number of env steps total    1167000
Number of rollouts total     0
Train Time (s)               43.87529403110966
(Previous) Eval Time (s)     15.45201878901571
Sample Time (s)              22.5628606043756
Epoch Time (s)               81.89017342450097
Total Train Time (s)         18431.855599387083
Epoch                        232
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:55:31.775463 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #232 | Epoch Duration: 89.48721051216125
2020-01-11 05:55:31.775776 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #232 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014813189
Z variance train             0.008135723
KL Divergence                9.693249
KL Loss                      0.9693249
QF Loss                      821.5596
VF Loss                      199.88571
Policy Loss                  -1417.875
Q Predictions Mean           1417.957
Q Predictions Std            285.68515
Q Predictions Max            1637.5593
Q Predictions Min            -4.397466
V Predictions Mean           1424.3474
V Predictions Std            282.1096
V Predictions Max            1646.3275
V Predictions Min            3.2435193
Log Pis Mean                 -0.13426782
Log Pis Std                  2.1780858
Log Pis Max                  9.963949
Log Pis Min                  -4.628115
Policy mu Mean               -0.06604715
Policy mu Std                0.91724753
Policy mu Max                3.7964401
Policy mu Min                -3.6828442
Policy log std Mean          -0.50492084
Policy log std Std           0.2043273
Policy log std Max           -0.019584954
Policy log std Min           -1.3020599
Z mean eval                  0.027392173
Z variance eval              0.007370589
total_rewards                [3228.54612521 3201.67654995 3171.48172266 1436.49104384 1387.82957923
 3135.14761249 1902.15352324 1282.47018584 3144.14973062 3266.17736685]
total_rewards_mean           2515.6123439941894
total_rewards_std            841.7079311570236
total_rewards_max            3266.1773668525043
total_rewards_min            1282.4701858429505
Number of train steps total  234000
Number of env steps total    1172000
Number of rollouts total     0
Train Time (s)               43.64209198998287
(Previous) Eval Time (s)     23.048779748845845
Sample Time (s)              21.938946842681617
Epoch Time (s)               88.62981858151034
Total Train Time (s)         18521.25472639315
Epoch                        233
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:57:01.178558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #233 | Epoch Duration: 89.40255117416382
2020-01-11 05:57:01.178739 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #233 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02788423
Z variance train             0.007368467
KL Divergence                9.880417
KL Loss                      0.9880417
QF Loss                      136.26009
VF Loss                      216.95169
Policy Loss                  -1368.8832
Q Predictions Mean           1368.8073
Q Predictions Std            362.84708
Q Predictions Max            1639.3154
Q Predictions Min            -6.2625537
V Predictions Mean           1366.2571
V Predictions Std            358.9115
V Predictions Max            1638.7407
V Predictions Min            -10.379871
Log Pis Mean                 -0.3968569
Log Pis Std                  2.1510694
Log Pis Max                  10.770519
Log Pis Min                  -5.6792774
Policy mu Mean               0.13396658
Policy mu Std                0.81832415
Policy mu Max                3.7229087
Policy mu Min                -2.978798
Policy log std Mean          -0.46304655
Policy log std Std           0.20923188
Policy log std Max           -0.035154015
Policy log std Min           -1.3126141
Z mean eval                  0.03617896
Z variance eval              0.008532478
total_rewards                [1299.10451875  408.87349037 2010.31828944 2533.42638767 1778.84388083
 3097.68457424 1249.81767391 1799.11310825 1062.84554693 3139.12724217]
total_rewards_mean           1837.9154712554744
total_rewards_std            841.2903268720601
total_rewards_max            3139.127242172594
total_rewards_min            408.87349036654876
Number of train steps total  235000
Number of env steps total    1177000
Number of rollouts total     0
Train Time (s)               43.83190498594195
(Previous) Eval Time (s)     23.821283959783614
Sample Time (s)              22.010942861437798
Epoch Time (s)               89.66413180716336
Total Train Time (s)         18606.454042406753
Epoch                        234
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:58:26.380885 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #234 | Epoch Duration: 85.20200037956238
2020-01-11 05:58:26.381061 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #234 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03622899
Z variance train             0.008520247
KL Divergence                9.566642
KL Loss                      0.9566642
QF Loss                      481.3001
VF Loss                      104.585236
Policy Loss                  -1325.6287
Q Predictions Mean           1320.2216
Q Predictions Std            317.41602
Q Predictions Max            1575.4922
Q Predictions Min            -6.290701
V Predictions Mean           1326.5364
V Predictions Std            314.8556
V Predictions Max            1583.594
V Predictions Min            3.9584796
Log Pis Mean                 -0.3572631
Log Pis Std                  1.8994131
Log Pis Max                  6.579069
Log Pis Min                  -7.276464
Policy mu Mean               0.08524958
Policy mu Std                0.8659252
Policy mu Max                3.2136073
Policy mu Min                -2.3521647
Policy log std Mean          -0.45503426
Policy log std Std           0.1972053
Policy log std Max           -0.015454888
Policy log std Min           -1.2288777
Z mean eval                  0.041691102
Z variance eval              0.008036009
total_rewards                [3147.16363513 3220.43319361 1067.88456215 1747.21503177 1884.42971177
  993.4331827  1111.19240046  884.69150396 1026.71785216 2652.04623173]
total_rewards_mean           1773.5207305436786
total_rewards_std            875.1068556306494
total_rewards_max            3220.4331936088793
total_rewards_min            884.6915039590241
Number of train steps total  236000
Number of env steps total    1182000
Number of rollouts total     0
Train Time (s)               43.92063638428226
(Previous) Eval Time (s)     19.358894270844758
Sample Time (s)              20.814542965963483
Epoch Time (s)               84.0940736210905
Total Train Time (s)         18689.146401884966
Epoch                        235
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 05:59:49.074841 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #235 | Epoch Duration: 82.69364166259766
2020-01-11 05:59:49.074997 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #235 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041721307
Z variance train             0.008028227
KL Divergence                9.686316
KL Loss                      0.96863157
QF Loss                      86.8884
VF Loss                      48.266247
Policy Loss                  -1400.5669
Q Predictions Mean           1398.9359
Q Predictions Std            274.45834
Q Predictions Max            1622.9259
Q Predictions Min            5.968979
V Predictions Mean           1401.6908
V Predictions Std            273.16925
V Predictions Max            1627.0979
V Predictions Min            4.9494357
Log Pis Mean                 -0.31150216
Log Pis Std                  2.0468788
Log Pis Max                  12.773743
Log Pis Min                  -6.348598
Policy mu Mean               0.11486837
Policy mu Std                0.8490734
Policy mu Max                3.3294709
Policy mu Min                -2.9574428
Policy log std Mean          -0.4573253
Policy log std Std           0.19669966
Policy log std Max           0.03166169
Policy log std Min           -1.2209218
Z mean eval                  0.01598142
Z variance eval              0.008076924
total_rewards                [ 962.58782031 1098.76462376 1085.99674686 1108.08576866 1037.04643015
 1370.07484892 1199.57036632  866.85479648 1321.9672058  1042.88920081]
total_rewards_mean           1109.383780806943
total_rewards_std            145.59194833316292
total_rewards_max            1370.0748489204257
total_rewards_min            866.8547964824955
Number of train steps total  237000
Number of env steps total    1187000
Number of rollouts total     0
Train Time (s)               44.21673125727102
(Previous) Eval Time (s)     17.95823817094788
Sample Time (s)              21.666268040891737
Epoch Time (s)               83.84123746911064
Total Train Time (s)         18765.737606312614
Epoch                        236
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:01:05.670309 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #236 | Epoch Duration: 76.59519076347351
2020-01-11 06:01:05.670490 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #236 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015952649
Z variance train             0.008068962
KL Divergence                9.614618
KL Loss                      0.96146184
QF Loss                      150.31284
VF Loss                      107.33585
Policy Loss                  -1388.4652
Q Predictions Mean           1386.1998
Q Predictions Std            280.8314
Q Predictions Max            1609.2604
Q Predictions Min            -1.1287608
V Predictions Mean           1394.17
V Predictions Std            280.94333
V Predictions Max            1621.0736
V Predictions Min            -0.24119395
Log Pis Mean                 -0.3595003
Log Pis Std                  1.8405579
Log Pis Max                  7.001207
Log Pis Min                  -5.6051736
Policy mu Mean               0.06386198
Policy mu Std                0.8334579
Policy mu Max                2.5108316
Policy mu Min                -2.6760104
Policy log std Mean          -0.46861544
Policy log std Std           0.19144757
Policy log std Max           0.016606927
Policy log std Min           -1.1416944
Z mean eval                  0.01735891
Z variance eval              0.008330317
total_rewards                [1731.37100274 1071.46402924 2764.60838927  958.64000982 1056.79730707
 1048.91268397 2143.47800137 1073.20572536 1029.58752489  951.88625476]
total_rewards_mean           1382.9950928484982
total_rewards_std            592.488093772817
total_rewards_max            2764.6083892674283
total_rewards_min            951.8862547589878
Number of train steps total  238000
Number of env steps total    1192000
Number of rollouts total     0
Train Time (s)               43.78344645584002
(Previous) Eval Time (s)     10.711980062071234
Sample Time (s)              21.427954643033445
Epoch Time (s)               75.9233811609447
Total Train Time (s)         18843.37494851835
Epoch                        237
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:02:23.311792 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #237 | Epoch Duration: 77.6411612033844
2020-01-11 06:02:23.311976 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #237 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017204124
Z variance train             0.008331707
KL Divergence                9.604055
KL Loss                      0.9604055
QF Loss                      204.77725
VF Loss                      175.20859
Policy Loss                  -1386.626
Q Predictions Mean           1384.3328
Q Predictions Std            282.44006
Q Predictions Max            1621.6254
Q Predictions Min            15.273836
V Predictions Mean           1388.5159
V Predictions Std            284.34824
V Predictions Max            1636.9291
V Predictions Min            18.008352
Log Pis Mean                 -0.4498618
Log Pis Std                  1.8841313
Log Pis Max                  9.727645
Log Pis Min                  -5.1635876
Policy mu Mean               0.10099721
Policy mu Std                0.8159041
Policy mu Max                3.4957469
Policy mu Min                -2.8158553
Policy log std Mean          -0.46521345
Policy log std Std           0.19183555
Policy log std Max           0.0075232685
Policy log std Min           -1.26916
Z mean eval                  0.017650202
Z variance eval              0.007820833
total_rewards                [3148.80139277 3315.61995155 3324.49860192 2263.13275313 3265.47642686
 2667.76666196 3296.54195684 1052.12106104 3285.95588413 1089.28316248]
total_rewards_mean           2670.919785267947
total_rewards_std            865.0276545405775
total_rewards_max            3324.498601918904
total_rewards_min            1052.1210610389737
Number of train steps total  239000
Number of env steps total    1197000
Number of rollouts total     0
Train Time (s)               42.78369616298005
(Previous) Eval Time (s)     12.429539756849408
Sample Time (s)              21.109603447839618
Epoch Time (s)               76.32283936766908
Total Train Time (s)         18933.41173529299
Epoch                        238
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:03:53.350796 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #238 | Epoch Duration: 90.03864574432373
2020-01-11 06:03:53.350990 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #238 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017502958
Z variance train             0.007828267
KL Divergence                9.801652
KL Loss                      0.9801652
QF Loss                      162.0404
VF Loss                      119.134125
Policy Loss                  -1367.2665
Q Predictions Mean           1368.4039
Q Predictions Std            296.20096
Q Predictions Max            1614.8
Q Predictions Min            2.0253959
V Predictions Mean           1370.9253
V Predictions Std            295.22342
V Predictions Max            1613.7211
V Predictions Min            3.8429985
Log Pis Mean                 -0.36311713
Log Pis Std                  2.0454218
Log Pis Max                  6.1624393
Log Pis Min                  -5.7212086
Policy mu Mean               0.10707519
Policy mu Std                0.8700043
Policy mu Max                2.9762864
Policy mu Min                -3.104498
Policy log std Mean          -0.47483373
Policy log std Std           0.21119136
Policy log std Max           0.10524005
Policy log std Min           -1.7640578
Z mean eval                  0.011832556
Z variance eval              0.0070038587
total_rewards                [1364.22908619 1941.41958855 3306.50923976  992.27322442  955.60610873
 3405.92634504 1073.60210851 2021.75591682 2753.87647519 2562.68497459]
total_rewards_mean           2037.788306781206
total_rewards_std            890.3288374245113
total_rewards_max            3405.9263450393264
total_rewards_min            955.6061087325512
Number of train steps total  240000
Number of env steps total    1202000
Number of rollouts total     0
Train Time (s)               43.76148539688438
(Previous) Eval Time (s)     26.14509457582608
Sample Time (s)              21.992311965674162
Epoch Time (s)               91.89889193838462
Total Train Time (s)         19019.179226906504
Epoch                        239
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:05:19.125351 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #239 | Epoch Duration: 85.77419781684875
2020-01-11 06:05:19.125634 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #239 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011586318
Z variance train             0.0070056096
KL Divergence                10.084494
KL Loss                      1.0084494
QF Loss                      165.65604
VF Loss                      71.61701
Policy Loss                  -1360.901
Q Predictions Mean           1358.2129
Q Predictions Std            309.30453
Q Predictions Max            1591.9908
Q Predictions Min            -13.106884
V Predictions Mean           1363.0032
V Predictions Std            302.9772
V Predictions Max            1595.5049
V Predictions Min            -0.6242293
Log Pis Mean                 -0.3144812
Log Pis Std                  1.9900836
Log Pis Max                  12.910147
Log Pis Min                  -5.5138087
Policy mu Mean               0.13174267
Policy mu Std                0.8353753
Policy mu Max                4.464844
Policy mu Min                -3.9441082
Policy log std Mean          -0.47724247
Policy log std Std           0.20290828
Policy log std Max           -0.030458927
Policy log std Min           -2.3799806
Z mean eval                  0.011321381
Z variance eval              0.0062913597
total_rewards                [1124.22801613  880.95839438 2237.09995441 2677.98060438 1139.10146426
 1171.31939073 1297.32173167  875.98305716 1770.14599946 1795.53201976]
total_rewards_mean           1496.967063232752
total_rewards_std            573.092672307887
total_rewards_max            2677.980604375668
total_rewards_min            875.9830571594418
Number of train steps total  241000
Number of env steps total    1207000
Number of rollouts total     0
Train Time (s)               44.08847771771252
(Previous) Eval Time (s)     20.020134875085205
Sample Time (s)              22.175148140639067
Epoch Time (s)               86.2837607334368
Total Train Time (s)         19101.101321168244
Epoch                        240
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:06:41.047676 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #240 | Epoch Duration: 81.92183661460876
2020-01-11 06:06:41.047799 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #240 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01164008
Z variance train             0.0062793186
KL Divergence                10.379103
KL Loss                      1.0379103
QF Loss                      459.6925
VF Loss                      269.9345
Policy Loss                  -1402.2992
Q Predictions Mean           1405.2229
Q Predictions Std            277.67337
Q Predictions Max            1637.8068
Q Predictions Min            -13.336756
V Predictions Mean           1400.388
V Predictions Std            276.31735
V Predictions Max            1613.7102
V Predictions Min            2.20267
Log Pis Mean                 0.3033645
Log Pis Std                  2.0806837
Log Pis Max                  10.916868
Log Pis Min                  -4.194953
Policy mu Mean               0.49234962
Policy mu Std                0.8947656
Policy mu Max                3.6774197
Policy mu Min                -3.13118
Policy log std Mean          -0.5103445
Policy log std Std           0.19189139
Policy log std Max           0.0027281344
Policy log std Min           -1.2276442
Z mean eval                  0.015316868
Z variance eval              0.005616518
total_rewards                [1066.41087795 1078.94995495 1256.15193403 1051.68344193 1077.77416635
 1085.62987411 1674.43869547 1034.23951969 1577.1332418  1032.44957775]
total_rewards_mean           1193.4861284022547
total_rewards_std            225.41442313292958
total_rewards_max            1674.438695467168
total_rewards_min            1032.449577751035
Number of train steps total  242000
Number of env steps total    1212000
Number of rollouts total     0
Train Time (s)               44.00463167903945
(Previous) Eval Time (s)     15.657989230938256
Sample Time (s)              21.517394182737917
Epoch Time (s)               81.18001509271562
Total Train Time (s)         19178.358314523473
Epoch                        241
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:07:58.306536 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #241 | Epoch Duration: 77.25864624977112
2020-01-11 06:07:58.306655 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #241 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015085973
Z variance train             0.0056175455
KL Divergence                10.626184
KL Loss                      1.0626185
QF Loss                      182.01155
VF Loss                      147.44275
Policy Loss                  -1406.3046
Q Predictions Mean           1404.6222
Q Predictions Std            263.14685
Q Predictions Max            1636.0258
Q Predictions Min            -2.639472
V Predictions Mean           1411.072
V Predictions Std            257.53073
V Predictions Max            1640.0608
V Predictions Min            13.048878
Log Pis Mean                 -0.26419702
Log Pis Std                  2.0140097
Log Pis Max                  11.117907
Log Pis Min                  -5.179428
Policy mu Mean               0.14811923
Policy mu Std                0.85314155
Policy mu Max                4.1075315
Policy mu Min                -2.9504895
Policy log std Mean          -0.46621045
Policy log std Std           0.19667827
Policy log std Max           0.08411974
Policy log std Min           -1.432195
Z mean eval                  0.012337999
Z variance eval              0.0052126357
total_rewards                [1264.2129105  2800.33900748 2709.35685919 1119.63466514 3241.06751723
 1337.04028621 1060.91700205 3036.74536593 1941.29520084 2318.72738916]
total_rewards_mean           2082.9336203722182
total_rewards_std            802.0530523545249
total_rewards_max            3241.0675172341644
total_rewards_min            1060.9170020522902
Number of train steps total  243000
Number of env steps total    1217000
Number of rollouts total     0
Train Time (s)               43.59529865020886
(Previous) Eval Time (s)     11.736374730244279
Sample Time (s)              22.37194906314835
Epoch Time (s)               77.70362244360149
Total Train Time (s)         19263.59582045907
Epoch                        242
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:09:23.547177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #242 | Epoch Duration: 85.24041366577148
2020-01-11 06:09:23.547360 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #242 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012111683
Z variance train             0.0052143065
KL Divergence                10.773299
KL Loss                      1.07733
QF Loss                      2176.2605
VF Loss                      222.75069
Policy Loss                  -1405.5657
Q Predictions Mean           1403.3599
Q Predictions Std            251.25447
Q Predictions Max            1630.222
Q Predictions Min            7.8156977
V Predictions Mean           1403.564
V Predictions Std            247.09947
V Predictions Max            1640.2137
V Predictions Min            3.8329763
Log Pis Mean                 -0.45469153
Log Pis Std                  2.0185366
Log Pis Max                  12.951206
Log Pis Min                  -4.555563
Policy mu Mean               0.018026557
Policy mu Std                0.8382526
Policy mu Max                2.6783044
Policy mu Min                -4.0824895
Policy log std Mean          -0.45792982
Policy log std Std           0.20303416
Policy log std Max           0.014925957
Policy log std Min           -1.6532519
Z mean eval                  0.033665027
Z variance eval              0.0051673325
total_rewards                [1601.42477627 1094.85910434 1023.78322691 2767.24317772 1064.05758148
 1165.4437566  1681.77926418 1171.74857076 2826.67436288 1107.94331042]
total_rewards_mean           1550.495713155377
total_rewards_std            658.646743975388
total_rewards_max            2826.6743628838567
total_rewards_min            1023.7832269093949
Number of train steps total  244000
Number of env steps total    1222000
Number of rollouts total     0
Train Time (s)               44.48531526559964
(Previous) Eval Time (s)     19.27288953680545
Sample Time (s)              22.47244831826538
Epoch Time (s)               86.23065312067047
Total Train Time (s)         19345.532002367545
Epoch                        243
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:10:45.485007 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #243 | Epoch Duration: 81.9375147819519
2020-01-11 06:10:45.485144 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #243 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033997692
Z variance train             0.0051710596
KL Divergence                10.748179
KL Loss                      1.074818
QF Loss                      117.909966
VF Loss                      166.68864
Policy Loss                  -1411.3143
Q Predictions Mean           1414.2358
Q Predictions Std            260.22894
Q Predictions Max            1642.2766
Q Predictions Min            7.5943875
V Predictions Mean           1418.2761
V Predictions Std            259.87192
V Predictions Max            1638.8958
V Predictions Min            18.58233
Log Pis Mean                 -0.16418824
Log Pis Std                  2.6719267
Log Pis Max                  25.898558
Log Pis Min                  -8.755741
Policy mu Mean               0.074399546
Policy mu Std                0.92699146
Policy mu Max                5.234191
Policy mu Min                -6.922205
Policy log std Mean          -0.47270557
Policy log std Std           0.20473714
Policy log std Max           0.097857654
Policy log std Min           -1.2830653
Z mean eval                  0.020558504
Z variance eval              0.005669407
total_rewards                [1617.70977461 1218.4722699  3355.07771102 1128.43854575  949.63744559
 3358.48674939 1989.98142174 1106.1761519  1075.1522165  1180.30599342]
total_rewards_mean           1697.9438279805624
total_rewards_std            878.3745183348877
total_rewards_max            3358.4867493867205
total_rewards_min            949.6374455865495
Number of train steps total  245000
Number of env steps total    1227000
Number of rollouts total     0
Train Time (s)               44.320155404973775
(Previous) Eval Time (s)     14.979508527554572
Sample Time (s)              21.960259318817407
Epoch Time (s)               81.25992325134575
Total Train Time (s)         19428.54820589302
Epoch                        244
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:12:08.508080 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #244 | Epoch Duration: 83.02281403541565
2020-01-11 06:12:08.508206 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #244 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021391405
Z variance train             0.0056754653
KL Divergence                10.502852
KL Loss                      1.0502852
QF Loss                      114.30642
VF Loss                      57.127327
Policy Loss                  -1400.8243
Q Predictions Mean           1401.5405
Q Predictions Std            265.035
Q Predictions Max            1628.5776
Q Predictions Min            -12.047842
V Predictions Mean           1399.7203
V Predictions Std            264.8007
V Predictions Max            1615.2656
V Predictions Min            -5.6295958
Log Pis Mean                 -0.33271435
Log Pis Std                  1.8384812
Log Pis Max                  5.700668
Log Pis Min                  -5.6673536
Policy mu Mean               0.05413817
Policy mu Std                0.8574657
Policy mu Max                2.23934
Policy mu Min                -3.525137
Policy log std Mean          -0.47614
Policy log std Std           0.18592858
Policy log std Max           0.0068015456
Policy log std Min           -1.3310509
Z mean eval                  0.04779982
Z variance eval              0.005799531
total_rewards                [1058.88969811 3398.58546949 1088.6318617  1034.19928647 1048.72184119
 1602.38145977  973.31352597 3372.60087602 2757.90412338 3303.20761035]
total_rewards_mean           1963.8435752452388
total_rewards_std            1042.3980814791496
total_rewards_max            3398.585469493072
total_rewards_min            973.3135259735691
Number of train steps total  246000
Number of env steps total    1232000
Number of rollouts total     0
Train Time (s)               44.1132493969053
(Previous) Eval Time (s)     16.742116386070848
Sample Time (s)              22.394707740750164
Epoch Time (s)               83.25007352372631
Total Train Time (s)         19514.48256113194
Epoch                        245
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:13:34.446598 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #245 | Epoch Duration: 85.93827557563782
2020-01-11 06:13:34.446807 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #245 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047576778
Z variance train             0.005799199
KL Divergence                10.431485
KL Loss                      1.0431485
QF Loss                      222.42029
VF Loss                      138.44357
Policy Loss                  -1396.1804
Q Predictions Mean           1396.3623
Q Predictions Std            349.5818
Q Predictions Max            1662.753
Q Predictions Min            -7.6186457
V Predictions Mean           1399.78
V Predictions Std            350.06155
V Predictions Max            1660.9725
V Predictions Min            -14.443803
Log Pis Mean                 -0.46639374
Log Pis Std                  1.9852093
Log Pis Max                  7.595132
Log Pis Min                  -5.9682093
Policy mu Mean               0.066350944
Policy mu Std                0.81052166
Policy mu Max                2.448742
Policy mu Min                -2.7688255
Policy log std Mean          -0.46851906
Policy log std Std           0.18774389
Policy log std Max           0.10258144
Policy log std Min           -1.2659717
Z mean eval                  0.012673994
Z variance eval              0.0065410347
total_rewards                [ 996.80490387 1076.53485864 1103.25715872  755.13280197 1691.57483473
 1000.68599784 1197.5407006  1041.06652515 1029.22682852 3443.20029943]
total_rewards_mean           1333.5024909485924
total_rewards_std            738.465814049693
total_rewards_max            3443.200299433523
total_rewards_min            755.1328019738286
Number of train steps total  247000
Number of env steps total    1237000
Number of rollouts total     0
Train Time (s)               44.61469912528992
(Previous) Eval Time (s)     19.430047732312232
Sample Time (s)              23.048122942913324
Epoch Time (s)               87.09286980051547
Total Train Time (s)         19595.120175004005
Epoch                        246
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:14:55.086417 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #246 | Epoch Duration: 80.63944149017334
2020-01-11 06:14:55.086593 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #246 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012623343
Z variance train             0.0065415404
KL Divergence                10.203417
KL Loss                      1.0203418
QF Loss                      140.3569
VF Loss                      115.43907
Policy Loss                  -1404.5471
Q Predictions Mean           1403.7144
Q Predictions Std            219.24483
Q Predictions Max            1612.0574
Q Predictions Min            5.812165
V Predictions Mean           1402.2517
V Predictions Std            218.70021
V Predictions Max            1607.9197
V Predictions Min            5.2635117
Log Pis Mean                 -0.28822377
Log Pis Std                  1.8871441
Log Pis Max                  9.291773
Log Pis Min                  -5.3429594
Policy mu Mean               0.22237028
Policy mu Std                0.85270476
Policy mu Max                2.968185
Policy mu Min                -2.7136507
Policy log std Mean          -0.47649312
Policy log std Std           0.18576382
Policy log std Max           0.02565229
Policy log std Min           -1.2010255
Z mean eval                  0.03620463
Z variance eval              0.006281513
total_rewards                [ 942.82570616  943.85933759 1650.97126495 1071.41518658 2201.58798266
 1043.52904523 1096.07848115  983.75957493 1646.17700068 1028.8840607 ]
total_rewards_mean           1260.9087640627645
total_rewards_std            403.50128225655436
total_rewards_max            2201.587982656383
total_rewards_min            942.8257061613241
Number of train steps total  248000
Number of env steps total    1242000
Number of rollouts total     0
Train Time (s)               44.898712780792266
(Previous) Eval Time (s)     12.976375581230968
Sample Time (s)              22.24879550607875
Epoch Time (s)               80.12388386810198
Total Train Time (s)         19674.75672171358
Epoch                        247
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:16:14.724752 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #247 | Epoch Duration: 79.63803100585938
2020-01-11 06:16:14.724888 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #247 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0371337
Z variance train             0.00628827
KL Divergence                10.30182
KL Loss                      1.030182
QF Loss                      217.7851
VF Loss                      69.10232
Policy Loss                  -1394.4407
Q Predictions Mean           1390.0044
Q Predictions Std            301.2303
Q Predictions Max            1615.0603
Q Predictions Min            4.712081
V Predictions Mean           1391.4152
V Predictions Std            298.72427
V Predictions Max            1617.6274
V Predictions Min            7.755002
Log Pis Mean                 -0.42915037
Log Pis Std                  2.2879515
Log Pis Max                  16.724323
Log Pis Min                  -5.6963506
Policy mu Mean               0.07240395
Policy mu Std                0.88672775
Policy mu Max                3.9681087
Policy mu Min                -5.121408
Policy log std Mean          -0.470232
Policy log std Std           0.19525608
Policy log std Max           0.0070111156
Policy log std Min           -1.3499329
Z mean eval                  0.014550736
Z variance eval              0.0054671294
total_rewards                [1060.2466586  2129.46651562 2778.13320968 3295.90490926 3372.45093474
 2820.30877468 3309.38068991 3343.23461338 1289.28549005 1296.94549798]
total_rewards_mean           2469.535729389364
total_rewards_std            897.4857410952378
total_rewards_max            3372.450934739943
total_rewards_min            1060.2466585964864
Number of train steps total  249000
Number of env steps total    1247000
Number of rollouts total     0
Train Time (s)               44.52698839874938
(Previous) Eval Time (s)     12.490264493972063
Sample Time (s)              22.058240048587322
Epoch Time (s)               79.07549294130877
Total Train Time (s)         19765.843822806142
Epoch                        248
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:17:45.815260 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #248 | Epoch Duration: 91.09027338027954
2020-01-11 06:17:45.815382 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #248 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014440109
Z variance train             0.0054673054
KL Divergence                10.637676
KL Loss                      1.0637677
QF Loss                      474.16943
VF Loss                      1650.5969
Policy Loss                  -1396.283
Q Predictions Mean           1397.1816
Q Predictions Std            281.5792
Q Predictions Max            1617.5715
Q Predictions Min            10.658552
V Predictions Mean           1394.0637
V Predictions Std            284.2121
V Predictions Max            1621.5663
V Predictions Min            8.840793
Log Pis Mean                 -0.40941083
Log Pis Std                  2.1679673
Log Pis Max                  16.568499
Log Pis Min                  -7.059907
Policy mu Mean               0.057038117
Policy mu Std                0.85304916
Policy mu Max                4.3014884
Policy mu Min                -5.162709
Policy log std Mean          -0.4549698
Policy log std Std           0.19762023
Policy log std Max           0.15529609
Policy log std Min           -1.552906
Z mean eval                  0.03165405
Z variance eval              0.0054059564
total_rewards                [2350.83734743 1931.16401833 3323.54217615 3356.45421076 3108.28307643
 3368.73678303 1588.59709794 3432.00270472 3356.97591762 3011.39239611]
total_rewards_mean           2882.7985728521967
total_rewards_std            641.2595438002085
total_rewards_max            3432.002704718272
total_rewards_min            1588.5970979385145
Number of train steps total  250000
Number of env steps total    1252000
Number of rollouts total     0
Train Time (s)               43.230359143577516
(Previous) Eval Time (s)     24.504811499733478
Sample Time (s)              22.376473469194025
Epoch Time (s)               90.11164411250502
Total Train Time (s)         19859.41178077925
Epoch                        249
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:19:19.384648 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #249 | Epoch Duration: 93.5691728591919
2020-01-11 06:19:19.384773 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #249 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03231845
Z variance train             0.005403714
KL Divergence                10.684814
KL Loss                      1.0684814
QF Loss                      157.28519
VF Loss                      117.61796
Policy Loss                  -1463.6626
Q Predictions Mean           1464.1865
Q Predictions Std            198.41544
Q Predictions Max            1657.4388
Q Predictions Min            101.11472
V Predictions Mean           1464.7783
V Predictions Std            194.98645
V Predictions Max            1648.1106
V Predictions Min            111.19637
Log Pis Mean                 -0.4032808
Log Pis Std                  1.987895
Log Pis Max                  10.687009
Log Pis Min                  -5.9517517
Policy mu Mean               0.26133826
Policy mu Std                0.8071741
Policy mu Max                3.06934
Policy mu Min                -2.8819804
Policy log std Mean          -0.45794833
Policy log std Std           0.18324022
Policy log std Max           0.14317513
Policy log std Min           -1.1842716
Z mean eval                  0.025130656
Z variance eval              0.0050231568
total_rewards                [1547.68129818 3177.8460714  1288.83123561 3140.47152508 1009.84655688
 3086.57176331 1190.09929125 1486.6621301  2603.16935404 2575.51490927]
total_rewards_mean           2110.6694135120792
total_rewards_std            839.726166133604
total_rewards_max            3177.8460714012426
total_rewards_min            1009.8465568839363
Number of train steps total  251000
Number of env steps total    1257000
Number of rollouts total     0
Train Time (s)               42.943413723260164
(Previous) Eval Time (s)     27.962087999563664
Sample Time (s)              22.092584413010627
Epoch Time (s)               92.99808613583446
Total Train Time (s)         19946.156150917523
Epoch                        250
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:20:46.132977 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #250 | Epoch Duration: 86.74809908866882
2020-01-11 06:20:46.133139 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #250 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025904547
Z variance train             0.005016298
KL Divergence                10.881938
KL Loss                      1.0881938
QF Loss                      252.95926
VF Loss                      132.44623
Policy Loss                  -1386.7241
Q Predictions Mean           1391.3218
Q Predictions Std            312.99893
Q Predictions Max            1642.3077
Q Predictions Min            -11.853959
V Predictions Mean           1389.6274
V Predictions Std            307.97217
V Predictions Max            1640.6489
V Predictions Min            3.9329934
Log Pis Mean                 -0.34363472
Log Pis Std                  2.190363
Log Pis Max                  13.0853615
Log Pis Min                  -5.617117
Policy mu Mean               0.09086689
Policy mu Std                0.8608685
Policy mu Max                3.6781461
Policy mu Min                -4.122481
Policy log std Mean          -0.4672235
Policy log std Std           0.21134396
Policy log std Max           0.03207922
Policy log std Min           -1.557446
Z mean eval                  0.023363914
Z variance eval              0.004975006
total_rewards                [3246.48019949 1154.22421761 1143.39529147 3019.7710259  2394.47267496
 1383.32153802 3194.08994464 1709.15953057 1880.28905949 3251.99382609]
total_rewards_mean           2237.7197308251043
total_rewards_std            842.9594694083222
total_rewards_max            3251.9938260937365
total_rewards_min            1143.3952914707913
Number of train steps total  252000
Number of env steps total    1262000
Number of rollouts total     0
Train Time (s)               44.19451269507408
(Previous) Eval Time (s)     21.711840831674635
Sample Time (s)              21.97817477909848
Epoch Time (s)               87.8845283058472
Total Train Time (s)         20032.908672864083
Epoch                        251
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:22:12.889816 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #251 | Epoch Duration: 86.75655150413513
2020-01-11 06:22:12.889970 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #251 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024185743
Z variance train             0.004971801
KL Divergence                10.928394
KL Loss                      1.0928395
QF Loss                      525.58026
VF Loss                      84.78343
Policy Loss                  -1381.6733
Q Predictions Mean           1381.2094
Q Predictions Std            292.21954
Q Predictions Max            1611.7156
Q Predictions Min            5.099703
V Predictions Mean           1380.5046
V Predictions Std            293.9663
V Predictions Max            1618.2913
V Predictions Min            -1.7242563
Log Pis Mean                 -0.12678568
Log Pis Std                  2.0510511
Log Pis Max                  9.491777
Log Pis Min                  -4.3861876
Policy mu Mean               0.14474727
Policy mu Std                0.8735942
Policy mu Max                3.172075
Policy mu Min                -3.5017114
Policy log std Mean          -0.47699475
Policy log std Std           0.20196466
Policy log std Max           -0.0023228526
Policy log std Min           -1.4548955
Z mean eval                  0.025535535
Z variance eval              0.005130503
total_rewards                [ 973.73470485 1046.37094933 2020.91804512 1095.18308825 1343.14585924
  230.37234025 1656.25897929 1032.28468294 1083.72897738 2189.58784935]
total_rewards_mean           1267.158547601939
total_rewards_std            538.921187861452
total_rewards_max            2189.5878493536793
total_rewards_min            230.37234025000532
Number of train steps total  253000
Number of env steps total    1267000
Number of rollouts total     0
Train Time (s)               43.5093941683881
(Previous) Eval Time (s)     20.583632573019713
Sample Time (s)              21.58637573523447
Epoch Time (s)               85.67940247664228
Total Train Time (s)         20109.685059281066
Epoch                        252
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:23:29.669809 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #252 | Epoch Duration: 76.77971458435059
2020-01-11 06:23:29.669965 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #252 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024925137
Z variance train             0.0051322496
KL Divergence                10.8295
KL Loss                      1.08295
QF Loss                      113.63004
VF Loss                      113.35526
Policy Loss                  -1432.5093
Q Predictions Mean           1430.9104
Q Predictions Std            163.44434
Q Predictions Max            1615.5023
Q Predictions Min            140.92972
V Predictions Mean           1434.5054
V Predictions Std            163.07233
V Predictions Max            1617.072
V Predictions Min            111.93179
Log Pis Mean                 -0.1345298
Log Pis Std                  1.8032064
Log Pis Max                  6.526406
Log Pis Min                  -5.410279
Policy mu Mean               0.15462743
Policy mu Std                0.85552686
Policy mu Max                3.0355606
Policy mu Min                -2.9303572
Policy log std Mean          -0.4772694
Policy log std Std           0.18299945
Policy log std Max           0.040554494
Policy log std Min           -1.2006605
Z mean eval                  0.023085585
Z variance eval              0.004301842
total_rewards                [1750.03320656 1124.90781031 1074.65504505 2427.02372207 3372.41007544
 3382.11656067 1016.99306174 1868.02178752  860.66627829 3400.46393928]
total_rewards_mean           2027.7291486925108
total_rewards_std            994.7889370410509
total_rewards_max            3400.463939276868
total_rewards_min            860.6662782915499
Number of train steps total  254000
Number of env steps total    1272000
Number of rollouts total     0
Train Time (s)               43.93464117962867
(Previous) Eval Time (s)     11.68369119707495
Sample Time (s)              22.10912109259516
Epoch Time (s)               77.72745346929878
Total Train Time (s)         20195.702575333882
Epoch                        253
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:24:55.689200 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #253 | Epoch Duration: 86.01911926269531
2020-01-11 06:24:55.689321 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #253 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022307556
Z variance train             0.0042987457
KL Divergence                11.245939
KL Loss                      1.124594
QF Loss                      281.05344
VF Loss                      270.42218
Policy Loss                  -1409.5173
Q Predictions Mean           1411.0925
Q Predictions Std            288.92828
Q Predictions Max            1635.0988
Q Predictions Min            -7.247744
V Predictions Mean           1418.3638
V Predictions Std            288.98642
V Predictions Max            1643.7158
V Predictions Min            -18.797821
Log Pis Mean                 -0.29775235
Log Pis Std                  2.0318625
Log Pis Max                  11.573058
Log Pis Min                  -6.234092
Policy mu Mean               0.15921684
Policy mu Std                0.8337675
Policy mu Max                2.6307273
Policy mu Min                -3.0423121
Policy log std Mean          -0.43944272
Policy log std Std           0.19538794
Policy log std Max           0.06903499
Policy log std Min           -1.4643621
Z mean eval                  0.010893904
Z variance eval              0.0038914655
total_rewards                [1255.98395624 2179.32247488 1239.01129409 2100.54794053 2593.88235936
 1174.87561463 3313.50685735 3264.88326578 3274.50734308 3184.16545144]
total_rewards_mean           2358.0686557379804
total_rewards_std            853.1220154478103
total_rewards_max            3313.5068573476055
total_rewards_min            1174.8756146279777
Number of train steps total  255000
Number of env steps total    1277000
Number of rollouts total     0
Train Time (s)               43.722310966812074
(Previous) Eval Time (s)     19.975110473111272
Sample Time (s)              22.145249709952623
Epoch Time (s)               85.84267114987597
Total Train Time (s)         20284.205796604976
Epoch                        254
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:26:24.195293 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #254 | Epoch Duration: 88.5058662891388
2020-01-11 06:26:24.195467 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #254 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011086327
Z variance train             0.0038898985
KL Divergence                11.467127
KL Loss                      1.1467127
QF Loss                      141.67197
VF Loss                      77.81264
Policy Loss                  -1462.2693
Q Predictions Mean           1462.3876
Q Predictions Std            202.78339
Q Predictions Max            1643.7837
Q Predictions Min            8.522137
V Predictions Mean           1459.7966
V Predictions Std            200.37692
V Predictions Max            1637.0743
V Predictions Min            13.59242
Log Pis Mean                 -0.26111907
Log Pis Std                  2.1423135
Log Pis Max                  15.558127
Log Pis Min                  -6.426102
Policy mu Mean               0.16627975
Policy mu Std                0.87130576
Policy mu Max                4.2888393
Policy mu Min                -3.048169
Policy log std Mean          -0.4754763
Policy log std Std           0.17757545
Policy log std Max           -0.03349501
Policy log std Min           -1.1669589
Z mean eval                  0.03251163
Z variance eval              0.0039229905
total_rewards                [1100.27764951 3448.17470322 1088.41251273 1031.41380558 1318.70632376
 1440.36471697 1137.69535757 2407.4556313  1770.16101311 1377.25450871]
total_rewards_mean           1611.991622244867
total_rewards_std            727.8692360477866
total_rewards_max            3448.1747032151625
total_rewards_min            1031.4138055790559
Number of train steps total  256000
Number of env steps total    1282000
Number of rollouts total     0
Train Time (s)               43.590130783151835
(Previous) Eval Time (s)     22.63805220508948
Sample Time (s)              21.015120401978493
Epoch Time (s)               87.24330339021981
Total Train Time (s)         20362.926839875057
Epoch                        255
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:27:42.917721 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #255 | Epoch Duration: 78.72212982177734
2020-01-11 06:27:42.917849 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #255 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03298801
Z variance train             0.0039224005
KL Divergence                11.447966
KL Loss                      1.1447966
QF Loss                      232.47324
VF Loss                      98.26904
Policy Loss                  -1443.523
Q Predictions Mean           1441.7583
Q Predictions Std            252.58174
Q Predictions Max            1648.0475
Q Predictions Min            6.921396
V Predictions Mean           1442.9595
V Predictions Std            250.31409
V Predictions Max            1655.7095
V Predictions Min            17.257753
Log Pis Mean                 -0.32996994
Log Pis Std                  1.8668325
Log Pis Max                  8.569384
Log Pis Min                  -5.130183
Policy mu Mean               0.013552114
Policy mu Std                0.8224526
Policy mu Max                3.2069426
Policy mu Min                -3.1441426
Policy log std Mean          -0.47648898
Policy log std Std           0.19043864
Policy log std Max           0.031688333
Policy log std Min           -1.2357253
Z mean eval                  0.01655155
Z variance eval              0.0035317824
total_rewards                [2589.88157401 1089.06397786 1069.04225733 1670.46081176 1370.62815784
 3331.88380555 3363.08792614 1888.27057779 3408.72171444 1242.62497552]
total_rewards_mean           2102.366577823752
total_rewards_std            929.8861910078656
total_rewards_max            3408.721714443412
total_rewards_min            1069.0422573347719
Number of train steps total  257000
Number of env steps total    1287000
Number of rollouts total     0
Train Time (s)               43.37632720824331
(Previous) Eval Time (s)     14.116653360892087
Sample Time (s)              20.061700381804258
Epoch Time (s)               77.55468095093966
Total Train Time (s)         20447.09754140675
Epoch                        256
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:29:07.090539 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #256 | Epoch Duration: 84.17259049415588
2020-01-11 06:29:07.090663 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #256 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015874885
Z variance train             0.0035308704
KL Divergence                11.735113
KL Loss                      1.1735114
QF Loss                      195.66481
VF Loss                      607.22797
Policy Loss                  -1444.2668
Q Predictions Mean           1449.7605
Q Predictions Std            215.85875
Q Predictions Max            1638.158
Q Predictions Min            -1.756247
V Predictions Mean           1463.7081
V Predictions Std            216.48633
V Predictions Max            1645.2733
V Predictions Min            5.3919873
Log Pis Mean                 -0.23203364
Log Pis Std                  1.951224
Log Pis Max                  6.673464
Log Pis Min                  -5.1604924
Policy mu Mean               0.071561925
Policy mu Std                0.85207206
Policy mu Max                2.5765946
Policy mu Min                -2.9976642
Policy log std Mean          -0.4922459
Policy log std Std           0.18829755
Policy log std Max           -0.03985268
Policy log std Min           -1.2345972
Z mean eval                  0.0205531
Z variance eval              0.0035629538
total_rewards                [3335.7541387   811.53535963 1428.24374247 1056.1452314  3359.83318511
 3361.6606513  2533.91977868 1177.50998847  877.19082388 1079.94840959]
total_rewards_mean           1902.1741309241163
total_rewards_std            1053.1275754083374
total_rewards_max            3361.660651297444
total_rewards_min            811.5353596303272
Number of train steps total  258000
Number of env steps total    1292000
Number of rollouts total     0
Train Time (s)               43.53271908080205
(Previous) Eval Time (s)     20.73436272703111
Sample Time (s)              22.154805037193
Epoch Time (s)               86.42188684502617
Total Train Time (s)         20530.674839081243
Epoch                        257
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:30:30.669505 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #257 | Epoch Duration: 83.57875061035156
2020-01-11 06:30:30.669627 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #257 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02130974
Z variance train             0.0035581538
KL Divergence                11.826263
KL Loss                      1.1826264
QF Loss                      85.467316
VF Loss                      72.0246
Policy Loss                  -1468.8783
Q Predictions Mean           1467.4069
Q Predictions Std            181.45882
Q Predictions Max            1650.2837
Q Predictions Min            357.2202
V Predictions Mean           1464.751
V Predictions Std            181.157
V Predictions Max            1650.8081
V Predictions Min            354.45
Log Pis Mean                 -0.37521523
Log Pis Std                  1.6650189
Log Pis Max                  7.286339
Log Pis Min                  -3.9859135
Policy mu Mean               0.12897776
Policy mu Std                0.7700954
Policy mu Max                2.534926
Policy mu Min                -2.9161153
Policy log std Mean          -0.48075986
Policy log std Std           0.18527922
Policy log std Max           -0.03557864
Policy log std Min           -1.2789394
Z mean eval                  0.017470915
Z variance eval              0.0038304955
total_rewards                [1415.16132019 1076.12798298  766.66999566  606.71721341  891.93906203
 1105.03052611 1068.02883269 3479.51299199  949.51982231 1092.01704027]
total_rewards_mean           1245.0724787645709
total_rewards_std            772.8518613259879
total_rewards_max            3479.5129919915853
total_rewards_min            606.7172134094952
Number of train steps total  259000
Number of env steps total    1297000
Number of rollouts total     0
Train Time (s)               43.651024849154055
(Previous) Eval Time (s)     17.89101221319288
Sample Time (s)              21.067363837733865
Epoch Time (s)               82.6094009000808
Total Train Time (s)         20606.351758045144
Epoch                        258
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:31:46.352291 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #258 | Epoch Duration: 75.68255305290222
2020-01-11 06:31:46.352474 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #258 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017776797
Z variance train             0.0038256433
KL Divergence                11.438848
KL Loss                      1.1438848
QF Loss                      100.66781
VF Loss                      71.15535
Policy Loss                  -1451.978
Q Predictions Mean           1451.8826
Q Predictions Std            224.27914
Q Predictions Max            1632.8043
Q Predictions Min            5.0590863
V Predictions Mean           1453.8899
V Predictions Std            222.65256
V Predictions Max            1635.9513
V Predictions Min            5.7912
Log Pis Mean                 -0.3238157
Log Pis Std                  1.8784436
Log Pis Max                  7.9315586
Log Pis Min                  -4.421927
Policy mu Mean               0.12141801
Policy mu Std                0.807409
Policy mu Max                3.4556584
Policy mu Min                -2.5766292
Policy log std Mean          -0.47496402
Policy log std Std           0.19051772
Policy log std Max           -0.0722128
Policy log std Min           -1.5107865
Z mean eval                  0.019126944
Z variance eval              0.004014209
total_rewards                [2893.60883703 1082.0428259  2549.28383825 1937.21596105 3342.65929869
 3301.21136715 3328.95783416 1118.49509834 3288.42873911 1914.10759474]
total_rewards_mean           2475.6011394403063
total_rewards_std            859.7303769935272
total_rewards_max            3342.659298691417
total_rewards_min            1082.042825895193
Number of train steps total  260000
Number of env steps total    1302000
Number of rollouts total     0
Train Time (s)               44.37857221392915
(Previous) Eval Time (s)     10.963938034139574
Sample Time (s)              22.002288688439876
Epoch Time (s)               77.3447989365086
Total Train Time (s)         20695.103849689942
Epoch                        259
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:33:15.107264 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #259 | Epoch Duration: 88.75464081764221
2020-01-11 06:33:15.107451 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #259 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017966747
Z variance train             0.0040094764
KL Divergence                11.341615
KL Loss                      1.1341615
QF Loss                      205.14017
VF Loss                      135.68788
Policy Loss                  -1456.3263
Q Predictions Mean           1458.3123
Q Predictions Std            235.53558
Q Predictions Max            1652.7233
Q Predictions Min            -0.79195863
V Predictions Mean           1448.262
V Predictions Std            233.78896
V Predictions Max            1642.0922
V Predictions Min            5.24648
Log Pis Mean                 -0.20100744
Log Pis Std                  1.8710853
Log Pis Max                  6.4750977
Log Pis Min                  -3.895576
Policy mu Mean               0.05393244
Policy mu Std                0.88961667
Policy mu Max                2.6357574
Policy mu Min                -3.1240985
Policy log std Mean          -0.45896998
Policy log std Std           0.19126798
Policy log std Max           -0.012785822
Policy log std Min           -1.4416186
Z mean eval                  0.021218488
Z variance eval              0.005753708
total_rewards                [1293.80367238 3358.68769843 1866.07665577 3321.09159937 2544.68519999
 2901.29418259 2862.86101545 3404.83360517 1076.88865119 1074.04521762]
total_rewards_mean           2370.426749796312
total_rewards_std            909.5290431632205
total_rewards_max            3404.8336051653996
total_rewards_min            1074.0452176217054
Number of train steps total  261000
Number of env steps total    1307000
Number of rollouts total     0
Train Time (s)               43.72826918680221
(Previous) Eval Time (s)     22.37353354599327
Sample Time (s)              22.237746360246092
Epoch Time (s)               88.33954909304157
Total Train Time (s)         20782.72408761736
Epoch                        260
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:34:42.729033 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #260 | Epoch Duration: 87.62145042419434
2020-01-11 06:34:42.729167 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #260 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020944247
Z variance train             0.005758908
KL Divergence                10.556215
KL Loss                      1.0556215
QF Loss                      151.55183
VF Loss                      83.40996
Policy Loss                  -1440.5652
Q Predictions Mean           1443.7256
Q Predictions Std            278.59097
Q Predictions Max            1663.0756
Q Predictions Min            -27.565582
V Predictions Mean           1439.7336
V Predictions Std            277.34534
V Predictions Max            1660.5327
V Predictions Min            0.34406203
Log Pis Mean                 -0.32310575
Log Pis Std                  1.7077228
Log Pis Max                  5.7418284
Log Pis Min                  -4.6660576
Policy mu Mean               0.039013434
Policy mu Std                0.8413438
Policy mu Max                2.5127273
Policy mu Min                -2.9765234
Policy log std Mean          -0.4570601
Policy log std Std           0.18484719
Policy log std Max           0.0050070286
Policy log std Min           -1.299943
Z mean eval                  0.024695037
Z variance eval              0.0057523535
total_rewards                [1896.53540491 3437.82194043 3436.23176011 3446.76629694 1237.72979573
 1353.06866989 1151.69433006 3485.2839942  1415.6605505  3444.26664381]
total_rewards_mean           2430.505938658783
total_rewards_std            1036.011747193837
total_rewards_max            3485.283994199954
total_rewards_min            1151.6943300625433
Number of train steps total  262000
Number of env steps total    1312000
Number of rollouts total     0
Train Time (s)               45.72675150912255
(Previous) Eval Time (s)     21.655193304177374
Sample Time (s)              21.513746175915003
Epoch Time (s)               88.89569098921493
Total Train Time (s)         20870.688145176973
Epoch                        261
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:36:10.695706 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #261 | Epoch Duration: 87.96642422676086
2020-01-11 06:36:10.695883 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #261 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025013294
Z variance train             0.005763191
KL Divergence                10.55451
KL Loss                      1.055451
QF Loss                      205.53732
VF Loss                      227.98393
Policy Loss                  -1447.2052
Q Predictions Mean           1444.5079
Q Predictions Std            256.6109
Q Predictions Max            1638.3824
Q Predictions Min            4.833823
V Predictions Mean           1437.5951
V Predictions Std            253.1159
V Predictions Max            1622.4266
V Predictions Min            10.533958
Log Pis Mean                 -0.38766482
Log Pis Std                  1.9487439
Log Pis Max                  14.484834
Log Pis Min                  -3.8413587
Policy mu Mean               0.097807944
Policy mu Std                0.83395964
Policy mu Max                4.3040266
Policy mu Min                -2.669325
Policy log std Mean          -0.45393026
Policy log std Std           0.18512964
Policy log std Max           -0.016544282
Policy log std Min           -1.1889353
Z mean eval                  0.029358868
Z variance eval              0.006209881
total_rewards                [3210.51430698 2909.38614378  754.14246641 1387.02219612 3252.39283802
 1744.52376686 2736.22981119 3205.51300074 3215.05071777  920.63490023]
total_rewards_mean           2333.541014809078
total_rewards_std            968.409204000416
total_rewards_max            3252.392838017637
total_rewards_min            754.1424664083316
Number of train steps total  263000
Number of env steps total    1317000
Number of rollouts total     0
Train Time (s)               43.15805828664452
(Previous) Eval Time (s)     20.72567647602409
Sample Time (s)              22.129681002814323
Epoch Time (s)               86.01341576548293
Total Train Time (s)         20958.697907883674
Epoch                        262
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:37:38.711388 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #262 | Epoch Duration: 88.01534724235535
2020-01-11 06:37:38.711597 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #262 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029596727
Z variance train             0.0062122024
KL Divergence                10.366664
KL Loss                      1.0366664
QF Loss                      164.7161
VF Loss                      75.28882
Policy Loss                  -1450.592
Q Predictions Mean           1449.4016
Q Predictions Std            174.62439
Q Predictions Max            1632.7565
Q Predictions Min            -0.75923914
V Predictions Mean           1453.014
V Predictions Std            174.59784
V Predictions Max            1634.8156
V Predictions Min            6.1412296
Log Pis Mean                 -0.45581424
Log Pis Std                  1.9357637
Log Pis Max                  9.755848
Log Pis Min                  -5.2247705
Policy mu Mean               0.14360799
Policy mu Std                0.8215278
Policy mu Max                2.8464408
Policy mu Min                -2.8126273
Policy log std Mean          -0.4609274
Policy log std Std           0.19233488
Policy log std Max           -0.055244178
Policy log std Min           -1.2969428
Z mean eval                  0.01418817
Z variance eval              0.00583703
total_rewards                [3368.29493602 3388.20966379 3338.26861053 3330.88698896 2493.27521142
 3267.91072629 3327.98657816 3347.90746217 3349.40379499 3413.28384358]
total_rewards_mean           3262.5427815924722
total_rewards_std            259.04056579263715
total_rewards_max            3413.2838435827357
total_rewards_min            2493.2752114212417
Number of train steps total  264000
Number of env steps total    1322000
Number of rollouts total     0
Train Time (s)               44.14159739809111
(Previous) Eval Time (s)     22.727364440914243
Sample Time (s)              22.78396760718897
Epoch Time (s)               89.65292944619432
Total Train Time (s)         21057.092456365004
Epoch                        263
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:39:17.108117 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #263 | Epoch Duration: 98.39637207984924
2020-01-11 06:39:17.108245 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #263 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015255625
Z variance train             0.005835143
KL Divergence                10.481537
KL Loss                      1.0481538
QF Loss                      70.284515
VF Loss                      53.058483
Policy Loss                  -1480.136
Q Predictions Mean           1475.7983
Q Predictions Std            236.09311
Q Predictions Max            1681.5001
Q Predictions Min            -4.526352
V Predictions Mean           1476.1378
V Predictions Std            235.60829
V Predictions Max            1679.5918
V Predictions Min            -7.279192
Log Pis Mean                 -0.38581836
Log Pis Std                  1.82171
Log Pis Max                  8.012297
Log Pis Min                  -5.1904507
Policy mu Mean               0.058863994
Policy mu Std                0.82358795
Policy mu Max                2.4007373
Policy mu Min                -3.0934756
Policy log std Mean          -0.46177277
Policy log std Std           0.20415989
Policy log std Max           0.027164549
Policy log std Min           -1.3668463
Z mean eval                  0.020401355
Z variance eval              0.0055464925
total_rewards                [3298.0982412  3287.9766118  1354.27771166 1132.14422318 2891.33669098
 3314.96801485 2891.88844231 3300.28759042 3320.07667609 1313.19527901]
total_rewards_mean           2610.4249481501947
total_rewards_std            895.0991838755563
total_rewards_max            3320.076676089565
total_rewards_min            1132.1442231764472
Number of train steps total  265000
Number of env steps total    1327000
Number of rollouts total     0
Train Time (s)               44.24115084996447
(Previous) Eval Time (s)     31.470560322981328
Sample Time (s)              22.005892228335142
Epoch Time (s)               97.71760340128094
Total Train Time (s)         21149.094549906906
Epoch                        264
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:40:49.112492 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #264 | Epoch Duration: 92.00413990020752
2020-01-11 06:40:49.112616 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #264 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020550456
Z variance train             0.0055449
KL Divergence                10.633336
KL Loss                      1.0633336
QF Loss                      256.38593
VF Loss                      89.32283
Policy Loss                  -1444.4257
Q Predictions Mean           1445.9849
Q Predictions Std            212.43906
Q Predictions Max            1641.9303
Q Predictions Min            43.813683
V Predictions Mean           1441.5267
V Predictions Std            210.3517
V Predictions Max            1634.28
V Predictions Min            52.080845
Log Pis Mean                 -0.23410615
Log Pis Std                  2.1208975
Log Pis Max                  10.453083
Log Pis Min                  -6.260852
Policy mu Mean               0.043500632
Policy mu Std                0.8925924
Policy mu Max                2.9798281
Policy mu Min                -2.877736
Policy log std Mean          -0.47048974
Policy log std Std           0.19453503
Policy log std Max           0.043433666
Policy log std Min           -1.1452465
Z mean eval                  0.0150171695
Z variance eval              0.0049866736
total_rewards                [1551.35966217 3401.27898116 2522.57942751 3368.8747002  3383.28459585
 3383.13715095 3362.37554678 3399.46258107 3388.11760009 3333.63899688]
total_rewards_mean           3109.410924266567
total_rewards_std            578.827512587934
total_rewards_max            3401.278981158167
total_rewards_min            1551.3596621700963
Number of train steps total  266000
Number of env steps total    1332000
Number of rollouts total     0
Train Time (s)               44.295836413279176
(Previous) Eval Time (s)     25.756845994386822
Sample Time (s)              21.909223731141537
Epoch Time (s)               91.96190613880754
Total Train Time (s)         21245.08977845963
Epoch                        265
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:42:25.109243 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #265 | Epoch Duration: 95.9965226650238
2020-01-11 06:42:25.109366 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #265 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014498599
Z variance train             0.0049831923
KL Divergence                10.846208
KL Loss                      1.0846208
QF Loss                      110.79349
VF Loss                      120.875305
Policy Loss                  -1464.4244
Q Predictions Mean           1464.23
Q Predictions Std            227.26572
Q Predictions Max            1647.0242
Q Predictions Min            -14.580218
V Predictions Mean           1465.4443
V Predictions Std            225.27855
V Predictions Max            1645.1089
V Predictions Min            6.934598
Log Pis Mean                 -0.19280034
Log Pis Std                  1.9837445
Log Pis Max                  7.6163616
Log Pis Min                  -5.299683
Policy mu Mean               0.09789323
Policy mu Std                0.86878496
Policy mu Max                2.4327397
Policy mu Min                -2.8235915
Policy log std Mean          -0.47310624
Policy log std Std           0.2111338
Policy log std Max           0.0037270784
Policy log std Min           -1.401054
Z mean eval                  0.013765177
Z variance eval              0.0047387728
total_rewards                [1115.41861732  854.94372949 1371.58328728 1852.62583268 1255.32233825
 1307.02893857 1079.24329673 3455.59008026 3494.82917247 1096.94720136]
total_rewards_mean           1688.3532494421556
total_rewards_std            926.8406301045768
total_rewards_max            3494.829172465591
total_rewards_min            854.9437294929869
Number of train steps total  267000
Number of env steps total    1337000
Number of rollouts total     0
Train Time (s)               43.25578205380589
(Previous) Eval Time (s)     29.791221170686185
Sample Time (s)              21.631549919955432
Epoch Time (s)               94.6785531444475
Total Train Time (s)         21325.432890919503
Epoch                        266
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:43:45.454678 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #266 | Epoch Duration: 80.345219373703
2020-01-11 06:43:45.454803 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #266 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013646148
Z variance train             0.0047320584
KL Divergence                11.042247
KL Loss                      1.1042247
QF Loss                      1135.7949
VF Loss                      187.76682
Policy Loss                  -1478.4465
Q Predictions Mean           1478.9232
Q Predictions Std            208.46977
Q Predictions Max            1663.4869
Q Predictions Min            8.337075
V Predictions Mean           1471.5701
V Predictions Std            204.01195
V Predictions Max            1650.6034
V Predictions Min            7.670309
Log Pis Mean                 -0.3566317
Log Pis Std                  1.9524366
Log Pis Max                  9.744076
Log Pis Min                  -4.8984547
Policy mu Mean               0.058179587
Policy mu Std                0.875758
Policy mu Max                4.1361885
Policy mu Min                -3.1966875
Policy log std Mean          -0.4554815
Policy log std Std           0.20616563
Policy log std Max           0.0016308427
Policy log std Min           -1.2578733
Z mean eval                  0.0075819604
Z variance eval              0.005767267
total_rewards                [3302.76643585 2396.25481963 3359.64810433 3347.41139712 3328.35931732
 3378.08768195 2965.5798393  3304.60232541 3338.40283401 3372.18599074]
total_rewards_mean           3209.329874565851
total_rewards_std            294.24540469157483
total_rewards_max            3378.0876819452046
total_rewards_min            2396.2548196327966
Number of train steps total  268000
Number of env steps total    1342000
Number of rollouts total     0
Train Time (s)               44.59943336574361
(Previous) Eval Time (s)     15.457648276817054
Sample Time (s)              21.83186190435663
Epoch Time (s)               81.88894354691729
Total Train Time (s)         21423.217028927524
Epoch                        267
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:45:23.245166 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #267 | Epoch Duration: 97.7902524471283
2020-01-11 06:45:23.245345 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #267 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.009533784
Z variance train             0.0057798023
KL Divergence                10.545311
KL Loss                      1.0545311
QF Loss                      5491.5347
VF Loss                      325.2544
Policy Loss                  -1469.0265
Q Predictions Mean           1471.8081
Q Predictions Std            220.79767
Q Predictions Max            1645.088
Q Predictions Min            18.076183
V Predictions Mean           1473.9489
V Predictions Std            217.3902
V Predictions Max            1637.1226
V Predictions Min            12.612349
Log Pis Mean                 -0.5263599
Log Pis Std                  1.7691903
Log Pis Max                  7.9775414
Log Pis Min                  -5.820357
Policy mu Mean               -0.06092726
Policy mu Std                0.8085733
Policy mu Max                3.40812
Policy mu Min                -2.6486466
Policy log std Mean          -0.42232838
Policy log std Std           0.20404471
Policy log std Max           0.12680432
Policy log std Min           -1.3652942
Z mean eval                  0.016826782
Z variance eval              0.0052619926
total_rewards                [1362.80622581 3311.45895055 1362.47559117  957.3817083   990.18038657
 3365.04931718 3424.3396708  1047.88059943 1085.61185849 3427.97266588]
total_rewards_mean           2033.5156974187207
total_rewards_std            1109.1338732418747
total_rewards_max            3427.972665878029
total_rewards_min            957.3817083026677
Number of train steps total  269000
Number of env steps total    1347000
Number of rollouts total     0
Train Time (s)               44.183652066625655
(Previous) Eval Time (s)     31.3587094983086
Sample Time (s)              22.039780049119145
Epoch Time (s)               97.5821416140534
Total Train Time (s)         21509.137973512523
Epoch                        268
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:46:49.167853 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #268 | Epoch Duration: 85.92237949371338
2020-01-11 06:46:49.167987 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #268 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017023476
Z variance train             0.005262524
KL Divergence                10.789046
KL Loss                      1.0789046
QF Loss                      97.167175
VF Loss                      84.06088
Policy Loss                  -1472.1896
Q Predictions Mean           1473.0629
Q Predictions Std            200.35518
Q Predictions Max            1637.2904
Q Predictions Min            2.3054092
V Predictions Mean           1479.2195
V Predictions Std            202.13666
V Predictions Max            1643.8143
V Predictions Min            0.5444301
Log Pis Mean                 -0.728395
Log Pis Std                  1.662596
Log Pis Max                  6.3108563
Log Pis Min                  -5.4439383
Policy mu Mean               0.09694034
Policy mu Std                0.7855488
Policy mu Max                1.6245056
Policy mu Min                -2.655982
Policy log std Mean          -0.41968477
Policy log std Std           0.18784916
Policy log std Max           0.035334706
Policy log std Min           -1.4489859
Z mean eval                  0.012929318
Z variance eval              0.0047602104
total_rewards                [3337.06934571 1151.69548439  987.1576736  3382.59015184 1086.74586229
 3444.58539722 3367.36912233 3416.81309773 3365.40160386 3391.6328748 ]
total_rewards_mean           2693.106061376374
total_rewards_std            1060.174576565406
total_rewards_max            3444.5853972231525
total_rewards_min            987.1576735960609
Number of train steps total  270000
Number of env steps total    1352000
Number of rollouts total     0
Train Time (s)               43.51119574997574
(Previous) Eval Time (s)     19.698722107801586
Sample Time (s)              21.440875311847776
Epoch Time (s)               84.6507931696251
Total Train Time (s)         21599.699998619035
Epoch                        269
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:48:19.731993 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #269 | Epoch Duration: 90.56390285491943
2020-01-11 06:48:19.732119 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #269 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012937373
Z variance train             0.0047616013
KL Divergence                10.995122
KL Loss                      1.0995122
QF Loss                      73.48664
VF Loss                      39.27158
Policy Loss                  -1456.9725
Q Predictions Mean           1456.2517
Q Predictions Std            237.32379
Q Predictions Max            1658.7488
Q Predictions Min            18.555433
V Predictions Mean           1454.0591
V Predictions Std            238.00772
V Predictions Max            1655.9427
V Predictions Min            3.6765707
Log Pis Mean                 -0.62011576
Log Pis Std                  1.7796404
Log Pis Max                  5.133111
Log Pis Min                  -5.815795
Policy mu Mean               0.15040495
Policy mu Std                0.7758908
Policy mu Max                2.1067092
Policy mu Min                -2.9490764
Policy log std Mean          -0.44177127
Policy log std Std           0.19858535
Policy log std Max           0.014966726
Policy log std Min           -1.2624927
Z mean eval                  0.013202605
Z variance eval              0.0047769914
total_rewards                [3261.77655883 2714.06257633 3262.47858638 1585.52681007 1511.13674053
 3250.22407777 3298.27302028 3255.59120996 3233.52839642 3247.70195939]
total_rewards_mean           2862.029993596247
total_rewards_std            676.6883102311872
total_rewards_max            3298.2730202774183
total_rewards_min            1511.1367405310177
Number of train steps total  271000
Number of env steps total    1357000
Number of rollouts total     0
Train Time (s)               43.94731139112264
(Previous) Eval Time (s)     25.61158533813432
Sample Time (s)              21.52877441002056
Epoch Time (s)               91.08767113927752
Total Train Time (s)         21694.335006531794
Epoch                        270
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:49:54.368836 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #270 | Epoch Duration: 94.63662195205688
2020-01-11 06:49:54.368957 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #270 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013207285
Z variance train             0.0047771065
KL Divergence                10.98196
KL Loss                      1.098196
QF Loss                      45.836845
VF Loss                      25.47816
Policy Loss                  -1486.4738
Q Predictions Mean           1485.1953
Q Predictions Std            164.89333
Q Predictions Max            1650.0881
Q Predictions Min            8.177234
V Predictions Mean           1485.1898
V Predictions Std            163.71469
V Predictions Max            1651.9303
V Predictions Min            6.2203097
Log Pis Mean                 -0.5438533
Log Pis Std                  1.6791495
Log Pis Max                  5.012432
Log Pis Min                  -4.558217
Policy mu Mean               0.07216095
Policy mu Std                0.8116269
Policy mu Max                1.9282811
Policy mu Min                -3.2014108
Policy log std Mean          -0.44280818
Policy log std Std           0.1921539
Policy log std Max           0.018708944
Policy log std Min           -1.3209087
Z mean eval                  0.03416139
Z variance eval              0.0051768287
total_rewards                [1303.72473609 3463.75599612 3426.95646512 1339.36177264 3374.7790661
 2719.59195764 3348.33022072 1819.13278869 3362.50237469 3401.46292516]
total_rewards_mean           2755.959830298621
total_rewards_std            863.9632098555235
total_rewards_max            3463.7559961226443
total_rewards_min            1303.7247360936315
Number of train steps total  272000
Number of env steps total    1362000
Number of rollouts total     0
Train Time (s)               43.41793708782643
(Previous) Eval Time (s)     29.160305257886648
Sample Time (s)              22.689532468561083
Epoch Time (s)               95.26777481427416
Total Train Time (s)         21786.530710527673
Epoch                        271
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:51:26.566737 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #271 | Epoch Duration: 92.1976866722107
2020-01-11 06:51:26.566863 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #271 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032638945
Z variance train             0.00517345
KL Divergence                10.796337
KL Loss                      1.0796337
QF Loss                      240.5978
VF Loss                      97.20588
Policy Loss                  -1456.6483
Q Predictions Mean           1454.8159
Q Predictions Std            257.81866
Q Predictions Max            1668.6678
Q Predictions Min            -3.2106051
V Predictions Mean           1462.7578
V Predictions Std            256.8732
V Predictions Max            1679.9702
V Predictions Min            3.9423223
Log Pis Mean                 -0.4554103
Log Pis Std                  1.8814453
Log Pis Max                  6.3049946
Log Pis Min                  -4.120413
Policy mu Mean               0.05989404
Policy mu Std                0.82299554
Policy mu Max                2.3878117
Policy mu Min                -2.8004568
Policy log std Mean          -0.4254149
Policy log std Std           0.19635835
Policy log std Max           0.11341819
Policy log std Min           -1.2454611
Z mean eval                  0.021477278
Z variance eval              0.004452334
total_rewards                [3306.49766396 3297.04713257 3293.61400521 3311.05599319 3263.10000012
 1914.44927012 3345.56210446 1000.15719925 3269.3130141  1257.19076699]
total_rewards_mean           2725.798714995712
total_rewards_std            899.4231095634442
total_rewards_max            3345.5621044606337
total_rewards_min            1000.1571992457625
Number of train steps total  273000
Number of env steps total    1367000
Number of rollouts total     0
Train Time (s)               43.835896912030876
(Previous) Eval Time (s)     26.089960461948067
Sample Time (s)              21.742079886607826
Epoch Time (s)               91.66793726058677
Total Train Time (s)         21879.42868444929
Epoch                        272
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:52:59.467343 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #272 | Epoch Duration: 92.900386095047
2020-01-11 06:52:59.467467 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #272 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021744521
Z variance train             0.004444836
KL Divergence                11.111997
KL Loss                      1.1111997
QF Loss                      480.70053
VF Loss                      279.95813
Policy Loss                  -1511.2736
Q Predictions Mean           1511.0051
Q Predictions Std            147.58992
Q Predictions Max            1678.6521
Q Predictions Min            94.9588
V Predictions Mean           1514.958
V Predictions Std            146.76006
V Predictions Max            1675.2958
V Predictions Min            93.13618
Log Pis Mean                 -0.494682
Log Pis Std                  1.5854523
Log Pis Max                  4.67634
Log Pis Min                  -4.649681
Policy mu Mean               0.088216834
Policy mu Std                0.77203953
Policy mu Max                2.0527198
Policy mu Min                -2.5070183
Policy log std Mean          -0.4430212
Policy log std Std           0.19552775
Policy log std Max           0.0074127913
Policy log std Min           -1.2535753
Z mean eval                  0.026267001
Z variance eval              0.004203904
total_rewards                [3191.09151382 3273.74815763 3209.18545769 3222.03674433 3183.25610206
 3191.57836355 3185.12852123 3248.85578763 3303.31864616 3228.10852205]
total_rewards_mean           3223.6307816154685
total_rewards_std            38.636985929035006
total_rewards_max            3303.3186461574646
total_rewards_min            3183.256102058096
Number of train steps total  274000
Number of env steps total    1372000
Number of rollouts total     0
Train Time (s)               44.71226417878643
(Previous) Eval Time (s)     27.32217744877562
Sample Time (s)              21.86613728106022
Epoch Time (s)               93.90057890862226
Total Train Time (s)         21979.020857186057
Epoch                        273
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:54:39.062108 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #273 | Epoch Duration: 99.5945303440094
2020-01-11 06:54:39.062289 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #273 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026425999
Z variance train             0.0042034667
KL Divergence                11.344856
KL Loss                      1.1344856
QF Loss                      151.41504
VF Loss                      44.824837
Policy Loss                  -1509.6857
Q Predictions Mean           1513.4583
Q Predictions Std            137.68369
Q Predictions Max            1665.392
Q Predictions Min            380.4723
V Predictions Mean           1508.7537
V Predictions Std            137.10678
V Predictions Max            1662.5072
V Predictions Min            362.12805
Log Pis Mean                 -0.5151319
Log Pis Std                  1.7754018
Log Pis Max                  5.138869
Log Pis Min                  -5.067999
Policy mu Mean               -0.0021039844
Policy mu Std                0.80799294
Policy mu Max                1.9625465
Policy mu Min                -2.9279282
Policy log std Mean          -0.44860697
Policy log std Std           0.19242766
Policy log std Max           0.004390478
Policy log std Min           -1.1943555
Z mean eval                  0.050694477
Z variance eval              0.0048032342
total_rewards                [3064.22698961 3123.64474089 3109.00834116 3132.8542753  3155.57629174
 3144.44484815 1334.77437329 3178.0421974  3155.66467156 1042.32891433]
total_rewards_mean           2744.0565643428254
total_rewards_std            781.0459052281973
total_rewards_max            3178.042197399904
total_rewards_min            1042.3289143307202
Number of train steps total  275000
Number of env steps total    1377000
Number of rollouts total     0
Train Time (s)               44.7989703589119
(Previous) Eval Time (s)     33.015879821032286
Sample Time (s)              21.618271828163415
Epoch Time (s)               99.4331220081076
Total Train Time (s)         22074.527585833333
Epoch                        274
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:56:14.570612 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #274 | Epoch Duration: 95.50819301605225
2020-01-11 06:56:14.570746 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #274 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.050330974
Z variance train             0.0048119887
KL Divergence                10.982243
KL Loss                      1.0982243
QF Loss                      137.00308
VF Loss                      128.02788
Policy Loss                  -1498.5743
Q Predictions Mean           1496.1902
Q Predictions Std            144.87459
Q Predictions Max            1659.728
Q Predictions Min            517.47314
V Predictions Mean           1495.6667
V Predictions Std            143.88466
V Predictions Max            1668.1658
V Predictions Min            553.1673
Log Pis Mean                 -0.78444123
Log Pis Std                  1.5985321
Log Pis Max                  4.944596
Log Pis Min                  -4.7099953
Policy mu Mean               0.068770505
Policy mu Std                0.7279713
Policy mu Max                1.8974974
Policy mu Min                -2.6252015
Policy log std Mean          -0.42741546
Policy log std Std           0.1975298
Policy log std Max           0.06066844
Policy log std Min           -1.1476007
Z mean eval                  0.021641113
Z variance eval              0.004869555
total_rewards                [3138.15995662 3174.9700754  3082.76553577 3093.33058638 3041.13922284
 3201.0750591  3204.33582666 1690.13190266 3109.5824969  3037.26335892]
total_rewards_mean           2977.275402125535
total_rewards_std            432.7964208229372
total_rewards_max            3204.3358266649716
total_rewards_min            1690.1319026558344
Number of train steps total  276000
Number of env steps total    1382000
Number of rollouts total     0
Train Time (s)               44.27378379786387
(Previous) Eval Time (s)     29.090723481960595
Sample Time (s)              21.92662231437862
Epoch Time (s)               95.29112959420308
Total Train Time (s)         22172.73103248235
Epoch                        275
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:57:52.779560 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #275 | Epoch Duration: 98.20870018005371
2020-01-11 06:57:52.779739 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #275 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021751642
Z variance train             0.0048675705
KL Divergence                11.02273
KL Loss                      1.102273
QF Loss                      46.266304
VF Loss                      34.58193
Policy Loss                  -1511.4856
Q Predictions Mean           1513.1755
Q Predictions Std            126.86537
Q Predictions Max            1681.4523
Q Predictions Min            757.12274
V Predictions Mean           1510.9833
V Predictions Std            124.971115
V Predictions Max            1677.0437
V Predictions Min            769.77374
Log Pis Mean                 -0.60784554
Log Pis Std                  1.771025
Log Pis Max                  7.3548436
Log Pis Min                  -5.655115
Policy mu Mean               0.102875106
Policy mu Std                0.7651342
Policy mu Max                2.226178
Policy mu Min                -2.5981467
Policy log std Mean          -0.43560386
Policy log std Std           0.19429748
Policy log std Max           0.038250685
Policy log std Min           -1.2444232
Z mean eval                  0.027347663
Z variance eval              0.004354815
total_rewards                [3197.27432081 3229.14368743 3144.21120012 2364.37464817 3273.88577115
 3208.99609981 3251.00707334 3273.45427296 3265.00871605 2147.00027969]
total_rewards_mean           3035.435606953106
total_rewards_std            394.71462361351905
total_rewards_max            3273.8857711511787
total_rewards_min            2147.000279692314
Number of train steps total  277000
Number of env steps total    1387000
Number of rollouts total     0
Train Time (s)               43.233756312169135
(Previous) Eval Time (s)     32.008037510793656
Sample Time (s)              21.824417354073375
Epoch Time (s)               97.06621117703617
Total Train Time (s)         22268.71806315705
Epoch                        276
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 06:59:28.769561 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #276 | Epoch Duration: 95.98969316482544
2020-01-11 06:59:28.769695 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #276 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028227663
Z variance train             0.0043624016
KL Divergence                11.303044
KL Loss                      1.1303045
QF Loss                      182.1453
VF Loss                      304.72586
Policy Loss                  -1507.4941
Q Predictions Mean           1511.9272
Q Predictions Std            161.71373
Q Predictions Max            1685.17
Q Predictions Min            105.26023
V Predictions Mean           1508.1807
V Predictions Std            161.05403
V Predictions Max            1671.3588
V Predictions Min            116.011894
Log Pis Mean                 -0.54206276
Log Pis Std                  1.765371
Log Pis Max                  7.0109143
Log Pis Min                  -4.920697
Policy mu Mean               0.108538866
Policy mu Std                0.77917176
Policy mu Max                2.1533244
Policy mu Min                -2.8777306
Policy log std Mean          -0.43045983
Policy log std Std           0.18985294
Policy log std Max           0.0010730624
Policy log std Min           -1.1494892
Z mean eval                  0.029621596
Z variance eval              0.004591116
total_rewards                [3313.4685075  3303.4044466  1912.69435453 3317.18115772 3339.06455034
 3328.37523327 3316.90019811 3307.70364625 1333.72288568 3318.42129424]
total_rewards_mean           2979.093627425817
total_rewards_std            690.2577292362494
total_rewards_max            3339.064550342891
total_rewards_min            1333.722885679505
Number of train steps total  278000
Number of env steps total    1392000
Number of rollouts total     0
Train Time (s)               43.98422539187595
(Previous) Eval Time (s)     30.931284696795046
Sample Time (s)              21.849338602740318
Epoch Time (s)               96.76484869141132
Total Train Time (s)         22362.614640902728
Epoch                        277
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:01:02.673793 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #277 | Epoch Duration: 93.90394997596741
2020-01-11 07:01:02.674097 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #277 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031533815
Z variance train             0.0045954175
KL Divergence                11.157186
KL Loss                      1.1157186
QF Loss                      344.8002
VF Loss                      352.31348
Policy Loss                  -1523.9907
Q Predictions Mean           1528.273
Q Predictions Std            124.605125
Q Predictions Max            1684.0117
Q Predictions Min            708.3514
V Predictions Mean           1514.4569
V Predictions Std            130.74684
V Predictions Max            1678.9779
V Predictions Min            621.08813
Log Pis Mean                 -0.46756572
Log Pis Std                  1.8391149
Log Pis Max                  8.811759
Log Pis Min                  -5.36807
Policy mu Mean               0.13297747
Policy mu Std                0.8003665
Policy mu Max                3.5524206
Policy mu Min                -2.9202876
Policy log std Mean          -0.44344175
Policy log std Std           0.19297901
Policy log std Max           0.017428845
Policy log std Min           -1.3958501
Z mean eval                  0.029218873
Z variance eval              0.0044524632
total_rewards                [3211.86828344 1835.25471397 2883.36139044 3168.25132929 3138.33412513
 3208.77022281 3279.77508118 3233.73190748 3118.59615274 3192.52001466]
total_rewards_mean           3027.0463221147484
total_rewards_std            410.2283304113844
total_rewards_max            3279.7750811812257
total_rewards_min            1835.254713972931
Number of train steps total  279000
Number of env steps total    1397000
Number of rollouts total     0
Train Time (s)               44.41893255384639
(Previous) Eval Time (s)     28.070121795870364
Sample Time (s)              22.008371042087674
Epoch Time (s)               94.49742539180443
Total Train Time (s)         22459.027226075996
Epoch                        278
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:02:39.087177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #278 | Epoch Duration: 96.41285586357117
2020-01-11 07:02:39.087320 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #278 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028714776
Z variance train             0.004460813
KL Divergence                11.168061
KL Loss                      1.1168061
QF Loss                      54.19204
VF Loss                      75.4727
Policy Loss                  -1521.4575
Q Predictions Mean           1521.903
Q Predictions Std            168.02924
Q Predictions Max            1676.8583
Q Predictions Min            -6.87757
V Predictions Mean           1524.8951
V Predictions Std            167.1202
V Predictions Max            1686.6627
V Predictions Min            -1.7407877
Log Pis Mean                 -0.6247946
Log Pis Std                  1.6198714
Log Pis Max                  5.271737
Log Pis Min                  -7.1238165
Policy mu Mean               0.043267775
Policy mu Std                0.755138
Policy mu Max                1.8695371
Policy mu Min                -2.9661791
Policy log std Mean          -0.41593918
Policy log std Std           0.18130393
Policy log std Max           0.044557363
Policy log std Min           -1.2032146
Z mean eval                  0.038847614
Z variance eval              0.0046434244
total_rewards                [3184.43704616 3151.9523966  3232.13343079 3151.28997129 3203.74498333
 3229.99810288 3173.06628218 3101.34915813 3172.93428446 3228.40645206]
total_rewards_mean           3182.9312107879514
total_rewards_std            39.94167078972027
total_rewards_max            3232.1334307945262
total_rewards_min            3101.349158128717
Number of train steps total  280000
Number of env steps total    1402000
Number of rollouts total     0
Train Time (s)               43.59146991511807
(Previous) Eval Time (s)     29.985338758677244
Sample Time (s)              21.830810349434614
Epoch Time (s)               95.40761902322993
Total Train Time (s)         22558.125967681408
Epoch                        279
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:04:18.192786 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #279 | Epoch Duration: 99.10531234741211
2020-01-11 07:04:18.193082 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #279 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039326932
Z variance train             0.0046445513
KL Divergence                11.105675
KL Loss                      1.1105675
QF Loss                      78.7981
VF Loss                      59.222145
Policy Loss                  -1518.5375
Q Predictions Mean           1517.3025
Q Predictions Std            130.46388
Q Predictions Max            1675.8357
Q Predictions Min            706.5446
V Predictions Mean           1521.4586
V Predictions Std            129.6013
V Predictions Max            1684.5258
V Predictions Min            722.1835
Log Pis Mean                 -0.62839377
Log Pis Std                  1.6320002
Log Pis Max                  6.053006
Log Pis Min                  -4.454299
Policy mu Mean               0.02758503
Policy mu Std                0.7599392
Policy mu Max                2.3146372
Policy mu Min                -3.1311193
Policy log std Mean          -0.4239039
Policy log std Std           0.19780163
Policy log std Max           0.00042364
Policy log std Min           -1.5002031
Z mean eval                  0.019772414
Z variance eval              0.004570001
total_rewards                [1726.37191204 1560.10136623  744.14832246 2300.9215041  1239.52015833
 1854.08340301 2767.5244265  1022.0813136  2624.71215111  440.24009054]
total_rewards_mean           1627.9704647920405
total_rewards_std            742.9802667451501
total_rewards_max            2767.5244264983166
total_rewards_min            440.24009053794583
Number of train steps total  281000
Number of env steps total    1407000
Number of rollouts total     0
Train Time (s)               43.97527243522927
(Previous) Eval Time (s)     33.682775063905865
Sample Time (s)              22.41758856596425
Epoch Time (s)               100.07563606509939
Total Train Time (s)         22639.980876394548
Epoch                        280
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:05:40.049574 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #280 | Epoch Duration: 81.856276512146
2020-01-11 07:05:40.049744 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #280 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018816432
Z variance train             0.004570866
KL Divergence                11.182676
KL Loss                      1.1182677
QF Loss                      1050.4155
VF Loss                      1395.7574
Policy Loss                  -1516.7438
Q Predictions Mean           1523.1466
Q Predictions Std            122.167046
Q Predictions Max            1664.8344
Q Predictions Min            718.8879
V Predictions Mean           1526.5864
V Predictions Std            118.66605
V Predictions Max            1703.5149
V Predictions Min            1017.4172
Log Pis Mean                 -0.4670911
Log Pis Std                  1.7678791
Log Pis Max                  6.285914
Log Pis Min                  -4.4392595
Policy mu Mean               0.14327587
Policy mu Std                0.8038487
Policy mu Max                2.4732437
Policy mu Min                -2.8762717
Policy log std Mean          -0.42008552
Policy log std Std           0.18106319
Policy log std Max           -0.0068576634
Policy log std Min           -1.0562071
Z mean eval                  0.028027494
Z variance eval              0.0043388
total_rewards                [1123.31059148 3093.29888327 1130.5980779   865.61592193 3041.34729072
  635.3771598  2176.94175607  365.01689485 3050.83203838 2354.72838063]
total_rewards_mean           1783.7066995023445
total_rewards_std            1020.7793003133918
total_rewards_max            3093.2988832735423
total_rewards_min            365.0168948494455
Number of train steps total  282000
Number of env steps total    1412000
Number of rollouts total     0
Train Time (s)               42.9883788228035
(Previous) Eval Time (s)     15.463199658319354
Sample Time (s)              21.04810159187764
Epoch Time (s)               79.49968007300049
Total Train Time (s)         22721.85600776039
Epoch                        281
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:07:01.930213 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #281 | Epoch Duration: 81.88029670715332
2020-01-11 07:07:01.930478 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #281 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027472382
Z variance train             0.004336315
KL Divergence                11.352103
KL Loss                      1.1352104
QF Loss                      184.0552
VF Loss                      103.373856
Policy Loss                  -1517.321
Q Predictions Mean           1516.1873
Q Predictions Std            132.45117
Q Predictions Max            1700.9286
Q Predictions Min            670.37103
V Predictions Mean           1519.9194
V Predictions Std            129.95659
V Predictions Max            1703.1166
V Predictions Min            715.3126
Log Pis Mean                 -0.30339712
Log Pis Std                  1.9864633
Log Pis Max                  7.973607
Log Pis Min                  -4.932067
Policy mu Mean               -0.27100924
Policy mu Std                0.82200986
Policy mu Max                2.6120992
Policy mu Min                -3.2307127
Policy log std Mean          -0.40238142
Policy log std Std           0.18299106
Policy log std Max           0.034197003
Policy log std Min           -0.9424566
Z mean eval                  0.039914913
Z variance eval              0.0045172954
total_rewards                [3119.22817312 3278.85632434 3311.41341755 3266.78768426 3140.54618226
 3256.75350532 3221.67762888 3244.83852684 2320.8687049  3203.27605405]
total_rewards_mean           3136.4246201522374
total_rewards_std            277.7258287431182
total_rewards_max            3311.4134175509407
total_rewards_min            2320.8687048963725
Number of train steps total  283000
Number of env steps total    1417000
Number of rollouts total     0
Train Time (s)               44.37683756602928
(Previous) Eval Time (s)     17.84357769601047
Sample Time (s)              22.006537460256368
Epoch Time (s)               84.22695272229612
Total Train Time (s)         22821.06245818548
Epoch                        282
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:08:41.143768 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #282 | Epoch Duration: 99.21307849884033
2020-01-11 07:08:41.144075 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #282 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039793458
Z variance train             0.0045153685
KL Divergence                11.24029
KL Loss                      1.124029
QF Loss                      36.364273
VF Loss                      17.363567
Policy Loss                  -1517.1879
Q Predictions Mean           1516.72
Q Predictions Std            122.778366
Q Predictions Max            1670.9468
Q Predictions Min            833.73676
V Predictions Mean           1517.0088
V Predictions Std            120.42352
V Predictions Max            1669.2009
V Predictions Min            850.7101
Log Pis Mean                 -0.71015054
Log Pis Std                  1.7161623
Log Pis Max                  7.1147547
Log Pis Min                  -6.589006
Policy mu Mean               -0.014751767
Policy mu Std                0.76747495
Policy mu Max                2.2392852
Policy mu Min                -3.0063663
Policy log std Mean          -0.4240799
Policy log std Std           0.1866967
Policy log std Max           0.08638227
Policy log std Min           -1.2684443
Z mean eval                  0.022773407
Z variance eval              0.004306172
total_rewards                [3232.14228451 3257.29073888 2206.38779713 3304.37629996 3238.27981053
 3255.1626356  3243.41290234 3225.4044236  3248.2826205  1336.59641376]
total_rewards_mean           2954.7335926811206
total_rewards_std            623.1020247977691
total_rewards_max            3304.376299961246
total_rewards_min            1336.596413756825
Number of train steps total  284000
Number of env steps total    1422000
Number of rollouts total     0
Train Time (s)               43.86513606226072
(Previous) Eval Time (s)     32.829406627919525
Sample Time (s)              22.415879981126636
Epoch Time (s)               99.11042267130688
Total Train Time (s)         22914.14950486552
Epoch                        283
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:10:14.233035 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #283 | Epoch Duration: 93.08874583244324
2020-01-11 07:10:14.233216 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #283 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022820324
Z variance train             0.0043008747
KL Divergence                11.329166
KL Loss                      1.1329167
QF Loss                      40.881397
VF Loss                      18.653194
Policy Loss                  -1521.8419
Q Predictions Mean           1521.0212
Q Predictions Std            114.50331
Q Predictions Max            1685.0576
Q Predictions Min            1045.7838
V Predictions Mean           1523.8127
V Predictions Std            115.134315
V Predictions Max            1688.079
V Predictions Min            1007.4201
Log Pis Mean                 -0.84952664
Log Pis Std                  1.4550484
Log Pis Max                  5.089741
Log Pis Min                  -4.536531
Policy mu Mean               0.11344079
Policy mu Std                0.6753585
Policy mu Max                1.6971319
Policy mu Min                -2.3827848
Policy log std Mean          -0.4178647
Policy log std Std           0.17182213
Policy log std Max           0.059737384
Policy log std Min           -1.3025763
Z mean eval                  0.046170443
Z variance eval              0.0041458732
total_rewards                [3244.84011414 3249.13203941 3183.63018247 3216.00439614 3044.33800724
 3136.84250118 3244.39938301 3177.77122465 3157.01856714 3231.20756701]
total_rewards_mean           3188.5183982391263
total_rewards_std            60.939886844493316
total_rewards_max            3249.1320394130216
total_rewards_min            3044.3380072406967
Number of train steps total  285000
Number of env steps total    1427000
Number of rollouts total     0
Train Time (s)               43.96281835483387
(Previous) Eval Time (s)     26.807513593230397
Sample Time (s)              21.464998981449753
Epoch Time (s)               92.23533092951402
Total Train Time (s)         23013.21830403665
Epoch                        284
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:11:53.309344 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #284 | Epoch Duration: 99.07593703269958
2020-01-11 07:11:53.309592 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #284 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045634452
Z variance train             0.004148136
KL Divergence                11.315095
KL Loss                      1.1315095
QF Loss                      84.37909
VF Loss                      64.63895
Policy Loss                  -1522.068
Q Predictions Mean           1525.2958
Q Predictions Std            162.97493
Q Predictions Max            1684.8925
Q Predictions Min            18.101473
V Predictions Mean           1527.1902
V Predictions Std            163.91505
V Predictions Max            1689.6874
V Predictions Min            9.9526825
Log Pis Mean                 -0.6564212
Log Pis Std                  1.8468214
Log Pis Max                  10.166983
Log Pis Min                  -5.111636
Policy mu Mean               0.06322018
Policy mu Std                0.7824611
Policy mu Max                2.4912446
Policy mu Min                -3.0700796
Policy log std Mean          -0.43550792
Policy log std Std           0.18525787
Policy log std Max           0.07113862
Policy log std Min           -1.0545325
Z mean eval                  0.05014505
Z variance eval              0.004858154
total_rewards                [3294.91683051 3223.86284045 1802.14716525 1825.50671993 3392.65547276
 3384.00560741 3352.69135894 3349.34193277 3396.69791663 1059.32386975]
total_rewards_mean           2808.1149714379094
total_rewards_std            839.9309752641107
total_rewards_max            3396.6979166288847
total_rewards_min            1059.3238697516863
Number of train steps total  286000
Number of env steps total    1432000
Number of rollouts total     0
Train Time (s)               44.04431908484548
(Previous) Eval Time (s)     33.6478740372695
Sample Time (s)              21.92311033140868
Epoch Time (s)               99.61530345352367
Total Train Time (s)         23105.627093941905
Epoch                        285
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:13:25.720620 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #285 | Epoch Duration: 92.41087317466736
2020-01-11 07:13:25.720793 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #285 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05009327
Z variance train             0.004858623
KL Divergence                10.959498
KL Loss                      1.0959499
QF Loss                      44.416435
VF Loss                      19.506975
Policy Loss                  -1532.2448
Q Predictions Mean           1529.8651
Q Predictions Std            122.93678
Q Predictions Max            1688.6173
Q Predictions Min            1014.6432
V Predictions Mean           1530.8982
V Predictions Std            121.15685
V Predictions Max            1688.554
V Predictions Min            1072.5219
Log Pis Mean                 -0.41300464
Log Pis Std                  1.8470259
Log Pis Max                  8.089981
Log Pis Min                  -3.673275
Policy mu Mean               0.019406395
Policy mu Std                0.8096004
Policy mu Max                1.817296
Policy mu Min                -3.1457267
Policy log std Mean          -0.42803457
Policy log std Std           0.18461074
Policy log std Max           0.010297209
Policy log std Min           -1.1812949
Z mean eval                  0.026731033
Z variance eval              0.004567216
total_rewards                [3303.30077954 3274.09121428 3205.14587551 3265.56674512 3278.525786
 3245.91881748 3254.15191085 3334.61793637 3310.70434235 3268.32618634]
total_rewards_mean           3274.0349593851556
total_rewards_std            34.53615401206838
total_rewards_max            3334.6179363692167
total_rewards_min            3205.145875506987
Number of train steps total  287000
Number of env steps total    1437000
Number of rollouts total     0
Train Time (s)               43.04860408697277
(Previous) Eval Time (s)     26.4431718387641
Sample Time (s)              23.77471812721342
Epoch Time (s)               93.26649405295029
Total Train Time (s)         23204.96417229157
Epoch                        286
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:15:05.060664 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #286 | Epoch Duration: 99.33969306945801
2020-01-11 07:15:05.060854 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #286 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026268655
Z variance train             0.0045681745
KL Divergence                11.033847
KL Loss                      1.1033847
QF Loss                      379.03082
VF Loss                      232.14679
Policy Loss                  -1532.9431
Q Predictions Mean           1529.8821
Q Predictions Std            118.513374
Q Predictions Max            1673.6847
Q Predictions Min            845.8714
V Predictions Mean           1535.584
V Predictions Std            118.88492
V Predictions Max            1679.893
V Predictions Min            836.56067
Log Pis Mean                 -0.33824998
Log Pis Std                  1.9726996
Log Pis Max                  8.192004
Log Pis Min                  -4.7654843
Policy mu Mean               -0.09451731
Policy mu Std                0.8461531
Policy mu Max                1.9401077
Policy mu Min                -3.0810409
Policy log std Mean          -0.44823197
Policy log std Std           0.18966085
Policy log std Max           0.05593553
Policy log std Min           -1.1229949
Z mean eval                  0.023316294
Z variance eval              0.004808181
total_rewards                [3200.70966783 3132.50900119 3128.62509449 3208.31104517 1254.53224296
 3270.61422281 3188.9786871  3258.2685241  1073.94341084  978.15151795]
total_rewards_mean           2569.464341444295
total_rewards_std            963.5373356504015
total_rewards_max            3270.614222809354
total_rewards_min            978.1515179547406
Number of train steps total  288000
Number of env steps total    1442000
Number of rollouts total     0
Train Time (s)               43.924869515933096
(Previous) Eval Time (s)     32.51612358028069
Sample Time (s)              21.936639957595617
Epoch Time (s)               98.3776330538094
Total Train Time (s)         23297.83800709108
Epoch                        287
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:16:37.938726 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #287 | Epoch Duration: 92.87772393226624
2020-01-11 07:16:37.938970 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #287 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023172002
Z variance train             0.004810477
KL Divergence                10.953286
KL Loss                      1.0953287
QF Loss                      36.947548
VF Loss                      25.666645
Policy Loss                  -1524.6367
Q Predictions Mean           1523.5925
Q Predictions Std            117.12126
Q Predictions Max            1702.9447
Q Predictions Min            1131.7701
V Predictions Mean           1522.6885
V Predictions Std            116.5302
V Predictions Max            1699.5431
V Predictions Min            1217.3951
Log Pis Mean                 -0.76452166
Log Pis Std                  1.7893819
Log Pis Max                  8.893698
Log Pis Min                  -4.160428
Policy mu Mean               0.014274771
Policy mu Std                0.7471501
Policy mu Max                2.6304076
Policy mu Min                -2.7548134
Policy log std Mean          -0.411661
Policy log std Std           0.17744808
Policy log std Max           0.056948364
Policy log std Min           -1.1676023
Z mean eval                  0.036087237
Z variance eval              0.0058313166
total_rewards                [3288.69827262 1242.81907719 3254.94951035 3350.8388364  3255.73805627
 3266.82421254 1112.6866096  3334.92589629 3263.58775173 3372.1999402 ]
total_rewards_mean           2874.3268163188436
total_rewards_std            849.7009321435629
total_rewards_max            3372.199940198853
total_rewards_min            1112.6866096023732
Number of train steps total  289000
Number of env steps total    1447000
Number of rollouts total     0
Train Time (s)               45.80986724188551
(Previous) Eval Time (s)     27.015941545832902
Sample Time (s)              19.9100030567497
Epoch Time (s)               92.73581184446812
Total Train Time (s)         23393.92447556043
Epoch                        288
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:18:14.026684 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #288 | Epoch Duration: 96.08754825592041
2020-01-11 07:18:14.026816 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #288 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035465974
Z variance train             0.00582352
KL Divergence                10.556123
KL Loss                      1.0556123
QF Loss                      23.499794
VF Loss                      12.21387
Policy Loss                  -1545.2545
Q Predictions Mean           1545.5728
Q Predictions Std            99.51869
Q Predictions Max            1694.1029
Q Predictions Min            1245.9946
V Predictions Mean           1547.3596
V Predictions Std            99.24941
V Predictions Max            1692.9868
V Predictions Min            1247.407
Log Pis Mean                 -0.73926777
Log Pis Std                  1.8172351
Log Pis Max                  4.8493853
Log Pis Min                  -6.671455
Policy mu Mean               0.05069208
Policy mu Std                0.7834593
Policy mu Max                1.6636577
Policy mu Min                -2.723181
Policy log std Mean          -0.41787055
Policy log std Std           0.16638052
Policy log std Max           -0.008393824
Policy log std Min           -1.1550366
Z mean eval                  0.017478412
Z variance eval              0.006187247
total_rewards                [3223.97150846 3313.60284803 1132.77605294  920.42311822  818.24699526
 1236.29587832  818.91842862  896.89918813 1018.22933475  881.84171845]
total_rewards_mean           1426.1205071180957
total_rewards_std            930.2454730452604
total_rewards_max            3313.6028480255623
total_rewards_min            818.2469952556714
Number of train steps total  290000
Number of env steps total    1452000
Number of rollouts total     0
Train Time (s)               44.22686819918454
(Previous) Eval Time (s)     30.36746515473351
Sample Time (s)              21.662118405103683
Epoch Time (s)               96.25645175902173
Total Train Time (s)         23473.545514662284
Epoch                        289
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:19:33.650265 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #289 | Epoch Duration: 79.62335658073425
2020-01-11 07:19:33.650385 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #289 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01805344
Z variance train             0.006187835
KL Divergence                10.417551
KL Loss                      1.0417551
QF Loss                      36.82899
VF Loss                      22.511496
Policy Loss                  -1546.3381
Q Predictions Mean           1548.2035
Q Predictions Std            114.98848
Q Predictions Max            1692.8232
Q Predictions Min            788.75275
V Predictions Mean           1544.1637
V Predictions Std            114.91525
V Predictions Max            1691.9935
V Predictions Min            770.26855
Log Pis Mean                 -0.80296475
Log Pis Std                  1.7173759
Log Pis Max                  5.922335
Log Pis Min                  -4.7471743
Policy mu Mean               0.009102295
Policy mu Std                0.76892537
Policy mu Max                1.7872101
Policy mu Min                -2.3357732
Policy log std Mean          -0.38756868
Policy log std Std           0.16448505
Policy log std Max           0.019429356
Policy log std Min           -1.1453272
Z mean eval                  0.02405211
Z variance eval              0.0065417513
total_rewards                [ 973.3777656   690.40625352 3176.97486574 1466.30712094 2055.67569881
 2573.23179781 3168.28030797 1595.40230699 3123.81370678  911.38069269]
total_rewards_mean           1973.4850516858883
total_rewards_std            934.8999082416393
total_rewards_max            3176.9748657411933
total_rewards_min            690.4062535243645
Number of train steps total  291000
Number of env steps total    1457000
Number of rollouts total     0
Train Time (s)               43.84922704799101
(Previous) Eval Time (s)     13.73413924407214
Sample Time (s)              21.569792446680367
Epoch Time (s)               79.15315873874351
Total Train Time (s)         23559.714456947986
Epoch                        290
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:20:59.822901 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #290 | Epoch Duration: 86.17241024971008
2020-01-11 07:20:59.823078 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #290 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024204463
Z variance train             0.0065389336
KL Divergence                10.260991
KL Loss                      1.0260991
QF Loss                      59.1594
VF Loss                      89.82514
Policy Loss                  -1541.3102
Q Predictions Mean           1543.8677
Q Predictions Std            118.66726
Q Predictions Max            1718.5309
Q Predictions Min            993.9649
V Predictions Mean           1548.9417
V Predictions Std            118.52272
V Predictions Max            1728.1089
V Predictions Min            999.79254
Log Pis Mean                 -0.57868385
Log Pis Std                  1.9122604
Log Pis Max                  6.074005
Log Pis Min                  -5.1733913
Policy mu Mean               0.0050852727
Policy mu Std                0.8356753
Policy mu Max                2.0162163
Policy mu Min                -3.0475273
Policy log std Mean          -0.4103181
Policy log std Std           0.18207572
Policy log std Max           -0.011924863
Policy log std Min           -1.2525059
Z mean eval                  0.02311647
Z variance eval              0.006376679
total_rewards                [3203.69922669 3267.98867567 1233.86321492 3232.09054161 3049.50261131
 3284.97115357 3285.84702905 1769.45768368 1007.32686676 1041.80008842]
total_rewards_mean           2437.654709167959
total_rewards_std            980.254523067213
total_rewards_max            3285.8470290491746
total_rewards_min            1007.3268667635042
Number of train steps total  292000
Number of env steps total    1462000
Number of rollouts total     0
Train Time (s)               43.02243333496153
(Previous) Eval Time (s)     20.75314630800858
Sample Time (s)              21.82651406340301
Epoch Time (s)               85.60209370637313
Total Train Time (s)         23648.519383948762
Epoch                        291
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:22:28.629959 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #291 | Epoch Duration: 88.80675053596497
2020-01-11 07:22:28.630091 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #291 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022903357
Z variance train             0.0063771144
KL Divergence                10.374627
KL Loss                      1.0374627
QF Loss                      73.23422
VF Loss                      82.834946
Policy Loss                  -1531.8359
Q Predictions Mean           1530.076
Q Predictions Std            122.358475
Q Predictions Max            1676.963
Q Predictions Min            848.2191
V Predictions Mean           1539.6671
V Predictions Std            120.682884
V Predictions Max            1687.306
V Predictions Min            863.5173
Log Pis Mean                 -0.73269004
Log Pis Std                  1.6980205
Log Pis Max                  6.457573
Log Pis Min                  -4.0107346
Policy mu Mean               0.0025295664
Policy mu Std                0.74675894
Policy mu Max                1.892344
Policy mu Min                -2.7388306
Policy log std Mean          -0.39680266
Policy log std Std           0.171835
Policy log std Max           -0.022314072
Policy log std Min           -1.0241936
Z mean eval                  0.01204622
Z variance eval              0.0058208564
total_rewards                [3237.1468537  2600.87025561 1037.7743417  2632.6791531  2054.22839124
 3327.99984437 1151.88329927  792.6849037   945.03937718 2078.30283075]
total_rewards_mean           1985.8609250613008
total_rewards_std            909.8488132348169
total_rewards_max            3327.9998443714603
total_rewards_min            792.6849036950623
Number of train steps total  293000
Number of env steps total    1467000
Number of rollouts total     0
Train Time (s)               44.44435120001435
(Previous) Eval Time (s)     23.9575587650761
Sample Time (s)              21.84194660000503
Epoch Time (s)               90.24385656509548
Total Train Time (s)         23735.146352713928
Epoch                        292
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:23:55.258414 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #292 | Epoch Duration: 86.62822842597961
2020-01-11 07:23:55.258534 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #292 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012318188
Z variance train             0.005820183
KL Divergence                10.514395
KL Loss                      1.0514395
QF Loss                      157.8072
VF Loss                      118.98584
Policy Loss                  -1537.806
Q Predictions Mean           1537.3452
Q Predictions Std            128.06454
Q Predictions Max            1685.1567
Q Predictions Min            758.87714
V Predictions Mean           1537.6672
V Predictions Std            123.979385
V Predictions Max            1686.2188
V Predictions Min            773.05566
Log Pis Mean                 -0.56728846
Log Pis Std                  1.730212
Log Pis Max                  4.4876065
Log Pis Min                  -4.2621307
Policy mu Mean               -0.019481141
Policy mu Std                0.79035056
Policy mu Max                1.798464
Policy mu Min                -2.7653587
Policy log std Mean          -0.4016261
Policy log std Std           0.16603214
Policy log std Max           -0.02565609
Policy log std Min           -1.085077
Z mean eval                  0.040942423
Z variance eval              0.006093584
total_rewards                [ 846.94779462 1782.57378859  682.64820177 1363.77631201  720.45840665
  696.50193424  624.02709891 1007.06066492  641.10747139 1610.81427801]
total_rewards_mean           997.5915951108138
total_rewards_std            410.16972828655025
total_rewards_max            1782.5737885902904
total_rewards_min            624.027098914726
Number of train steps total  294000
Number of env steps total    1472000
Number of rollouts total     0
Train Time (s)               45.03676827484742
(Previous) Eval Time (s)     20.341685181949288
Sample Time (s)              22.150808694772422
Epoch Time (s)               87.52926215156913
Total Train Time (s)         23812.59217205504
Epoch                        293
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:25:12.706252 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #293 | Epoch Duration: 77.44762969017029
2020-01-11 07:25:12.706369 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #293 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041598305
Z variance train             0.0060897493
KL Divergence                10.49053
KL Loss                      1.0490531
QF Loss                      73.87686
VF Loss                      83.86083
Policy Loss                  -1548.5515
Q Predictions Mean           1548.8846
Q Predictions Std            124.98568
Q Predictions Max            1701.9313
Q Predictions Min            789.2655
V Predictions Mean           1547.4811
V Predictions Std            122.87155
V Predictions Max            1711.7582
V Predictions Min            781.1787
Log Pis Mean                 -0.7177332
Log Pis Std                  1.8881764
Log Pis Max                  5.773047
Log Pis Min                  -5.4603777
Policy mu Mean               0.22139484
Policy mu Std                0.7738821
Policy mu Max                2.047459
Policy mu Min                -3.0059953
Policy log std Mean          -0.41270685
Policy log std Std           0.164828
Policy log std Max           0.11971688
Policy log std Min           -1.0560999
Z mean eval                  0.040184982
Z variance eval              0.005993829
total_rewards                [3316.12223143  461.67420952  729.9563326  3267.50613789 3387.79365053
 3317.12013342 3358.00509578 3322.63358544 3325.94829525 1312.48391091]
total_rewards_mean           2579.924358277628
total_rewards_std            1159.319431278269
total_rewards_max            3387.793650534006
total_rewards_min            461.67420952399186
Number of train steps total  295000
Number of env steps total    1477000
Number of rollouts total     0
Train Time (s)               43.46970587223768
(Previous) Eval Time (s)     10.259815887082368
Sample Time (s)              22.101524721365422
Epoch Time (s)               75.83104648068547
Total Train Time (s)         23903.780172855128
Epoch                        294
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:26:43.900471 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #294 | Epoch Duration: 91.19399213790894
2020-01-11 07:26:43.900663 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #294 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039715335
Z variance train             0.0059901765
KL Divergence                10.717698
KL Loss                      1.0717698
QF Loss                      303.91507
VF Loss                      267.82373
Policy Loss                  -1544.1919
Q Predictions Mean           1549.1068
Q Predictions Std            119.41295
Q Predictions Max            1715.8972
Q Predictions Min            1175.0581
V Predictions Mean           1547.6077
V Predictions Std            117.72145
V Predictions Max            1693.1829
V Predictions Min            1147.5942
Log Pis Mean                 -0.79851794
Log Pis Std                  1.7628379
Log Pis Max                  6.1692324
Log Pis Min                  -5.420769
Policy mu Mean               0.05628584
Policy mu Std                0.76577896
Policy mu Max                2.2958705
Policy mu Min                -2.4558456
Policy log std Mean          -0.3913809
Policy log std Std           0.16559133
Policy log std Max           0.097485006
Policy log std Min           -0.98645085
Z mean eval                  0.03850142
Z variance eval              0.0060333675
total_rewards                [ 903.23882662 3358.32991915 1547.56439029 3358.65324541 3379.0652872
 3362.637279   3422.50250538  790.99879749  655.77093673 3383.55875316]
total_rewards_mean           2416.2319940424504
total_rewards_std            1197.1247402929666
total_rewards_max            3422.5025053796558
total_rewards_min            655.7709367259056
Number of train steps total  296000
Number of env steps total    1482000
Number of rollouts total     0
Train Time (s)               44.13829726027325
(Previous) Eval Time (s)     25.622532341163605
Sample Time (s)              22.072213164065033
Epoch Time (s)               91.83304276550189
Total Train Time (s)         23992.61141707655
Epoch                        295
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:28:12.736902 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #295 | Epoch Duration: 88.83609318733215
2020-01-11 07:28:12.737072 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #295 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036130127
Z variance train             0.0060348464
KL Divergence                10.593413
KL Loss                      1.0593413
QF Loss                      131.05492
VF Loss                      359.5479
Policy Loss                  -1556.6317
Q Predictions Mean           1559.5781
Q Predictions Std            116.57127
Q Predictions Max            1695.4941
Q Predictions Min            1038.4824
V Predictions Mean           1567.721
V Predictions Std            118.01111
V Predictions Max            1718.7279
V Predictions Min            1013.7829
Log Pis Mean                 -0.6846751
Log Pis Std                  1.795592
Log Pis Max                  8.325117
Log Pis Min                  -3.9478722
Policy mu Mean               -0.05958395
Policy mu Std                0.758005
Policy mu Max                1.7504185
Policy mu Min                -3.2262735
Policy log std Mean          -0.40259477
Policy log std Std           0.15634641
Policy log std Max           0.08113438
Policy log std Min           -1.0997285
Z mean eval                  0.030911064
Z variance eval              0.0062564746
total_rewards                [3224.52577906  795.11704569 3249.76958244  995.65869448 3205.02873011
  793.02086803 2912.92879336 2988.87536076 3274.1994273  3337.49223284]
total_rewards_mean           2477.6616514073776
total_rewards_std            1066.4380540748343
total_rewards_max            3337.492232840513
total_rewards_min            793.0208680327314
Number of train steps total  297000
Number of env steps total    1487000
Number of rollouts total     0
Train Time (s)               44.42758700391278
(Previous) Eval Time (s)     22.62534489808604
Sample Time (s)              21.877392067108303
Epoch Time (s)               88.93032396910712
Total Train Time (s)         24083.384016295895
Epoch                        296
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:29:43.512542 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #296 | Epoch Duration: 90.77532362937927
2020-01-11 07:29:43.512758 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #296 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030865857
Z variance train             0.006252583
KL Divergence                10.477173
KL Loss                      1.0477173
QF Loss                      47.309853
VF Loss                      24.568499
Policy Loss                  -1548.9152
Q Predictions Mean           1548.5566
Q Predictions Std            104.051125
Q Predictions Max            1672.483
Q Predictions Min            1248.3186
V Predictions Mean           1547.4745
V Predictions Std            103.92573
V Predictions Max            1677.439
V Predictions Min            1242.9225
Log Pis Mean                 -0.5666536
Log Pis Std                  1.8718437
Log Pis Max                  6.0033894
Log Pis Min                  -6.849199
Policy mu Mean               -0.13274415
Policy mu Std                0.7764153
Policy mu Max                1.6150889
Policy mu Min                -2.7186172
Policy log std Mean          -0.38819584
Policy log std Std           0.15502892
Policy log std Max           0.037130684
Policy log std Min           -1.0992823
Z mean eval                  0.018364666
Z variance eval              0.0065234536
total_rewards                [1208.79270171 3327.16973976 1619.66867419  761.25489139  969.81863171
 1755.39249337 3430.14549748 1774.23945796 1075.08080738 1328.60389494]
total_rewards_mean           1725.0166789891603
total_rewards_std            885.0994459997163
total_rewards_max            3430.145497481613
total_rewards_min            761.2548913871022
Number of train steps total  298000
Number of env steps total    1492000
Number of rollouts total     0
Train Time (s)               44.020033415872604
(Previous) Eval Time (s)     24.47010381007567
Sample Time (s)              21.39981493074447
Epoch Time (s)               89.88995215669274
Total Train Time (s)         24165.718071575742
Epoch                        297
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:31:05.853036 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #297 | Epoch Duration: 82.34008383750916
2020-01-11 07:31:05.853313 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #297 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018274507
Z variance train             0.0065211453
KL Divergence                10.426962
KL Loss                      1.0426962
QF Loss                      11349.09
VF Loss                      241.47664
Policy Loss                  -1555.9921
Q Predictions Mean           1562.4192
Q Predictions Std            111.17554
Q Predictions Max            1705.0525
Q Predictions Min            949.1948
V Predictions Mean           1558.5239
V Predictions Std            109.92905
V Predictions Max            1696.6377
V Predictions Min            897.1887
Log Pis Mean                 -0.79296845
Log Pis Std                  1.6453621
Log Pis Max                  6.212986
Log Pis Min                  -5.0863976
Policy mu Mean               -0.005906219
Policy mu Std                0.7273131
Policy mu Max                1.7683465
Policy mu Min                -2.7125661
Policy log std Mean          -0.415378
Policy log std Std           0.15301824
Policy log std Max           0.016662538
Policy log std Min           -1.0561749
Z mean eval                  0.03993323
Z variance eval              0.0057715713
total_rewards                [ 754.9077074  1020.64342633 1064.88762492 1681.46340691 1757.73395117
 1184.78368012 1208.0915758  2943.71498446 2923.96374131 1438.9878611 ]
total_rewards_mean           1597.9177959515425
total_rewards_std            726.5001630146774
total_rewards_max            2943.714984460461
total_rewards_min            754.9077073962555
Number of train steps total  299000
Number of env steps total    1497000
Number of rollouts total     0
Train Time (s)               43.89086322998628
(Previous) Eval Time (s)     16.919984650798142
Sample Time (s)              22.10019518667832
Epoch Time (s)               82.91104306746274
Total Train Time (s)         24247.047502167523
Epoch                        298
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:32:27.183640 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #298 | Epoch Duration: 81.33013486862183
2020-01-11 07:32:27.183771 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #298 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040057126
Z variance train             0.005774919
KL Divergence                10.772654
KL Loss                      1.0772654
QF Loss                      45.83883
VF Loss                      18.325546
Policy Loss                  -1586.4672
Q Predictions Mean           1586.1609
Q Predictions Std            105.8034
Q Predictions Max            1718.2731
Q Predictions Min            1280.1299
V Predictions Mean           1585.2543
V Predictions Std            104.87654
V Predictions Max            1709.6547
V Predictions Min            1281.4456
Log Pis Mean                 -0.99770695
Log Pis Std                  1.6106539
Log Pis Max                  8.818715
Log Pis Min                  -4.6163583
Policy mu Mean               -0.07657858
Policy mu Std                0.68225867
Policy mu Max                1.5236979
Policy mu Min                -2.6489432
Policy log std Mean          -0.38571405
Policy log std Std           0.1433622
Policy log std Max           0.0015033185
Policy log std Min           -0.99870557
Z mean eval                  0.016148208
Z variance eval              0.0057254224
total_rewards                [ 483.516982    482.16506049 1069.03900735  463.90595299  705.1953369
  483.21104601 1307.86979807  726.94116481 3422.68558605 1293.67188609]
total_rewards_mean           1043.8201820740337
total_rewards_std            853.6300743658771
total_rewards_max            3422.685586052966
total_rewards_min            463.9059529851414
Number of train steps total  300000
Number of env steps total    1502000
Number of rollouts total     0
Train Time (s)               43.69529428705573
(Previous) Eval Time (s)     15.338853489141911
Sample Time (s)              21.9742146381177
Epoch Time (s)               81.00836241431534
Total Train Time (s)         24322.17454737425
Epoch                        299
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:33:42.316265 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #299 | Epoch Duration: 75.13237738609314
2020-01-11 07:33:42.316445 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #299 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015861355
Z variance train             0.005726319
KL Divergence                10.68182
KL Loss                      1.068182
QF Loss                      81.396736
VF Loss                      53.835213
Policy Loss                  -1563.0854
Q Predictions Mean           1563.8489
Q Predictions Std            108.12694
Q Predictions Max            1722.4493
Q Predictions Min            1143.1195
V Predictions Mean           1566.1973
V Predictions Std            108.41874
V Predictions Max            1724.7007
V Predictions Min            1126.4303
Log Pis Mean                 -0.67314315
Log Pis Std                  1.6759827
Log Pis Max                  6.895857
Log Pis Min                  -5.1186466
Policy mu Mean               -0.06845356
Policy mu Std                0.7550637
Policy mu Max                1.8236111
Policy mu Min                -2.5139549
Policy log std Mean          -0.41191325
Policy log std Std           0.14649872
Policy log std Max           -0.02710788
Policy log std Min           -1.2156563
Z mean eval                  0.022497078
Z variance eval              0.005790173
total_rewards                [1028.46887613  449.62472593  552.40426706  701.79930657 1057.45557747
  607.7882795   440.66624572  798.17734256  431.73363426  969.74798131]
total_rewards_mean           703.7866236511193
total_rewards_std            234.54744243558758
total_rewards_max            1057.4555774733258
total_rewards_min            431.7336342584669
Number of train steps total  301000
Number of env steps total    1507000
Number of rollouts total     0
Train Time (s)               43.50166854029521
(Previous) Eval Time (s)     9.462620404083282
Sample Time (s)              20.853709026239812
Epoch Time (s)               73.81799797061831
Total Train Time (s)         24393.0776854367
Epoch                        300
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:34:53.223818 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #300 | Epoch Duration: 70.90716290473938
2020-01-11 07:34:53.224066 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #300 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022320006
Z variance train             0.0057902387
KL Divergence                10.659512
KL Loss                      1.0659512
QF Loss                      299.5269
VF Loss                      193.27747
Policy Loss                  -1546.0905
Q Predictions Mean           1545.7501
Q Predictions Std            131.07413
Q Predictions Max            1716.4292
Q Predictions Min            605.61646
V Predictions Mean           1545.4421
V Predictions Std            131.0059
V Predictions Max            1714.3481
V Predictions Min            607.0689
Log Pis Mean                 -0.843099
Log Pis Std                  1.4854218
Log Pis Max                  5.007551
Log Pis Min                  -3.567421
Policy mu Mean               0.044838797
Policy mu Std                0.6993204
Policy mu Max                1.7566817
Policy mu Min                -2.4870462
Policy log std Mean          -0.38906154
Policy log std Std           0.13246976
Policy log std Max           0.018934727
Policy log std Min           -0.8550496
Z mean eval                  0.04264861
Z variance eval              0.005447953
total_rewards                [ 937.22569893 1005.45473703  922.95797441 1114.64833553  894.60483315
  901.48173197 1026.33344667 1263.4332689  2108.37461522 1284.97720712]
total_rewards_mean           1145.9491848926034
total_rewards_std            347.9438546699163
total_rewards_max            2108.374615221859
total_rewards_min            894.6048331540972
Number of train steps total  302000
Number of env steps total    1512000
Number of rollouts total     0
Train Time (s)               44.11867632297799
(Previous) Eval Time (s)     6.551524518057704
Sample Time (s)              18.648703860118985
Epoch Time (s)               69.31890470115468
Total Train Time (s)         24465.80612002965
Epoch                        301
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:36:05.954770 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #301 | Epoch Duration: 72.73054361343384
2020-01-11 07:36:05.954935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #301 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042944096
Z variance train             0.0054507083
KL Divergence                10.85503
KL Loss                      1.085503
QF Loss                      114.01956
VF Loss                      95.413284
Policy Loss                  -1577.1752
Q Predictions Mean           1573.9838
Q Predictions Std            135.75026
Q Predictions Max            1728.3204
Q Predictions Min            179.80896
V Predictions Mean           1573.7952
V Predictions Std            136.29889
V Predictions Max            1721.9995
V Predictions Min            139.44098
Log Pis Mean                 -0.61653805
Log Pis Std                  1.6397842
Log Pis Max                  6.003288
Log Pis Min                  -4.3283
Policy mu Mean               -0.042714417
Policy mu Std                0.787634
Policy mu Max                2.2284017
Policy mu Min                -2.4297838
Policy log std Mean          -0.39617407
Policy log std Std           0.14370278
Policy log std Max           -0.04679969
Policy log std Min           -1.0650394
Z mean eval                  0.04464964
Z variance eval              0.005735737
total_rewards                [661.85080111 657.34671067 909.10131198 661.90568559 677.66538089
 655.5012187  664.98251018 658.81788211 671.56446964 644.91784967]
total_rewards_mean           686.3653820523027
total_rewards_std            74.7221270505913
total_rewards_max            909.1013119768309
total_rewards_min            644.917849667243
Number of train steps total  303000
Number of env steps total    1517000
Number of rollouts total     0
Train Time (s)               43.68811382167041
(Previous) Eval Time (s)     9.96293494105339
Sample Time (s)              21.88589208899066
Epoch Time (s)               75.53694085171446
Total Train Time (s)         24538.588441842236
Epoch                        302
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:37:18.739185 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #302 | Epoch Duration: 72.78411865234375
2020-01-11 07:37:18.739321 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #302 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.044828914
Z variance train             0.0057315985
KL Divergence                10.784995
KL Loss                      1.0784996
QF Loss                      54.01645
VF Loss                      18.943228
Policy Loss                  -1576.8108
Q Predictions Mean           1575.7644
Q Predictions Std            109.50638
Q Predictions Max            1701.514
Q Predictions Min            1261.106
V Predictions Mean           1573.8693
V Predictions Std            108.317345
V Predictions Max            1699.8925
V Predictions Min            1260.8085
Log Pis Mean                 -0.78293043
Log Pis Std                  1.6787906
Log Pis Max                  4.183743
Log Pis Min                  -9.194816
Policy mu Mean               -0.07786687
Policy mu Std                0.7411436
Policy mu Max                1.4438964
Policy mu Min                -2.5038595
Policy log std Mean          -0.40815
Policy log std Std           0.14978075
Policy log std Max           0.02300325
Policy log std Min           -1.1698582
Z mean eval                  0.032996632
Z variance eval              0.0056920685
total_rewards                [1523.20106524  687.18072168 1524.31155601  961.85027089  667.67896751
  677.58852111 1246.05452402  678.70453307  665.58047922  677.34652615]
total_rewards_mean           930.9497164898685
total_rewards_std            345.59739074533866
total_rewards_max            1524.311556011533
total_rewards_min            665.5804792225233
Number of train steps total  304000
Number of env steps total    1522000
Number of rollouts total     0
Train Time (s)               43.57157294405624
(Previous) Eval Time (s)     7.209875799249858
Sample Time (s)              21.533976946026087
Epoch Time (s)               72.31542568933219
Total Train Time (s)         24612.99553020764
Epoch                        303
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:38:33.149112 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #303 | Epoch Duration: 74.40962624549866
2020-01-11 07:38:33.149295 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #303 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03311576
Z variance train             0.005684052
KL Divergence                10.948637
KL Loss                      1.0948638
QF Loss                      63.014748
VF Loss                      34.877453
Policy Loss                  -1574.0276
Q Predictions Mean           1575.1089
Q Predictions Std            108.79437
Q Predictions Max            1715.6932
Q Predictions Min            1279.1663
V Predictions Mean           1573.2104
V Predictions Std            108.808365
V Predictions Max            1710.5089
V Predictions Min            1272.3059
Log Pis Mean                 -0.6366846
Log Pis Std                  1.5661882
Log Pis Max                  4.6704063
Log Pis Min                  -5.4610853
Policy mu Mean               0.04652549
Policy mu Std                0.76942766
Policy mu Max                1.8188392
Policy mu Min                -2.3235762
Policy log std Mean          -0.41367948
Policy log std Std           0.14842898
Policy log std Max           -0.046515435
Policy log std Min           -0.9538859
Z mean eval                  0.023544708
Z variance eval              0.0053404937
total_rewards                [1217.60767222  922.47921608  686.73247675 1104.68012619 2051.1178641
  664.46278173 1746.84827111 1502.71751611  687.71857609  964.81687468]
total_rewards_mean           1154.91813750607
total_rewards_std            452.6764316544608
total_rewards_max            2051.117864097118
total_rewards_min            664.4627817332724
Number of train steps total  305000
Number of env steps total    1527000
Number of rollouts total     0
Train Time (s)               43.752070205286145
(Previous) Eval Time (s)     9.303830736782402
Sample Time (s)              21.43821882456541
Epoch Time (s)               74.49411976663396
Total Train Time (s)         24688.6613054974
Epoch                        304
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:39:48.819844 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #304 | Epoch Duration: 75.67041778564453
2020-01-11 07:39:48.820041 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #304 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023721768
Z variance train             0.00534606
KL Divergence                11.09484
KL Loss                      1.1094841
QF Loss                      109.1359
VF Loss                      51.771564
Policy Loss                  -1561.5413
Q Predictions Mean           1562.0151
Q Predictions Std            110.38781
Q Predictions Max            1700.2954
Q Predictions Min            1257.5831
V Predictions Mean           1559.2036
V Predictions Std            111.88798
V Predictions Max            1697.0466
V Predictions Min            1255.68
Log Pis Mean                 -0.67762774
Log Pis Std                  1.6947261
Log Pis Max                  4.780022
Log Pis Min                  -5.922353
Policy mu Mean               0.044492956
Policy mu Std                0.7681694
Policy mu Max                3.0445874
Policy mu Min                -2.2778213
Policy log std Mean          -0.3981779
Policy log std Std           0.14672685
Policy log std Max           -0.047412813
Policy log std Min           -1.1241518
Z mean eval                  0.01758303
Z variance eval              0.0056151813
total_rewards                [ 927.71011147  666.44910413  902.1243457   683.71160565  942.06225354
  971.1778049  1429.07957126  906.01628204  905.6914794   932.45312909]
total_rewards_mean           926.6475687175437
total_rewards_std            195.67335649300227
total_rewards_max            1429.0795712601314
total_rewards_min            666.4491041324267
Number of train steps total  306000
Number of env steps total    1532000
Number of rollouts total     0
Train Time (s)               44.30069108912721
(Previous) Eval Time (s)     10.479897025972605
Sample Time (s)              22.12555873207748
Epoch Time (s)               76.9061468471773
Total Train Time (s)         24764.218695231248
Epoch                        305
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:41:04.381435 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #305 | Epoch Duration: 75.56124567985535
2020-01-11 07:41:04.381606 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #305 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017499566
Z variance train             0.0056183683
KL Divergence                10.928062
KL Loss                      1.0928062
QF Loss                      360.56067
VF Loss                      64.57749
Policy Loss                  -1544.4006
Q Predictions Mean           1543.5084
Q Predictions Std            148.20888
Q Predictions Max            1702.898
Q Predictions Min            181.94878
V Predictions Mean           1540.7549
V Predictions Std            147.33228
V Predictions Max            1696.4569
V Predictions Min            168.21672
Log Pis Mean                 -0.770729
Log Pis Std                  1.669648
Log Pis Max                  3.9371865
Log Pis Min                  -5.565453
Policy mu Mean               0.214625
Policy mu Std                0.7466558
Policy mu Max                1.9041324
Policy mu Min                -2.2979276
Policy log std Mean          -0.41250268
Policy log std Std           0.13963346
Policy log std Max           0.087703735
Policy log std Min           -1.047816
Z mean eval                  0.01946177
Z variance eval              0.0052672997
total_rewards                [ 940.21041411 2040.04633457  641.83200509  660.98349601  670.50164961
  663.63720252  829.14183379  935.84380519  678.55163639  659.20168504]
total_rewards_mean           871.9950062325879
total_rewards_std            404.8610943971384
total_rewards_max            2040.046334567353
total_rewards_min            641.8320050947281
Number of train steps total  307000
Number of env steps total    1537000
Number of rollouts total     0
Train Time (s)               43.52748491289094
(Previous) Eval Time (s)     9.134741642978042
Sample Time (s)              22.398944261483848
Epoch Time (s)               75.06117081735283
Total Train Time (s)         24838.620691689663
Epoch                        306
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:42:18.785199 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #306 | Epoch Duration: 74.40347456932068
2020-01-11 07:42:18.785321 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #306 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019331899
Z variance train             0.0052659707
KL Divergence                11.118235
KL Loss                      1.1118234
QF Loss                      68.20291
VF Loss                      40.37908
Policy Loss                  -1594.9419
Q Predictions Mean           1595.1313
Q Predictions Std            122.0576
Q Predictions Max            1739.3394
Q Predictions Min            852.7819
V Predictions Mean           1597.1892
V Predictions Std            122.91231
V Predictions Max            1742.5264
V Predictions Min            833.17834
Log Pis Mean                 -0.636546
Log Pis Std                  1.6764902
Log Pis Max                  4.42223
Log Pis Min                  -5.324046
Policy mu Mean               0.14230533
Policy mu Std                0.74576926
Policy mu Max                1.9656533
Policy mu Min                -2.650637
Policy log std Mean          -0.40157926
Policy log std Std           0.15236391
Policy log std Max           -0.006198257
Policy log std Min           -1.1297224
Z mean eval                  0.025569955
Z variance eval              0.005944919
total_rewards                [ 933.10006144  706.08392176  705.64396861  911.74631034  693.55552003
 1021.20766059 1236.4754879   696.54777056  999.0566447   938.44984569]
total_rewards_mean           884.1867191612312
total_rewards_std            172.4298399678868
total_rewards_max            1236.475487900548
total_rewards_min            693.5555200262183
Number of train steps total  308000
Number of env steps total    1542000
Number of rollouts total     0
Train Time (s)               43.4625813937746
(Previous) Eval Time (s)     8.476812905166298
Sample Time (s)              21.589231914374977
Epoch Time (s)               73.52862621331587
Total Train Time (s)         24911.4869130305
Epoch                        307
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:43:31.655134 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #307 | Epoch Duration: 72.86970281600952
2020-01-11 07:43:31.655295 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #307 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025523484
Z variance train             0.005946162
KL Divergence                10.709993
KL Loss                      1.0709994
QF Loss                      49.881496
VF Loss                      38.369423
Policy Loss                  -1583.2947
Q Predictions Mean           1585.5369
Q Predictions Std            145.52473
Q Predictions Max            1746.6099
Q Predictions Min            159.59727
V Predictions Mean           1586.6436
V Predictions Std            145.47101
V Predictions Max            1749.2502
V Predictions Min            176.87387
Log Pis Mean                 -0.731531
Log Pis Std                  1.7277
Log Pis Max                  4.201536
Log Pis Min                  -5.9453125
Policy mu Mean               0.084681414
Policy mu Std                0.7584547
Policy mu Max                1.9998726
Policy mu Min                -2.2411556
Policy log std Mean          -0.39748183
Policy log std Std           0.16092819
Policy log std Max           -0.005213648
Policy log std Min           -1.3182544
Z mean eval                  0.018298175
Z variance eval              0.007070626
total_rewards                [ 682.26065469 1167.10986396 1007.47805771 1225.35761947 2075.84513913
 1008.63963664  977.23923265  991.51837737  985.03791625  930.9799345 ]
total_rewards_mean           1105.1466432376005
total_rewards_std            351.0360153764841
total_rewards_max            2075.8451391335816
total_rewards_min            682.2606546870323
Number of train steps total  309000
Number of env steps total    1547000
Number of rollouts total     0
Train Time (s)               43.211109892930835
(Previous) Eval Time (s)     7.817656164988875
Sample Time (s)              19.7558690845035
Epoch Time (s)               70.78463514242321
Total Train Time (s)         24985.296397794504
Epoch                        308
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:44:45.469085 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #308 | Epoch Duration: 73.81364679336548
2020-01-11 07:44:45.469261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #308 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018326107
Z variance train             0.007045319
KL Divergence                10.162836
KL Loss                      1.0162836
QF Loss                      206.05643
VF Loss                      101.94348
Policy Loss                  -1563.1815
Q Predictions Mean           1568.1599
Q Predictions Std            124.25857
Q Predictions Max            1731.8159
Q Predictions Min            1163.7904
V Predictions Mean           1560.9082
V Predictions Std            123.50123
V Predictions Max            1721.1509
V Predictions Min            1251.2692
Log Pis Mean                 -0.56113374
Log Pis Std                  1.9276264
Log Pis Max                  9.281296
Log Pis Min                  -4.7727327
Policy mu Mean               0.06250777
Policy mu Std                0.79752284
Policy mu Max                1.9439701
Policy mu Min                -2.740313
Policy log std Mean          -0.41375664
Policy log std Std           0.18372795
Policy log std Max           0.04887572
Policy log std Min           -1.2744313
Z mean eval                  0.018095724
Z variance eval              0.0075516934
total_rewards                [658.65028528 999.08651237 933.74993998 650.51267998 656.1288773
 661.54031608 940.17417995 938.95196085 673.51420128 941.08096324]
total_rewards_mean           805.3389916315589
total_rewards_std            146.38803430299112
total_rewards_max            999.0865123699622
total_rewards_min            650.5126799816403
Number of train steps total  310000
Number of env steps total    1552000
Number of rollouts total     0
Train Time (s)               44.06038928683847
(Previous) Eval Time (s)     10.846431476995349
Sample Time (s)              22.91354905627668
Epoch Time (s)               77.8203698201105
Total Train Time (s)         25059.50395769812
Epoch                        309
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:45:59.683138 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #309 | Epoch Duration: 74.21371030807495
2020-01-11 07:45:59.683401 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #309 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018544914
Z variance train             0.0075529604
KL Divergence                10.167841
KL Loss                      1.0167841
QF Loss                      57.13797
VF Loss                      71.37454
Policy Loss                  -1583.605
Q Predictions Mean           1583.0857
Q Predictions Std            166.65425
Q Predictions Max            1737.3525
Q Predictions Min            158.0454
V Predictions Mean           1580.188
V Predictions Std            168.32939
V Predictions Max            1734.5824
V Predictions Min            160.10414
Log Pis Mean                 -0.75372493
Log Pis Std                  1.6339861
Log Pis Max                  3.453133
Log Pis Min                  -5.8345137
Policy mu Mean               0.11532703
Policy mu Std                0.7389652
Policy mu Max                1.8620465
Policy mu Min                -2.310659
Policy log std Mean          -0.4033723
Policy log std Std           0.15523286
Policy log std Max           -0.03720033
Policy log std Min           -1.1895897
Z mean eval                  0.020526718
Z variance eval              0.007013702
total_rewards                [ 793.62288332  990.29945882  739.13912689 1028.52663035  807.1364025
  998.71356757  948.31150504  886.60883953 2051.53225068  942.87100203]
total_rewards_mean           1018.6761666728532
total_rewards_std            356.3384432100317
total_rewards_max            2051.532250679598
total_rewards_min            739.1391268912878
Number of train steps total  311000
Number of env steps total    1557000
Number of rollouts total     0
Train Time (s)               44.49184877006337
(Previous) Eval Time (s)     7.2395106120966375
Sample Time (s)              21.657291805837303
Epoch Time (s)               73.38865118799731
Total Train Time (s)         25135.17485576868
Epoch                        310
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:47:15.355489 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #310 | Epoch Duration: 75.67186975479126
2020-01-11 07:47:15.355613 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #310 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020457037
Z variance train             0.00701216
KL Divergence                10.516094
KL Loss                      1.0516094
QF Loss                      39.810646
VF Loss                      34.2018
Policy Loss                  -1583.2036
Q Predictions Mean           1582.844
Q Predictions Std            121.03185
Q Predictions Max            1754.1564
Q Predictions Min            1259.9381
V Predictions Mean           1582.0286
V Predictions Std            121.47234
V Predictions Max            1752.1786
V Predictions Min            1258.5142
Log Pis Mean                 -0.7715813
Log Pis Std                  1.6960912
Log Pis Max                  5.909898
Log Pis Min                  -5.62728
Policy mu Mean               0.13292016
Policy mu Std                0.7551717
Policy mu Max                1.9423974
Policy mu Min                -2.561604
Policy log std Mean          -0.42125598
Policy log std Std           0.14950472
Policy log std Max           0.09231186
Policy log std Min           -0.98029566
Z mean eval                  0.049547315
Z variance eval              0.006511529
total_rewards                [ 801.38017456  886.07826378  952.91346264  820.88811626  833.53495406
  795.13007497 1019.85336641  826.21305889  782.39423003  957.37223764]
total_rewards_mean           867.5757939248575
total_rewards_std            77.98221232949706
total_rewards_max            1019.8533664134777
total_rewards_min            782.3942300314427
Number of train steps total  312000
Number of env steps total    1562000
Number of rollouts total     0
Train Time (s)               44.2501554870978
(Previous) Eval Time (s)     9.5225272863172
Sample Time (s)              21.799235832411796
Epoch Time (s)               75.5719186058268
Total Train Time (s)         25209.166262989864
Epoch                        311
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:48:29.349280 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #311 | Epoch Duration: 73.99357271194458
2020-01-11 07:48:29.349406 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #311 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05272895
Z variance train             0.006489233
KL Divergence                10.771063
KL Loss                      1.0771064
QF Loss                      85.67027
VF Loss                      62.469692
Policy Loss                  -1608.0116
Q Predictions Mean           1607.2375
Q Predictions Std            117.48548
Q Predictions Max            1770.555
Q Predictions Min            1284.412
V Predictions Mean           1604.459
V Predictions Std            118.3157
V Predictions Max            1766.0496
V Predictions Min            1277.7504
Log Pis Mean                 -0.90004516
Log Pis Std                  1.6395224
Log Pis Max                  4.592739
Log Pis Min                  -7.124709
Policy mu Mean               0.03795031
Policy mu Std                0.73936474
Policy mu Max                1.8070592
Policy mu Min                -2.8313003
Policy log std Mean          -0.42719653
Policy log std Std           0.14100984
Policy log std Max           -0.057346642
Policy log std Min           -1.4108491
Z mean eval                  0.031695865
Z variance eval              0.0058772946
total_rewards                [ 799.34572562  865.7199558   877.11952483  840.84690118  847.27123175
  915.17372978  772.18436433 1055.0756935   881.29980612 1020.64613016]
total_rewards_mean           887.468306305341
total_rewards_std            84.8879465193568
total_rewards_max            1055.075693496177
total_rewards_min            772.1843643311884
Number of train steps total  313000
Number of env steps total    1567000
Number of rollouts total     0
Train Time (s)               43.844319318886846
(Previous) Eval Time (s)     7.943938240874559
Sample Time (s)              21.810737289022654
Epoch Time (s)               73.59899484878406
Total Train Time (s)         25282.273555345833
Epoch                        312
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:49:42.460917 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #312 | Epoch Duration: 73.11140656471252
2020-01-11 07:49:42.461065 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #312 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031198552
Z variance train             0.0058818134
KL Divergence                10.921141
KL Loss                      1.0921141
QF Loss                      66.84595
VF Loss                      72.45666
Policy Loss                  -1588.9454
Q Predictions Mean           1587.6404
Q Predictions Std            146.21269
Q Predictions Max            1760.3389
Q Predictions Min            594.5371
V Predictions Mean           1583.0325
V Predictions Std            146.56784
V Predictions Max            1758.7089
V Predictions Min            561.11926
Log Pis Mean                 -0.61463714
Log Pis Std                  1.7805392
Log Pis Max                  8.172039
Log Pis Min                  -3.897586
Policy mu Mean               0.0783088
Policy mu Std                0.7698254
Policy mu Max                2.2067456
Policy mu Min                -3.302696
Policy log std Mean          -0.42502776
Policy log std Std           0.16595684
Policy log std Max           -0.0005221665
Policy log std Min           -1.4975607
Z mean eval                  0.028946644
Z variance eval              0.005575747
total_rewards                [ 837.59948109  908.31436078 1840.57462962  835.86240272  900.14314889
 1032.82007163 1487.75700592  795.42223594  786.80633779  822.07098895]
total_rewards_mean           1024.7370663353547
total_rewards_std            336.1674576815333
total_rewards_max            1840.5746296226685
total_rewards_min            786.8063377948681
Number of train steps total  314000
Number of env steps total    1572000
Number of rollouts total     0
Train Time (s)               43.81738266395405
(Previous) Eval Time (s)     7.456094016321003
Sample Time (s)              21.551520962268114
Epoch Time (s)               72.82499764254317
Total Train Time (s)         25357.498048777226
Epoch                        313
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:50:57.687198 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #313 | Epoch Duration: 75.22601675987244
2020-01-11 07:50:57.687318 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #313 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029261187
Z variance train             0.005579276
KL Divergence                11.09017
KL Loss                      1.109017
QF Loss                      58.723583
VF Loss                      57.722073
Policy Loss                  -1566.1938
Q Predictions Mean           1564.6113
Q Predictions Std            182.22513
Q Predictions Max            1746.2649
Q Predictions Min            203.20723
V Predictions Mean           1563.7411
V Predictions Std            180.76329
V Predictions Max            1739.8265
V Predictions Min            194.74399
Log Pis Mean                 -0.6450721
Log Pis Std                  1.5600191
Log Pis Max                  3.9761264
Log Pis Min                  -5.3677516
Policy mu Mean               0.030248975
Policy mu Std                0.76594514
Policy mu Max                2.5713873
Policy mu Min                -1.984333
Policy log std Mean          -0.40613517
Policy log std Std           0.15773304
Policy log std Max           0.07574484
Policy log std Min           -1.2473772
Z mean eval                  0.011793645
Z variance eval              0.0069126626
total_rewards                [877.110503   999.26044952 974.86772402 800.39090371 879.52239258
 823.92336743 900.99266489 749.04381889 717.40147286 840.64037721]
total_rewards_mean           856.3153674107514
total_rewards_std            85.25360414152382
total_rewards_max            999.2604495196645
total_rewards_min            717.4014728641733
Number of train steps total  315000
Number of env steps total    1577000
Number of rollouts total     0
Train Time (s)               43.798387050163
(Previous) Eval Time (s)     9.85687794117257
Sample Time (s)              21.804841002449393
Epoch Time (s)               75.46010599378496
Total Train Time (s)         25431.4231235818
Epoch                        314
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:52:11.614560 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #314 | Epoch Duration: 73.92714142799377
2020-01-11 07:52:11.614684 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #314 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011365612
Z variance train             0.0069214515
KL Divergence                10.719057
KL Loss                      1.0719057
QF Loss                      55.471325
VF Loss                      31.778687
Policy Loss                  -1591.7369
Q Predictions Mean           1589.7872
Q Predictions Std            141.22542
Q Predictions Max            1760.0074
Q Predictions Min            524.5599
V Predictions Mean           1590.1152
V Predictions Std            140.7838
V Predictions Max            1761.9517
V Predictions Min            486.0982
Log Pis Mean                 -0.6290919
Log Pis Std                  1.7426682
Log Pis Max                  6.795663
Log Pis Min                  -5.3987126
Policy mu Mean               0.02533712
Policy mu Std                0.76828694
Policy mu Max                1.805138
Policy mu Min                -2.7161577
Policy log std Mean          -0.41432557
Policy log std Std           0.14098425
Policy log std Max           0.011154592
Policy log std Min           -0.94381905
Z mean eval                  0.019201528
Z variance eval              0.0059985695
total_rewards                [1038.60492068  767.18559827  710.56350812  900.29578212  928.19511327
  920.97414999  761.02134964 1081.27093517  789.61820661 1035.41907601]
total_rewards_mean           893.314863988047
total_rewards_std            124.9887650498189
total_rewards_max            1081.2709351707756
total_rewards_min            710.5635081175852
Number of train steps total  316000
Number of env steps total    1582000
Number of rollouts total     0
Train Time (s)               43.52071629976854
(Previous) Eval Time (s)     8.323658614885062
Sample Time (s)              21.607981910463423
Epoch Time (s)               73.45235682511702
Total Train Time (s)         25504.927920886315
Epoch                        315
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:53:25.127359 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #315 | Epoch Duration: 73.51252841949463
2020-01-11 07:53:25.127661 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #315 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01917739
Z variance train             0.0060010264
KL Divergence                10.792269
KL Loss                      1.0792269
QF Loss                      97.235176
VF Loss                      51.51295
Policy Loss                  -1584.6093
Q Predictions Mean           1585.9177
Q Predictions Std            144.54655
Q Predictions Max            1757.3474
Q Predictions Min            851.6149
V Predictions Mean           1585.863
V Predictions Std            141.53964
V Predictions Max            1753.893
V Predictions Min            826.39575
Log Pis Mean                 -0.4581018
Log Pis Std                  1.8617
Log Pis Max                  10.246071
Log Pis Min                  -5.1630745
Policy mu Mean               0.15575463
Policy mu Std                0.8183094
Policy mu Max                3.4421778
Policy mu Min                -2.9931486
Policy log std Mean          -0.43703735
Policy log std Std           0.15733507
Policy log std Max           0.007882804
Policy log std Min           -1.2485859
Z mean eval                  0.028385645
Z variance eval              0.006272608
total_rewards                [ 898.98897448 1048.99991025 1895.54465774 1001.70943676 1015.26163861
 1004.16033099 1027.22095991 1891.3152241   908.6696611   903.60322806]
total_rewards_mean           1159.547402199229
total_rewards_std            370.5565062114333
total_rewards_max            1895.5446577386617
total_rewards_min            898.9889744810911
Number of train steps total  317000
Number of env steps total    1587000
Number of rollouts total     0
Train Time (s)               44.63431650400162
(Previous) Eval Time (s)     8.383576071821153
Sample Time (s)              21.28289634268731
Epoch Time (s)               74.30078891851008
Total Train Time (s)         25582.2989564999
Epoch                        316
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:54:42.499501 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #316 | Epoch Duration: 77.3716287612915
2020-01-11 07:54:42.499620 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #316 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02911746
Z variance train             0.0063015064
KL Divergence                10.897984
KL Loss                      1.0897983
QF Loss                      196.30862
VF Loss                      270.2513
Policy Loss                  -1588.9398
Q Predictions Mean           1594.957
Q Predictions Std            158.67401
Q Predictions Max            1778.5199
Q Predictions Min            160.54355
V Predictions Mean           1596.6824
V Predictions Std            159.27527
V Predictions Max            1795.115
V Predictions Min            158.39398
Log Pis Mean                 -0.5788642
Log Pis Std                  1.7474046
Log Pis Max                  7.293186
Log Pis Min                  -5.1400614
Policy mu Mean               0.012535562
Policy mu Std                0.7988544
Policy mu Max                1.7877607
Policy mu Min                -3.1730366
Policy log std Mean          -0.41365167
Policy log std Std           0.15356019
Policy log std Max           -0.0006393492
Policy log std Min           -1.5859387
Z mean eval                  0.039470747
Z variance eval              0.0062099057
total_rewards                [ 925.13686064 1011.63300663 1732.43690088  741.27763243 3265.84296213
  924.10581991  715.01065505  888.52977391 1260.71320536  899.8935966 ]
total_rewards_mean           1236.458041352831
total_rewards_std            732.2197963459531
total_rewards_max            3265.842962126712
total_rewards_min            715.0106550459643
Number of train steps total  318000
Number of env steps total    1592000
Number of rollouts total     0
Train Time (s)               43.826358647085726
(Previous) Eval Time (s)     11.454204814974219
Sample Time (s)              21.74682102492079
Epoch Time (s)               77.02738448698074
Total Train Time (s)         25660.535860163625
Epoch                        317
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:56:00.744691 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #317 | Epoch Duration: 78.24495768547058
2020-01-11 07:56:00.744875 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #317 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035602685
Z variance train             0.0062168133
KL Divergence                10.722432
KL Loss                      1.0722432
QF Loss                      178.53577
VF Loss                      162.4192
Policy Loss                  -1578.2164
Q Predictions Mean           1580.1709
Q Predictions Std            169.51228
Q Predictions Max            1749.2705
Q Predictions Min            501.7759
V Predictions Mean           1587.6909
V Predictions Std            169.07133
V Predictions Max            1754.4033
V Predictions Min            481.42
Log Pis Mean                 -0.74901557
Log Pis Std                  1.7503573
Log Pis Max                  9.499966
Log Pis Min                  -5.03995
Policy mu Mean               -0.011087908
Policy mu Std                0.7873071
Policy mu Max                1.7290282
Policy mu Min                -3.8169618
Policy log std Mean          -0.42254546
Policy log std Std           0.1810847
Policy log std Max           0.04102233
Policy log std Min           -1.4159881
Z mean eval                  0.020217488
Z variance eval              0.0064376285
total_rewards                [1312.86287614 2865.65477964 1420.36014764 2608.44993545 2105.95970446
 3152.32802049  866.72186336  838.76806562 3166.02681647 2694.89221208]
total_rewards_mean           2103.2024421357573
total_rewards_std            873.8170206407938
total_rewards_max            3166.0268164736262
total_rewards_min            838.7680656183535
Number of train steps total  319000
Number of env steps total    1597000
Number of rollouts total     0
Train Time (s)               44.41506898403168
(Previous) Eval Time (s)     12.671517636161298
Sample Time (s)              21.676887661684304
Epoch Time (s)               78.76347428187728
Total Train Time (s)         25747.436628390104
Epoch                        318
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:57:27.646997 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #318 | Epoch Duration: 86.9019923210144
2020-01-11 07:57:27.647130 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #318 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020777661
Z variance train             0.0064405976
KL Divergence                10.5047
KL Loss                      1.05047
QF Loss                      107.54952
VF Loss                      122.585014
Policy Loss                  -1577.8179
Q Predictions Mean           1579.907
Q Predictions Std            182.71275
Q Predictions Max            1768.8394
Q Predictions Min            520.4053
V Predictions Mean           1586.0802
V Predictions Std            182.3507
V Predictions Max            1784.2445
V Predictions Min            525.968
Log Pis Mean                 -0.5030364
Log Pis Std                  1.7978052
Log Pis Max                  12.29676
Log Pis Min                  -5.896312
Policy mu Mean               -0.011347513
Policy mu Std                0.78740674
Policy mu Max                2.6065402
Policy mu Min                -3.6261425
Policy log std Mean          -0.4328173
Policy log std Std           0.16128984
Policy log std Max           0.020773053
Policy log std Min           -1.2768158
Z mean eval                  0.021537198
Z variance eval              0.0060772365
total_rewards                [2255.36568801 3240.06922743 3232.93099004 3157.83983386 1078.87785568
 3230.18622783 2394.63991665 3224.62228884 1179.78893085 3148.32295328]
total_rewards_mean           2614.264391248575
total_rewards_std            818.4829982342874
total_rewards_max            3240.0692274336407
total_rewards_min            1078.8778556796474
Number of train steps total  320000
Number of env steps total    1602000
Number of rollouts total     0
Train Time (s)               44.04644576180726
(Previous) Eval Time (s)     20.809801507741213
Sample Time (s)              21.579447130672634
Epoch Time (s)               86.43569440022111
Total Train Time (s)         25839.901475212537
Epoch                        319
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 07:59:00.114040 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #319 | Epoch Duration: 92.46681094169617
2020-01-11 07:59:00.114164 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #319 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021672685
Z variance train             0.0060777087
KL Divergence                10.509211
KL Loss                      1.0509211
QF Loss                      52.654465
VF Loss                      17.401268
Policy Loss                  -1599.0238
Q Predictions Mean           1599.2871
Q Predictions Std            126.1851
Q Predictions Max            1772.7433
Q Predictions Min            1080.0691
V Predictions Mean           1599.4719
V Predictions Std            124.168526
V Predictions Max            1768.4897
V Predictions Min            1138.2672
Log Pis Mean                 -0.5371586
Log Pis Std                  1.7361168
Log Pis Max                  5.1400023
Log Pis Min                  -5.7621975
Policy mu Mean               0.12050583
Policy mu Std                0.7958763
Policy mu Max                1.966441
Policy mu Min                -2.596932
Policy log std Mean          -0.40709546
Policy log std Std           0.15278797
Policy log std Max           0.10564694
Policy log std Min           -1.1765176
Z mean eval                  0.016439762
Z variance eval              0.0052978247
total_rewards                [3200.6656114  1153.90337762 2810.36960757 3234.85204839 3186.85811622
 1935.57242345 3245.94789176  967.22044988 1188.39522545  724.67961212]
total_rewards_mean           2164.8464363858766
total_rewards_std            1019.0308955955255
total_rewards_max            3245.9478917551546
total_rewards_min            724.6796121178429
Number of train steps total  321000
Number of env steps total    1607000
Number of rollouts total     0
Train Time (s)               45.012574716005474
(Previous) Eval Time (s)     26.840676533058286
Sample Time (s)              21.723888197913766
Epoch Time (s)               93.57713944697753
Total Train Time (s)         25928.607481598854
Epoch                        320
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:00:28.822080 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #320 | Epoch Duration: 88.70782208442688
2020-01-11 08:00:28.822203 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #320 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016358163
Z variance train             0.0052896524
KL Divergence                10.903791
KL Loss                      1.0903791
QF Loss                      223.36652
VF Loss                      73.15917
Policy Loss                  -1600.1826
Q Predictions Mean           1597.5764
Q Predictions Std            146.4906
Q Predictions Max            1759.1925
Q Predictions Min            333.85684
V Predictions Mean           1602.4456
V Predictions Std            147.60172
V Predictions Max            1767.9719
V Predictions Min            300.42175
Log Pis Mean                 -0.64080167
Log Pis Std                  1.6446128
Log Pis Max                  4.5088973
Log Pis Min                  -4.2070985
Policy mu Mean               0.067366764
Policy mu Std                0.7684579
Policy mu Max                2.095186
Policy mu Min                -2.4656994
Policy log std Mean          -0.42167583
Policy log std Std           0.17017499
Policy log std Max           0.12238696
Policy log std Min           -1.3736085
Z mean eval                  0.021297824
Z variance eval              0.0044701486
total_rewards                [1549.57067746 1973.6930712  1755.60239868 2209.74347946 2301.6323085
 1139.87153565 3211.18069727 1847.7400207   664.88860124 1798.00774111]
total_rewards_mean           1845.1930531256044
total_rewards_std            648.9928630596943
total_rewards_max            3211.1806972684044
total_rewards_min            664.8886012375676
Number of train steps total  322000
Number of env steps total    1612000
Number of rollouts total     0
Train Time (s)               44.28610119828954
(Previous) Eval Time (s)     21.97111358633265
Sample Time (s)              22.374645525123924
Epoch Time (s)               88.63186030974612
Total Train Time (s)         26014.258660362568
Epoch                        321
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:01:54.475298 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #321 | Epoch Duration: 85.65300250053406
2020-01-11 08:01:54.475422 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #321 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020256285
Z variance train             0.004469757
KL Divergence                11.331961
KL Loss                      1.1331961
QF Loss                      125.28469
VF Loss                      65.57204
Policy Loss                  -1589.0814
Q Predictions Mean           1589.7415
Q Predictions Std            176.21918
Q Predictions Max            1763.1135
Q Predictions Min            319.2912
V Predictions Mean           1590.775
V Predictions Std            177.55074
V Predictions Max            1763.2277
V Predictions Min            289.3324
Log Pis Mean                 -0.5851505
Log Pis Std                  1.7613602
Log Pis Max                  6.750832
Log Pis Min                  -4.704011
Policy mu Mean               0.07421831
Policy mu Std                0.8289577
Policy mu Max                2.0421727
Policy mu Min                -3.1128204
Policy log std Mean          -0.41215885
Policy log std Std           0.15478523
Policy log std Max           0.06090334
Policy log std Min           -1.2083068
Z mean eval                  0.014184949
Z variance eval              0.0043439474
total_rewards                [ 976.50742807 3090.47581007 1159.24736388 1377.19144999 1140.84819158
  660.8986527  3156.81019955 2175.24952608  845.50596336  839.30709418]
total_rewards_mean           1542.2041679461051
total_rewards_std            884.0803565568157
total_rewards_max            3156.810199553944
total_rewards_min            660.8986526972903
Number of train steps total  323000
Number of env steps total    1617000
Number of rollouts total     0
Train Time (s)               43.76145833497867
(Previous) Eval Time (s)     18.99200346088037
Sample Time (s)              21.838416762650013
Epoch Time (s)               84.59187855850905
Total Train Time (s)         26094.268236011732
Epoch                        322
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:03:14.488415 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #322 | Epoch Duration: 80.01288437843323
2020-01-11 08:03:14.488582 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #322 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014545386
Z variance train             0.004347601
KL Divergence                11.393499
KL Loss                      1.1393499
QF Loss                      144.37277
VF Loss                      84.53502
Policy Loss                  -1606.28
Q Predictions Mean           1604.2991
Q Predictions Std            151.31244
Q Predictions Max            1781.5052
Q Predictions Min            560.40436
V Predictions Mean           1604.0359
V Predictions Std            151.57864
V Predictions Max            1786.4326
V Predictions Min            549.86523
Log Pis Mean                 -0.3888887
Log Pis Std                  1.9785043
Log Pis Max                  9.138994
Log Pis Min                  -5.9158573
Policy mu Mean               -0.011463758
Policy mu Std                0.8465474
Policy mu Max                2.095378
Policy mu Min                -3.977599
Policy log std Mean          -0.4384451
Policy log std Std           0.16910759
Policy log std Max           0.08063999
Policy log std Min           -1.3542173
Z mean eval                  0.013714209
Z variance eval              0.004566461
total_rewards                [1648.61935333 1610.03027573 2571.1429852  1075.12321735 3246.74714615
 2612.31799324 3137.52403588 3133.60741626 3155.81458972 3171.48304639]
total_rewards_mean           2536.2410059243157
total_rewards_std            761.4604601977808
total_rewards_max            3246.7471461469977
total_rewards_min            1075.1232173483147
Number of train steps total  324000
Number of env steps total    1622000
Number of rollouts total     0
Train Time (s)               44.62422355217859
(Previous) Eval Time (s)     14.412773524876684
Sample Time (s)              21.8647135309875
Epoch Time (s)               80.90171060804278
Total Train Time (s)         26186.89562969841
Epoch                        323
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:04:47.121449 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #323 | Epoch Duration: 92.63273620605469
2020-01-11 08:04:47.121583 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #323 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01421026
Z variance train             0.0045645256
KL Divergence                11.171366
KL Loss                      1.1171366
QF Loss                      428.9978
VF Loss                      119.88649
Policy Loss                  -1589.5177
Q Predictions Mean           1590.6415
Q Predictions Std            167.91449
Q Predictions Max            1763.9785
Q Predictions Min            56.097755
V Predictions Mean           1595.7511
V Predictions Std            167.55287
V Predictions Max            1771.4352
V Predictions Min            122.32607
Log Pis Mean                 -0.12518182
Log Pis Std                  2.1753345
Log Pis Max                  10.800411
Log Pis Min                  -4.6349926
Policy mu Mean               0.018370053
Policy mu Std                0.93536747
Policy mu Max                2.1948044
Policy mu Min                -3.926015
Policy log std Mean          -0.43440032
Policy log std Std           0.16081344
Policy log std Max           0.109568626
Policy log std Min           -1.290178
Z mean eval                  0.024430973
Z variance eval              0.0042838333
total_rewards                [3148.65692093 1206.83240068 2828.11483083  736.19395161 1793.5661692
 1920.49483912 3144.12890011 3129.24399385 2791.96039072 1597.07335945]
total_rewards_mean           2229.62657564871
total_rewards_std            844.2116970340994
total_rewards_max            3148.6569209309396
total_rewards_min            736.1939516081055
Number of train steps total  325000
Number of env steps total    1627000
Number of rollouts total     0
Train Time (s)               45.28055504988879
(Previous) Eval Time (s)     26.14354086201638
Sample Time (s)              21.27308055665344
Epoch Time (s)               92.69717646855861
Total Train Time (s)         26276.622056102846
Epoch                        324
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:06:16.850654 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #324 | Epoch Duration: 89.72895812988281
2020-01-11 08:06:16.850835 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #324 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024586875
Z variance train             0.004286547
KL Divergence                11.361498
KL Loss                      1.1361498
QF Loss                      202.81221
VF Loss                      168.70111
Policy Loss                  -1561.8666
Q Predictions Mean           1561.9692
Q Predictions Std            223.10387
Q Predictions Max            1761.7839
Q Predictions Min            92.251884
V Predictions Mean           1565.9651
V Predictions Std            220.37956
V Predictions Max            1758.0363
V Predictions Min            108.47826
Log Pis Mean                 -0.4548148
Log Pis Std                  1.8727231
Log Pis Max                  8.389824
Log Pis Min                  -4.6204915
Policy mu Mean               0.0423945
Policy mu Std                0.8382478
Policy mu Max                2.1185448
Policy mu Min                -3.841287
Policy log std Mean          -0.39366236
Policy log std Std           0.14935789
Policy log std Max           0.18274724
Policy log std Min           -1.2284615
Z mean eval                  0.033136744
Z variance eval              0.0048553487
total_rewards                [2505.93360259 3109.86144562 3112.78980455 2725.04010444 3117.21234601
 3084.75419081 3078.88324236 3078.22926113 3075.42550989 3189.22825649]
total_rewards_mean           3007.7357763897803
total_rewards_std            204.61132295867097
total_rewards_max            3189.2282564857423
total_rewards_min            2505.933602593562
Number of train steps total  326000
Number of env steps total    1632000
Number of rollouts total     0
Train Time (s)               44.25271269818768
(Previous) Eval Time (s)     23.175047306809574
Sample Time (s)              20.117600886151195
Epoch Time (s)               87.54536089114845
Total Train Time (s)         26371.7576639303
Epoch                        325
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:07:51.995331 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #325 | Epoch Duration: 95.14431858062744
2020-01-11 08:07:51.995645 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #325 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033422165
Z variance train             0.0048518055
KL Divergence                10.9813385
KL Loss                      1.0981339
QF Loss                      275.52753
VF Loss                      183.12025
Policy Loss                  -1592.5396
Q Predictions Mean           1592.2347
Q Predictions Std            161.87993
Q Predictions Max            1786.5835
Q Predictions Min            684.3089
V Predictions Mean           1583.8916
V Predictions Std            163.64278
V Predictions Max            1769.5029
V Predictions Min            674.0138
Log Pis Mean                 -0.44084132
Log Pis Std                  1.754055
Log Pis Max                  5.046939
Log Pis Min                  -3.951457
Policy mu Mean               0.05972572
Policy mu Std                0.8614762
Policy mu Max                2.0300193
Policy mu Min                -3.241343
Policy log std Mean          -0.41896844
Policy log std Std           0.17286432
Policy log std Max           -0.049818516
Policy log std Min           -1.3823814
Z mean eval                  0.012575368
Z variance eval              0.0045647137
total_rewards                [3169.06250889  993.921469   1254.39549307   23.32433956 2030.51348239
 3209.05278791  716.91629147  984.00604723 3213.25018605 2914.96931859]
total_rewards_mean           1850.9411924165966
total_rewards_std            1143.2550339270388
total_rewards_max            3213.250186049407
total_rewards_min            23.324339559331104
Number of train steps total  327000
Number of env steps total    1637000
Number of rollouts total     0
Train Time (s)               43.756329610943794
(Previous) Eval Time (s)     30.77373472834006
Sample Time (s)              21.71735625527799
Epoch Time (s)               96.24742059456185
Total Train Time (s)         26453.992702031508
Epoch                        326
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:09:14.233312 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #326 | Epoch Duration: 82.23743009567261
2020-01-11 08:09:14.233488 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #326 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.012588156
Z variance train             0.0045630718
KL Divergence                11.066974
KL Loss                      1.1066974
QF Loss                      127.80555
VF Loss                      80.51075
Policy Loss                  -1594.1525
Q Predictions Mean           1594.5852
Q Predictions Std            165.11766
Q Predictions Max            1775.8655
Q Predictions Min            469.6199
V Predictions Mean           1594.7026
V Predictions Std            162.37573
V Predictions Max            1773.651
V Predictions Min            486.94305
Log Pis Mean                 -0.45476812
Log Pis Std                  1.7947009
Log Pis Max                  10.626499
Log Pis Min                  -3.8283136
Policy mu Mean               0.087430775
Policy mu Std                0.8350529
Policy mu Max                2.5749183
Policy mu Min                -3.0843606
Policy log std Mean          -0.42250016
Policy log std Std           0.16181971
Policy log std Max           0.03153348
Policy log std Min           -1.1702523
Z mean eval                  0.014634356
Z variance eval              0.0044669234
total_rewards                [1733.91495569 1781.78286004  777.63836669 1115.9003072  2578.10796473
 1631.09224566 1052.73129329 1210.25342017 3287.49447911 2885.40238235]
total_rewards_mean           1805.431827493137
total_rewards_std            803.0287223039987
total_rewards_max            3287.494479112631
total_rewards_min            777.6383666862567
Number of train steps total  328000
Number of env steps total    1642000
Number of rollouts total     0
Train Time (s)               43.70379091706127
(Previous) Eval Time (s)     16.763499225024134
Sample Time (s)              21.683094382286072
Epoch Time (s)               82.15038452437147
Total Train Time (s)         26537.692538451403
Epoch                        327
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:10:37.937743 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #327 | Epoch Duration: 83.70411014556885
2020-01-11 08:10:37.937933 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #327 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01439731
Z variance train             0.0044714874
KL Divergence                11.065623
KL Loss                      1.1065624
QF Loss                      370.19876
VF Loss                      234.54785
Policy Loss                  -1606.4202
Q Predictions Mean           1604.7528
Q Predictions Std            131.84521
Q Predictions Max            1775.8882
Q Predictions Min            590.65204
V Predictions Mean           1600.9681
V Predictions Std            132.77994
V Predictions Max            1765.479
V Predictions Min            573.71704
Log Pis Mean                 -0.43165886
Log Pis Std                  2.0580583
Log Pis Max                  9.9997225
Log Pis Min                  -5.570334
Policy mu Mean               0.043258633
Policy mu Std                0.90673006
Policy mu Max                2.6365178
Policy mu Min                -3.3256395
Policy log std Mean          -0.40167055
Policy log std Std           0.16972707
Policy log std Max           0.198769
Policy log std Min           -1.4122872
Z mean eval                  0.03132275
Z variance eval              0.0053633116
total_rewards                [1851.77829733 3212.89512723  456.47295055  462.12769979 1575.88270012
 3264.60388153 1588.69063801  461.51501773 2727.83051418 1569.29228123]
total_rewards_mean           1717.1089107683033
total_rewards_std            1023.2689691777231
total_rewards_max            3264.603881528969
total_rewards_min            456.4729505480006
Number of train steps total  329000
Number of env steps total    1647000
Number of rollouts total     0
Train Time (s)               44.52558602206409
(Previous) Eval Time (s)     18.316982559859753
Sample Time (s)              22.139857369475067
Epoch Time (s)               84.98242595139891
Total Train Time (s)         26622.263045823667
Epoch                        328
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:12:02.514526 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #328 | Epoch Duration: 84.57643508911133
2020-01-11 08:12:02.514746 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #328 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031881567
Z variance train             0.00535968
KL Divergence                10.595966
KL Loss                      1.0595967
QF Loss                      72.76416
VF Loss                      140.97133
Policy Loss                  -1590.7874
Q Predictions Mean           1591.9937
Q Predictions Std            163.72598
Q Predictions Max            1780.7751
Q Predictions Min            634.4382
V Predictions Mean           1595.3469
V Predictions Std            165.02849
V Predictions Max            1780.923
V Predictions Min            610.9909
Log Pis Mean                 -0.15195596
Log Pis Std                  1.9223503
Log Pis Max                  8.400595
Log Pis Min                  -4.6056166
Policy mu Mean               0.07009832
Policy mu Std                0.88433504
Policy mu Max                2.086606
Policy mu Min                -3.9366555
Policy log std Mean          -0.41836587
Policy log std Std           0.16025811
Policy log std Max           0.007945359
Policy log std Min           -1.22406
Z mean eval                  0.015176279
Z variance eval              0.0050917426
total_rewards                [1080.839369   1018.99250506 1149.81996981  967.82771514  467.75280557
 3255.93074067 1390.6913524  1066.09391768  722.51641853  740.73643418]
total_rewards_mean           1186.120122802959
total_rewards_std            731.9633360352168
total_rewards_max            3255.9307406710154
total_rewards_min            467.7528055672306
Number of train steps total  330000
Number of env steps total    1652000
Number of rollouts total     0
Train Time (s)               43.6446664868854
(Previous) Eval Time (s)     17.910721326246858
Sample Time (s)              22.228083512280136
Epoch Time (s)               83.78347132541239
Total Train Time (s)         26700.25857352931
Epoch                        329
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:13:20.513650 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #329 | Epoch Duration: 77.99872875213623
2020-01-11 08:13:20.513830 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #329 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015058669
Z variance train             0.005093497
KL Divergence                10.754173
KL Loss                      1.0754174
QF Loss                      154.88943
VF Loss                      123.37998
Policy Loss                  -1583.3693
Q Predictions Mean           1580.3281
Q Predictions Std            141.24593
Q Predictions Max            1741.5704
Q Predictions Min            845.03546
V Predictions Mean           1583.6956
V Predictions Std            145.63193
V Predictions Max            1749.4946
V Predictions Min            850.34686
Log Pis Mean                 -0.5402349
Log Pis Std                  1.9946342
Log Pis Max                  11.006716
Log Pis Min                  -7.789568
Policy mu Mean               0.026856108
Policy mu Std                0.8281027
Policy mu Max                2.7114692
Policy mu Min                -2.998542
Policy log std Mean          -0.39563814
Policy log std Std           0.15215611
Policy log std Max           0.13566568
Policy log std Min           -1.0758739
Z mean eval                  0.018552154
Z variance eval              0.004931882
total_rewards                [2685.22003051  857.51678735 2871.78561568  855.20534687 2609.10721727
 1919.14430791 1487.64430215 2090.06835847 1255.78468307 1146.89947272]
total_rewards_mean           1777.8376122019931
total_rewards_std            726.746512644001
total_rewards_max            2871.7856156841226
total_rewards_min            855.2053468710034
Number of train steps total  331000
Number of env steps total    1657000
Number of rollouts total     0
Train Time (s)               44.08069920679554
(Previous) Eval Time (s)     12.125725517049432
Sample Time (s)              21.50679672975093
Epoch Time (s)               77.7132214535959
Total Train Time (s)         26783.56822864944
Epoch                        330
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:14:43.830174 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #330 | Epoch Duration: 83.3161473274231
2020-01-11 08:14:43.830413 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #330 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019806188
Z variance train             0.004927748
KL Divergence                11.028384
KL Loss                      1.1028384
QF Loss                      236.69046
VF Loss                      202.9501
Policy Loss                  -1574.4995
Q Predictions Mean           1573.2361
Q Predictions Std            212.93993
Q Predictions Max            1760.3478
Q Predictions Min            246.22676
V Predictions Mean           1578.5125
V Predictions Std            208.78627
V Predictions Max            1773.3541
V Predictions Min            241.10854
Log Pis Mean                 -0.69058555
Log Pis Std                  1.7827868
Log Pis Max                  5.4528074
Log Pis Min                  -6.645152
Policy mu Mean               -0.04658988
Policy mu Std                0.79471517
Policy mu Max                1.8956343
Policy mu Min                -2.9401395
Policy log std Mean          -0.3901794
Policy log std Std           0.17056037
Policy log std Max           -0.004907608
Policy log std Min           -1.3048357
Z mean eval                  0.051410817
Z variance eval              0.004416505
total_rewards                [ 822.35904242 1175.17440097 1153.11051988 1175.63736511  674.41284661
  999.741026   2396.66778238  970.78367146 1158.94593536  667.61791245]
total_rewards_mean           1119.4450502635964
total_rewards_std            465.5261225509768
total_rewards_max            2396.6677823847
total_rewards_min            667.6179124499729
Number of train steps total  332000
Number of env steps total    1662000
Number of rollouts total     0
Train Time (s)               44.43434979300946
(Previous) Eval Time (s)     17.728387143928558
Sample Time (s)              19.645544851198792
Epoch Time (s)               81.80828178813681
Total Train Time (s)         26859.305551290978
Epoch                        331
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:15:59.570003 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #331 | Epoch Duration: 75.73943519592285
2020-01-11 08:15:59.570144 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #331 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051622085
Z variance train             0.0044199396
KL Divergence                11.285092
KL Loss                      1.1285093
QF Loss                      90.55813
VF Loss                      62.762188
Policy Loss                  -1608.2975
Q Predictions Mean           1609.9481
Q Predictions Std            129.8586
Q Predictions Max            1768.4868
Q Predictions Min            733.20496
V Predictions Mean           1613.2395
V Predictions Std            129.46771
V Predictions Max            1769.6519
V Predictions Min            691.91345
Log Pis Mean                 -0.63791656
Log Pis Std                  1.7252047
Log Pis Max                  6.4486074
Log Pis Min                  -5.181603
Policy mu Mean               0.086588286
Policy mu Std                0.8097483
Policy mu Max                1.730436
Policy mu Min                -3.0193248
Policy log std Mean          -0.4171219
Policy log std Std           0.16407295
Policy log std Max           0.074038
Policy log std Min           -1.1575558
Z mean eval                  0.019300858
Z variance eval              0.004251418
total_rewards                [2662.93143003  995.47886126 2516.33691854 3165.57001169  896.453486
 1519.56313624 1536.06210062 1301.5869383  2004.6689888  1437.7856537 ]
total_rewards_mean           1803.6437525182253
total_rewards_std            718.0460113351136
total_rewards_max            3165.570011691921
total_rewards_min            896.4534859982169
Number of train steps total  333000
Number of env steps total    1667000
Number of rollouts total     0
Train Time (s)               43.519993271678686
(Previous) Eval Time (s)     11.659314261283726
Sample Time (s)              21.746665767394006
Epoch Time (s)               76.92597330035642
Total Train Time (s)         26940.81375456415
Epoch                        332
---------------------------  --------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:17:21.084888 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #332 | Epoch Duration: 81.51456022262573
2020-01-11 08:17:21.085124 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #332 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019133558
Z variance train             0.0042510764
KL Divergence                11.322966
KL Loss                      1.1322966
QF Loss                      93.17981
VF Loss                      247.99335
Policy Loss                  -1591.6161
Q Predictions Mean           1594.1105
Q Predictions Std            189.42323
Q Predictions Max            1786.3477
Q Predictions Min            282.13852
V Predictions Mean           1598.9525
V Predictions Std            192.1947
V Predictions Max            1808.4489
V Predictions Min            239.15216
Log Pis Mean                 -0.5786614
Log Pis Std                  1.6097333
Log Pis Max                  4.7855797
Log Pis Min                  -4.154455
Policy mu Mean               0.03525013
Policy mu Std                0.81994885
Policy mu Max                1.8901659
Policy mu Min                -3.266861
Policy log std Mean          -0.40471527
Policy log std Std           0.14772336
Policy log std Max           -0.007389039
Policy log std Min           -1.0415586
Z mean eval                  0.035123035
Z variance eval              0.005449222
total_rewards                [2376.95925875 1727.92656485 1381.89751511 1708.28232099 1110.67509813
 1742.71119996 3285.69449531 3079.01156616 1311.29533821  815.86015665]
total_rewards_mean           1854.031351412625
total_rewards_std            775.9560259390321
total_rewards_max            3285.6944953075113
total_rewards_min            815.860156647854
Number of train steps total  334000
Number of env steps total    1672000
Number of rollouts total     0
Train Time (s)               44.30104281893
(Previous) Eval Time (s)     16.247630076948553
Sample Time (s)              19.70622243359685
Epoch Time (s)               80.2548953294754
Total Train Time (s)         27023.80020328192
Epoch                        333
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:18:44.071073 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #333 | Epoch Duration: 82.9858021736145
2020-01-11 08:18:44.071200 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #333 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035016615
Z variance train             0.0054317787
KL Divergence                10.939215
KL Loss                      1.0939215
QF Loss                      123.84578
VF Loss                      126.34335
Policy Loss                  -1608.3978
Q Predictions Mean           1611.4829
Q Predictions Std            197.26456
Q Predictions Max            1790.915
Q Predictions Min            81.60528
V Predictions Mean           1615.0769
V Predictions Std            195.11288
V Predictions Max            1795.2749
V Predictions Min            155.31116
Log Pis Mean                 -0.42319593
Log Pis Std                  1.8539758
Log Pis Max                  6.038534
Log Pis Min                  -4.4164743
Policy mu Mean               0.008930002
Policy mu Std                0.8324524
Policy mu Max                2.4645295
Policy mu Min                -2.7712169
Policy log std Mean          -0.4105072
Policy log std Std           0.16605146
Policy log std Max           -0.061569378
Policy log std Min           -1.2516102
Z mean eval                  0.034831923
Z variance eval              0.0051335837
total_rewards                [ 943.23792395 1942.33073344  952.88650541 1010.58381569  820.97464591
  448.51634894 1007.63579127 1394.01425416 1710.69334429 1524.18651444]
total_rewards_mean           1175.5059877503459
total_rewards_std            430.9134123882593
total_rewards_max            1942.3307334440403
total_rewards_min            448.51634893900086
Number of train steps total  335000
Number of env steps total    1677000
Number of rollouts total     0
Train Time (s)               43.43440444115549
(Previous) Eval Time (s)     18.978283593896776
Sample Time (s)              19.882171478588134
Epoch Time (s)               82.2948595136404
Total Train Time (s)         27098.777397201397
Epoch                        334
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:19:59.050678 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #334 | Epoch Duration: 74.97938394546509
2020-01-11 08:19:59.050815 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #334 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03699854
Z variance train             0.0051426324
KL Divergence                11.028818
KL Loss                      1.1028818
QF Loss                      517.60144
VF Loss                      676.1959
Policy Loss                  -1614.8867
Q Predictions Mean           1621.9362
Q Predictions Std            163.49792
Q Predictions Max            1794.4316
Q Predictions Min            506.9538
V Predictions Mean           1598.7686
V Predictions Std            161.94786
V Predictions Max            1770.6869
V Predictions Min            507.07803
Log Pis Mean                 -0.5083604
Log Pis Std                  1.8826902
Log Pis Max                  6.87489
Log Pis Min                  -5.1070127
Policy mu Mean               0.05867836
Policy mu Std                0.8031593
Policy mu Max                2.0456777
Policy mu Min                -3.2384732
Policy log std Mean          -0.40559247
Policy log std Std           0.16191547
Policy log std Max           0.13876835
Policy log std Min           -1.4462572
Z mean eval                  0.014994006
Z variance eval              0.0057617845
total_rewards                [ 915.39527295 1082.42355672  870.71022253  949.61812627  776.06004613
  716.37733177 1224.13404445  948.20371712  925.59397956  927.39801005]
total_rewards_mean           933.5914307551014
total_rewards_std            135.4333607749352
total_rewards_max            1224.1340444511184
total_rewards_min            716.3773317670763
Number of train steps total  336000
Number of env steps total    1682000
Number of rollouts total     0
Train Time (s)               43.11377377901226
(Previous) Eval Time (s)     11.662600342184305
Sample Time (s)              21.745233917143196
Epoch Time (s)               76.52160803833976
Total Train Time (s)         27172.627932025585
Epoch                        335
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:21:12.905966 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #335 | Epoch Duration: 73.85504961013794
2020-01-11 08:21:12.906125 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #335 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014837032
Z variance train             0.0057516578
KL Divergence                10.663889
KL Loss                      1.066389
QF Loss                      330.52795
VF Loss                      134.37772
Policy Loss                  -1592.3864
Q Predictions Mean           1596.0164
Q Predictions Std            150.17372
Q Predictions Max            1792.9287
Q Predictions Min            531.13727
V Predictions Mean           1583.8398
V Predictions Std            148.11362
V Predictions Max            1784.8782
V Predictions Min            525.46246
Log Pis Mean                 -0.42256552
Log Pis Std                  1.5831581
Log Pis Max                  4.7776613
Log Pis Min                  -4.1446905
Policy mu Mean               -0.06392711
Policy mu Std                0.80811507
Policy mu Max                1.7265952
Policy mu Min                -2.951859
Policy log std Mean          -0.39565387
Policy log std Std           0.1606846
Policy log std Max           0.02311334
Policy log std Min           -1.2720339
Z mean eval                  0.034915935
Z variance eval              0.00509807
total_rewards                [1257.14844488  970.80494251 1064.18780746  775.00129315 1017.03838963
 1210.41768139 1626.00966138 3113.75955233  981.08353112 1006.42650921]
total_rewards_mean           1302.1877813073604
total_rewards_std            641.3563905093943
total_rewards_max            3113.7595523298664
total_rewards_min            775.0012931548617
Number of train steps total  337000
Number of env steps total    1687000
Number of rollouts total     0
Train Time (s)               43.91962854517624
(Previous) Eval Time (s)     8.995783212594688
Sample Time (s)              21.524741175118834
Epoch Time (s)               74.44015293288976
Total Train Time (s)         27251.693459875416
Epoch                        336
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:22:31.979171 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #336 | Epoch Duration: 79.07290863990784
2020-01-11 08:22:31.979362 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #336 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03487339
Z variance train             0.0051056272
KL Divergence                10.842577
KL Loss                      1.0842577
QF Loss                      769.6667
VF Loss                      97.27713
Policy Loss                  -1605.2633
Q Predictions Mean           1603.1724
Q Predictions Std            175.75754
Q Predictions Max            1789.1163
Q Predictions Min            41.536243
V Predictions Mean           1599.1262
V Predictions Std            176.12592
V Predictions Max            1788.601
V Predictions Min            -5.337884
Log Pis Mean                 -0.51305306
Log Pis Std                  1.7591677
Log Pis Max                  9.668308
Log Pis Min                  -4.8479643
Policy mu Mean               -0.0381669
Policy mu Std                0.8039585
Policy mu Max                1.7683108
Policy mu Min                -3.3680665
Policy log std Mean          -0.41152754
Policy log std Std           0.1673325
Policy log std Max           0.029325724
Policy log std Min           -1.7012882
Z mean eval                  0.024404129
Z variance eval              0.0055455063
total_rewards                [ 917.74992807  986.51007878 1080.73061938 2074.16446056  896.51830848
 1869.63004585  997.01776265 1406.29229018 1011.05292942  967.6282483 ]
total_rewards_mean           1220.72946716717
total_rewards_std            401.65857270468416
total_rewards_max            2074.1644605640413
total_rewards_min            896.518308481492
Number of train steps total  338000
Number of env steps total    1692000
Number of rollouts total     0
Train Time (s)               44.857825436163694
(Previous) Eval Time (s)     13.628277905285358
Sample Time (s)              21.841606095898896
Epoch Time (s)               80.32770943734795
Total Train Time (s)         27330.83136665076
Epoch                        337
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:23:51.119894 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #337 | Epoch Duration: 79.14038634300232
2020-01-11 08:23:51.120034 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #337 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024241263
Z variance train             0.005548147
KL Divergence                10.605716
KL Loss                      1.0605716
QF Loss                      98.773445
VF Loss                      110.49419
Policy Loss                  -1583.8966
Q Predictions Mean           1590.0161
Q Predictions Std            137.50146
Q Predictions Max            1779.9271
Q Predictions Min            660.0428
V Predictions Mean           1592.5577
V Predictions Std            138.66263
V Predictions Max            1783.5194
V Predictions Min            631.2348
Log Pis Mean                 -0.5394889
Log Pis Std                  1.633646
Log Pis Max                  5.5056825
Log Pis Min                  -4.354549
Policy mu Mean               -0.08165062
Policy mu Std                0.7941732
Policy mu Max                1.8152573
Policy mu Min                -3.3267996
Policy log std Mean          -0.4001753
Policy log std Std           0.16820814
Policy log std Max           0.019361585
Policy log std Min           -1.1431444
Z mean eval                  0.031405635
Z variance eval              0.005427887
total_rewards                [1194.66262961 1130.34946261 1650.13914083  917.63889337 1243.5072312
  819.09221943 1104.31694539  970.48717302 1034.47109053 1098.08102141]
total_rewards_mean           1116.2745807399529
total_rewards_std            215.34520343993154
total_rewards_max            1650.1391408309971
total_rewards_min            819.0922194303787
Number of train steps total  339000
Number of env steps total    1697000
Number of rollouts total     0
Train Time (s)               43.417569464072585
(Previous) Eval Time (s)     12.44071755791083
Sample Time (s)              22.827867821790278
Epoch Time (s)               78.68615484377369
Total Train Time (s)         27407.935516647063
Epoch                        338
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:25:08.232351 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #338 | Epoch Duration: 77.11222076416016
2020-01-11 08:25:08.232483 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #338 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031178284
Z variance train             0.005425027
KL Divergence                10.713856
KL Loss                      1.0713856
QF Loss                      446.79977
VF Loss                      424.51706
Policy Loss                  -1597.7517
Q Predictions Mean           1596.261
Q Predictions Std            162.92038
Q Predictions Max            1783.6855
Q Predictions Min            531.98865
V Predictions Mean           1591.622
V Predictions Std            167.1432
V Predictions Max            1794.3945
V Predictions Min            525.7832
Log Pis Mean                 -0.69855607
Log Pis Std                  1.9547533
Log Pis Max                  12.439182
Log Pis Min                  -4.9718394
Policy mu Mean               0.02571403
Policy mu Std                0.81130713
Policy mu Max                2.7160184
Policy mu Min                -3.4907193
Policy log std Mean          -0.38138768
Policy log std Std           0.17439073
Policy log std Max           0.08469483
Policy log std Min           -1.4843841
Z mean eval                  0.041306816
Z variance eval              0.0063190074
total_rewards                [2375.93258552  933.56581059  786.55314478 2004.20326746 1712.33582174
 1214.76729617 1056.82348972 1943.04077834 1207.21975585  797.77988684]
total_rewards_mean           1403.222183702624
total_rewards_std            534.3820341233657
total_rewards_max            2375.932585521153
total_rewards_min            786.5531447779603
Number of train steps total  340000
Number of env steps total    1702000
Number of rollouts total     0
Train Time (s)               44.19133966229856
(Previous) Eval Time (s)     10.866542446892709
Sample Time (s)              21.669571340084076
Epoch Time (s)               76.72745344927534
Total Train Time (s)         27487.91418771539
Epoch                        339
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:26:28.212034 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #339 | Epoch Duration: 79.97945618629456
2020-01-11 08:26:28.212155 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #339 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.041179504
Z variance train             0.0063129314
KL Divergence                10.476453
KL Loss                      1.0476453
QF Loss                      146.35614
VF Loss                      84.9545
Policy Loss                  -1601.4167
Q Predictions Mean           1603.0251
Q Predictions Std            137.28925
Q Predictions Max            1773.3228
Q Predictions Min            487.239
V Predictions Mean           1601.5908
V Predictions Std            136.21518
V Predictions Max            1767.0872
V Predictions Min            483.81534
Log Pis Mean                 -0.76502657
Log Pis Std                  1.5485584
Log Pis Max                  4.2740474
Log Pis Min                  -5.329573
Policy mu Mean               0.010869001
Policy mu Std                0.7745526
Policy mu Max                1.6379046
Policy mu Min                -2.290373
Policy log std Mean          -0.36612344
Policy log std Std           0.1602865
Policy log std Max           0.064453274
Policy log std Min           -1.3303021
Z mean eval                  0.021173839
Z variance eval              0.0060393754
total_rewards                [1480.07040757  906.09447297 1131.58674815 1505.28762619 1112.0339265
 1746.06864973 1230.92578505  959.77966234 1314.29325226 1431.21232406]
total_rewards_mean           1281.7352854828196
total_rewards_std            250.40118455064717
total_rewards_max            1746.0686497318734
total_rewards_min            906.0944729698882
Number of train steps total  341000
Number of env steps total    1707000
Number of rollouts total     0
Train Time (s)               43.445199297741055
(Previous) Eval Time (s)     14.118310886900872
Sample Time (s)              21.63758152909577
Epoch Time (s)               79.2010917137377
Total Train Time (s)         27565.7686310485
Epoch                        340
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:27:46.070149 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #340 | Epoch Duration: 77.85789155960083
2020-01-11 08:27:46.070311 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #340 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021744091
Z variance train             0.00603799
KL Divergence                10.458967
KL Loss                      1.0458968
QF Loss                      104.660645
VF Loss                      112.485
Policy Loss                  -1587.8466
Q Predictions Mean           1587.7596
Q Predictions Std            183.90051
Q Predictions Max            1791.5219
Q Predictions Min            39.807438
V Predictions Mean           1585.7831
V Predictions Std            183.65622
V Predictions Max            1787.3457
V Predictions Min            12.375993
Log Pis Mean                 -0.6906029
Log Pis Std                  1.7183712
Log Pis Max                  5.04734
Log Pis Min                  -4.059283
Policy mu Mean               -0.00073620304
Policy mu Std                0.79430073
Policy mu Max                2.4388828
Policy mu Min                -3.410467
Policy log std Mean          -0.41099653
Policy log std Std           0.18163012
Policy log std Max           0.04012531
Policy log std Min           -1.1709862
Z mean eval                  0.0150053445
Z variance eval              0.0071214996
total_rewards                [1020.98699732 3359.22098215 2429.29165837 1274.1085958  1000.9477961
 1211.94453911 1576.90625711 1800.24279467 1801.63413634 1011.21664973]
total_rewards_mean           1648.6500406695056
total_rewards_std            716.7830465836158
total_rewards_max            3359.2209821474553
total_rewards_min            1000.9477960967886
Number of train steps total  342000
Number of env steps total    1712000
Number of rollouts total     0
Train Time (s)               43.51511581707746
(Previous) Eval Time (s)     12.774838216137141
Sample Time (s)              22.294963569846004
Epoch Time (s)               78.5849176030606
Total Train Time (s)         27646.951120391954
Epoch                        341
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:29:07.254816 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #341 | Epoch Duration: 81.18438529968262
2020-01-11 08:29:07.254937 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #341 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0154912155
Z variance train             0.00710711
KL Divergence                10.233053
KL Loss                      1.0233053
QF Loss                      114.946754
VF Loss                      86.841354
Policy Loss                  -1612.1711
Q Predictions Mean           1614.8743
Q Predictions Std            164.36017
Q Predictions Max            1788.4463
Q Predictions Min            386.5205
V Predictions Mean           1618.1792
V Predictions Std            163.93875
V Predictions Max            1789.8406
V Predictions Min            386.8262
Log Pis Mean                 -0.64663
Log Pis Std                  1.7995462
Log Pis Max                  10.458513
Log Pis Min                  -4.415206
Policy mu Mean               0.047106136
Policy mu Std                0.77694446
Policy mu Max                2.3979356
Policy mu Min                -3.0403378
Policy log std Mean          -0.37965754
Policy log std Std           0.15221278
Policy log std Max           0.014823079
Policy log std Min           -1.1644688
Z mean eval                  0.024828658
Z variance eval              0.007428441
total_rewards                [1044.05790675 3276.27307898 1687.65829174 1123.0070522  2449.94275909
  962.63932256 2242.19995999 1924.15176715 1114.78734434 1402.40907857]
total_rewards_mean           1722.7126561365847
total_rewards_std            715.8341506277267
total_rewards_max            3276.2730789785096
total_rewards_min            962.6393225584937
Number of train steps total  343000
Number of env steps total    1717000
Number of rollouts total     0
Train Time (s)               44.463441140949726
(Previous) Eval Time (s)     15.374061487615108
Sample Time (s)              21.39814644586295
Epoch Time (s)               81.23564907442778
Total Train Time (s)         27730.348225569818
Epoch                        342
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:30:30.653997 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #342 | Epoch Duration: 83.39896845817566
2020-01-11 08:30:30.654121 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #342 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02444512
Z variance train             0.007431204
KL Divergence                10.243774
KL Loss                      1.0243775
QF Loss                      224.87471
VF Loss                      221.97581
Policy Loss                  -1580.0383
Q Predictions Mean           1581.6226
Q Predictions Std            182.18886
Q Predictions Max            1771.6907
Q Predictions Min            35.646313
V Predictions Mean           1581.4277
V Predictions Std            185.50201
V Predictions Max            1770.7695
V Predictions Min            58.87959
Log Pis Mean                 -0.5431438
Log Pis Std                  2.0243533
Log Pis Max                  10.182942
Log Pis Min                  -6.2565174
Policy mu Mean               -0.1407253
Policy mu Std                0.7836602
Policy mu Max                2.0109603
Policy mu Min                -3.2290077
Policy log std Mean          -0.37159717
Policy log std Std           0.16669385
Policy log std Max           0.3466752
Policy log std Min           -1.1585351
Z mean eval                  0.019699028
Z variance eval              0.0078628715
total_rewards                [1847.32394625  933.11261858 1529.59386444 1848.30491166 1615.09621201
  838.77993866 1234.51119477 1243.54532585  753.42917219  963.55717602]
total_rewards_mean           1280.7254360438208
total_rewards_std            389.25895090856073
total_rewards_max            1848.3049116577147
total_rewards_min            753.429172193992
Number of train steps total  344000
Number of env steps total    1722000
Number of rollouts total     0
Train Time (s)               43.74641282716766
(Previous) Eval Time (s)     17.537122837733477
Sample Time (s)              22.030811372678727
Epoch Time (s)               83.31434703757986
Total Train Time (s)         27808.461326497607
Epoch                        343
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:31:48.770761 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #343 | Epoch Duration: 78.11654877662659
2020-01-11 08:31:48.770882 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #343 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019882578
Z variance train             0.007858537
KL Divergence                10.07112
KL Loss                      1.007112
QF Loss                      174.23111
VF Loss                      98.96109
Policy Loss                  -1589.1398
Q Predictions Mean           1589.2378
Q Predictions Std            148.97635
Q Predictions Max            1770.6781
Q Predictions Min            501.95447
V Predictions Mean           1587.5707
V Predictions Std            146.60562
V Predictions Max            1772.8624
V Predictions Min            519.41364
Log Pis Mean                 -0.46038952
Log Pis Std                  1.6133666
Log Pis Max                  4.8936896
Log Pis Min                  -3.3402863
Policy mu Mean               -0.092432715
Policy mu Std                0.808015
Policy mu Max                2.6536894
Policy mu Min                -3.2707055
Policy log std Mean          -0.44272664
Policy log std Std           0.18584602
Policy log std Max           -0.028314114
Policy log std Min           -1.5843875
Z mean eval                  0.021334548
Z variance eval              0.0071939984
total_rewards                [1528.29994399 1326.00371899 1786.24243263 1877.70921925 1458.01435488
 1475.05359651 1055.47592827 1036.42521679 1295.24690609  951.66566643]
total_rewards_mean           1379.013698383144
total_rewards_std            294.4113523011848
total_rewards_max            1877.709219245492
total_rewards_min            951.6656664340555
Number of train steps total  345000
Number of env steps total    1727000
Number of rollouts total     0
Train Time (s)               43.97850830713287
(Previous) Eval Time (s)     12.339085289742798
Sample Time (s)              21.98027894180268
Epoch Time (s)               78.29787253867835
Total Train Time (s)         27887.595183409285
Epoch                        344
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:33:07.911184 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #344 | Epoch Duration: 79.14020943641663
2020-01-11 08:33:07.911311 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #344 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021220425
Z variance train             0.0072005554
KL Divergence                10.191629
KL Loss                      1.019163
QF Loss                      85.16434
VF Loss                      30.909552
Policy Loss                  -1594.9094
Q Predictions Mean           1595.0956
Q Predictions Std            132.57875
Q Predictions Max            1776.6771
Q Predictions Min            690.12573
V Predictions Mean           1595.6458
V Predictions Std            131.93654
V Predictions Max            1781.0067
V Predictions Min            699.2912
Log Pis Mean                 -0.49883506
Log Pis Std                  1.8267933
Log Pis Max                  9.493164
Log Pis Min                  -5.2845016
Policy mu Mean               0.038452085
Policy mu Std                0.80742365
Policy mu Max                1.9577341
Policy mu Min                -3.6971316
Policy log std Mean          -0.4301634
Policy log std Std           0.156026
Policy log std Max           -0.060588807
Policy log std Min           -1.1696011
Z mean eval                  0.02739026
Z variance eval              0.0076830303
total_rewards                [1273.72368743 1006.69757587 1374.05245688  999.46278238 1197.91052168
  973.2554149  1140.36668752  937.9984909  1152.77460481 1195.71927446]
total_rewards_mean           1125.1961496821907
total_rewards_std            135.359240732664
total_rewards_max            1374.0524568763333
total_rewards_min            937.998490898677
Number of train steps total  346000
Number of env steps total    1732000
Number of rollouts total     0
Train Time (s)               44.0599802271463
(Previous) Eval Time (s)     13.181172438897192
Sample Time (s)              21.661219909321517
Epoch Time (s)               78.902372575365
Total Train Time (s)         27964.65313700633
Epoch                        345
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:34:24.970947 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #345 | Epoch Duration: 77.05954194068909
2020-01-11 08:34:24.971072 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #345 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027502334
Z variance train             0.00768092
KL Divergence                10.066092
KL Loss                      1.0066092
QF Loss                      101.00949
VF Loss                      132.71631
Policy Loss                  -1589.8357
Q Predictions Mean           1587.61
Q Predictions Std            205.3102
Q Predictions Max            1771.6892
Q Predictions Min            6.2859073
V Predictions Mean           1585.2499
V Predictions Std            204.58905
V Predictions Max            1773.2428
V Predictions Min            5.8638206
Log Pis Mean                 -0.37496653
Log Pis Std                  1.7517602
Log Pis Max                  5.7854934
Log Pis Min                  -4.7977786
Policy mu Mean               0.24616288
Policy mu Std                0.80156285
Policy mu Max                2.0081763
Policy mu Min                -3.212401
Policy log std Mean          -0.4507699
Policy log std Std           0.15874392
Policy log std Max           0.0524078
Policy log std Min           -1.2119491
Z mean eval                  0.014397221
Z variance eval              0.006737438
total_rewards                [1029.75285437 1180.17984423 1290.57672944 1170.61606414  949.6064626
  646.78809533 1574.00712291 1788.63892336 1715.11225979  928.35688732]
total_rewards_mean           1227.3635243489525
total_rewards_std            350.0292745057058
total_rewards_max            1788.6389233602551
total_rewards_min            646.7880953258061
Number of train steps total  347000
Number of env steps total    1737000
Number of rollouts total     0
Train Time (s)               44.45746978092939
(Previous) Eval Time (s)     11.338087378069758
Sample Time (s)              22.069446576293558
Epoch Time (s)               77.8650037352927
Total Train Time (s)         28043.34297024645
Epoch                        346
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:35:43.663466 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #346 | Epoch Duration: 78.6922972202301
2020-01-11 08:35:43.663592 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #346 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.014604432
Z variance train             0.0067257173
KL Divergence                10.376923
KL Loss                      1.0376923
QF Loss                      73.51094
VF Loss                      20.216423
Policy Loss                  -1613.4481
Q Predictions Mean           1611.4307
Q Predictions Std            166.27791
Q Predictions Max            1775.8662
Q Predictions Min            8.582314
V Predictions Mean           1611.477
V Predictions Std            165.97757
V Predictions Max            1777.7196
V Predictions Min            4.7851596
Log Pis Mean                 -0.47924447
Log Pis Std                  1.7264307
Log Pis Max                  5.1463747
Log Pis Min                  -5.9402533
Policy mu Mean               0.10737754
Policy mu Std                0.77891725
Policy mu Max                1.7867548
Policy mu Min                -2.8700786
Policy log std Mean          -0.4238793
Policy log std Std           0.15658718
Policy log std Max           0.02021426
Policy log std Min           -1.3762774
Z mean eval                  0.017376183
Z variance eval              0.0069610826
total_rewards                [1228.57691677  984.69125795 2212.66103919 1818.85227957  966.65353112
 1022.09554824 1196.73264262 1485.00956355 1254.87489687 2968.18017008]
total_rewards_mean           1513.8327845969377
total_rewards_std            613.8028116203667
total_rewards_max            2968.1801700822343
total_rewards_min            966.6535311231592
Number of train steps total  348000
Number of env steps total    1742000
Number of rollouts total     0
Train Time (s)               43.92891082307324
(Previous) Eval Time (s)     12.16512429015711
Sample Time (s)              21.132530007511377
Epoch Time (s)               77.22656512074172
Total Train Time (s)         28123.17720273882
Epoch                        347
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:37:03.500229 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #347 | Epoch Duration: 79.83654403686523
2020-01-11 08:37:03.500356 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #347 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018789278
Z variance train             0.0069615035
KL Divergence                10.139203
KL Loss                      1.0139203
QF Loss                      93.52893
VF Loss                      130.09785
Policy Loss                  -1592.5536
Q Predictions Mean           1588.874
Q Predictions Std            169.5438
Q Predictions Max            1782.6272
Q Predictions Min            567.03973
V Predictions Mean           1585.5956
V Predictions Std            170.45163
V Predictions Max            1774.7753
V Predictions Min            536.3977
Log Pis Mean                 -0.45776048
Log Pis Std                  1.7161089
Log Pis Max                  8.61013
Log Pis Min                  -4.4697776
Policy mu Mean               0.15444066
Policy mu Std                0.81001836
Policy mu Max                2.702063
Policy mu Min                -3.474629
Policy log std Mean          -0.41526365
Policy log std Std           0.14999254
Policy log std Max           -0.009844005
Policy log std Min           -1.2070589
Z mean eval                  0.042315852
Z variance eval              0.0062444275
total_rewards                [ 653.57558619 1324.30275393  636.53689688 3336.09447539 1283.19893173
  992.93611702  763.26077194 1221.24020705 1763.64860849  904.20341097]
total_rewards_mean           1287.8997759588774
total_rewards_std            759.1668179276083
total_rewards_max            3336.0944753922076
total_rewards_min            636.5368968783102
Number of train steps total  349000
Number of env steps total    1747000
Number of rollouts total     0
Train Time (s)               43.41631590202451
(Previous) Eval Time (s)     14.77483515162021
Sample Time (s)              21.844357011374086
Epoch Time (s)               80.0355080650188
Total Train Time (s)         28200.64631734509
Epoch                        348
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:38:20.973230 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #348 | Epoch Duration: 77.4727714061737
2020-01-11 08:38:20.973389 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #348 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.042428236
Z variance train             0.006243805
KL Divergence                10.355272
KL Loss                      1.0355272
QF Loss                      54.75563
VF Loss                      59.537918
Policy Loss                  -1628.1172
Q Predictions Mean           1627.5743
Q Predictions Std            140.33163
Q Predictions Max            1813.6313
Q Predictions Min            467.72824
V Predictions Mean           1627.3604
V Predictions Std            138.93208
V Predictions Max            1813.4497
V Predictions Min            473.07086
Log Pis Mean                 -0.5300249
Log Pis Std                  1.676555
Log Pis Max                  9.069103
Log Pis Min                  -4.6234617
Policy mu Mean               0.06861036
Policy mu Std                0.81874937
Policy mu Max                2.6372194
Policy mu Min                -4.189261
Policy log std Mean          -0.4195534
Policy log std Std           0.18051879
Policy log std Max           0.052947313
Policy log std Min           -1.6066146
Z mean eval                  0.018298116
Z variance eval              0.0065164575
total_rewards                [1127.99436839  856.17905462 1924.25687832 1231.32859065  859.61691715
 1203.56183486 1577.19250113  958.98819014 1692.58421942  858.77550175]
total_rewards_mean           1229.0478056425934
total_rewards_std            362.7391605976414
total_rewards_max            1924.256878319735
total_rewards_min            856.1790546225931
Number of train steps total  350000
Number of env steps total    1752000
Number of rollouts total     0
Train Time (s)               44.686848788987845
(Previous) Eval Time (s)     12.211845832876861
Sample Time (s)              21.82902750186622
Epoch Time (s)               78.72772212373093
Total Train Time (s)         28278.531265412457
Epoch                        349
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:39:38.861634 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #349 | Epoch Duration: 77.88811826705933
2020-01-11 08:39:38.861791 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #349 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018191224
Z variance train             0.006509534
KL Divergence                10.4904585
KL Loss                      1.0490459
QF Loss                      275.0641
VF Loss                      89.58978
Policy Loss                  -1600.0582
Q Predictions Mean           1603.8887
Q Predictions Std            154.42426
Q Predictions Max            1780.7684
Q Predictions Min            609.1187
V Predictions Mean           1593.3394
V Predictions Std            152.57953
V Predictions Max            1762.645
V Predictions Min            600.74304
Log Pis Mean                 -0.5721728
Log Pis Std                  1.79665
Log Pis Max                  8.020449
Log Pis Min                  -4.659837
Policy mu Mean               0.054226458
Policy mu Std                0.81052035
Policy mu Max                2.9194357
Policy mu Min                -3.2261894
Policy log std Mean          -0.40195206
Policy log std Std           0.15950727
Policy log std Max           0.015394688
Policy log std Min           -1.1706173
Z mean eval                  0.04193222
Z variance eval              0.0063886433
total_rewards                [2535.61084968 1233.2080621   824.30685947  889.9116637  2998.46562534
 1572.37665106 1305.19263831 1227.32638323  843.06267535 1338.24958988]
total_rewards_mean           1476.7710998134366
total_rewards_std            691.9327433640453
total_rewards_max            2998.465625344248
total_rewards_min            824.3068594691922
Number of train steps total  351000
Number of env steps total    1757000
Number of rollouts total     0
Train Time (s)               44.725860820151865
(Previous) Eval Time (s)     11.371986582875252
Sample Time (s)              22.648360586259514
Epoch Time (s)               78.74620798928663
Total Train Time (s)         28360.596563053317
Epoch                        350
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:41:00.931919 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #350 | Epoch Duration: 82.07001113891602
2020-01-11 08:41:00.932050 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #350 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043152004
Z variance train             0.0063698897
KL Divergence                10.322041
KL Loss                      1.032204
QF Loss                      186.89767
VF Loss                      181.0143
Policy Loss                  -1602.4081
Q Predictions Mean           1603.8108
Q Predictions Std            135.55106
Q Predictions Max            1768.8566
Q Predictions Min            794.874
V Predictions Mean           1591.1843
V Predictions Std            135.11026
V Predictions Max            1762.875
V Predictions Min            788.0754
Log Pis Mean                 -0.6601909
Log Pis Std                  1.6651907
Log Pis Max                  4.093054
Log Pis Min                  -4.6721296
Policy mu Mean               0.057092626
Policy mu Std                0.79546577
Policy mu Max                1.9747661
Policy mu Min                -2.3495634
Policy log std Mean          -0.38996148
Policy log std Std           0.16740867
Policy log std Max           0.36742878
Policy log std Min           -1.1390752
Z mean eval                  0.039121285
Z variance eval              0.0069284057
total_rewards                [1162.79204579 3047.1768473  1336.20502835 1343.01037129 3433.18802065
 1659.2797737  1198.59948893 3419.23976521 1559.14376489 1831.21445478]
total_rewards_mean           1998.9849560890289
total_rewards_std            878.5892434655137
total_rewards_max            3433.188020649782
total_rewards_min            1162.7920457927296
Number of train steps total  352000
Number of env steps total    1762000
Number of rollouts total     0
Train Time (s)               44.23676648689434
(Previous) Eval Time (s)     14.695552721619606
Sample Time (s)              21.591566252987832
Epoch Time (s)               80.52388546150178
Total Train Time (s)         28445.410461383406
Epoch                        351
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:42:25.751566 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #351 | Epoch Duration: 84.81936836242676
2020-01-11 08:42:25.751872 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #351 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03923536
Z variance train             0.0069308034
KL Divergence                10.273788
KL Loss                      1.0273789
QF Loss                      95.75261
VF Loss                      55.642345
Policy Loss                  -1614.8427
Q Predictions Mean           1616.2163
Q Predictions Std            136.03519
Q Predictions Max            1804.5637
Q Predictions Min            840.33563
V Predictions Mean           1615.7014
V Predictions Std            133.23334
V Predictions Max            1798.3062
V Predictions Min            821.5848
Log Pis Mean                 -0.56479037
Log Pis Std                  1.7136415
Log Pis Max                  5.728731
Log Pis Min                  -7.4427676
Policy mu Mean               -0.012170848
Policy mu Std                0.8045047
Policy mu Max                2.0235767
Policy mu Min                -2.5758862
Policy log std Mean          -0.40706
Policy log std Std           0.16817878
Policy log std Max           -0.03177166
Policy log std Min           -1.3173261
Z mean eval                  0.00875388
Z variance eval              0.0067572743
total_rewards                [2453.81249131 2147.55683321 1550.17891261 1882.83117145  958.69274475
 1058.1776683  1890.19773052 1277.40485397 1314.8316787  1906.80265278]
total_rewards_mean           1644.0486737618044
total_rewards_std            464.8079858031517
total_rewards_max            2453.8124913149454
total_rewards_min            958.6927447461505
Number of train steps total  353000
Number of env steps total    1767000
Number of rollouts total     0
Train Time (s)               44.613380334340036
(Previous) Eval Time (s)     18.990759515203536
Sample Time (s)              22.356466566678137
Epoch Time (s)               85.96060641622171
Total Train Time (s)         28527.893898531795
Epoch                        352
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:43:48.242851 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #352 | Epoch Duration: 82.49067997932434
2020-01-11 08:43:48.243161 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #352 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.00892235
Z variance train             0.006759754
KL Divergence                10.541372
KL Loss                      1.0541372
QF Loss                      123.72356
VF Loss                      24.135435
Policy Loss                  -1585.1403
Q Predictions Mean           1583.0706
Q Predictions Std            154.56432
Q Predictions Max            1769.4108
Q Predictions Min            457.50253
V Predictions Mean           1584.9236
V Predictions Std            154.1775
V Predictions Max            1780.2499
V Predictions Min            467.67862
Log Pis Mean                 -0.6262531
Log Pis Std                  1.7743201
Log Pis Max                  5.246772
Log Pis Min                  -7.5511317
Policy mu Mean               0.084856786
Policy mu Std                0.77382594
Policy mu Max                1.7648224
Policy mu Min                -3.1739118
Policy log std Mean          -0.4039204
Policy log std Std           0.16620316
Policy log std Max           -0.0752964
Policy log std Min           -1.1626266
Z mean eval                  0.042515486
Z variance eval              0.0084383255
total_rewards                [2010.40526378 3266.89867921 3237.28159067 3251.66029163 2264.32013473
 1175.98845202 3250.27753121 1032.1567303   960.40273655 2404.16365714]
total_rewards_mean           2285.3555067228363
total_rewards_std            915.4926268124321
total_rewards_max            3266.898679207382
total_rewards_min            960.4027365484687
Number of train steps total  354000
Number of env steps total    1772000
Number of rollouts total     0
Train Time (s)               43.185190978925675
(Previous) Eval Time (s)     15.520585247781128
Sample Time (s)              22.796069382689893
Epoch Time (s)               81.5018456093967
Total Train Time (s)         28614.93135658838
Epoch                        353
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:45:15.285829 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #353 | Epoch Duration: 87.04242181777954
2020-01-11 08:45:15.286079 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #353 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04312618
Z variance train             0.008436238
KL Divergence                10.138221
KL Loss                      1.0138221
QF Loss                      130.6193
VF Loss                      134.9566
Policy Loss                  -1577.4794
Q Predictions Mean           1578.8933
Q Predictions Std            184.33914
Q Predictions Max            1753.3523
Q Predictions Min            270.03333
V Predictions Mean           1580.6188
V Predictions Std            180.51712
V Predictions Max            1758.05
V Predictions Min            281.93787
Log Pis Mean                 -0.50246894
Log Pis Std                  1.876864
Log Pis Max                  9.367413
Log Pis Min                  -5.0078125
Policy mu Mean               0.056813765
Policy mu Std                0.84102845
Policy mu Max                2.6188653
Policy mu Min                -2.9974275
Policy log std Mean          -0.41180328
Policy log std Std           0.17283793
Policy log std Max           -0.04889451
Policy log std Min           -1.394753
Z mean eval                  0.02035668
Z variance eval              0.0077701346
total_rewards                [1121.72703891 1886.18612286 3330.16366889 3323.57435994 3290.22900737
 3397.5993262  2382.38018825 1653.15262866 2755.17754442 1541.21368594]
total_rewards_mean           2468.1403571429464
total_rewards_std            823.3600674244904
total_rewards_max            3397.5993262011675
total_rewards_min            1121.727038906157
Number of train steps total  355000
Number of env steps total    1777000
Number of rollouts total     0
Train Time (s)               44.193287276197225
(Previous) Eval Time (s)     21.06090047582984
Sample Time (s)              22.13536772504449
Epoch Time (s)               87.38955547707155
Total Train Time (s)         28705.685515010264
Epoch                        354
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:46:46.043629 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #354 | Epoch Duration: 90.75737833976746
2020-01-11 08:46:46.043754 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #354 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0197987
Z variance train             0.007765443
KL Divergence                10.295045
KL Loss                      1.0295045
QF Loss                      234.80728
VF Loss                      164.6467
Policy Loss                  -1591.7133
Q Predictions Mean           1591.3135
Q Predictions Std            163.07292
Q Predictions Max            1766.3218
Q Predictions Min            400.31693
V Predictions Mean           1597.1533
V Predictions Std            165.66182
V Predictions Max            1776.8312
V Predictions Min            350.45346
Log Pis Mean                 -0.7465694
Log Pis Std                  1.5974731
Log Pis Max                  7.1958156
Log Pis Min                  -4.524844
Policy mu Mean               -0.003580169
Policy mu Std                0.76287955
Policy mu Max                1.8131979
Policy mu Min                -3.2414033
Policy log std Mean          -0.37099528
Policy log std Std           0.15726008
Policy log std Max           -0.03167036
Policy log std Min           -1.1858999
Z mean eval                  0.028544087
Z variance eval              0.007873349
total_rewards                [1277.98894449 2438.76923343  940.83655549 3354.79536053 1626.35615938
 1516.2362539  2519.28751033 3311.17591225 1854.98465787 2058.65555642]
total_rewards_mean           2089.9086144090134
total_rewards_std            773.1254285580987
total_rewards_max            3354.7953605304883
total_rewards_min            940.8365554854214
Number of train steps total  356000
Number of env steps total    1782000
Number of rollouts total     0
Train Time (s)               44.31179168401286
(Previous) Eval Time (s)     24.428494095802307
Sample Time (s)              20.26468313066289
Epoch Time (s)               89.00496891047806
Total Train Time (s)         28791.28622760577
Epoch                        355
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:48:11.647751 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #355 | Epoch Duration: 85.60388398170471
2020-01-11 08:48:11.647934 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #355 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028395634
Z variance train             0.007870117
KL Divergence                10.458557
KL Loss                      1.0458558
QF Loss                      47.880234
VF Loss                      29.496447
Policy Loss                  -1573.3702
Q Predictions Mean           1571.6842
Q Predictions Std            158.07666
Q Predictions Max            1746.9814
Q Predictions Min            600.25116
V Predictions Mean           1572.0981
V Predictions Std            159.00812
V Predictions Max            1742.3313
V Predictions Min            587.5658
Log Pis Mean                 -0.5416445
Log Pis Std                  1.6105772
Log Pis Max                  5.4338007
Log Pis Min                  -4.836663
Policy mu Mean               -0.004462477
Policy mu Std                0.8194249
Policy mu Max                1.827117
Policy mu Min                -3.0893278
Policy log std Mean          -0.39591646
Policy log std Std           0.15241535
Policy log std Max           -0.051104397
Policy log std Min           -1.1531699
Z mean eval                  0.04007045
Z variance eval              0.0073118866
total_rewards                [1268.14346231  942.94183094  764.06704775 1018.10601898  786.49321435
 1357.83612949  937.15049971  885.14438102  752.14226379  993.15992631]
total_rewards_mean           970.5184774661602
total_rewards_std            193.57455803934192
total_rewards_max            1357.8361294939605
total_rewards_min            752.1422637941097
Number of train steps total  357000
Number of env steps total    1787000
Number of rollouts total     0
Train Time (s)               44.58253805199638
(Previous) Eval Time (s)     21.027162682730705
Sample Time (s)              21.523280145134777
Epoch Time (s)               87.13298087986186
Total Train Time (s)         28867.178739712108
Epoch                        356
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:49:27.545069 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #356 | Epoch Duration: 75.89698457717896
2020-01-11 08:49:27.545227 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #356 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03986578
Z variance train             0.0073238597
KL Divergence                10.575025
KL Loss                      1.0575025
QF Loss                      152.98413
VF Loss                      134.01915
Policy Loss                  -1606.8485
Q Predictions Mean           1608.2212
Q Predictions Std            194.5713
Q Predictions Max            1799.8644
Q Predictions Min            9.719782
V Predictions Mean           1611.2916
V Predictions Std            193.23132
V Predictions Max            1803.0863
V Predictions Min            -13.606516
Log Pis Mean                 -0.3796136
Log Pis Std                  1.738003
Log Pis Max                  5.440524
Log Pis Min                  -5.3419447
Policy mu Mean               0.19842303
Policy mu Std                0.8431867
Policy mu Max                3.5111136
Policy mu Min                -2.988626
Policy log std Mean          -0.42456007
Policy log std Std           0.14578283
Policy log std Max           -0.088208675
Policy log std Min           -1.078156
Z mean eval                  0.037643023
Z variance eval              0.007304775
total_rewards                [1177.77869226 1026.94143552 1136.50389924 1013.57018021 2695.23848957
 1919.76452368 1108.36222264 1293.06802904 1288.18774711 1023.78968724]
total_rewards_mean           1368.3204906513793
total_rewards_std            509.47015747965014
total_rewards_max            2695.2384895707596
total_rewards_min            1013.5701802146309
Number of train steps total  358000
Number of env steps total    1792000
Number of rollouts total     0
Train Time (s)               44.24296108307317
(Previous) Eval Time (s)     9.790921948850155
Sample Time (s)              22.398806403391063
Epoch Time (s)               76.43268943531439
Total Train Time (s)         28946.6980020809
Epoch                        357
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:50:47.069012 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #357 | Epoch Duration: 79.52364993095398
2020-01-11 08:50:47.069205 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #357 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037584506
Z variance train             0.007308217
KL Divergence                10.549411
KL Loss                      1.054941
QF Loss                      105.3882
VF Loss                      45.000153
Policy Loss                  -1583.5032
Q Predictions Mean           1584.2803
Q Predictions Std            145.68044
Q Predictions Max            1758.134
Q Predictions Min            615.6424
V Predictions Mean           1580.0524
V Predictions Std            143.49965
V Predictions Max            1749.0297
V Predictions Min            652.4477
Log Pis Mean                 -0.3494424
Log Pis Std                  1.8303982
Log Pis Max                  8.52174
Log Pis Min                  -5.7148075
Policy mu Mean               0.118113905
Policy mu Std                0.8443442
Policy mu Max                2.9367845
Policy mu Min                -3.5164096
Policy log std Mean          -0.43202114
Policy log std Std           0.16096775
Policy log std Max           -0.06239444
Policy log std Min           -1.667022
Z mean eval                  0.06033958
Z variance eval              0.007021744
total_rewards                [1226.31954072 1251.23855602 1038.29173785 1063.68629577 2088.73648847
 1695.01856479 1616.51925372 1073.06340871 1068.26688041 1650.0147204 ]
total_rewards_mean           1377.115544685636
total_rewards_std            343.3240320593048
total_rewards_max            2088.736488471719
total_rewards_min            1038.291737850377
Number of train steps total  359000
Number of env steps total    1797000
Number of rollouts total     0
Train Time (s)               44.4883395251818
(Previous) Eval Time (s)     12.881631926167756
Sample Time (s)              22.33604956138879
Epoch Time (s)               79.70602101273835
Total Train Time (s)         29026.80068911938
Epoch                        358
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:52:07.173265 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #358 | Epoch Duration: 80.10392117500305
2020-01-11 08:52:07.173388 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #358 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06032131
Z variance train             0.0070244437
KL Divergence                10.6537695
KL Loss                      1.065377
QF Loss                      723.7007
VF Loss                      157.01848
Policy Loss                  -1561.3312
Q Predictions Mean           1565.813
Q Predictions Std            210.82368
Q Predictions Max            1776.4031
Q Predictions Min            32.89304
V Predictions Mean           1563.5713
V Predictions Std            218.44023
V Predictions Max            1765.0751
V Predictions Min            20.84277
Log Pis Mean                 -0.76426244
Log Pis Std                  1.7073606
Log Pis Max                  11.548962
Log Pis Min                  -4.8861566
Policy mu Mean               0.016624926
Policy mu Std                0.7785999
Policy mu Max                3.5071523
Policy mu Min                -3.3537486
Policy log std Mean          -0.4320736
Policy log std Std           0.15766408
Policy log std Max           -0.01808849
Policy log std Min           -1.2878377
Z mean eval                  0.019901745
Z variance eval              0.006597714
total_rewards                [1129.74554137 1011.79622427  967.20117807 1409.10475472 1001.67796014
 1281.45180111 1745.42678482 1169.70153107 1318.05234053  980.72543486]
total_rewards_mean           1201.4883550975292
total_rewards_std            233.37660129559092
total_rewards_max            1745.4267848222953
total_rewards_min            967.2011780703546
Number of train steps total  360000
Number of env steps total    1802000
Number of rollouts total     0
Train Time (s)               44.42237682035193
(Previous) Eval Time (s)     13.279280080925673
Sample Time (s)              21.566851863171905
Epoch Time (s)               79.2685087644495
Total Train Time (s)         29103.897287300322
Epoch                        359
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:53:24.273611 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #359 | Epoch Duration: 77.1001193523407
2020-01-11 08:53:24.273770 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #359 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0194584
Z variance train             0.0065987534
KL Divergence                10.488529
KL Loss                      1.0488529
QF Loss                      109.97894
VF Loss                      78.32607
Policy Loss                  -1582.493
Q Predictions Mean           1587.473
Q Predictions Std            155.61566
Q Predictions Max            1784.1975
Q Predictions Min            575.29755
V Predictions Mean           1586.5093
V Predictions Std            152.33313
V Predictions Max            1791.0458
V Predictions Min            576.9746
Log Pis Mean                 -0.56037545
Log Pis Std                  1.5043279
Log Pis Max                  6.2584553
Log Pis Min                  -4.7847414
Policy mu Mean               0.20139527
Policy mu Std                0.7632909
Policy mu Max                2.0425768
Policy mu Min                -2.648889
Policy log std Mean          -0.4281714
Policy log std Std           0.16016513
Policy log std Max           0.10940924
Policy log std Min           -1.6352326
Z mean eval                  0.020793596
Z variance eval              0.0063254638
total_rewards                [1206.27442372 2135.73577083 2068.51992544 3297.21072692 3235.69452837
 2129.8297896  1182.92610086 3295.08769408 3314.65604805 1787.10077229]
total_rewards_mean           2365.3035780174932
total_rewards_std            816.3157072240983
total_rewards_max            3314.656048052293
total_rewards_min            1182.926100860375
Number of train steps total  361000
Number of env steps total    1807000
Number of rollouts total     0
Train Time (s)               43.46888437168673
(Previous) Eval Time (s)     11.110640234779567
Sample Time (s)              21.982343829702586
Epoch Time (s)               76.56186843616888
Total Train Time (s)         29193.217639951967
Epoch                        360
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:54:53.596788 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #360 | Epoch Duration: 89.32290172576904
2020-01-11 08:54:53.596916 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #360 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02023709
Z variance train             0.0063280733
KL Divergence                10.642711
KL Loss                      1.0642711
QF Loss                      63.962517
VF Loss                      62.09579
Policy Loss                  -1578.8245
Q Predictions Mean           1579.0787
Q Predictions Std            160.01624
Q Predictions Max            1776.6614
Q Predictions Min            403.3308
V Predictions Mean           1581.8867
V Predictions Std            158.73352
V Predictions Max            1774.8129
V Predictions Min            454.7756
Log Pis Mean                 -0.49820742
Log Pis Std                  2.1153047
Log Pis Max                  9.348211
Log Pis Min                  -6.6905456
Policy mu Mean               -0.011110611
Policy mu Std                0.87972635
Policy mu Max                2.8092744
Policy mu Min                -3.1766133
Policy log std Mean          -0.45653808
Policy log std Std           0.15520556
Policy log std Max           -0.037112653
Policy log std Min           -1.0621632
Z mean eval                  0.017410174
Z variance eval              0.0056271716
total_rewards                [2326.60777023 1633.90705534 1795.00374907 1009.75279436 2994.06561354
  931.22025009 1829.69288661 1519.98695065 1109.41803456 1623.68967881]
total_rewards_mean           1677.3344783280231
total_rewards_std            595.5500495640341
total_rewards_max            2994.065613541986
total_rewards_min            931.220250094663
Number of train steps total  362000
Number of env steps total    1812000
Number of rollouts total     0
Train Time (s)               43.770733542740345
(Previous) Eval Time (s)     23.871424017008394
Sample Time (s)              21.937244853470474
Epoch Time (s)               89.57940241321921
Total Train Time (s)         29273.793080274016
Epoch                        361
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:56:14.178723 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #361 | Epoch Duration: 80.58165502548218
2020-01-11 08:56:14.179031 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #361 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018065587
Z variance train             0.005612917
KL Divergence                10.908308
KL Loss                      1.0908308
QF Loss                      173.47806
VF Loss                      155.20255
Policy Loss                  -1578.1633
Q Predictions Mean           1581.691
Q Predictions Std            191.14073
Q Predictions Max            1748.483
Q Predictions Min            -74.25055
V Predictions Mean           1585.752
V Predictions Std            183.33513
V Predictions Max            1754.0742
V Predictions Min            149.61859
Log Pis Mean                 -0.51907146
Log Pis Std                  2.03842
Log Pis Max                  12.50744
Log Pis Min                  -6.917639
Policy mu Mean               0.02095441
Policy mu Std                0.8456099
Policy mu Max                2.5251503
Policy mu Min                -4.888721
Policy log std Mean          -0.43575755
Policy log std Std           0.15523526
Policy log std Max           -0.053106546
Policy log std Min           -1.1307911
Z mean eval                  0.021877166
Z variance eval              0.00581782
total_rewards                [3313.09231541 2478.62889903 3253.8845731  3220.13221811 2052.48989678
 1103.86201949 2604.69283807 2084.60501576 3263.5077848  1765.93003269]
total_rewards_mean           2514.0825593238555
total_rewards_std            721.2009431786446
total_rewards_max            3313.092315414649
total_rewards_min            1103.862019490594
Number of train steps total  363000
Number of env steps total    1817000
Number of rollouts total     0
Train Time (s)               43.79615624016151
(Previous) Eval Time (s)     14.873384980950505
Sample Time (s)              19.868582343216985
Epoch Time (s)               78.538123564329
Total Train Time (s)         29362.682586877607
Epoch                        362
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:57:43.069950 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #362 | Epoch Duration: 88.8907036781311
2020-01-11 08:57:43.070070 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #362 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021482792
Z variance train             0.005822067
KL Divergence                10.74568
KL Loss                      1.074568
QF Loss                      92.61853
VF Loss                      116.45922
Policy Loss                  -1613.5043
Q Predictions Mean           1615.1294
Q Predictions Std            159.0768
Q Predictions Max            1785.9772
Q Predictions Min            67.9002
V Predictions Mean           1606.727
V Predictions Std            157.57361
V Predictions Max            1770.5841
V Predictions Min            47.33178
Log Pis Mean                 -0.6550981
Log Pis Std                  1.8581347
Log Pis Max                  8.259348
Log Pis Min                  -8.282949
Policy mu Mean               -0.07007191
Policy mu Std                0.78307414
Policy mu Max                2.3917062
Policy mu Min                -2.9829628
Policy log std Mean          -0.4227519
Policy log std Std           0.145492
Policy log std Max           -0.094533384
Policy log std Min           -1.0625552
Z mean eval                  0.03256905
Z variance eval              0.0065496005
total_rewards                [1525.95737571 1046.90275768 2644.52233488 1342.23668451 1058.01196672
 3300.31362496 2777.54805403 1841.11865669 1596.49976128 2427.62068183]
total_rewards_mean           1956.073189828837
total_rewards_std            742.6661337129317
total_rewards_max            3300.313624956846
total_rewards_min            1046.9027576806973
Number of train steps total  364000
Number of env steps total    1822000
Number of rollouts total     0
Train Time (s)               43.93427317170426
(Previous) Eval Time (s)     25.225754915270954
Sample Time (s)              21.705902906134725
Epoch Time (s)               90.86593099310994
Total Train Time (s)         29447.82639144035
Epoch                        363
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 08:59:08.216803 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #363 | Epoch Duration: 85.14663982391357
2020-01-11 08:59:08.216942 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #363 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033298254
Z variance train             0.0065448536
KL Divergence                10.462652
KL Loss                      1.0462652
QF Loss                      90.42299
VF Loss                      46.034004
Policy Loss                  -1613.157
Q Predictions Mean           1612.2793
Q Predictions Std            162.80928
Q Predictions Max            1786.3793
Q Predictions Min            451.55426
V Predictions Mean           1610.6536
V Predictions Std            160.3162
V Predictions Max            1791.4492
V Predictions Min            460.81943
Log Pis Mean                 -0.5179421
Log Pis Std                  2.0359492
Log Pis Max                  7.3094425
Log Pis Min                  -7.1214113
Policy mu Mean               -0.03329616
Policy mu Std                0.8452966
Policy mu Max                1.8295625
Policy mu Min                -3.078993
Policy log std Mean          -0.42223772
Policy log std Std           0.16614553
Policy log std Max           -0.04890853
Policy log std Min           -1.9062796
Z mean eval                  0.023007322
Z variance eval              0.0063352897
total_rewards                [1004.05439978 2606.74080876 1255.57317138 1597.41978725 1333.32645619
 1363.48097511 1264.5122618   916.15411535 1550.89350919 2996.54149145]
total_rewards_mean           1588.869697626596
total_rewards_std            643.8997363908526
total_rewards_max            2996.541491452906
total_rewards_min            916.1541153517205
Number of train steps total  365000
Number of env steps total    1827000
Number of rollouts total     0
Train Time (s)               44.28938355483115
(Previous) Eval Time (s)     19.506219437811524
Sample Time (s)              22.244354818947613
Epoch Time (s)               86.03995781159028
Total Train Time (s)         29528.485680039972
Epoch                        364
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:00:28.879783 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #364 | Epoch Duration: 80.66273164749146
2020-01-11 09:00:28.879960 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #364 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.022920968
Z variance train             0.0063345814
KL Divergence                10.55207
KL Loss                      1.055207
QF Loss                      531.5933
VF Loss                      41.559246
Policy Loss                  -1566.1764
Q Predictions Mean           1565.3134
Q Predictions Std            153.44945
Q Predictions Max            1757.0521
Q Predictions Min            804.49915
V Predictions Mean           1562.2958
V Predictions Std            152.35095
V Predictions Max            1753.6787
V Predictions Min            798.4401
Log Pis Mean                 -0.7942945
Log Pis Std                  1.7241231
Log Pis Max                  7.559999
Log Pis Min                  -4.4304633
Policy mu Mean               0.05550593
Policy mu Std                0.75893325
Policy mu Max                1.9504902
Policy mu Min                -3.8220153
Policy log std Mean          -0.4288632
Policy log std Std           0.16216516
Policy log std Max           -0.12094964
Policy log std Min           -1.1566843
Z mean eval                  0.030071061
Z variance eval              0.0061508697
total_rewards                [1201.4210802   994.82317697  951.11602396 3291.68421913 1525.10731395
 1022.26470298 1035.4138859  1410.4831924   954.07463889 3326.73241291]
total_rewards_mean           1571.3120647301848
total_rewards_std            888.4033748315208
total_rewards_max            3326.732412908577
total_rewards_min            951.116023961083
Number of train steps total  366000
Number of env steps total    1832000
Number of rollouts total     0
Train Time (s)               44.1781565239653
(Previous) Eval Time (s)     14.12872127816081
Sample Time (s)              22.042681188788265
Epoch Time (s)               80.34955899091437
Total Train Time (s)         29610.372451466043
Epoch                        365
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:01:50.768855 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #365 | Epoch Duration: 81.88875579833984
2020-01-11 09:01:50.768987 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #365 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029880702
Z variance train             0.0061562173
KL Divergence                10.746494
KL Loss                      1.0746495
QF Loss                      87.812515
VF Loss                      54.729485
Policy Loss                  -1588.7637
Q Predictions Mean           1588.2266
Q Predictions Std            129.20651
Q Predictions Max            1744.9199
Q Predictions Min            1067.1826
V Predictions Mean           1588.7241
V Predictions Std            129.16946
V Predictions Max            1748.5308
V Predictions Min            1078.4025
Log Pis Mean                 -0.47968182
Log Pis Std                  2.0042055
Log Pis Max                  8.031124
Log Pis Min                  -4.1425066
Policy mu Mean               -0.019663924
Policy mu Std                0.8395766
Policy mu Max                2.4528794
Policy mu Min                -4.003307
Policy log std Mean          -0.42696646
Policy log std Std           0.1690768
Policy log std Max           -0.060465485
Policy log std Min           -1.6077231
Z mean eval                  0.05540328
Z variance eval              0.007245449
total_rewards                [2106.69287377 1661.66746018 1012.30935643  959.24813994 1416.65595602
 2120.77917824  976.48119404 2091.44547001 1845.24702975 1684.59932821]
total_rewards_mean           1587.5125986596697
total_rewards_std            449.1489647126284
total_rewards_max            2120.779178239879
total_rewards_min            959.248139944389
Number of train steps total  367000
Number of env steps total    1837000
Number of rollouts total     0
Train Time (s)               44.544120602775365
(Previous) Eval Time (s)     15.667669487185776
Sample Time (s)              22.082416114397347
Epoch Time (s)               82.29420620435849
Total Train Time (s)         29693.265106536914
Epoch                        366
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:03:13.669402 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #366 | Epoch Duration: 82.90026879310608
2020-01-11 09:03:13.669703 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #366 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055538673
Z variance train             0.0072424123
KL Divergence                10.535621
KL Loss                      1.053562
QF Loss                      153.95674
VF Loss                      43.51954
Policy Loss                  -1607.9291
Q Predictions Mean           1607.5752
Q Predictions Std            144.18616
Q Predictions Max            1767.5974
Q Predictions Min            529.55347
V Predictions Mean           1609.1006
V Predictions Std            144.97467
V Predictions Max            1772.7744
V Predictions Min            522.1287
Log Pis Mean                 -0.7159653
Log Pis Std                  1.7835023
Log Pis Max                  8.398695
Log Pis Min                  -6.4850755
Policy mu Mean               0.059407726
Policy mu Std                0.7869805
Policy mu Max                1.9960221
Policy mu Min                -3.2854078
Policy log std Mean          -0.4247302
Policy log std Std           0.16119337
Policy log std Max           0.06423628
Policy log std Min           -1.3437254
Z mean eval                  0.049411807
Z variance eval              0.0068442672
total_rewards                [2458.02407308 3330.90641234 1300.65120451 1276.85018994 2469.22686416
 1713.31970288 3289.61393758 3174.53612514 1763.15644884 1170.35233398]
total_rewards_mean           2194.66372924501
total_rewards_std            818.7552392612885
total_rewards_max            3330.906412341267
total_rewards_min            1170.3523339832095
Number of train steps total  368000
Number of env steps total    1842000
Number of rollouts total     0
Train Time (s)               44.03500987030566
(Previous) Eval Time (s)     16.273460939060897
Sample Time (s)              21.493056918028742
Epoch Time (s)               81.8015277273953
Total Train Time (s)         29778.634455102496
Epoch                        367
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:04:39.040823 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #367 | Epoch Duration: 85.37089037895203
2020-01-11 09:04:39.041003 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #367 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.049109846
Z variance train             0.006847205
KL Divergence                10.733709
KL Loss                      1.0733709
QF Loss                      242.17712
VF Loss                      28.481216
Policy Loss                  -1613.0234
Q Predictions Mean           1613.542
Q Predictions Std            131.56932
Q Predictions Max            1792.9214
Q Predictions Min            542.3563
V Predictions Mean           1615.9993
V Predictions Std            132.29689
V Predictions Max            1798.5748
V Predictions Min            502.5311
Log Pis Mean                 -0.44871536
Log Pis Std                  1.8450598
Log Pis Max                  8.945951
Log Pis Min                  -4.327595
Policy mu Mean               -0.013863944
Policy mu Std                0.84604007
Policy mu Max                2.1329684
Policy mu Min                -3.5199292
Policy log std Mean          -0.4382101
Policy log std Std           0.1635252
Policy log std Max           0.008228213
Policy log std Min           -1.3579632
Z mean eval                  0.017358351
Z variance eval              0.0058527915
total_rewards                [1750.91464019 2192.51031959 1073.78645723 1056.08091245 3328.05457002
 3358.74213244 3358.48740682 1058.45903762 3347.14310612 2516.94346174]
total_rewards_mean           2304.112204422726
total_rewards_std            966.8007971776494
total_rewards_max            3358.742132444995
total_rewards_min            1056.0809124508444
Number of train steps total  369000
Number of env steps total    1847000
Number of rollouts total     0
Train Time (s)               44.09264005254954
(Previous) Eval Time (s)     19.84259732766077
Sample Time (s)              21.88117990968749
Epoch Time (s)               85.8164172898978
Total Train Time (s)         29867.168603728525
Epoch                        368
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:06:07.579660 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #368 | Epoch Duration: 88.53845310211182
2020-01-11 09:06:07.579904 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #368 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01756373
Z variance train             0.0058537805
KL Divergence                10.910417
KL Loss                      1.0910417
QF Loss                      35.230457
VF Loss                      40.080914
Policy Loss                  -1603.5132
Q Predictions Mean           1601.9382
Q Predictions Std            141.12488
Q Predictions Max            1759.8547
Q Predictions Min            705.7271
V Predictions Mean           1604.5239
V Predictions Std            141.36191
V Predictions Max            1764.6765
V Predictions Min            708.27405
Log Pis Mean                 -0.59212947
Log Pis Std                  1.9344808
Log Pis Max                  9.063433
Log Pis Min                  -4.407107
Policy mu Mean               0.04710779
Policy mu Std                0.8034465
Policy mu Max                2.1973395
Policy mu Min                -3.3394282
Policy log std Mean          -0.438495
Policy log std Std           0.15945612
Policy log std Max           0.026569188
Policy log std Min           -1.0968995
Z mean eval                  0.029029336
Z variance eval              0.005762805
total_rewards                [1523.78133977 3348.06552817 2999.28479213  905.40128358 2093.04373349
 3260.52685548 1522.03753607 1592.71124634 2530.20725745 1639.34836357]
total_rewards_mean           2141.4407936043567
total_rewards_std            802.7348889650295
total_rewards_max            3348.06552816555
total_rewards_min            905.4012835766162
Number of train steps total  370000
Number of env steps total    1852000
Number of rollouts total     0
Train Time (s)               44.70516276592389
(Previous) Eval Time (s)     22.56438369816169
Sample Time (s)              21.924450215883553
Epoch Time (s)               89.19399667996913
Total Train Time (s)         29953.000179021154
Epoch                        369
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:07:33.417294 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #369 | Epoch Duration: 85.8370418548584
2020-01-11 09:07:33.417539 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #369 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029380944
Z variance train             0.005763788
KL Divergence                10.721092
KL Loss                      1.0721092
QF Loss                      138.22789
VF Loss                      98.76664
Policy Loss                  -1600.6473
Q Predictions Mean           1600.2969
Q Predictions Std            148.90347
Q Predictions Max            1778.8525
Q Predictions Min            739.1036
V Predictions Mean           1594.3582
V Predictions Std            148.45769
V Predictions Max            1770.8016
V Predictions Min            756.3707
Log Pis Mean                 -0.6103569
Log Pis Std                  1.9242069
Log Pis Max                  8.849497
Log Pis Min                  -5.009255
Policy mu Mean               0.014498414
Policy mu Std                0.8310057
Policy mu Max                2.514448
Policy mu Min                -3.1032293
Policy log std Mean          -0.4353839
Policy log std Std           0.16780014
Policy log std Max           -0.043234438
Policy log std Min           -1.2684808
Z mean eval                  0.012191942
Z variance eval              0.0051916745
total_rewards                [1259.1122483  1758.33011407 1154.83145008 1833.8351748  3340.30563637
 3354.49180047 1638.94276825 1674.0256632  1121.78805705 1286.40653499]
total_rewards_mean           1842.2069447575482
total_rewards_std            790.469089704272
total_rewards_max            3354.4918004651577
total_rewards_min            1121.7880570475254
Number of train steps total  371000
Number of env steps total    1857000
Number of rollouts total     0
Train Time (s)               44.54192630993202
(Previous) Eval Time (s)     19.20732482802123
Sample Time (s)              21.42465651873499
Epoch Time (s)               85.17390765668824
Total Train Time (s)         30036.998336640652
Epoch                        370
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:08:57.417884 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #370 | Epoch Duration: 84.00011706352234
2020-01-11 09:08:57.418076 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #370 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.011817065
Z variance train             0.00518661
KL Divergence                10.851876
KL Loss                      1.0851877
QF Loss                      114.11685
VF Loss                      91.20301
Policy Loss                  -1589.9615
Q Predictions Mean           1586.4213
Q Predictions Std            162.36884
Q Predictions Max            1764.1123
Q Predictions Min            375.31656
V Predictions Mean           1591.7539
V Predictions Std            162.10303
V Predictions Max            1770.7057
V Predictions Min            401.54004
Log Pis Mean                 -0.54605794
Log Pis Std                  1.7381188
Log Pis Max                  8.863119
Log Pis Min                  -5.0264077
Policy mu Mean               0.0068770205
Policy mu Std                0.82103866
Policy mu Max                1.9273913
Policy mu Min                -3.1959522
Policy log std Mean          -0.42774186
Policy log std Std           0.15954864
Policy log std Max           -0.00502643
Policy log std Min           -1.4854015
Z mean eval                  0.035162568
Z variance eval              0.0047867163
total_rewards                [2747.84335814 2630.3823663   979.7088005  1247.8425782  1296.85927976
  941.54435009 1753.42783991 1800.59241256 1280.60863527  938.7805149 ]
total_rewards_mean           1561.7590135627038
total_rewards_std            632.6011457161575
total_rewards_max            2747.84335814003
total_rewards_min            938.7805148996301
Number of train steps total  372000
Number of env steps total    1862000
Number of rollouts total     0
Train Time (s)               44.801213891245425
(Previous) Eval Time (s)     18.033316106069833
Sample Time (s)              21.862218076363206
Epoch Time (s)               84.69674807367846
Total Train Time (s)         30117.886175457388
Epoch                        371
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:10:18.309592 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #371 | Epoch Duration: 80.89138650894165
2020-01-11 09:10:18.309772 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #371 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03531011
Z variance train             0.004787643
KL Divergence                11.121107
KL Loss                      1.1121107
QF Loss                      65.048416
VF Loss                      67.25836
Policy Loss                  -1591.0624
Q Predictions Mean           1589.9751
Q Predictions Std            165.697
Q Predictions Max            1764.6127
Q Predictions Min            641.29974
V Predictions Mean           1591.2668
V Predictions Std            162.61848
V Predictions Max            1767.3483
V Predictions Min            651.42224
Log Pis Mean                 -0.6502075
Log Pis Std                  1.712208
Log Pis Max                  5.861554
Log Pis Min                  -5.382333
Policy mu Mean               0.004419157
Policy mu Std                0.76601666
Policy mu Max                1.6869414
Policy mu Min                -3.2149265
Policy log std Mean          -0.4264233
Policy log std Std           0.17152658
Policy log std Max           -0.026454926
Policy log std Min           -1.2423632
Z mean eval                  0.0833737
Z variance eval              0.0052017285
total_rewards                [1596.91483303 3358.87687368 1428.96979755 2714.6904851  1154.19917859
 3037.74328988 1024.63083965 3336.74017211 1567.50170105 2472.42197317]
total_rewards_mean           2169.268914379606
total_rewards_std            866.0317020005202
total_rewards_max            3358.8768736771053
total_rewards_min            1024.63083964894
Number of train steps total  373000
Number of env steps total    1867000
Number of rollouts total     0
Train Time (s)               44.808717992156744
(Previous) Eval Time (s)     14.227712060790509
Sample Time (s)              22.17492312565446
Epoch Time (s)               81.21135317860171
Total Train Time (s)         30203.841584998183
Epoch                        372
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:11:44.272112 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #372 | Epoch Duration: 85.96219253540039
2020-01-11 09:11:44.272307 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #372 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0865839
Z variance train             0.0052209357
KL Divergence                10.9923725
KL Loss                      1.0992373
QF Loss                      137.25421
VF Loss                      272.98
Policy Loss                  -1565.6735
Q Predictions Mean           1571.4594
Q Predictions Std            163.30266
Q Predictions Max            1764.4655
Q Predictions Min            570.5967
V Predictions Mean           1574.2188
V Predictions Std            163.03937
V Predictions Max            1777.8983
V Predictions Min            552.4089
Log Pis Mean                 -0.40776348
Log Pis Std                  1.8323733
Log Pis Max                  11.163192
Log Pis Min                  -4.5574465
Policy mu Mean               0.03509532
Policy mu Std                0.81953704
Policy mu Max                2.4419258
Policy mu Min                -2.9729013
Policy log std Mean          -0.45129418
Policy log std Std           0.15460026
Policy log std Max           -0.03443089
Policy log std Min           -1.1724085
Z mean eval                  0.020032877
Z variance eval              0.004371083
total_rewards                [3433.43866184 3415.18933806 2027.37054117 1441.95175251 2496.96074981
 1910.96699745 1025.39176676 1325.66924327 1273.67741445 1287.3443928 ]
total_rewards_mean           1963.7960858131435
total_rewards_std            839.7302883507175
total_rewards_max            3433.4386618378444
total_rewards_min            1025.391766762436
Number of train steps total  374000
Number of env steps total    1872000
Number of rollouts total     0
Train Time (s)               43.83992154011503
(Previous) Eval Time (s)     18.97828818531707
Sample Time (s)              21.744686746038496
Epoch Time (s)               84.5628964714706
Total Train Time (s)         30286.746833753306
Epoch                        373
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:13:07.186176 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #373 | Epoch Duration: 82.9136860370636
2020-01-11 09:13:07.186455 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #373 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02018581
Z variance train             0.004374239
KL Divergence                11.304903
KL Loss                      1.1304903
QF Loss                      57.841377
VF Loss                      33.11249
Policy Loss                  -1591.1129
Q Predictions Mean           1590.2561
Q Predictions Std            148.98062
Q Predictions Max            1760.252
Q Predictions Min            508.835
V Predictions Mean           1587.9487
V Predictions Std            149.37988
V Predictions Max            1756.8567
V Predictions Min            486.8504
Log Pis Mean                 -0.6104243
Log Pis Std                  1.7825649
Log Pis Max                  4.5030975
Log Pis Min                  -6.2993865
Policy mu Mean               -0.024394505
Policy mu Std                0.80093515
Policy mu Max                1.7520926
Policy mu Min                -2.7129183
Policy log std Mean          -0.44955635
Policy log std Std           0.16638312
Policy log std Max           -0.048143268
Policy log std Min           -1.1113353
Z mean eval                  0.023864137
Z variance eval              0.004711358
total_rewards                [1895.64494987 2449.66946583 3005.62107078 2433.22072045  919.40253977
 2754.38454043  379.6955034  1126.59369323  997.99370887 1330.87846308]
total_rewards_mean           1729.3104655722764
total_rewards_std            851.8257261938786
total_rewards_max            3005.6210707830405
total_rewards_min            379.6955034006129
Number of train steps total  375000
Number of env steps total    1877000
Number of rollouts total     0
Train Time (s)               43.94729198468849
(Previous) Eval Time (s)     17.328822585288435
Sample Time (s)              21.859599237330258
Epoch Time (s)               83.13571380730718
Total Train Time (s)         30369.587151289452
Epoch                        374
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:14:30.028059 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #374 | Epoch Duration: 82.84140729904175
2020-01-11 09:14:30.028191 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #374 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023998078
Z variance train             0.0047129826
KL Divergence                11.20516
KL Loss                      1.1205161
QF Loss                      94.80691
VF Loss                      91.93688
Policy Loss                  -1581.7117
Q Predictions Mean           1583.0938
Q Predictions Std            185.8163
Q Predictions Max            1768.5851
Q Predictions Min            28.28528
V Predictions Mean           1583.6925
V Predictions Std            183.77002
V Predictions Max            1763.9204
V Predictions Min            101.841354
Log Pis Mean                 -0.27314466
Log Pis Std                  2.0163252
Log Pis Max                  10.244379
Log Pis Min                  -6.0270853
Policy mu Mean               -0.039832845
Policy mu Std                0.882825
Policy mu Max                4.752212
Policy mu Min                -3.537464
Policy log std Mean          -0.4548141
Policy log std Std           0.18027134
Policy log std Max           0.35365033
Policy log std Min           -1.4027538
Z mean eval                  0.035158183
Z variance eval              0.0040123686
total_rewards                [2551.65918898 1039.98905927 2069.04226601 3085.25195239 3371.69739821
 2773.3678163  1159.12204779 3325.17719476 1073.97561598 1075.939514  ]
total_rewards_mean           2152.522205368622
total_rewards_std            939.6854831075234
total_rewards_max            3371.697398213535
total_rewards_min            1039.9890592679333
Number of train steps total  376000
Number of env steps total    1882000
Number of rollouts total     0
Train Time (s)               44.06935302820057
(Previous) Eval Time (s)     17.034283032175153
Sample Time (s)              22.527968580834568
Epoch Time (s)               83.63160464121029
Total Train Time (s)         30456.768402692862
Epoch                        375
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:15:57.213542 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #375 | Epoch Duration: 87.18524670600891
2020-01-11 09:15:57.213702 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #375 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035332225
Z variance train             0.0040121293
KL Divergence                11.640718
KL Loss                      1.1640719
QF Loss                      95.844185
VF Loss                      17.29914
Policy Loss                  -1592.3113
Q Predictions Mean           1590.0032
Q Predictions Std            164.42143
Q Predictions Max            1761.8774
Q Predictions Min            534.62695
V Predictions Mean           1591.4526
V Predictions Std            164.77882
V Predictions Max            1763.0542
V Predictions Min            527.69116
Log Pis Mean                 -0.33493653
Log Pis Std                  1.9418341
Log Pis Max                  6.3821497
Log Pis Min                  -4.078553
Policy mu Mean               -0.0016354447
Policy mu Std                0.84172815
Policy mu Max                2.1687117
Policy mu Min                -3.2170534
Policy log std Mean          -0.44590345
Policy log std Std           0.17245246
Policy log std Max           -0.056915373
Policy log std Min           -1.2155539
Z mean eval                  0.030171206
Z variance eval              0.0039273696
total_rewards                [1049.65166849 2479.66127781 1263.17437989 1882.00785904 1025.73380611
 1933.43588275 1082.52264686 1136.66204768 2757.42706732 2766.7968593 ]
total_rewards_mean           1737.707349523842
total_rewards_std            685.8944805814577
total_rewards_max            2766.796859297223
total_rewards_min            1025.733806106935
Number of train steps total  377000
Number of env steps total    1887000
Number of rollouts total     0
Train Time (s)               44.334608355071396
(Previous) Eval Time (s)     20.58766701677814
Sample Time (s)              21.40770101454109
Epoch Time (s)               86.32997638639063
Total Train Time (s)         30539.570628764573
Epoch                        376
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:17:20.020273 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #376 | Epoch Duration: 82.80643606185913
2020-01-11 09:17:20.020458 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #376 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030100593
Z variance train             0.003928072
KL Divergence                11.6947365
KL Loss                      1.1694736
QF Loss                      80.91618
VF Loss                      47.505596
Policy Loss                  -1596.449
Q Predictions Mean           1594.6697
Q Predictions Std            163.0805
Q Predictions Max            1760.2966
Q Predictions Min            394.62006
V Predictions Mean           1595.898
V Predictions Std            162.17194
V Predictions Max            1756.9231
V Predictions Min            408.06677
Log Pis Mean                 -0.40513474
Log Pis Std                  2.050919
Log Pis Max                  9.119312
Log Pis Min                  -5.5293927
Policy mu Mean               -0.019330347
Policy mu Std                0.8459839
Policy mu Max                2.1427076
Policy mu Min                -3.4681976
Policy log std Mean          -0.44694868
Policy log std Std           0.15561825
Policy log std Max           -0.113211334
Policy log std Min           -1.1501802
Z mean eval                  0.03705223
Z variance eval              0.004069281
total_rewards                [1718.601252   1019.78806433 2361.08394118 2696.88033803 1608.07331519
 1540.13001197  788.09141342 1152.97102327 1654.18588528 1577.93183256]
total_rewards_mean           1611.7737077222057
total_rewards_std            547.5239130724883
total_rewards_max            2696.880338025724
total_rewards_min            788.0914134159273
Number of train steps total  378000
Number of env steps total    1892000
Number of rollouts total     0
Train Time (s)               44.27053480502218
(Previous) Eval Time (s)     17.06386477779597
Sample Time (s)              22.013196270912886
Epoch Time (s)               83.34759585373104
Total Train Time (s)         30620.731353993993
Epoch                        377
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:18:41.184587 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #377 | Epoch Duration: 81.16398668289185
2020-01-11 09:18:41.184748 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #377 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035679836
Z variance train             0.004057874
KL Divergence                11.66156
KL Loss                      1.166156
QF Loss                      143.74973
VF Loss                      101.11779
Policy Loss                  -1574.2853
Q Predictions Mean           1580.2532
Q Predictions Std            146.78502
Q Predictions Max            1761.3417
Q Predictions Min            861.68066
V Predictions Mean           1578.585
V Predictions Std            148.3414
V Predictions Max            1749.0555
V Predictions Min            847.54645
Log Pis Mean                 -0.6117564
Log Pis Std                  1.9554999
Log Pis Max                  9.017606
Log Pis Min                  -5.973505
Policy mu Mean               0.0017880189
Policy mu Std                0.7687398
Policy mu Max                2.5807517
Policy mu Min                -3.0188897
Policy log std Mean          -0.45732865
Policy log std Std           0.17161769
Policy log std Max           -0.069542766
Policy log std Min           -1.2737775
Z mean eval                  0.026615392
Z variance eval              0.0039227623
total_rewards                [ 991.80468001 1328.01273771 1544.51122081 2140.83760244 1642.48389054
 2002.93948503 2072.1820287  1290.29138672 1616.85328094 1561.14559473]
total_rewards_mean           1619.1061907644241
total_rewards_std            349.377527966852
total_rewards_max            2140.8376024432737
total_rewards_min            991.804680012093
Number of train steps total  379000
Number of env steps total    1897000
Number of rollouts total     0
Train Time (s)               43.70665404293686
(Previous) Eval Time (s)     14.880003672093153
Sample Time (s)              22.569869220722467
Epoch Time (s)               81.15652693575248
Total Train Time (s)         30702.675599162932
Epoch                        378
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:20:03.137338 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #378 | Epoch Duration: 81.95245623588562
2020-01-11 09:20:03.137521 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #378 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026588518
Z variance train             0.003923542
KL Divergence                11.648031
KL Loss                      1.1648031
QF Loss                      79.54381
VF Loss                      53.35173
Policy Loss                  -1581.8833
Q Predictions Mean           1582.8049
Q Predictions Std            169.10014
Q Predictions Max            1735.3948
Q Predictions Min            567.6263
V Predictions Mean           1585.1826
V Predictions Std            169.12871
V Predictions Max            1746.3984
V Predictions Min            578.39905
Log Pis Mean                 -0.29712436
Log Pis Std                  2.0730364
Log Pis Max                  10.786016
Log Pis Min                  -5.086143
Policy mu Mean               0.011493613
Policy mu Std                0.85540175
Policy mu Max                2.583342
Policy mu Min                -2.9966483
Policy log std Mean          -0.45194808
Policy log std Std           0.17138568
Policy log std Max           -0.012025446
Policy log std Min           -1.2420077
Z mean eval                  0.03512335
Z variance eval              0.0045207716
total_rewards                [2179.46406893 1104.04474614 2795.05700597 3410.76382474 1012.37308825
 1850.09820275 1660.33041457 1689.29393002 3326.01020393 2084.01067463]
total_rewards_mean           2111.144615992106
total_rewards_std            794.2879914408334
total_rewards_max            3410.7638247395503
total_rewards_min            1012.373088248161
Number of train steps total  380000
Number of env steps total    1902000
Number of rollouts total     0
Train Time (s)               44.954034503083676
(Previous) Eval Time (s)     15.675676940008998
Sample Time (s)              21.544733237475157
Epoch Time (s)               82.17444468056783
Total Train Time (s)         30789.904683255125
Epoch                        379
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:21:30.367963 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #379 | Epoch Duration: 87.23031210899353
2020-01-11 09:21:30.368101 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #379 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.034649946
Z variance train             0.0045240195
KL Divergence                11.406532
KL Loss                      1.1406533
QF Loss                      374.41437
VF Loss                      209.36333
Policy Loss                  -1570.6674
Q Predictions Mean           1572.0468
Q Predictions Std            146.18349
Q Predictions Max            1768.4739
Q Predictions Min            729.13635
V Predictions Mean           1573.4492
V Predictions Std            142.84438
V Predictions Max            1767.6458
V Predictions Min            715.81116
Log Pis Mean                 -0.63729537
Log Pis Std                  1.7825913
Log Pis Max                  8.331643
Log Pis Min                  -4.9692297
Policy mu Mean               0.021859469
Policy mu Std                0.7391765
Policy mu Max                2.3107874
Policy mu Min                -3.0193672
Policy log std Mean          -0.4331406
Policy log std Std           0.1728687
Policy log std Max           0.005158752
Policy log std Min           -1.5714147
Z mean eval                  0.017013956
Z variance eval              0.005888532
total_rewards                [2624.58076225 1935.86674235  876.45868985  649.7132877   658.03329401
 3296.05145412 2171.60197898  375.57219571 2702.56548232 2988.99652877]
total_rewards_mean           1827.9440416052844
total_rewards_std            1039.4397668573395
total_rewards_max            3296.0514541184266
total_rewards_min            375.57219571207185
Number of train steps total  381000
Number of env steps total    1907000
Number of rollouts total     0
Train Time (s)               44.075378451962024
(Previous) Eval Time (s)     20.731317806057632
Sample Time (s)              21.769374831113964
Epoch Time (s)               86.57607108913362
Total Train Time (s)         30876.024597799405
Epoch                        380
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:22:56.493005 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #380 | Epoch Duration: 86.12480425834656
2020-01-11 09:22:56.493131 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #380 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.016060593
Z variance train             0.0058770366
KL Divergence                10.96324
KL Loss                      1.096324
QF Loss                      258.45752
VF Loss                      221.25656
Policy Loss                  -1598.1653
Q Predictions Mean           1598.976
Q Predictions Std            149.90541
Q Predictions Max            1752.864
Q Predictions Min            417.2194
V Predictions Mean           1594.1912
V Predictions Std            147.70702
V Predictions Max            1741.8325
V Predictions Min            452.46027
Log Pis Mean                 -0.056133933
Log Pis Std                  2.1676164
Log Pis Max                  12.360083
Log Pis Min                  -5.13876
Policy mu Mean               -0.21658604
Policy mu Std                0.94267845
Policy mu Max                2.1151729
Policy mu Min                -4.7517066
Policy log std Mean          -0.45729694
Policy log std Std           0.18017605
Policy log std Max           -0.036390394
Policy log std Min           -1.3021544
Z mean eval                  0.091763295
Z variance eval              0.00539909
total_rewards                [2062.06766251 3438.73703513 3493.61998458 3426.26769069 1728.46317253
 1487.44275685 3409.64815427 1294.38053601 2955.49416293 2059.15301176]
total_rewards_mean           2535.5274167268635
total_rewards_std            849.0572884867654
total_rewards_max            3493.619984577968
total_rewards_min            1294.38053601463
Number of train steps total  382000
Number of env steps total    1912000
Number of rollouts total     0
Train Time (s)               43.520297795999795
(Previous) Eval Time (s)     20.279807440936565
Sample Time (s)              21.894813927356154
Epoch Time (s)               85.69491916429251
Total Train Time (s)         30963.446879660245
Epoch                        381
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:24:23.916390 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #381 | Epoch Duration: 87.4231481552124
2020-01-11 09:24:23.916566 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #381 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.093595535
Z variance train             0.00540196
KL Divergence                11.138187
KL Loss                      1.1138188
QF Loss                      67.89351
VF Loss                      43.075146
Policy Loss                  -1595.8247
Q Predictions Mean           1594.638
Q Predictions Std            149.45294
Q Predictions Max            1737.0594
Q Predictions Min            17.67638
V Predictions Mean           1599.6833
V Predictions Std            147.8489
V Predictions Max            1744.7761
V Predictions Min            55.342037
Log Pis Mean                 -0.75366104
Log Pis Std                  1.8718992
Log Pis Max                  7.484896
Log Pis Min                  -5.9506316
Policy mu Mean               0.028306998
Policy mu Std                0.7675873
Policy mu Max                2.494018
Policy mu Min                -3.0935645
Policy log std Mean          -0.4293008
Policy log std Std           0.16977714
Policy log std Max           -0.012977868
Policy log std Min           -1.2389119
Z mean eval                  0.0503698
Z variance eval              0.0055506905
total_rewards                [3409.59249362 3338.52041973 1931.00461446 1531.91967783 3388.59714394
 3377.51365899 1590.45843852 1184.17428149 3371.77335389 1048.56834232]
total_rewards_mean           2417.2122424806503
total_rewards_std            985.2823476903743
total_rewards_max            3409.5924936242063
total_rewards_min            1048.568342323555
Number of train steps total  383000
Number of env steps total    1917000
Number of rollouts total     0
Train Time (s)               43.5425562011078
(Previous) Eval Time (s)     22.00774807156995
Sample Time (s)              20.1775856888853
Epoch Time (s)               85.72788996156305
Total Train Time (s)         31050.502389057074
Epoch                        382
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:25:50.976092 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #382 | Epoch Duration: 87.05939769744873
2020-01-11 09:25:50.976230 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #382 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.047523372
Z variance train             0.005564657
KL Divergence                11.0273485
KL Loss                      1.1027349
QF Loss                      83.86392
VF Loss                      279.11002
Policy Loss                  -1604.2815
Q Predictions Mean           1606.7725
Q Predictions Std            123.649956
Q Predictions Max            1783.6215
Q Predictions Min            1122.6904
V Predictions Mean           1608.0479
V Predictions Std            127.09778
V Predictions Max            1795.1527
V Predictions Min            1112.8364
Log Pis Mean                 -0.50287765
Log Pis Std                  1.9181663
Log Pis Max                  6.3966904
Log Pis Min                  -4.4134293
Policy mu Mean               -0.08868454
Policy mu Std                0.8320582
Policy mu Max                1.7653911
Policy mu Min                -3.531901
Policy log std Mean          -0.41376093
Policy log std Std           0.17165926
Policy log std Max           -0.010903001
Policy log std Min           -1.1994724
Z mean eval                  0.03733926
Z variance eval              0.0058961296
total_rewards                [2901.88864892 3280.5063044  3340.82522264 3073.75954518 3314.91028705
 3415.90839247 2198.03977222 3339.3106038  2546.96613144  624.36874459]
total_rewards_mean           2803.6483652710845
total_rewards_std            818.7585726356358
total_rewards_max            3415.908392474452
total_rewards_min            624.3687445909243
Number of train steps total  384000
Number of env steps total    1922000
Number of rollouts total     0
Train Time (s)               45.04267161525786
(Previous) Eval Time (s)     23.339014149736613
Sample Time (s)              21.713080117013305
Epoch Time (s)               90.09476588200778
Total Train Time (s)         31144.054819612764
Epoch                        383
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:27:24.530950 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #383 | Epoch Duration: 93.55462694168091
2020-01-11 09:27:24.531089 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #383 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03645215
Z variance train             0.0059059267
KL Divergence                10.962561
KL Loss                      1.0962561
QF Loss                      77.76238
VF Loss                      56.375885
Policy Loss                  -1582.3948
Q Predictions Mean           1578.958
Q Predictions Std            175.8628
Q Predictions Max            1769.6327
Q Predictions Min            636.02
V Predictions Mean           1578.0963
V Predictions Std            175.42047
V Predictions Max            1768.9425
V Predictions Min            630.72327
Log Pis Mean                 -0.53396416
Log Pis Std                  1.8721591
Log Pis Max                  8.173789
Log Pis Min                  -5.5821753
Policy mu Mean               -0.07236507
Policy mu Std                0.79603446
Policy mu Max                1.7367907
Policy mu Min                -3.1707993
Policy log std Mean          -0.4067966
Policy log std Std           0.15892029
Policy log std Max           -0.06191951
Policy log std Min           -1.0266603
Z mean eval                  0.03324442
Z variance eval              0.0073736184
total_rewards                [1364.70758133 1191.79394151 1559.67908049 3392.29540816 2494.86175627
 1064.03211039 3350.46454644 3368.14673784 3356.87765196 3342.50618204]
total_rewards_mean           2448.536499641866
total_rewards_std            981.6952906932875
total_rewards_max            3392.2954081561224
total_rewards_min            1064.0321103902052
Number of train steps total  385000
Number of env steps total    1927000
Number of rollouts total     0
Train Time (s)               43.89446491608396
(Previous) Eval Time (s)     26.798635552171618
Sample Time (s)              21.656194041483104
Epoch Time (s)               92.34929450973868
Total Train Time (s)         31233.53478709841
Epoch                        384
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:28:54.014065 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #384 | Epoch Duration: 89.48288297653198
2020-01-11 09:28:54.014186 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #384 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03335324
Z variance train             0.0073956596
KL Divergence                9.979719
KL Loss                      0.99797195
QF Loss                      170.77203
VF Loss                      140.91893
Policy Loss                  -1598.3776
Q Predictions Mean           1592.6178
Q Predictions Std            122.749855
Q Predictions Max            1745.4446
Q Predictions Min            1028.2332
V Predictions Mean           1601.2323
V Predictions Std            124.6419
V Predictions Max            1773.2084
V Predictions Min            1023.35376
Log Pis Mean                 -0.66395485
Log Pis Std                  1.949215
Log Pis Max                  7.7266083
Log Pis Min                  -4.505163
Policy mu Mean               -0.111886345
Policy mu Std                0.8204569
Policy mu Max                1.6826273
Policy mu Min                -3.175541
Policy log std Mean          -0.4011198
Policy log std Std           0.15889497
Policy log std Max           0.008446157
Policy log std Min           -1.1599854
Z mean eval                  0.037707455
Z variance eval              0.008600192
total_rewards                [2489.65040994 2455.64960366 1544.26850444 2176.27069993 1884.06236406
 1485.76840401 3013.81067467 1034.67694066 1808.80901253 1419.66493265]
total_rewards_mean           1931.2631546538923
total_rewards_std            570.0673862525899
total_rewards_max            3013.810674667122
total_rewards_min            1034.6769406588958
Number of train steps total  386000
Number of env steps total    1932000
Number of rollouts total     0
Train Time (s)               43.76964649185538
(Previous) Eval Time (s)     23.931960746645927
Sample Time (s)              22.10584252467379
Epoch Time (s)               89.8074497631751
Total Train Time (s)         31318.12425248325
Epoch                        385
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:30:18.611120 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #385 | Epoch Duration: 84.59677338600159
2020-01-11 09:30:18.611391 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #385 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036391605
Z variance train             0.00859228
KL Divergence                9.522913
KL Loss                      0.9522913
QF Loss                      106.12506
VF Loss                      73.042114
Policy Loss                  -1586.3019
Q Predictions Mean           1582.5752
Q Predictions Std            128.5637
Q Predictions Max            1741.2083
Q Predictions Min            821.3038
V Predictions Mean           1586.9785
V Predictions Std            126.70195
V Predictions Max            1743.8408
V Predictions Min            856.6993
Log Pis Mean                 -0.34265453
Log Pis Std                  2.1269128
Log Pis Max                  7.442872
Log Pis Min                  -4.6362963
Policy mu Mean               -0.05674391
Policy mu Std                0.8827351
Policy mu Max                2.0677712
Policy mu Min                -3.0682516
Policy log std Mean          -0.43698668
Policy log std Std           0.1628649
Policy log std Max           -0.009572804
Policy log std Min           -0.99013597
Z mean eval                  0.02877644
Z variance eval              0.006990602
total_rewards                [ 998.17562585 3432.99924182 1008.50380925 1419.75014509 1002.48562478
 3099.60606947 1220.17036839 1017.32866501 1887.6281943  2542.36976586]
total_rewards_mean           1762.9017509824585
total_rewards_std            888.7899485571863
total_rewards_max            3432.999241815643
total_rewards_min            998.1756258518438
Number of train steps total  387000
Number of env steps total    1937000
Number of rollouts total     0
Train Time (s)               43.908888164907694
(Previous) Eval Time (s)     18.720981194172055
Sample Time (s)              22.460656724404544
Epoch Time (s)               85.09052608348429
Total Train Time (s)         31401.042607719544
Epoch                        386
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:31:41.534369 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #386 | Epoch Duration: 82.92276668548584
2020-01-11 09:31:41.534548 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #386 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030678025
Z variance train             0.006994559
KL Divergence                10.028563
KL Loss                      1.0028563
QF Loss                      823.54285
VF Loss                      307.167
Policy Loss                  -1602.5596
Q Predictions Mean           1604.0881
Q Predictions Std            188.13644
Q Predictions Max            1787.0626
Q Predictions Min            108.731766
V Predictions Mean           1592.9323
V Predictions Std            184.5828
V Predictions Max            1771.6188
V Predictions Min            244.40959
Log Pis Mean                 -0.39520884
Log Pis Std                  2.0379417
Log Pis Max                  11.394801
Log Pis Min                  -4.465742
Policy mu Mean               -0.044848766
Policy mu Std                0.85433555
Policy mu Max                2.1754732
Policy mu Min                -3.0234604
Policy log std Mean          -0.4256867
Policy log std Std           0.16348045
Policy log std Max           -0.027377754
Policy log std Min           -1.2019194
Z mean eval                  0.024393592
Z variance eval              0.008503623
total_rewards                [3351.35493216 2842.07693406 3345.05830437 3281.90805626 3124.05359639
 3397.70582925 2838.30026942 1959.413718   1120.01152117 3313.77387838]
total_rewards_mean           2857.3657039464524
total_rewards_std            711.2537174911819
total_rewards_max            3397.7058292497186
total_rewards_min            1120.0115211669186
Number of train steps total  388000
Number of env steps total    1942000
Number of rollouts total     0
Train Time (s)               44.277994784060866
(Previous) Eval Time (s)     16.552979791071266
Sample Time (s)              19.72032984206453
Epoch Time (s)               80.55130441719666
Total Train Time (s)         31492.981296275742
Epoch                        387
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:33:13.480162 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #387 | Epoch Duration: 91.94542074203491
2020-01-11 09:33:13.480419 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #387 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024709936
Z variance train             0.008500455
KL Divergence                9.684944
KL Loss                      0.9684944
QF Loss                      204.78503
VF Loss                      87.63285
Policy Loss                  -1588.3702
Q Predictions Mean           1588.9805
Q Predictions Std            172.15773
Q Predictions Max            1775.314
Q Predictions Min            553.63824
V Predictions Mean           1581.3248
V Predictions Std            172.26251
V Predictions Max            1768.6816
V Predictions Min            535.17725
Log Pis Mean                 -0.6010854
Log Pis Std                  2.0768526
Log Pis Max                  10.348816
Log Pis Min                  -5.759371
Policy mu Mean               -0.06471622
Policy mu Std                0.8746298
Policy mu Max                2.261077
Policy mu Min                -3.2145119
Policy log std Mean          -0.42013493
Policy log std Std           0.16178107
Policy log std Max           -0.053400382
Policy log std Min           -1.123861
Z mean eval                  0.034934916
Z variance eval              0.0073450385
total_rewards                [3327.2592247  1685.76634883  932.4505561  3296.50319845 3404.88215514
 3373.30538262 2749.60320825 3317.03975837 3420.85314878 1021.23718576]
total_rewards_mean           2652.8900166991552
total_rewards_std            977.3049172314858
total_rewards_max            3420.8531487813325
total_rewards_min            932.4505560980953
Number of train steps total  389000
Number of env steps total    1947000
Number of rollouts total     0
Train Time (s)               43.643697826657444
(Previous) Eval Time (s)     27.946836553979665
Sample Time (s)              21.861449704505503
Epoch Time (s)               93.45198408514261
Total Train Time (s)         31586.04797716206
Epoch                        388
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:34:46.551508 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #388 | Epoch Duration: 93.07091999053955
2020-01-11 09:34:46.551683 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #388 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033855956
Z variance train             0.007358926
KL Divergence                9.870373
KL Loss                      0.9870373
QF Loss                      171.50276
VF Loss                      67.07585
Policy Loss                  -1604.5283
Q Predictions Mean           1610.3463
Q Predictions Std            146.92508
Q Predictions Max            1779.8142
Q Predictions Min            506.3907
V Predictions Mean           1607.3975
V Predictions Std            148.72656
V Predictions Max            1776.9602
V Predictions Min            467.11078
Log Pis Mean                 -0.29313585
Log Pis Std                  2.0866807
Log Pis Max                  7.357292
Log Pis Min                  -4.6614013
Policy mu Mean               -0.066526614
Policy mu Std                0.88160694
Policy mu Max                2.3722994
Policy mu Min                -3.2766576
Policy log std Mean          -0.42021474
Policy log std Std           0.16322435
Policy log std Max           -0.03193623
Policy log std Min           -1.5618092
Z mean eval                  0.023906633
Z variance eval              0.0066853673
total_rewards                [1640.50479542 1030.22330213 1095.26042908  808.47534951 2996.86430875
 2446.25310687 1103.45075507  996.06260027 2992.60432194 2281.12342536]
total_rewards_mean           1739.0822394409242
total_rewards_std            818.2953262014748
total_rewards_max            2996.8643087470505
total_rewards_min            808.4753495095295
Number of train steps total  390000
Number of env steps total    1952000
Number of rollouts total     0
Train Time (s)               44.0970305823721
(Previous) Eval Time (s)     27.56551990332082
Sample Time (s)              21.37083867425099
Epoch Time (s)               93.03338915994391
Total Train Time (s)         31668.258181950077
Epoch                        389
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:36:08.764954 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #389 | Epoch Duration: 82.2130835056305
2020-01-11 09:36:08.765150 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #389 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0237369
Z variance train             0.0066868686
KL Divergence                10.160548
KL Loss                      1.0160549
QF Loss                      57.720665
VF Loss                      83.721176
Policy Loss                  -1605.4167
Q Predictions Mean           1605.3909
Q Predictions Std            130.57982
Q Predictions Max            1783.9889
Q Predictions Min            715.3685
V Predictions Mean           1602.9761
V Predictions Std            126.1645
V Predictions Max            1778.3744
V Predictions Min            834.2384
Log Pis Mean                 -0.44669306
Log Pis Std                  1.8370103
Log Pis Max                  9.348786
Log Pis Min                  -3.921846
Policy mu Mean               0.04034691
Policy mu Std                0.83290154
Policy mu Max                2.242352
Policy mu Min                -3.3142653
Policy log std Mean          -0.44682196
Policy log std Std           0.16759714
Policy log std Max           -0.07104643
Policy log std Min           -1.2903318
Z mean eval                  0.021307275
Z variance eval              0.0055681756
total_rewards                [2271.9528957  1386.1512479  1408.00886608 1616.43224013 1166.54433316
 3383.49652347 3385.4089655  3404.86869277 1864.2595982  2031.09298702]
total_rewards_mean           2191.8216349926934
total_rewards_std            842.704471071621
total_rewards_max            3404.8686927721383
total_rewards_min            1166.5443331592
Number of train steps total  391000
Number of env steps total    1957000
Number of rollouts total     0
Train Time (s)               44.144872524775565
(Previous) Eval Time (s)     16.74497465370223
Sample Time (s)              21.68204898200929
Epoch Time (s)               82.57189616048709
Total Train Time (s)         31755.24295039056
Epoch                        390
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:37:35.752544 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #390 | Epoch Duration: 86.98727369308472
2020-01-11 09:37:35.752667 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #390 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02117848
Z variance train             0.0055705914
KL Divergence                10.550653
KL Loss                      1.0550654
QF Loss                      80.7935
VF Loss                      29.469433
Policy Loss                  -1591.7391
Q Predictions Mean           1594.8643
Q Predictions Std            142.20142
Q Predictions Max            1789.3528
Q Predictions Min            825.7018
V Predictions Mean           1591.1355
V Predictions Std            140.79608
V Predictions Max            1784.1212
V Predictions Min            826.1939
Log Pis Mean                 -0.67299163
Log Pis Std                  1.9180058
Log Pis Max                  8.248602
Log Pis Min                  -4.6847568
Policy mu Mean               -0.005249822
Policy mu Std                0.827003
Policy mu Max                1.8284051
Policy mu Min                -3.2907238
Policy log std Mean          -0.44269216
Policy log std Std           0.15951933
Policy log std Max           0.005228281
Policy log std Min           -1.4675286
Z mean eval                  0.057103496
Z variance eval              0.004785658
total_rewards                [2378.89623555 1067.54950697 3470.56799438 3411.57135359 1363.46698028
 2161.69460301 1030.26103689 2903.16018815 1489.16459512 2155.18179946]
total_rewards_mean           2143.151429340452
total_rewards_std            862.3022954878915
total_rewards_max            3470.567994384894
total_rewards_min            1030.2610368890516
Number of train steps total  392000
Number of env steps total    1962000
Number of rollouts total     0
Train Time (s)               44.87745970534161
(Previous) Eval Time (s)     21.160103262402117
Sample Time (s)              21.906436883844435
Epoch Time (s)               87.94399985158816
Total Train Time (s)         31841.356293457095
Epoch                        391
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:39:01.867758 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #391 | Epoch Duration: 86.1149971485138
2020-01-11 09:39:01.867884 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #391 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.058273263
Z variance train             0.0047807163
KL Divergence                10.992271
KL Loss                      1.0992272
QF Loss                      68.95523
VF Loss                      74.64601
Policy Loss                  -1570.051
Q Predictions Mean           1570.2666
Q Predictions Std            192.71512
Q Predictions Max            1761.9259
Q Predictions Min            526.98865
V Predictions Mean           1571.1328
V Predictions Std            189.70609
V Predictions Max            1758.2312
V Predictions Min            549.7333
Log Pis Mean                 -0.54933757
Log Pis Std                  1.7981894
Log Pis Max                  6.8148785
Log Pis Min                  -4.5967755
Policy mu Mean               0.094988704
Policy mu Std                0.84039086
Policy mu Max                3.251623
Policy mu Min                -2.8956108
Policy log std Mean          -0.43545905
Policy log std Std           0.15662035
Policy log std Max           -0.05897543
Policy log std Min           -1.3961664
Z mean eval                  0.029187758
Z variance eval              0.004792294
total_rewards                [3273.87152515 1539.0361257  1017.21958622 1880.75411899 1026.80035975
 2004.06125363 1032.20377344 1610.39643493 2115.91200938 2771.11803232]
total_rewards_mean           1827.1373219516815
total_rewards_std            718.3391500202376
total_rewards_max            3273.871525145466
total_rewards_min            1017.2195862218151
Number of train steps total  393000
Number of env steps total    1967000
Number of rollouts total     0
Train Time (s)               44.03453034441918
(Previous) Eval Time (s)     19.3308427920565
Sample Time (s)              21.547540419735014
Epoch Time (s)               84.9129135562107
Total Train Time (s)         31922.923273317516
Epoch                        392
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:40:23.439068 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #392 | Epoch Duration: 81.57107329368591
2020-01-11 09:40:23.439262 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #392 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.029225081
Z variance train             0.004792987
KL Divergence                10.933201
KL Loss                      1.0933201
QF Loss                      374.86182
VF Loss                      53.875805
Policy Loss                  -1593.9564
Q Predictions Mean           1594.5668
Q Predictions Std            162.74586
Q Predictions Max            1755.1039
Q Predictions Min            219.67859
V Predictions Mean           1592.7766
V Predictions Std            162.53145
V Predictions Max            1754.0642
V Predictions Min            228.96918
Log Pis Mean                 -0.39648804
Log Pis Std                  1.9513263
Log Pis Max                  7.6973753
Log Pis Min                  -6.546302
Policy mu Mean               -0.031116536
Policy mu Std                0.8528036
Policy mu Max                2.9274259
Policy mu Min                -3.2831361
Policy log std Mean          -0.43901417
Policy log std Std           0.17676339
Policy log std Max           -0.006457597
Policy log std Min           -1.370884
Z mean eval                  0.04815344
Z variance eval              0.004920203
total_rewards                [2544.85772904 2880.11078474 1044.62270672 2740.33795221 1652.29776402
 3319.91001874 3348.22199961 3344.84199917 1840.31898267 2738.57182138]
total_rewards_mean           2545.4091758293052
total_rewards_std            749.5296879771262
total_rewards_max            3348.2219996051235
total_rewards_min            1044.6227067204713
Number of train steps total  394000
Number of env steps total    1972000
Number of rollouts total     0
Train Time (s)               43.79629038227722
(Previous) Eval Time (s)     15.98873781785369
Sample Time (s)              21.874442882835865
Epoch Time (s)               81.65947108296677
Total Train Time (s)         32011.12169243116
Epoch                        393
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:41:51.642114 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #393 | Epoch Duration: 88.2027018070221
2020-01-11 09:41:51.642278 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #393 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048187878
Z variance train             0.004921936
KL Divergence                10.945257
KL Loss                      1.0945257
QF Loss                      35.285072
VF Loss                      23.938076
Policy Loss                  -1613.364
Q Predictions Mean           1612.7834
Q Predictions Std            126.70307
Q Predictions Max            1772.7787
Q Predictions Min            607.4654
V Predictions Mean           1610.2361
V Predictions Std            126.83849
V Predictions Max            1770.3904
V Predictions Min            605.3572
Log Pis Mean                 -0.7284294
Log Pis Std                  1.607147
Log Pis Max                  4.483685
Log Pis Min                  -7.172286
Policy mu Mean               -0.019182207
Policy mu Std                0.7622031
Policy mu Max                1.6711817
Policy mu Min                -3.0333223
Policy log std Mean          -0.40763187
Policy log std Std           0.14633591
Policy log std Max           0.024621576
Policy log std Min           -0.9931139
Z mean eval                  0.031060273
Z variance eval              0.004566136
total_rewards                [2970.54971436  836.61998824 1035.41918563 1511.2866029  2037.18085502
  991.02618159 1596.67219719 2380.19743813  947.81404332 1016.39347695]
total_rewards_mean           1532.3159683327785
total_rewards_std            684.0032359073153
total_rewards_max            2970.549714355563
total_rewards_min            836.6199882401763
Number of train steps total  395000
Number of env steps total    1977000
Number of rollouts total     0
Train Time (s)               44.39575390703976
(Previous) Eval Time (s)     22.531718033831567
Sample Time (s)              21.479280422907323
Epoch Time (s)               88.40675236377865
Total Train Time (s)         32091.358766228426
Epoch                        394
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:43:11.881431 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #394 | Epoch Duration: 80.2390341758728
2020-01-11 09:43:11.881558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #394 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0306077
Z variance train             0.0045676017
KL Divergence                11.079067
KL Loss                      1.1079067
QF Loss                      337.52332
VF Loss                      362.61435
Policy Loss                  -1572.3138
Q Predictions Mean           1571.3835
Q Predictions Std            206.81618
Q Predictions Max            1751.2831
Q Predictions Min            188.65186
V Predictions Mean           1578.5164
V Predictions Std            195.7652
V Predictions Max            1754.7283
V Predictions Min            561.98505
Log Pis Mean                 -0.48692572
Log Pis Std                  2.0576947
Log Pis Max                  10.162743
Log Pis Min                  -5.865412
Policy mu Mean               -0.011750032
Policy mu Std                0.8370112
Policy mu Max                3.2309222
Policy mu Min                -3.6329703
Policy log std Mean          -0.42629734
Policy log std Std           0.1597263
Policy log std Max           -0.024498284
Policy log std Min           -1.0882196
Z mean eval                  0.047807448
Z variance eval              0.0047131954
total_rewards                [2403.99902133 1224.94602298 1968.17343641 3382.01633086 3437.93486514
 1600.09948582 2250.55900313 2904.25016894 3402.95215378  968.73161174]
total_rewards_mean           2354.36621001338
total_rewards_std            869.4231623088847
total_rewards_max            3437.93486514254
total_rewards_min            968.7316117369226
Number of train steps total  396000
Number of env steps total    1982000
Number of rollouts total     0
Train Time (s)               44.60602247295901
(Previous) Eval Time (s)     14.363750775810331
Sample Time (s)              21.587981456890702
Epoch Time (s)               80.55775470566005
Total Train Time (s)         32180.062831178308
Epoch                        395
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:44:40.592499 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #395 | Epoch Duration: 88.71081256866455
2020-01-11 09:44:40.592687 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #395 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04776016
Z variance train             0.0047126953
KL Divergence                11.12265
KL Loss                      1.112265
QF Loss                      198.00055
VF Loss                      207.88138
Policy Loss                  -1587.9014
Q Predictions Mean           1585.9425
Q Predictions Std            156.14613
Q Predictions Max            1757.2118
Q Predictions Min            676.82605
V Predictions Mean           1594.7585
V Predictions Std            154.03561
V Predictions Max            1759.5052
V Predictions Min            671.9615
Log Pis Mean                 -0.4433126
Log Pis Std                  2.010884
Log Pis Max                  9.385865
Log Pis Min                  -4.731546
Policy mu Mean               -0.07563191
Policy mu Std                0.82802755
Policy mu Max                2.1560593
Policy mu Min                -3.1863742
Policy log std Mean          -0.4311382
Policy log std Std           0.17833544
Policy log std Max           -0.03675732
Policy log std Min           -1.1785791
Z mean eval                  0.024972491
Z variance eval              0.0044233534
total_rewards                [3311.80239827 1553.45664467 2979.62021541 1039.09191402 2624.95027823
  231.59495364 1192.63720197 3362.83684051 1056.19669812  758.28527838]
total_rewards_mean           1811.0472423211577
total_rewards_std            1091.136723438302
total_rewards_max            3362.836840509087
total_rewards_min            231.5949536429165
Number of train steps total  397000
Number of env steps total    1987000
Number of rollouts total     0
Train Time (s)               44.69372630910948
(Previous) Eval Time (s)     22.516565705183893
Sample Time (s)              19.84792149439454
Epoch Time (s)               87.05821350868791
Total Train Time (s)         32261.26465618657
Epoch                        396
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:46:01.798881 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #396 | Epoch Duration: 81.2060399055481
2020-01-11 09:46:01.799074 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #396 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02552099
Z variance train             0.004418764
KL Divergence                11.333353
KL Loss                      1.1333354
QF Loss                      152.7461
VF Loss                      83.80544
Policy Loss                  -1601.8339
Q Predictions Mean           1600.4824
Q Predictions Std            162.62871
Q Predictions Max            1768.6855
Q Predictions Min            342.83627
V Predictions Mean           1603.0198
V Predictions Std            162.42628
V Predictions Max            1779.9176
V Predictions Min            336.5894
Log Pis Mean                 -0.65603304
Log Pis Std                  1.9619265
Log Pis Max                  9.745523
Log Pis Min                  -5.829157
Policy mu Mean               0.060999334
Policy mu Std                0.80961
Policy mu Max                1.8175116
Policy mu Min                -3.4628253
Policy log std Mean          -0.41467515
Policy log std Std           0.16640146
Policy log std Max           -0.06346026
Policy log std Min           -1.109416
Z mean eval                  0.025401682
Z variance eval              0.0036299217
total_rewards                [3380.60701933 3365.09343108 2717.98023306 3408.70287799 1332.88335429
 1920.11203628 1970.33363528 1178.78380447 1366.21636803 1866.50840809]
total_rewards_mean           2250.722116790489
total_rewards_std            847.7667113333929
total_rewards_max            3408.7028779906414
total_rewards_min            1178.7838044659852
Number of train steps total  398000
Number of env steps total    1992000
Number of rollouts total     0
Train Time (s)               43.93366579292342
(Previous) Eval Time (s)     16.6641682269983
Sample Time (s)              22.259055827278644
Epoch Time (s)               82.85688984720036
Total Train Time (s)         32346.974836374167
Epoch                        397
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:47:27.513082 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #397 | Epoch Duration: 85.71385383605957
2020-01-11 09:47:27.513260 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #397 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025480459
Z variance train             0.0036304544
KL Divergence                11.840689
KL Loss                      1.1840689
QF Loss                      45.788902
VF Loss                      32.84723
Policy Loss                  -1592.7548
Q Predictions Mean           1591.8027
Q Predictions Std            139.39502
Q Predictions Max            1747.229
Q Predictions Min            580.4843
V Predictions Mean           1592.4929
V Predictions Std            138.76962
V Predictions Max            1746.9084
V Predictions Min            595.09094
Log Pis Mean                 -0.54927576
Log Pis Std                  1.8392469
Log Pis Max                  9.802824
Log Pis Min                  -5.9674206
Policy mu Mean               -0.01778
Policy mu Std                0.7827325
Policy mu Max                2.0666158
Policy mu Min                -3.2301936
Policy log std Mean          -0.42616403
Policy log std Std           0.16370526
Policy log std Max           -0.020790458
Policy log std Min           -1.1838785
Z mean eval                  0.06848463
Z variance eval              0.0042392705
total_rewards                [1063.77053164 1921.49621065  966.18896298 1022.01939774 1045.80103168
 1363.04279711 1333.32335523 1017.15999134 1154.43962344 1308.17707418]
total_rewards_mean           1219.5418975997234
total_rewards_std            271.4746722734392
total_rewards_max            1921.4962106532996
total_rewards_min            966.1889629782444
Number of train steps total  399000
Number of env steps total    1997000
Number of rollouts total     0
Train Time (s)               44.16065013688058
(Previous) Eval Time (s)     19.520886411890388
Sample Time (s)              21.768831009045243
Epoch Time (s)               85.45036755781621
Total Train Time (s)         32425.1187781943
Epoch                        398
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:48:45.658943 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #398 | Epoch Duration: 78.14555525779724
2020-01-11 09:48:45.659072 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #398 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.068414606
Z variance train             0.004238569
KL Divergence                11.452742
KL Loss                      1.1452742
QF Loss                      459.0232
VF Loss                      89.63302
Policy Loss                  -1590.9093
Q Predictions Mean           1589.7504
Q Predictions Std            177.49937
Q Predictions Max            1768.3262
Q Predictions Min            39.129475
V Predictions Mean           1591.0917
V Predictions Std            177.23991
V Predictions Max            1769.3619
V Predictions Min            16.589556
Log Pis Mean                 -0.29107535
Log Pis Std                  2.0704439
Log Pis Max                  13.288227
Log Pis Min                  -5.4315677
Policy mu Mean               0.0003029344
Policy mu Std                0.86562353
Policy mu Max                3.7133646
Policy mu Min                -3.5163507
Policy log std Mean          -0.43944037
Policy log std Std           0.16015802
Policy log std Max           -0.039675474
Policy log std Min           -1.2621952
Z mean eval                  0.028690476
Z variance eval              0.0041880147
total_rewards                [2195.55127241 1447.14389532 1752.45655425 3345.27799805 1642.62036536
  967.50086499 1287.79245739 1561.27692533 2694.3099691  2493.0998365 ]
total_rewards_mean           1938.7030138693008
total_rewards_std            692.5369005411654
total_rewards_max            3345.277998054349
total_rewards_min            967.5008649933291
Number of train steps total  400000
Number of env steps total    2002000
Number of rollouts total     0
Train Time (s)               44.104760359972715
(Previous) Eval Time (s)     12.215835974086076
Sample Time (s)              21.956174852792174
Epoch Time (s)               78.27677118685097
Total Train Time (s)         32509.232140354812
Epoch                        399
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:50:09.775487 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #399 | Epoch Duration: 84.11630272865295
2020-01-11 09:50:09.775610 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #399 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02873512
Z variance train             0.004188933
KL Divergence                11.458357
KL Loss                      1.1458358
QF Loss                      495.8388
VF Loss                      69.230606
Policy Loss                  -1606.2483
Q Predictions Mean           1605.739
Q Predictions Std            157.88875
Q Predictions Max            1797.7977
Q Predictions Min            563.5737
V Predictions Mean           1604.6841
V Predictions Std            151.1835
V Predictions Max            1787.7338
V Predictions Min            553.32855
Log Pis Mean                 -0.62669086
Log Pis Std                  1.8867359
Log Pis Max                  10.180595
Log Pis Min                  -5.1777625
Policy mu Mean               0.0025412415
Policy mu Std                0.7645875
Policy mu Max                2.2605612
Policy mu Min                -3.4298737
Policy log std Mean          -0.42254272
Policy log std Std           0.16649707
Policy log std Max           0.07949382
Policy log std Min           -1.8576792
Z mean eval                  0.01992378
Z variance eval              0.0040773842
total_rewards                [2405.28326533 1092.47792998 2624.34471387 3294.91125313 2355.65337843
  942.9728172  1247.47211088 1976.84194247 3353.04763753 1858.91006814]
total_rewards_mean           2115.1915116955233
total_rewards_std            811.3591099424316
total_rewards_max            3353.047637528799
total_rewards_min            942.9728172020039
Number of train steps total  401000
Number of env steps total    2007000
Number of rollouts total     0
Train Time (s)               43.753201817162335
(Previous) Eval Time (s)     18.055111817084253
Sample Time (s)              21.792721931356937
Epoch Time (s)               83.60103556560352
Total Train Time (s)         32594.603281114716
Epoch                        400
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:51:35.149904 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #400 | Epoch Duration: 85.37418055534363
2020-01-11 09:51:35.150025 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #400 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.019555544
Z variance train             0.0040806746
KL Divergence                11.503165
KL Loss                      1.1503166
QF Loss                      91.43132
VF Loss                      82.494255
Policy Loss                  -1596.8832
Q Predictions Mean           1594.3378
Q Predictions Std            137.64142
Q Predictions Max            1726.8728
Q Predictions Min            503.93164
V Predictions Mean           1600.7451
V Predictions Std            136.65097
V Predictions Max            1730.1764
V Predictions Min            502.01895
Log Pis Mean                 -0.5797672
Log Pis Std                  1.8614651
Log Pis Max                  8.731564
Log Pis Min                  -5.295706
Policy mu Mean               -0.04670352
Policy mu Std                0.82338816
Policy mu Max                1.9700998
Policy mu Min                -3.1362293
Policy log std Mean          -0.41933092
Policy log std Std           0.14794248
Policy log std Max           -0.082303226
Policy log std Min           -0.9620409
Z mean eval                  0.036667813
Z variance eval              0.004473659
total_rewards                [3306.11722012 2615.18152668 2774.87043447 3289.79391824 1825.50126829
 1108.60251225 3327.64351269 3243.32735101  690.59696926 2447.34742097]
total_rewards_mean           2462.8982133979785
total_rewards_std            908.5059705138043
total_rewards_max            3327.643512691818
total_rewards_min            690.5969692622226
Number of train steps total  402000
Number of env steps total    2012000
Number of rollouts total     0
Train Time (s)               44.42399117490277
(Previous) Eval Time (s)     19.828015092760324
Sample Time (s)              21.849277175497264
Epoch Time (s)               86.10128344316036
Total Train Time (s)         32683.86976518482
Epoch                        401
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:53:04.420271 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #401 | Epoch Duration: 89.27013731002808
2020-01-11 09:53:04.420452 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #401 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.036778543
Z variance train             0.004471118
KL Divergence                11.220928
KL Loss                      1.1220928
QF Loss                      56.099693
VF Loss                      35.07785
Policy Loss                  -1595.767
Q Predictions Mean           1594.4912
Q Predictions Std            150.68236
Q Predictions Max            1764.4332
Q Predictions Min            334.2847
V Predictions Mean           1595.8585
V Predictions Std            151.65633
V Predictions Max            1766.7838
V Predictions Min            311.25632
Log Pis Mean                 -0.60848844
Log Pis Std                  1.9531544
Log Pis Max                  9.369238
Log Pis Min                  -6.2616553
Policy mu Mean               -0.005264183
Policy mu Std                0.8345723
Policy mu Max                1.8127494
Policy mu Min                -3.278984
Policy log std Mean          -0.42473063
Policy log std Std           0.16296995
Policy log std Max           -0.06620884
Policy log std Min           -1.2119961
Z mean eval                  0.027873537
Z variance eval              0.004623713
total_rewards                [1214.30489611 1270.3790273  1607.50290539  922.68678051 2158.88227989
 1321.28693202 1321.97432565  878.31769016 1560.91562664 1837.8931397 ]
total_rewards_mean           1409.4143603367222
total_rewards_std            374.06765061408447
total_rewards_max            2158.8822798900137
total_rewards_min            878.3176901648312
Number of train steps total  403000
Number of env steps total    2017000
Number of rollouts total     0
Train Time (s)               44.44942449871451
(Previous) Eval Time (s)     22.996610771864653
Sample Time (s)              22.268480900209397
Epoch Time (s)               89.71451617078856
Total Train Time (s)         32764.232915828936
Epoch                        402
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:54:24.786164 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #402 | Epoch Duration: 80.36558365821838
2020-01-11 09:54:24.786296 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #402 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028510774
Z variance train             0.0046254224
KL Divergence                11.007957
KL Loss                      1.1007957
QF Loss                      57.28871
VF Loss                      62.372128
Policy Loss                  -1582.3027
Q Predictions Mean           1581.0822
Q Predictions Std            183.41765
Q Predictions Max            1739.6937
Q Predictions Min            491.95514
V Predictions Mean           1579.3469
V Predictions Std            181.39944
V Predictions Max            1741.9078
V Predictions Min            505.82977
Log Pis Mean                 -0.45537788
Log Pis Std                  1.9446499
Log Pis Max                  7.238984
Log Pis Min                  -4.383488
Policy mu Mean               -0.012465748
Policy mu Std                0.8365931
Policy mu Max                2.1574872
Policy mu Min                -3.3943353
Policy log std Mean          -0.41444626
Policy log std Std           0.14754072
Policy log std Max           -0.05098912
Policy log std Min           -1.0516797
Z mean eval                  0.059936155
Z variance eval              0.0042701485
total_rewards                [1236.85012093 1567.0921174   822.62932232 3248.81704364 1554.64283144
  787.12906834 3186.21096372 2039.38359743 1234.0411331  1006.99508624]
total_rewards_mean           1668.3791284562842
total_rewards_std            852.445120618131
total_rewards_max            3248.8170436412847
total_rewards_min            787.1290683358266
Number of train steps total  404000
Number of env steps total    2022000
Number of rollouts total     0
Train Time (s)               43.70406606188044
(Previous) Eval Time (s)     13.647428926080465
Sample Time (s)              21.33023300766945
Epoch Time (s)               78.68172799563035
Total Train Time (s)         32844.2049535336
Epoch                        403
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:55:44.762053 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #403 | Epoch Duration: 79.97564363479614
2020-01-11 09:55:44.762230 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #403 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0596968
Z variance train             0.0042693526
KL Divergence                11.21712
KL Loss                      1.1217121
QF Loss                      68.90484
VF Loss                      19.75755
Policy Loss                  -1591.351
Q Predictions Mean           1589.2977
Q Predictions Std            150.05334
Q Predictions Max            1746.6686
Q Predictions Min            667.2879
V Predictions Mean           1592.0625
V Predictions Std            149.27634
V Predictions Max            1750.6586
V Predictions Min            687.72205
Log Pis Mean                 -0.6952343
Log Pis Std                  1.8116138
Log Pis Max                  6.3281183
Log Pis Min                  -5.0010834
Policy mu Mean               -0.03089193
Policy mu Std                0.8221202
Policy mu Max                1.8848207
Policy mu Min                -3.191041
Policy log std Mean          -0.41099486
Policy log std Std           0.1789388
Policy log std Max           0.18447697
Policy log std Min           -1.7070208
Z mean eval                  0.045780353
Z variance eval              0.004648667
total_rewards                [ 882.08823908 1616.5413738  1202.03705881 1010.55452245 3368.27568107
  971.2659616  1154.88939924 3344.96515975 1325.30535479 1062.8410165 ]
total_rewards_mean           1593.8763767107691
total_rewards_std            902.787104033141
total_rewards_max            3368.2756810736287
total_rewards_min            882.0882390752264
Number of train steps total  405000
Number of env steps total    2027000
Number of rollouts total     0
Train Time (s)               43.85655133193359
(Previous) Eval Time (s)     14.941091482993215
Sample Time (s)              21.493842666503042
Epoch Time (s)               80.29148548142985
Total Train Time (s)         32923.996626323555
Epoch                        404
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:57:04.558365 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #404 | Epoch Duration: 79.79592657089233
2020-01-11 09:57:04.558635 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #404 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046174645
Z variance train             0.0046465555
KL Divergence                11.08263
KL Loss                      1.108263
QF Loss                      80.80413
VF Loss                      85.64337
Policy Loss                  -1596.8245
Q Predictions Mean           1595.973
Q Predictions Std            151.52708
Q Predictions Max            1770.5875
Q Predictions Min            615.5908
V Predictions Mean           1597.186
V Predictions Std            149.0489
V Predictions Max            1762.4048
V Predictions Min            602.2928
Log Pis Mean                 -0.6490203
Log Pis Std                  1.7368915
Log Pis Max                  7.7811184
Log Pis Min                  -4.838678
Policy mu Mean               -0.024588572
Policy mu Std                0.7701395
Policy mu Max                2.0680416
Policy mu Min                -3.2753584
Policy log std Mean          -0.38430008
Policy log std Std           0.18485703
Policy log std Max           0.013963014
Policy log std Min           -1.327599
Z mean eval                  0.0491075
Z variance eval              0.004963823
total_rewards                [1402.08757287 1087.49747936 1013.67551548  982.94261994 1040.76470179
 2337.85862523 1306.10745238 2751.09916012 1341.44824302 3322.20487791]
total_rewards_mean           1658.5686248113466
total_rewards_std            793.3146767766219
total_rewards_max            3322.204877909343
total_rewards_min            982.942619942608
Number of train steps total  406000
Number of env steps total    2032000
Number of rollouts total     0
Train Time (s)               44.82578624319285
(Previous) Eval Time (s)     14.445264023728669
Sample Time (s)              19.95860836096108
Epoch Time (s)               79.2296586278826
Total Train Time (s)         33006.11909423722
Epoch                        405
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:58:26.684229 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #405 | Epoch Duration: 82.12542986869812
2020-01-11 09:58:26.684408 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #405 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048721053
Z variance train             0.0049568666
KL Divergence                10.878016
KL Loss                      1.0878017
QF Loss                      103.08352
VF Loss                      74.43802
Policy Loss                  -1591.7771
Q Predictions Mean           1591.9305
Q Predictions Std            115.769516
Q Predictions Max            1759.6969
Q Predictions Min            1271.8839
V Predictions Mean           1591.573
V Predictions Std            117.4644
V Predictions Max            1752.0065
V Predictions Min            1290.5702
Log Pis Mean                 -0.5745977
Log Pis Std                  1.7171882
Log Pis Max                  6.346272
Log Pis Min                  -4.5699944
Policy mu Mean               -0.012905885
Policy mu Std                0.76807135
Policy mu Max                1.6077695
Policy mu Min                -2.7443612
Policy log std Mean          -0.40550938
Policy log std Std           0.16745785
Policy log std Max           0.19012693
Policy log std Min           -1.2913088
Z mean eval                  0.025263513
Z variance eval              0.004585
total_rewards                [1038.02804411 1250.83131065 1322.61162652 1042.31379805 1332.52164229
 1032.35030792  827.47235404 1657.7279465  2794.82540258  813.54109329]
total_rewards_mean           1311.222352594596
total_rewards_std            550.6170942628942
total_rewards_max            2794.825402581638
total_rewards_min            813.541093293217
Number of train steps total  407000
Number of env steps total    2037000
Number of rollouts total     0
Train Time (s)               43.70531533891335
(Previous) Eval Time (s)     17.340778197161853
Sample Time (s)              20.819760993588716
Epoch Time (s)               81.86585452966392
Total Train Time (s)         33083.72113795485
Epoch                        406
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 09:59:44.289045 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #406 | Epoch Duration: 77.60441422462463
2020-01-11 09:59:44.289196 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #406 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025014248
Z variance train             0.0045805024
KL Divergence                11.098764
KL Loss                      1.1098765
QF Loss                      58.272633
VF Loss                      53.68545
Policy Loss                  -1581.7523
Q Predictions Mean           1582.6345
Q Predictions Std            184.0123
Q Predictions Max            1752.3634
Q Predictions Min            -18.65623
V Predictions Mean           1583.5459
V Predictions Std            183.45135
V Predictions Max            1749.9181
V Predictions Min            -37.924927
Log Pis Mean                 -0.8044244
Log Pis Std                  1.6054268
Log Pis Max                  6.611467
Log Pis Min                  -5.3727217
Policy mu Mean               0.05774051
Policy mu Std                0.71430016
Policy mu Max                2.0268798
Policy mu Min                -3.0357165
Policy log std Mean          -0.38128805
Policy log std Std           0.15238386
Policy log std Max           0.0851737
Policy log std Min           -1.1513546
Z mean eval                  0.020404741
Z variance eval              0.0039542047
total_rewards                [3339.85075021 3410.10904746 3445.51663985 1571.40853452 1027.93517304
 2032.7789219  1059.61456553 2491.26037776 3429.02698131 1856.96348961]
total_rewards_mean           2366.446448118172
total_rewards_std            940.6492508783352
total_rewards_max            3445.5166398452943
total_rewards_min            1027.9351730376554
Number of train steps total  408000
Number of env steps total    2042000
Number of rollouts total     0
Train Time (s)               44.216263202019036
(Previous) Eval Time (s)     13.079178046900779
Sample Time (s)              21.871654911432415
Epoch Time (s)               79.16709616035223
Total Train Time (s)         33172.88454333646
Epoch                        407
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:01:13.456006 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #407 | Epoch Duration: 89.16664242744446
2020-01-11 10:01:13.456193 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #407 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020373438
Z variance train             0.003953137
KL Divergence                11.437708
KL Loss                      1.1437708
QF Loss                      41.483543
VF Loss                      22.385668
Policy Loss                  -1597.6859
Q Predictions Mean           1596.6597
Q Predictions Std            144.91743
Q Predictions Max            1766.6725
Q Predictions Min            451.84985
V Predictions Mean           1594.8708
V Predictions Std            145.03032
V Predictions Max            1760.9363
V Predictions Min            447.8497
Log Pis Mean                 -0.6031505
Log Pis Std                  1.8660742
Log Pis Max                  10.7844095
Log Pis Min                  -4.8971896
Policy mu Mean               0.061777726
Policy mu Std                0.7765889
Policy mu Max                1.9528108
Policy mu Min                -3.1295543
Policy log std Mean          -0.40822005
Policy log std Std           0.16424647
Policy log std Max           0.00569582
Policy log std Min           -1.1840518
Z mean eval                  0.016694665
Z variance eval              0.004488242
total_rewards                [3300.25609916 2134.74946231 2631.62482141 1899.616996   2521.03483891
 2506.77389338 2187.35876355  987.91191084 1882.54761203 2244.97672725]
total_rewards_mean           2229.6851124846567
total_rewards_std            570.2480901990435
total_rewards_max            3300.2560991601877
total_rewards_min            987.9119108365325
Number of train steps total  409000
Number of env steps total    2047000
Number of rollouts total     0
Train Time (s)               44.52024574205279
(Previous) Eval Time (s)     23.078484694007784
Sample Time (s)              22.135430924594402
Epoch Time (s)               89.73416136065498
Total Train Time (s)         33260.895247299224
Epoch                        408
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:02:41.469276 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #408 | Epoch Duration: 88.01296401023865
2020-01-11 10:02:41.469400 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #408 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017403819
Z variance train             0.0044914745
KL Divergence                11.226816
KL Loss                      1.1226816
QF Loss                      96.31591
VF Loss                      96.18205
Policy Loss                  -1591.6344
Q Predictions Mean           1589.2524
Q Predictions Std            138.13144
Q Predictions Max            1772.221
Q Predictions Min            843.672
V Predictions Mean           1586.8599
V Predictions Std            135.02504
V Predictions Max            1771.8573
V Predictions Min            915.27985
Log Pis Mean                 -0.60152805
Log Pis Std                  2.051593
Log Pis Max                  17.470154
Log Pis Min                  -4.254171
Policy mu Mean               -0.0312527
Policy mu Std                0.7946091
Policy mu Max                6.0916715
Policy mu Min                -2.9380434
Policy log std Mean          -0.43034586
Policy log std Std           0.18469715
Policy log std Max           -0.019308507
Policy log std Min           -1.3159962
Z mean eval                  0.03654516
Z variance eval              0.004289997
total_rewards                [1317.63826447 2034.2688422  2518.48319073 3449.96418764 1053.68463478
 2302.98219622 1278.74211494 3431.75130106 1318.77701107 3423.31048289]
total_rewards_mean           2212.9602225979615
total_rewards_std            918.248631360824
total_rewards_max            3449.9641876444925
total_rewards_min            1053.6846347768699
Number of train steps total  410000
Number of env steps total    2052000
Number of rollouts total     0
Train Time (s)               43.66368260234594
(Previous) Eval Time (s)     21.357044871896505
Sample Time (s)              21.309025610797107
Epoch Time (s)               86.32975308503956
Total Train Time (s)         33345.237115043215
Epoch                        409
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:04:05.817054 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #409 | Epoch Duration: 84.34754180908203
2020-01-11 10:04:05.817231 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #409 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03726532
Z variance train             0.004289718
KL Divergence                11.252178
KL Loss                      1.1252178
QF Loss                      162.92867
VF Loss                      30.84566
Policy Loss                  -1613.7416
Q Predictions Mean           1615.1934
Q Predictions Std            130.13083
Q Predictions Max            1770.2314
Q Predictions Min            887.03455
V Predictions Mean           1617.3477
V Predictions Std            130.62064
V Predictions Max            1770.431
V Predictions Min            888.3679
Log Pis Mean                 -0.45927292
Log Pis Std                  1.7436233
Log Pis Max                  9.574704
Log Pis Min                  -4.076935
Policy mu Mean               -0.067217
Policy mu Std                0.80935884
Policy mu Max                2.0646832
Policy mu Min                -3.4432418
Policy log std Mean          -0.43365756
Policy log std Std           0.17261325
Policy log std Max           0.05938244
Policy log std Min           -1.8894175
Z mean eval                  0.028117204
Z variance eval              0.004556128
total_rewards                [3397.59302364 1437.25444354 2304.57086361 1700.00409187 3437.77037862
 1452.52470692 1698.19757919 2111.79841981 3440.07311379 1364.64177525]
total_rewards_mean           2234.442839623827
total_rewards_std            827.7114484681912
total_rewards_max            3440.073113785742
total_rewards_min            1364.6417752480038
Number of train steps total  411000
Number of env steps total    2057000
Number of rollouts total     0
Train Time (s)               44.514041516929865
(Previous) Eval Time (s)     19.37452652398497
Sample Time (s)              22.049870115239173
Epoch Time (s)               85.938438156154
Total Train Time (s)         33431.19002089882
Epoch                        410
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:05:31.774149 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #410 | Epoch Duration: 85.9567723274231
2020-01-11 10:05:31.774326 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #410 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028168729
Z variance train             0.004557061
KL Divergence                11.106297
KL Loss                      1.1106297
QF Loss                      54.90493
VF Loss                      37.814205
Policy Loss                  -1585.3577
Q Predictions Mean           1582.6884
Q Predictions Std            167.30971
Q Predictions Max            1741.3688
Q Predictions Min            457.27072
V Predictions Mean           1580.8564
V Predictions Std            164.6593
V Predictions Max            1741.4966
V Predictions Min            473.20566
Log Pis Mean                 -0.51236266
Log Pis Std                  1.9570614
Log Pis Max                  9.62731
Log Pis Min                  -6.262004
Policy mu Mean               0.0013535988
Policy mu Std                0.81030935
Policy mu Max                2.3442142
Policy mu Min                -3.407337
Policy log std Mean          -0.4316326
Policy log std Std           0.15703546
Policy log std Max           -0.005167693
Policy log std Min           -1.1865871
Z mean eval                  0.030692587
Z variance eval              0.0047499896
total_rewards                [3337.85661705 2794.16242234 1259.49950227 3364.41767331 3333.73360284
  162.38428625 3378.98123457 2941.11402481 2252.70213038  257.50283749]
total_rewards_mean           2308.235433130485
total_rewards_std            1221.6200902346213
total_rewards_max            3378.9812345716687
total_rewards_min            162.38428624563247
Number of train steps total  412000
Number of env steps total    2062000
Number of rollouts total     0
Train Time (s)               44.394464975222945
(Previous) Eval Time (s)     19.392593116965145
Sample Time (s)              19.922708219382912
Epoch Time (s)               83.709766311571
Total Train Time (s)         33517.998010479845
Epoch                        411
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:06:58.590420 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #411 | Epoch Duration: 86.81593346595764
2020-01-11 10:06:58.590670 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #411 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030715942
Z variance train             0.0047515086
KL Divergence                11.039928
KL Loss                      1.1039928
QF Loss                      92.04673
VF Loss                      134.64557
Policy Loss                  -1598.9081
Q Predictions Mean           1598.8472
Q Predictions Std            143.25525
Q Predictions Max            1779.789
Q Predictions Min            887.9675
V Predictions Mean           1596.6798
V Predictions Std            144.3177
V Predictions Max            1775.2887
V Predictions Min            826.7734
Log Pis Mean                 -0.46164948
Log Pis Std                  1.7603521
Log Pis Max                  8.032549
Log Pis Min                  -4.5693254
Policy mu Mean               0.09387618
Policy mu Std                0.81727314
Policy mu Max                2.2706065
Policy mu Min                -3.2034235
Policy log std Mean          -0.43801665
Policy log std Std           0.17464265
Policy log std Max           -0.047109693
Policy log std Min           -1.1750313
Z mean eval                  0.040632047
Z variance eval              0.00457923
total_rewards                [1325.62287061 3002.42695453 3414.45125048 2904.74020252 3230.16186108
 1413.91028592 1345.71973448 1075.97401539 1041.7861485  3414.2711387 ]
total_rewards_mean           2216.906446221545
total_rewards_std            993.2487152878663
total_rewards_max            3414.4512504848544
total_rewards_min            1041.7861485014575
Number of train steps total  413000
Number of env steps total    2067000
Number of rollouts total     0
Train Time (s)               44.09549510432407
(Previous) Eval Time (s)     22.498523585963994
Sample Time (s)              21.94700916018337
Epoch Time (s)               88.54102785047144
Total Train Time (s)         33605.01668032771
Epoch                        412
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:08:25.612249 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #412 | Epoch Duration: 87.02141094207764
2020-01-11 10:08:25.612372 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #412 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04170108
Z variance train             0.0045724222
KL Divergence                11.01188
KL Loss                      1.1011881
QF Loss                      339.13422
VF Loss                      343.0679
Policy Loss                  -1605.9452
Q Predictions Mean           1606.3369
Q Predictions Std            159.82904
Q Predictions Max            1776.457
Q Predictions Min            177.9054
V Predictions Mean           1595.3252
V Predictions Std            162.14554
V Predictions Max            1775.2816
V Predictions Min            140.46284
Log Pis Mean                 -0.619273
Log Pis Std                  1.8414258
Log Pis Max                  6.5182176
Log Pis Min                  -4.175502
Policy mu Mean               -0.011328106
Policy mu Std                0.78494865
Policy mu Max                2.229261
Policy mu Min                -3.1564486
Policy log std Mean          -0.42283726
Policy log std Std           0.17168625
Policy log std Max           -0.034901828
Policy log std Min           -1.1264278
Z mean eval                  0.025383497
Z variance eval              0.0049944995
total_rewards                [3416.28306919 3427.65190276 3398.35313834 1026.50058477 3410.84610384
 2771.61122093 1006.3649221  3450.18510507 1876.72049846 3372.40702325]
total_rewards_mean           2715.6923568699194
total_rewards_std            969.5309064994068
total_rewards_max            3450.1851050657287
total_rewards_min            1006.3649221028347
Number of train steps total  414000
Number of env steps total    2072000
Number of rollouts total     0
Train Time (s)               43.707261573988944
(Previous) Eval Time (s)     20.97865751804784
Sample Time (s)              22.049426056910306
Epoch Time (s)               86.73534514894709
Total Train Time (s)         33697.30685824016
Epoch                        413
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:09:57.905325 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #413 | Epoch Duration: 92.29283094406128
2020-01-11 10:09:57.905452 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #413 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025285404
Z variance train             0.004993367
KL Divergence                10.772072
KL Loss                      1.0772072
QF Loss                      57.866295
VF Loss                      56.159363
Policy Loss                  -1602.0059
Q Predictions Mean           1602.729
Q Predictions Std            140.36406
Q Predictions Max            1770.2067
Q Predictions Min            730.8027
V Predictions Mean           1601.0046
V Predictions Std            140.73152
V Predictions Max            1774.5011
V Predictions Min            732.6645
Log Pis Mean                 -0.7255064
Log Pis Std                  1.6403565
Log Pis Max                  5.302866
Log Pis Min                  -4.745646
Policy mu Mean               0.007553021
Policy mu Std                0.734692
Policy mu Max                1.8768035
Policy mu Min                -2.8947158
Policy log std Mean          -0.41241574
Policy log std Std           0.16164042
Policy log std Max           -0.0063180327
Policy log std Min           -1.0568717
Z mean eval                  0.02089102
Z variance eval              0.005191033
total_rewards                [1863.38794665 1488.6374344  3429.79079048  214.09493762 2111.95728961
  968.06409938 3174.74579645 1249.70673239 2130.65565961  992.06968681]
total_rewards_mean           1762.3110373405755
total_rewards_std            948.806667466418
total_rewards_max            3429.790790477138
total_rewards_min            214.09493762178533
Number of train steps total  415000
Number of env steps total    2077000
Number of rollouts total     0
Train Time (s)               43.820963468868285
(Previous) Eval Time (s)     26.535887914709747
Sample Time (s)              21.335630847141147
Epoch Time (s)               91.69248223071918
Total Train Time (s)         33779.21077685477
Epoch                        414
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:11:19.815027 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #414 | Epoch Duration: 81.90948104858398
2020-01-11 10:11:19.815163 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #414 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.020821359
Z variance train             0.0051883557
KL Divergence                10.691193
KL Loss                      1.0691193
QF Loss                      106.786316
VF Loss                      25.456488
Policy Loss                  -1585.4181
Q Predictions Mean           1586.7615
Q Predictions Std            138.03758
Q Predictions Max            1755.9775
Q Predictions Min            921.45166
V Predictions Mean           1584.8492
V Predictions Std            136.9133
V Predictions Max            1757.0474
V Predictions Min            930.1926
Log Pis Mean                 -0.56413877
Log Pis Std                  1.7798759
Log Pis Max                  7.4764886
Log Pis Min                  -3.9663205
Policy mu Mean               -0.042111054
Policy mu Std                0.778972
Policy mu Max                2.1743755
Policy mu Min                -3.1807425
Policy log std Mean          -0.42987022
Policy log std Std           0.18034427
Policy log std Max           0.0082782805
Policy log std Min           -1.2505882
Z mean eval                  0.010901123
Z variance eval              0.005262171
total_rewards                [1148.62816435 1022.7584073  2862.29981065 3393.7628378  1085.56077603
 2305.60768246 1968.35850542  984.03202389 3324.48947522 2050.0642471 ]
total_rewards_mean           2014.556193021718
total_rewards_std            899.0783157400377
total_rewards_max            3393.762837797845
total_rewards_min            984.0320238884048
Number of train steps total  416000
Number of env steps total    2082000
Number of rollouts total     0
Train Time (s)               44.00342003023252
(Previous) Eval Time (s)     16.75262748496607
Sample Time (s)              22.059208745136857
Epoch Time (s)               82.81525626033545
Total Train Time (s)         33864.99655889394
Epoch                        415
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:12:45.603745 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #415 | Epoch Duration: 85.7884750366211
2020-01-11 10:12:45.603868 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #415 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.010834925
Z variance train             0.00526198
KL Divergence                10.642378
KL Loss                      1.0642378
QF Loss                      69.78224
VF Loss                      30.273838
Policy Loss                  -1601.0483
Q Predictions Mean           1602.6421
Q Predictions Std            163.99011
Q Predictions Max            1777.9135
Q Predictions Min            328.34488
V Predictions Mean           1598.0406
V Predictions Std            164.21
V Predictions Max            1770.6221
V Predictions Min            325.31204
Log Pis Mean                 -0.7104558
Log Pis Std                  1.7519795
Log Pis Max                  5.7689853
Log Pis Min                  -6.619829
Policy mu Mean               -0.0038391042
Policy mu Std                0.757129
Policy mu Max                2.1362824
Policy mu Min                -3.2266772
Policy log std Mean          -0.4057369
Policy log std Std           0.15614094
Policy log std Max           -0.072677895
Policy log std Min           -1.0822009
Z mean eval                  0.032213707
Z variance eval              0.006158604
total_rewards                [1859.33040394 1930.55503238 1898.70275525 2939.37975304 2928.58802763
 2120.02964376 3417.23208488 3393.82425008 3414.83521303 2940.20766956]
total_rewards_mean           2684.2684833557805
total_rewards_std            628.3945593941586
total_rewards_max            3417.2320848791205
total_rewards_min            1859.3304039447812
Number of train steps total  417000
Number of env steps total    2087000
Number of rollouts total     0
Train Time (s)               44.92625656770542
(Previous) Eval Time (s)     19.72558824205771
Sample Time (s)              21.99207156850025
Epoch Time (s)               86.64391637826338
Total Train Time (s)         33954.296445443295
Epoch                        416
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:14:14.908330 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #416 | Epoch Duration: 89.30435419082642
2020-01-11 10:14:14.908510 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #416 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032392897
Z variance train             0.006157639
KL Divergence                10.285584
KL Loss                      1.0285585
QF Loss                      83.00711
VF Loss                      31.044632
Policy Loss                  -1561.7244
Q Predictions Mean           1562.5422
Q Predictions Std            190.50854
Q Predictions Max            1753.7457
Q Predictions Min            113.82708
V Predictions Mean           1558.9032
V Predictions Std            193.2283
V Predictions Max            1749.7565
V Predictions Min            -8.229139
Log Pis Mean                 -0.82201517
Log Pis Std                  1.6782593
Log Pis Max                  7.3866315
Log Pis Min                  -6.118288
Policy mu Mean               0.0020271812
Policy mu Std                0.72997534
Policy mu Max                2.3185546
Policy mu Min                -3.0228617
Policy log std Mean          -0.3991692
Policy log std Std           0.15885164
Policy log std Max           0.06456584
Policy log std Min           -1.2272319
Z mean eval                  0.048802875
Z variance eval              0.005862237
total_rewards                [3410.95350885 1779.41781386 3370.98923794  993.9799548  1466.41072537
  975.04196932 1519.50172197 1739.81092041 3180.79456945 3424.38558187]
total_rewards_mean           2186.128600384088
total_rewards_std            981.9205212309656
total_rewards_max            3424.3855818682937
total_rewards_min            975.0419693178862
Number of train steps total  418000
Number of env steps total    2092000
Number of rollouts total     0
Train Time (s)               44.652648696210235
(Previous) Eval Time (s)     22.38578214403242
Sample Time (s)              21.7036827839911
Epoch Time (s)               88.74211362423375
Total Train Time (s)         34042.24182308279
Epoch                        417
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:15:42.857801 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #417 | Epoch Duration: 87.9491560459137
2020-01-11 10:15:42.857972 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #417 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.048504267
Z variance train             0.0058672205
KL Divergence                10.384885
KL Loss                      1.0384885
QF Loss                      44.35047
VF Loss                      20.977325
Policy Loss                  -1592.7501
Q Predictions Mean           1591.4253
Q Predictions Std            163.71191
Q Predictions Max            1743.146
Q Predictions Min            435.46912
V Predictions Mean           1592.2838
V Predictions Std            165.06071
V Predictions Max            1750.3251
V Predictions Min            427.48013
Log Pis Mean                 -0.63800037
Log Pis Std                  1.7849765
Log Pis Max                  4.9391303
Log Pis Min                  -4.8314533
Policy mu Mean               0.027184011
Policy mu Std                0.75329983
Policy mu Max                2.2092245
Policy mu Min                -2.1485975
Policy log std Mean          -0.42819557
Policy log std Std           0.17483515
Policy log std Max           -0.07482353
Policy log std Min           -1.8971288
Z mean eval                  0.018744558
Z variance eval              0.0059148306
total_rewards                [3392.72473347 3380.47531105 1529.36674009 1142.01795096  976.45208126
 3291.11537685 1623.30740217 1304.00441878 1478.37668016 2722.7119095 ]
total_rewards_mean           2084.055260428666
total_rewards_std            941.6851954863286
total_rewards_max            3392.7247334722347
total_rewards_min            976.4520812621316
Number of train steps total  419000
Number of env steps total    2097000
Number of rollouts total     0
Train Time (s)               44.43624848732725
(Previous) Eval Time (s)     21.59257356170565
Sample Time (s)              21.940329589881003
Epoch Time (s)               87.9691516389139
Total Train Time (s)         34129.3310555974
Epoch                        418
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:17:09.949033 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #418 | Epoch Duration: 87.09094047546387
2020-01-11 10:17:09.949157 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #418 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018991493
Z variance train             0.005925267
KL Divergence                10.358462
KL Loss                      1.0358462
QF Loss                      57.551476
VF Loss                      92.26728
Policy Loss                  -1624.6987
Q Predictions Mean           1624.1703
Q Predictions Std            124.62468
Q Predictions Max            1764.3796
Q Predictions Min            934.8316
V Predictions Mean           1619.7096
V Predictions Std            123.0347
V Predictions Max            1761.009
V Predictions Min            921.4779
Log Pis Mean                 -0.6422279
Log Pis Std                  1.6841868
Log Pis Max                  6.8869934
Log Pis Min                  -5.4149933
Policy mu Mean               0.019720403
Policy mu Std                0.7569996
Policy mu Max                1.7172209
Policy mu Min                -3.0191615
Policy log std Mean          -0.40653896
Policy log std Std           0.16392137
Policy log std Max           0.0053376257
Policy log std Min           -1.3676419
Z mean eval                  0.03719402
Z variance eval              0.0057175467
total_rewards                [1540.53272546 3430.63840917 1059.45771482 1004.67280145 3103.69224463
  999.20147105 1583.3616653  3334.23102492 1495.3575507  1023.64427216]
total_rewards_mean           1857.4789879671068
total_rewards_std            964.9579665963802
total_rewards_max            3430.638409173693
total_rewards_min            999.2014710497049
Number of train steps total  420000
Number of env steps total    2102000
Number of rollouts total     0
Train Time (s)               43.65261345356703
(Previous) Eval Time (s)     20.714115587063134
Sample Time (s)              23.0869585480541
Epoch Time (s)               87.45368758868426
Total Train Time (s)         34214.09800397279
Epoch                        419
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:18:34.718685 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #419 | Epoch Duration: 84.76943254470825
2020-01-11 10:18:34.718817 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #419 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.037079204
Z variance train             0.0057207732
KL Divergence                10.4868555
KL Loss                      1.0486856
QF Loss                      107.98298
VF Loss                      153.58162
Policy Loss                  -1595.3497
Q Predictions Mean           1593.6018
Q Predictions Std            162.32579
Q Predictions Max            1763.1135
Q Predictions Min            340.8334
V Predictions Mean           1590.522
V Predictions Std            161.88603
V Predictions Max            1752.4001
V Predictions Min            370.89273
Log Pis Mean                 -0.5629088
Log Pis Std                  1.7569321
Log Pis Max                  9.484291
Log Pis Min                  -4.681893
Policy mu Mean               -0.05406201
Policy mu Std                0.8051263
Policy mu Max                2.1718402
Policy mu Min                -3.2243247
Policy log std Mean          -0.42981967
Policy log std Std           0.16625118
Policy log std Max           0.014373779
Policy log std Min           -1.1692228
Z mean eval                  0.045706023
Z variance eval              0.0049371766
total_rewards                [3323.06500417 3382.87374747 3372.30251062 3334.209628    195.26967512
 3383.11693235 3301.2718218  3373.08760688 3300.35572104 3292.42813441]
total_rewards_mean           3025.7980781861115
total_rewards_std            944.1181470044937
total_rewards_max            3383.1169323496456
total_rewards_min            195.2696751198628
Number of train steps total  421000
Number of env steps total    2107000
Number of rollouts total     0
Train Time (s)               45.27690525026992
(Previous) Eval Time (s)     18.029610578902066
Sample Time (s)              21.930998436175287
Epoch Time (s)               85.23751426534727
Total Train Time (s)         34311.53843258694
Epoch                        420
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:20:12.162127 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #420 | Epoch Duration: 97.44321537017822
2020-01-11 10:20:12.162249 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #420 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.046046287
Z variance train             0.0049349144
KL Divergence                10.876612
KL Loss                      1.0876611
QF Loss                      413.22632
VF Loss                      388.5256
Policy Loss                  -1622.8385
Q Predictions Mean           1623.5269
Q Predictions Std            108.48547
Q Predictions Max            1764.0597
Q Predictions Min            1185.1873
V Predictions Mean           1621.3525
V Predictions Std            102.727745
V Predictions Max            1760.4323
V Predictions Min            1234.2627
Log Pis Mean                 -0.6166121
Log Pis Std                  2.3589394
Log Pis Max                  10.310904
Log Pis Min                  -6.5778866
Policy mu Mean               -0.02889107
Policy mu Std                0.83827156
Policy mu Max                2.187685
Policy mu Min                -3.460463
Policy log std Mean          -0.39613524
Policy log std Std           0.15938178
Policy log std Max           -0.044918478
Policy log std Min           -1.0425658
Z mean eval                  0.064903036
Z variance eval              0.005142391
total_rewards                [1532.8432983  1070.87412016 1763.22046384 1070.74711373 1184.78510246
  984.85462565  864.42895184 3420.4542509  2739.1261582  1012.29393457]
total_rewards_mean           1564.36280196596
total_rewards_std            814.0925113761175
total_rewards_max            3420.4542509035778
total_rewards_min            864.4289518445262
Number of train steps total  422000
Number of env steps total    2112000
Number of rollouts total     0
Train Time (s)               44.25772107997909
(Previous) Eval Time (s)     30.235086511820555
Sample Time (s)              21.81770514138043
Epoch Time (s)               96.31051273318008
Total Train Time (s)         34392.92920529237
Epoch                        421
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:21:33.555435 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #421 | Epoch Duration: 81.39309549331665
2020-01-11 10:21:33.555554 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #421 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06271132
Z variance train             0.005129234
KL Divergence                10.739638
KL Loss                      1.0739639
QF Loss                      209.40823
VF Loss                      111.48163
Policy Loss                  -1598.8533
Q Predictions Mean           1605.8944
Q Predictions Std            150.76033
Q Predictions Max            1750.8589
Q Predictions Min            706.3663
V Predictions Mean           1598.1436
V Predictions Std            149.66055
V Predictions Max            1744.068
V Predictions Min            684.7065
Log Pis Mean                 -0.36794126
Log Pis Std                  1.9499289
Log Pis Max                  9.829863
Log Pis Min                  -4.977973
Policy mu Mean               0.024303058
Policy mu Std                0.84369206
Policy mu Max                2.7546904
Policy mu Min                -3.2508779
Policy log std Mean          -0.45625305
Policy log std Std           0.20130521
Policy log std Max           0.024656862
Policy log std Min           -1.6531074
Z mean eval                  0.039798718
Z variance eval              0.0054273154
total_rewards                [2586.0569912  2603.21876941  851.43266762 1242.4792175  3330.90836086
  966.81583426 3159.20367141 1721.11835965  986.17493111 3327.15154641]
total_rewards_mean           2077.456034944934
total_rewards_std            979.2789778237062
total_rewards_max            3330.9083608631972
total_rewards_min            851.4326676199286
Number of train steps total  423000
Number of env steps total    2117000
Number of rollouts total     0
Train Time (s)               44.103894896805286
(Previous) Eval Time (s)     15.317425206303596
Sample Time (s)              21.721309169195592
Epoch Time (s)               81.14262927230448
Total Train Time (s)         34479.609833678696
Epoch                        422
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:23:00.241750 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #422 | Epoch Duration: 86.68610405921936
2020-01-11 10:23:00.241874 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #422 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039777223
Z variance train             0.0054323096
KL Divergence                10.588204
KL Loss                      1.0588205
QF Loss                      47.982944
VF Loss                      55.71228
Policy Loss                  -1610.8401
Q Predictions Mean           1609.9966
Q Predictions Std            137.24483
Q Predictions Max            1765.2556
Q Predictions Min            876.4627
V Predictions Mean           1607.8137
V Predictions Std            138.31104
V Predictions Max            1758.9109
V Predictions Min            856.1678
Log Pis Mean                 -0.6534684
Log Pis Std                  1.7476176
Log Pis Max                  5.8929257
Log Pis Min                  -4.5433674
Policy mu Mean               -0.075230084
Policy mu Std                0.76970404
Policy mu Max                1.7870693
Policy mu Min                -3.2223153
Policy log std Mean          -0.3933958
Policy log std Std           0.1675179
Policy log std Max           0.03903839
Policy log std Min           -1.2199308
Z mean eval                  0.020855092
Z variance eval              0.0064779907
total_rewards                [2705.9284131  2518.6893324  3422.01107431 2955.82809504  963.11972439
 3204.81330834 3373.77423827 3351.16448359  926.92945197  940.18761474]
total_rewards_mean           2436.2445736149557
total_rewards_std            1015.5925726862155
total_rewards_max            3422.011074309905
total_rewards_min            926.9294519727679
Number of train steps total  424000
Number of env steps total    2122000
Number of rollouts total     0
Train Time (s)               44.75283586094156
(Previous) Eval Time (s)     20.860650508198887
Sample Time (s)              22.1466554091312
Epoch Time (s)               87.76014177827165
Total Train Time (s)         34570.47340590088
Epoch                        423
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:24:31.111846 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #423 | Epoch Duration: 90.86988162994385
2020-01-11 10:24:31.111975 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #423 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021538332
Z variance train             0.006479801
KL Divergence                10.138121
KL Loss                      1.0138121
QF Loss                      159.17307
VF Loss                      67.47805
Policy Loss                  -1599.8583
Q Predictions Mean           1601.2655
Q Predictions Std            138.53351
Q Predictions Max            1785.1565
Q Predictions Min            708.0457
V Predictions Mean           1593.7184
V Predictions Std            138.2164
V Predictions Max            1774.7555
V Predictions Min            707.87134
Log Pis Mean                 -0.76276565
Log Pis Std                  1.678355
Log Pis Max                  10.121363
Log Pis Min                  -4.615576
Policy mu Mean               -0.06854699
Policy mu Std                0.7834798
Policy mu Max                1.9511886
Policy mu Min                -3.5373213
Policy log std Mean          -0.42415467
Policy log std Std           0.18639688
Policy log std Max           -0.00910458
Policy log std Min           -1.4267193
Z mean eval                  0.05299849
Z variance eval              0.005476638
total_rewards                [3402.59933854 2058.23475053 1014.78393915 3421.09793592 1002.65755276
 3408.40653709 1040.2701065  3373.96611121 1317.86497945 3391.19472224]
total_rewards_mean           2343.107597338735
total_rewards_std            1094.1441496722
total_rewards_max            3421.0979359183666
total_rewards_min            1002.657552763286
Number of train steps total  425000
Number of env steps total    2127000
Number of rollouts total     0
Train Time (s)               44.128924182616174
(Previous) Eval Time (s)     23.970138983801007
Sample Time (s)              21.789212381932884
Epoch Time (s)               89.88827554835007
Total Train Time (s)         34656.55666887853
Epoch                        424
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:25:57.204723 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #424 | Epoch Duration: 86.09259963035583
2020-01-11 10:25:57.205029 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #424 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.052982964
Z variance train             0.005468615
KL Divergence                10.598629
KL Loss                      1.059863
QF Loss                      315.86044
VF Loss                      139.0233
Policy Loss                  -1585.5432
Q Predictions Mean           1593.8064
Q Predictions Std            185.6676
Q Predictions Max            1785.0992
Q Predictions Min            0.95872295
V Predictions Mean           1582.0728
V Predictions Std            185.1784
V Predictions Max            1787.264
V Predictions Min            -0.7358458
Log Pis Mean                 -0.74169767
Log Pis Std                  1.7649686
Log Pis Max                  8.531136
Log Pis Min                  -4.8237543
Policy mu Mean               -0.055435125
Policy mu Std                0.71690124
Policy mu Max                2.411398
Policy mu Min                -3.1958675
Policy log std Mean          -0.40491545
Policy log std Std           0.16393173
Policy log std Max           -0.08412215
Policy log std Min           -1.1099111
Z mean eval                  0.0179339
Z variance eval              0.0053111985
total_rewards                [1240.40745998 3376.96258524 1018.1583209  3339.9019119  3340.53330176
 3414.95628687  981.6091961  3342.66029537 3363.90683782 3352.48877054]
total_rewards_mean           2677.1584966489436
total_rewards_std            1047.6342763720538
total_rewards_max            3414.956286872557
total_rewards_min            981.6091961037203
Number of train steps total  426000
Number of env steps total    2132000
Number of rollouts total     0
Train Time (s)               43.93067805003375
(Previous) Eval Time (s)     20.174190239049494
Sample Time (s)              21.70748033327982
Epoch Time (s)               85.81234862236306
Total Train Time (s)         34748.51248085592
Epoch                        425
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:27:29.164137 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #425 | Epoch Duration: 91.95889735221863
2020-01-11 10:27:29.164261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #425 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.01795488
Z variance train             0.0053164633
KL Divergence                10.645961
KL Loss                      1.064596
QF Loss                      68.26048
VF Loss                      57.821747
Policy Loss                  -1600.9614
Q Predictions Mean           1601.9453
Q Predictions Std            161.34557
Q Predictions Max            1758.4786
Q Predictions Min            493.3699
V Predictions Mean           1598.6865
V Predictions Std            161.05583
V Predictions Max            1753.7886
V Predictions Min            497.9421
Log Pis Mean                 -0.3411343
Log Pis Std                  2.0087042
Log Pis Max                  9.1412325
Log Pis Min                  -6.7617617
Policy mu Mean               -0.084391735
Policy mu Std                0.8812782
Policy mu Max                1.9804287
Policy mu Min                -3.3145347
Policy log std Mean          -0.45986763
Policy log std Std           0.19205222
Policy log std Max           -0.0841465
Policy log std Min           -1.3650331
Z mean eval                  0.041395936
Z variance eval              0.006292251
total_rewards                [ 820.61287704 1592.36824396 3070.56763944 3352.51466765 1440.6802247
 2266.01149326 1254.24821251  991.89402954 3338.47727875 1239.84767452]
total_rewards_mean           1936.7222341367328
total_rewards_std            939.0348747570995
total_rewards_max            3352.514667646256
total_rewards_min            820.6128770392561
Number of train steps total  427000
Number of env steps total    2137000
Number of rollouts total     0
Train Time (s)               44.70247075892985
(Previous) Eval Time (s)     26.32050161017105
Sample Time (s)              21.845119996462017
Epoch Time (s)               92.86809236556292
Total Train Time (s)         34834.07763751736
Epoch                        426
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:28:54.731461 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #426 | Epoch Duration: 85.56710481643677
2020-01-11 10:28:54.731579 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #426 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04149147
Z variance train             0.006286992
KL Divergence                10.276199
KL Loss                      1.02762
QF Loss                      113.105316
VF Loss                      60.534683
Policy Loss                  -1617.3156
Q Predictions Mean           1616.7434
Q Predictions Std            121.4078
Q Predictions Max            1764.5582
Q Predictions Min            1053.3938
V Predictions Mean           1618.4924
V Predictions Std            122.46463
V Predictions Max            1764.1505
V Predictions Min            1053.8705
Log Pis Mean                 -0.44005996
Log Pis Std                  1.9978248
Log Pis Max                  6.931865
Log Pis Min                  -5.912814
Policy mu Mean               -0.057485502
Policy mu Std                0.8378346
Policy mu Max                3.014869
Policy mu Min                -3.2992754
Policy log std Mean          -0.43498197
Policy log std Std           0.19213448
Policy log std Max           -0.031466335
Policy log std Min           -1.7977107
Z mean eval                  0.026760021
Z variance eval              0.005169266
total_rewards                [1264.24408751 2203.80052435 3386.35023366 1040.37637225 1946.62517151
 1017.05092993 3446.95879198 3350.56143507 3386.70295412 1024.71757265]
total_rewards_mean           2206.7388073016723
total_rewards_std            1037.2642444258897
total_rewards_max            3446.958791975509
total_rewards_min            1017.0509299330979
Number of train steps total  428000
Number of env steps total    2142000
Number of rollouts total     0
Train Time (s)               44.12428648909554
(Previous) Eval Time (s)     19.019253837876022
Sample Time (s)              22.17116096895188
Epoch Time (s)               85.31470129592344
Total Train Time (s)         34920.55805512797
Epoch                        427
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:30:21.217048 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #427 | Epoch Duration: 86.4853572845459
2020-01-11 10:30:21.217242 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #427 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02646998
Z variance train             0.005167483
KL Divergence                10.7358055
KL Loss                      1.0735806
QF Loss                      158.53326
VF Loss                      162.77887
Policy Loss                  -1591.8593
Q Predictions Mean           1594.7175
Q Predictions Std            129.30318
Q Predictions Max            1755.5442
Q Predictions Min            918.7906
V Predictions Mean           1582.7314
V Predictions Std            126.76602
V Predictions Max            1729.7234
V Predictions Min            926.8848
Log Pis Mean                 -0.5517511
Log Pis Std                  1.9886631
Log Pis Max                  7.9767003
Log Pis Min                  -4.612892
Policy mu Mean               -0.037086632
Policy mu Std                0.82305855
Policy mu Max                1.8772979
Policy mu Min                -3.3157556
Policy log std Mean          -0.40194497
Policy log std Std           0.16843387
Policy log std Max           -0.004427433
Policy log std Min           -1.016227
Z mean eval                  0.022647059
Z variance eval              0.004890357
total_rewards                [1865.53461815 3364.34876415 3118.22555863 3032.61558821 1888.9347878
 2350.50023659 3415.52867876 3029.08528865 1569.29303437 2008.48647167]
total_rewards_mean           2564.2553026983614
total_rewards_std            663.0170250660227
total_rewards_max            3415.5286787606647
total_rewards_min            1569.2930343701537
Number of train steps total  429000
Number of env steps total    2147000
Number of rollouts total     0
Train Time (s)               45.37784397462383
(Previous) Eval Time (s)     20.18963426211849
Sample Time (s)              22.065056156367064
Epoch Time (s)               87.63253439310938
Total Train Time (s)         35013.01158173755
Epoch                        428
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:31:53.674992 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #428 | Epoch Duration: 92.45759892463684
2020-01-11 10:31:53.675165 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #428 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02908602
Z variance train             0.0048726466
KL Divergence                11.012226
KL Loss                      1.1012226
QF Loss                      152.63423
VF Loss                      481.61853
Policy Loss                  -1585.1462
Q Predictions Mean           1584.1077
Q Predictions Std            145.85112
Q Predictions Max            1731.294
Q Predictions Min            783.71136
V Predictions Mean           1567.1375
V Predictions Std            144.83684
V Predictions Max            1720.9036
V Predictions Min            757.71655
Log Pis Mean                 -0.7919892
Log Pis Std                  1.6988844
Log Pis Max                  8.438897
Log Pis Min                  -4.0351906
Policy mu Mean               -0.05741197
Policy mu Std                0.7597566
Policy mu Max                1.8336898
Policy mu Min                -3.1565127
Policy log std Mean          -0.40681842
Policy log std Std           0.18902709
Policy log std Max           0.07659924
Policy log std Min           -1.1898354
Z mean eval                  0.028030839
Z variance eval              0.0042320197
total_rewards                [1588.56667865 3322.67672823 3350.69834103 2979.05336369 3378.62797876
 3314.54257202 1882.09583319 1748.8583918  3393.7288979  3373.43689224]
total_rewards_mean           2833.228567750698
total_rewards_std            727.5578366552892
total_rewards_max            3393.7288979035243
total_rewards_min            1588.566678649517
Number of train steps total  430000
Number of env steps total    2152000
Number of rollouts total     0
Train Time (s)               43.397168445866555
(Previous) Eval Time (s)     25.01445165090263
Sample Time (s)              21.70131302252412
Epoch Time (s)               90.1129331192933
Total Train Time (s)         35105.501206020825
Epoch                        429
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:33:26.170321 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #429 | Epoch Duration: 92.49501609802246
2020-01-11 10:33:26.170491 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #429 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027812203
Z variance train             0.004231902
KL Divergence                11.311183
KL Loss                      1.1311183
QF Loss                      478.3916
VF Loss                      45.529232
Policy Loss                  -1585.9713
Q Predictions Mean           1589.8278
Q Predictions Std            164.6814
Q Predictions Max            1763.3317
Q Predictions Min            440.77316
V Predictions Mean           1584.8518
V Predictions Std            164.35405
V Predictions Max            1758.5859
V Predictions Min            432.4623
Log Pis Mean                 -0.61042774
Log Pis Std                  1.9151314
Log Pis Max                  6.6569815
Log Pis Min                  -5.6042323
Policy mu Mean               -0.0030623376
Policy mu Std                0.8004616
Policy mu Max                2.3506043
Policy mu Min                -3.495625
Policy log std Mean          -0.4211681
Policy log std Std           0.19663131
Policy log std Max           -0.064290196
Policy log std Min           -1.8074926
Z mean eval                  0.07292004
Z variance eval              0.0044191494
total_rewards                [1120.68090462 1240.16603331 1428.53177771 1374.59955193  993.74649413
 1134.7497225   963.05989803  313.27388935  273.60615585 1859.53900303]
total_rewards_mean           1070.195343046774
total_rewards_std            458.75301438099586
total_rewards_max            1859.5390030321425
total_rewards_min            273.606155850245
Number of train steps total  431000
Number of env steps total    2157000
Number of rollouts total     0
Train Time (s)               44.34756094403565
(Previous) Eval Time (s)     27.39627779275179
Sample Time (s)              22.001143116969615
Epoch Time (s)               93.74498185375705
Total Train Time (s)         35183.129645798355
Epoch                        430
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:34:43.799552 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #430 | Epoch Duration: 77.62893295288086
2020-01-11 10:34:43.799685 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #430 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.07340163
Z variance train             0.0044134567
KL Divergence                11.349701
KL Loss                      1.1349701
QF Loss                      78.908554
VF Loss                      160.0292
Policy Loss                  -1602.7756
Q Predictions Mean           1599.6997
Q Predictions Std            168.43398
Q Predictions Max            1755.72
Q Predictions Min            -6.046746
V Predictions Mean           1592.7473
V Predictions Std            167.02849
V Predictions Max            1742.1038
V Predictions Min            7.175918
Log Pis Mean                 -0.49267036
Log Pis Std                  1.7879122
Log Pis Max                  6.438826
Log Pis Min                  -4.241744
Policy mu Mean               0.063560896
Policy mu Std                0.8400167
Policy mu Max                2.4049182
Policy mu Min                -3.2083526
Policy log std Mean          -0.4283689
Policy log std Std           0.17764989
Policy log std Max           -0.057553828
Policy log std Min           -1.2040215
Z mean eval                  0.034679122
Z variance eval              0.0040349015
total_rewards                [2000.59707287 1238.48418496 1556.67627607 3399.72093423 2594.51532084
 3375.68716677 2125.08839163 2489.01118077  873.49852709 2384.73383186]
total_rewards_mean           2203.8012887098894
total_rewards_std            789.8151705410232
total_rewards_max            3399.7209342261626
total_rewards_min            873.4985270946007
Number of train steps total  432000
Number of env steps total    2162000
Number of rollouts total     0
Train Time (s)               44.585199526976794
(Previous) Eval Time (s)     11.279985398985445
Sample Time (s)              21.802556219510734
Epoch Time (s)               77.66774114547297
Total Train Time (s)         35270.477105199825
Epoch                        431
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:36:11.150597 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #431 | Epoch Duration: 87.35081958770752
2020-01-11 10:36:11.150721 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #431 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035246886
Z variance train             0.00403869
KL Divergence                11.489667
KL Loss                      1.1489667
QF Loss                      98.39465
VF Loss                      31.850533
Policy Loss                  -1594.9419
Q Predictions Mean           1592.4453
Q Predictions Std            144.00429
Q Predictions Max            1756.0703
Q Predictions Min            509.86783
V Predictions Mean           1593.6135
V Predictions Std            143.26927
V Predictions Max            1764.428
V Predictions Min            529.5368
Log Pis Mean                 -0.86287314
Log Pis Std                  1.8306942
Log Pis Max                  7.2389283
Log Pis Min                  -4.2238774
Policy mu Mean               -0.015616392
Policy mu Std                0.74549663
Policy mu Max                2.296814
Policy mu Min                -3.2834272
Policy log std Mean          -0.42759213
Policy log std Std           0.19460128
Policy log std Max           -0.04695201
Policy log std Min           -1.3367208
Z mean eval                  0.0301067
Z variance eval              0.004188868
total_rewards                [ 958.74214801 2684.22974419  946.83242775  938.98858035  920.20008942
 3382.77395936 1217.81209759 2614.89386948 1134.46437965 2910.04151338]
total_rewards_mean           1770.8978809186563
total_rewards_std            943.8055486427497
total_rewards_max            3382.773959363513
total_rewards_min            920.2000894215172
Number of train steps total  433000
Number of env steps total    2167000
Number of rollouts total     0
Train Time (s)               44.11824107868597
(Previous) Eval Time (s)     20.962795304134488
Sample Time (s)              22.27293019928038
Epoch Time (s)               87.35396658210084
Total Train Time (s)         35354.55297765508
Epoch                        432
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:37:35.229741 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #432 | Epoch Duration: 84.07892799377441
2020-01-11 10:37:35.229869 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #432 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030456875
Z variance train             0.004200744
KL Divergence                11.527336
KL Loss                      1.1527337
QF Loss                      160.34027
VF Loss                      61.1077
Policy Loss                  -1616.1038
Q Predictions Mean           1618.8093
Q Predictions Std            141.64603
Q Predictions Max            1772.2987
Q Predictions Min            671.4707
V Predictions Mean           1616.792
V Predictions Std            141.89827
V Predictions Max            1772.7828
V Predictions Min            666.8741
Log Pis Mean                 -0.65349984
Log Pis Std                  1.8166771
Log Pis Max                  7.857119
Log Pis Min                  -4.223794
Policy mu Mean               -0.07229629
Policy mu Std                0.7565922
Policy mu Max                1.7659171
Policy mu Min                -3.2218444
Policy log std Mean          -0.4304436
Policy log std Std           0.16051707
Policy log std Max           -0.066343725
Policy log std Min           -1.2578695
Z mean eval                  0.028866103
Z variance eval              0.0057829646
total_rewards                [2854.70679826 1126.72792218  974.80964514 3444.0512371  3358.32257426
 3366.36138462 3396.22204269  957.99226157 3344.04998765 3357.68190144]
total_rewards_mean           2618.0925754915825
total_rewards_std            1058.5845755814232
total_rewards_max            3444.05123710182
total_rewards_min            957.992261570027
Number of train steps total  434000
Number of env steps total    2172000
Number of rollouts total     0
Train Time (s)               44.4672495117411
(Previous) Eval Time (s)     17.68750739796087
Sample Time (s)              21.902359307277948
Epoch Time (s)               84.05711621697992
Total Train Time (s)         35446.94788051024
Epoch                        433
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:39:07.629297 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #433 | Epoch Duration: 92.3993194103241
2020-01-11 10:39:07.629476 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #433 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028806046
Z variance train             0.0057719187
KL Divergence                10.938383
KL Loss                      1.0938383
QF Loss                      118.10965
VF Loss                      65.17627
Policy Loss                  -1580.1469
Q Predictions Mean           1579.4481
Q Predictions Std            172.86339
Q Predictions Max            1745.5673
Q Predictions Min            707.50256
V Predictions Mean           1580.5922
V Predictions Std            169.866
V Predictions Max            1739.6786
V Predictions Min            708.2436
Log Pis Mean                 -0.65882874
Log Pis Std                  1.908595
Log Pis Max                  8.15929
Log Pis Min                  -6.4155846
Policy mu Mean               -0.103749625
Policy mu Std                0.7823121
Policy mu Max                2.4791713
Policy mu Min                -3.0729501
Policy log std Mean          -0.43968132
Policy log std Std           0.1914089
Policy log std Max           0.035698563
Policy log std Min           -1.5135711
Z mean eval                  0.045296457
Z variance eval              0.0051886206
total_rewards                [3388.78797008 3120.77202362 3381.9119165  2685.04491389 1526.52982598
 1147.57064102 3338.49089463 3341.26444026 1108.99097365  985.6189364 ]
total_rewards_mean           2402.498253603503
total_rewards_std            1015.2834387954412
total_rewards_max            3388.787970082962
total_rewards_min            985.6189363997629
Number of train steps total  435000
Number of env steps total    2177000
Number of rollouts total     0
Train Time (s)               44.13703267881647
(Previous) Eval Time (s)     26.029467666056007
Sample Time (s)              21.8753508948721
Epoch Time (s)               92.04185123974457
Total Train Time (s)         35534.10752240522
Epoch                        434
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:40:34.795598 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #434 | Epoch Duration: 87.16590452194214
2020-01-11 10:40:34.795872 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #434 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045556813
Z variance train             0.0051903874
KL Divergence                10.974791
KL Loss                      1.0974791
QF Loss                      223.15178
VF Loss                      124.28986
Policy Loss                  -1601.2476
Q Predictions Mean           1604.8811
Q Predictions Std            126.399284
Q Predictions Max            1763.3307
Q Predictions Min            785.631
V Predictions Mean           1603.9758
V Predictions Std            127.7153
V Predictions Max            1764.4753
V Predictions Min            767.5661
Log Pis Mean                 -0.83741105
Log Pis Std                  1.6763242
Log Pis Max                  8.345573
Log Pis Min                  -4.7479277
Policy mu Mean               -0.047495198
Policy mu Std                0.70850307
Policy mu Max                2.1989772
Policy mu Min                -3.0294602
Policy log std Mean          -0.44152245
Policy log std Std           0.17083897
Policy log std Max           0.040799826
Policy log std Min           -1.2962646
Z mean eval                  0.02754276
Z variance eval              0.005251941
total_rewards                [1049.33055424 3425.16204721 1210.1146686  3400.76086059  960.28551807
 1927.09423973 3378.13403563 3405.87776927 3447.07082764 3365.87548677]
total_rewards_mean           2556.970600775895
total_rewards_std            1064.915188246552
total_rewards_max            3447.070827641458
total_rewards_min            960.2855180736648
Number of train steps total  436000
Number of env steps total    2182000
Number of rollouts total     0
Train Time (s)               43.87439854070544
(Previous) Eval Time (s)     21.153260773047805
Sample Time (s)              19.6073117996566
Epoch Time (s)               84.63497111340985
Total Train Time (s)         35622.565903522074
Epoch                        435
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:42:03.257692 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #435 | Epoch Duration: 88.46164464950562
2020-01-11 10:42:03.257830 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #435 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027203983
Z variance train             0.005246723
KL Divergence                10.755868
KL Loss                      1.0755868
QF Loss                      122.562065
VF Loss                      99.00402
Policy Loss                  -1589.2087
Q Predictions Mean           1590.0874
Q Predictions Std            159.54987
Q Predictions Max            1745.0353
Q Predictions Min            392.60788
V Predictions Mean           1591.692
V Predictions Std            157.85956
V Predictions Max            1742.5533
V Predictions Min            412.09406
Log Pis Mean                 -0.7465311
Log Pis Std                  1.7125965
Log Pis Max                  7.0907087
Log Pis Min                  -5.023163
Policy mu Mean               -0.055164695
Policy mu Std                0.7561592
Policy mu Max                2.079494
Policy mu Min                -3.3644593
Policy log std Mean          -0.40540138
Policy log std Std           0.1754967
Policy log std Max           0.11243048
Policy log std Min           -1.6316049
Z mean eval                  0.05563424
Z variance eval              0.006353197
total_rewards                [3378.48318513 3445.29332582 3363.26544072 3407.0722185  2677.21710431
 2749.37787326 3390.96680964 3393.06809917 1186.31284279 3383.08134038]
total_rewards_mean           3037.4138239715476
total_rewards_std            673.4818141039281
total_rewards_max            3445.293325820451
total_rewards_min            1186.3128427862773
Number of train steps total  437000
Number of env steps total    2187000
Number of rollouts total     0
Train Time (s)               43.74637300008908
(Previous) Eval Time (s)     24.97971588000655
Sample Time (s)              21.998125093989074
Epoch Time (s)               90.7242139740847
Total Train Time (s)         35717.64548318274
Epoch                        436
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:43:38.339935 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #436 | Epoch Duration: 95.08194851875305
2020-01-11 10:43:38.340138 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #436 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055627503
Z variance train             0.0063485056
KL Divergence                10.3560295
KL Loss                      1.0356029
QF Loss                      348.22836
VF Loss                      51.700935
Policy Loss                  -1576.1437
Q Predictions Mean           1572.9622
Q Predictions Std            166.21178
Q Predictions Max            1733.3201
Q Predictions Min            655.5037
V Predictions Mean           1576.1621
V Predictions Std            164.70517
V Predictions Max            1737.3168
V Predictions Min            658.39465
Log Pis Mean                 -0.7906088
Log Pis Std                  1.8998154
Log Pis Max                  8.677748
Log Pis Min                  -4.454563
Policy mu Mean               -0.1606816
Policy mu Std                0.7445372
Policy mu Max                2.7298484
Policy mu Min                -3.5234733
Policy log std Mean          -0.4148747
Policy log std Std           0.16796163
Policy log std Max           0.006165445
Policy log std Min           -1.1937356
Z mean eval                  0.04486929
Z variance eval              0.007007065
total_rewards                [2971.12824166 3522.42397504 3059.91215663 3390.8145747  3426.67402013
  959.87590743 1613.06114461 3476.12544495 3455.18096514 3394.9434557 ]
total_rewards_mean           2927.013988600159
total_rewards_std            850.5550077762033
total_rewards_max            3522.4239750439297
total_rewards_min            959.8759074259159
Number of train steps total  438000
Number of env steps total    2192000
Number of rollouts total     0
Train Time (s)               43.129139319993556
(Previous) Eval Time (s)     29.337198494933546
Sample Time (s)              22.108080366626382
Epoch Time (s)               94.57441818155348
Total Train Time (s)         35808.50159617048
Epoch                        437
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:45:09.200501 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #437 | Epoch Duration: 90.86023378372192
2020-01-11 10:45:09.200677 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #437 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04549117
Z variance train             0.0070205256
KL Divergence                10.180519
KL Loss                      1.018052
QF Loss                      190.99113
VF Loss                      211.06882
Policy Loss                  -1567.1757
Q Predictions Mean           1568.1936
Q Predictions Std            173.54037
Q Predictions Max            1739.111
Q Predictions Min            -19.80521
V Predictions Mean           1574.8203
V Predictions Std            168.17352
V Predictions Max            1749.509
V Predictions Min            168.47635
Log Pis Mean                 -0.5072488
Log Pis Std                  2.0270443
Log Pis Max                  8.40369
Log Pis Min                  -4.9919515
Policy mu Mean               -0.13080545
Policy mu Std                0.8164789
Policy mu Max                3.012078
Policy mu Min                -3.0928812
Policy log std Mean          -0.42919254
Policy log std Std           0.1913178
Policy log std Max           -0.010944009
Policy log std Min           -1.4859262
Z mean eval                  0.0333787
Z variance eval              0.006917719
total_rewards                [1181.07265773 3322.63435444 1321.71317984 1218.39958179 1305.9459099
 2153.28449676 1277.91622012 2675.30928502 1245.73950263  987.74497016]
total_rewards_mean           1668.97601583949
total_rewards_std            739.691222509332
total_rewards_max            3322.6343544383794
total_rewards_min            987.7449701649729
Number of train steps total  439000
Number of env steps total    2197000
Number of rollouts total     0
Train Time (s)               43.8600476142019
(Previous) Eval Time (s)     25.62275251187384
Sample Time (s)              21.928432940971106
Epoch Time (s)               91.41123306704685
Total Train Time (s)         35890.23677552771
Epoch                        438
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:46:30.938420 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #438 | Epoch Duration: 81.73761415481567
2020-01-11 10:46:30.938550 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #438 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03311942
Z variance train             0.006917756
KL Divergence                10.243927
KL Loss                      1.0243927
QF Loss                      287.24023
VF Loss                      89.81706
Policy Loss                  -1594.858
Q Predictions Mean           1595.0007
Q Predictions Std            134.3115
Q Predictions Max            1748.2089
Q Predictions Min            847.1162
V Predictions Mean           1597.942
V Predictions Std            134.10619
V Predictions Max            1748.7666
V Predictions Min            847.5306
Log Pis Mean                 -0.5899761
Log Pis Std                  1.7287846
Log Pis Max                  6.282351
Log Pis Min                  -4.1873364
Policy mu Mean               -0.115102656
Policy mu Std                0.777398
Policy mu Max                1.4196924
Policy mu Min                -2.8376687
Policy log std Mean          -0.4339246
Policy log std Std           0.19276568
Policy log std Max           0.04046002
Policy log std Min           -1.2855947
Z mean eval                  0.037672844
Z variance eval              0.005769494
total_rewards                [1003.92412498 3295.86534676 3334.39072222 1256.12229361 3314.86792222
 3307.04589714 2760.84774733 1813.19721603  872.61547631 3363.0459737 ]
total_rewards_mean           2432.1922720284388
total_rewards_std            1015.7463552906469
total_rewards_max            3363.045973698346
total_rewards_min            872.6154763050699
Number of train steps total  440000
Number of env steps total    2202000
Number of rollouts total     0
Train Time (s)               44.46432670112699
(Previous) Eval Time (s)     15.948871950153261
Sample Time (s)              21.886097877286375
Epoch Time (s)               82.29929652856663
Total Train Time (s)         35979.95494984556
Epoch                        439
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:48:00.662568 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #439 | Epoch Duration: 89.72390723228455
2020-01-11 10:48:00.662691 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #439 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03815579
Z variance train             0.0057310583
KL Divergence                10.554247
KL Loss                      1.0554247
QF Loss                      204.9299
VF Loss                      451.54742
Policy Loss                  -1611.6095
Q Predictions Mean           1605.8699
Q Predictions Std            116.97851
Q Predictions Max            1771.7684
Q Predictions Min            889.5424
V Predictions Mean           1600.0095
V Predictions Std            118.07458
V Predictions Max            1767.9131
V Predictions Min            854.89136
Log Pis Mean                 -0.76731205
Log Pis Std                  1.6595504
Log Pis Max                  6.8187203
Log Pis Min                  -7.093354
Policy mu Mean               -0.07944814
Policy mu Std                0.76358056
Policy mu Max                1.8191252
Policy mu Min                -3.3067844
Policy log std Mean          -0.409294
Policy log std Std           0.15135291
Policy log std Max           -0.00246346
Policy log std Min           -1.1130188
Z mean eval                  0.042291965
Z variance eval              0.005197646
total_rewards                [1790.04596818 2316.67063751 2708.17903116 1426.31320118 1691.39350198
 2082.59664198 1524.28314467 2647.91916699 1515.613909   2197.97060439]
total_rewards_mean           1990.0985807047298
total_rewards_std            446.76648095572966
total_rewards_max            2708.179031159288
total_rewards_min            1426.3132011829257
Number of train steps total  441000
Number of env steps total    2207000
Number of rollouts total     0
Train Time (s)               44.60781469615176
(Previous) Eval Time (s)     23.373236063867807
Sample Time (s)              21.65349749615416
Epoch Time (s)               89.63454825617373
Total Train Time (s)         36064.47977210535
Epoch                        440
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:49:25.197127 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #440 | Epoch Duration: 84.53430819511414
2020-01-11 10:49:25.197373 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #440 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04201417
Z variance train             0.0051915394
KL Divergence                10.823021
KL Loss                      1.0823021
QF Loss                      164.5767
VF Loss                      119.54262
Policy Loss                  -1594.1793
Q Predictions Mean           1596.0292
Q Predictions Std            160.32153
Q Predictions Max            1747.7056
Q Predictions Min            167.45166
V Predictions Mean           1601.2032
V Predictions Std            158.53807
V Predictions Max            1752.526
V Predictions Min            159.97884
Log Pis Mean                 -0.84536505
Log Pis Std                  1.628603
Log Pis Max                  6.102312
Log Pis Min                  -6.149683
Policy mu Mean               -0.018308962
Policy mu Std                0.77438694
Policy mu Max                3.8478897
Policy mu Min                -3.1230109
Policy log std Mean          -0.44195488
Policy log std Std           0.18534096
Policy log std Max           0.0057160556
Policy log std Min           -1.6134028
Z mean eval                  0.04986633
Z variance eval              0.0046862336
total_rewards                [1042.85098291 3281.09549536 3325.40025434 1238.32168645  983.84169585
 2272.56537283 1482.58725527 3342.94936726 3292.95790592 1214.36908946]
total_rewards_mean           2147.6939105631086
total_rewards_std            1007.1295493417147
total_rewards_max            3342.9493672598182
total_rewards_min            983.841695845547
Number of train steps total  442000
Number of env steps total    2212000
Number of rollouts total     0
Train Time (s)               44.81727113109082
(Previous) Eval Time (s)     18.2727120090276
Sample Time (s)              21.927315916866064
Epoch Time (s)               85.01729905698448
Total Train Time (s)         36152.0814912864
Epoch                        441
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:50:52.801887 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #441 | Epoch Duration: 87.60433793067932
2020-01-11 10:50:52.802017 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #441 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04835587
Z variance train             0.004682877
KL Divergence                11.085741
KL Loss                      1.1085742
QF Loss                      274.94275
VF Loss                      136.23616
Policy Loss                  -1595.584
Q Predictions Mean           1595.6716
Q Predictions Std            139.0555
Q Predictions Max            1740.0708
Q Predictions Min            770.21985
V Predictions Mean           1596.4177
V Predictions Std            139.50137
V Predictions Max            1740.8489
V Predictions Min            787.95544
Log Pis Mean                 -0.6666499
Log Pis Std                  1.7528532
Log Pis Max                  6.596644
Log Pis Min                  -4.365125
Policy mu Mean               -0.06930624
Policy mu Std                0.76183826
Policy mu Max                1.8787419
Policy mu Min                -3.1199048
Policy log std Mean          -0.43796405
Policy log std Std           0.17103033
Policy log std Max           -0.0018621385
Policy log std Min           -1.7061121
Z mean eval                  0.022086985
Z variance eval              0.0048543205
total_rewards                [3363.6974325  1819.3820919  2904.03267286 1901.3877625  1509.53166788
 1520.97732544 2713.08988352  882.74882493 3350.97764553 1029.99941919]
total_rewards_mean           2099.5824726243545
total_rewards_std            872.521476973332
total_rewards_max            3363.697432495318
total_rewards_min            882.7488249276554
Number of train steps total  443000
Number of env steps total    2217000
Number of rollouts total     0
Train Time (s)               44.47541615087539
(Previous) Eval Time (s)     20.859542040154338
Sample Time (s)              22.48085530148819
Epoch Time (s)               87.81581349251792
Total Train Time (s)         36239.38627897436
Epoch                        442
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:52:20.114648 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #442 | Epoch Duration: 87.31253719329834
2020-01-11 10:52:20.114773 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #442 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02227671
Z variance train             0.0048478246
KL Divergence                11.174303
KL Loss                      1.1174303
QF Loss                      69.88832
VF Loss                      48.767384
Policy Loss                  -1564.4854
Q Predictions Mean           1562.99
Q Predictions Std            152.3062
Q Predictions Max            1733.5823
Q Predictions Min            714.6149
V Predictions Mean           1565.2712
V Predictions Std            152.67787
V Predictions Max            1735.7462
V Predictions Min            725.77155
Log Pis Mean                 -0.65090173
Log Pis Std                  1.6301646
Log Pis Max                  3.9907265
Log Pis Min                  -6.7689314
Policy mu Mean               0.025866942
Policy mu Std                0.7615523
Policy mu Max                1.8864186
Policy mu Min                -3.2535117
Policy log std Mean          -0.43747878
Policy log std Std           0.16872987
Policy log std Max           -0.0394938
Policy log std Min           -1.3090761
Z mean eval                  0.0467276
Z variance eval              0.0049676113
total_rewards                [3321.89678953  968.22240172 3328.25451701 1203.35504635 2492.42046061
  976.64154139 3321.77695304 2684.68959724 3334.99100048 1972.78975321]
total_rewards_mean           2360.5038060582324
total_rewards_std            959.157203417872
total_rewards_max            3334.9910004781923
total_rewards_min            968.2224017226374
Number of train steps total  444000
Number of env steps total    2222000
Number of rollouts total     0
Train Time (s)               44.20695641078055
(Previous) Eval Time (s)     20.356010620947927
Sample Time (s)              21.82711312128231
Epoch Time (s)               86.39008015301079
Total Train Time (s)         36327.087933089584
Epoch                        443
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:53:47.824440 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #443 | Epoch Duration: 87.70956206321716
2020-01-11 10:53:47.824599 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #443 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0465127
Z variance train             0.0049682693
KL Divergence                11.1543045
KL Loss                      1.1154305
QF Loss                      69.7117
VF Loss                      50.423706
Policy Loss                  -1591.597
Q Predictions Mean           1590.8195
Q Predictions Std            154.9394
Q Predictions Max            1764.7968
Q Predictions Min            725.49554
V Predictions Mean           1590.105
V Predictions Std            156.12868
V Predictions Max            1767.2368
V Predictions Min            682.72925
Log Pis Mean                 -0.45714694
Log Pis Std                  1.7667719
Log Pis Max                  7.966549
Log Pis Min                  -4.947542
Policy mu Mean               -0.052321553
Policy mu Std                0.81722903
Policy mu Max                1.8123362
Policy mu Min                -3.3438232
Policy log std Mean          -0.42298985
Policy log std Std           0.1747642
Policy log std Max           0.0492374
Policy log std Min           -1.4026638
Z mean eval                  0.038570732
Z variance eval              0.0050668935
total_rewards                [3299.12567801 3364.6439476  1380.2427908  1622.37147666 3086.33927206
 3318.39610059  929.26344565 1685.40266507 1240.7276006  3381.19539881]
total_rewards_mean           2330.7708375862953
total_rewards_std            981.352857602277
total_rewards_max            3381.1953988134546
total_rewards_min            929.2634456529432
Number of train steps total  445000
Number of env steps total    2227000
Number of rollouts total     0
Train Time (s)               45.024957643356174
(Previous) Eval Time (s)     21.675249645020813
Sample Time (s)              21.635212580207735
Epoch Time (s)               88.33541986858472
Total Train Time (s)         36418.61959547596
Epoch                        444
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:55:19.359484 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #444 | Epoch Duration: 91.53476977348328
2020-01-11 10:55:19.359606 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #444 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03709659
Z variance train             0.0050602434
KL Divergence                11.024193
KL Loss                      1.1024193
QF Loss                      250.23026
VF Loss                      83.69302
Policy Loss                  -1573.4039
Q Predictions Mean           1580.9434
Q Predictions Std            155.90677
Q Predictions Max            1760.5435
Q Predictions Min            631.66254
V Predictions Mean           1573.1068
V Predictions Std            159.50508
V Predictions Max            1751.048
V Predictions Min            595.2537
Log Pis Mean                 -0.5616677
Log Pis Std                  2.0859382
Log Pis Max                  8.43943
Log Pis Min                  -3.9807305
Policy mu Mean               -0.07489232
Policy mu Std                0.8077283
Policy mu Max                2.1405172
Policy mu Min                -3.0951266
Policy log std Mean          -0.42478275
Policy log std Std           0.16874412
Policy log std Max           0.0586994
Policy log std Min           -1.2519616
Z mean eval                  0.05153997
Z variance eval              0.005256702
total_rewards                [ 963.78568255 2586.53706483 1581.03179281 3262.79710012 1969.45481769
  807.45643576  108.52845771 3348.0952868  3290.31426627 3355.50206776]
total_rewards_mean           2127.350297230174
total_rewards_std            1155.2571641214322
total_rewards_max            3355.5020677576495
total_rewards_min            108.52845771189732
Number of train steps total  446000
Number of env steps total    2232000
Number of rollouts total     0
Train Time (s)               44.27392094396055
(Previous) Eval Time (s)     24.874362755566835
Sample Time (s)              21.206887021660805
Epoch Time (s)               90.35517072118819
Total Train Time (s)         36504.92656473396
Epoch                        445
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:56:45.669685 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #445 | Epoch Duration: 86.30998539924622
2020-01-11 10:56:45.669807 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #445 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.051444292
Z variance train             0.005257389
KL Divergence                10.790631
KL Loss                      1.0790632
QF Loss                      113.16531
VF Loss                      103.61795
Policy Loss                  -1585.1432
Q Predictions Mean           1587.6157
Q Predictions Std            139.6028
Q Predictions Max            1734.0007
Q Predictions Min            736.2187
V Predictions Mean           1587.4386
V Predictions Std            138.71497
V Predictions Max            1731.32
V Predictions Min            728.2645
Log Pis Mean                 -0.6703626
Log Pis Std                  1.7428954
Log Pis Max                  7.2229185
Log Pis Min                  -5.6833935
Policy mu Mean               -0.074165046
Policy mu Std                0.79423356
Policy mu Max                1.8709042
Policy mu Min                -3.2083936
Policy log std Mean          -0.42599258
Policy log std Std           0.16571534
Policy log std Max           -0.003800422
Policy log std Min           -1.2353401
Z mean eval                  0.028337335
Z variance eval              0.0061446284
total_rewards                [1214.34718232 1153.59816311 1238.82340207 3364.09064165 1906.60831153
 3268.84346236 2391.91452419  954.00191745  975.49777437 1473.04328572]
total_rewards_mean           1794.076866477709
total_rewards_std            868.528586377763
total_rewards_max            3364.0906416471466
total_rewards_min            954.0019174487086
Number of train steps total  447000
Number of env steps total    2237000
Number of rollouts total     0
Train Time (s)               44.16440379060805
(Previous) Eval Time (s)     20.82894552592188
Sample Time (s)              22.01428517512977
Epoch Time (s)               87.0076344916597
Total Train Time (s)         36589.02786963293
Epoch                        446
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:58:09.773657 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #446 | Epoch Duration: 84.10376048088074
2020-01-11 10:58:09.773779 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #446 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.028161183
Z variance train             0.0061399965
KL Divergence                10.339512
KL Loss                      1.0339512
QF Loss                      118.854095
VF Loss                      49.85461
Policy Loss                  -1587.5938
Q Predictions Mean           1589.0562
Q Predictions Std            171.64449
Q Predictions Max            1748.1576
Q Predictions Min            472.6646
V Predictions Mean           1591.1198
V Predictions Std            171.17398
V Predictions Max            1751.0287
V Predictions Min            487.87155
Log Pis Mean                 -0.7170336
Log Pis Std                  1.8371453
Log Pis Max                  8.841251
Log Pis Min                  -6.3727183
Policy mu Mean               -0.098466754
Policy mu Std                0.76334107
Policy mu Max                2.6569378
Policy mu Min                -3.0673208
Policy log std Mean          -0.44383764
Policy log std Std           0.17217809
Policy log std Max           -0.008027285
Policy log std Min           -1.2084897
Z mean eval                  0.022035003
Z variance eval              0.0055007995
total_rewards                [3277.56736745 1530.65883936 2534.8666659  1001.89053208 2950.0694773
 1738.39997253 1728.13656225 1722.0808425  3196.99693866 3326.06705041]
total_rewards_mean           2300.6734248441467
total_rewards_std            808.9616891991919
total_rewards_max            3326.0670504082227
total_rewards_min            1001.8905320791907
Number of train steps total  448000
Number of env steps total    2242000
Number of rollouts total     0
Train Time (s)               44.29875557171181
(Previous) Eval Time (s)     17.924817939754575
Sample Time (s)              21.92328712902963
Epoch Time (s)               84.14686064049602
Total Train Time (s)         36676.94350693794
Epoch                        447
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 10:59:37.697920 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #447 | Epoch Duration: 87.92404627799988
2020-01-11 10:59:37.698046 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #447 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023126584
Z variance train             0.005512815
KL Divergence                10.585405
KL Loss                      1.0585406
QF Loss                      255.97336
VF Loss                      149.55614
Policy Loss                  -1597.9336
Q Predictions Mean           1602.224
Q Predictions Std            143.1459
Q Predictions Max            1758.8832
Q Predictions Min            285.64908
V Predictions Mean           1604.4827
V Predictions Std            145.61531
V Predictions Max            1759.1919
V Predictions Min            265.3242
Log Pis Mean                 -0.51741666
Log Pis Std                  1.7486199
Log Pis Max                  5.956944
Log Pis Min                  -5.53126
Policy mu Mean               -0.013318104
Policy mu Std                0.8340724
Policy mu Max                2.3845942
Policy mu Min                -3.2079465
Policy log std Mean          -0.44045964
Policy log std Std           0.18136656
Policy log std Max           0.09043792
Policy log std Min           -1.4178876
Z mean eval                  0.030765047
Z variance eval              0.005662992
total_rewards                [2096.51321566  913.82990632 1197.2470236  2674.05287266 1155.01236825
 3350.36534427 2977.18371655 1659.66894706 3169.68545819  948.28115124]
total_rewards_mean           2014.1840003799784
total_rewards_std            914.7845943728495
total_rewards_max            3350.365344269065
total_rewards_min            913.8299063210271
Number of train steps total  449000
Number of env steps total    2247000
Number of rollouts total     0
Train Time (s)               44.66559220897034
(Previous) Eval Time (s)     21.701777204871178
Sample Time (s)              21.7752432259731
Epoch Time (s)               88.14261263981462
Total Train Time (s)         36763.867857369594
Epoch                        448
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:01:04.625028 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #448 | Epoch Duration: 86.92688083648682
2020-01-11 11:01:04.625163 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #448 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031010967
Z variance train             0.005668751
KL Divergence                10.50128
KL Loss                      1.050128
QF Loss                      68.60212
VF Loss                      54.350655
Policy Loss                  -1603.5912
Q Predictions Mean           1604.3553
Q Predictions Std            161.6107
Q Predictions Max            1776.0576
Q Predictions Min            393.22263
V Predictions Mean           1597.7195
V Predictions Std            160.62628
V Predictions Max            1767.5403
V Predictions Min            398.3017
Log Pis Mean                 -0.57442975
Log Pis Std                  1.8497596
Log Pis Max                  5.7086315
Log Pis Min                  -5.2819567
Policy mu Mean               -0.030251661
Policy mu Std                0.802793
Policy mu Max                1.8763468
Policy mu Min                -3.1943874
Policy log std Mean          -0.4165683
Policy log std Std           0.1461985
Policy log std Max           0.04269892
Policy log std Min           -1.0431098
Z mean eval                  0.014049791
Z variance eval              0.006497448
total_rewards                [ 991.58026011 3378.45841513 1211.07791251 3320.91019508  985.76015084
 2330.59713779 1230.44741312 3263.22398423 2066.7812201  3255.69632219]
total_rewards_mean           2203.4533011104522
total_rewards_std            988.8115726807778
total_rewards_max            3378.4584151315394
total_rewards_min            985.760150842151
Number of train steps total  450000
Number of env steps total    2252000
Number of rollouts total     0
Train Time (s)               44.21162130404264
(Previous) Eval Time (s)     20.48580706305802
Sample Time (s)              22.54131638025865
Epoch Time (s)               87.2387447473593
Total Train Time (s)         36853.47060219897
Epoch                        449
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:02:34.232969 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #449 | Epoch Duration: 89.6076979637146
2020-01-11 11:02:34.233091 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #449 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.013973111
Z variance train             0.006498164
KL Divergence                10.161388
KL Loss                      1.0161389
QF Loss                      63.20387
VF Loss                      52.393402
Policy Loss                  -1595.2445
Q Predictions Mean           1595.9669
Q Predictions Std            173.58908
Q Predictions Max            1741.4563
Q Predictions Min            409.67505
V Predictions Mean           1596.082
V Predictions Std            172.65942
V Predictions Max            1739.9575
V Predictions Min            427.8466
Log Pis Mean                 -0.6194021
Log Pis Std                  1.8932283
Log Pis Max                  9.966106
Log Pis Min                  -4.3127356
Policy mu Mean               -0.002772182
Policy mu Std                0.77114356
Policy mu Max                1.9666437
Policy mu Min                -3.5471053
Policy log std Mean          -0.413162
Policy log std Std           0.18248291
Policy log std Max           0.07124394
Policy log std Min           -1.2430952
Z mean eval                  0.04053046
Z variance eval              0.0063159177
total_rewards                [2869.25008468 2584.40462194 2604.67866865 2403.91213836 1193.86544135
 3400.25587943 3370.64173115 1178.83152391 3401.24574976 3388.60987949]
total_rewards_mean           2639.569571871384
total_rewards_std            811.830421425142
total_rewards_max            3401.245749759712
total_rewards_min            1178.8315239056278
Number of train steps total  451000
Number of env steps total    2257000
Number of rollouts total     0
Train Time (s)               44.468699829652905
(Previous) Eval Time (s)     22.85449790302664
Sample Time (s)              23.685917552094907
Epoch Time (s)               91.00911528477445
Total Train Time (s)         36945.7869872516
Epoch                        450
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:04:06.555230 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #450 | Epoch Duration: 92.32203722000122
2020-01-11 11:04:06.555387 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #450 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040337853
Z variance train             0.0063165515
KL Divergence                10.19615
KL Loss                      1.019615
QF Loss                      40.800713
VF Loss                      16.874876
Policy Loss                  -1607.6436
Q Predictions Mean           1607.9778
Q Predictions Std            171.1768
Q Predictions Max            1816.2936
Q Predictions Min            163.09575
V Predictions Mean           1608.9725
V Predictions Std            170.87105
V Predictions Max            1815.5083
V Predictions Min            147.50917
Log Pis Mean                 -0.5656693
Log Pis Std                  1.6764107
Log Pis Max                  5.021531
Log Pis Min                  -3.5501056
Policy mu Mean               -0.009597505
Policy mu Std                0.76016486
Policy mu Max                1.8039443
Policy mu Min                -3.1274114
Policy log std Mean          -0.39636227
Policy log std Std           0.16216832
Policy log std Max           0.0222103
Policy log std Min           -1.2542138
Z mean eval                  0.018709652
Z variance eval              0.005393756
total_rewards                [1239.47543638 1830.64894121 3341.24887353 1284.78319657 1435.24116701
 1601.75120306 1468.72675153 1165.17024479 1395.43679139 1139.40881828]
total_rewards_mean           1590.1891423745333
total_rewards_std            616.5202432223866
total_rewards_max            3341.2488735256798
total_rewards_min            1139.4088182830737
Number of train steps total  452000
Number of env steps total    2262000
Number of rollouts total     0
Train Time (s)               43.86359504982829
(Previous) Eval Time (s)     24.167137467768043
Sample Time (s)              21.618810595478863
Epoch Time (s)               89.6495431130752
Total Train Time (s)         37025.84895034507
Epoch                        451
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:05:26.621313 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #451 | Epoch Duration: 80.06579446792603
2020-01-11 11:05:26.621433 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #451 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017995255
Z variance train             0.005410691
KL Divergence                10.58631
KL Loss                      1.0586311
QF Loss                      216.63846
VF Loss                      160.35892
Policy Loss                  -1582.5505
Q Predictions Mean           1583.2065
Q Predictions Std            169.5052
Q Predictions Max            1759.5217
Q Predictions Min            376.61224
V Predictions Mean           1580.5981
V Predictions Std            168.30327
V Predictions Max            1750.1462
V Predictions Min            360.40128
Log Pis Mean                 -0.4150297
Log Pis Std                  1.789046
Log Pis Max                  7.6619296
Log Pis Min                  -5.2567506
Policy mu Mean               0.17808537
Policy mu Std                0.81224954
Policy mu Max                2.2061963
Policy mu Min                -2.7258728
Policy log std Mean          -0.40817937
Policy log std Std           0.17640182
Policy log std Max           0.13170257
Policy log std Min           -1.2030888
Z mean eval                  0.03318385
Z variance eval              0.0054369923
total_rewards                [2276.2476559  2239.05403042  943.94407945 2634.13130956 1533.97741062
 3354.95706099  993.0530775   995.89450313 1770.17690714 2629.50094935]
total_rewards_mean           1937.093698406717
total_rewards_std            783.3013428994118
total_rewards_max            3354.957060986116
total_rewards_min            943.9440794495044
Number of train steps total  453000
Number of env steps total    2267000
Number of rollouts total     0
Train Time (s)               45.2436537030153
(Previous) Eval Time (s)     14.583135391119868
Sample Time (s)              20.52275795582682
Epoch Time (s)               80.34954704996198
Total Train Time (s)         37108.27202345757
Epoch                        452
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:06:49.048893 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #452 | Epoch Duration: 82.42735290527344
2020-01-11 11:06:49.049062 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #452 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03340658
Z variance train             0.005436032
KL Divergence                10.596015
KL Loss                      1.0596015
QF Loss                      95.44167
VF Loss                      38.020042
Policy Loss                  -1599.542
Q Predictions Mean           1598.4619
Q Predictions Std            139.89146
Q Predictions Max            1752.3815
Q Predictions Min            818.0171
V Predictions Mean           1601.0923
V Predictions Std            140.13925
V Predictions Max            1756.8246
V Predictions Min            803.9853
Log Pis Mean                 -0.59018713
Log Pis Std                  2.029521
Log Pis Max                  9.09878
Log Pis Min                  -3.9364989
Policy mu Mean               0.0012106622
Policy mu Std                0.7877012
Policy mu Max                2.2112908
Policy mu Min                -3.3973475
Policy log std Mean          -0.4185187
Policy log std Std           0.16712572
Policy log std Max           0.12547156
Policy log std Min           -1.6094923
Z mean eval                  0.045613058
Z variance eval              0.005963371
total_rewards                [1816.11559256 2430.54336492 2723.49853655 3304.70330984 2347.77857907
 2439.41121297 3273.05743056 2146.75126365 2118.60600054 3368.91402687]
total_rewards_mean           2596.9379317542453
total_rewards_std            522.0890044015476
total_rewards_max            3368.914026872733
total_rewards_min            1816.115592562954
Number of train steps total  454000
Number of env steps total    2272000
Number of rollouts total     0
Train Time (s)               44.965308255981654
(Previous) Eval Time (s)     16.660678781569004
Sample Time (s)              21.60605057887733
Epoch Time (s)               83.23203761642799
Total Train Time (s)         37200.55702860048
Epoch                        453
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:08:21.342374 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #453 | Epoch Duration: 92.29309630393982
2020-01-11 11:08:21.342636 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #453 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.045712717
Z variance train             0.0059638717
KL Divergence                10.392592
KL Loss                      1.0392593
QF Loss                      63.13999
VF Loss                      28.676483
Policy Loss                  -1603.0192
Q Predictions Mean           1602.8441
Q Predictions Std            124.37979
Q Predictions Max            1761.8816
Q Predictions Min            695.7199
V Predictions Mean           1600.3374
V Predictions Std            123.28578
V Predictions Max            1758.6292
V Predictions Min            710.27924
Log Pis Mean                 -0.5642482
Log Pis Std                  1.8295683
Log Pis Max                  5.0245733
Log Pis Min                  -5.048773
Policy mu Mean               0.035023276
Policy mu Std                0.82555234
Policy mu Max                2.1801622
Policy mu Min                -2.9721532
Policy log std Mean          -0.41155282
Policy log std Std           0.17252009
Policy log std Max           -0.013633847
Policy log std Min           -1.2052715
Z mean eval                  0.06879847
Z variance eval              0.0047939876
total_rewards                [ 999.05729134 3326.44877161 1525.80865787 1147.03834051 3328.24050647
 1116.46550421  105.76261696 1871.81632788 2848.25028784 1437.17091164]
total_rewards_mean           1770.6059216329934
total_rewards_std            1018.4922551628592
total_rewards_max            3328.240506470991
total_rewards_min            105.76261695838834
Number of train steps total  455000
Number of env steps total    2277000
Number of rollouts total     0
Train Time (s)               44.593603231944144
(Previous) Eval Time (s)     25.72148409532383
Sample Time (s)              22.174474884290248
Epoch Time (s)               92.48956221155822
Total Train Time (s)         37284.352319032885
Epoch                        454
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:09:45.139571 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #454 | Epoch Duration: 83.79677557945251
2020-01-11 11:09:45.139706 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #454 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06908182
Z variance train             0.0047968975
KL Divergence                10.983572
KL Loss                      1.0983572
QF Loss                      74.521324
VF Loss                      34.855476
Policy Loss                  -1584.369
Q Predictions Mean           1586.149
Q Predictions Std            188.25488
Q Predictions Max            1764.7157
Q Predictions Min            429.01636
V Predictions Mean           1586.6804
V Predictions Std            187.23837
V Predictions Max            1769.1494
V Predictions Min            444.09656
Log Pis Mean                 -0.49693036
Log Pis Std                  1.940385
Log Pis Max                  6.945325
Log Pis Min                  -5.587004
Policy mu Mean               0.032243963
Policy mu Std                0.8358864
Policy mu Max                2.4765334
Policy mu Min                -3.1711779
Policy log std Mean          -0.4153223
Policy log std Std           0.18744142
Policy log std Max           0.03675562
Policy log std Min           -1.5307148
Z mean eval                  0.017431369
Z variance eval              0.0049882447
total_rewards                [1259.69026563 1240.95866994 3351.50497021 3353.40638472 3286.31511855
 3328.20495417 1067.15461766 3352.92101641 1073.90237123 3307.57659269]
total_rewards_mean           2462.1634961215304
total_rewards_std            1064.578317036753
total_rewards_max            3353.406384723588
total_rewards_min            1067.1546176576585
Number of train steps total  456000
Number of env steps total    2282000
Number of rollouts total     0
Train Time (s)               44.2453753198497
(Previous) Eval Time (s)     17.028463087044656
Sample Time (s)              22.28878639731556
Epoch Time (s)               83.56262480420992
Total Train Time (s)         37375.214381751604
Epoch                        455
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:11:16.005284 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #455 | Epoch Duration: 90.86541628837585
2020-01-11 11:11:16.005485 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #455 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017542398
Z variance train             0.0049841353
KL Divergence                10.89875
KL Loss                      1.0898751
QF Loss                      48.65888
VF Loss                      38.43663
Policy Loss                  -1577.8074
Q Predictions Mean           1578.4551
Q Predictions Std            150.82286
Q Predictions Max            1748.4009
Q Predictions Min            656.8232
V Predictions Mean           1578.1758
V Predictions Std            150.8893
V Predictions Max            1743.853
V Predictions Min            647.1338
Log Pis Mean                 -0.8827914
Log Pis Std                  1.6834908
Log Pis Max                  6.114741
Log Pis Min                  -5.4400673
Policy mu Mean               0.023935571
Policy mu Std                0.7260227
Policy mu Max                3.0049868
Policy mu Min                -2.4806151
Policy log std Mean          -0.41804934
Policy log std Std           0.14938483
Policy log std Max           -0.0036364198
Policy log std Min           -0.970549
Z mean eval                  0.049556132
Z variance eval              0.0042136684
total_rewards                [1017.91323952  805.45737508 2608.40650772  918.86765802 1172.70563662
 1158.77579475 1235.36059597 1138.12695691  785.68859807  908.03408158]
total_rewards_mean           1174.9336444239793
total_rewards_std            500.9592430509555
total_rewards_max            2608.4065077244027
total_rewards_min            785.6885980689308
Number of train steps total  457000
Number of env steps total    2287000
Number of rollouts total     0
Train Time (s)               44.32005964498967
(Previous) Eval Time (s)     24.331003583967686
Sample Time (s)              21.960206603631377
Epoch Time (s)               90.61126983258873
Total Train Time (s)         37452.67600824544
Epoch                        456
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:12:33.470409 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #456 | Epoch Duration: 77.46479916572571
2020-01-11 11:12:33.470570 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #456 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04924965
Z variance train             0.004215479
KL Divergence                11.296188
KL Loss                      1.1296189
QF Loss                      102.46518
VF Loss                      118.08189
Policy Loss                  -1602.2148
Q Predictions Mean           1604.4679
Q Predictions Std            132.5773
Q Predictions Max            1745.0769
Q Predictions Min            754.43353
V Predictions Mean           1607.1492
V Predictions Std            133.88069
V Predictions Max            1755.9556
V Predictions Min            743.76306
Log Pis Mean                 -0.84502333
Log Pis Std                  1.7162641
Log Pis Max                  6.929064
Log Pis Min                  -4.7320523
Policy mu Mean               -0.051911075
Policy mu Std                0.7440415
Policy mu Max                1.4228688
Policy mu Min                -2.6124456
Policy log std Mean          -0.39664355
Policy log std Std           0.15039152
Policy log std Max           -0.004167199
Policy log std Min           -0.9955353
Z mean eval                  0.088755295
Z variance eval              0.0050175637
total_rewards                [2059.37334029 1519.84170667 1177.76044969 1145.9124817   721.01004385
  974.69364121  980.13929111  222.10126271 2558.38185592  961.94295357]
total_rewards_mean           1232.115702670329
total_rewards_std            634.0834769924626
total_rewards_max            2558.381855922178
total_rewards_min            222.10126270606887
Number of train steps total  458000
Number of env steps total    2292000
Number of rollouts total     0
Train Time (s)               44.08297983324155
(Previous) Eval Time (s)     11.184287080075592
Sample Time (s)              21.880861286073923
Epoch Time (s)               77.14812819939107
Total Train Time (s)         37531.641377166845
Epoch                        457
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:13:52.442091 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #457 | Epoch Duration: 78.97140264511108
2020-01-11 11:13:52.442217 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #457 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.09054723
Z variance train             0.005023646
KL Divergence                10.852275
KL Loss                      1.0852275
QF Loss                      129.66946
VF Loss                      49.54545
Policy Loss                  -1586.029
Q Predictions Mean           1588.7299
Q Predictions Std            126.69573
Q Predictions Max            1735.8612
Q Predictions Min            835.1408
V Predictions Mean           1583.1405
V Predictions Std            125.67759
V Predictions Max            1731.3826
V Predictions Min            844.4795
Log Pis Mean                 -0.7148007
Log Pis Std                  1.6510977
Log Pis Max                  6.7458296
Log Pis Min                  -4.2544246
Policy mu Mean               0.13947208
Policy mu Std                0.7609652
Policy mu Max                3.303967
Policy mu Min                -2.415792
Policy log std Mean          -0.39242253
Policy log std Std           0.14987533
Policy log std Max           0.0739502
Policy log std Min           -1.1401159
Z mean eval                  0.05598563
Z variance eval              0.0051139244
total_rewards                [3369.74656895  984.99705503 1157.17402076 3295.74515277 1540.88313012
  960.35178766 1739.71439854 1215.91796055 3395.4591303  3338.24133633]
total_rewards_mean           2099.823054100339
total_rewards_std            1044.4370424050387
total_rewards_max            3395.459130301854
total_rewards_min            960.3517876597679
Number of train steps total  459000
Number of env steps total    2297000
Number of rollouts total     0
Train Time (s)               44.3805262488313
(Previous) Eval Time (s)     13.007311180699617
Sample Time (s)              21.23146680602804
Epoch Time (s)               78.61930423555896
Total Train Time (s)         37618.32757093897
Epoch                        458
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:15:19.132906 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #458 | Epoch Duration: 86.69059658050537
2020-01-11 11:15:19.133028 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #458 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055923294
Z variance train             0.0051046954
KL Divergence                10.754393
KL Loss                      1.0754393
QF Loss                      284.93744
VF Loss                      540.0359
Policy Loss                  -1603.0453
Q Predictions Mean           1605.7424
Q Predictions Std            123.735374
Q Predictions Max            1746.3125
Q Predictions Min            952.3333
V Predictions Mean           1590.0846
V Predictions Std            119.81118
V Predictions Max            1730.8782
V Predictions Min            994.2405
Log Pis Mean                 -0.53575003
Log Pis Std                  1.7480915
Log Pis Max                  7.1494355
Log Pis Min                  -5.5261536
Policy mu Mean               0.04099105
Policy mu Std                0.8075019
Policy mu Max                2.192454
Policy mu Min                -2.8807836
Policy log std Mean          -0.43500352
Policy log std Std           0.15629777
Policy log std Max           0.0017513037
Policy log std Min           -1.2198186
Z mean eval                  0.02548359
Z variance eval              0.005558394
total_rewards                [ 921.78376538 3347.89525615  951.27361838 3364.66964222 3375.37646379
 1787.65019335  955.64370774 3302.68972861 1913.05398897 1128.43635932]
total_rewards_mean           2104.847272391181
total_rewards_std            1064.1056743152085
total_rewards_max            3375.3764637909476
total_rewards_min            921.7837653783421
Number of train steps total  460000
Number of env steps total    2302000
Number of rollouts total     0
Train Time (s)               44.799364460166544
(Previous) Eval Time (s)     21.07834458211437
Sample Time (s)              22.27562635578215
Epoch Time (s)               88.15333539806306
Total Train Time (s)         37706.70416087797
Epoch                        459
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:16:47.512281 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #459 | Epoch Duration: 88.37915921211243
2020-01-11 11:16:47.512405 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #459 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025470015
Z variance train             0.005550533
KL Divergence                10.518337
KL Loss                      1.0518337
QF Loss                      3300.2664
VF Loss                      1218.1993
Policy Loss                  -1593.0892
Q Predictions Mean           1592.0078
Q Predictions Std            151.44083
Q Predictions Max            1730.4955
Q Predictions Min            754.0712
V Predictions Mean           1592.5635
V Predictions Std            151.1838
V Predictions Max            1737.5966
V Predictions Min            731.8814
Log Pis Mean                 -0.4676373
Log Pis Std                  1.8548887
Log Pis Max                  7.6901526
Log Pis Min                  -6.3366265
Policy mu Mean               -0.02468768
Policy mu Std                0.8203435
Policy mu Max                2.0042036
Policy mu Min                -3.346057
Policy log std Mean          -0.44159234
Policy log std Std           0.18027394
Policy log std Max           -0.035621077
Policy log std Min           -1.5523472
Z mean eval                  0.024390915
Z variance eval              0.0054761395
total_rewards                [ 989.3819035  3126.72412238 1012.27887775  942.67820195 3347.68946602
  952.43384672 2330.1431839  1495.16637949 3342.80750042 1787.88076093]
total_rewards_mean           1932.7184243078123
total_rewards_std            972.869481686191
total_rewards_max            3347.689466016886
total_rewards_min            942.6782019529022
Number of train steps total  461000
Number of env steps total    2307000
Number of rollouts total     0
Train Time (s)               44.76723102061078
(Previous) Eval Time (s)     21.303909044712782
Sample Time (s)              22.048775016330183
Epoch Time (s)               88.11991508165374
Total Train Time (s)         37792.43093128316
Epoch                        460
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:18:13.243950 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #460 | Epoch Duration: 85.7314522266388
2020-01-11 11:18:13.244086 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #460 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024238296
Z variance train             0.0054846015
KL Divergence                10.573185
KL Loss                      1.0573186
QF Loss                      119.94528
VF Loss                      67.81767
Policy Loss                  -1602.7626
Q Predictions Mean           1604.9675
Q Predictions Std            169.53134
Q Predictions Max            1738.6871
Q Predictions Min            208.55902
V Predictions Mean           1603.3848
V Predictions Std            168.57277
V Predictions Max            1737.1096
V Predictions Min            218.95102
Log Pis Mean                 -0.52114147
Log Pis Std                  1.7231407
Log Pis Max                  5.732762
Log Pis Min                  -4.1017733
Policy mu Mean               -0.06932036
Policy mu Std                0.81186795
Policy mu Max                2.1338766
Policy mu Min                -3.6109438
Policy log std Mean          -0.40293446
Policy log std Std           0.17032799
Policy log std Max           0.1359567
Policy log std Min           -1.0866234
Z mean eval                  0.0495966
Z variance eval              0.0046555125
total_rewards                [1494.08292378 3321.88793144 2317.49158931 1731.06842715 1794.79163739
  878.88206358  192.46149818 1722.56610448 1002.09797836 2900.1224678 ]
total_rewards_mean           1735.5452621482175
total_rewards_std            890.2983551013908
total_rewards_max            3321.887931444808
total_rewards_min            192.46149818245084
Number of train steps total  462000
Number of env steps total    2312000
Number of rollouts total     0
Train Time (s)               44.36724050203338
(Previous) Eval Time (s)     18.915190214291215
Sample Time (s)              21.830081139691174
Epoch Time (s)               85.11251185601577
Total Train Time (s)         37874.980482907034
Epoch                        461
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:19:35.798792 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #461 | Epoch Duration: 82.55460023880005
2020-01-11 11:19:35.798946 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #461 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04997396
Z variance train             0.0046493816
KL Divergence                11.033581
KL Loss                      1.1033581
QF Loss                      351.71762
VF Loss                      197.41481
Policy Loss                  -1596.149
Q Predictions Mean           1596.4329
Q Predictions Std            132.42935
Q Predictions Max            1738.3009
Q Predictions Min            780.8357
V Predictions Mean           1603.7661
V Predictions Std            133.02454
V Predictions Max            1744.5409
V Predictions Min            772.6459
Log Pis Mean                 -0.5617671
Log Pis Std                  1.9177816
Log Pis Max                  7.7606907
Log Pis Min                  -5.0833035
Policy mu Mean               -0.042645086
Policy mu Std                0.79992974
Policy mu Max                2.0602455
Policy mu Min                -3.0607076
Policy log std Mean          -0.44527662
Policy log std Std           0.16823126
Policy log std Max           0.01582846
Policy log std Min           -1.121843
Z mean eval                  0.030038211
Z variance eval              0.0052049174
total_rewards                [3409.03227218  899.22144918 3323.97389266  923.00376086  965.40598609
 3411.25738224 3342.2814631  2307.87921324 3323.67740469 3433.4325136 ]
total_rewards_mean           2533.9165337827917
total_rewards_std            1096.569032503733
total_rewards_max            3433.432513595645
total_rewards_min            899.2214491788757
Number of train steps total  463000
Number of env steps total    2317000
Number of rollouts total     0
Train Time (s)               43.92808769410476
(Previous) Eval Time (s)     16.357009805738926
Sample Time (s)              21.470477659720927
Epoch Time (s)               81.75557515956461
Total Train Time (s)         37965.76514291903
Epoch                        462
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:21:06.587060 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #462 | Epoch Duration: 90.78797483444214
2020-01-11 11:21:06.587182 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #462 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.030378286
Z variance train             0.005207335
KL Divergence                10.703825
KL Loss                      1.0703825
QF Loss                      103.30211
VF Loss                      55.390003
Policy Loss                  -1593.9105
Q Predictions Mean           1591.7612
Q Predictions Std            159.37517
Q Predictions Max            1784.264
Q Predictions Min            814.98395
V Predictions Mean           1591.2452
V Predictions Std            156.75624
V Predictions Max            1781.3293
V Predictions Min            831.42474
Log Pis Mean                 -0.46798414
Log Pis Std                  1.8304487
Log Pis Max                  8.859575
Log Pis Min                  -5.3961196
Policy mu Mean               0.11238059
Policy mu Std                0.8057376
Policy mu Max                2.3205724
Policy mu Min                -3.2610805
Policy log std Mean          -0.43915215
Policy log std Std           0.17804234
Policy log std Max           0.009803981
Policy log std Min           -1.5347577
Z mean eval                  0.014506231
Z variance eval              0.0060693393
total_rewards                [3292.22778156 3311.57044924  952.23262674 3315.56895461  978.12007824
 3331.18242772 3320.710268   3299.02110305 3326.99473962 3278.35676428]
total_rewards_mean           2840.5985193062857
total_rewards_std            937.8526986286691
total_rewards_max            3331.1824277238657
total_rewards_min            952.2326267414194
Number of train steps total  464000
Number of env steps total    2322000
Number of rollouts total     0
Train Time (s)               44.17435749201104
(Previous) Eval Time (s)     25.38916263729334
Sample Time (s)              21.510744851082563
Epoch Time (s)               91.07426498038694
Total Train Time (s)         38059.73161241645
Epoch                        463
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:22:40.559885 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #463 | Epoch Duration: 93.97260093688965
2020-01-11 11:22:40.560061 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #463 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0111277485
Z variance train             0.0060693547
KL Divergence                10.359755
KL Loss                      1.0359755
QF Loss                      212.69885
VF Loss                      65.70147
Policy Loss                  -1626.1395
Q Predictions Mean           1626.2126
Q Predictions Std            130.57492
Q Predictions Max            1813.5153
Q Predictions Min            849.68036
V Predictions Mean           1620.7363
V Predictions Std            131.16464
V Predictions Max            1810.8524
V Predictions Min            840.39624
Log Pis Mean                 -0.56396544
Log Pis Std                  1.6902027
Log Pis Max                  6.1790175
Log Pis Min                  -4.6059785
Policy mu Mean               0.013854131
Policy mu Std                0.7558309
Policy mu Max                1.6892306
Policy mu Min                -3.233366
Policy log std Mean          -0.45772484
Policy log std Std           0.18289648
Policy log std Max           -0.06508666
Policy log std Min           -1.5255711
Z mean eval                  0.040314708
Z variance eval              0.004957321
total_rewards                [2844.76497014 1182.74088709 1732.24091271  199.51160519 3309.91635419
 1214.49511732 2280.25106039 1501.8688444  3316.29569498 1469.98170569]
total_rewards_mean           1905.206715207388
total_rewards_std            963.2374505977274
total_rewards_max            3316.2956949783643
total_rewards_min            199.51160518561812
Number of train steps total  465000
Number of env steps total    2327000
Number of rollouts total     0
Train Time (s)               44.362497601192445
(Previous) Eval Time (s)     28.287242055870593
Sample Time (s)              22.130231382790953
Epoch Time (s)               94.77997103985399
Total Train Time (s)         38145.63868236542
Epoch                        464
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:24:06.467534 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #464 | Epoch Duration: 85.9073429107666
2020-01-11 11:24:06.467660 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #464 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.039342593
Z variance train             0.0049520247
KL Divergence                10.895686
KL Loss                      1.0895686
QF Loss                      536.4615
VF Loss                      351.63687
Policy Loss                  -1594.4658
Q Predictions Mean           1600.0203
Q Predictions Std            137.56732
Q Predictions Max            1738.1768
Q Predictions Min            804.32
V Predictions Mean           1600.7834
V Predictions Std            139.35057
V Predictions Max            1739.483
V Predictions Min            770.75275
Log Pis Mean                 -0.36996022
Log Pis Std                  1.8760717
Log Pis Max                  9.530429
Log Pis Min                  -5.2696996
Policy mu Mean               0.08154326
Policy mu Std                0.8623873
Policy mu Max                3.1183608
Policy mu Min                -3.0015683
Policy log std Mean          -0.42727032
Policy log std Std           0.17324214
Policy log std Max           0.10265857
Policy log std Min           -1.1806719
Z mean eval                  0.039820056
Z variance eval              0.005202382
total_rewards                [1003.16517571 2279.89524416 1613.89593725  969.03107861 2255.79859602
 3298.81646986  945.36511323 1990.36391935  977.80299062 2503.92385872]
total_rewards_mean           1783.8058383525408
total_rewards_std            773.3127341112588
total_rewards_max            3298.8164698592705
total_rewards_min            945.3651132295304
Number of train steps total  466000
Number of env steps total    2332000
Number of rollouts total     0
Train Time (s)               43.37815560027957
(Previous) Eval Time (s)     19.41433356422931
Sample Time (s)              21.076353740878403
Epoch Time (s)               83.86884290538728
Total Train Time (s)         38227.371189386584
Epoch                        465
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:25:28.203406 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #465 | Epoch Duration: 81.7356538772583
2020-01-11 11:25:28.203527 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #465 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03933625
Z variance train             0.005190739
KL Divergence                10.735617
KL Loss                      1.0735617
QF Loss                      319.224
VF Loss                      861.66046
Policy Loss                  -1592.0017
Q Predictions Mean           1590.6447
Q Predictions Std            156.64388
Q Predictions Max            1745.4637
Q Predictions Min            544.37537
V Predictions Mean           1607.3507
V Predictions Std            162.96262
V Predictions Max            1757.834
V Predictions Min            434.78094
Log Pis Mean                 -0.5884214
Log Pis Std                  1.9079884
Log Pis Max                  9.945863
Log Pis Min                  -8.165806
Policy mu Mean               -0.0064296997
Policy mu Std                0.7749443
Policy mu Max                2.3998077
Policy mu Min                -3.0875049
Policy log std Mean          -0.43151355
Policy log std Std           0.16267677
Policy log std Max           -0.042580485
Policy log std Min           -1.1590601
Z mean eval                  0.024553308
Z variance eval              0.0053873835
total_rewards                [1233.75416822 3306.06847588  940.81314434 1985.76950126  859.84588738
 1786.69781707  918.25571264 3115.93097711 1002.18467968 3345.49334883]
total_rewards_mean           1849.4813712408063
total_rewards_std            987.6931659456761
total_rewards_max            3345.4933488322135
total_rewards_min            859.8458873844653
Number of train steps total  467000
Number of env steps total    2337000
Number of rollouts total     0
Train Time (s)               44.348359948024154
(Previous) Eval Time (s)     17.280888291075826
Sample Time (s)              21.592600067146122
Epoch Time (s)               83.2218483062461
Total Train Time (s)         38311.62386131752
Epoch                        466
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:26:52.464939 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #466 | Epoch Duration: 84.26131844520569
2020-01-11 11:26:52.465064 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #466 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024963934
Z variance train             0.005382416
KL Divergence                10.689629
KL Loss                      1.0689629
QF Loss                      256.30618
VF Loss                      90.26051
Policy Loss                  -1591.0985
Q Predictions Mean           1594.8816
Q Predictions Std            166.77031
Q Predictions Max            1762.7941
Q Predictions Min            691.22754
V Predictions Mean           1588.9972
V Predictions Std            165.37477
V Predictions Max            1766.2523
V Predictions Min            682.97034
Log Pis Mean                 -0.49828643
Log Pis Std                  1.9870515
Log Pis Max                  9.428129
Log Pis Min                  -4.3298545
Policy mu Mean               4.8739216e-06
Policy mu Std                0.8198267
Policy mu Max                2.2885106
Policy mu Min                -3.49101
Policy log std Mean          -0.44938278
Policy log std Std           0.18902887
Policy log std Max           0.03125617
Policy log std Min           -1.336013
Z mean eval                  0.028305799
Z variance eval              0.006048495
total_rewards                [ 971.53392516 3385.46874761 3354.87496031 1012.11254941 3346.16057105
 1566.01315005 3359.97779349 1259.57070198  929.58541991 2747.62161219]
total_rewards_mean           2193.2919431167566
total_rewards_std            1073.2310841321769
total_rewards_max            3385.4687476103904
total_rewards_min            929.5854199105897
Number of train steps total  468000
Number of env steps total    2342000
Number of rollouts total     0
Train Time (s)               43.948375263717026
(Previous) Eval Time (s)     18.32009903760627
Sample Time (s)              21.966536218766123
Epoch Time (s)               84.23501052008942
Total Train Time (s)         38397.001580820885
Epoch                        467
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:28:17.849634 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #467 | Epoch Duration: 85.38445019721985
2020-01-11 11:28:17.849830 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #467 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.027747337
Z variance train             0.006055789
KL Divergence                10.453645
KL Loss                      1.0453645
QF Loss                      62.617622
VF Loss                      99.959724
Policy Loss                  -1596.1155
Q Predictions Mean           1597.6685
Q Predictions Std            144.62512
Q Predictions Max            1750.4442
Q Predictions Min            705.0338
V Predictions Mean           1602.3253
V Predictions Std            143.8595
V Predictions Max            1762.5309
V Predictions Min            723.5567
Log Pis Mean                 -0.77600706
Log Pis Std                  1.6277945
Log Pis Max                  6.770405
Log Pis Min                  -4.7188244
Policy mu Mean               -0.10925663
Policy mu Std                0.751388
Policy mu Max                2.4090922
Policy mu Min                -3.1858153
Policy log std Mean          -0.4313991
Policy log std Std           0.16053855
Policy log std Max           -0.046330005
Policy log std Min           -1.3925223
Z mean eval                  0.06467513
Z variance eval              0.00581799
total_rewards                [3320.10881529 1795.40254463 3325.43884664 3398.44617805 3215.1387248
 1043.31414276 1285.05571735 3090.95361805 1402.3374599  1045.16478293]
total_rewards_mean           2292.136083039481
total_rewards_std            1000.2798718092117
total_rewards_max            3398.446178051683
total_rewards_min            1043.3141427636813
Number of train steps total  469000
Number of env steps total    2347000
Number of rollouts total     0
Train Time (s)               44.132700093090534
(Previous) Eval Time (s)     19.469287319108844
Sample Time (s)              20.47040459467098
Epoch Time (s)               84.07239200687036
Total Train Time (s)         38481.9486889136
Epoch                        468
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:29:42.805497 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #468 | Epoch Duration: 84.95551776885986
2020-01-11 11:29:42.805667 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #468 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.06482526
Z variance train             0.0058150594
KL Divergence                10.678534
KL Loss                      1.0678533
QF Loss                      103.70029
VF Loss                      49.026894
Policy Loss                  -1601.1481
Q Predictions Mean           1602.8179
Q Predictions Std            160.14366
Q Predictions Max            1766.0002
Q Predictions Min            91.37987
V Predictions Mean           1597.967
V Predictions Std            158.05122
V Predictions Max            1758.0232
V Predictions Min            130.1712
Log Pis Mean                 -0.66402304
Log Pis Std                  1.7009732
Log Pis Max                  7.3076334
Log Pis Min                  -4.379617
Policy mu Mean               0.037500326
Policy mu Std                0.7483803
Policy mu Max                1.5923396
Policy mu Min                -3.085201
Policy log std Mean          -0.4310182
Policy log std Std           0.17029312
Policy log std Max           -0.06891939
Policy log std Min           -1.2223043
Z mean eval                  0.031845987
Z variance eval              0.005472172
total_rewards                [ 954.94915804 3231.95917533 2395.83724626 2698.19927421 1825.8678584
 1231.73188976 2132.73835883 1215.60393896 3342.94144594 2035.28086952]
total_rewards_mean           2106.51092152522
total_rewards_std            787.322632174323
total_rewards_max            3342.9414459380014
total_rewards_min            954.9491580403426
Number of train steps total  470000
Number of env steps total    2352000
Number of rollouts total     0
Train Time (s)               44.28959732502699
(Previous) Eval Time (s)     20.35218335269019
Sample Time (s)              21.801901194266975
Epoch Time (s)               86.44368187198415
Total Train Time (s)         38568.54349822644
Epoch                        469
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:31:09.403488 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #469 | Epoch Duration: 86.59770250320435
2020-01-11 11:31:09.403614 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #469 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03167949
Z variance train             0.0054753534
KL Divergence                10.698907
KL Loss                      1.0698907
QF Loss                      124.32557
VF Loss                      48.12812
Policy Loss                  -1592.0292
Q Predictions Mean           1588.5667
Q Predictions Std            150.37076
Q Predictions Max            1743.7773
Q Predictions Min            661.83685
V Predictions Mean           1596.3942
V Predictions Std            148.77242
V Predictions Max            1752.6744
V Predictions Min            693.03046
Log Pis Mean                 -0.7816746
Log Pis Std                  1.9277943
Log Pis Max                  8.178732
Log Pis Min                  -7.343575
Policy mu Mean               0.028466647
Policy mu Std                0.8002901
Policy mu Max                2.385359
Policy mu Min                -3.0852067
Policy log std Mean          -0.4287126
Policy log std Std           0.1768053
Policy log std Max           -0.03589821
Policy log std Min           -1.5566704
Z mean eval                  0.018882608
Z variance eval              0.0059959595
total_rewards                [1701.08043058 1792.17888016 1227.48019342 1287.911154   2319.28510355
 3390.16259969 1187.90132965 1013.20863416 2315.18353604 2068.9640879 ]
total_rewards_mean           1830.3355949142274
total_rewards_std            687.0511616517194
total_rewards_max            3390.1625996854236
total_rewards_min            1013.2086341592961
Number of train steps total  471000
Number of env steps total    2357000
Number of rollouts total     0
Train Time (s)               44.48940603993833
(Previous) Eval Time (s)     20.505970834288746
Sample Time (s)              21.453124444000423
Epoch Time (s)               86.4485013182275
Total Train Time (s)         38651.4974139519
Epoch                        470
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:32:32.360618 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #470 | Epoch Duration: 82.95690941810608
2020-01-11 11:32:32.360754 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #470 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.018919151
Z variance train             0.005994773
KL Divergence                10.451551
KL Loss                      1.0451552
QF Loss                      96.15448
VF Loss                      24.680943
Policy Loss                  -1589.6853
Q Predictions Mean           1590.0524
Q Predictions Std            203.6397
Q Predictions Max            1755.4979
Q Predictions Min            24.358486
V Predictions Mean           1588.7328
V Predictions Std            203.48982
V Predictions Max            1751.0688
V Predictions Min            20.747555
Log Pis Mean                 -0.3930388
Log Pis Std                  1.805016
Log Pis Max                  9.21253
Log Pis Min                  -4.30842
Policy mu Mean               -0.04487959
Policy mu Std                0.8194103
Policy mu Max                2.8172019
Policy mu Min                -3.2728698
Policy log std Mean          -0.43681684
Policy log std Std           0.18512456
Policy log std Max           0.022544324
Policy log std Min           -1.9457989
Z mean eval                  0.026705822
Z variance eval              0.006165122
total_rewards                [1741.30959584 2871.08600612 1536.49296921 1196.0648581   958.62780787
  978.91690843 2374.61867569 3383.12744492 1089.3243087  1254.47457853]
total_rewards_mean           1738.4043153413247
total_rewards_std            810.4396822200367
total_rewards_max            3383.127444915809
total_rewards_min            958.6278078722667
Number of train steps total  472000
Number of env steps total    2362000
Number of rollouts total     0
Train Time (s)               44.67121214000508
(Previous) Eval Time (s)     17.014131798874587
Sample Time (s)              21.251761380117387
Epoch Time (s)               82.93710531899706
Total Train Time (s)         38733.399993834086
Epoch                        471
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:33:54.268932 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #471 | Epoch Duration: 81.90806245803833
2020-01-11 11:33:54.269112 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #471 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026546266
Z variance train             0.0061690905
KL Divergence                10.405967
KL Loss                      1.0405967
QF Loss                      4061.1643
VF Loss                      860.13403
Policy Loss                  -1585.2949
Q Predictions Mean           1586.759
Q Predictions Std            204.91354
Q Predictions Max            1737.6976
Q Predictions Min            41.683388
V Predictions Mean           1592.6675
V Predictions Std            195.08788
V Predictions Max            1740.7072
V Predictions Min            6.9389963
Log Pis Mean                 -0.4065365
Log Pis Std                  2.4420578
Log Pis Max                  20.261787
Log Pis Min                  -4.649601
Policy mu Mean               -0.08466598
Policy mu Std                0.8809186
Policy mu Max                3.1116574
Policy mu Min                -4.9315805
Policy log std Mean          -0.39988807
Policy log std Std           0.1931594
Policy log std Max           -0.020143539
Policy log std Min           -1.7809504
Z mean eval                  0.032431263
Z variance eval              0.006120314
total_rewards                [2095.14604481 1282.23111378 3199.41655817 1175.19645064 3355.49500327
 3316.29959473 1829.56185219 1876.03138038 1240.83137072 1250.28574058]
total_rewards_mean           2062.049510927606
total_rewards_std            857.7576398479134
total_rewards_max            3355.495003269556
total_rewards_min            1175.196450644907
Number of train steps total  473000
Number of env steps total    2367000
Number of rollouts total     0
Train Time (s)               44.901605260092765
(Previous) Eval Time (s)     15.984805227722973
Sample Time (s)              21.560896852985024
Epoch Time (s)               82.44730734080076
Total Train Time (s)         38820.76050587278
Epoch                        472
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:35:21.632824 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #472 | Epoch Duration: 87.36357522010803
2020-01-11 11:35:21.632958 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #472 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032447886
Z variance train             0.006120625
KL Divergence                10.456136
KL Loss                      1.0456136
QF Loss                      145.36403
VF Loss                      40.992294
Policy Loss                  -1587.3743
Q Predictions Mean           1588.0214
Q Predictions Std            153.31694
Q Predictions Max            1762.4056
Q Predictions Min            63.137634
V Predictions Mean           1588.9867
V Predictions Std            154.43196
V Predictions Max            1764.8325
V Predictions Min            37.57732
Log Pis Mean                 -0.3562401
Log Pis Std                  2.1924129
Log Pis Max                  10.78471
Log Pis Min                  -4.7652183
Policy mu Mean               -0.030261777
Policy mu Std                0.88540334
Policy mu Max                2.643137
Policy mu Min                -3.4813836
Policy log std Mean          -0.43726954
Policy log std Std           0.18028769
Policy log std Max           -0.032936484
Policy log std Min           -1.5968575
Z mean eval                  0.02131763
Z variance eval              0.0064923353
total_rewards                [1773.4683681  3378.69606924 3325.09657581 3374.04000429 3361.9258706
 1260.21750755 3376.39645488 3355.80851653 2455.19385849 3380.21310798]
total_rewards_mean           2904.1056333470588
total_rewards_std            752.9216531359522
total_rewards_max            3380.213107977814
total_rewards_min            1260.2175075488499
Number of train steps total  474000
Number of env steps total    2372000
Number of rollouts total     0
Train Time (s)               44.56628241110593
(Previous) Eval Time (s)     20.90081677818671
Sample Time (s)              22.098418114241213
Epoch Time (s)               87.56551730353385
Total Train Time (s)         38915.433859357145
Epoch                        473
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:36:56.309591 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #473 | Epoch Duration: 94.676522731781
2020-01-11 11:36:56.309759 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #473 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.021402331
Z variance train             0.006491092
KL Divergence                10.234398
KL Loss                      1.0234398
QF Loss                      125.32503
VF Loss                      234.97726
Policy Loss                  -1580.2408
Q Predictions Mean           1580.2012
Q Predictions Std            173.28328
Q Predictions Max            1762.9427
Q Predictions Min            599.5532
V Predictions Mean           1572.6392
V Predictions Std            173.82147
V Predictions Max            1758.3281
V Predictions Min            591.2079
Log Pis Mean                 -0.62040704
Log Pis Std                  1.8596069
Log Pis Max                  8.09343
Log Pis Min                  -7.3644485
Policy mu Mean               0.011531522
Policy mu Std                0.8032857
Policy mu Max                2.6625125
Policy mu Min                -3.2200513
Policy log std Mean          -0.41465285
Policy log std Std           0.17046544
Policy log std Max           -0.056069165
Policy log std Min           -1.1029048
Z mean eval                  0.041731805
Z variance eval              0.007844637
total_rewards                [3304.45631575 3334.73363004 1579.5661924  3338.33138027 2330.18810539
 3345.47640217  991.3706393  2416.17000262 3281.38481254 3313.46726143]
total_rewards_mean           2723.514474191157
total_rewards_std            818.1252071611385
total_rewards_max            3345.4764021665483
total_rewards_min            991.3706393037467
Number of train steps total  475000
Number of env steps total    2377000
Number of rollouts total     0
Train Time (s)               43.924478555098176
(Previous) Eval Time (s)     28.011559715028852
Sample Time (s)              21.674996059853584
Epoch Time (s)               93.61103432998061
Total Train Time (s)         39006.09585759556
Epoch                        474
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:38:26.980796 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #474 | Epoch Duration: 90.67090582847595
2020-01-11 11:38:26.980956 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #474 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.04091321
Z variance train             0.007853009
KL Divergence                9.693945
KL Loss                      0.9693945
QF Loss                      72.85878
VF Loss                      139.12723
Policy Loss                  -1599.2039
Q Predictions Mean           1597.8071
Q Predictions Std            140.54979
Q Predictions Max            1754.4834
Q Predictions Min            669.60565
V Predictions Mean           1601.8145
V Predictions Std            141.79701
V Predictions Max            1751.9419
V Predictions Min            673.1277
Log Pis Mean                 -0.56636214
Log Pis Std                  1.8763988
Log Pis Max                  9.576909
Log Pis Min                  -4.3395877
Policy mu Mean               -0.01786303
Policy mu Std                0.7833121
Policy mu Max                2.078257
Policy mu Min                -3.0811398
Policy log std Mean          -0.4352995
Policy log std Std           0.18076803
Policy log std Max           -0.03548315
Policy log std Min           -1.2853885
Z mean eval                  0.040193684
Z variance eval              0.00631067
total_rewards                [1784.41596646 1818.12308398 1064.52728244 1798.68057562  917.55996648
 3310.60260196 2865.73089248 1206.60666243 3310.65479222 3410.48036959]
total_rewards_mean           2148.738219366348
total_rewards_std            935.3904668696986
total_rewards_max            3410.4803695879345
total_rewards_min            917.5599664809102
Number of train steps total  476000
Number of env steps total    2382000
Number of rollouts total     0
Train Time (s)               44.14155068201944
(Previous) Eval Time (s)     25.071165257133543
Sample Time (s)              21.995008398313075
Epoch Time (s)               91.20772433746606
Total Train Time (s)         39094.384524723515
Epoch                        475
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:39:55.269261 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #475 | Epoch Duration: 88.28818988800049
2020-01-11 11:39:55.269383 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #475 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040007375
Z variance train             0.006324249
KL Divergence                10.27408
KL Loss                      1.027408
QF Loss                      119.90073
VF Loss                      224.17834
Policy Loss                  -1578.4968
Q Predictions Mean           1578.9353
Q Predictions Std            197.23781
Q Predictions Max            1783.6617
Q Predictions Min            -20.00339
V Predictions Mean           1566.3064
V Predictions Std            195.74911
V Predictions Max            1768.1166
V Predictions Min            -3.8722522
Log Pis Mean                 -0.5581944
Log Pis Std                  1.8132107
Log Pis Max                  7.9833345
Log Pis Min                  -4.797927
Policy mu Mean               -0.10398536
Policy mu Std                0.8271082
Policy mu Max                1.8834062
Policy mu Min                -3.0291836
Policy log std Mean          -0.42465243
Policy log std Std           0.18141492
Policy log std Max           -0.0061784387
Policy log std Min           -1.2299169
Z mean eval                  0.022703683
Z variance eval              0.0056710485
total_rewards                [3398.44424145 1832.12829523 2398.41425127  981.66993578 3345.05592303
 2116.19326134 1357.05322685 3293.71702688 1272.80323467  524.6618387 ]
total_rewards_mean           2052.0141235187853
total_rewards_std            988.3168006800832
total_rewards_max            3398.444241446876
total_rewards_min            524.6618386972833
Number of train steps total  477000
Number of env steps total    2387000
Number of rollouts total     0
Train Time (s)               44.77072752872482
(Previous) Eval Time (s)     22.151385870296508
Sample Time (s)              21.375520029105246
Epoch Time (s)               88.29763342812657
Total Train Time (s)         39179.49312423542
Epoch                        476
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:41:20.388762 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #476 | Epoch Duration: 85.11927103996277
2020-01-11 11:41:20.388936 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #476 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.023458418
Z variance train             0.0056771925
KL Divergence                10.652408
KL Loss                      1.0652407
QF Loss                      146.84744
VF Loss                      116.69038
Policy Loss                  -1583.062
Q Predictions Mean           1580.0726
Q Predictions Std            199.81073
Q Predictions Max            1770.6288
Q Predictions Min            21.588293
V Predictions Mean           1580.7996
V Predictions Std            196.43393
V Predictions Max            1778.5564
V Predictions Min            11.089067
Log Pis Mean                 -0.45689505
Log Pis Std                  1.9917428
Log Pis Max                  9.0755
Log Pis Min                  -4.6752534
Policy mu Mean               -0.12509553
Policy mu Std                0.81281036
Policy mu Max                3.208358
Policy mu Min                -3.2564232
Policy log std Mean          -0.43560863
Policy log std Std           0.18266045
Policy log std Max           -0.077943996
Policy log std Min           -1.464717
Z mean eval                  0.03371198
Z variance eval              0.0068192966
total_rewards                [2047.14844024 3335.40720994 3332.73738459 3319.84615176 3330.12144991
 1036.39042607 3357.75485964 1326.94459226 3339.73510745 3334.38690506]
total_rewards_mean           2776.0472526914746
total_rewards_std            886.0570919576809
total_rewards_max            3357.754859642148
total_rewards_min            1036.390426065428
Number of train steps total  478000
Number of env steps total    2392000
Number of rollouts total     0
Train Time (s)               44.24505592789501
(Previous) Eval Time (s)     18.972797507885844
Sample Time (s)              21.946917563676834
Epoch Time (s)               85.16477099945769
Total Train Time (s)         39272.8736868687
Epoch                        477
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:42:53.771226 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #477 | Epoch Duration: 93.38216972351074
2020-01-11 11:42:53.771350 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #477 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03236216
Z variance train             0.0068176603
KL Divergence                10.22064
KL Loss                      1.0220641
QF Loss                      103.02768
VF Loss                      53.97545
Policy Loss                  -1596.0597
Q Predictions Mean           1596.8782
Q Predictions Std            150.53888
Q Predictions Max            1765.0653
Q Predictions Min            760.9348
V Predictions Mean           1598.2189
V Predictions Std            150.63806
V Predictions Max            1768.0198
V Predictions Min            749.23834
Log Pis Mean                 -0.6167864
Log Pis Std                  1.8151612
Log Pis Max                  7.437038
Log Pis Min                  -4.1947403
Policy mu Mean               -0.10388612
Policy mu Std                0.77746415
Policy mu Max                2.1198642
Policy mu Min                -3.2860367
Policy log std Mean          -0.4156271
Policy log std Std           0.20430636
Policy log std Max           0.012547195
Policy log std Min           -1.5053349
Z mean eval                  0.026246693
Z variance eval              0.006298966
total_rewards                [1268.25262576 1041.67914604 1247.72607092  990.62051064  978.62177769
 1072.16167163 1217.47690087 1215.65855379 3297.3686503  3394.04722994]
total_rewards_mean           1572.3613137583293
total_rewards_std            892.637220412207
total_rewards_max            3394.0472299437884
total_rewards_min            978.6217776920324
Number of train steps total  479000
Number of env steps total    2397000
Number of rollouts total     0
Train Time (s)               44.74728161515668
(Previous) Eval Time (s)     27.18994884006679
Sample Time (s)              22.338778597302735
Epoch Time (s)               94.2760090525262
Total Train Time (s)         39354.56474262383
Epoch                        478
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:44:15.464775 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #478 | Epoch Duration: 81.69333219528198
2020-01-11 11:44:15.464898 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #478 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.026108354
Z variance train             0.006290353
KL Divergence                10.424361
KL Loss                      1.0424361
QF Loss                      293.9813
VF Loss                      110.70407
Policy Loss                  -1598.9785
Q Predictions Mean           1602.2197
Q Predictions Std            122.16969
Q Predictions Max            1748.826
Q Predictions Min            832.94183
V Predictions Mean           1598.46
V Predictions Std            123.04165
V Predictions Max            1748.8804
V Predictions Min            834.3662
Log Pis Mean                 -0.46031514
Log Pis Std                  1.7341832
Log Pis Max                  5.0097466
Log Pis Min                  -4.665149
Policy mu Mean               0.06213158
Policy mu Std                0.83636063
Policy mu Max                2.732247
Policy mu Min                -3.076935
Policy log std Mean          -0.43530068
Policy log std Std           0.1702686
Policy log std Max           -0.062075764
Policy log std Min           -1.643488
Z mean eval                  0.0500846
Z variance eval              0.0053098663
total_rewards                [1479.9153692  1034.38898958 1166.61604478 2110.0464695  1666.65091531
 1074.34017462 2819.99151786 1990.04772503 1016.93327811 3318.3497402 ]
total_rewards_mean           1767.7280224173949
total_rewards_std            755.9727542780776
total_rewards_max            3318.3497401955738
total_rewards_min            1016.933278108943
Number of train steps total  480000
Number of env steps total    2402000
Number of rollouts total     0
Train Time (s)               44.43149974476546
(Previous) Eval Time (s)     14.607020578812808
Sample Time (s)              21.752376671414822
Epoch Time (s)               80.79089699499309
Total Train Time (s)         39438.56049094023
Epoch                        479
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:45:39.463512 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #479 | Epoch Duration: 83.99852323532104
2020-01-11 11:45:39.463635 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #479 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0507492
Z variance train             0.005312594
KL Divergence                10.753181
KL Loss                      1.0753182
QF Loss                      513.10297
VF Loss                      116.67736
Policy Loss                  -1598.26
Q Predictions Mean           1602.2523
Q Predictions Std            154.19398
Q Predictions Max            1787.2701
Q Predictions Min            438.6907
V Predictions Mean           1597.8982
V Predictions Std            154.63094
V Predictions Max            1777.0217
V Predictions Min            444.77927
Log Pis Mean                 -0.5687648
Log Pis Std                  1.8951789
Log Pis Max                  9.162108
Log Pis Min                  -5.3588085
Policy mu Mean               0.086352944
Policy mu Std                0.797586
Policy mu Max                2.42915
Policy mu Min                -4.250392
Policy log std Mean          -0.4336517
Policy log std Std           0.1837741
Policy log std Max           -0.079017505
Policy log std Min           -1.3105437
Z mean eval                  0.024545033
Z variance eval              0.0057456912
total_rewards                [3397.80715926 1350.37927791 2616.99009819 1229.86997246 3386.12959924
 3187.12504184  976.81955432 3372.42335388 1143.56210434 3429.73458255]
total_rewards_mean           2409.0840744005764
total_rewards_std            1035.1252697890886
total_rewards_max            3429.734582553617
total_rewards_min            976.8195543245971
Number of train steps total  481000
Number of env steps total    2407000
Number of rollouts total     0
Train Time (s)               44.55571030406281
(Previous) Eval Time (s)     17.814392295200378
Sample Time (s)              22.35312554007396
Epoch Time (s)               84.72322813933715
Total Train Time (s)         39527.93880770821
Epoch                        480
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:47:08.849639 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #480 | Epoch Duration: 89.38589096069336
2020-01-11 11:47:08.849832 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #480 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.024932602
Z variance train             0.005741612
KL Divergence                10.504374
KL Loss                      1.0504373
QF Loss                      298.9395
VF Loss                      54.554176
Policy Loss                  -1582.1681
Q Predictions Mean           1582.3933
Q Predictions Std            153.13387
Q Predictions Max            1750.6616
Q Predictions Min            343.87076
V Predictions Mean           1585.6395
V Predictions Std            151.80635
V Predictions Max            1752.4197
V Predictions Min            382.95352
Log Pis Mean                 -0.5233352
Log Pis Std                  1.8700229
Log Pis Max                  10.009386
Log Pis Min                  -6.3067417
Policy mu Mean               -0.04284058
Policy mu Std                0.8038047
Policy mu Max                2.4437814
Policy mu Min                -2.9621263
Policy log std Mean          -0.4266542
Policy log std Std           0.18023618
Policy log std Max           0.044320792
Policy log std Min           -1.3863078
Z mean eval                  0.0345406
Z variance eval              0.005558816
total_rewards                [2485.99733104 3306.64440226 1133.21722019 3333.92683059 3330.55907436
 3301.16222675 3350.16015985 1089.73757486 3359.78667766 1013.76658266]
total_rewards_mean           2570.4958080208135
total_rewards_std            1007.776185446465
total_rewards_max            3359.7866776595683
total_rewards_min            1013.7665826597761
Number of train steps total  482000
Number of env steps total    2412000
Number of rollouts total     0
Train Time (s)               44.48274300713092
(Previous) Eval Time (s)     22.476806764956564
Sample Time (s)              23.283022926654667
Epoch Time (s)               90.24257269874215
Total Train Time (s)         39620.96431810036
Epoch                        481
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:48:41.877573 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #481 | Epoch Duration: 93.02760791778564
2020-01-11 11:48:41.877709 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #481 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035111103
Z variance train             0.0055551543
KL Divergence                10.662203
KL Loss                      1.0662203
QF Loss                      422.2978
VF Loss                      87.44145
Policy Loss                  -1573.8116
Q Predictions Mean           1576.6396
Q Predictions Std            143.95471
Q Predictions Max            1725.7427
Q Predictions Min            696.0955
V Predictions Mean           1573.9082
V Predictions Std            137.59834
V Predictions Max            1723.0846
V Predictions Min            725.6098
Log Pis Mean                 -0.49341196
Log Pis Std                  2.0483286
Log Pis Max                  7.4760203
Log Pis Min                  -5.4165354
Policy mu Mean               0.006893271
Policy mu Std                0.8411428
Policy mu Max                3.0857856
Policy mu Min                -3.122951
Policy log std Mean          -0.4237151
Policy log std Std           0.1837535
Policy log std Max           -0.00819245
Policy log std Min           -1.6893939
Z mean eval                  0.03539573
Z variance eval              0.0059864507
total_rewards                [3106.59961595 3331.27679943 3291.4361306  3332.0135283  1025.27222095
  956.5347288  3323.91525183 1173.26793194 3286.26028644 1440.65200252]
total_rewards_mean           2426.7228496761736
total_rewards_std            1051.6887025124024
total_rewards_max            3332.013528298851
total_rewards_min            956.5347288043041
Number of train steps total  483000
Number of env steps total    2417000
Number of rollouts total     0
Train Time (s)               43.872573339380324
(Previous) Eval Time (s)     25.261597925331444
Sample Time (s)              22.04772422509268
Epoch Time (s)               91.18189548980445
Total Train Time (s)         39710.02780556213
Epoch                        482
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:50:10.949998 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #482 | Epoch Duration: 89.07217764854431
2020-01-11 11:50:10.950177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #482 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.035526976
Z variance train             0.0059862644
KL Divergence                10.5114565
KL Loss                      1.0511457
QF Loss                      226.60504
VF Loss                      217.0901
Policy Loss                  -1594.9838
Q Predictions Mean           1592.7783
Q Predictions Std            155.48932
Q Predictions Max            1756.7552
Q Predictions Min            594.3246
V Predictions Mean           1589.0048
V Predictions Std            152.77646
V Predictions Max            1746.6289
V Predictions Min            619.2546
Log Pis Mean                 -0.8627136
Log Pis Std                  1.8501414
Log Pis Max                  5.870371
Log Pis Min                  -8.217597
Policy mu Mean               0.07422252
Policy mu Std                0.76739264
Policy mu Max                2.1770089
Policy mu Min                -3.223407
Policy log std Mean          -0.43655768
Policy log std Std           0.18193173
Policy log std Max           0.016509384
Policy log std Min           -1.3782719
Z mean eval                  0.032915678
Z variance eval              0.0056324657
total_rewards                [3247.25693568 2598.85940167 1299.99749857 2242.43268663 3317.0048685
 2687.37116682 1203.45753299 2713.31149027  971.40055991 1016.40897823]
total_rewards_mean           2129.750111927412
total_rewards_std            875.8111026616851
total_rewards_max            3317.0048684996427
total_rewards_min            971.4005599127989
Number of train steps total  484000
Number of env steps total    2422000
Number of rollouts total     0
Train Time (s)               45.00715429522097
(Previous) Eval Time (s)     23.151640705298632
Sample Time (s)              22.631556702312082
Epoch Time (s)               90.79035170283169
Total Train Time (s)         39798.669979656115
Epoch                        483
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:51:39.602168 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #483 | Epoch Duration: 88.65184569358826
2020-01-11 11:51:39.602346 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #483 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.033706192
Z variance train             0.0056355484
KL Divergence                10.69441
KL Loss                      1.0694411
QF Loss                      68.71708
VF Loss                      70.1354
Policy Loss                  -1600.0375
Q Predictions Mean           1600.2661
Q Predictions Std            146.7854
Q Predictions Max            1764.9564
Q Predictions Min            795.1664
V Predictions Mean           1595.2725
V Predictions Std            145.8095
V Predictions Max            1756.9927
V Predictions Min            794.52484
Log Pis Mean                 -0.68630147
Log Pis Std                  1.7709581
Log Pis Max                  5.8269286
Log Pis Min                  -4.5639315
Policy mu Mean               -0.03761283
Policy mu Std                0.7851166
Policy mu Max                2.0229323
Policy mu Min                -2.9419122
Policy log std Mean          -0.43078384
Policy log std Std           0.1944679
Policy log std Max           -0.002020508
Policy log std Min           -1.2043407
Z mean eval                  0.015113154
Z variance eval              0.0062797293
total_rewards                [2215.75757171 3336.67285926 3367.43033883 2341.06189789 1197.70353106
 3179.38180858 3386.19412071 3325.59296954 1194.13069164 3363.84430003]
total_rewards_mean           2690.7770089247438
total_rewards_std            852.6754601913832
total_rewards_max            3386.194120709699
total_rewards_min            1194.1306916387803
Number of train steps total  485000
Number of env steps total    2427000
Number of rollouts total     0
Train Time (s)               44.05919709475711
(Previous) Eval Time (s)     21.012847993988544
Sample Time (s)              21.194192287512124
Epoch Time (s)               86.26623737625778
Total Train Time (s)         39890.815355093684
Epoch                        484
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:53:11.751531 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #484 | Epoch Duration: 92.1490592956543
2020-01-11 11:53:11.751664 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #484 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015203002
Z variance train             0.0062852753
KL Divergence                10.419625
KL Loss                      1.0419625
QF Loss                      80.630646
VF Loss                      42.573364
Policy Loss                  -1612.113
Q Predictions Mean           1611.0671
Q Predictions Std            117.346886
Q Predictions Max            1763.7722
Q Predictions Min            943.55035
V Predictions Mean           1613.7812
V Predictions Std            116.87262
V Predictions Max            1773.649
V Predictions Min            931.0562
Log Pis Mean                 -0.55776143
Log Pis Std                  2.0745194
Log Pis Max                  10.856245
Log Pis Min                  -5.1836243
Policy mu Mean               -0.010108501
Policy mu Std                0.809138
Policy mu Max                1.903446
Policy mu Min                -3.8528895
Policy log std Mean          -0.4089975
Policy log std Std           0.19628264
Policy log std Max           0.03218025
Policy log std Min           -1.2417431
Z mean eval                  0.025279706
Z variance eval              0.004969645
total_rewards                [3402.77678062 3359.60205575 3372.51432671 1472.4682435  1199.70706009
 3360.09052739  969.40295003 3362.40774793 1020.06165025 3400.01055224]
total_rewards_mean           2491.9041894508237
total_rewards_std            1090.3025892142066
total_rewards_max            3402.776780615525
total_rewards_min            969.4029500326803
Number of train steps total  486000
Number of env steps total    2432000
Number of rollouts total     0
Train Time (s)               44.603486771695316
(Previous) Eval Time (s)     26.895427256822586
Sample Time (s)              22.24713866505772
Epoch Time (s)               93.74605269357562
Total Train Time (s)         39982.551466355566
Epoch                        485
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:54:43.492165 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #485 | Epoch Duration: 91.74040532112122
2020-01-11 11:54:43.492337 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #485 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.025207262
Z variance train             0.0049723256
KL Divergence                10.891911
KL Loss                      1.0891911
QF Loss                      77.08871
VF Loss                      52.682487
Policy Loss                  -1575.105
Q Predictions Mean           1574.067
Q Predictions Std            151.4004
Q Predictions Max            1743.9603
Q Predictions Min            685.9535
V Predictions Mean           1573.4463
V Predictions Std            152.47485
V Predictions Max            1738.5282
V Predictions Min            693.76324
Log Pis Mean                 -0.41078117
Log Pis Std                  2.0664155
Log Pis Max                  9.98921
Log Pis Min                  -4.5081844
Policy mu Mean               -0.038125027
Policy mu Std                0.819106
Policy mu Max                2.6459222
Policy mu Min                -3.3775818
Policy log std Mean          -0.40523902
Policy log std Std           0.18518862
Policy log std Max           0.03522247
Policy log std Min           -1.5414618
Z mean eval                  0.034820635
Z variance eval              0.005382019
total_rewards                [3339.32186095 3284.80194749 1049.93285497 3389.13383866 1228.00976244
 3361.27956787 1257.85763369 1248.11446733 3398.86289492 2342.99617476]
total_rewards_mean           2390.031100307341
total_rewards_std            1019.5684778759854
total_rewards_max            3398.862894918583
total_rewards_min            1049.9328549690888
Number of train steps total  487000
Number of env steps total    2437000
Number of rollouts total     0
Train Time (s)               44.03810505429283
(Previous) Eval Time (s)     24.88953877799213
Sample Time (s)              22.707901176065207
Epoch Time (s)               91.63554500835016
Total Train Time (s)         40072.24175354047
Epoch                        486
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:56:13.186797 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #486 | Epoch Duration: 89.69431805610657
2020-01-11 11:56:13.186984 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #486 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.03483317
Z variance train             0.005385071
KL Divergence                10.6901
KL Loss                      1.06901
QF Loss                      133.60196
VF Loss                      57.174614
Policy Loss                  -1594.8385
Q Predictions Mean           1595.6067
Q Predictions Std            151.9369
Q Predictions Max            1753.4154
Q Predictions Min            569.8961
V Predictions Mean           1591.0829
V Predictions Std            151.99225
V Predictions Max            1752.6011
V Predictions Min            570.06683
Log Pis Mean                 -0.6122068
Log Pis Std                  1.7577363
Log Pis Max                  7.176218
Log Pis Min                  -4.7100043
Policy mu Mean               -0.056545544
Policy mu Std                0.7767074
Policy mu Max                2.3483806
Policy mu Min                -3.440632
Policy log std Mean          -0.4103438
Policy log std Std           0.17868015
Policy log std Max           0.037930995
Policy log std Min           -1.2538476
Z mean eval                  0.016160633
Z variance eval              0.0063018044
total_rewards                [3349.69528222 3323.23815275 3333.78966976 3425.74590418 3414.67737915
 1218.77670733 3389.80894947 3314.38843049 3358.28245495 3399.73996003]
total_rewards_mean           3152.814289034063
total_rewards_std            645.7233111518601
total_rewards_max            3425.745904182641
total_rewards_min            1218.7767073310465
Number of train steps total  488000
Number of env steps total    2442000
Number of rollouts total     0
Train Time (s)               44.19953224668279
(Previous) Eval Time (s)     22.948066086042672
Sample Time (s)              21.96653296938166
Epoch Time (s)               89.11413130210713
Total Train Time (s)         40167.30448262254
Epoch                        487
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:57:48.254500 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #487 | Epoch Duration: 95.06736612319946
2020-01-11 11:57:48.254683 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #487 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.015499082
Z variance train             0.0063115517
KL Divergence                10.405137
KL Loss                      1.0405138
QF Loss                      143.55643
VF Loss                      90.95771
Policy Loss                  -1565.9283
Q Predictions Mean           1566.255
Q Predictions Std            168.847
Q Predictions Max            1758.2972
Q Predictions Min            535.28235
V Predictions Mean           1560.1853
V Predictions Std            167.90376
V Predictions Max            1743.8866
V Predictions Min            537.7574
Log Pis Mean                 -0.347448
Log Pis Std                  1.9738966
Log Pis Max                  8.101436
Log Pis Min                  -4.3538766
Policy mu Mean               -0.050385434
Policy mu Std                0.8549579
Policy mu Max                2.2057567
Policy mu Min                -3.2481709
Policy log std Mean          -0.44286215
Policy log std Std           0.20630768
Policy log std Max           0.037477612
Policy log std Min           -1.2355107
Z mean eval                  0.03178631
Z variance eval              0.005846373
total_rewards                [1775.22809906 1223.42250779 3352.19824311 3433.09900528  110.29641524
 3345.96455748 3345.19294478 3336.7224382  3303.33103449 1082.90244276]
total_rewards_mean           2430.8357688175715
total_rewards_std            1191.5672091074518
total_rewards_max            3433.0990052769757
total_rewards_min            110.29641524146088
Number of train steps total  489000
Number of env steps total    2447000
Number of rollouts total     0
Train Time (s)               44.743666369933635
(Previous) Eval Time (s)     28.901048209052533
Sample Time (s)              22.17640303168446
Epoch Time (s)               95.82111761067063
Total Train Time (s)         40258.19395518117
Epoch                        488
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 11:59:19.149211 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #488 | Epoch Duration: 90.89432144165039
2020-01-11 11:59:19.149463 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #488 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031422038
Z variance train             0.0058430876
KL Divergence                10.498688
KL Loss                      1.0498688
QF Loss                      125.316345
VF Loss                      118.7547
Policy Loss                  -1569.9464
Q Predictions Mean           1567.8877
Q Predictions Std            168.7709
Q Predictions Max            1790.3229
Q Predictions Min            219.3082
V Predictions Mean           1565.7244
V Predictions Std            170.7861
V Predictions Max            1785.324
V Predictions Min            193.04164
Log Pis Mean                 -0.48166895
Log Pis Std                  1.9282018
Log Pis Max                  8.515306
Log Pis Min                  -3.5483787
Policy mu Mean               0.10614216
Policy mu Std                0.80057293
Policy mu Max                2.502337
Policy mu Min                -3.171853
Policy log std Mean          -0.44373775
Policy log std Std           0.18742466
Policy log std Max           -0.06833136
Policy log std Min           -1.2214599
Z mean eval                  0.032098543
Z variance eval              0.0068218447
total_rewards                [3282.19411162 3272.02135312 3305.15127078 2891.12819025 3268.39789772
 3280.37457654 3327.32134811 3141.64061465 3340.62442839 3341.08693407]
total_rewards_mean           3244.9940725259485
total_rewards_std            129.8431775655827
total_rewards_max            3341.086934073185
total_rewards_min            2891.12819025464
Number of train steps total  490000
Number of env steps total    2452000
Number of rollouts total     0
Train Time (s)               44.43532662792131
(Previous) Eval Time (s)     23.973988614976406
Sample Time (s)              21.175531641580164
Epoch Time (s)               89.58484688447788
Total Train Time (s)         40356.13098983094
Epoch                        489
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:00:57.089117 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #489 | Epoch Duration: 97.93949913978577
2020-01-11 12:00:57.089265 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #489 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032099523
Z variance train             0.006827563
KL Divergence                10.184329
KL Loss                      1.018433
QF Loss                      43.253983
VF Loss                      22.804968
Policy Loss                  -1592.4012
Q Predictions Mean           1590.979
Q Predictions Std            135.63237
Q Predictions Max            1766.1378
Q Predictions Min            648.47
V Predictions Mean           1593.5853
V Predictions Std            136.30339
V Predictions Max            1768.7362
V Predictions Min            658.9903
Log Pis Mean                 -0.6624875
Log Pis Std                  1.8626785
Log Pis Max                  6.302866
Log Pis Min                  -5.8868093
Policy mu Mean               -0.0348597
Policy mu Std                0.7827309
Policy mu Max                1.9397523
Policy mu Min                -2.8630943
Policy log std Mean          -0.4087218
Policy log std Std           0.16881661
Policy log std Max           0.04025185
Policy log std Min           -1.1506994
Z mean eval                  0.032672547
Z variance eval              0.0067387857
total_rewards                [3390.86713105 3379.34976501 1086.75535269 3346.35645917 3397.6361058
 3412.57004972 3440.65625144 3355.81983501  960.9264702  1066.22473871]
total_rewards_mean           2683.7162158800356
total_rewards_std            1078.1103255803855
total_rewards_max            3440.6562514362145
total_rewards_min            960.9264701969818
Number of train steps total  491000
Number of env steps total    2457000
Number of rollouts total     0
Train Time (s)               44.71360935876146
(Previous) Eval Time (s)     32.32838522223756
Sample Time (s)              22.10190811380744
Epoch Time (s)               99.14390269480646
Total Train Time (s)         40446.88091314258
Epoch                        490
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:02:27.843564 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #490 | Epoch Duration: 90.75418257713318
2020-01-11 12:02:27.843742 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #490 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.032618605
Z variance train             0.0067345435
KL Divergence                10.131844
KL Loss                      1.0131844
QF Loss                      150.26035
VF Loss                      122.37718
Policy Loss                  -1564.1271
Q Predictions Mean           1565.1023
Q Predictions Std            188.60126
Q Predictions Max            1735.3121
Q Predictions Min            75.87108
V Predictions Mean           1561.4781
V Predictions Std            187.35498
V Predictions Max            1731.2952
V Predictions Min            146.65392
Log Pis Mean                 -0.6440798
Log Pis Std                  1.9056644
Log Pis Max                  7.3944736
Log Pis Min                  -4.27065
Policy mu Mean               -0.03452511
Policy mu Std                0.79776746
Policy mu Max                3.311732
Policy mu Min                -3.6401327
Policy log std Mean          -0.42582187
Policy log std Std           0.18934259
Policy log std Max           -0.02027613
Policy log std Min           -1.1850876
Z mean eval                  0.03139729
Z variance eval              0.00591907
total_rewards                [2933.73191893 1245.34774548 3383.83962883 2990.15969835 3405.19247962
 3342.74649751 1019.69952876 1815.28235594 2542.48105878 2958.97613888]
total_rewards_mean           2563.74570510746
total_rewards_std            845.2961661650562
total_rewards_max            3405.1924796173466
total_rewards_min            1019.699528759244
Number of train steps total  492000
Number of env steps total    2462000
Number of rollouts total     0
Train Time (s)               45.10637855017558
(Previous) Eval Time (s)     23.938417402096093
Sample Time (s)              21.87305481825024
Epoch Time (s)               90.91785077052191
Total Train Time (s)         40537.118788309395
Epoch                        491
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:03:58.087567 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #491 | Epoch Duration: 90.24367618560791
2020-01-11 12:03:58.087774 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #491 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.031102274
Z variance train             0.005911546
KL Divergence                10.616279
KL Loss                      1.0616279
QF Loss                      66.8978
VF Loss                      65.902596
Policy Loss                  -1599.025
Q Predictions Mean           1598.142
Q Predictions Std            145.75027
Q Predictions Max            1759.0308
Q Predictions Min            674.6327
V Predictions Mean           1594.2192
V Predictions Std            143.72562
V Predictions Max            1756.7521
V Predictions Min            676.9243
Log Pis Mean                 -0.5321752
Log Pis Std                  2.0057342
Log Pis Max                  10.182611
Log Pis Min                  -5.019034
Policy mu Mean               -0.037270073
Policy mu Std                0.80238676
Policy mu Max                2.5839038
Policy mu Min                -2.9707932
Policy log std Mean          -0.42095828
Policy log std Std           0.1825434
Policy log std Max           -0.03791192
Policy log std Min           -1.5064112
Z mean eval                  0.017194843
Z variance eval              0.006484691
total_rewards                [3129.38191089  873.36197254 2458.48058805 3284.20615138 3345.58711229
 3360.34667815 3395.52018294 3371.59547687 3343.38957373  896.56833648]
total_rewards_mean           2745.84379833368
total_rewards_std            967.1366189354569
total_rewards_max            3395.5201829428165
total_rewards_min            873.3619725400473
Number of train steps total  493000
Number of env steps total    2467000
Number of rollouts total     0
Train Time (s)               45.15211064508185
(Previous) Eval Time (s)     23.26398040028289
Sample Time (s)              21.95555431675166
Epoch Time (s)               90.3716453621164
Total Train Time (s)         40631.757693277206
Epoch                        492
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:05:32.729792 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #492 | Epoch Duration: 94.64186573028564
2020-01-11 12:05:32.729930 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #492 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.017004108
Z variance train             0.0064743273
KL Divergence                10.227785
KL Loss                      1.0227785
QF Loss                      60.845886
VF Loss                      62.588768
Policy Loss                  -1582.8038
Q Predictions Mean           1582.5265
Q Predictions Std            134.45946
Q Predictions Max            1756.2324
Q Predictions Min            921.3672
V Predictions Mean           1584.2307
V Predictions Std            133.87088
V Predictions Max            1762.3289
V Predictions Min            943.76733
Log Pis Mean                 -0.6610282
Log Pis Std                  1.8467772
Log Pis Max                  9.981168
Log Pis Min                  -5.43676
Policy mu Mean               -0.1114602
Policy mu Std                0.7640335
Policy mu Max                2.6346219
Policy mu Min                -3.2998188
Policy log std Mean          -0.4107599
Policy log std Std           0.16801612
Policy log std Max           -0.011649311
Policy log std Min           -1.3506209
Z mean eval                  0.051700473
Z variance eval              0.008081324
total_rewards                [3357.61584376 3343.44380504 3384.22676919 3359.92943785 3370.2178375
 1341.45297531 3346.17651043 3400.46819877  957.13573436 2125.41137928]
total_rewards_mean           2798.6078491492635
total_rewards_std            906.8454258193495
total_rewards_max            3400.4681987688764
total_rewards_min            957.135734361029
Number of train steps total  494000
Number of env steps total    2472000
Number of rollouts total     0
Train Time (s)               44.6788081410341
(Previous) Eval Time (s)     27.533962205052376
Sample Time (s)              22.260589766316116
Epoch Time (s)               94.47336011240259
Total Train Time (s)         40724.77107152203
Epoch                        493
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:07:05.748025 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #493 | Epoch Duration: 93.01790022850037
2020-01-11 12:07:05.748260 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #493 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05173541
Z variance train             0.008090822
KL Divergence                9.688862
KL Loss                      0.9688862
QF Loss                      214.4623
VF Loss                      64.40693
Policy Loss                  -1585.1953
Q Predictions Mean           1584.1073
Q Predictions Std            150.16022
Q Predictions Max            1720.1089
Q Predictions Min            700.42487
V Predictions Mean           1583.3326
V Predictions Std            151.30615
V Predictions Max            1720.8903
V Predictions Min            676.3397
Log Pis Mean                 -0.42750186
Log Pis Std                  2.0976772
Log Pis Max                  10.238341
Log Pis Min                  -5.3465996
Policy mu Mean               -0.109654985
Policy mu Std                0.84156376
Policy mu Max                2.9551816
Policy mu Min                -3.252159
Policy log std Mean          -0.43955675
Policy log std Std           0.18963866
Policy log std Max           -0.009786606
Policy log std Min           -1.3697684
Z mean eval                  0.04072684
Z variance eval              0.007813832
total_rewards                [3412.80687605 3432.75925184 1683.34933693 3399.7466963  1260.23714537
 1051.71764426 3418.19141135 1234.51951898 1174.61257364 3417.72432738]
total_rewards_mean           2348.566478209239
total_rewards_std            1078.346759027092
total_rewards_max            3432.7592518395836
total_rewards_min            1051.7176442583275
Number of train steps total  495000
Number of env steps total    2477000
Number of rollouts total     0
Train Time (s)               44.027247064281255
(Previous) Eval Time (s)     26.078233415726572
Sample Time (s)              21.22911149682477
Epoch Time (s)               91.3345919768326
Total Train Time (s)         40812.558037677314
Epoch                        494
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:08:33.541121 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #494 | Epoch Duration: 87.79270148277283
2020-01-11 12:08:33.541299 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #494 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.040821806
Z variance train             0.007806746
KL Divergence                9.822347
KL Loss                      0.98223466
QF Loss                      82.938705
VF Loss                      40.437164
Policy Loss                  -1588.0046
Q Predictions Mean           1589.385
Q Predictions Std            154.4753
Q Predictions Max            1754.9777
Q Predictions Min            492.40274
V Predictions Mean           1592.3416
V Predictions Std            154.00606
V Predictions Max            1763.1318
V Predictions Min            500.3038
Log Pis Mean                 -0.62857425
Log Pis Std                  1.8266008
Log Pis Max                  10.180255
Log Pis Min                  -4.4852257
Policy mu Mean               -0.07665717
Policy mu Std                0.7699134
Policy mu Max                2.0499637
Policy mu Min                -3.392565
Policy log std Mean          -0.40658164
Policy log std Std           0.16797154
Policy log std Max           0.09361875
Policy log std Min           -1.1203774
Z mean eval                  0.043753132
Z variance eval              0.007535752
total_rewards                [1378.91098403 1575.92096598 2446.80681343  910.59590899  753.29455614
 1031.36533565 1000.16543549 3206.56171763 3318.63031547 2909.82453168]
total_rewards_mean           1853.2076564485592
total_rewards_std            961.826739725879
total_rewards_max            3318.630315470916
total_rewards_min            753.2945561424276
Number of train steps total  496000
Number of env steps total    2482000
Number of rollouts total     0
Train Time (s)               44.545811555814
(Previous) Eval Time (s)     22.53609969187528
Sample Time (s)              22.03153358027339
Epoch Time (s)               89.11344482796267
Total Train Time (s)         40897.76185288699
Epoch                        495
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:09:58.744253 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #495 | Epoch Duration: 85.2028238773346
2020-01-11 12:09:58.744374 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #495 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.043694895
Z variance train             0.007550816
KL Divergence                9.881319
KL Loss                      0.98813194
QF Loss                      140.64716
VF Loss                      64.54732
Policy Loss                  -1571.1382
Q Predictions Mean           1569.8506
Q Predictions Std            190.83939
Q Predictions Max            1735.924
Q Predictions Min            -14.330564
V Predictions Mean           1575.0858
V Predictions Std            192.39224
V Predictions Max            1748.2935
V Predictions Min            -29.539076
Log Pis Mean                 -0.45486602
Log Pis Std                  1.9786334
Log Pis Max                  7.752437
Log Pis Min                  -4.6637936
Policy mu Mean               -0.18098567
Policy mu Std                0.8014455
Policy mu Max                1.8705552
Policy mu Min                -3.1454291
Policy log std Mean          -0.41546044
Policy log std Std           0.17903371
Policy log std Max           0.013889611
Policy log std Min           -1.0948875
Z mean eval                  0.05107529
Z variance eval              0.007888548
total_rewards                [ 187.03435453 1228.14266508 3404.74389143 3348.48126547 3313.69034378
 3347.89268188 3358.75498698  194.38438365 3353.28672384 1485.15497261]
total_rewards_mean           2322.156626925513
total_rewards_std            1318.4072438831793
total_rewards_max            3404.743891431855
total_rewards_min            187.0343545296379
Number of train steps total  497000
Number of env steps total    2487000
Number of rollouts total     0
Train Time (s)               44.05850703874603
(Previous) Eval Time (s)     18.625220635905862
Sample Time (s)              21.94613646855578
Epoch Time (s)               84.62986414320767
Total Train Time (s)         40985.974445813335
Epoch                        496
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:11:26.961253 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #496 | Epoch Duration: 88.21675777435303
2020-01-11 12:11:26.961421 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #496 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.05126732
Z variance train             0.007899689
KL Divergence                9.6847515
KL Loss                      0.96847516
QF Loss                      419.1424
VF Loss                      52.876667
Policy Loss                  -1592.3237
Q Predictions Mean           1593.2007
Q Predictions Std            131.82562
Q Predictions Max            1746.919
Q Predictions Min            869.3777
V Predictions Mean           1586.9597
V Predictions Std            130.78505
V Predictions Max            1740.6154
V Predictions Min            862.326
Log Pis Mean                 -0.7386975
Log Pis Std                  1.8158091
Log Pis Max                  9.557329
Log Pis Min                  -4.588715
Policy mu Mean               -0.011798084
Policy mu Std                0.7563419
Policy mu Max                3.5624292
Policy mu Min                -3.1876662
Policy log std Mean          -0.3967016
Policy log std Std           0.18814817
Policy log std Max           -0.026163995
Policy log std Min           -1.3037194
Z mean eval                  0.056580685
Z variance eval              0.009561444
total_rewards                [ 949.7737022   955.55425463 2357.002192   3389.07018637  680.66790195
 1014.1009047  3463.60163703  981.41022189 3468.45147991  953.99470083]
total_rewards_mean           1821.362718151077
total_rewards_std            1143.4361323872283
total_rewards_max            3468.451479908845
total_rewards_min            680.6679019477464
Number of train steps total  498000
Number of env steps total    2492000
Number of rollouts total     0
Train Time (s)               44.343569377902895
(Previous) Eval Time (s)     22.211867009289563
Sample Time (s)              21.708189125638455
Epoch Time (s)               88.26362551283091
Total Train Time (s)         41069.956090423744
Epoch                        497
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:12:50.945258 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #497 | Epoch Duration: 83.98371648788452
2020-01-11 12:12:50.945378 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #497 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.055217616
Z variance train             0.009565655
KL Divergence                9.256702
KL Loss                      0.92567027
QF Loss                      81.733376
VF Loss                      65.541275
Policy Loss                  -1575.0596
Q Predictions Mean           1576.9204
Q Predictions Std            168.79683
Q Predictions Max            1764.6014
Q Predictions Min            294.8545
V Predictions Mean           1577.2847
V Predictions Std            170.47647
V Predictions Max            1773.8588
V Predictions Min            260.28214
Log Pis Mean                 -0.51213515
Log Pis Std                  1.9779786
Log Pis Max                  8.399037
Log Pis Min                  -4.2907443
Policy mu Mean               0.003919056
Policy mu Std                0.81412935
Policy mu Max                3.0875676
Policy mu Min                -3.0722756
Policy log std Mean          -0.43664303
Policy log std Std           0.19763245
Policy log std Max           -0.047468007
Policy log std Min           -1.6052655
Z mean eval                  0.027103111
Z variance eval              0.008590585
total_rewards                [1675.98185109  718.923569    902.87672236 3405.69830141  847.45746108
 1210.34816835 3386.45335039 1810.71721217  294.68593016  910.65243417]
total_rewards_mean           1516.379500016802
total_rewards_std            1029.1590394865889
total_rewards_max            3405.698301405785
total_rewards_min            294.68593015867566
Number of train steps total  499000
Number of env steps total    2497000
Number of rollouts total     0
Train Time (s)               44.63232981506735
(Previous) Eval Time (s)     17.931716221850365
Sample Time (s)              22.187605537008494
Epoch Time (s)               84.75165157392621
Total Train Time (s)         41153.17374315858
Epoch                        498
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:14:14.165874 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #498 | Epoch Duration: 83.22040343284607
2020-01-11 12:14:14.165996 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #498 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.02534615
Z variance train             0.008602631
KL Divergence                9.472161
KL Loss                      0.94721615
QF Loss                      234.95416
VF Loss                      189.11095
Policy Loss                  -1584.592
Q Predictions Mean           1588.7104
Q Predictions Std            140.14471
Q Predictions Max            1766.675
Q Predictions Min            894.84973
V Predictions Mean           1584.2214
V Predictions Std            139.68837
V Predictions Max            1761.2002
V Predictions Min            871.6483
Log Pis Mean                 -0.42137325
Log Pis Std                  2.0166008
Log Pis Max                  8.840765
Log Pis Min                  -4.835064
Policy mu Mean               0.040860277
Policy mu Std                0.8257437
Policy mu Max                2.2420514
Policy mu Min                -3.4046497
Policy log std Mean          -0.4266615
Policy log std Std           0.16430415
Policy log std Max           0.13109171
Policy log std Min           -1.3110391
Z mean eval                  0.03143128
Z variance eval              0.009184889
total_rewards                [3397.33494967 3339.67267551 1482.98345651 3007.28318548 1188.30329285
 3357.95283367 3391.36454993 3353.73815616 2677.99377559 3371.14324966]
total_rewards_mean           2856.77701250232
total_rewards_std            793.7017065304718
total_rewards_max            3397.33494967071
total_rewards_min            1188.303292850121
Number of train steps total  500000
Number of env steps total    2502000
Number of rollouts total     0
Train Time (s)               43.635860552079976
(Previous) Eval Time (s)     16.40022307401523
Sample Time (s)              22.04705395642668
Epoch Time (s)               82.08313758252189
Total Train Time (s)         41246.91253012279
Epoch                        499
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:15:47.912677 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #499 | Epoch Duration: 93.74658751487732
2020-01-11 12:15:47.912804 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Iteration #499 | Started Training: True
2020-01-11 12:15:48.245956 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] Variant:
2020-01-11 12:15:48.246555 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] {
  "env_name": "HalfCheetah-v2",
  "n_train_tasks": 1,
  "n_eval_tasks": 1,
  "latent_size": 5,
  "net_size": 300,
  "path_to_weights": null,
  "env_params": {
    "n_tasks": 2,
    "randomize_tasks": true
  },
  "algo_params": {
    "meta_batch": 1,
    "num_iterations": 500,
    "num_initial_steps": 2000,
    "num_tasks_sample": 5,
    "num_steps_prior": 400,
    "num_steps_posterior": 0,
    "num_extra_rl_steps_posterior": 600,
    "num_train_steps_per_itr": 1000,
    "num_evals": 2,
    "num_steps_per_eval": 600,
    "batch_size": 256,
    "embedding_batch_size": 20,
    "embedding_mini_batch_size": 20,
    "max_path_length": 200,
    "discount": 0.99,
    "soft_target_tau": 0.005,
    "policy_lr": 0.0003,
    "qf_lr": 0.0003,
    "vf_lr": 0.0003,
    "context_lr": 0.0003,
    "reward_scale": 5.0,
    "sparse_rewards": false,
    "kl_lambda": 0.1,
    "use_information_bottleneck": true,
    "use_next_obs_in_context": false,
    "update_post_train": 1,
    "num_exp_traj_eval": 2,
    "recurrent": true,
    "dump_eval_paths": false
  },
  "util_params": {
    "base_log_dir": "./test/train1000/H-20_inverse-seed",
    "use_gpu": true,
    "gpu_id": 1,
    "debug": false,
    "docker": false,
    "num_iterations": 3000
  }
}
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.0020600972
Z variance train             0.69202816
KL Divergence                0.15040708
KL Loss                      0.015040708
QF Loss                      28.183
VF Loss                      15.911762
Policy Loss                  -3.9524562
Q Predictions Mean           -0.00330954
Q Predictions Std            0.0025812825
Q Predictions Max            0.003119661
Q Predictions Min            -0.009606319
V Predictions Mean           5.9093145e-05
V Predictions Std            0.0024167623
V Predictions Max            0.0058722943
V Predictions Min            -0.0071488265
Log Pis Mean                 -3.9758787
Log Pis Std                  0.5386233
Log Pis Max                  -2.552077
Log Pis Min                  -5.277665
Policy mu Mean               -9.328403e-05
Policy mu Std                0.0020495066
Policy mu Max                0.007327754
Policy mu Min                -0.0048345733
Policy log std Mean          -0.00030216295
Policy log std Std           0.0015193376
Policy log std Max           0.0043097665
Policy log std Min           -0.003943738
Z mean eval                  0.18584004
Z variance eval              0.30799332
total_rewards                [-209.75237883 -200.52026262 -177.23130825 -167.54452311 -186.50713563
 -191.19055325 -167.23350191 -167.15963588 -182.70551887 -157.74649576]
total_rewards_mean           -180.75913141105792
total_rewards_std            15.688514848634444
total_rewards_max            -157.74649576028037
total_rewards_min            -209.7523788279863
Number of train steps total  1000
Number of env steps total    7000
Number of rollouts total     0
Train Time (s)               42.24196321005002
(Previous) Eval Time (s)     0
Sample Time (s)              30.262959756422788
Epoch Time (s)               72.5049229664728
Total Train Time (s)         105.48112335661426
Epoch                        0
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:17:33.823390 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #0 | Epoch Duration: 105.48710322380066
2020-01-11 12:17:33.823677 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #0 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.16559115
Z variance train             0.30562943
KL Divergence                1.3302995
KL Loss                      0.13302995
QF Loss                      12.327865
VF Loss                      3.5192213
Policy Loss                  -16.371422
Q Predictions Mean           12.9579735
Q Predictions Std            6.2498684
Q Predictions Max            29.620481
Q Predictions Min            -6.919672
V Predictions Mean           16.500942
V Predictions Std            5.595462
V Predictions Max            30.714216
V Predictions Min            -2.165135
Log Pis Mean                 -3.0824866
Log Pis Std                  1.3168906
Log Pis Max                  0.49670863
Log Pis Min                  -7.115242
Policy mu Mean               0.056227464
Policy mu Std                0.4509173
Policy mu Max                1.1253784
Policy mu Min                -1.2824268
Policy log std Mean          -0.2003717
Policy log std Std           0.08322352
Policy log std Max           -0.094599195
Policy log std Min           -0.4677144
Z mean eval                  0.30950513
Z variance eval              0.15528515
total_rewards                [-248.31617773 -251.37876513 -201.14882157 -212.3997642  -236.65337911
 -237.58134203 -224.93979461 -250.78461873 -248.1475152  -201.03185997]
total_rewards_mean           -231.23820382833233
total_rewards_std            19.097635912892873
total_rewards_max            -201.03185996873373
total_rewards_min            -251.3787651252597
Number of train steps total  2000
Number of env steps total    12000
Number of rollouts total     0
Train Time (s)               42.16188034089282
(Previous) Eval Time (s)     32.98200049530715
Sample Time (s)              20.7704764935188
Epoch Time (s)               95.91435732971877
Total Train Time (s)         200.70479990076274
Epoch                        1
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:19:09.044587 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #1 | Epoch Duration: 95.22071552276611
2020-01-11 12:19:09.044712 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #1 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.3095908
Z variance train             0.1552274
KL Divergence                2.8877683
KL Loss                      0.28877684
QF Loss                      28.534382
VF Loss                      4.261294
Policy Loss                  -29.617222
Q Predictions Mean           25.296654
Q Predictions Std            10.647309
Q Predictions Max            54.617996
Q Predictions Min            -14.917496
V Predictions Mean           28.97959
V Predictions Std            9.933784
V Predictions Max            57.860794
V Predictions Min            -5.908034
Log Pis Mean                 -3.3271968
Log Pis Std                  1.2098199
Log Pis Max                  1.4419845
Log Pis Min                  -7.258246
Policy mu Mean               0.1135541
Policy mu Std                0.38979638
Policy mu Max                1.3143734
Policy mu Min                -0.9772454
Policy log std Mean          -0.20843469
Policy log std Std           0.06674733
Policy log std Max           -0.063460186
Policy log std Min           -0.4690865
Z mean eval                  0.558038
Z variance eval              0.0816489
total_rewards                [-308.48214667 -236.20604511 -220.78454545 -285.96465983 -245.84911356
 -268.79605359 -245.72562265 -199.17705236 -250.92078715 -243.59187613]
total_rewards_mean           -250.549790250008
total_rewards_std            29.61095610771312
total_rewards_max            -199.17705236455774
total_rewards_min            -308.48214666784423
Number of train steps total  3000
Number of env steps total    17000
Number of rollouts total     0
Train Time (s)               43.24886351823807
(Previous) Eval Time (s)     32.28811395308003
Sample Time (s)              21.617964779026806
Epoch Time (s)               97.1549422503449
Total Train Time (s)         298.77745401859283
Epoch                        2
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:20:47.118075 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #2 | Epoch Duration: 98.07326865196228
2020-01-11 12:20:47.118200 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #2 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.54893386
Z variance train             0.08726196
KL Divergence                4.8524704
KL Loss                      0.48524705
QF Loss                      29.061104
VF Loss                      4.823239
Policy Loss                  -46.339714
Q Predictions Mean           42.183025
Q Predictions Std            13.1568365
Q Predictions Max            84.283646
Q Predictions Min            -0.1025891
V Predictions Mean           46.56375
V Predictions Std            12.467995
V Predictions Max            86.88575
V Predictions Min            6.473359
Log Pis Mean                 -3.2811937
Log Pis Std                  1.3717824
Log Pis Max                  1.0882809
Log Pis Min                  -7.5400743
Policy mu Mean               0.043214638
Policy mu Std                0.47027314
Policy mu Max                1.9189286
Policy mu Min                -1.5536793
Policy log std Mean          -0.20664339
Policy log std Std           0.076004475
Policy log std Max           -0.049106747
Policy log std Min           -0.6495507
Z mean eval                  0.753764
Z variance eval              0.06121973
total_rewards                [-143.78836915 -138.68591203 -112.81884455 -121.69072401 -127.97149908
 -209.06694622 -123.37751558 -156.05747855 -104.44968863 -119.70540432]
total_rewards_mean           -135.76123821072343
total_rewards_std            28.346472627427573
total_rewards_max            -104.44968862586441
total_rewards_min            -209.0669462172701
Number of train steps total  4000
Number of env steps total    22000
Number of rollouts total     0
Train Time (s)               42.96867426857352
(Previous) Eval Time (s)     33.20618709176779
Sample Time (s)              21.9429399385117
Epoch Time (s)               98.11780129885301
Total Train Time (s)         395.22616697242483
Epoch                        3
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:22:23.567994 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #3 | Epoch Duration: 96.44968152046204
2020-01-11 12:22:23.568123 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #3 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.7764463
Z variance train             0.052531708
KL Divergence                7.237256
KL Loss                      0.7237256
QF Loss                      43.32676
VF Loss                      10.039244
Policy Loss                  -63.192448
Q Predictions Mean           58.852
Q Predictions Std            15.130372
Q Predictions Max            113.83617
Q Predictions Min            9.308786
V Predictions Mean           64.5431
V Predictions Std            14.823861
V Predictions Max            113.81343
V Predictions Min            20.945656
Log Pis Mean                 -3.104137
Log Pis Std                  1.6060246
Log Pis Max                  2.8944268
Log Pis Min                  -7.5435195
Policy mu Mean               0.06680863
Policy mu Std                0.49880254
Policy mu Max                1.9226758
Policy mu Min                -1.372908
Policy log std Mean          -0.21119244
Policy log std Std           0.091725096
Policy log std Max           0.0024010278
Policy log std Min           -0.64928174
Z mean eval                  0.92060405
Z variance eval              0.051371843
total_rewards                [-188.52086373 -160.05642317 -147.70690989 -208.72723178 -133.73984975
 -156.9290255  -164.89975776 -125.04828521 -168.04285173 -193.47276985]
total_rewards_mean           -164.71439683565586
total_rewards_std            24.99284059854631
total_rewards_max            -125.04828520742674
total_rewards_min            -208.72723178178572
Number of train steps total  5000
Number of env steps total    27000
Number of rollouts total     0
Train Time (s)               43.3089035442099
(Previous) Eval Time (s)     31.537812333088368
Sample Time (s)              21.530327634885907
Epoch Time (s)               96.37704351218417
Total Train Time (s)         490.5649649677798
Epoch                        4
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:23:58.909286 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #4 | Epoch Duration: 95.34105110168457
2020-01-11 12:23:58.909469 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #4 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 0.92265236
Z variance train             0.051336445
KL Divergence                8.434088
KL Loss                      0.84340876
QF Loss                      35.216118
VF Loss                      8.430434
Policy Loss                  -74.90462
Q Predictions Mean           69.91186
Q Predictions Std            15.972688
Q Predictions Max            126.75994
Q Predictions Min            34.293987
V Predictions Mean           73.58263
V Predictions Std            15.714586
V Predictions Max            128.46939
V Predictions Min            36.665367
Log Pis Mean                 -2.8829134
Log Pis Std                  1.4986029
Log Pis Max                  3.7177806
Log Pis Min                  -6.833454
Policy mu Mean               0.06435246
Policy mu Std                0.51327604
Policy mu Max                1.9853638
Policy mu Min                -1.5592855
Policy log std Mean          -0.23384398
Policy log std Std           0.10498797
Policy log std Max           -0.0113859745
Policy log std Min           -0.7179337
Z mean eval                  1.0178843
Z variance eval              0.04250083
total_rewards                [-151.79513374 -162.93276438 -147.15128462 -145.74472617 -128.95805731
 -150.01460259 -192.21842933 -133.37765019 -128.87438563 -167.95424981]
total_rewards_mean           -150.90212837765387
total_rewards_std            18.59750413650274
total_rewards_max            -128.87438562965554
total_rewards_min            -192.21842933225838
Number of train steps total  6000
Number of env steps total    32000
Number of rollouts total     0
Train Time (s)               43.5812860801816
(Previous) Eval Time (s)     30.501552977599204
Sample Time (s)              20.07932383241132
Epoch Time (s)               94.16216289019212
Total Train Time (s)         587.2914257170632
Epoch                        5
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:25:35.635278 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #5 | Epoch Duration: 96.72567749023438
2020-01-11 12:25:35.635413 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #5 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0181682
Z variance train             0.042591345
KL Divergence                9.576448
KL Loss                      0.9576449
QF Loss                      39.25441
VF Loss                      8.310037
Policy Loss                  -86.86194
Q Predictions Mean           83.98616
Q Predictions Std            18.742405
Q Predictions Max            151.65579
Q Predictions Min            47.155373
V Predictions Mean           85.274796
V Predictions Std            18.601213
V Predictions Max            132.48674
V Predictions Min            46.928284
Log Pis Mean                 -3.1312184
Log Pis Std                  1.5873042
Log Pis Max                  2.9333131
Log Pis Min                  -6.9211426
Policy mu Mean               0.017812004
Policy mu Std                0.46540222
Policy mu Max                1.9541844
Policy mu Min                -1.9846884
Policy log std Mean          -0.21517003
Policy log std Std           0.101355664
Policy log std Max           -0.0061489344
Policy log std Min           -0.73644257
Z mean eval                  1.0568721
Z variance eval              0.04502411
total_rewards                [-107.83425917 -134.4388758  -117.44695325 -125.75032666  -73.35675248
  -84.37024071  -99.00594087  -53.99233715  -61.54109585 -126.99450769]
total_rewards_mean           -98.47312896343854
total_rewards_std            27.333514033836128
total_rewards_max            -53.99233714892616
total_rewards_min            -134.43887579708087
Number of train steps total  7000
Number of env steps total    37000
Number of rollouts total     0
Train Time (s)               44.387974727898836
(Previous) Eval Time (s)     33.06481331726536
Sample Time (s)              21.364508517086506
Epoch Time (s)               98.8172965622507
Total Train Time (s)         686.1522840294056
Epoch                        6
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:27:14.497373 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #6 | Epoch Duration: 98.86184525489807
2020-01-11 12:27:14.497553 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #6 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0613319
Z variance train             0.04488374
KL Divergence                10.342905
KL Loss                      1.0342906
QF Loss                      38.843193
VF Loss                      21.359701
Policy Loss                  -101.65652
Q Predictions Mean           97.68727
Q Predictions Std            23.980492
Q Predictions Max            163.92717
Q Predictions Min            57.86278
V Predictions Mean           98.7585
V Predictions Std            23.798973
V Predictions Max            166.61041
V Predictions Min            63.63736
Log Pis Mean                 -3.214964
Log Pis Std                  1.3896179
Log Pis Max                  1.9597057
Log Pis Min                  -6.3674264
Policy mu Mean               0.012315399
Policy mu Std                0.46292523
Policy mu Max                1.8960283
Policy mu Min                -1.7398049
Policy log std Mean          -0.23355329
Policy log std Std           0.10025261
Policy log std Max           0.090940714
Policy log std Min           -0.6785979
Z mean eval                  1.0979204
Z variance eval              0.04145319
total_rewards                [-45.95266423 -61.60290244 -71.36822087 -47.1051806  -13.1582554
 -50.81926584 -61.6739537  -82.97738117 -18.52707876 -43.53391899]
total_rewards_mean           -49.67188220003153
total_rewards_std            20.56463391918392
total_rewards_max            -13.158255402119606
total_rewards_min            -82.97738117328277
Number of train steps total  8000
Number of env steps total    42000
Number of rollouts total     0
Train Time (s)               43.162616645917296
(Previous) Eval Time (s)     33.10909095685929
Sample Time (s)              22.25908508663997
Epoch Time (s)               98.53079268941656
Total Train Time (s)         784.7431868975982
Epoch                        7
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:28:53.090500 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #7 | Epoch Duration: 98.59273481369019
2020-01-11 12:28:53.090759 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #7 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.0979568
Z variance train             0.041657664
KL Divergence                11.14563
KL Loss                      1.114563
QF Loss                      28.661596
VF Loss                      10.421909
Policy Loss                  -113.773964
Q Predictions Mean           109.389755
Q Predictions Std            26.95564
Q Predictions Max            188.39154
Q Predictions Min            72.94373
V Predictions Mean           114.68779
V Predictions Std            27.058546
V Predictions Max            197.47667
V Predictions Min            79.670876
Log Pis Mean                 -3.1573057
Log Pis Std                  1.4279749
Log Pis Max                  2.6324375
Log Pis Min                  -6.765694
Policy mu Mean               -0.03201894
Policy mu Std                0.46627107
Policy mu Max                1.9313345
Policy mu Min                -1.9017223
Policy log std Mean          -0.23636396
Policy log std Std           0.101216555
Policy log std Max           0.10597792
Policy log std Min           -0.70060575
Z mean eval                  1.1419532
Z variance eval              0.03755837
total_rewards                [-59.87330452 -17.83489846 -71.8545005  -10.9047206  -71.58403273
  -9.13220641 -36.87867087 -35.96536922 -22.75054316  -4.44734399]
total_rewards_mean           -34.12255904742957
total_rewards_std            24.372051984117
total_rewards_max            -4.447343992945109
total_rewards_min            -71.85450050443185
Number of train steps total  9000
Number of env steps total    47000
Number of rollouts total     0
Train Time (s)               42.691810810007155
(Previous) Eval Time (s)     33.17076000524685
Sample Time (s)              22.516645714640617
Epoch Time (s)               98.37921652989462
Total Train Time (s)         881.7194856475107
Epoch                        8
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:30:30.069834 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #8 | Epoch Duration: 96.97886943817139
2020-01-11 12:30:30.070137 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #8 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1372417
Z variance train             0.03777818
KL Divergence                11.72912
KL Loss                      1.172912
QF Loss                      31.659367
VF Loss                      7.179397
Policy Loss                  -117.81958
Q Predictions Mean           114.34748
Q Predictions Std            27.767927
Q Predictions Max            197.00972
Q Predictions Min            75.42309
V Predictions Mean           118.76131
V Predictions Std            28.36486
V Predictions Max            204.55684
V Predictions Min            84.16558
Log Pis Mean                 -3.267201
Log Pis Std                  1.4309007
Log Pis Max                  2.0273662
Log Pis Min                  -6.361932
Policy mu Mean               0.03513206
Policy mu Std                0.45367497
Policy mu Max                1.7903631
Policy mu Min                -1.9631909
Policy log std Mean          -0.22874789
Policy log std Std           0.107567474
Policy log std Max           0.08112313
Policy log std Min           -0.7886902
Z mean eval                  1.1606027
Z variance eval              0.045483314
total_rewards                [-15.07297906  -7.33435856 -10.24317321   8.00023741 -58.45675469
 -15.77935169  -8.01537386 -14.0461922  -16.23445675   1.0362501 ]
total_rewards_mean           -13.614615251334635
total_rewards_std            16.699370250394903
total_rewards_max            8.000237406874145
total_rewards_min            -58.4567546940165
Number of train steps total  10000
Number of env steps total    52000
Number of rollouts total     0
Train Time (s)               42.66581978695467
(Previous) Eval Time (s)     31.77016917290166
Sample Time (s)              21.60548312496394
Epoch Time (s)               96.04147208482027
Total Train Time (s)         979.2595014832914
Epoch                        9
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:32:07.608243 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #9 | Epoch Duration: 97.5378828048706
2020-01-11 12:32:07.608422 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #9 | Started Training: True
---------------------------  --------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1607916
Z variance train             0.0455797
KL Divergence                11.662987
KL Loss                      1.1662987
QF Loss                      29.607681
VF Loss                      8.75674
Policy Loss                  -129.58498
Q Predictions Mean           127.31658
Q Predictions Std            32.415054
Q Predictions Max            236.31355
Q Predictions Min            89.65092
V Predictions Mean           130.50073
V Predictions Std            32.65002
V Predictions Max            241.80768
V Predictions Min            92.4087
Log Pis Mean                 -3.2984648
Log Pis Std                  1.4175286
Log Pis Max                  1.2915066
Log Pis Min                  -7.524759
Policy mu Mean               0.007542758
Policy mu Std                0.46677092
Policy mu Max                1.7791708
Policy mu Min                -1.7558572
Policy log std Mean          -0.23715217
Policy log std Std           0.11719772
Policy log std Max           0.26493296
Policy log std Min           -0.76352626
Z mean eval                  1.1816143
Z variance eval              0.04508263
total_rewards                [ 6.11185369 51.75237034  9.24413526 64.9956963  52.55719444 39.08494432
  7.46589628 34.04390559 31.1594491  17.39348515]
total_rewards_mean           31.380893047804165
total_rewards_std            19.889735920234337
total_rewards_max            64.99569629637664
total_rewards_min            6.111853694534236
Number of train steps total  11000
Number of env steps total    57000
Number of rollouts total     0
Train Time (s)               42.36824020976201
(Previous) Eval Time (s)     33.266366666182876
Sample Time (s)              22.16512540495023
Epoch Time (s)               97.79973228089511
Total Train Time (s)         1074.651222480461
Epoch                        10
---------------------------  --------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:33:43.000370 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #10 | Epoch Duration: 95.39181804656982
2020-01-11 12:33:43.000509 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #10 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.1835927
Z variance train             0.045223754
KL Divergence                11.998756
KL Loss                      1.1998757
QF Loss                      32.248833
VF Loss                      7.871694
Policy Loss                  -142.76549
Q Predictions Mean           140.76733
Q Predictions Std            35.249115
Q Predictions Max            244.27731
Q Predictions Min            97.60948
V Predictions Mean           142.14252
V Predictions Std            35.167618
V Predictions Max            250.84715
V Predictions Min            100.46678
Log Pis Mean                 -3.1800642
Log Pis Std                  1.466007
Log Pis Max                  3.694059
Log Pis Min                  -6.7546625
Policy mu Mean               0.058144093
Policy mu Std                0.45798707
Policy mu Max                1.5080462
Policy mu Min                -1.9619982
Policy log std Mean          -0.22972734
Policy log std Std           0.114281006
Policy log std Max           0.27930713
Policy log std Min           -0.7352505
Z mean eval                  1.208993
Z variance eval              0.045823883
total_rewards                [272.9658942  181.14123446  79.07467    133.8316305  128.9309958
 167.64296372 168.42909512 177.0944402  187.36081143 113.57286621]
total_rewards_mean           161.00446016503946
total_rewards_std            49.72213636036173
total_rewards_max            272.965894198641
total_rewards_min            79.07467000315766
Number of train steps total  12000
Number of env steps total    62000
Number of rollouts total     0
Train Time (s)               42.3035854822956
(Previous) Eval Time (s)     30.85820125695318
Sample Time (s)              21.268086451105773
Epoch Time (s)               94.42987319035456
Total Train Time (s)         1167.793439622037
Epoch                        11
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:35:16.147177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #11 | Epoch Duration: 93.14648270606995
2020-01-11 12:35:16.147434 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #11 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2079556
Z variance train             0.045861937
KL Divergence                12.235235
KL Loss                      1.2235235
QF Loss                      30.506771
VF Loss                      9.51557
Policy Loss                  -152.44145
Q Predictions Mean           148.17366
Q Predictions Std            38.71521
Q Predictions Max            262.89227
Q Predictions Min            102.13195
V Predictions Mean           153.01993
V Predictions Std            39.79134
V Predictions Max            270.85574
V Predictions Min            103.26917
Log Pis Mean                 -3.1609511
Log Pis Std                  1.4801074
Log Pis Max                  2.3881633
Log Pis Min                  -8.005582
Policy mu Mean               0.0426883
Policy mu Std                0.47691208
Policy mu Max                2.172201
Policy mu Min                -1.8370585
Policy log std Mean          -0.23474894
Policy log std Std           0.10717843
Policy log std Max           0.22917502
Policy log std Min           -0.8652712
Z mean eval                  1.2277794
Z variance eval              0.04472827
total_rewards                [249.54219435 241.99780266 193.58951365 233.54665129 123.40303788
 251.02130087 179.99137319 290.52194408 237.95189856 230.49714685]
total_rewards_mean           223.2062863376139
total_rewards_std            44.084756055709946
total_rewards_max            290.5219440765163
total_rewards_min            123.4030378834662
Number of train steps total  13000
Number of env steps total    67000
Number of rollouts total     0
Train Time (s)               42.30710013723001
(Previous) Eval Time (s)     29.574527690187097
Sample Time (s)              21.614177708048373
Epoch Time (s)               93.49580553546548
Total Train Time (s)         1264.6672550505027
Epoch                        12
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:36:53.024243 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #12 | Epoch Duration: 96.87660026550293
2020-01-11 12:36:53.024558 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #12 | Started Training: True
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2270677
Z variance train             0.04472376
KL Divergence                12.672585
KL Loss                      1.2672585
QF Loss                      27.576317
VF Loss                      9.040525
Policy Loss                  -156.08661
Q Predictions Mean           153.14452
Q Predictions Std            38.082855
Q Predictions Max            281.83264
Q Predictions Min            108.399055
V Predictions Mean           156.49568
V Predictions Std            37.921284
V Predictions Max            277.76697
V Predictions Min            117.20155
Log Pis Mean                 -3.1251464
Log Pis Std                  1.3510581
Log Pis Max                  1.15365
Log Pis Min                  -6.6285667
Policy mu Mean               0.0315288
Policy mu Std                0.46606022
Policy mu Max                1.5845894
Policy mu Min                -1.8225046
Policy log std Mean          -0.22964394
Policy log std Std           0.103285536
Policy log std Max           0.19793047
Policy log std Min           -0.7842805
Z mean eval                  1.2334087
Z variance eval              0.050741185
total_rewards                [283.16278203 199.25185456 309.33779705 284.60992609 156.38972552
 202.50260768 262.73954623 255.95735192 280.21910777 386.52401349]
total_rewards_mean           262.06947123351773
total_rewards_std            61.40514371125438
total_rewards_max            386.524013491249
total_rewards_min            156.38972551853075
Number of train steps total  14000
Number of env steps total    72000
Number of rollouts total     0
Train Time (s)               42.61099339509383
(Previous) Eval Time (s)     32.95507546002045
Sample Time (s)              21.01467065513134
Epoch Time (s)               96.58073951024562
Total Train Time (s)         1360.5995521345176
Epoch                        13
---------------------------  ------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:38:28.956632 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #13 | Epoch Duration: 95.93184661865234
2020-01-11 12:38:28.956792 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #13 | Started Training: True
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2320352
Z variance train             0.050591785
KL Divergence                12.208779
KL Loss                      1.220878
QF Loss                      36.76989
VF Loss                      10.960081
Policy Loss                  -175.248
Q Predictions Mean           170.6648
Q Predictions Std            46.07423
Q Predictions Max            313.8325
Q Predictions Min            122.313675
V Predictions Mean           174.81021
V Predictions Std            45.80331
V Predictions Max            320.71243
V Predictions Min            127.4466
Log Pis Mean                 -2.9783516
Log Pis Std                  1.5033078
Log Pis Max                  1.5007019
Log Pis Min                  -6.666532
Policy mu Mean               0.012805298
Policy mu Std                0.49441925
Policy mu Max                1.6241202
Policy mu Min                -2.1117616
Policy log std Mean          -0.24656254
Policy log std Std           0.1254228
Policy log std Max           0.31772053
Policy log std Min           -0.8626399
Z mean eval                  1.2546648
Z variance eval              0.046989657
total_rewards                [368.14599353 551.47460327 479.21103138 304.17266708 519.3472135
 334.6984743  296.02615315 566.3024509  778.29124031 402.65537882]
total_rewards_mean           460.03252062452464
total_rewards_std            142.64076879890865
total_rewards_max            778.2912403144154
total_rewards_min            296.0261531526455
Number of train steps total  15000
Number of env steps total    77000
Number of rollouts total     0
Train Time (s)               43.10120340809226
(Previous) Eval Time (s)     32.30595307610929
Sample Time (s)              19.919198364950716
Epoch Time (s)               95.32635484915227
Total Train Time (s)         1453.7026953506283
Epoch                        14
---------------------------  -----------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:40:02.060016 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #14 | Epoch Duration: 93.10308194160461
2020-01-11 12:40:02.060203 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #14 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2574222
Z variance train             0.047022916
KL Divergence                12.526917
KL Loss                      1.2526917
QF Loss                      36.390167
VF Loss                      23.787
Policy Loss                  -187.41519
Q Predictions Mean           183.7345
Q Predictions Std            49.392025
Q Predictions Max            342.20676
Q Predictions Min            130.11653
V Predictions Mean           183.97731
V Predictions Std            49.881306
V Predictions Max            341.52216
V Predictions Min            129.51389
Log Pis Mean                 -2.9938405
Log Pis Std                  1.466527
Log Pis Max                  1.7879374
Log Pis Min                  -6.7233686
Policy mu Mean               0.018197922
Policy mu Std                0.52159256
Policy mu Max                1.7157183
Policy mu Min                -1.914024
Policy log std Mean          -0.26438263
Policy log std Std           0.1292547
Policy log std Max           0.19127452
Policy log std Min           -1.0364424
Z mean eval                  1.2737949
Z variance eval              0.048073187
total_rewards                [ 324.09429894  335.12848833  340.84343242  366.96223161  646.85367844
  835.09312417 1115.44310841  430.19168651  378.63944555  961.85738732]
total_rewards_mean           573.510688170678
total_rewards_std            281.54121093512686
total_rewards_max            1115.4431084063585
total_rewards_min            324.09429893924283
Number of train steps total  16000
Number of env steps total    82000
Number of rollouts total     0
Train Time (s)               42.072212557308376
(Previous) Eval Time (s)     30.082427410874516
Sample Time (s)              21.673911201301962
Epoch Time (s)               93.82855116948485
Total Train Time (s)         1549.1563392947428
Epoch                        15
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:41:37.515338 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #15 | Epoch Duration: 95.45493793487549
2020-01-11 12:41:37.515579 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #15 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.2731892
Z variance train             0.048077628
KL Divergence                13.153128
KL Loss                      1.3153127
QF Loss                      35.558628
VF Loss                      10.831697
Policy Loss                  -201.45845
Q Predictions Mean           198.48401
Q Predictions Std            61.341423
Q Predictions Max            403.41638
Q Predictions Min            132.80156
V Predictions Mean           202.65594
V Predictions Std            60.660152
V Predictions Max            404.85812
V Predictions Min            139.3603
Log Pis Mean                 -2.6592836
Log Pis Std                  1.7516173
Log Pis Max                  3.6335368
Log Pis Min                  -7.4293675
Policy mu Mean               0.019532805
Policy mu Std                0.55550194
Policy mu Max                1.8551294
Policy mu Min                -1.9014325
Policy log std Mean          -0.27483907
Policy log std Std           0.13503657
Policy log std Max           0.25802267
Policy log std Min           -1.0399631
Z mean eval                  1.3069807
Z variance eval              0.046694607
total_rewards                [ 773.98590825 1468.11113766 1625.96768342 1026.68685291  599.08758512
 1206.14656651 1570.48278279 1720.23511779 1612.74556764 1674.72759047]
total_rewards_mean           1327.8176792552258
total_rewards_std            382.915745431692
total_rewards_max            1720.2351177919156
total_rewards_min            599.0875851234638
Number of train steps total  17000
Number of env steps total    87000
Number of rollouts total     0
Train Time (s)               42.10780535824597
(Previous) Eval Time (s)     31.708558866288513
Sample Time (s)              19.872026523109525
Epoch Time (s)               93.68839074764401
Total Train Time (s)         1643.8396025388502
Epoch                        16
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:43:12.199247 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #16 | Epoch Duration: 94.68350601196289
2020-01-11 12:43:12.199431 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #16 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3068507
Z variance train             0.046612017
KL Divergence                13.563445
KL Loss                      1.3563446
QF Loss                      40.374428
VF Loss                      14.575862
Policy Loss                  -226.86494
Q Predictions Mean           222.65259
Q Predictions Std            76.50847
Q Predictions Max            415.65952
Q Predictions Min            129.33469
V Predictions Mean           227.1358
V Predictions Std            76.51096
V Predictions Max            434.5397
V Predictions Min            140.02516
Log Pis Mean                 -2.6116195
Log Pis Std                  1.9291317
Log Pis Max                  3.6538892
Log Pis Min                  -12.030105
Policy mu Mean               0.036597036
Policy mu Std                0.5841259
Policy mu Max                1.8888711
Policy mu Min                -1.9460658
Policy log std Mean          -0.28591633
Policy log std Std           0.13215803
Policy log std Max           0.14121822
Policy log std Min           -0.98576915
Z mean eval                  1.3331821
Z variance eval              0.039041124
total_rewards                [1916.57753348  568.78764664 2153.62798758 2154.41305608 1324.13718089
 1864.40850363 1935.04910215 2015.87413857 1157.8693063  2188.10974475]
total_rewards_mean           1727.8854200073554
total_rewards_std            508.57892261105684
total_rewards_max            2188.1097447514467
total_rewards_min            568.7876466359617
Number of train steps total  18000
Number of env steps total    92000
Number of rollouts total     0
Train Time (s)               42.7711774520576
(Previous) Eval Time (s)     32.70342986704782
Sample Time (s)              20.144336157478392
Epoch Time (s)               95.61894347658381
Total Train Time (s)         1736.4320395989344
Epoch                        17
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:44:44.792866 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #17 | Epoch Duration: 92.59329605102539
2020-01-11 12:44:44.793045 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #17 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.332936
Z variance train             0.0389629
KL Divergence                13.933081
KL Loss                      1.393308
QF Loss                      43.115383
VF Loss                      16.060017
Policy Loss                  -235.54831
Q Predictions Mean           231.72572
Q Predictions Std            88.57946
Q Predictions Max            460.36053
Q Predictions Min            146.3666
V Predictions Mean           236.00883
V Predictions Std            88.03071
V Predictions Max            460.78793
V Predictions Min            151.30215
Log Pis Mean                 -2.2603025
Log Pis Std                  2.0039499
Log Pis Max                  4.8563023
Log Pis Min                  -7.2395973
Policy mu Mean               0.06626826
Policy mu Std                0.6166891
Policy mu Max                2.233716
Policy mu Min                -2.0703816
Policy log std Mean          -0.29066566
Policy log std Std           0.14860824
Policy log std Max           -0.0016314387
Policy log std Min           -1.0322715
Z mean eval                  1.3701439
Z variance eval              0.033238254
total_rewards                [2354.28111817 2418.19780421 2311.8338507  2306.85915677 2319.28661064
  464.01333167 1212.98903057 2338.30813367 1430.45423874 2453.95206225]
total_rewards_mean           1961.0175337389578
total_rewards_std            648.2363437245234
total_rewards_max            2453.952062252085
total_rewards_min            464.0133316651063
Number of train steps total  19000
Number of env steps total    97000
Number of rollouts total     0
Train Time (s)               42.39368833322078
(Previous) Eval Time (s)     29.677535419818014
Sample Time (s)              20.067608659621328
Epoch Time (s)               92.13883241266012
Total Train Time (s)         1831.766337290872
Epoch                        18
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:46:20.126970 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #18 | Epoch Duration: 95.3337950706482
2020-01-11 12:46:20.127106 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #18 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3713998
Z variance train             0.033314634
KL Divergence                14.355921
KL Loss                      1.435592
QF Loss                      55.852654
VF Loss                      17.857512
Policy Loss                  -270.89783
Q Predictions Mean           266.40155
Q Predictions Std            100.397446
Q Predictions Max            508.59058
Q Predictions Min            163.2699
V Predictions Mean           269.35526
V Predictions Std            98.74502
V Predictions Max            497.2213
V Predictions Min            168.31602
Log Pis Mean                 -2.082341
Log Pis Std                  2.2511666
Log Pis Max                  8.544183
Log Pis Min                  -10.9767475
Policy mu Mean               0.05093154
Policy mu Std                0.69079363
Policy mu Max                2.0510473
Policy mu Min                -2.2593732
Policy log std Mean          -0.3302134
Policy log std Std           0.16345575
Policy log std Max           -0.06507003
Policy log std Min           -1.0522617
Z mean eval                  1.3988658
Z variance eval              0.03226484
total_rewards                [2427.89417958 2679.52528575 2501.96232065 2585.09543706 2464.11082209
 2612.2745451  2584.22805677 2494.07545404 2605.67878791 2546.20251824]
total_rewards_mean           2550.104740719544
total_rewards_std            73.41291610919005
total_rewards_max            2679.525285753112
total_rewards_min            2427.89417957559
Number of train steps total  20000
Number of env steps total    102000
Number of rollouts total     0
Train Time (s)               42.947358006145805
(Previous) Eval Time (s)     32.87226929701865
Sample Time (s)              21.883602315559983
Epoch Time (s)               97.70322961872444
Total Train Time (s)         1929.3250639033504
Epoch                        19
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:47:57.688885 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #19 | Epoch Duration: 97.56160640716553
2020-01-11 12:47:57.689128 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #19 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.3969795
Z variance train             0.032188494
KL Divergence                14.978494
KL Loss                      1.4978493
QF Loss                      44.22353
VF Loss                      19.815252
Policy Loss                  -280.6172
Q Predictions Mean           277.75757
Q Predictions Std            112.606766
Q Predictions Max            544.99835
Q Predictions Min            168.76175
V Predictions Mean           282.16754
V Predictions Std            113.47301
V Predictions Max            550.1002
V Predictions Min            174.89703
Log Pis Mean                 -1.9954413
Log Pis Std                  2.300026
Log Pis Max                  7.138862
Log Pis Min                  -7.584649
Policy mu Mean               0.066559315
Policy mu Std                0.6698342
Policy mu Max                2.2319143
Policy mu Min                -2.302606
Policy log std Mean          -0.330361
Policy log std Std           0.15515842
Policy log std Max           0.016320847
Policy log std Min           -1.0694513
Z mean eval                  1.4407095
Z variance eval              0.030914783
total_rewards                [2227.68912838 2090.81784224 2750.57789446 2764.41643719 2857.96789534
  981.01837828 2512.47921353 2889.58863    2922.95018308 2483.42228042]
total_rewards_mean           2448.0927882913397
total_rewards_std            558.022211652051
total_rewards_max            2922.950183076543
total_rewards_min            981.0183782805298
Number of train steps total  21000
Number of env steps total    107000
Number of rollouts total     0
Train Time (s)               42.49451812496409
(Previous) Eval Time (s)     32.73039839696139
Sample Time (s)              22.784715045709163
Epoch Time (s)               98.00963156763464
Total Train Time (s)         2027.3100720141083
Epoch                        20
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:49:35.673179 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #20 | Epoch Duration: 97.98391056060791
2020-01-11 12:49:35.673309 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #20 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4402459
Z variance train             0.030920345
KL Divergence                14.740303
KL Loss                      1.4740304
QF Loss                      77.01211
VF Loss                      20.950796
Policy Loss                  -322.4619
Q Predictions Mean           318.2886
Q Predictions Std            139.3641
Q Predictions Max            647.6665
Q Predictions Min            176.54297
V Predictions Mean           322.44772
V Predictions Std            139.29616
V Predictions Max            646.75684
V Predictions Min            181.09706
Log Pis Mean                 -1.5741367
Log Pis Std                  2.6301477
Log Pis Max                  8.580648
Log Pis Min                  -8.004488
Policy mu Mean               0.09951649
Policy mu Std                0.7310671
Policy mu Max                2.190695
Policy mu Min                -2.363791
Policy log std Mean          -0.35569277
Policy log std Std           0.16852129
Policy log std Max           -0.03988194
Policy log std Min           -1.3093686
Z mean eval                  1.4337538
Z variance eval              0.051154934
total_rewards                [2577.2221641  2597.38865375 2127.21964426 2553.29701086 2635.98652576
 1748.97087775 2660.2779425  2488.03899832 2649.54099843 2595.43411576]
total_rewards_mean           2463.337693146589
total_rewards_std            279.93779180341136
total_rewards_max            2660.27794249936
total_rewards_min            1748.9708777451065
Number of train steps total  22000
Number of env steps total    112000
Number of rollouts total     0
Train Time (s)               43.114227146841586
(Previous) Eval Time (s)     32.70444031525403
Sample Time (s)              22.011008651927114
Epoch Time (s)               97.82967611402273
Total Train Time (s)         2124.8140120147727
Epoch                        21
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:51:13.181889 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #21 | Epoch Duration: 97.5084342956543
2020-01-11 12:51:13.182177 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #21 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4348826
Z variance train             0.051005304
KL Divergence                13.688628
KL Loss                      1.3688629
QF Loss                      80.68423
VF Loss                      23.173033
Policy Loss                  -346.53867
Q Predictions Mean           343.6209
Q Predictions Std            150.69302
Q Predictions Max            640.82043
Q Predictions Min            177.68805
V Predictions Mean           346.72223
V Predictions Std            150.42761
V Predictions Max            636.2412
V Predictions Min            177.81708
Log Pis Mean                 -1.4201126
Log Pis Std                  2.5483716
Log Pis Max                  6.6180053
Log Pis Min                  -8.258106
Policy mu Mean               0.10870341
Policy mu Std                0.7253248
Policy mu Max                2.325253
Policy mu Min                -2.2543678
Policy log std Mean          -0.371331
Policy log std Std           0.17255661
Policy log std Max           -0.09147741
Policy log std Min           -1.2143077
Z mean eval                  1.4746153
Z variance eval              0.042634986
total_rewards                [2845.80362884 2893.33617203 2899.1189105  2895.43166859 2949.7832196
 2880.10551696 2951.32339746 2936.93438651 2865.95674059 2823.22069397]
total_rewards_mean           2894.10143350612
total_rewards_std            40.7207233987449
total_rewards_max            2951.3233974609852
total_rewards_min            2823.220693973689
Number of train steps total  23000
Number of env steps total    117000
Number of rollouts total     0
Train Time (s)               43.09139126073569
(Previous) Eval Time (s)     32.3829345991835
Sample Time (s)              21.354831613134593
Epoch Time (s)               96.82915747305378
Total Train Time (s)         2220.6476048659533
Epoch                        22
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:52:49.012852 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #22 | Epoch Duration: 95.83047795295715
2020-01-11 12:52:49.012991 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #22 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.4750243
Z variance train             0.042638432
KL Divergence                14.42005
KL Loss                      1.442005
QF Loss                      65.07955
VF Loss                      16.579695
Policy Loss                  -370.32285
Q Predictions Mean           364.97375
Q Predictions Std            169.06178
Q Predictions Max            703.5051
Q Predictions Min            185.68782
V Predictions Mean           368.95444
V Predictions Std            168.06778
V Predictions Max            698.9242
V Predictions Min            190.25488
Log Pis Mean                 -1.2532831
Log Pis Std                  2.495862
Log Pis Max                  5.549727
Log Pis Min                  -7.4365654
Policy mu Mean               0.1073413
Policy mu Std                0.75832653
Policy mu Max                2.0711715
Policy mu Min                -2.3818464
Policy log std Mean          -0.3846419
Policy log std Std           0.18187062
Policy log std Max           -0.08167314
Policy log std Min           -1.2568288
Z mean eval                  1.5220845
Z variance eval              0.03439974
total_rewards                [3068.92902256 2874.85444534 1104.89537187 3213.44738972 2918.40894962
 3104.08341211 2908.92818147 2960.87581186 1787.12983927 2825.92342263]
total_rewards_mean           2676.747584645047
total_rewards_std            643.5172597062459
total_rewards_max            3213.4473897206167
total_rewards_min            1104.895371869934
Number of train steps total  24000
Number of env steps total    122000
Number of rollouts total     0
Train Time (s)               42.9812594843097
(Previous) Eval Time (s)     31.38402487291023
Sample Time (s)              21.683006569277495
Epoch Time (s)               96.04829092649743
Total Train Time (s)         2317.3493792139925
Epoch                        23
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:54:25.716570 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #23 | Epoch Duration: 96.70348477363586
2020-01-11 12:54:25.716695 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #23 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5214757
Z variance train             0.034399014
KL Divergence                15.356363
KL Loss                      1.5356363
QF Loss                      86.39348
VF Loss                      17.51632
Policy Loss                  -407.3951
Q Predictions Mean           402.9383
Q Predictions Std            187.25491
Q Predictions Max            744.6842
Q Predictions Min            195.15234
V Predictions Mean           407.96094
V Predictions Std            186.45229
V Predictions Max            746.0808
V Predictions Min            203.17554
Log Pis Mean                 -1.3011489
Log Pis Std                  2.6717217
Log Pis Max                  8.488476
Log Pis Min                  -6.4356136
Policy mu Mean               0.095635585
Policy mu Std                0.7832526
Policy mu Max                3.028858
Policy mu Min                -2.4715254
Policy log std Mean          -0.39920008
Policy log std Std           0.18112087
Policy log std Max           -0.1036234
Policy log std Min           -1.2012184
Z mean eval                  1.5422484
Z variance eval              0.036072426
total_rewards                [3102.68658939 3100.47625311 3219.32227599 3022.94718176  687.5122642
 3146.86598966 3191.29314703 3168.8034992  3241.44862427 3052.05708953]
total_rewards_mean           2893.341291412474
total_rewards_std            738.2934552829313
total_rewards_max            3241.448624271655
total_rewards_min            687.5122641955594
Number of train steps total  25000
Number of env steps total    127000
Number of rollouts total     0
Train Time (s)               43.293173434212804
(Previous) Eval Time (s)     32.03896441170946
Sample Time (s)              21.43511241907254
Epoch Time (s)               96.7672502649948
Total Train Time (s)         2414.1288167624734
Epoch                        24
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:56:02.500429 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #24 | Epoch Duration: 96.78362512588501
2020-01-11 12:56:02.500602 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #24 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5442002
Z variance train             0.03611075
KL Divergence                15.63897
KL Loss                      1.563897
QF Loss                      115.99391
VF Loss                      21.889174
Policy Loss                  -426.1147
Q Predictions Mean           424.17957
Q Predictions Std            201.89757
Q Predictions Max            814.08746
Q Predictions Min            210.66583
V Predictions Mean           426.34274
V Predictions Std            198.69307
V Predictions Max            815.8374
V Predictions Min            213.97511
Log Pis Mean                 -1.1354558
Log Pis Std                  2.8598182
Log Pis Max                  7.474073
Log Pis Min                  -6.1769667
Policy mu Mean               0.07859081
Policy mu Std                0.7893187
Policy mu Max                2.2749133
Policy mu Min                -2.2572641
Policy log std Mean          -0.39531025
Policy log std Std           0.19104998
Policy log std Max           -0.119996905
Policy log std Min           -1.4175198
Z mean eval                  1.5877932
Z variance eval              0.030448034
total_rewards                [3046.45643943 3145.29303524 3023.7012785  3112.28882408 3204.08908387
 3216.00807392 3012.61119801 3106.68700723 3030.18903549 3093.6330734 ]
total_rewards_mean           3099.095704915676
total_rewards_std            69.11638186440432
total_rewards_max            3216.0080739218242
total_rewards_min            3012.6111980063947
Number of train steps total  26000
Number of env steps total    132000
Number of rollouts total     0
Train Time (s)               42.20840078499168
(Previous) Eval Time (s)     32.05512595595792
Sample Time (s)              20.991761366836727
Epoch Time (s)               95.25528810778633
Total Train Time (s)         2505.9166415324435
Epoch                        25
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:57:34.287362 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #25 | Epoch Duration: 91.78662061691284
2020-01-11 12:57:34.287542 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #25 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.5879084
Z variance train             0.030477792
KL Divergence                16.222404
KL Loss                      1.6222404
QF Loss                      102.902374
VF Loss                      29.149105
Policy Loss                  -462.8815
Q Predictions Mean           458.9621
Q Predictions Std            218.92155
Q Predictions Max            867.1898
Q Predictions Min            217.17345
V Predictions Mean           463.86685
V Predictions Std            219.13406
V Predictions Max            878.8083
V Predictions Min            220.54941
Log Pis Mean                 -1.122361
Log Pis Std                  2.573708
Log Pis Max                  7.2253137
Log Pis Min                  -6.745794
Policy mu Mean               -0.025069773
Policy mu Std                0.7971674
Policy mu Max                2.46408
Policy mu Min                -2.0529642
Policy log std Mean          -0.39240864
Policy log std Std           0.18601194
Policy log std Max           -0.070201725
Policy log std Min           -1.3447236
Z mean eval                  1.6264435
Z variance eval              0.023386572
total_rewards                [3423.94336701 3450.98343749 3398.96464205 3413.67293179 1679.80257134
 3390.73134695 3332.47804895 3420.84052158 3412.34547239 3244.35056325]
total_rewards_mean           3216.81129027973
total_rewards_std            515.3947403335997
total_rewards_max            3450.9834374937227
total_rewards_min            1679.802571336076
Number of train steps total  27000
Number of env steps total    137000
Number of rollouts total     0
Train Time (s)               42.16971834609285
(Previous) Eval Time (s)     28.586221844423562
Sample Time (s)              21.54930498590693
Epoch Time (s)               92.30524517642334
Total Train Time (s)         2601.143303928897
Epoch                        26
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 12:59:09.519063 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #26 | Epoch Duration: 95.23125004768372
2020-01-11 12:59:09.519492 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #26 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6261961
Z variance train             0.023336252
KL Divergence                17.209616
KL Loss                      1.7209616
QF Loss                      123.18682
VF Loss                      30.016088
Policy Loss                  -480.05936
Q Predictions Mean           472.97424
Q Predictions Std            237.87042
Q Predictions Max            882.9557
Q Predictions Min            223.6351
V Predictions Mean           481.00937
V Predictions Std            238.36607
V Predictions Max            880.4326
V Predictions Min            229.16469
Log Pis Mean                 -1.3092086
Log Pis Std                  2.5801399
Log Pis Max                  8.371778
Log Pis Min                  -6.103297
Policy mu Mean               0.052476365
Policy mu Std                0.7680616
Policy mu Max                2.415873
Policy mu Min                -2.2790542
Policy log std Mean          -0.38445655
Policy log std Std           0.18576057
Policy log std Max           -0.10632616
Policy log std Min           -1.3433657
Z mean eval                  1.6467371
Z variance eval              0.022244427
total_rewards                [3611.66325525 3539.06703021 3417.41692221 3474.74268673 3609.53298141
 3507.80599486 3754.72299195 3434.27222788 3566.29256822 3547.01023981]
total_rewards_mean           3546.2526898516817
total_rewards_std            93.76924673088803
total_rewards_max            3754.7229919526653
total_rewards_min            3417.416922206335
Number of train steps total  28000
Number of env steps total    142000
Number of rollouts total     0
Train Time (s)               42.527222691103816
(Previous) Eval Time (s)     31.511936719994992
Sample Time (s)              19.917980534490198
Epoch Time (s)               93.957139945589
Total Train Time (s)         2695.9869467737153
Epoch                        27
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:00:44.360772 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #27 | Epoch Duration: 94.84103059768677
2020-01-11 13:00:44.360918 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #27 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6473491
Z variance train             0.022244647
KL Divergence                17.757713
KL Loss                      1.7757714
QF Loss                      137.49762
VF Loss                      29.620857
Policy Loss                  -560.29047
Q Predictions Mean           554.1667
Q Predictions Std            245.90453
Q Predictions Max            955.2624
Q Predictions Min            224.00615
V Predictions Mean           561.72125
V Predictions Std            245.51239
V Predictions Max            960.3256
V Predictions Min            230.49055
Log Pis Mean                 -0.29365793
Log Pis Std                  3.167773
Log Pis Max                  9.017248
Log Pis Min                  -6.825396
Policy mu Mean               0.16897821
Policy mu Std                0.8810352
Policy mu Max                2.4743404
Policy mu Min                -2.6210074
Policy log std Mean          -0.46411452
Policy log std Std           0.22301826
Policy log std Max           -0.081804045
Policy log std Min           -1.4099196
Z mean eval                  1.6581113
Z variance eval              0.02714703
total_rewards                [3625.93309588 3449.09692828 3628.96990868 3674.94677924 3683.73298121
 3608.60484683 3508.48010231 3536.91431339 3546.88356542 3470.58652697]
total_rewards_mean           3573.4149048204176
total_rewards_std            78.640332317214
total_rewards_max            3683.7329812077005
total_rewards_min            3449.0969282761625
Number of train steps total  29000
Number of env steps total    147000
Number of rollouts total     0
Train Time (s)               42.31541578704491
(Previous) Eval Time (s)     32.3956492850557
Sample Time (s)              21.46703255129978
Epoch Time (s)               96.17809762340039
Total Train Time (s)         2791.8865153039806
Epoch                        28
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:02:20.261646 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #28 | Epoch Duration: 95.90057134628296
2020-01-11 13:02:20.261841 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #28 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6575752
Z variance train             0.027196934
KL Divergence                17.45718
KL Loss                      1.745718
QF Loss                      159.87155
VF Loss                      30.11134
Policy Loss                  -577.23224
Q Predictions Mean           572.5016
Q Predictions Std            262.8892
Q Predictions Max            986.64374
Q Predictions Min            228.02573
V Predictions Mean           575.4907
V Predictions Std            260.7483
V Predictions Max            989.2197
V Predictions Min            231.86612
Log Pis Mean                 -0.24156313
Log Pis Std                  3.3678453
Log Pis Max                  9.481196
Log Pis Min                  -6.5673943
Policy mu Mean               0.14427069
Policy mu Std                0.9240663
Policy mu Max                3.1558218
Policy mu Min                -2.400493
Policy log std Mean          -0.45407328
Policy log std Std           0.22298846
Policy log std Max           -0.06876079
Policy log std Min           -1.5007874
Z mean eval                  1.6772344
Z variance eval              0.030634668
total_rewards                [3946.92814518 3679.38992324 3952.80315624 3775.25970158 3713.42669026
 3832.92652702 3847.59403404 3679.94408416 3883.63085213 3806.02637528]
total_rewards_mean           3811.792948913736
total_rewards_std            95.39023362771717
total_rewards_max            3952.803156240816
total_rewards_min            3679.3899232424988
Number of train steps total  30000
Number of env steps total    152000
Number of rollouts total     0
Train Time (s)               42.44721477571875
(Previous) Eval Time (s)     32.117874330841005
Sample Time (s)              21.49486838746816
Epoch Time (s)               96.05995749402791
Total Train Time (s)         2886.4317364036106
Epoch                        29
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:03:54.806501 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #29 | Epoch Duration: 94.5445499420166
2020-01-11 13:03:54.806627 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #29 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.6758677
Z variance train             0.030652165
KL Divergence                18.109795
KL Loss                      1.8109795
QF Loss                      122.54306
VF Loss                      57.039158
Policy Loss                  -589.9078
Q Predictions Mean           590.3627
Q Predictions Std            291.64346
Q Predictions Max            1052.1368
Q Predictions Min            237.9438
V Predictions Mean           594.5376
V Predictions Std            288.14334
V Predictions Max            1043.5312
V Predictions Min            242.38663
Log Pis Mean                 -0.18591428
Log Pis Std                  3.4023447
Log Pis Max                  11.095757
Log Pis Min                  -7.090241
Policy mu Mean               0.07597696
Policy mu Std                0.8923723
Policy mu Max                2.4517636
Policy mu Min                -2.8139453
Policy log std Mean          -0.42308435
Policy log std Std           0.21284893
Policy log std Max           -0.05305621
Policy log std Min           -1.4591577
Z mean eval                  1.70501
Z variance eval              0.030382406
total_rewards                [3710.31168588 3837.92783062 3794.31602835 3939.13380361 1264.83082036
 3972.41733441 3912.9336196  3829.75607714 3970.22500915 3687.36148661]
total_rewards_mean           3591.9213695720273
total_rewards_std            781.538213658533
total_rewards_max            3972.4173344120554
total_rewards_min            1264.8308203556874
Number of train steps total  31000
Number of env steps total    157000
Number of rollouts total     0
Train Time (s)               43.83397172112018
(Previous) Eval Time (s)     30.60223420104012
Sample Time (s)              21.506750700529665
Epoch Time (s)               95.94295662268996
Total Train Time (s)         2983.4585837787017
Epoch                        30
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:05:31.837710 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #30 | Epoch Duration: 97.03098630905151
2020-01-11 13:05:31.837838 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #30 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.70429
Z variance train             0.030391488
KL Divergence                18.316103
KL Loss                      1.8316103
QF Loss                      150.75728
VF Loss                      35.64144
Policy Loss                  -600.43634
Q Predictions Mean           596.3391
Q Predictions Std            303.25516
Q Predictions Max            1102.1014
Q Predictions Min            232.03543
V Predictions Mean           598.9276
V Predictions Std            299.45108
V Predictions Max            1086.6866
V Predictions Min            236.6767
Log Pis Mean                 -0.62261677
Log Pis Std                  3.2029912
Log Pis Max                  8.347695
Log Pis Min                  -8.025433
Policy mu Mean               0.056232136
Policy mu Std                0.86135644
Policy mu Max                2.320281
Policy mu Min                -2.3070376
Policy log std Mean          -0.43735743
Policy log std Std           0.22598304
Policy log std Max           -0.07654556
Policy log std Min           -1.642095
Z mean eval                  1.7227081
Z variance eval              0.02600883
total_rewards                [3911.60691777 3867.8612136  3896.18373867 3998.64414795 4028.08441913
 3885.98183657 3869.35713857 3974.07172404 4092.42388191 4035.68194874]
total_rewards_mean           3955.9896966940514
total_rewards_std            76.176549330897
total_rewards_max            4092.4238819134353
total_rewards_min            3867.8612135981034
Number of train steps total  32000
Number of env steps total    162000
Number of rollouts total     0
Train Time (s)               43.76305831409991
(Previous) Eval Time (s)     31.689995681867003
Sample Time (s)              21.660417574923486
Epoch Time (s)               97.1134715708904
Total Train Time (s)         3078.651874409057
Epoch                        31
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:07:07.031406 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #31 | Epoch Duration: 95.19345712661743
2020-01-11 13:07:07.031587 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #31 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7236696
Z variance train             0.025973987
KL Divergence                18.948772
KL Loss                      1.8948773
QF Loss                      138.42473
VF Loss                      50.495758
Policy Loss                  -705.56854
Q Predictions Mean           701.58203
Q Predictions Std            320.22345
Q Predictions Max            1192.1971
Q Predictions Min            245.64796
V Predictions Mean           703.2892
V Predictions Std            316.1158
V Predictions Max            1179.1351
V Predictions Min            254.56488
Log Pis Mean                 0.21200214
Log Pis Std                  3.2604585
Log Pis Max                  12.618551
Log Pis Min                  -6.9899282
Policy mu Mean               0.01760473
Policy mu Std                0.94023377
Policy mu Max                2.8478248
Policy mu Min                -2.370255
Policy log std Mean          -0.47180378
Policy log std Std           0.23501635
Policy log std Max           -0.045796543
Policy log std Min           -1.5181723
Z mean eval                  1.761437
Z variance eval              0.024826769
total_rewards                [3997.20837802 4058.01024451 3946.18910031 4033.75966836 4079.07090757
 4176.36620998 4013.27251139 4158.60600998 4083.89637642 3996.80479251]
total_rewards_mean           4054.318419905404
total_rewards_std            69.02281367730966
total_rewards_max            4176.366209982842
total_rewards_min            3946.1891003098517
Number of train steps total  33000
Number of env steps total    167000
Number of rollouts total     0
Train Time (s)               43.45320475520566
(Previous) Eval Time (s)     29.76971656223759
Sample Time (s)              21.108813083730638
Epoch Time (s)               94.33173440117389
Total Train Time (s)         3175.17664096551
Epoch                        32
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:08:43.557521 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #32 | Epoch Duration: 96.52573537826538
2020-01-11 13:08:43.557779 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #32 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7603706
Z variance train             0.024814371
KL Divergence                19.653616
KL Loss                      1.9653616
QF Loss                      152.53018
VF Loss                      39.55108
Policy Loss                  -710.3494
Q Predictions Mean           709.30383
Q Predictions Std            338.89688
Q Predictions Max            1215.605
Q Predictions Min            257.50848
V Predictions Mean           713.64136
V Predictions Std            335.77423
V Predictions Max            1212.1195
V Predictions Min            262.20078
Log Pis Mean                 0.078160554
Log Pis Std                  3.2945733
Log Pis Max                  10.038805
Log Pis Min                  -7.2271013
Policy mu Mean               0.054890815
Policy mu Std                0.9362431
Policy mu Max                2.5031528
Policy mu Min                -2.1412113
Policy log std Mean          -0.46457693
Policy log std Std           0.23096186
Policy log std Max           -0.060051404
Policy log std Min           -1.5508921
Z mean eval                  1.763665
Z variance eval              0.026596207
total_rewards                [4029.51356759 4111.12098674 4074.43708371 3956.59466184 3794.56929378
 3855.62681448 4270.30193264 4087.09765866 3885.90078721 4035.68243773]
total_rewards_mean           4010.0845224388904
total_rewards_std            133.27161988186495
total_rewards_max            4270.301932640566
total_rewards_min            3794.5692937794715
Number of train steps total  34000
Number of env steps total    172000
Number of rollouts total     0
Train Time (s)               43.260340380016714
(Previous) Eval Time (s)     31.963442329782993
Sample Time (s)              21.72004848672077
Epoch Time (s)               96.94383119652048
Total Train Time (s)         3272.5101396888494
Epoch                        33
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:10:20.892399 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #33 | Epoch Duration: 97.33446168899536
2020-01-11 13:10:20.892585 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #33 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7627236
Z variance train             0.026588555
KL Divergence                19.24765
KL Loss                      1.924765
QF Loss                      211.40443
VF Loss                      44.433987
Policy Loss                  -770.23566
Q Predictions Mean           768.1849
Q Predictions Std            339.6553
Q Predictions Max            1240.3774
Q Predictions Min            252.86581
V Predictions Mean           771.69226
V Predictions Std            337.0856
V Predictions Max            1218.7611
V Predictions Min            256.75513
Log Pis Mean                 0.5810482
Log Pis Std                  3.5844746
Log Pis Max                  10.855139
Log Pis Min                  -5.8510513
Policy mu Mean               0.015143187
Policy mu Std                0.98229116
Policy mu Max                2.6882925
Policy mu Min                -3.0781655
Policy log std Mean          -0.4938961
Policy log std Std           0.24346676
Policy log std Max           -0.10703277
Policy log std Min           -1.793875
Z mean eval                  1.7625809
Z variance eval              0.03201181
total_rewards                [4362.34411473 4091.48663088 4197.18655178 4226.57998139 4043.24074053
 4178.69396481 4064.21123995 4185.65013362 4208.43294407 4216.94757443]
total_rewards_mean           4177.477387617948
total_rewards_std            88.20586516367179
total_rewards_max            4362.344114727202
total_rewards_min            4043.240740528118
Number of train steps total  35000
Number of env steps total    177000
Number of rollouts total     0
Train Time (s)               41.82646150980145
(Previous) Eval Time (s)     32.353807064238936
Sample Time (s)              20.06849890667945
Epoch Time (s)               94.24876748071983
Total Train Time (s)         3366.258900405839
Epoch                        34
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:11:54.641617 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #34 | Epoch Duration: 93.74889802932739
2020-01-11 13:11:54.641760 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #34 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.76393
Z variance train             0.03211578
KL Divergence                18.732975
KL Loss                      1.8732976
QF Loss                      130.6392
VF Loss                      45.200127
Policy Loss                  -767.8724
Q Predictions Mean           758.98035
Q Predictions Std            356.0424
Q Predictions Max            1246.1046
Q Predictions Min            261.94604
V Predictions Mean           767.92694
V Predictions Std            355.11023
V Predictions Max            1246.8025
V Predictions Min            272.32123
Log Pis Mean                 0.0857845
Log Pis Std                  3.5025406
Log Pis Max                  12.109724
Log Pis Min                  -6.4053335
Policy mu Mean               0.072730206
Policy mu Std                0.9476609
Policy mu Max                2.3968682
Policy mu Min                -2.3062422
Policy log std Mean          -0.48189226
Policy log std Std           0.24552834
Policy log std Max           -0.02354765
Policy log std Min           -1.8787483
Z mean eval                  1.7914375
Z variance eval              0.027954247
total_rewards                [4264.11938824 4338.8948006  4267.35439648 4417.75297312 4406.73412138
 4289.02527991 4156.55457093 4334.02115857 4189.07231036 4317.41727431]
total_rewards_mean           4298.094627388478
total_rewards_std            79.71849142375869
total_rewards_max            4417.752973120028
total_rewards_min            4156.554570926937
Number of train steps total  36000
Number of env steps total    182000
Number of rollouts total     0
Train Time (s)               44.266317484900355
(Previous) Eval Time (s)     31.85366951394826
Sample Time (s)              21.329572279006243
Epoch Time (s)               97.44955927785486
Total Train Time (s)         3463.903490829747
Epoch                        35
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:13:32.286860 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #35 | Epoch Duration: 97.64494276046753
2020-01-11 13:13:32.287049 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #35 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.792774
Z variance train             0.027984345
KL Divergence                19.109781
KL Loss                      1.9109782
QF Loss                      186.15009
VF Loss                      68.417694
Policy Loss                  -782.692
Q Predictions Mean           778.2642
Q Predictions Std            373.88458
Q Predictions Max            1329.1456
Q Predictions Min            255.30331
V Predictions Mean           778.00085
V Predictions Std            372.1411
V Predictions Max            1317.0128
V Predictions Min            259.64163
Log Pis Mean                 0.8567048
Log Pis Std                  4.0499516
Log Pis Max                  11.966231
Log Pis Min                  -7.833919
Policy mu Mean               0.042244542
Policy mu Std                1.014811
Policy mu Max                2.5400286
Policy mu Min                -2.8833814
Policy log std Mean          -0.49927464
Policy log std Std           0.2561925
Policy log std Max           -0.0281557
Policy log std Min           -1.9259164
Z mean eval                  1.792972
Z variance eval              0.034658805
total_rewards                [4477.94622984 4341.04454965 4262.71482407 4438.40452072 4369.84114135
 4331.07488011 4407.51339641 4609.72283156 4410.52475098 4188.31188955]
total_rewards_mean           4383.709901424894
total_rewards_std            110.3824198405617
total_rewards_max            4609.722831560889
total_rewards_min            4188.311889547502
Number of train steps total  37000
Number of env steps total    187000
Number of rollouts total     0
Train Time (s)               43.325576439034194
(Previous) Eval Time (s)     32.04880224680528
Sample Time (s)              21.396969705820084
Epoch Time (s)               96.77134839165956
Total Train Time (s)         3559.584328929428
Epoch                        36
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:15:07.971503 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #36 | Epoch Duration: 95.6843113899231
2020-01-11 13:15:07.971708 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #36 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.7909782
Z variance train             0.03459408
KL Divergence                19.044308
KL Loss                      1.9044307
QF Loss                      198.32599
VF Loss                      38.240124
Policy Loss                  -855.11005
Q Predictions Mean           849.8803
Q Predictions Std            379.2237
Q Predictions Max            1345.5767
Q Predictions Min            261.06635
V Predictions Mean           853.85425
V Predictions Std            378.29037
V Predictions Max            1347.5538
V Predictions Min            258.81378
Log Pis Mean                 0.52666783
Log Pis Std                  3.3548326
Log Pis Max                  11.139956
Log Pis Min                  -7.7290106
Policy mu Mean               0.025746236
Policy mu Std                0.96954167
Policy mu Max                2.3731723
Policy mu Min                -2.3516304
Policy log std Mean          -0.49954593
Policy log std Std           0.26622272
Policy log std Max           -0.054417476
Policy log std Min           -1.698126
Z mean eval                  1.8462458
Z variance eval              0.01787645
total_rewards                [4201.82680052 4400.68525456 4339.56710068 4188.13837346 4408.60400272
 4356.71408992 4240.52828534 4295.0123606  4194.71355891 4368.09894114]
total_rewards_mean           4299.388876784935
total_rewards_std            82.55066388061809
total_rewards_max            4408.604002720664
total_rewards_min            4188.138373462806
Number of train steps total  38000
Number of env steps total    192000
Number of rollouts total     0
Train Time (s)               43.50834957091138
(Previous) Eval Time (s)     30.96148019609973
Sample Time (s)              21.091371241025627
Epoch Time (s)               95.56120100803673
Total Train Time (s)         3656.5657838168554
Epoch                        37
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:16:44.954639 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #37 | Epoch Duration: 96.98271465301514
2020-01-11 13:16:44.954889 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #37 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8472153
Z variance train             0.01788735
KL Divergence                20.802034
KL Loss                      2.0802035
QF Loss                      322.19202
VF Loss                      85.758896
Policy Loss                  -881.6459
Q Predictions Mean           880.7978
Q Predictions Std            390.57278
Q Predictions Max            1446.9421
Q Predictions Min            270.96408
V Predictions Mean           880.2649
V Predictions Std            389.33936
V Predictions Max            1442.4596
V Predictions Min            261.87442
Log Pis Mean                 0.300747
Log Pis Std                  3.298462
Log Pis Max                  10.336834
Log Pis Min                  -6.6074185
Policy mu Mean               -0.030406967
Policy mu Std                0.97060084
Policy mu Max                2.5133967
Policy mu Min                -2.6227758
Policy log std Mean          -0.48952666
Policy log std Std           0.25298738
Policy log std Max           -0.010105312
Policy log std Min           -1.6307201
Z mean eval                  1.865009
Z variance eval              0.01560286
total_rewards                [4298.57000654 4417.6070239  4155.85532372 4489.00420186 4190.91247359
 4307.06918909 4312.59314719 4071.59734287 4271.48438605 4193.73028597]
total_rewards_mean           4270.842338077934
total_rewards_std            117.56481439648198
total_rewards_max            4489.004201861221
total_rewards_min            4071.5973428666694
Number of train steps total  39000
Number of env steps total    197000
Number of rollouts total     0
Train Time (s)               43.52528098132461
(Previous) Eval Time (s)     32.38273781212047
Sample Time (s)              21.407889638561755
Epoch Time (s)               97.31590843200684
Total Train Time (s)         3752.063366523944
Epoch                        38
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:18:20.452606 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #38 | Epoch Duration: 95.49755501747131
2020-01-11 13:18:20.452793 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #38 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8651285
Z variance train             0.01559487
KL Divergence                21.507
KL Loss                      2.1507
QF Loss                      137.6814
VF Loss                      92.44415
Policy Loss                  -905.0648
Q Predictions Mean           898.81836
Q Predictions Std            419.47894
Q Predictions Max            1464.7845
Q Predictions Min            269.07904
V Predictions Mean           902.75104
V Predictions Std            417.28006
V Predictions Max            1446.949
V Predictions Min            278.17352
Log Pis Mean                 0.55937356
Log Pis Std                  3.6366942
Log Pis Max                  12.339548
Log Pis Min                  -5.5139065
Policy mu Mean               -0.015056311
Policy mu Std                0.9651629
Policy mu Max                2.4770067
Policy mu Min                -2.8489897
Policy log std Mean          -0.48547044
Policy log std Std           0.25118575
Policy log std Max           -0.048802465
Policy log std Min           -1.7813113
Z mean eval                  1.8748318
Z variance eval              0.013171451
total_rewards                [4769.93290827 4580.65852388 4620.76419977 4734.0912128  4486.28702408
 4604.42958398 4633.26529122 4465.13661702 4594.80229352 4591.77123298]
total_rewards_mean           4608.113888751186
total_rewards_std            89.07538491754516
total_rewards_max            4769.932908273719
total_rewards_min            4465.136617023151
Number of train steps total  40000
Number of env steps total    202000
Number of rollouts total     0
Train Time (s)               43.22206576168537
(Previous) Eval Time (s)     30.56412765197456
Sample Time (s)              21.837384913116693
Epoch Time (s)               95.62357832677662
Total Train Time (s)         3847.6009027049877
Epoch                        39
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:19:55.992843 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #39 | Epoch Duration: 95.53987884521484
2020-01-11 13:19:55.993116 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #39 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8745253
Z variance train             0.013175577
KL Divergence                22.213459
KL Loss                      2.221346
QF Loss                      242.82385
VF Loss                      87.23586
Policy Loss                  -925.4173
Q Predictions Mean           916.97534
Q Predictions Std            431.6822
Q Predictions Max            1489.5942
Q Predictions Min            271.84863
V Predictions Mean           922.02734
V Predictions Std            426.43524
V Predictions Max            1471.8368
V Predictions Min            282.47174
Log Pis Mean                 0.659155
Log Pis Std                  3.4385557
Log Pis Max                  11.475911
Log Pis Min                  -6.44726
Policy mu Mean               -0.00047588968
Policy mu Std                1.0198287
Policy mu Max                2.886326
Policy mu Min                -2.631104
Policy log std Mean          -0.5099922
Policy log std Std           0.2723689
Policy log std Max           -0.0995183
Policy log std Min           -1.8496935
Z mean eval                  1.8704599
Z variance eval              0.020186761
total_rewards                [4567.02099442 4510.47073024 4401.00660371 4486.27139078 4544.53997381
 4537.89961207 4512.91248296 4440.4075391  4371.55224293 4534.03404316]
total_rewards_mean           4490.611561317698
total_rewards_std            62.05120076193455
total_rewards_max            4567.020994422799
total_rewards_min            4371.552242933667
Number of train steps total  41000
Number of env steps total    207000
Number of rollouts total     0
Train Time (s)               43.79435905907303
(Previous) Eval Time (s)     30.480160533916205
Sample Time (s)              22.022109216079116
Epoch Time (s)               96.29662880906835
Total Train Time (s)         3946.307220946066
Epoch                        40
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:21:34.698828 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #40 | Epoch Duration: 98.70552706718445
2020-01-11 13:21:34.698968 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #40 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8711998
Z variance train             0.020245332
KL Divergence                21.602934
KL Loss                      2.1602933
QF Loss                      211.41788
VF Loss                      76.311
Policy Loss                  -945.0127
Q Predictions Mean           946.83057
Q Predictions Std            444.9426
Q Predictions Max            1516.571
Q Predictions Min            271.4715
V Predictions Mean           941.0121
V Predictions Std            441.13876
V Predictions Max            1506.7993
V Predictions Min            272.3872
Log Pis Mean                 0.292354
Log Pis Std                  3.5337758
Log Pis Max                  10.584921
Log Pis Min                  -6.563359
Policy mu Mean               0.08018626
Policy mu Std                0.98344374
Policy mu Max                2.758355
Policy mu Min                -2.2926068
Policy log std Mean          -0.4838504
Policy log std Std           0.27592275
Policy log std Max           -0.08923848
Policy log std Min           -1.9567071
Z mean eval                  1.8853958
Z variance eval              0.015078606
total_rewards                [4479.84615043 4609.58956945 4535.77348273 4536.29752029 4508.50038365
 4794.93243288 4679.25697496 4536.24520018 4878.49137144 4697.63079134]
total_rewards_mean           4625.656387734913
total_rewards_std            126.46574543213134
total_rewards_max            4878.491371435974
total_rewards_min            4479.846150430956
Number of train steps total  42000
Number of env steps total    212000
Number of rollouts total     0
Train Time (s)               42.866991941817105
(Previous) Eval Time (s)     32.8888155198656
Sample Time (s)              21.875162133481354
Epoch Time (s)               97.63096959516406
Total Train Time (s)         4043.042207996361
Epoch                        41
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:23:11.435379 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #41 | Epoch Duration: 96.73625421524048
2020-01-11 13:23:11.435569 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #41 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8853323
Z variance train             0.015009066
KL Divergence                22.616392
KL Loss                      2.2616394
QF Loss                      181.07072
VF Loss                      84.155594
Policy Loss                  -956.0091
Q Predictions Mean           950.57465
Q Predictions Std            460.56714
Q Predictions Max            1543.5399
Q Predictions Min            196.46454
V Predictions Mean           953.58264
V Predictions Std            457.92645
V Predictions Max            1544.3177
V Predictions Min            221.9864
Log Pis Mean                 0.3543234
Log Pis Std                  3.6568136
Log Pis Max                  12.143593
Log Pis Min                  -6.925106
Policy mu Mean               0.026537674
Policy mu Std                0.96838295
Policy mu Max                2.7585096
Policy mu Min                -2.6952069
Policy log std Mean          -0.49374
Policy log std Std           0.27509674
Policy log std Max           -0.016464382
Policy log std Min           -1.6403594
Z mean eval                  1.9114069
Z variance eval              0.010052593
total_rewards                [4726.81116392 4788.24418733 4787.60331898 4763.67728311 4784.28641556
 4733.22048907 4848.35815074 4503.92492825 4773.88972308 4685.30300233]
total_rewards_mean           4739.531866238159
total_rewards_std            88.85178491113889
total_rewards_max            4848.358150744882
total_rewards_min            4503.924928253288
Number of train steps total  43000
Number of env steps total    217000
Number of rollouts total     0
Train Time (s)               42.34037375962362
(Previous) Eval Time (s)     31.993841150775552
Sample Time (s)              21.5357922767289
Epoch Time (s)               95.87000718712807
Total Train Time (s)         4139.921473968308
Epoch                        42
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:24:48.315351 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #42 | Epoch Duration: 96.87965893745422
2020-01-11 13:24:48.315532 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #42 | Started Training: True
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.912514
Z variance train             0.01004279
KL Divergence                23.79985
KL Loss                      2.379985
QF Loss                      274.67453
VF Loss                      116.109764
Policy Loss                  -1028.4525
Q Predictions Mean           1030.912
Q Predictions Std            453.84097
Q Predictions Max            1603.6067
Q Predictions Min            277.5246
V Predictions Mean           1032.0232
V Predictions Std            450.2161
V Predictions Max            1613.3221
V Predictions Min            286.79727
Log Pis Mean                 0.6879817
Log Pis Std                  3.6948128
Log Pis Max                  11.301444
Log Pis Min                  -7.237737
Policy mu Mean               0.025068423
Policy mu Std                1.0350338
Policy mu Max                3.0605705
Policy mu Min                -2.7941632
Policy log std Mean          -0.5078104
Policy log std Std           0.27949294
Policy log std Max           -0.03891574
Policy log std Min           -1.954822
Z mean eval                  1.8949807
Z variance eval              0.0133387325
total_rewards                [4778.17486993 4981.0149229  4927.6604487  4694.11266093 4963.21260248
 5093.6399771  4811.35074979 4882.76054644 5016.56796097 4883.7071148 ]
total_rewards_mean           4903.220185405264
total_rewards_std            113.11829680587303
total_rewards_max            5093.63997710216
total_rewards_min            4694.1126609255025
Number of train steps total  44000
Number of env steps total    222000
Number of rollouts total     0
Train Time (s)               42.64674807572737
(Previous) Eval Time (s)     33.00324227614328
Sample Time (s)              21.83800086705014
Epoch Time (s)               97.4879912189208
Total Train Time (s)         4238.371556752827
Epoch                        43
---------------------------  ----------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:26:26.766025 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #43 | Epoch Duration: 98.45036292076111
2020-01-11 13:26:26.766160 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #43 | Started Training: True
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
Z mean train                 1.8948425
Z variance train             0.0133519
KL Divergence                23.205814
KL Loss                      2.3205814
QF Loss                      199.22879
VF Loss                      81.07489
Policy Loss                  -1090.3064
Q Predictions Mean           1088.9043
Q Predictions Std            460.66116
Q Predictions Max            1648.0137
Q Predictions Min            279.9093
V Predictions Mean           1091.4546
V Predictions Std            458.32193
V Predictions Max            1664.7235
V Predictions Min            283.26486
Log Pis Mean                 1.1016394
Log Pis Std                  3.794955
Log Pis Max                  10.671128
Log Pis Min                  -6.529024
Policy mu Mean               -0.03347673
Policy mu Std                1.0509853
Policy mu Max                2.9624019
Policy mu Min                -2.556752
Policy log std Mean          -0.53069896
Policy log std Std           0.29415345
Policy log std Max           -0.030977607
Policy log std Min           -2.0328226
Z mean eval                  1.8877357
Z variance eval              0.01387343
total_rewards                [4509.2360483  4708.1623878  4757.57789002 4538.02959373 4747.6359794
 4783.41534067 4768.04894099 4567.82348565 4570.37050892 4767.40539121]
total_rewards_mean           4671.770556668182
total_rewards_std            105.22072404782914
total_rewards_max            4783.4153406681735
total_rewards_min            4509.236048297228
Number of train steps total  45000
Number of env steps total    227000
Number of rollouts total     0
Train Time (s)               42.375199652742594
(Previous) Eval Time (s)     33.96535968314856
Sample Time (s)              21.132043573074043
Epoch Time (s)               97.4726029089652
Total Train Time (s)         4334.496799193323
Epoch                        44
---------------------------  ---------------------------------------------------------------------------------------------------------------------------------------------
2020-01-11 13:28:02.896367 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #44 | Epoch Duration: 96.13004970550537
2020-01-11 13:28:02.896639 UTC | [2020_01_10_11_29_18] [2020_01_11_00_48_19] [2020_01_11_12_15_48] Iteration #44 | Started Training: True
